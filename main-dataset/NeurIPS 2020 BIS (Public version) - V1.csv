paper title (separate scrape),paper authors (separate scrape),title,paper identifier,paper link,impact statement,impact statement title,word count,sentence count,opt out,ambiguous opt out,manually corrected,human review,Image based PDF,paper title (subjects),primary subject area,secondary subject areas,clustering subject preference,authors,affiliations,academic,industry,mixed,country
A graph similarity for deep learning,Seongmin Ok,A Graph Similarity for Deep Learning,0004d0b59e19461ff126e3a08a814c33,https://proceedings.neurips.cc/paper/2020/file/0004d0b59e19461ff126e3a08a814c33-Paper.pdf,"This article mainly discusses two topics: how to measure similarity between graphs, and how to learn from graphs. One of the most important subjects in both fields is the molecular graph. A chemically meaningful similarity between molecules helps find new drugs and invent new materials of great value. Many chemical search engines support similarity search based on fingerprints, which indicate the existence of certain substructures. The fingerprints have been useful to find molecules of interest, but they are inherently limited to local properties. The proposed graph similarity is simple, fast and efficient. The proposed graph neural network reports particular strength in molecular property prediction and molecular graph generation, albeit not studied extensively. It is possible that the proposed algorithms provide another, global perspective to molecular similarity. Another task for which the proposed neural network showed strength is the node classification. The node classification is mostly used to automatically categorize articles, devices, people, and other entities in interconnected networks at large scale. Some related examples include identifying false accounts in social network services, classifying a person for a recommendation system based on its friends’ interest, and detecting malicious edge-devices in Internet of Things or mobile networks. As with every machine learning applications, assessing and understanding the data is crucial in such cases. Especially in graph-structured data, we believe that the characteristic of data is the most important factor in deciding which graph learning algorithm to use. It is necessary to understand the principle and limitation of an algorithm to prevent failure. For example, our method has two caveats. First, it uses sum to collect information from the neighbors, and hence more suitable when the counts indeed matter and not just the distributions. Second, our method decides the similarity between two graphs using the local information. Hence when the ""global"" graph properties such as hamiltonicity, treewidth, and chromatic number are the deciding factor, our algorithm might not be the best choice. Graph learning in general are being applied to more and more tasks and applications. Some of the examples include recommendation systems, transportation analysis, and credit assignments. However, the study of risks regarding graph learning, such as adversarial attack, privacy protection, ethics and biases are still at an early stage. In practice, we should be warned about such risks and devise testing and monitoring framework from the start to avoid undesirable outcomes.",Broader impact,390,22,,,FALSE,FALSE,FALSE,A graph similarity for deep learning,Algorithms -> Representation Learning,Algorithms -> Similarity and Distance Learning,Deep learning,['Seongmin Ok'],{'Samsung Advanced Institute of Technology'},0,1,0,{'South Korea'}
An Unsupervised Information-Theoretic Perceptual Quality Metric,"Sangnie Bhardwaj, Ian Fischer, Johannes Ballé, Troy Chinen",An Unsupervised Information-Theoretic Perceptual Quality Metric,00482b9bed15a272730fcb590ffebddd,https://proceedings.neurips.cc/paper/2020/file/00482b9bed15a272730fcb590ffebddd-Paper.pdf,"Many deep perceptual image metrics rely on the collection of large datasets of rated images as training data; such data could reflect the biases of human raters. While we cannot claim that PIM is free of bias, by being completely unsupervised, one possible source of bias is removed. The broad concern about AI reducing work opportunities, in this case, seems inapplicable. Perceptual metrics are most often used as loss functions in the development of some other product, but the final quality ultimately needs to be verified by human eye. We envision this need for verification continuing into the foreseeable future. On the other hand, good perceptual metrics have the potential to enable other research and technology which improves the lives of AI consumers, as well as reduce the burden on researchers of frequent, tiresome – and often infeasible at scale – human evaluations.",Broader Impact,143,6,FALSE,FALSE,FALSE,FALSE,FALSE,An Unsupervised Information-Theoretic Perceptual Quality Metric,Neuroscience and Cognitive Science -> Visual Perception,Algorithms -> Representation Learning; Algorithms -> Unsupervised Learning; Theory -> Information Theory,Neuroscience and cognitive science,"['Sangnie Bhardwaj', ' Ian Fischer', ' Johannes Ballé', ' Troy Chinen']","{'Google', 'Google LLC'}",0,1,0,{'USA'}
Self-Supervised MultiModal Versatile Networks,"Jean-Baptiste Alayrac, Adria Recasens, Rosalia Schneider, Relja Arandjelović, Jason Ramapuram, Jeffrey De Fauw, Lucas Smaira, Sander Dieleman, Andrew Zisserman",Self-Supervised MultiModal Versatile Networks,0060ef47b12160b9198302ebdb144dcf,https://proceedings.neurips.cc/paper/2020/file/0060ef47b12160b9198302ebdb144dcf-Paper.pdf,"Potential benefits. Our method can enable a better user experience when searching for visual or audio content on the web since we can index that type of media based on our learned multimodal embeddings. More broadly, learning video representations without labels in such a self-supervised manner greatly increases the scale at which we can train models, to the extent of leveraging any available collection of web video data. This enables capturing a more representative view of the overall distribution of web content as opposed to smaller scale curated datasets such as Kinetics. We believe this can be an important factor in designing methods that better understand whether or not a given content is safe ( e.g . to filter out violent or undesired web content) thanks to the better coverage of the overall distribution. Potential risks. Every method that learns from data, self-supervised methods even more deeply so, brings the risk of learning biases and perpetuating them in the form of decisions. We encourage the deployment of our method to be done with careful consideration of the consequences from any potential underlying biases in the data.",6 Broader impact,186,9,,,FALSE,FALSE,FALSE,Self-Supervised MultiModal Versatile Networks,Algorithms -> Representation Learning,Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Baptiste Alayrac', ' Adria Recasens', ' Rosalia Schneider', ' Relja Arandjelović', ' Jason Ramapuram', ' Jeffrey De Fauw', ' Lucas Smaira', ' Sander Dieleman', ' Andrew Zisserman']","{'DeepMind', 'Deepmind', 'University of Geneva'}",1,1,1,"{'UK', 'Switzerland'}"
"Benchmarking Deep Inverse Models over time, and the Neural-Adjoint method","Simiao Ren, Willie Padilla, Jordan Malof","Benchmarking Deep Inverse Models over time, and the Neural-Adjoint method",007ff380ee5ac49ffc34442f5c2a2b86,https://proceedings.neurips.cc/paper/2020/file/007ff380ee5ac49ffc34442f5c2a2b86-Paper.pdf,"We believe the most proximate impacts of this work will be positive. In particular, higher-dimensional inverse problems like our meta-material problem present a major obstacle to the development of beneficial technologies across many disciplines e.g., in materials, chemistry, and bio-chemistry. The Neural-Adjoint method represents a tool to develop much more accurate inverse designs for these complex problems. Furthermore, the ability to replicate inverse studies for complex problems, as we propose, will also accelerate progress, and enable many researchers to study these problems even if they lack sophisticated simulation equipment or expertise. As with many tools, we also acknowledge that these advances can be used to accelerate the development of technologies that are used for negative purposes, which we believe is the most immediate negative outcome of our work.",Broader Impact,128,5,,,FALSE,FALSE,FALSE,"Benchmarking Deep Inverse Models over time, and the Neural-Adjoint method",Deep Learning,Algorithms -> Regression; Applications -> Information Retrieval; Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models; Deep Learning -> Supervised Deep Networks,Deep learning,"['Simiao Ren', ' Willie Padilla', ' Jordan Malof']",{'Duke University'},1,0,0,{'USA'}
Off-Policy Evaluation and Learning for External Validity under a Covariate Shift,"Masatoshi Uehara, Masahiro Kato, Shota Yasui",Off-Policy Evaluation and Learning for External Validity under a Covariate Shift,0084ae4bc24c0795d1e6a4f58444d39b,https://proceedings.neurips.cc/paper/2020/file/0084ae4bc24c0795d1e6a4f58444d39b-Paper.pdf,"Because the policies in sequential decision-making problems are critical in various real-world applications, the OPE methods are employed to evaluate the new policy and reduce the risk of deploying a poor policy. We focus on the OPE under a covariate shift between a historical and evaluation data. This setting has many practical applications. For example, in the advertising applications, we usually deliver advertisements only in the particular region to test the market in the beginning of the planned advertising campaign, then expand to other regions that have different feature distribution. Thus, we face the covariate shift in the evaluation and training a new policy for the new region. Despite its practical importance, the OPE methods under the covariate shift have not been researched well, and people apply standard OPE methods to cases under the covariate shift. For instance, Hirano et al. (2003a) briefly discuss such a setting in Section 4.2, but did not discuss estimation of the density ratio, i.e., simply considered a case where the density ratio is known. As we explained, the standard methods are not robust against the covariate shift. Among the standard methods, the IPW estimator is not consistent, and the DM and DR estimator has consistency when the model of conditional outcome is correct. In particular, under a covariate shift, the standard DR estimator is not doubly robust; i.e., it is consistent only when the model of conditional outcome is correct. Thus, the standard estimator has a potential risk to mislead the user’s decision making and might cause serious problems in the industry because many decision makings such as ad-optimization rely on the result of the evaluation. On the other hand, the proposed estimator is doubly robust. This robustness helps to avert the potential consequences of incorrect decision-making.",Broader Impact,293,14,,,FALSE,FALSE,FALSE,Off-Policy Evaluation and Learning for External Validity under a Covariate Shift,Probabilistic Methods -> Causal Inference,,Causality,"['Masatoshi Uehara', ' Masahiro Kato', ' Shota Yasui']","{'Cornell University', 'Cyberagent', 'The University of Tokyo'}",1,1,1,"{'Japan', 'USA'}"
Neural Methods for Point-wise Dependency Estimation,"Yao-Hung Hubert Tsai, Han Zhao, Makoto Yamada, Louis-Philippe Morency, Russ R. Salakhutdinov",Neural Methods for Point-wise Dependency Estimation,00a03ec6533ca7f5c644d198d815329c,https://proceedings.neurips.cc/paper/2020/file/00a03ec6533ca7f5c644d198d815329c-Paper.pdf,"This paper presents methods for estimating point-wise dependency between high-dimensional data using neural networks. This work may benefit the applications that require understanding instance- level dependency. Take adversarial samples detection as an example: we can perform point-wise dependency estimation between data and label, and the ones with low point-wise dependency can be regarded as adversarial samples. We should also be aware of the malicious usage for our framework. For instance, people with bad intentions can use our framework to detect samples that have a high point-wise dependency with their of-interest private attributes. Then, these detected samples may be used for malicious purposes.",Broader Impact,102,6,,,FALSE,FALSE,FALSE,Neural Methods for Point-wise Dependency Estimation,Algorithms -> Relational Learning,Algorithms -> Representation Learning; Algorithms -> Similarity and Distance Learning; Deep Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Hung Hubert Tsai', ' Han Zhao', ' Makoto Yamada', 'Philippe Morency', ' Russ Salakhutdinov']","{'Kyoto University/RIKEN AIP', 'Carnegie Mellon University'}",1,0,0,"{'Japan', 'USA'}"
Fast and Flexible Temporal Point Processes with Triangular Maps,"Oleksandr Shchur, Nicholas Gao, Marin Biloš, Stephan Günnemann",Fast and Flexible Temporal Point Processes with Triangular Maps,00ac8ed3b4327bdd4ebbebcb2ba10a00,https://proceedings.neurips.cc/paper/2020/file/00ac8ed3b4327bdd4ebbebcb2ba10a00-Paper.pdf,"Existing works have applied TPPs and MJPs for analyzing electronic health records [61, 62], detecting anomalies in network traffic [63, 64] and modeling user behavior on online platforms [65, 66]. Thanks to fast sampling, our model can be used for solving new prediction tasks on such data, and the overall improved scalability allows practitioners to work with larger datasets. We do not find any of the above use cases ethically questionable, though, general precautions must be implemented when handling sensitive personal data. Since our model exploits fast parallel computations, has fewer parameters and converges in fewer iterations, it is likely to be more energy-efficient compared to RNN-based TPPs. However, we haven’t performed experiments analyzing this specific aspect of our model.",Broader impact,120,5,,,FALSE,FALSE,FALSE,Fast and Flexible Temporal Point Processes with Triangular Maps,Probabilistic Methods,Algorithms -> Density Estimation; Applications -> Time Series Analysis; Deep Learning -> Generative Models; Deep Learning -> Predictive Models; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Oleksandr Shchur', ' Nicholas Gao', ' Marin Biloš', ' Stephan Günnemann']",{'Technical University of Munich'},1,0,0,{'Germany'}
Backpropagating Linearly Improves Transferability of Adversarial Examples,"Yiwen Guo, Qizhang Li, Hao Chen",Backpropagating Linearly Improves Transferability of Adversarial Examples,00e26af6ac3b1c1c49d7c3d79c60d000,https://proceedings.neurips.cc/paper/2020/file/00e26af6ac3b1c1c49d7c3d79c60d000-Paper.pdf,"This work can potentially contribute to deeper understanding of DNN models and the adversarial phenomenon. The reliability of different models are compared under practical adversarial attacks, making it possible for commercial machine-learning-as-a-service platforms to choose more suitable models for security-critical applications.",Broader Impact,41,2,FALSE,FALSE,FALSE,FALSE,FALSE,Backpropagating Linearly Improves Transferability of Adversarial Examples,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Adversarial Learning; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> CNN Architectures,Deep learning,"['Yiwen Guo', ' Qizhang Li', ' Hao Chen']","{'UC Davis', 'ByteDance AI Lab'}",1,1,1,"{'USA', 'China'}"
PyGlove: Symbolic Programming for Automated Machine Learning,"Daiyi Peng, Xuanyi Dong, Esteban Real, Mingxing Tan, Yifeng Lu, Gabriel Bender, Hanxiao Liu, Adam Kraft, Chen Liang, Quoc Le",PyGlove: Symbolic Programming for Automated Machine Learning,012a91467f210472fab4e11359bbfef6,https://proceedings.neurips.cc/paper/2020/file/012a91467f210472fab4e11359bbfef6-Paper.pdf,"Symbolic programming/PyGlove makes AutoML more accessible to machine learning practitioners, which means manual trial-and-error of many categories can be replaced by machines. This can also greatly increase the productivity of AutoML research, at the cost of increasing demand for computation, and – a result – increasing CO 2 emissions. We see a big potential in symbolic programming/PyGlove in making machine learning researchers more productive. On a new ground of mutable programs, experiments can be reproduced more easily, modified with lower cost, and shared like data. A large variety of experiments can co-exist in a shared code base that makes combining and comparing different techniques more convenient. Symbolic programming/PyGlove makes it much easier to develop search-based programs which can be used in a broad spectrum of research and product areas. Some potential areas, such as medicine design, have a clear societal benefit, while others potential applications, such as video surveillance, could improve security while raising new privacy concerns.",Broader Impact,157,7,,,FALSE,FALSE,FALSE,PyGlove: Symbolic Programming for Automated Machine Learning,"Data, Challenges, Implementations, and Software -> Software Toolkits",Algorithms -> AutoML,AutoML,"['Daiyi Peng', ' Xuanyi Dong', ' Esteban Real', ' Mingxing Tan', ' Yifeng Lu', ' Gabriel Bender', ' Hanxiao Liu', ' Adam Kraft', ' Chen Liang', ' Quoc V Le']","{'Google', 'University of Technology Sydney', 'Google Brain'}",1,1,1,"{'Australia', 'USA'}"
Fourier Sparse Leverage Scores and Approximate Kernel Learning,"Tamas Erdelyi, Cameron Musco, Christopher Musco",Fourier Sparse Leverage Scores and Approximate Kernel Learning,012d9fe15b2493f21902cd55603382ec,https://proceedings.neurips.cc/paper/2020/file/012d9fe15b2493f21902cd55603382ec-Paper.pdf,"Our work contributes to an improved understanding of sampling for kernel approximation and kernel- related function approximation problems. It ties together work in machine learning, signal processing, and approximation theory, which we feel has value in connecting different research communities. Our results in particular focus on low-dimensional interpolation problems, which arise in application areas such as geology, ecology and other scientific fields, medical imaging, and wireless communication. In many of these areas, data driven methods are used to effect positive societal change. As with all work on efficient learning methods, the algorithms we present, or future variants of them, have the potential to scale inference to even larger data sets than the current state of the art. This can lead to a variety of negative impacts. For example, it may drive the proliferation of massive data collection by corporations and governments for inference tasks, and thus contribute to the associated privacy risks of this data collection. Kernel methods and Gaussian process regression are extremely general tools, used in many applications, including those that may have negative society impacts, such are cell-phone localization, and human and other target tracking. It is possible that our techniques could be employed in these applications.",Broader Impacts,200,9,,,FALSE,FALSE,FALSE,Fourier Sparse Leverage Scores and Approximate Kernel Learning,Algorithms -> Kernel Methods,Applications -> Matrix and Tensor Factorization; Theory -> Spaces of Functions and Kernels,Theory (including computational and statistical analyses),"['Tamas Erdelyi', ' Cameron Musco', ' Christopher Musco']","{'New York University', 'Microsoft Research'}",1,1,1,{'USA'}
Improved Algorithms for Online Submodular Maximization via First-order Regret Bounds,"Nicholas Harvey, Christopher Liaw, Tasuku Soma",Improved Algorithms for Online Submodular Maximization via First-order Regret Bounds,0163cceb20f5ca7b313419c068abd9dc,https://proceedings.neurips.cc/paper/2020/file/0163cceb20f5ca7b313419c068abd9dc-Paper.pdf,This is a theoretical work and does not present any foreseeable societal consequences.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Improved Algorithms for Online Submodular Maximization via First-order Regret Bounds,Optimization -> Submodular Optimization,Algorithms -> Online Learning,Submodular optimization,"['Nicholas Harvey', ' Christopher Liaw', ' Tasuku Soma']","{'University of British Columbia', 'University of Tokyo'}",1,0,0,"{'Japan', 'Canada'}"
Synbols: Probing Learning Algorithms with Synthetic Datasets,"Alexandre Lacoste, Pau Rodríguez López, Frederic Branchaud-Charron, Parmida Atighehchian, Massimo Caccia, Issam Hadj Laradji, Alexandre Drouin, Matthew Craddock, Laurent Charlin, David Vázquez",Synbols: Probing Learning Algorithms with Synthetic Datasets,0169cf885f882efd795951253db5cdfb,https://proceedings.neurips.cc/paper/2020/file/0169cf885f882efd795951253db5cdfb-Paper.pdf,"The introduction of benchmark new datasets has historically fueled progress in machine learning. However, recent large-scale datasets are immense, which makes ML research over-reliant on massive computation cycles. This biases research advances towards fast and computationally-intensive methods, leading to economic and environmental impacts. Economically, reliance on massive computation cycles creates disparities between researchers and organizations with limited computation and hardware budgets, versus those with more resources. With regard to the environment and climate change, recent analyses [48, 28] conclude that the greenhouse gases emitted from training very large-scale models, such as transformers, can be equivalent to 10 years’ worth of individual emissions. While these impacts are not unique to ML research, they are reflective of systemic challenges that ML research could address by developing widely available, high-quality, and diverse datasets that mimic real-world concepts and are conscious of computational hurdles. The Synbols synthetic dataset generator is designed to explore the behavior of learning algorithms and discover brittleness to certain configurations. It is expected to stimulate the improvement of core properties in vision algorithms: • Identifiability of latent properties • Reusability of machine learning models in new environments • Robustness to changes in the data distribution • Better performance on small datasets We designed Synbols with diverse and flexible features (i.e., font diversity, different languages, lower resolution for POC, flexible texture of the background and foreground) and we demonstrated its versatility by reporting numerous findings across 5 different machine learning paradigms. Its characteristics address the economic and environmental challenges and we expect this tool to have a transversal impact on the field of machine vision with potential impact on the field of machine learning. Its broader impacts, both positive and negative, will be guided by the progress that it stimulates in the machine vision community, where potential applications range from autonomous weapons to climate change mitigation. Nevertheless, we hope that our work will help develop more robust and reliable machine learning algorithms while reducing the amount of greenhouse gas emissions from training by way of its smaller scale. Economic impact: reliance on computing-intensive environments creates disparities, especially for researchers and organizations with limited computation and hardware budgets. Environmental impact: Recent analyses [45, 28] conclude that the greenhouse gases emitted from training very large-scale models, such as transformers, can be equivalent to 10 years’ worth of individual emissions",Broader Impact,386,13,,,TRUE,TRUE,FALSE,Synbols: Probing Learning Algorithms with Synthetic Datasets,"Data, Challenges, Implementations, and Software -> Virtual Environments","Algorithms -> Active Learning; Algorithms -> Few-Shot Learning; Algorithms -> Representation Learning; Applications -> Object Detection; Data, Challenges, Implementations, and Software -> Benchmarks; Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories; Data, Challenges, Implementations, and Software -> Software Toolkits","Datasets, challenges, software","['Alexandre Lacoste', ' Pau Rodríguez López', 'Charron', ' Parmida Atighehchian', ' Massimo Caccia', ' Issam Hadj Laradji', ' Alexandre Drouin', ' Matthew Craddock', ' Laurent Charlin', ' David Vázquez']","{'ElementAI', 'MILA', 'University of British Columbia', 'CVC UAB', 'Element AI'}",1,1,1,{'Canada'}
Adversarially Robust Streaming Algorithms via Differential Privacy,"Avinatan Hasidim, Haim Kaplan, Yishay Mansour, Yossi Matias, Uri Stemmer",Adversarially Robust Streaming Algorithms via Differential Privacy,0172d289da48c48de8c5ebf3de9f7ee1,https://proceedings.neurips.cc/paper/2020/file/0172d289da48c48de8c5ebf3de9f7ee1-Paper.pdf,"Our work applies differential privacy and generalization bounds to make streaming algorithms robust to adversarial attacks and feedback loops (in which the value reported by the algorithm affects future updates). The idea of using differential privacy as a tool to protect against adversarial attacks on the randomness of the algorithm may be applicable more generally, when a randomized ML model that reports continuously is exposed to a dangerous feedback loop or malicious users. We believe that the connection we establish in this work is only the beginning, and that, following our work, ideas from the literature of differential privacy will continue to find new applications in the field of robust streaming and other related areas.",Broader Impact,115,3,,,FALSE,FALSE,FALSE,Adversarially Robust Streaming Algorithms via Differential Privacy,Algorithms -> Adaptive Data Analysis,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Theory (including computational and statistical analyses),"['Avinatan Hasidim', ' Haim Kaplan', ' Yishay Mansour', ' Yossi Matias', ' Uri Stemmer']","{'Google', 'Tel Aviv University / Google', 'Ben-Gurion University', 'TAU, GOOGLE'}",1,1,1,"{'USA', 'Israel'}"
Trading Personalization for Accuracy: Data Debugging in Collaborative Filtering,"Long Chen, Yuan Yao, Feng Xu, Miao Xu, Hanghang Tong",Trading Personalization for Accuracy: Data Debugging in Collaborative Filtering,019fa4fdf1c04cf73ba25aa2223769cd,https://proceedings.neurips.cc/paper/2020/file/019fa4fdf1c04cf73ba25aa2223769cd-Paper.pdf,"In this paper, researchers introduce a data debugging method for factorization-based collaborative filtering which improves the recommendation by identifying and correcting the overly personalized ratings in recommendation systems. As far as we know, researches on collaborative filtering have mainly focused on two directions: using advanced models and using additional information, yet few papers explore data from the overly personalized aspect. The current research suggests a new direction for collaborative filtering, orthogonal to the classical two directions. The proposed method, together with others, can improve the accuracy of recommendation systems, which will further ease the process of information acquiring. In a world locked down today due to the impact of coronavirus, easy information acquiring can give those who are not familiar with the Internet, especially disadvantaged people, many conveniences in acquiring necessities and public information online. The current work tries to spot minorities who are identified as over-personalized and decrease their impact in terms of affecting the overall recommendation accuracy. However, it can work naturally in a reverse way: giving more priority to minorities, as a necessary step in the proposed algorithm is to identify the minorities. From the algorithm aspect, we can design special treatment for these minorities. For the social aspect, the idea of this work can be extended to much broader areas like opinion mining and decision making. For example, policymakers can understand better what kind of people are counted as minorities and how the minorities impact the final output; they may also pay special attention to minorities by giving them more weights in future decision making. Finally, there may be a trend of making ‘more personalized’ recommendations. Although in the current paper, we trade personalization for accuracy, our proposed method also provides an access to those more ‘personalized’ data. Further research may be invoked on these personalized data, working towards satisfying both population and personalization.",Broader Impact,308,13,,,FALSE,FALSE,FALSE,Trading Personalization for Accuracy: Data Debugging in Collaborative Filtering,Algorithms -> Collaborative Filtering,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Long Chen', ' Yuan Yao', ' Hanghang Tong', ' Miao Xu', ' Feng Xu']","{'RIKEN AIP', 'Nanjing University', 'University of Illinois at Urbana-Champaign'}",1,0,0,"{'Japan', 'China', 'USA'}"
Cascaded Text Generation with Markov Transformers,"Yuntian Deng, Alexander Rush",Cascaded Text Generation with Markov Transformers,01a0683665f38d8e5e567b3b15ca98bf,https://proceedings.neurips.cc/paper/2020/file/01a0683665f38d8e5e567b3b15ca98bf-Paper.pdf,"Our work proposes an alternative approach to beam search that enables more efficient text generation. This work primarily uses machine translation as an application, but in the long run, it might be applied to longer-form text generation such as summarizing or translating entire documents, or be deployed to edge devices due to its faster inference and lower computational costs. On the positive side, more efficient text generation can make these technologies more accessible to the general public. For example, machine translation can help overcome language barriers [37]; document summarization makes data more interpretable [33]. However, there are potential risks. Faster text generation has provoked concerns about generating fake news and targeted propaganda [56, 9] and might pose safety concerns if it was used to generate hate speech or to harass people [48]. Another potential problem is that it might generate language that appears fluent but fabricates facts [22]. To mitigate those issues, there have been works trying to detect machine-generated text [10, 62, 2]. While these works address some concerns over the abuse of text generation, we should be cautious that fake news detection is still a mostly unsolved technical problem and requires active future research [44, 4] as well as non-technical mitigation efforts.",Broader Impact,204,9,,,FALSE,FALSE,FALSE,Cascaded Text Generation with Markov Transformers,Applications -> Natural Language Processing,Deep Learning -> Generative Models,Natural language processing,"['Yuntian Deng', ' Alexander Rush']","{'Harvard University', 'Cornell University'}",1,0,0,{'USA'}
Improving Local Identifiability in Probabilistic Box Embeddings,"Shib Dasgupta, Michael Boratko, Dongxu Zhang, Luke Vilnis, Xiang Li, Andrew McCallum",Improving Local Identifiability in Probabilistic Box Embeddings,01c9d2c5b3ff5cbba349ec39a570b5e3,https://proceedings.neurips.cc/paper/2020/file/01c9d2c5b3ff5cbba349ec39a570b5e3-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Improving Local Identifiability in Probabilistic Box Embeddings,Algorithms -> Representation Learning,Algorithms -> Relational Learning; Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'University of Massachusetts, Amherst', 'University of Massachusetts Amherst', 'UMass Amherst'}",1,0,0,{'USA'}
Permute-and-Flip: A new mechanism for differentially private selection,"Ryan McKenna, Daniel R. Sheldon",Permute-and-Flip: A new mechanism for differentially private selection,01e00f2f4bfcbb7505cb641066f2859b,https://proceedings.neurips.cc/paper/2020/file/01e00f2f4bfcbb7505cb641066f2859b-Paper.pdf,"Our work fi ts in the established research area of differential privacy, which enables the positive societal bene fi ts of gleaning insight and utility from data sets about people while offering formal guarantees of privacy to individuals who contribute data. While these bene fi ts are largely positive, unintended harms could arise due to misapplication of differential privacy or misconceptions about its guarantees. Additionally, dif fi cult social choices are faced when deciding how to balance privacy and utility. Our work addresses a foundational differential privacy task and enables better utility-privacy tradeoffs within this broader context.",Broader Impact,97,4,,,FALSE,FALSE,FALSE,Permute-and-Flip: A new mechanism for differentially private selection,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Ryan McKenna', ' Daniel Sheldon']","{'University of Massachusetts, Amherst', 'University of Massachusetts Amherst'}",1,0,0,{'USA'}
Deep reconstruction of strange attractors from time series,William Gilpin,Deep reconstruction of strange attractors from time series,021bbc7ee20b71134d53e20206bd6feb,https://proceedings.neurips.cc/paper/2020/file/021bbc7ee20b71134d53e20206bd6feb-Paper.pdf,"While our work is motivated by conceptual and theoretical problems in the theory of nonlinear and chaotic dynamical systems, our method incurs comparable ethical and societal impacts to other techniques for mining time series data. While we focus primarily on datasets from the natural sciences, our technique can be used to identify recurring patterns and motifs within industrial datasets, such as subtle usage patterns of a utility, or fluctuations in consumer demand. Likewise, our technique is well-suited to the analysis of data from fitness trackers, in which a small number of measured dynamical variables (acceleration, elevation, heart rate, etc) are used as a proxy for a model of an individual’s behavior (and even overall health status). Both of these examples represent cases in which the technique may identify latent factors about individuals that they might not anticipate being observable to a third-party—thus introducing concerns about privacy. Avoiding such problems first requires intervention at the level of the data provided to the technique (e.g., aggregating time series across individuals before training the model) or strict retention limitation policies (e.g., providing an overall health score, and then deleting the underlying model behind that score). For example, in our technique, the rows of the Hankel matrix used to train the model can be randomly sampled from a pool of user time series, resulting in an aggregated model that avoids modeling any particular user. However, the ability of our method to identify latent dynamical variables also motivates potential positive societal impacts, particularly in regards to potential benefits for the analysis of physiological data. We show examples of non-trivial structure being extracted from cardiac measurements and neural activity; these structures may be used to better identify and detect anomalous dynamics, potentially improving health monitoring. More broadly, better identification of latent factors within time series data may allow for more principled identification and removal of features that undermine individual privacy, although this would require ex post facto analysis and interpretation of latent variables discovered using our technique.",Broader Impact,331,9,,,FALSE,FALSE,FALSE,Deep reconstruction of strange attractors from time series,Algorithms -> Dynamical Systems,Applications -> Time Series Analysis,Deep learning,['William Gilpin'],{'Harvard University'},1,0,0,{'USA'}
Reciprocal Adversarial Learning via Characteristic Functions,"Shengxi Li, Zeyang Yu, Min Xiang, Danilo Mandic",Reciprocal Adversarial Learning via Characteristic Functions,021f6dd88a11ca489936ae770e4634ad,https://proceedings.neurips.cc/paper/2020/file/021f6dd88a11ca489936ae770e4634ad-Paper.pdf,"A combination of the auto-encoder and GANs has been extensively studied, and has been shown to achieve a broader data generation and reconstruction. The RCF-GAN proposed in this paper provides a neat and new structure in the combination. The studies of GANs and those design on probabilistic auto-encoders basically start from different perspectives because the former serves for the generation, or it “decodes” from random noise, whilst the latter, as its name implies, focuses on encoding to summarise information. Although there are extensive attempts on combining those two structures, they typically embed one into the other as components such as by using an auto-encoder as a discriminator in GANs or using an adversarial idea in an auto-encoder. This paper provides a way of equally treating the two structures; the proposed structure, which contains only two modules, can be regarded both as an “encoder-decoder” and “discriminator-generator”. The proposed combination benefits both, that is, it equips an auto-encoder the ability to meaningfully encode via matching in the embedded domain, whilst ensuring the convergence of the adversarial as a GAN. Moreover, instead of being a component to measure the distance as in the W-GAN, regarding the critic as an independent feature mapping module with a sufficient distance metric is beneficial to allow learning in the embedded domain for any types of feature extraction models, such as the deep canonical correlation analysis net and graph auto encoder. A large amount of unsupervised learning models, then, can be connected and improved with the adversarial learning. Another potential benefit of our work is to bring the general concept of the characteristic function (CF) into practice, by providing efficient sampling methods. The CF has been previously studied as a powerful tool in theoretical probabilistic analysis, while its practical applications have been limited due to complex functional forms. We should also highlight the physical meaning of the CF components introduced in this paper. It is a well known experimental phenomenon that the phase of discrete Fourier transform of images captures the saliency information, which motivates a large volume of works in saliency detection. This paper gives a probabilistic explanation to this, paving the way for future work to embark upon this intrinsic relationship.",6 Broader Impact,365,13,,,FALSE,FALSE,FALSE,Reciprocal Adversarial Learning via Characteristic Functions,Deep Learning -> Generative Models,Algorithms -> Adversarial Learning; Algorithms -> Density Estimation; Algorithms -> Unsupervised Learning; Applications -> Computer Vision; Deep Learning -> Adversarial Networks; Deep Learning -> Deep Autoencoders,Probabilistic methods and inference,"['Shengxi Li', ' Zeyang Yu', ' Min Xiang', ' Danilo P Mandic']",{'Imperial College London'},1,0,0,{'UK'}
Statistical Guarantees of Distributed Nearest Neighbor Classification,"Jiexin Duan, Xingye Qiao, Guang Cheng",Statistical Guarantees of Distributed Nearest Neighbor Classification,022e0ee5162c13d9a7bb3bd00fb032ce,https://proceedings.neurips.cc/paper/2020/file/022e0ee5162c13d9a7bb3bd00fb032ce-Paper.pdf,"Our work provides a statistical guarantee for the performance of nearest neighbor classifiers under the distributed framework. It also provides a guideline to choose suitable number of machines for parallel computing in practice. In addition, this paper reveals the accuracy lost of the majority voting scheme compared to the weighted voting scheme, which sheds light upon the choice of the voting scheme. Our work will advance the theoretical frontier for the nearest neighbor classifier.",Broader Impact,74,4,,,FALSE,FALSE,FALSE,Statistical Guarantees of Distributed Nearest Neighbor Classification,Algorithms -> Classification,Algorithms -> Large Scale Learning; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Jiexin Duan', ' Xingye Qiao', ' Guang Cheng']","{'Binghamton University', 'Purdue University'}",1,0,0,{'USA'}
Stein Self-Repulsive Dynamics: Benefits From Past Samples,"Mao Ye, Tongzheng Ren, Qiang Liu",Stein Self-Repulsive Dynamics: Benefits from Past Samples,023d0a5671efd29e80b4deef8262e297,https://proceedings.neurips.cc/paper/2020/file/023d0a5671efd29e80b4deef8262e297-Paper.pdf,This work incorporates Stein repulsive force into Langevin dynamics to improve sample efficiency. It brings a positively improvement to the community such as reinforcement learning and Bayesian neural network that needs efficient sampler. Our work do not have any negative societal impacts that we can foresee in the future.,Broader Impact Statement,49,3,FALSE,FALSE,TRUE,TRUE,FALSE,Stein Self-Repulsive Dynamics: Benefits From Past Samples,Probabilistic Methods -> Variational Inference,Algorithms -> Kernel Methods; Probabilistic Methods -> MCMC,,"['Mao Ye', ' Tongzheng Ren', ' Qiang Liu']","{'The University of Texas at Austin', 'UT Austin'}",1,0,0,{'USA'}
The Statistical Complexity of Early-Stopped Mirror Descent,"Tomas Vaskevicius, Varun Kanade, Patrick Rebeschini",The Statistical Complexity of Early-Stopped Mirror Descent,024d2d699e6c1a82c9ba986386f4d824,https://proceedings.neurips.cc/paper/2020/file/024d2d699e6c1a82c9ba986386f4d824-Paper.pdf,This work does not present any foreseeable ethical or societal consequences.,Broader Impact,11,1,TRUE,FALSE,FALSE,FALSE,FALSE,The Statistical Complexity of Early-Stopped Mirror Descent,Theory,Optimization -> Convex Optimization; Theory -> Regularization; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Tomas Vaskevicius', ' Varun Kanade', ' Patrick Rebeschini']",{'University of Oxford'},1,0,0,{'UK'}
Algorithmic recourse under imperfect causal knowledge: a probabilistic approach,"Amir-Hossein Karimi, Bodo Julius von Kügelgen, Bernhard Schölkopf, Isabel Valera",Algorithmic recourse under imperfect causal knowledge: a probabilistic approach,02a3c7fb3f489288ae6942498498db20,https://proceedings.neurips.cc/paper/2020/file/02a3c7fb3f489288ae6942498498db20-Paper.pdf,"Our work falls into the domain of explainable AI, which—given the increasing use of often intranspar- ent (“blackbox”) machine learning models in consequential decision making—is of rapidly-growing societal importance. In particular, we consider the task of enabling and facilitating algorithmic recourse , which aims to provide individuals with guidance and recommendations on how best (i.e., efficiently and ideally at low cost) to recover from unfavourable decisions made by an automated system. To address this task, we build on the framework of causal modelling, which constitutes a principled and mathematically rigorous way to reason about the downstream effects of actions. Since correlation does not imply causation, this requires to make additional assumptions based on a general understanding of the domain at hand. While this may perhaps seem restrictive at first, we point out that other approaches to explainability also make implicit assumptions of a causal nature (e.g., that all features can be changed at will without affecting others in the case of “counterfactual” explanations), without explicitly and clearly stating such assumptions. The advantage of phrasing assumptions about relations between features in the form of a causal graph is that the latter is transparent and intuitive to understand and can thus be challenged by decision makers and individuals alike. While theoretically sound from a causal perspective, at the same time, our method is aimed at being practical by not making further assumptions beyond the causal graph which would be hard or impossible to test or challenge empirically—in contrast to the assumed known specification of the full SCM in [22]. We start from the position that the model is only partially known, and use this to motivate probabilistic approaches to causal algorithmic recourse which take uncertainty into account. Our approaches are more robust to misspeficiation than naive point-based recourse methods (as demonstrated experimentally): “system-failure” is thus fundamentally baked in to our methods. Moreover, the interpretable “conservativeness parameter” gamma-LCB can be used trade-off the desired level of robustness against the effort an individual is willing to put into achieving recourse. The importance of causal reasoning for an ethical and socially beneficial use of ML-assisted tech- nology has also been stressed in a number of recent works in the field of explainability and fair algorithmic decision making [29, 42, 24, 63, 64, 10, 57, 15]. We thus hope that some of the proba- bilistic approaches for causal reasoning under imperfect knowledge proposed in this work may also prove useful for related tasks such as fairness, accountability, transparency. To this end, we have created a user-friendly implementation of all the approaches proposed in this work that we will make publicly available to be scrutinised, re-used, and further improved by the community. The code is highly flexible and only requires the specification of a causal graph, as well as a labelled training dataset. Since our work considers the classifier as given, it is possible that it is explicitly discriminatory or reproduces biases in the data. While not directly addressing this problem, our work aims to enable individuals to overcome a potentially unfairly obtained decision with minimal effort. If successful recourse examples are included in future training data, this may help de-bias a system over time; we consider the intersection of our work with fair decision making in the context of a classifier evolving over time as the result of further data collection [25] a fruitful and important direction for future research. In addition, observing that certain minority groups consistently receive more costly recourse recommendations may be a way to reveal bias in the underlying decision making system. While our framework is intended to help individuals increase their chances for a more favourable prediction given that they were, e.g., denied a loan or bail, we cannot rule out a priori, that the same approach could also be used by foes in unintended ways, e.g., to “game” a spam filter or similar system built to protect society from harm. However, since our framework requires the specification of a causal graph which usually requires an understanding of the domain and the causal influences at play, it is unlikely that it could be abused by a purely virtual system without a human in the loop.",Broader Impact,694,20,,,TRUE,TRUE,FALSE,Algorithmic recourse under imperfect causal knowledge: a probabilistic approach,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Probabilistic Methods -> Causal Inference,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Hossein Karimi', ' Julius von Kügelgen', ' Bernhard Schölkopf', ' Isabel Valera']","{'UWaterloo', 'MPI for Intelligent Systems', 'Max Planck Institute for Intelligent Systems'}",1,0,0,"{'Canada', 'Germany'}"
Quantitative Propagation of Chaos for SGD in Wide Neural Networks,"Valentin De Bortoli, Alain Durmus, Xavier Fontaine, Umut Simsekli",Quantitative Propagation of Chaos for SGD in Wide Neural Networks,02e74f10e0327ad868d138f2b4fdd6f0,https://proceedings.neurips.cc/paper/2020/file/02e74f10e0327ad868d138f2b4fdd6f0-Paper.pdf,"Today neural networks can be seen by the non-expert public as black boxes and the lack of under- standing of the underlying mechanisms in deep learning can frighten some decision makers to use them due to the risk of unexplained failures. A theoretical understanding of the behavior of usual training algorithms such as SGD when applied to neural networks is indeed still largely missing. Such a theory would benefit the experimentators who could use these results to design new algorithms and improve existing ones. For instance, deriving properties on the limit points of SGD would give more insight on the estimators constructed by training neural networks. In particular, we could characterize their bias and dependency with respect to the training data and quantify their generalization properties. Analyzing the long-time behavior of classical training algorithms such as SGD is crucial to pinpoint what are the essential properties of neural networks. We show that in the simplistic case of a two-layer neural network SGD admits a limiting dynamics when parameter case the = 1 number we 2 obtain [0 , 1] of . hidden If a stochastic 2 [0 units , 1) mean-field we N ! recover + 1 dynamics. . known We identify deterministic Therefore, two regimes we mean-field claim depending that, dynamics at least on an in and the internal in case the of two-layer neural networks, the long-time behavior of SGD can be analyzed using these mean-field approximations. It constitutes a step towards a deeper understanding of their properties. We focus on the simplistic case of a two-layer neural network.",Broader Impact,261,13,,,FALSE,TRUE,FALSE,Quantitative Propagation of Chaos for SGD in Wide Neural Networks,Theory -> Large Deviations and Asymptotic Analysis,,Theory (including computational and statistical analyses),"['Valentin De Bortoli', ' Alain Durmus', ' Xavier Fontaine', ' Umut Simsekli']","{'ENS Paris Saclay', 'Institut Polytechnique de Paris/ University of Oxford', 'ENS Paris-Saclay'}",1,0,0,"{'France', 'UK'}"
A Causal View on Robustness  of Neural Networks,"Cheng Zhang, Kun Zhang, Yingzhen Li",A Causal View on Robustness of Neural Networks,02ed812220b0705fabb868ddbf17ea20,https://proceedings.neurips.cc/paper/2020/file/02ed812220b0705fabb868ddbf17ea20-Paper.pdf,"In this work, we provide a causal perspective on the robustness of deep learning, and propose a causal consistent deep generative model as an instance to improve the robustness of model regarding unseen manipulations. We view the robustness of AI solution under unseen manipulation as a key factor for many AI-aided decision making system to be trusted. While we do not intent to claim we have solved this problem perfectly (especially concerning large-scale and real-life applications), our work has shown great improvement over existing methods regarding the robustness towards unseen manipulations. We hope our research can inspire more solutions towards the final goal of AI safety.",Broader Impact,106,4,,,FALSE,FALSE,FALSE,A Causal View on Robustness  of Neural Networks,Deep Learning -> Generative Models,,,"['Cheng Zhang', ' Kun Zhang', ' Yingzhen Li']","{'CMU', 'Microsoft Research, Cambridge, UK', 'Microsoft Research Cambridge'}",1,1,1,"{'UK', 'USA'}"
Minimax Classification with 0-1 Loss and Performance Guarantees,"Santiago Mazuelas, Andrea Zanoni, Aritz Pérez",Minimax Classification with 0-1 Loss and Performance Guarantees,02f657d55eaf1c4840ce8d66fcdaf90c,https://proceedings.neurips.cc/paper/2020/file/02f657d55eaf1c4840ce8d66fcdaf90c-Paper.pdf,"The results presented in the paper can enable new approaches for supervised learning that can benefit general applications of supervised classification. Such results do not put anybody at a disadvantage, create consequences in case of failure or leverage biases in the data.",Broader Impact,42,2,FALSE,TRUE,FALSE,FALSE,FALSE,Minimax Classification with 0-1 Loss and Performance Guarantees,Algorithms -> Classification,Optimization -> Convex Optimization; Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Santiago Mazuelas', ' Andrea Zanoni', ' Aritz Pérez', 'Basque Center for Applied Mathematics']","{'Ecole Polytechnique Federale de Lausanne', 'Basque Center for Applied Mathematics', 'BCAM'}",1,0,0,"{'Spain', 'Switzerland'}"
How to Learn a Useful Critic? Model-based Action-Gradient-Estimator Policy Optimization,"Pierluca D'Oro, Wojciech  Jaśkowski",How to Learn a Useful Critic? Model-based Action-Gradient-Estimator Policy Optimization,03255088ed63354a54e0e5ed957e9008,https://proceedings.neurips.cc/paper/2020/file/03255088ed63354a54e0e5ed957e9008-Paper.pdf,"The method presented in this paper is a reinforcement learning algorithm that can be used to control a system executing real-valued actions in an environment. Therefore, a natural application of it is in robotics, with positive (e.g., elderly care, resource-efficiency in manufacturing) and negative (e.g., military) applications. Alongside other deep reinforcement learning algorithms, our method is computationally intensive and its training can thus require considerable resources (i.e., hardware and electricity); on the other hand, given that in many real-world scenarios every interaction with a system implies an economic or environmental cost, the sample efficiency of MAGE is aligned with the modern principles of responsible artificial intelligence.",Broader Impact,106,3,,,FALSE,FALSE,FALSE,How to Learn a Useful Critic? Model-based Action-Gradient-Estimator Policy Optimization,Reinforcement Learning and Planning -> Model-Based RL,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Oro', ' Wojciech Jaśkowski']","{'NNAISENSE SA', 'NNAISENSE, Politecnico di Milano'}",1,1,1,"{'Italy', 'Switzerland'}"
Coresets for Regressions with Panel Data,"Lingxiao Huang, K Sudhir, Nisheeth Vishnoi",Coresets for Regressions with Panel Data,03287fcce194dbd958c2ec5b33705912,https://proceedings.neurips.cc/paper/2020/file/03287fcce194dbd958c2ec5b33705912-Paper.pdf,"Many organizations have to routinely outsource data processing to external consultants and statis- ticians. A major practical challenge for organizations in doing this is to minimize issues of data security in terms of exposure of their data for potential abuse. Further, minimization of such exposure is considered as necessary due diligence by laws such as GDPR and CCPA which mandates firms to minimize security breaches that violate the privacy rights of the data owner [45, 34]. Coreset based approaches to sharing data for processing can be very valuable for firms in addressing data security and to be in compliance with privacy regulations like GDPR and CCPA. Obtaining unbiased estimates of the regression relationships from observational data is often very critical for making correct policy decisions in economics and many social sciences. Panel data is one critical ingredient for obtaining unbiased estimates. As ML methods are being adopted by many social scientists [5], ML scholars are becoming sensitive to these issues and our work in using coreset methods for panel data can have significant impact for these scholars. We don’t foresee immediate negative impact from using our method. However, one concern might be that coresets constructed and shared for one purpose or model may be used by the data processor for other kinds of models, which may lead to erroneous conclusions. There is also the potential for issues of fairness to arise as different groups may not be adequately represented in the coreset without incorporating fairness constraints [29]. These issues may need to be explored in future research.",Broader impact,257,11,,,FALSE,FALSE,FALSE,Coresets for Regressions with Panel Data,Algorithms -> Data Compression,Algorithms -> Regression,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Lingxiao Huang', ' K Sudhir', ' Nisheeth Vishnoi']","{'Yale University', 'EPFL'}",1,0,0,"{'USA', 'Switzerland'}"
Learning Composable Energy Surrogates for PDE Order Reduction,"Alex Beatson, Jordan Ash, Geoffrey Roeder, Tianju Xue, Ryan P. Adams",Learning Composable Energy Surrogates for PDE Order Reduction,0332d694daab22e0e0eaf7a5e88433f9,https://proceedings.neurips.cc/paper/2020/file/0332d694daab22e0e0eaf7a5e88433f9-Paper.pdf,"Our work accelerates the simulation of mechanical meta-materials, and could lead to methods for accelerated simulation of other PDEs. More efficient materials design could have impact on a wide variety of downstream applications, such as soft robotics, structural engineering, biomedical engineering, and many more. Due to the incredibly wide variety of applications which might make use of advances in material design–every physical man-made object makes use of this science–it is difficult to precisely assess impact. However, we believe that meta-material driven advances in soft robotics and structural/biomedical engineering are likely to have a range of positive effects.",13 Broader impacts,97,4,,,FALSE,TRUE,FALSE,Learning Composable Energy Surrogates for PDE Order Reduction,Applications,Algorithms -> Structured Prediction; Deep Learning -> Predictive Models,"Other applications (e.g., robotics, biology, climate, finance)","['Alex Beatson', ' Jordan Ash', ' Geoffrey Roeder', ' Tianju Xue', ' Ryan Adams']","{'Princeton University', 'Microsoft Research'}",1,1,1,{'USA'}
Efficient Contextual Bandits with Continuous Actions,"Maryam Majzoubi, Chicheng Zhang, Rajan Chari, Akshay Krishnamurthy, John Langford, Aleksandrs Slivkins",Efficient Contextual Bandits with Continuous Actions,033cc385728c51d97360020ed57776f0,https://proceedings.neurips.cc/paper/2020/file/033cc385728c51d97360020ed57776f0-Paper.pdf,"Our study of efficient contextual bandits with continuous actions can be applied to a wide range of applications, such as precision medicine, personalized recommendations, data center optimization, operating systems, networking, etc. Many of these applications have potential for significant positive impact to society, but these methods can also cause unintend harms, for example by creating filter bubble effects when deployed in recommendation engines. More generally our research belongs to the general paradigm of interactive machine learning, which must always be used with care due to the presence of feedback loops. We are certainly mindful of these issues, and encourage practitioners to consider these consequences when deploying interactive learning systems.",Broader Impact,109,4,,,FALSE,FALSE,FALSE,Efficient Contextual Bandits with Continuous Actions,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Maryam Majzoubi', ' Chicheng Zhang', ' Rajan Chari', ' Akshay Krishnamurthy', ' John Langford', ' Aleksandrs Slivkins']","{'Microsoft Research', 'University of Arizona', 'NYU Tandon', 'Microsoft Research New York', 'Microsoft'}",1,1,1,{'USA'}
Achieving Equalized Odds by Resampling Sensitive Attributes,"Yaniv Romano, Stephen Bates, Emmanuel Candes",Achieving Equalized Odds by Resampling Sensitive Attributes,03593ce517feac573fdaafa6dcedef61,https://proceedings.neurips.cc/paper/2020/file/03593ce517feac573fdaafa6dcedef61-Paper.pdf,"This work aims to build tools for fair, reliable machine learning algorithms for high-stakes decisions— an essential task for the ethical use of machine learning. The immediate positive outcome from this work is a new algorithm for training algorithms to satisfy the equalized odds property. Our technique explicitly detects biases in a learned model to alert the analyst to any imbalanced performance, while training a model to seek equal performance, when possible. One technical point of failure is that our hypothesis test assumes i.i.d. data. If this assumption fails, the test may lead to incorrect and potentially biased results. Furthermore, while our hypothesis test can detect some violations of the equalized odds property, it is not guaranteed to detect any such violation. Lastly, one possible negative impact is that with the increasing availability of so-called “fair” training algorithms, researchers will accept that an algorithm is fair or ethical without sufficient scrutiny. We emphasize that ethical machine learning must be viewed as an important unsolved problem that requires both further algorithmic and conceptual advances, as well as rigorous, critical thought on the part of the researcher in each new setting.",Broader Impact,189,9,,,FALSE,FALSE,FALSE,Achieving Equalized Odds by Resampling Sensitive Attributes,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Adversarial Learning; Algorithms -> Classification; Algorithms -> Regression; Algorithms -> Uncertainty Estimation; Deep Learning -> Adversarial Networks; Deep Learning -> Predictive Models,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yaniv Romano', ' Stephen Bates', ' Emmanuel Candes']",{'Stanford University'},1,0,0,{'USA'}
Multi-Robot Collision Avoidance under Uncertainty with Probabilistic Safety Barrier Certificates,"Wenhao Luo, Wen Sun, Ashish Kapoor",Multi-Robot Collision Avoidance under Uncertainty with Probabilistic Safety Barrier Certificates,03793ef7d06ffd63d34ade9d091f1ced,https://proceedings.neurips.cc/paper/2020/file/03793ef7d06ffd63d34ade9d091f1ced-Paper.pdf,"The objective of this work is to provide an explicit safety design for multi-robot systems in terms of collision avoidance that could guarantee probabilistic safety in real-world applications under uncertainty. This is a critical component towards AI and robotics safety [5] when we envision a future with significant increase on AI and multi-robot deployments to our society. As pointed out in [5], while we have seen successful efforts in the aircraft collision avoidance system, the same verification tools are often unable to be directly applied to modern autonomous system powered by AI and machine learning under uncertainty, e.g. autonomous drone fleets. And yet this technique is in high demands considering its wide applications that are rapidly growing at scale. The ultimate goal of this work is to develop such a model-based, formally provable automatic collision avoidance system (ACAS) for autonomous aerial robots that work with various uncertainty models developed by perception modules, AI and machine learning technologies, and to enable runtime verification and mitigation so that the executed control policies are safe at all times. An intuitive example is to consider the transfer of a control policy trained in a simulator to the real-world deployment. In this case, it is desired to have an unbiased barrier wrapped around the policy so that the safety is always ensured in the first place, which is the exact purpose of our proposed probabilistic safety barrier certificates (PrSBC) constraints. We believe our work will lead to fruitful results on safety improvements for both civil applications and academic research. On the other hand, as critical as the safety itself, the consequence of failure of such safety system could also be catastrophic in nature. For example, very inaccurate robot dynamics model and super inferior sensing information from the environments could cast immense threats to the safety design. We strive to minimize these factors by always accounting for uncertainty, properly leveraging conservativeness and absolute safety, and including worst-case analysis to increase the robustness of our design.",Broader Impact,329,11,,,FALSE,FALSE,FALSE,Multi-Robot Collision Avoidance under Uncertainty with Probabilistic Safety Barrier Certificates,Social Aspects of Machine Learning -> AI Safety,Applications -> Robotics; Theory -> Control Theory,Safety and Robustness for Autonomous Systems,"['Wenhao Luo', ' Wen Sun', ' Ashish Kapoor']","{'Microsoft', 'Carnegie Mellon University', 'Microsoft Research NYC'}",1,1,1,{'USA'}
Hard Shape-Constrained Kernel Machines,"Pierre-Cyril Aubin-Frankowski, Zoltan Szabo",Hard Shape-Constrained Kernel Machines,03fa2f7502f5f6b9169e67d17cbf51bb,https://proceedings.neurips.cc/paper/2020/file/03fa2f7502f5f6b9169e67d17cbf51bb-Paper.pdf,"Shape constraints play a central role in economics, social sciences, biology, finance, game theory, reinforcement learning and control problems as they enable more data-efficient computation and help interpretability. The proposed principled way of imposing hard shape constraints and algorithmic solution are expected to have positive impact in the aforementioned areas. For instance, from social perspective the studied quantile regression application can allow ensuring that safety regulations are better met. The improved sample efficiency, however, might result in dropping production indices and reduced privacy due to more target-specific applications.",5 Broader impact,88,4,,,FALSE,FALSE,FALSE,Hard Shape-Constrained Kernel Machines,Algorithms -> Kernel Methods,Algorithms -> Regression; Optimization -> Convex Optimization,Kernel methods with constraints,"['Frankowski', ' Zoltan Szabo']","{'Ecole Polytechnique', 'MINES ParisTech'}",1,0,0,"{'France', 'Switzerland'}"
A Closer Look at the Training Strategy for Modern Meta-Learning,"JIAXIN CHEN, Xiao-Ming Wu, Yanke Li, Qimai LI, Li-Ming Zhan, Fu-lai Chung",A Closer Look at the Training Strategy for Modern Meta-Learning,0415740eaa4d9decbc8da001d3fd805f,https://proceedings.neurips.cc/paper/2020/file/0415740eaa4d9decbc8da001d3fd805f-Paper.pdf,"Meta-learning aims to endow machine the ability of adapting to a novel task rapidly. The concept of meta-learning is first introduced by Juergen Schmidhuber in 1987 and attracts explosive attention in the past few years. The support/query (S/Q) episodic training strategy is proposed by Vinyals et al. in 2016 to train modern meta-learning algorithms, which has become a standard practice. However, why S/Q training is effective remains under-explored. Our analysis shows that S/Q training leads to a generalization bound independent of the inner-task sample size, in the sense that in spite of very limited training samples per task (e.g., 1 or 5), the generalization gap converges to 0 as long as enough training tasks are given. This result provides a theoretical justification for the commonly used S/Q training strategy, as well as a theoretical foundation for modern meta-learning algorithms trained with such strategy.",Broader Impact,143,7,,,FALSE,FALSE,FALSE,A Closer Look at the Training Strategy for Modern Meta-Learning,Algorithms -> Meta-Learning,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['JIAXIN CHEN', 'Ming Wu', ' Yanke Li', ' Qimai LI', 'Ming Zhan', 'lai Chung']","{'ETH Zurich', 'The Hong Kong PolyU', 'The Hong Kong Polytechnic University'}",1,0,0,"{'China', 'Switzerland'}"
On the Value of Out-of-Distribution Testing: An Example of Goodhart's Law,"Damien Teney, Ehsan Abbasnejad, Kushal Kafle, Robik Shrestha, Christopher Kanan, Anton van den Hengel",On the Value of Out-of-Distribution Testing: An Example of Goodhart’s Law,045117b0e0a11a242b9765e79cbf113f,https://proceedings.neurips.cc/paper/2020/file/045117b0e0a11a242b9765e79cbf113f-Paper.pdf,"By providing a better representation of the state of the art in visual question answering, and of current capabilities of AI systems, we believe this work will have a positive impact.",Broader impact,31,1,FALSE,FALSE,TRUE,TRUE,FALSE,On the Value of Out-of-Distribution Testing: An Example of Goodhart's Law,Applications -> Visual Question Answering,"Data, Challenges, Implementations, and Software -> Benchmarks",Vision,"['Damien Teney', ' Ehsan Abbasnejad', ' Kushal Kafle', ' Robik Shrestha', ' Christopher Kanan', ' Anton van den Hengel']","{'Rochester Institute of Technology', 'University of Adelaide'}",1,0,0,"{'Australia', 'USA'}"
Generalised Bayesian Filtering via Sequential Monte Carlo,"Ayman Boustati, Omer Deniz Akyildiz, Theodoros Damoulas, Adam Johansen",Generalised Bayesian Filtering via Sequential Monte Carlo,04ecb1fa28506ccb6f72b12c0245ddbc,https://proceedings.neurips.cc/paper/2020/file/04ecb1fa28506ccb6f72b12c0245ddbc-Paper.pdf,"Robust inference in the context of misspecified models is a topic of broad interest. However, there are a few robust generally-applicable methods which can be employed in the context of online inference in time series settings. This paper provides a principled solution to this problem within a formal framework backed by theoretical guarantees and opening up the benefits to multiple application domains. The illustrative applications demonstrate the potential improvements in settings including navigation and Gaussian process regression, which, if realised more widely, could have wide-reaching impact. We hope that this inspires the community to build-on or apply our work to other challenging real-world scenarios. Of particular interest is the application of Robust SMC methods, like the β -BPF and the auxiliary counterpart which were developed in this work, to impactful data-streaming applications in environmental monitoring and forecasting. Indeed, our research in this area was motivated by a real- world application in which existing techniques were inadequate (see https://www.turing.ac.uk/ research/research-projects/london-air-quality for more details). We have demonstrated the benefits such methods in proof-of-concept work and are incorporating the resulting algorithms into a fully-developed platform, that has been in development for approximately three years. We are partnering with local authorities to help in directly informing policy makers and ultimately the general public. More widely, this work provides an additional illustration that the GBI framework can provide good solutions to challenging problems in the world of misspecified framework and hence provides additional motivation to further investigate this extremely promising but rather new direction.",Broader Impact,249,10,,,FALSE,FALSE,FALSE,Generalised Bayesian Filtering via Sequential Monte Carlo,Probabilistic Methods,Applications -> Signal Processing; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> MCMC,Probabilistic methods and inference,"['Ayman Boustati', ' Omer Deniz Akyildiz', ' Theodoros Damoulas', ' Adam Johansen']",{'University of Warwick'},1,0,0,{'UK'}
Deterministic Approximation for Submodular Maximization over a Matroid in Nearly Linear Time,"Kai Han, zongmai Cao, Shuang Cui, Benwei Wu",Deterministic Approximation for Submodular Maximization over a Matroid in Nearly Linear Time,05128e44e27c36bdba71221bfccf735d,https://proceedings.neurips.cc/paper/2020/file/05128e44e27c36bdba71221bfccf735d-Paper.pdf,"Submodular optimization is an important research topic in data mining, machine learning and optimization theory, as it has numerous applications such as crowdsourcing [47], viral marketing [34], feature selection [28], network monitoring [40], document summarization [20, 41], online adver- tising [49], crowd teaching [46] and blogosphere mining [21]. Matroid is a fundamental structure in combinatorics that captures the essence of a notion of ""independence"" that generalizes linear independence in vector spaces. The matroid structure has been pervasively found in various areas such as geometry, network theory, coding theory and graph theory [8]. The study on submodular maximization subject to matroid constraints dates back to the 1970s (e.g., [27]), and it is still a hot research topic today [3, 5, 16, 25, 44, 45]. A lot of practical problems can be cast as the problem of submodular maximziation over a matroid constraint (or more general p -set system constraints), such as diversity maximization [1], video summarization [52], clustering [42], multi-robot allocation [51] and planning sensor networks [19]. Therefore, our study has addressed a general and fundamental theoretical problem with many potential applications. Due to the massive datasets used everywhere nowadays, it is very important that submodular optimization algorithms should achieve accuracy and efficiency simultaneously. Recently, there emerge great interests on designing more practical and efficient algorithms for submodular optimization (e.g., [2, 4, 11, 13, 23, 36, 43]), and our work advances the state of the art in this area by propos- ing a new efficient algorithm with improved performance bounds. Moreover, our algorithms are based on a novel “simultaneous greedy-search” framework, which is different from the classical “repeated greedy-search” and “local search” frameworks adopted by the state-of-the-art algorithms (e.g., [25, 31, 38, 44]). We believe that our “simultaneous greedy-search” framework has the potential to be extended to address other problems on submodular maximization with more complex constraints, which is the topic of our ongoing research.",Broader Impact,314,10,,,FALSE,FALSE,FALSE,Deterministic Approximation for Submodular Maximization over a Matroid in Nearly Linear Time,Optimization,Optimization -> Submodular Optimization,Optimization Methods (continuous or discrete),"['Kai Han', ' zongmai Cao', ' Shuang Cui', ' Benwei Wu']",{'University of Science and Technology of China'},1,0,0,{'China'}
Flows for simultaneous manifold learning and density estimation,"Johann Brehmer, Kyle Cranmer",Flows for simultaneous manifold learning and density estimation,051928341be67dcba03f0e04104d9047,https://proceedings.neurips.cc/paper/2020/file/051928341be67dcba03f0e04104d9047-Paper.pdf,"Manifold-learning flows have the potential to improve the efficiency with which scientists extract knowledge from large-scale experiments. Many phenomena have their most accurate description in terms of complex computer simulations which do not admit a tractable likelihood. In this common case, normalizing flows can be trained on synthetic data and used as a surrogate for the likelihood function, enabling high-quality inference on model parameters [21]. When the data have a manifold structure, manifold-learning flows may improve the quality and efficiency of this process further and ultimately contribute to scientific progress. We have demonstrated this with a real-world particle physics dataset, though the same technique is applicable to fields as diverse as neuroscience, systems biology, and epidemiology. All generative models carry a risk of being abused for the generation of fake data that are then masqueraded as real documents. This danger also applies to manifold-learning flows. While manifold-learning flows are currently far away from being able to generate realistic high-resolution images, videos, or audio, this concern should be kept in mind in the long term. Finally, the models we trained on image datasets of human faces clearly lack diversity. They reproduce and reinforce the biases inherent in the training data. Before using such (or other) models in any real-life application, it is crucial to understand, measure, and mitigate such biases.",Broader impact,219,11,,,FALSE,FALSE,FALSE,Flows for simultaneous manifold learning and density estimation,Algorithms -> Density Estimation,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models; Probabilistic Methods,Probabilistic methods and inference,"['Johann Brehmer', ' Kyle Cranmer']",{'New York University'},1,0,0,{'USA'}
Simultaneous Preference and Metric Learning from Paired Comparisons,"Austin Xu, Mark Davenport",Simultaneous Preference and Metric Learning from Paired Comparisons,0561bc7ecba98e39ca7994f93311ba23,https://proceedings.neurips.cc/paper/2020/file/0561bc7ecba98e39ca7994f93311ba23-Paper.pdf,"In an increasingly diverse set of contexts, automated ranking systems are playing an increasing role in society. We naturally have an interest in ensuring that these systems are as accurate as possible and not undermined by poor modeling assumptions. If used to augment such systems, our research could be used to develop improved models for how users implicitly process the features of the ranked items by learning a metric. In particular, in addition to providing a more powerful and flexible model of preference, the metric illuminates how features are combined and the ordering of importance of the combined features, providing both additional insight as well as helping to better identify user desires and rankings. In certain applications, such as in hiring or admissions committees, there is also the potential to apply our techniques to discover if the metric of an evaluator is significantly influenced by certain factors (e.g., race, gender, sexual orientation, religion, etc.) which we do not wish to influence our decisions. This information may be useful as feedback to the evaluator or alternatively, to explicitly compensate for the existence of such influence (e.g., by re-ranking candidates using a modified metric that eliminates dependence on those factors). However, this optimistic assessment of the potential of our approach should be tempered by two important caveats. First, in the absence of any strong theoretical guarantees, we are unable to provide any notion of confidence intervals or statistical significance in the learned parameters, and so one must evaluate the learned models with a degree of caution and awareness that the learned parameters may be the result of chance variation in a small dataset. More generally, there is no notion of causal influence in our model, and it is always possible that the observed dependence on the features is the result of correlations with some unobserved latent factors. Second, due to both the potential for inaccuracies in the learned parameters as well as the personal nature of the revealed preferences, as with any system involving personal data, privacy remains a significant concern.",Broader Impact,339,11,,,FALSE,FALSE,FALSE,Simultaneous Preference and Metric Learning from Paired Comparisons,Algorithms -> Ranking and Preference Learning,Algorithms -> Metric Learning; Algorithms -> Similarity and Distance Learning; Applications -> Recommender Systems,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Austin Xu', ' Mark Davenport']",{'Georgia Institute of Technology'},1,0,0,{'USA'}
Efficient Variational Inference for Sparse Deep Learning with Theoretical Guarantee,"Jincheng Bai, Qifan Song, Guang Cheng",Efficient Variational Inference for Sparse Deep Learning with Theoretical Guarantee,05a624166c8eb8273b8464e8d9cb5bd9,https://proceedings.neurips.cc/paper/2020/file/05a624166c8eb8273b8464e8d9cb5bd9-Paper.pdf,"We believe the ethical aspects are not applicable to this work. For future societal consequences, deep learning has a wide range of applications such as computer version and natural language processing. Our work provides a solution to overcome the drawbacks of modern deep neural network, and also improves the understanding of deep learning. The proposed method could improve the existing applications. Specifically, sparse learning helps apply deep neural networks to hardware limited devices, like cell phones or pads, which will broaden the horizon of deep learning application. In addition, as a Bayesian method, not only a result, but also the knowledge of confidence or certainty in that result are provided, which could benefit people in various aspects. For example, in the application of cancer diagnostic, by providing the certainty associated with each possible outcome, Bayesian learning would assist the medical professionals to make a better judgement about whether the tumor is a cancer or a benign one. Such kind of ability to quantify uncertainty would contribute to the modern deep learning.",Broader Impact,171,8,FALSE,FALSE,FALSE,FALSE,FALSE,Efficient Variational Inference for Sparse Deep Learning with Theoretical Guarantee,Probabilistic Methods -> Variational Inference,Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Supervised Deep Networks,Deep learning,"['Jincheng Bai', ' Qifan Song', ' Guang Cheng']","{'Purdue University ', 'Purdue University'}",1,0,0,{'USA'}
Learning Manifold Implicitly via Explicit Heat-Kernel Learning,"Yufan Zhou, Changyou Chen, Jinhui Xu",Learning Manifold Implicitly via Explicit Heat-Kernel Learning,05e2a0647e260c355dd2b2175edb45b8,https://proceedings.neurips.cc/paper/2020/file/05e2a0647e260c355dd2b2175edb45b8-Paper.pdf,"We propose a fundamentally novel method to implicitly learn the geometric information of a manifold by explicitly learning its associated heat kernel, which is the solution of heat equation with initial conditions given. Our proposed method is general and can be applied in many down-stream applications. Specifically, it could be used to improve many kernel-related algorithms and applications. It may also inspire researchers in deep learning to borrow ideas from other fields (mathematics, physics, etc.) and apply them to their own research. This can benefit both fields and thus promote interdisciplinary research.",Broader Impact,92,6,,,FALSE,FALSE,FALSE,Learning Manifold Implicitly via Explicit Heat-Kernel Learning,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning,Algorithms -> Unsupervised Learning; Deep Learning -> Adversarial Networks; Deep Learning -> Generative Models,Deep learning,"['Yufan Zhou', ' Changyou Chen', ' Jinhui Xu']","{'University at Buffalo', 'SUNY at Buffalo'}",1,0,0,{'USA'}
Deep Relational Topic Modeling via Graph Poisson Gamma Belief Network,"Chaojie Wang, Hao Zhang, Bo Chen, Dongsheng Wang, Zhengjue Wang, Mingyuan Zhou",Deep Relational Topic Modeling via Graph Poisson Gamma Belief Network,05ee45de8d877c3949760a94fa691533,https://proceedings.neurips.cc/paper/2020/file/05ee45de8d877c3949760a94fa691533-Paper.pdf,"The proposed GPGBN can be used to analyze network data, such as citation networks and social networks. Distinct from traditional network analysis, our model can provide intuitive visualization for hierarchical semantic topics and relationships, which potentially explain the underlying reasons for connections between the nodes (representing documents, persons, or other entities) of the network. The developed WGAE and WGCAE are more flexible for downstream network analysis tasks, like link prediction (predict if there is a connection between the suspects), node classification (determine which community the person belongs to) and so on. Meanwhile, benefiting from incorporating the GPGBN as a decoder, both WGAE and WGCAE can provide interpretable visualization and help the user to explain the basis for the network decision. Of course, these characteristics can also be exploited by ill-intentioned users, so the risk of the proposed models being used in malicious ways cannot be ignored. We advocate that researchers in this field pay more attention to the study of interpretable graph models, rather than only focusing on the numerical performance. The interpretable model enables the users to understand what the model really learns, which helps to evaluate the trust of the model decision and further explore additional applications.",Broader Impact,199,7,,,FALSE,FALSE,FALSE,Deep Relational Topic Modeling via Graph Poisson Gamma Belief Network,Probabilistic Methods -> Topic Models,Probabilistic Methods -> Hierarchical Models; Probabilistic Methods -> Latent Variable Models,Probabilistic methods and inference,"['Chaojie Wang', ' Hao Zhang', ' Bo Chen', ' Dongsheng Wang', ' Zhengjue Wang', ' Mingyuan Zhou']","{'Xidian University', 'University of Texas at Austin'}",1,0,0,"{'USA', 'China'}"
One-bit Supervision for Image Classification,"Hengtong Hu, Lingxi Xie, Zewei Du, Richang Hong, Qi Tian",One-bit Supervision for Image Classification,05f971b5ec196b8c65b75d2ef8267331,https://proceedings.neurips.cc/paper/2020/file/05f971b5ec196b8c65b75d2ef8267331-Paper.pdf,"This paper presents a new setting for semi-supervised learning and achieves higher efficiency of making use of annotation. We summarize the potential impact of our work in the following aspects. • To the research community. The one-bit supervision setting is a new problem to the community. It raises two new challenges, namely, how to obtain more positive labels and how to learn from negative labels. We provide a simple baseline, but also notice that much room is left for improvement. We believe the study on these problems can advance the research community. • To training with limited labeled data. It is an urgent requirement to extract knowledge from unlabeled or weakly-labeled data. Our work provides a new methodology that largely reduces the burden of annotation. The range of application will be even broadened after follow-up efforts generalize this framework to other vision tasks. • To the downstream engineers. We provide a new framework for data annotation that can ease the downstream engineers to develop AI-based systems, especially for some scenarios in which collecting training data is difficult and/or expensive. While this may help to develop AI-based applications, there exist risks that some engineers, with relatively less knowledge in deep learning, can deliberately use the algorithm, e.g., without considering the form of one-bit information, which may actually harm the performance of the designed system. • To the society. There is a long-lasting debate on the impact that AI can bring to the human society. Our method has the potential to generalize the existing AI algorithms to more applications, while it also raises a serious concern of privacy, since one-bit annotation is easily collected from some ‘weak’ behaviors of web users, e.g., if he/she views the recommended images. Therefore, in general, our work can bring both beneficial and harmful impacts and it really depends on the motivation of the users. We also encourage the community to investigate the following problems. 1. Is it possible to generalize one-bit supervision to other forms, e.g., introducing other types of light-weighted information that helps model training? 2. Are there any other solutions that can achieve higher efficiency than the proposed multi-stage training and negative label suppression methods? 3. How to generalize one-bit or few-bit supervision to other vision scenarios? In particular, what is a proper form of one-bit supervision in object detection or semantic segmentation?",Broader Impact,389,26,FALSE,FALSE,TRUE,TRUE,FALSE,One-bit Supervision for Image Classification,Algorithms -> Classification,Algorithms -> Active Learning; Algorithms -> Semi-Supervised Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['hengtong hu', ' Lingxi Xie', ' Zewei Du', ' Richang Hong', ' Qi Tian']",{'Hefei University of Technology'},1,0,0,{'China'}
What is being transferred in transfer learning?,"Behnam Neyshabur, Hanie Sedghi, Chiyuan Zhang",What is being transferred in transfer learning?,0607f4c705595b911a4f3e7a127b44e0,https://proceedings.neurips.cc/paper/2020/file/0607f4c705595b911a4f3e7a127b44e0-Paper.pdf,Transfer learning requires using a model that is trained on different data and adapt it to new data distribution. The difference in data distribution brings risk. Proper transfer moves the model towards distribution of data in the target domain. Our goal is to understand transfer learning to improve its performance and reduce the risk. This work is a foundational analysis.,Broader Impact,60,5,FALSE,TRUE,FALSE,FALSE,FALSE,What is being transferred in transfer learning?,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Multitask and Transfer Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Behnam Neyshabur', ' Hanie Sedghi', ' Chiyuan Zhang']","{'Google', 'Google Brain'}",0,1,0,{'USA'}
Submodular Maximization Through Barrier Functions,"Ashwinkumar Badanidiyuru, Amin Karbasi, Ehsan Kazemi, Jan Vondrak",Submodular Maximization Through Barrier Functions,061412e4a03c02f9902576ec55ebbe77,https://proceedings.neurips.cc/paper/2020/file/061412e4a03c02f9902576ec55ebbe77-Paper.pdf,"The problems studied in this work have deep and far-reaching applications, as scalable data summarization methods play a central role in nearly every scientific and industrial venture in todays information age. Submodular techniques (with applications to human brain parcellation) has the potential to dramatically improve healthcare by reducing risk in delicate medical procedures. More- over, as machine learning systems are ubiquitously deployed, ensuring fairness and counteracting implicit/historical bias become serious societal considerations. For this reason, a good algorithm that encourages diversity or provides a representative summary could be beneficial to move towards a more fair and just society. On the other hand, an algorithm that fails to summarize the data properly could potentially strengthen the existing historical biases.",Broader Impact,118,5,,,FALSE,FALSE,FALSE,Submodular Maximization Through Barrier Functions,Optimization -> Submodular Optimization,Optimization -> Discrete Optimization,Optimization Methods (continuous or discrete),"['Ashwinkumar Badanidiyuru', ' Amin Karbasi', ' Ehsan Kazemi', ' Jan Vondrak']","{'Google', 'Stanford University', 'Yale', 'Google Research'}",1,1,1,{'USA'}
Neural Networks with Recurrent Generative Feedback,"Yujia Huang, James Gornet, Sihui Dai, Zhiding Yu, Tan Nguyen, Doris Tsao, Anima Anandkumar",Neural Networks with Recurrent Generative Feedback,0660895c22f8a14eb039bfb9beb0778f,https://proceedings.neurips.cc/paper/2020/file/0660895c22f8a14eb039bfb9beb0778f-Paper.pdf,"Convolutional neural networks (CNNs) can achieve superhuman performance on image classification tasks. This advantage allows their deployment to computer vision applications such as medical imaging, security, and autonomous driving. However, CNNs trained on natural images tend to overfit to image textures. Such flaw can cause a CNN to fail against adversarial attacks and on distorted images. This may further lead to unreliable predictions potentially causing false medical diagnoses, traffic accidents, and false identification of criminal suspects. To address the robustness issues in CNNs, CNN-F adopts an architectural design which resembles human vision mechanisms in certain aspects. The deployment of CNN-F renders more robust AI systems. Despite the improved robustness, current method does not tackle other social and ethical issues intrinsic to a CNN. A CNN can imitate human biases in the image datasets. In automated surveillance, biased training datasets can improperly calibrate CNN-F systems to make incorrect decisions based on race, gender, and age. Furthermore, while robust, human-like computer vision systems can provide a net positive societal impact, there exists potential use cases with nefarious, unethical purposes. More human-like computer vision algorithms, for example, could circumvent human verification software. Motivated by these limitations, we encourage research into human bias in machine learning and security in computer vision algorithms. We also recommend researchers and policymakers examine how people abuse CNN models and mitigate their exploitation.",Broader Impacts,224,14,,,FALSE,FALSE,FALSE,Neural Networks with Recurrent Generative Feedback,Neuroscience and Cognitive Science,Neuroscience and Cognitive Science -> Visual Perception,Deep learning,"['Yujia Huang', ' James Gornet', ' Sihui Dai', ' Zhiding Yu', ' Minh Nguyen', ' Doris Tsao', ' Anima Anandkumar']","{'NVIDIA', 'California Institute of Technology', 'Caltech', 'Rice University', 'NVIDIA / Caltech'}",1,1,1,{'USA'}
Learning to Extrapolate Knowledge: Transductive Few-shot Out-of-Graph Link Prediction,"Jinheon Baek, Dong Bok Lee, Sung Ju Hwang",Learning to Extrapolate Knowledge: Transductive Few-shot Out-of-Graph Link Prediction,0663a4ddceacb40b095eda264a85f15c,https://proceedings.neurips.cc/paper/2020/file/0663a4ddceacb40b095eda264a85f15c-Paper.pdf,"Constructing knowledge bases that accurately reflect up-to-date knowledge about the entities and the links between them is crucial for its application in real-world scenarios. However, conventional link prediction methods for knowledge base systems mostly consider static knowledge graph that does not change over time. Yet, as new entities emerge every day [36] (e.g. COVID-19), the ability to dynamically incorporating them into the existing knowledge graph is becoming a significantly important problem, which we mainly tackle in this paper. As a specific example of our approach, the novel coronavirus, COVID-19, is threatening our lives around the globe. To eradicate the novel coronavirus, we may want to best utilize the accumulated knowledge about existing coronavirus variants [53, 7] by identifying the links between the seen (SARS and MERS) and unseen entities (COVID-19), or the links between unseen entities that have newly emerged (COVID-19 and novel vaccine understudy). The following are more use cases of our proposed out-of-graph link prediction system: • The proposed meta-learning based few-shot out-of-graph link prediction method can infer and inform the relationship between the entities that describe past coronavirus outbreaks and the current COVID-19 situation. • Our transductive inference, with stochastic transductive GENs, can lead to finding the relationships among novel entities regarding COVID-19 that rapidly emerge over time, which may allow us to discover meaningful links among them. • Regarding drug-drug interaction prediction, our method can be further utilized to analyze the side-effects of simultaneously taking novel antiviral drugs for COVID-19 and existing drugs, before the clinical trials. While we describe the impact of our method on a specific, but significantly important topic, our method can be broadly applied to any real-world applications that require to predict the links which involve unseen entities. While our method obtains significantly better performance over existing methods on out-of-graph link prediction, its prediction performance is yet far from perfect. Thus, the model should be used as a candidate selection tool (Hits@N) when inferring critical information (e.g. drug-drug interaction prediction for COVID-19), and more efforts should be made to develop a reliable system.",Broader Impact,341,11,,,TRUE,TRUE,FALSE,Learning to Extrapolate Knowledge: Transductive Few-shot Out-of-Graph Link Prediction,Algorithms -> Relational Learning,Algorithms -> Meta-Learning; Deep Learning -> Supervised Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jinheon Baek', ' Dong Bok Lee', ' Sung Ju Hwang']","{'KAIST, AITRICS', 'KAIST'}",1,1,1,{'South Korea'}
Exploiting weakly supervised visual patterns to learn from partial annotations,"Kaustav Kundu, Joseph Tighe",Exploiting weakly supervised visual patterns to learn from partial annotations,066ca7bf90807fcd8e4f1eaef4e4e8f7,https://proceedings.neurips.cc/paper/2020/file/066ca7bf90807fcd8e4f1eaef4e4e8f7-Paper.pdf,We investigate the issue of training classification models in partially annotated datasets. Partially annotated datasets can enable democratization of AI and allow small and large organizations to construct and train models with the requirement of large data sources. The partially annotated datasets are realistic in nature. We hope that in-depth studying of this problem can start more formal discussions into fairness issues concerning large-scale datasets.,6 Broader Impact,65,4,,,FALSE,FALSE,FALSE,Exploiting weakly supervised visual patterns to learn from partial annotations,Algorithms -> Missing Data,Algorithms -> Classification; Algorithms -> Large Scale Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Kaustav Kundu', ' Joseph Tighe']",{'Amazon'},0,1,0,{'USA'}
Improving Inference for Neural Image Compression,"Yibo Yang, Robert Bamler, Stephan Mandt",Improving Inference for Neural Image Compression,066f182b787111ed4cb65ed437f0855b,https://proceedings.neurips.cc/paper/2020/file/066f182b787111ed4cb65ed437f0855b-Paper.pdf,"Improved image and video compression is becoming more and more important as our lives become more digital. For instance, video compression is of enormous societal relevance, as over 80% of web traffic is due to video streaming, and the share of video data is expected to increase even further in the future [Cisco, 2017]. Moreover, there is an explosion of different new data formats that need to be efficiently compressed; examples include high resolution medical images, lidar data, 3D graphics data, DNA sequences, etc. It would be very costly to design custom codecs for such data, making learnable compression indispensable. Ultimately, better compression algorithms, both for data and models, will also facilitate the possibility to carry-out machine learning on local devices, as opposed to large centralized servers. This may address many of our privacy concerns. Currently, neural compression comes with a few drawbacks compared to hand-engineered codecs, such as higher computation/energy cost, and lack of performance guarantees, which we hope can be overcome by active research in this area. Our work on improving the encoding procedure already has the potential to lower the overall energy consumption of a neural codec, for applications where the increased cost of encoding can be amortized across many file transfer/decoding operations and translate to net savings, e.g., on a content hosting website that has millions of visitors per day.",Broader Impacts,224,8,,,FALSE,FALSE,FALSE,Improving Inference for Neural Image Compression,Algorithms -> Data Compression,Probabilistic Methods -> Variational Inference,Deep generative modeling and applications (data compression),"['Yibo Yang', ' Robert Bamler', ' Stephan Mandt']","{'University of California, Irivine', 'University of California at Irvine'}",1,0,0,{'USA'}
Neuron Merging: Compensating for Pruned Neurons,"Woojeong Kim, Suhyun Kim, Mincheol Park, Geunseok Jeon",Neuron Merging: Compensating for Pruned Neurons,0678ca2eae02d542cc931e81b74de122,https://proceedings.neurips.cc/paper/2020/file/0678ca2eae02d542cc931e81b74de122-Paper.pdf,"This work has the same potential impact as any neural network acceleration study. The positive effect comes from reducing the resource overhead of deep learning models during inference time. Data-free acceleration approaches have more potential in that the model can be lightened using only model weights, without any access to the training dataset. Therefore, we can more easily deploy neural network models to mobile phones or edge devices. We thus take a step closer to energy-friendly deep learning, facilitating a wider use of Artificial Intelligence in industrial IoT or Smart-home technology. At the same time, research on neural network acceleration may have some negative consequences. If the neural network models are more widely used for wearable devices or surveillance cameras, there is a possibility of privacy invasion or cybercrime. In addition, the malfunction of industrial IoT devices could cause a severe problem for the whole production process.",Broader Impact,147,8,,,FALSE,FALSE,FALSE,Neuron Merging: Compensating for Pruned Neurons,Deep Learning -> Efficient Inference Methods,,Resource aware machine learning,"['Woojeong Kim', ' Suhyun Kim', ' Mincheol Park', ' Geunseok Jeon']",{'Korea Institute of Science and Technology'},1,0,0,{'South Korea'}
FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,"Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang, Colin A. Raffel, Ekin Dogus Cubuk, Alexey Kurakin, Chun-Liang Li",FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,06964dce9addb1c5cb5d6e3d9838f733,https://proceedings.neurips.cc/paper/2020/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf,"FixMatch helps democratize machine learning in two ways: first, its simplicity makes it available to a wider audience, and second, its accuracy with only a few labels means that it can be applied to domains where previously machine learning was not feasible. The flip side of democratization of machine learning research is that it becomes easy for both good and bad actors to apply. We hope that this ability will be used for good—for example, obtaining medical scans is often far cheaper than paying an expert doctor to label every image. However, it is possible that more advanced techniques for semi-supervised learning will allow for more advanced surveillance: for example, the efficacy of our one-shot classification might allow for more accurate person identification from a few images. Broadly speaking, any progress on semi-supervised learning will have these same consequences.",Broader Impact,139,5,,,FALSE,FALSE,FALSE,FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence,Algorithms -> Semi-Supervised Learning,Algorithms -> Classification; Applications -> Computer Vision; Deep Learning -> Efficient Training Methods,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Kihyuk Sohn', ' David Berthelot', ' Nicholas Carlini', ' Zizhao Zhang', ' Han Zhang', ' Colin A Raffel', ' Ekin Dogus Cubuk', ' Alexey Kurakin', 'Liang Li']","{'Google Brain', 'NEC Laboratories America', 'Google'}",0,1,0,{'USA'}
Reinforcement Learning with Combinatorial Actions: An Application to Vehicle Routing,"Arthur Delarue, Ross Anderson, Christian Tjandraatmadja",Reinforcement Learning with Combinatorial Actions: An Application to Vehicle Routing,06a9d51e04213572ef0720dd27a84792,https://proceedings.neurips.cc/paper/2020/file/06a9d51e04213572ef0720dd27a84792-Paper.pdf,This paper presents methodological work and does not have foreseeable direct societal implications.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Reinforcement Learning with Combinatorial Actions: An Application to Vehicle Routing,Optimization -> Discrete Optimization,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Arthur Delarue', ' Ross Anderson', ' Christian Tjandraatmadja']","{'Google', 'MIT', 'Google Research'}",1,1,1,{'USA'}
Towards Playing Full MOBA Games with Deep Reinforcement Learning,"Deheng Ye, Guibin Chen, Wen Zhang, Sheng Chen, Bo Yuan, Bo Liu, Jia Chen, Zhao Liu, Fuhao Qiu, Hongsheng Yu, Yinyuting Yin, Bei Shi, Liang Wang, Tengfei Shi, Qiang Fu, Wei Yang, Lanxiao Huang, Wei Liu",Towards Playing Full MOBA Games with Deep Reinforcement Learning,06d5ae105ea1bea4d800bc96491876e9,https://proceedings.neurips.cc/paper/2020/file/06d5ae105ea1bea4d800bc96491876e9-Paper.pdf,"To the research community . MOBA (Multiplayer Online Battle Arena) poses a grand challenge to the AI community. We would believe that mastering a typical MOBA game without restrictions will become the next AI milestone like AlphaGo or AlphaStar . To this end, this paper is introducing a MOBA AI learning paradigm towards this goal. Moreover, the proposed methodology is based on general-purpose machine learning components that are applicable to other similar multiplayer domains. Our results suggest that curriculum-guided reinforcement learning can help handle very complex tasks involving multi-agent competition and cooperation, real-time decision-making, imperfect observation, complex strategy space, and combinatorial action space. We herewith expect this work to provide inspirations to other complex real-world problems, e.g., real-time decisions of robotics. To the game industry . Honor of Kings , published by Tencent, has a tremendously large user group. It was reported to be the world’s most popular and highest-grossing game of all time, as well as the most downloaded App worldwide 6 . Our AI has found several real-world applications in the game, and is changing the way that MOBA game designers work, particularly game balance designers, elaborated as follows: 1) Game balance testing. In MOBA and many other game types, balancing the ability of each character is essential. The numerical values and skill-sets design of a MOBA hero, e.g., the physical/magical attack value, blood, and skill types, are traditionally set based on the experience of game balance designers. Value adjustments to a hero must be tested in the Beta game servers for months, to see its win-rate in the hero pool through a significantly large number of human matches. In self-play reinforcement learning, the agents are very sensitive to feature changes and hero adjustments affect the win-rate of the team. Using similar techniques presented in this paper, we have constructed a balance testing tool for Honor of Kings . 2) PVE (player vs environment) game mode. We had deployed earlier checkpoints trained by our method (with a much weaker ability than the AI in this paper, mainly for entertainment) into Honor of Kings . These checkpoints are for players at all levels. 3) AFK hosting. It happens that players in casual matches drop offline or AFK (away from the keyboard) during a game due to an unstable network, temporary emergencies, etc. We have developed a preliminary learning-based AI to host the dropped players. To the esports community . The playing style of our AI is different from normal playing of human esports players 7 . For example, in MOBA, a commonly seen opening-strategy for human teams is the three-lane-strategy, i.e., marksman and warrior heroes go to bottom and top lanes, respectively, while the mage hero plays the middle. However, such a strategy has seldom been adopted by the AI team. Our AI has its way of fast upgrading and team cooperation, which has inspired new strategies to professional players. As commented by a professional coach, “AI’s resource allocation is a bit weird but effective. After trying out some of AI’s playing style, we observe a slight increase of gold and experience gained during certain game phases. Another finding given by AI is that some marksman heroes are suitable to play middle, apart from playing bottom. These are interesting and helpful to us.” In the future, we would believe that with larger hero pool support, the strategies explored by self-play reinforcement learning will have an even broader impact on how esports players play the game. 6 https://en.wikipedia.org/wiki/Honor_of_Kings 7 Matches played by AI can be found from the Google Drive link: https://sourl.cn/NVwV6L",6 Broader Impact,576,32,,,TRUE,TRUE,FALSE,Towards Playing Full MOBA Games with Deep Reinforcement Learning,Applications -> Game Playing,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Deheng Ye', ' Guibin Chen', ' Wen Zhang', ' chen sheng', ' Bo Yuan', ' Bo Liu', ' Jia Chen', ' Hongsheng Yu', ' Zhao Liu', ' Fuhao Qiu', ' Liang Wang', ' Tengfei Shi', ' Yinyuting Yin', ' Bei Shi', ' Lanxiao Huang', ' qiang fu', ' Wei Yang', ' Wei Liu']","{'qq', 'Tencent AI Lab', 'Tencent'}",0,1,0,{'China'}
Rankmax: An Adaptive Projection Alternative to the Softmax Function,"Weiwei Kong, Walid Krichene, Nicolas Mayoraz, Steffen Rendle, Li Zhang",Rankmax: An Adaptive Projection Alternative to the Softmax Function,070dbb6024b5ef93784428afc71f2146,https://proceedings.neurips.cc/paper/2020/file/070dbb6024b5ef93784428afc71f2146-Paper.pdf,"We derived a training method that is theoretically motivated and that shows a good performance on a popular benchmark. It can be used to expand the toolbox of practitioners, and may potentially lead to an improved model quality in some applications. Similarly to other optimization methods, the method we develop is not specific to a particular model or application.",Broader Impact,59,3,FALSE,FALSE,FALSE,FALSE,FALSE,Rankmax: An Adaptive Projection Alternative to the Softmax Function,Algorithms -> Classification,Applications -> Information Retrieval; Applications -> Recommender Systems; Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Weiwei Kong', ' Walid Krichene', ' Nicolas E Mayoraz', ' Steffen Rendle', ' Li Zhang']","{'Google', 'Georgia Institute of Technology'}",1,1,1,{'USA'}
Online Agnostic Boosting via Regret Minimization,"Nataly Brukhim, Xinyi Chen, Elad Hazan, Shay Moran",Online Agnostic Boosting via Regret Minimization,07168af6cb0ef9f78dae15739dd73255,https://proceedings.neurips.cc/paper/2020/file/07168af6cb0ef9f78dae15739dd73255-Paper.pdf,There are no foreseen ethical or societal consequences for the research presented herein.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Online Agnostic Boosting via Regret Minimization,Algorithms -> Boosting and Ensemble Methods,Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Nataly Brukhim', ' Xinyi Chen', ' Elad Hazan', ' Shay Moran']","{'Google AI Princeton', 'Princeton University'}",1,1,1,{'USA'}
Causal Intervention for Weakly-Supervised Semantic Segmentation,"Dong Zhang, Hanwang Zhang, Jinhui Tang, Xian-Sheng Hua, Qianru Sun",Causal Intervention for Weakly-Supervised Semantic Segmentation,07211688a0869d995947a8fb11b215d6,https://proceedings.neurips.cc/paper/2020/file/07211688a0869d995947a8fb11b215d6-Paper.pdf,"The positive impacts of this work are two-fold: 1) it improves the fairness of the weakly-supervised semantic segmentation model, which can prevent the potential discrimination of deep models, e . g ., an unfair AI could blindly cater to the majority, causing gender, racial or religious discrimination; 2) it allows some objects to be accurately segmented without extensive multi-context training images, e . g ., to segment a car on the road, by using our proposed method, we don’t need to photograph any car under any context. The negative impacts could also happen when the proposed weakly-supervised semantic segmentation technique falls into the wrong hands, e . g ., it can be used to segment the minority groups for malicious purposes. Therefore, we have to make sure that the weakly-supervised semantic segmentation technique is used for the right purpose.",Broader Impact,139,6,,,FALSE,FALSE,FALSE,Causal Intervention for Weakly-Supervised Semantic Segmentation,Applications -> Computer Vision,Applications -> Image Segmentation; Probabilistic Methods -> Causal Inference,Vision,"['Dong Zhang', ' Hanwang Zhang', ' Jinhui Tang', 'Sheng Hua', ' Qianru Sun']","{'Damo Academy, Alibaba Group', 'NTU', 'Singapore Management University', 'Nanjing University of Science and Technology'}",1,1,1,"{'Singapore', 'UK', 'China'}"
Belief Propagation Neural Networks,"Jonathan Kuck, Shuvam Chakraborty, Hao Tang, Rachel Luo, Jiaming Song, Ashish Sabharwal, Stefano Ermon",Belief Propagation Neural Networks,07217414eb3fbe24d4e5b6cafb91ca18,https://proceedings.neurips.cc/paper/2020/file/07217414eb3fbe24d4e5b6cafb91ca18-Paper.pdf,"This work makes both a theoretical contribution and a practical one by advancing the state-of-the-art in approximate inference on some benchmark problems. Our theoretical analysis of neural fixed point iterators is unlikely to have a direct impact on society. BPNN, on the other hand, can make approximate inference more scalable. Because approximate inference is a key computational problem underlying, for example, much of Bayesian statistics, it is applicable to many domains, both beneficial and harmful to society. Among the beneficial ones, we have applications of probabilistic inference to medical diagnosis and applications of model counting to reliability, safety, and privacy analysis.",Broader impact,101,5,,,FALSE,FALSE,FALSE,Belief Propagation Neural Networks,Probabilistic Methods -> Belief Propagation,Deep Learning; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Jonathan Kuck', ' Shuvam Chakraborty', ' Hao Tang', ' Rachel Luo', ' Jiaming Song', ' Ashish Sabharwal', ' Stefano Ermon']","{'Stanford', 'Stanford University', 'Shanghai Jiao Tong University', 'Allen Institute for AI'}",1,0,0,"{'USA', 'China'}"
Over-parameterized Adversarial Training: An Analysis Overcoming the Curse of Dimensionality,"Yi Zhang, Orestis Plevrakis, Simon S. Du, Xingguo Li, Zhao Song, Sanjeev Arora",Over-parameterized Adversarial Training: An Analysis Overcoming the Curse of Dimensionality,0740bb92e583cd2b88ec7c59f985cb41,https://proceedings.neurips.cc/paper/2020/file/0740bb92e583cd2b88ec7c59f985cb41-Paper.pdf,This does not present any foreseeable societal consequence.,8 Broader Impact,8,1,TRUE,FALSE,FALSE,FALSE,FALSE,Over-parameterized Adversarial Training: An Analysis Overcoming the Curse of Dimensionality,Theory,Optimization -> Non-Convex Optimization,Deep learning,"['Yi Zhang', ' Orestis Plevrakis', ' Simon Du', ' Xingguo Li', ' Zhao Song', ' Sanjeev Arora']","{'Princeton University', 'Institute for Advanced Study', 'IAS/Princeton'}",1,1,1,{'USA'}
Post-training Iterative Hierarchical Data Augmentation for Deep Networks,"Adil Khan, Khadija Fraz",Post-training Iterative Hierarchical Data Augmentation for Deep Networks,074177d3eb6371e32c16c55a3b8f706b,https://proceedings.neurips.cc/paper/2020/file/074177d3eb6371e32c16c55a3b8f706b-Paper.pdf,"In this paper, we proposed a new data augmentation technique to improve the generalization of any deep network, making our work general enough to be applied to a large variety of supervised learning problems. Since we do not foresee any particular application for our method, a Broader Impact discussion is not applicable.",Broader Impact,52,2,TRUE,FALSE,FALSE,FALSE,FALSE,Post-training Iterative Hierarchical Data Augmentation for Deep Networks,Deep Learning -> Efficient Training Methods,Deep Learning -> Generative Models; Deep Learning -> Supervised Deep Networks,Deep learning,"['Adil Khan', ' Khadija Fraz']","{'Innopolis University', 'Hazara University'}",1,0,0,"{'Russia', 'Pakistan'}"
Debugging Tests for Model Explanations,"Julius Adebayo, Michael Muelly, Ilaria Liccardi, Been Kim",Debugging Tests for Model Explanations,075b051ec3d22dac7b33f788da631fd4,https://proceedings.neurips.cc/paper/2020/file/075b051ec3d22dac7b33f788da631fd4-Paper.pdf,"Predictive models are increasingly being investigated, sometimes legally regulated for deployment in critical settings. Interpretability methods promise to provide insights about how models make decisions. This may increase user trust and provide the evidence needed to ensure that models deployed in mission-critical settings function adequately. The goal of our work is to investigate this literature with a critical eye: can attribution methods signal that there may be issues with the model, data or at test-time setting? We provide both quantitative and qualitative approaches to evaluate many popular attribution methods in order to provide practitioners and researchers with a set of debugging tests which may be used in validation. We hope our work is one of the first of many to bridge the gap between methods developed in academia and practical usage of those methods in the real world.",Broader Impact,138,6,,,FALSE,FALSE,FALSE,Debugging Tests for Model Explanations,"Deep Learning -> Visualization, Interpretability, and Explainability","Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",,"['Julius Adebayo', ' Michael Muelly', ' Ilaria Liccardi', ' Been Kim']","{'Google', 'Stanford University', 'MIT'}",1,1,1,{'USA'}
Robust compressed sensing using generative models,"Ajil Jalal, Liu Liu, Alexandros G. Dimakis, Constantine Caramanis",Robust Compressed Sensing using Generative Models,07cb5f86508f146774a2fac4373a8e50,https://proceedings.neurips.cc/paper/2020/file/07cb5f86508f146774a2fac4373a8e50-Paper.pdf,"Sparsity has played an important role across many areas of statistics, engineering and computer science, as a regularizing prior that captures important structure in many applications. Recent work has illustrated that given enough data, deep generative models are poised to play a revolutionary role, as a modern, data-driven replacement for sparsity. Much work remains to bring this agenda to fruition, but we believe that, as a variety of recent works have suggested, this direction can revolutionize imaging in a number of different important domains, not least of all, medical imaging. This work addresses the robustness, and hence the trustworthiness and reliability of GAN-inversion- based techniques. As mentioned, this is especially critical, since high quality GANs will always produce perceptually high quality images, hence recovery failures may not be readily detectable by inspection. Still, many significant issues remain that this work does not address. This includes understanding when and how sufficiently powerful and expressive GANs can be trained, since the scope of high quality GANs still appears to be limited. Another important consideration includes the core computational issue: the GAN inversion problem, which this work also faces, is intractable in the worst case, yet in practice appears to not pose a significant challenge. Understanding this dichotomy is very important.",9 Broader Impact,208,9,,,FALSE,TRUE,FALSE,Robust compressed sensing using generative models,Algorithms -> Sparsity and Compressed Sensing,Algorithms -> Regression; Theory -> Information Theory,Theory (including computational and statistical analyses),"['Ajil Jalal', ' Liu Liu', ' Alexandros Dimakis', ' Constantine Caramanis']","{'University of Texas, Austin', 'University of Texas at Austin', 'UT Austin'}",1,0,0,{'USA'}
Fairness without Demographics through Adversarially Reweighted Learning,"Preethi Lahoti, Alex Beutel, Jilin Chen, Kang Lee, Flavien Prost, Nithum Thain, Xuezhi Wang, Ed Chi",Fairness without Demographics through Adversarially Reweighted Learning,07fc15c9d169ee48573edd749d25945d,https://proceedings.neurips.cc/paper/2020/file/07fc15c9d169ee48573edd749d25945d-Paper.pdf,"Any machine learning system that learns from data runs the risk of introducing unfairness in decision making. Recent research [19, 5, 30, 9] has identified fairness concerns in several ML systems, especially toward protected groups that are under-represented in the data. Thus, alongside the technical advancements in improving ML systems it crucial that we also focus on ensuring that they work for everyone. One of the key practical challenges in addressing unfairness in ML systems is that most methods require access to protected demographic features, placing fairness and privacy in tension. In this work we work toward addressing these important challenges by proposing a new training method to improve worst-case performance of protected groups, in the absence of protected group information in the datasets. One limitation of methods in this space, including ours, is the difficulty of evaluating their effectiveness when we don’t have demographics in a real application. Therefore, while we think developing better debiasing methods is crucial, there remains further challenges in evaluating them. Further, this work relies on the assumption that protected groups are computationally-identifiable. However, if there were no signal about protected groups in the remaining features X and class labels Y , we cannot make any statements about improving the model for protected groups. Similarly, we observe that when the ground truth labels in the training dataset are noisy, the performance of ARL drops. Looking forward, we believe further research is needed to validate how the proposed approach can remain effective in a wide variety of real world applications beyond the datasets we have studied in this work.",7 Broader Impact,263,11,,,FALSE,FALSE,FALSE,Fairness without Demographics through Adversarially Reweighted Learning,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Adversarial Learning; Deep Learning -> Adversarial Networks,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Preethi Lahoti', ' Alex Beutel', ' Jilin Chen', ' Kang Lee', ' Flavien Prost', ' Nithum Thain', ' Xuezhi Wang', ' Ed Chi']","{'Google', 'Max Planck Institute for Informatics', 'Google Brain', 'Google Research'}",1,1,1,"{'USA', 'Germany'}"
Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model,"Alex Lee, Anusha Nagabandi, Pieter Abbeel, Sergey Levine",Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model,08058bf500242562c0d031ff830ad094,https://proceedings.neurips.cc/paper/2020/file/08058bf500242562c0d031ff830ad094-Paper.pdf,"Despite the existence of automated robotic systems in controlled environments such as factories or labs, standard approaches to controlling systems still require precise and expensive sensor setups to monitor the relevant details of interest in the environment, such as the joint positions of a robot or pose information of all objects in the area. To instead be able to learn directly from the more ubiquitous and rich modality of vision would greatly advance the current state of our learning systems. Not only would this ability to learn directly from images preclude expensive real-world setups, but it would also remove the expensive need for human-engineering efforts in state estimation. While it would indeed be very beneficial for our learning systems to be able to learn directly from raw image observations, this introduces algorithm challenges of dealing with high-dimensional as well as partially observable inputs. In this paper, we study the use of explicitly learning latent representations to assist model-free reinforcement learning directly from raw, high-dimensional images. Standard end-to-end RL methods try to solve both representation learning and task learning together, and in practice, this leads to brittle solutions which are sensitive to hyperparameters but are also slow and inefficient. These challenges illustrate the predominant use of simulation in the deep RL community; we hope that with more efficient, stable, easy-to-use, and easy-to-train deep RL algorithms such as the one we propose in this work, we can help the field of deep RL to transition to more widespread use in real-world setups such as robotics. From a broader perspective, there are numerous use cases and areas of application where autonomous decision making agents can have positive effects in our society, from automating dangerous and undesirable tasks, to accelerating automation and economic efficiency of society. That being said, however, automated decision making systems do introduce safety concerns, further exacerbated by the lack of explainability when they do make mistakes. Although this work does not explicitly address safety concerns, we feel that it can be used in conjunction with levels of safety controllers to minimize negative impacts, while drawing on its powerful deep reinforcement learning roots to enable automated and robust tasks in the real world.",Broader Impact,362,10,,,FALSE,FALSE,FALSE,Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Alex Lee', ' Anusha Nagabandi', ' Pieter Abbeel', ' Sergey Levine']",{'UC Berkeley'},1,0,0,{'USA'}
Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian,"Jack Parker-Holder, Luke Metz, Cinjon Resnick, Hengyuan Hu, Adam Lerer, Alistair Letcher, Alexander Peysakhovich, Aldo Pacchiano, Jakob Foerster",Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian,08425b881bcde94a383cd258cea331be,https://proceedings.neurips.cc/paper/2020/file/08425b881bcde94a383cd258cea331be-Paper.pdf,"We believe our method is the first to propose following the eigenvectors of the Hessian to optimize in the parameter space to train neural networks. This provides a stark contrast to SGD as commonly used across a broad spectrum of applications. Most specifically, it allows us to seek a variety of solutions more easily. Given how strong DNNs are as function approximators, algorithms that enable more structured exploration of the range of solutions are more likely to find those that are semantically aligned with what humans care about. In our view, the most significant advantage of that is the possibility that we could discover the minima that are not ‘shortcut solutions’ [16] like texture but rather generalizable solutions like shape [18]. The texture and shape biases are just one of many problematic solution tradeoffs that we are trying to address. This also holds for non-causal/causal solutions (the non-causal or correlative solution patterns are much easier to find) as well as concerns around learned biases that we see in applied areas across machine learning. All of these could in principle be partially addressed by our method. Furthermore, while SGD has been optimized over decades and is extremely effective, there is no guarantee that RR will ever become a competitive optimizer. However, maybe this is simply an instance of the ‘no-free-lunch’ theorem [53] - we cannot expect to find diverse solutions in science unless we are willing to take a risk by not following the locally greedy path. Still, we are committed to making this journey as resource-and time efficient as possible, making our code available and testing the method on toy environments are important measures in this direction.",Broader Impact,277,11,,,FALSE,FALSE,FALSE,Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian,Deep Learning -> Optimization for Deep Networks,Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Multi-Agent RL,Optimization Methods (continuous or discrete),"['Holder', ' Cinjon Resnick', ' Luke Metz', ' Hengyuan Hu', ' Adam Lerer', ' Alistair Letcher', ' Alexander Peysakhovich', ' Aldo Pacchiano', ' Jakob Foerster']","{'University of Oxford', 'Facebook', 'NYU', 'UC Berkeley', 'Facebook AI Research', 'Google Brain', 'None'}",1,1,1,"{'UK', 'USA'}"
The route to chaos in routing games: When is price of anarchy too optimistic?,"Thiparat Chotibut, Fryderyk Falniowski, Michał Misiurewicz, Georgios Piliouras",The route to chaos in routing games: When is price of anarchy too optimistic?,0887f1a5b9970ad13f46b8c1485f7900,https://proceedings.neurips.cc/paper/2020/file/0887f1a5b9970ad13f46b8c1485f7900-Paper.pdf,"Our theoretical work provides a model that suggests that societal systems whose performance is impacted negatively under increased demand (e.g. road networks, public health services, etc.) might undergo violent phase transitions after exceeding critical thresholds. One could in principle use our quantitative predictions and toolsets to try to predict whether such a complex networked system is close to the onset of chaos/instability and to try to mitigate its destructive consequences.",Broader societal impact,70,2,FALSE,FALSE,TRUE,TRUE,FALSE,The route to chaos in routing games: When is price of anarchy too optimistic?,Theory -> Game Theory and Computational Economics,Algorithms -> Dynamical Systems; Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Thiparat Chotibut', ' Fryderyk Falniowski', ' Michał Misiurewicz', ' Georgios Piliouras']","{'Indiana University-Purdue University Indianapolis', 'Cracow University of Economics', 'Chulalongkorn university', 'Singapore University of Technology and Design'}",1,0,0,"{'Singapore', 'USA', 'Thailand'}"
Online Algorithm for Unsupervised Sequential Selection with Contextual Information,"Arun Verma, Manjesh Kumar Hanawal, Csaba Szepesvari, Venkatesh Saligrama",Online Algorithm for Unsupervised Sequential Selection with Contextual Information,08e5d8066881eab185d0de9db3b36c7f,https://proceedings.neurips.cc/paper/2020/file/08e5d8066881eab185d0de9db3b36c7f-Paper.pdf,"The work considered the unsupervised sequential selection problem with contextual information. While we are not targeting any specific applications, the work has many potential civilian applications.  As usual, these can improve societal conditions, but of course, with any technology, specific deployments need care. However, this is outside of the scope of the present work, which is aimed at improving the basic algorithms and understand the fundamental challenges in this problem setting. Of course, the authors hope that their work will have an altogether positive impact, both by deepening our understanding of challenging sequential decision making under uncertainty and by potential future (careful) applications of the algorithms developed here. Having said this, we do not foresee any immediate negative impact of this work.",7 Broader Impact,122,6,,,FALSE,FALSE,FALSE,Online Algorithm for Unsupervised Sequential Selection with Contextual Information,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning,Reinforcement learning and planning,"['Arun Verma', ' Manjesh Kumar Hanawal', ' Csaba Szepesvari', ' Venkatesh Saligrama']","{'Indian Institute of Technology Bombay', 'Boston University', 'IIT Bombay', 'DeepMind / University of Alberta'}",1,1,1,"{'Canada', 'India', 'UK', 'USA'}"
Adapting Neural Architectures Between Domains,"Yanxi Li, Zhaohui Yang, Yunhe Wang, Chang Xu",Adapting Neural Architectures Between Domains,08f38e0434442128fab5ead6217ca759,https://proceedings.neurips.cc/paper/2020/file/08f38e0434442128fab5ead6217ca759-Paper.pdf,This paper provides a novel perspective of cross-domain generalization in neural architecture search towards the efficient design of neural architectures with strong generalizability. This will lead to a better understanding of the generalizability of neural architectures. The proposed method will be used to design neural architectures for computer vision tasks with affordable computation cost.,Broader Impact,54,3,FALSE,FALSE,FALSE,FALSE,FALSE,Adapting Neural Architectures Between Domains,Deep Learning -> CNN Architectures,,AutoML,"['Yanxi Li', ' zhaohui yang', ' Yunhe Wang', ' Chang Xu']","{'University of Sydney', 'peking university'}",1,0,0,"{'Australia', 'China'}"
What went wrong and when? Instance-wise feature importance for time-series black-box models,"Sana Tonekaboni, Shalmali Joshi, Kieran Campbell, David K. Duvenaud, Anna Goldenberg",What went wrong and when? Instance-wise feature importance for time-series black-box models,08fa43588c2571ade19bc0fa5936e028,https://proceedings.neurips.cc/paper/2020/file/08fa43588c2571ade19bc0fa5936e028-Paper.pdf,"This work adds to the growing body of literature in instance-level feature importance attribution and lies in the general purview of explainable machine learning. We focus on the time-series domain, where not many methods have been developed. We are primarily motivated by potential applicability to clinical settings, where time-series data is widely collected in real-time and in Electronic Health Records or EHRs. This preliminary proof-of-concept serves to determine the utility of the proposed framework and highlights specific benefits compared to the existing literature in this area. While there is no clear consensus on the practical utility of explainable ML and its implication on the trust and safety of end-users, we believe there is a general benefit to grounding this class of methods methodologically. Our work is a step toward that. We additionally evaluate the method with preliminary reliability tests. We believe this is a crucial first step toward improving the framework for practical deployment. At this juncture, the proposed method’s application is currently unsafe without further testing on the deployment data and further understanding the nature of the underlying clinical tasks where such a method may be used.",Broader Impact,188,9,,,FALSE,FALSE,FALSE,What went wrong and when? Instance-wise feature importance for time-series black-box models,Applications -> Time Series Analysis,Applications -> Health,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Sana Tonekaboni', ' Shalmali Joshi', ' Kieran Campbell', ' David Duvenaud', ' Anna Goldenberg']","{'Vector Institute', 'University of Toronto Vector institute', 'University of British Columbia', 'University of Toronto', 'University of Toronto Vector Institute'}",1,0,0,{'Canada'}
Towards Better Generalization of Adaptive Gradient Methods,"Yingxue Zhou, Belhal Karimi, Jinxing Yu, Zhiqiang Xu, Ping Li",Towards Better Generalization of Adaptive Gradient Methods,08fb104b0f2f838f3ce2d2b3741a12c2,https://proceedings.neurips.cc/paper/2020/file/08fb104b0f2f838f3ce2d2b3741a12c2-Paper.pdf,"We believe that our work stands in the line of several papers towards improving generalization and avoiding over-fitting. Indeed, the basic principle of our method is to fit any given model, in particular deep model, using an intermediate differentially-private mechanisms allowing the model to fit fresh samples while passing over the same batch of n observations. The impact of such work is straightforward and could avoid learning, and thus reproducing at testing phase, the bias existent in the training dataset.",Broader Impact,80,3,,,FALSE,FALSE,FALSE,Towards Better Generalization of Adaptive Gradient Methods,Algorithms -> Stochastic Methods,Deep Learning -> Optimization for Deep Networks; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Yingxue Zhou', ' Belhal Karimi', ' Jinxing Yu', ' Zhiqiang Xu', ' Ping Li']","{'Ecole Polytechnique', 'University of Minnesota', 'Baidu Research USA', 'Baidu Research'}",1,1,1,"{'France', 'USA', 'Switzerland', 'China'}"
Learning Guidance Rewards with Trajectory-space Smoothing,"Tanmay Gangwani, Yuan Zhou, Jian Peng",Learning Guidance Rewards with Trajectory-space Smoothing,0912d0f15f1394268c66639e39b26215,https://proceedings.neurips.cc/paper/2020/file/0912d0f15f1394268c66639e39b26215-Paper.pdf,"In this paper, we propose techniques to improve the sample-efficiency of Reinforcement Learning (RL) algorithms when the environmental rewards are sparse or delayed. Many real-world decision- making problems of interest are of this nature – the rewarding (or penalizing) feedback is usually available only after a long sequence of interaction with the environment. Some prominent examples include a.) Chemical Synthesis , where the product yield and the functional measurements mostly happen at the last step of the entire process; b.) Industrial Control Processes , which involve sequential calibration of many control variables to achieve the desired output, for instance, the final metal purity metric in a metal-refining furnace operation; and c.) RL in healthcare for uncovering promising treatment regimes, where there could be delayed interaction between treatments and human bodies. Techniques that make RL algorithms robust in the face of delayed rewards are therefore poised to have a hugely positive societal influence across a range of sectors. We believe our work is a step in the direction of developing such techniques.",Broader Impact,171,7,,,FALSE,FALSE,FALSE,Learning Guidance Rewards with Trajectory-space Smoothing,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Tanmay Gangwani', ' Yuan Zhou', ' Jian Peng']","{'University of Illinois at Urbana-Champaign', 'UIUC', 'University of Illinois, Urbana-Champaign'}",1,0,0,{'USA'}
Variance Reduction via Accelerated Dual Averaging for Finite-Sum Optimization,"Chaobing Song, Yong Jiang, Yi Ma",Variance Reduction via Accelerated Dual Averaging for Finite-Sum Optimization,093b60fd0557804c8ba0cbf1453da22f,https://proceedings.neurips.cc/paper/2020/file/093b60fd0557804c8ba0cbf1453da22f-Paper.pdf,"The finite-sum structure widely exists in statistical learning, operational research, and signal process- ing. This work successfully exploits the finite-sum structure to push the performance of this kind of problems in both theory and practice. The theoretical contribution helps us better understand this simple but effective structure, while the superior empirical performance shows potential applications of this work in all the related subjects. It may benefit the broad academic and research community. There are no foreseeable negative or biased consequences.",Broader Impact,80,5,FALSE,TRUE,FALSE,FALSE,FALSE,Variance Reduction via Accelerated Dual Averaging for Finite-Sum Optimization,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization,,,"{'UC Berkeley', 'Tsinghua University', 'Tsinghua'}",1,0,0,"{'USA', 'China'}"
Tree! I am no Tree! I am a low dimensional Hyperbolic Embedding,"Rishi Sonthalia, Anna Gilbert",Tree! I am no Tree! I am a Low Dimensional Hyperbolic Embedding,093f65e080a295f8076b1c5722a46aa2,https://proceedings.neurips.cc/paper/2020/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf,"There are multiple aspects to the broader impacts of our work, from the impact upon computational biology, specifically, to the impact upon data sciences more generally. The potential impacts on society, both positive and negative, are large. Computational biology is undergoing a revolution due to simultaneous advances in the creation of novel technologies for the collection of multiple and novel sources of data, and in the progress of the development of machine learning algorithms for the analysis of such data. Social science has a similar revolution in its use of computational techniques for the analysis and gathering of data. Cellular differentiation is the process by which cells transition from one cell type (typically an immature cell) into more specialized types. Understanding how cells differentiate is a critical problem in modern developmental and cancer biology. Single-cell measurement technologies, such as single- cell RNA-sequencing (scRNA-seq) and mass cytometry, have enabled the study of these processes. To visualize, cluster, and infer temporal properties of the developmental trajectory, many researchers have developed algorithms that leverage hierarchical representations of single cell data. To discover these geometric relationships, many state-of-the-art methods rely on distances in low-dimensional Euclidean embeddings of cell measurements. This approach is limited, however, because these types of embeddings lead to substantial distortions in the visualization, clustering, and the identification of cell type lineages. Our work is specifically focused on extracting and representing hierarchical information. On the more negative side, these algorithms might also be used to analyze social hierarchies and to divine social structure from data about peoples’ interactions. Such tools might encourage, even justify, the intrusive and pervasive collection of data about how people interact and with whom.",5 Broader Impact,276,13,,,FALSE,FALSE,FALSE,Tree! I am no Tree! I am a low dimensional Hyperbolic Embedding,Algorithms -> Representation Learning,Algorithms -> Large Scale Learning; Algorithms -> Metric Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Rishi S Sonthalia', ' Anna Gilbert']",{'University of Michigan'},1,0,0,{'USA'}
Deep Structural Causal Models for Tractable Counterfactual Inference,"Nick Pawlowski, Daniel Coelho de Castro, Ben Glocker",Deep Structural Causal Models for Tractable Counterfactual Inference,0987b8b338d6c90bbedd8631bc499221,https://proceedings.neurips.cc/paper/2020/file/0987b8b338d6c90bbedd8631bc499221-Paper.pdf,"Causal inference can be applied to a wide range of applications, promising to provide a deeper understanding of the observed data and prevent the fitting of spurious correlations. Our research presents a methodological contribution to the causal literature proposing a framework that combines causal models and deep learning to facilitate modelling high-dimensional data. Because of the general applicability of deep learning and causal inference, our framework could have a broad impact of enabling fairer machine learning models explicitly modelling causal mechanisms, reducing spurious correlations and tackling statistical and societal biases. The resulting models offer better interpretability due to counterfactual explanations and could yield novel understanding through causal discovery. However, causal modelling relies on strong assumptions and cannot always unambiguously determine the true causal structure of observational data. It therefore is necessary to carefully consider and communicate the assumptions being made by the analyst. In this light, our methodology is susceptible to being used to wrongly claim the discovery of causal structures due to careless application or intentional misuse. Particularly, the use of ‘black-box’ components as causal mechanisms may exacerbate concerns about identifiability, already present even for simple linear models. Whereas deep causal models can be useful for deriving insights from data, we must be cautious about their use in consequential decision-making, such as in informing policies or in the context of healthcare.",Broader Impact,222,9,,,FALSE,FALSE,FALSE,Deep Structural Causal Models for Tractable Counterfactual Inference,Probabilistic Methods -> Causal Inference,Deep Learning -> Generative Models; Probabilistic Methods -> Graphical Models; Probabilistic Methods -> Variational Inference,Causality,"['Nick Pawlowski', ' Daniel Coelho de Castro', ' Ben Glocker']",{'Imperial College London'},1,0,0,{'UK'}
Convolutional Generation of Textured 3D Meshes,"Dario Pavllo, Graham Spinks, Thomas Hofmann, Marie-Francine Moens, Aurelien Lucchi",Convolutional Generation of Textured 3D Meshes,098d86c982354a96556bd861823ebfbd,https://proceedings.neurips.cc/paper/2020/file/098d86c982354a96556bd861823ebfbd-Paper.pdf,"Our line of research can positively benefit the video game and film industries, both of which impact the life of billions of users. The ability to partially automate the construction of tailored 3D shapes with textures has the potential to reduce costs and timelines by lessening tedious work. The impact on jobs in this area is likely to be minimal as this work is usually performed by specialists whose expertise could be redirected to more creative tasks [2]. Other areas like education and arts could benefit from the ability to bring new concepts to life in an (interactive) 3D environment. Additionally, mesh generation is a hard problem that is likely to be central in many research areas and industry applications going forward. Adversely, generative models can be used toward fake content creation. The negative societal impact of our method on image generation is likely small as many image modification tools have existed for years [10]. In the longer term, approaches that involve 3D generation might facilitate manipulation of fake video sequences which is harder to achieve with modern software tools. Such applications bring on concerns over exploitation, privacy, political manipulation and the undermining of public institutions. Comparable considerations have already become part of public discourse. A range of approaches have been suggested to tackle such issues ranging from technological, legal, and market solutions. For a more in-depth overview of this discussion we refer to [6].",Broader Impact,235,12,,,FALSE,FALSE,FALSE,Convolutional Generation of Textured 3D Meshes,Applications -> Computer Vision,Deep Learning -> Generative Models,Vision,"['Dario Pavllo', ' Graham Spinks', ' Thomas Hofmann', 'Francine Moens', ' Aurelien Lucchi']","{'ETH Zurich', 'KU Leuven'}",1,0,0,"{'Belgium', 'Switzerland'}"
A Statistical Framework for Low-bitwidth Training of Deep Neural Networks,"Jianfei Chen, Yu Gai, Zhewei Yao, Michael W. Mahoney, Joseph E. Gonzalez",A Statistical Framework for Low-bitwidth Training of Deep Neural Networks,099fe6b0b444c23836c4a5d07346082b,https://proceedings.neurips.cc/paper/2020/file/099fe6b0b444c23836c4a5d07346082b-Paper.pdf,"Fully quantized training, including our work, can be potentially used to reduce the cost (and thus, for example, the carbon footprint) of training large deep neural networks. In recent years, huge models such as EfficientNet-B7 [16], BERT [18], GPT-2 [17] and GPT-3 [44] have achieve impressive results in many areas, particularly in natural language processing. However, these models are becoming pro- hibitively expensive to train. For example, the GPT-3 model takes 3,640 petaflops-days to train [44], while a V100 GPU only has ∼ 15 teraflops single precision throughput. Training is necessary when, for example, adapting to a new language. The prohibitive training time makes machine learning research and potential applications increasingly rely on these amounts of computational resources, and it is thus increasingly inaccessible and unfair. The low-bitwidth quantizers presented in this paper can potentially reduce the cost of training neural networks, making state-of-the-art machine learning more democratized. Fully quantized training may also be applied for training on edge devices. Due to the high energy cost, training is not yet widely done on edge devices. Using the energy-efficient low-bitwidth hardware, the techniques proposed in this paper can potentially help move training towards edge. Training on edge enables new applications, such as locally-trained personalized models. Locally trained models improve privacy, as they do not need to upload user information to the cloud.",Broader Impact,221,12,,,FALSE,FALSE,FALSE,A Statistical Framework for Low-bitwidth Training of Deep Neural Networks,Deep Learning -> Efficient Training Methods,Optimization -> Stochastic Optimization,,"['Jianfei Chen', ' Yu Gai', ' Zhewei Yao', ' Michael W Mahoney', ' Joseph Gonzalez']","{'UC Berkeley', 'RealAI'}",1,1,1,"{'USA', 'China'}"
Better Set Representations For Relational Reasoning,"Qian Huang, Horace He, Abhay Singh, Yan Zhang, Ser Nam Lim, Austin R. Benson",Better Set Representations For Relational Reasoning,09ccf3183d9e90e5ae1f425d5f9b2c00,https://proceedings.neurips.cc/paper/2020/file/09ccf3183d9e90e5ae1f425d5f9b2c00-Paper.pdf,"As neural networks continue to be deployed in a number of high-stakes tasks, it is crucial to have a better understanding of their limitations and robustness. In this paper, we make some progress on both of these issues. We showed that end-to-end learning systems that use an intermediate set-structured representation often have difficulty properly decomposing the input into set elements, illustrating that existing pipelines are not actually creating the representations that they intended to make. Also, our experiments in Section 3.1 demonstrated that a popular relational reasoning approach in fact learns a brittle model on a fairly simple dataset. We have presented a first approach at alleviating some of these systemic problems, and our experiments highlight how to learn more meaningful set representations, which helps improve robustness in addition to predictive performance. In addition, our method improves reasoning capabilities of a wide variety of neural networks, which might increase the likelihood of such systems being used in the wild. Most modern machine learning systems are only relied upon to do “System 1” tasks, and we are contributing to models being relied upon for “System 2” tasks as well. This has many potential ramifications, both positive and negative, largely related to the general problems of using machine learning in practice.",Broader Impact,209,8,,,FALSE,FALSE,FALSE,Better Set Representations For Relational Reasoning,Algorithms -> Relational Learning,Algorithms -> Representation Learning; Applications -> Object Detection; Applications -> Object Recognition,Deep learning,"['Qian Huang', ' Horace He', ' Abhay Singh', ' Yan Zhang', ' Ser Nam Lim', ' Austin Benson']","{'University of Southampton', 'Facebook AI', 'Cornell University'}",1,1,1,"{'UK', 'USA'}"
AutoSync: Learning to Synchronize for Data-Parallel Distributed Deep Learning,"Hao Zhang, Yuan Li, Zhijie Deng, Xiaodan Liang, Lawrence Carin, Eric Xing",AutoSync: Learning to Synchronize for Data-Parallel Distributed Deep Learning,0a2298a72858d90d5c4b4fee954b6896,https://proceedings.neurips.cc/paper/2020/file/0a2298a72858d90d5c4b4fee954b6896-Paper.pdf,"The proposed AutoSync alleviates the burden on ML researchers and practitioners in choosing appropriate synchronization strategy for efficient distributed training, enables substantial speed up of ML prototyping and training, and reduces the cost of their operational workloads using distributed computing. Further, AutoSync is transferable to unseen model and cluster settings by the design of domain-agnostic features. By this, finding a good synchronization strategy for a large-scale ML model such as BERT [7] and GPT [28] or on a relatively expensive cluster only requires developing runtime simulators using data collected from a streamlined model on handy clusters, saving substantial experimental efforts and budgets. We will release and open-source our code and a new dataset to benefit the research community, to democratize high-performance ML systems, and make them accessible to non-ML-educated software developers and society at large. Since such needs are prevalent across many disciplines beyond computing and information science – such as industrial and manufacturing, healthcare, biology, social science, and finance – our deliverables are expected to have a catalytic impact.",Broader Impact,170,5,,,FALSE,FALSE,FALSE,AutoSync: Learning to Synchronize for Data-Parallel Distributed Deep Learning,Algorithms -> AutoML,Algorithms -> Large Scale Learning,AutoML,"['Hao Zhang', ' Yuan Li', ' Zhijie Deng', ' Xiaodan Liang', ' Lawrence Carin', ' Eric Xing']","{'Sun Yat-sen University', 'Tsinghua University', 'Duke University'}",1,0,0,"{'USA', 'China'}"
A Combinatorial Perspective on Transfer Learning,"Jianan Wang, Eren Sezener, David Budden, Marcus Hutter, Joel Veness",A Combinatorial Perspective on Transfer Learning,0a3b6f64f0523984e51323fe53b8c504,https://proceedings.neurips.cc/paper/2020/file/0a3b6f64f0523984e51323fe53b8c504-Paper.pdf,"This paper introduces a novel combinatorial perspective on transfer learning: past experiences can generalize to an exponentially growing number of unseen tasks. Taken to its limits, an obvious widespread benefit is improved data efficiency in solving unseen tasks, which could dramatically reduce compute and energy consumption. Privacy and algorithmic bias should be considered for real world applications to ensure that they are ethical and of positive benefit to society. Our proposed algorithm is online and therefore does not necessarily require storing data, which is potentially beneficial in terms of privacy. The algorithm inherits many interpretability properties from GLNs [VLB + 19], which might be helpful for understanding and addressing any potential bias issues in deployment.",Broader Impact,115,5,,,FALSE,FALSE,FALSE,A Combinatorial Perspective on Transfer Learning,Algorithms -> Continual Learning,Algorithms -> Multitask and Transfer Learning; Algorithms -> Online Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jianan Wang', ' Eren Sezener', ' David Budden', ' Marcus Hutter', ' Joel Veness']","{'DeepMind', 'Deepmind'}",0,1,0,{'UK'}
Hardness of Learning Neural Networks with Natural Weights,"Amit Daniely, Gal Vardi",Hardness of Learning Neural Networks with Natural Weights,0a4dc6dae338c9cb08947c07581f77a2,https://proceedings.neurips.cc/paper/2020/file/0a4dc6dae338c9cb08947c07581f77a2-Paper.pdf,Not applicable as far as we can see (this is a purely theoretical paper).,Broader Impact,14,1,TRUE,FALSE,FALSE,FALSE,FALSE,Hardness of Learning Neural Networks with Natural Weights,Theory -> Computational Learning Theory,Theory -> Hardness of Learning and Approximations,Theory (including computational and statistical analyses),"['Amit Daniely', ' Gal Vardi']","{'Weizmann Institute of Science', 'Hebrew University and Google Research'}",1,0,0,{'Israel'}
Higher-Order Spectral Clustering of Directed Graphs,"Steinar Laenen, He Sun",Higher-Order Spectral Clustering of Directed Graphs,0a5052334511e344f15ae0bfafd47a67,https://proceedings.neurips.cc/paper/2020/file/0a5052334511e344f15ae0bfafd47a67-Paper.pdf,"The primary focus of our work is efficient clustering algorithms for digraphs, whose clusters are defined with respect to the edge directions between different clusters. We believe that our work could have long-term social impact. For instance, when modelling the transmission of COVID-19 among individuals through a digraph, the cluster (group of people) with the highest ratio of out-going edges represents the most infectious community. This type of information could aid local containment policy. With the development of many tracing Apps for COVID-19 and a significant amount of infection data available in the near future, our studied algorithm could potentially be applied in this context. In addition, as shown by our experimental results on the UN Comtrade Dataset, our work could be employed to analyse many practical data for which most traditional clustering algorithms do not suffice.",6 Broader Impact,137,6,,,FALSE,FALSE,FALSE,Higher-Order Spectral Clustering of Directed Graphs,Algorithms,Algorithms -> Clustering; Algorithms -> Spectral Methods,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Valdimar Steinar Ericsson Laenen', ' He Sun']","{'School of Informatics, The University of Edinburgh', 'FiveAI'}",1,1,1,{'UK'}
Primal-Dual Mesh Convolutional Neural Networks,"Francesco Milano, Antonio Loquercio, Antoni Rosinol, Davide Scaramuzza, Luca Carlone",Primal-Dual Mesh Convolutional Neural Networks,0a656cc19f3f5b41530182a9e03982a4,https://proceedings.neurips.cc/paper/2020/file/0a656cc19f3f5b41530182a9e03982a4-Paper.pdf,"Processing of 3D data, in the form of point-cloud, voxel-grids, or meshes finds important applications in several fields, including computer graphics, vision, and robotics. Further developments of this work, which proposes a novel framework for mesh processing based on deep leaning, could have a benefit on several real-world applications, including augmented and virtual reality, robotics, and spatial 3D scene understanding of environments. These applications can have profound positive implications for the future of our society, by, for example, improving the quality of virtual social interactions, or increasing the spatial-awareness of current robotic systems to integrate them in our everyday life.",Broader Impact,100,3,,,FALSE,FALSE,FALSE,Primal-Dual Mesh Convolutional Neural Networks,Deep Learning -> CNN Architectures,Applications -> Computer Vision; Deep Learning -> Attention Models,Deep learning,"['Francesco Milano', ' Antonio Loquercio', ' Antoni Rosinol', ' Davide Scaramuzza', ' Luca Carlone']","{'Massachusetts Institute of Technology', 'ETH Zurich', 'ETH / University of Zurich', 'MIT'}",1,0,0,"{'USA', 'Switzerland', 'Germany'}"
The Advantage of Conditional Meta-Learning for Biased Regularization and Fine Tuning,"Giulia Denevi, Massimiliano Pontil, Carlo Ciliberto",The Advantage of Conditional Meta-Learning for Biased Regularization and Fine Tuning,0a716fe8c7745e51a3185fc8be6ca23a,https://proceedings.neurips.cc/paper/2020/file/0a716fe8c7745e51a3185fc8be6ca23a-Paper.pdf,"Meta-learning is a very important field for machine learning with potential societal implications related to applications such as recommender systems. In this work we focused mostly on theoretical and modeling aspects, however in the future the topic will need to take into consideration contributions from other fields related to ethical and societal aspects, such as privacy and fairness.",Broader impact,58,2,FALSE,FALSE,FALSE,FALSE,FALSE,The Advantage of Conditional Meta-Learning for Biased Regularization and Fine Tuning,Algorithms -> Meta-Learning,Algorithms; Algorithms -> Online Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Giulia Denevi', ' Massimiliano Pontil', ' Carlo Ciliberto']",{'Imperial College London'},1,0,0,{'UK'}
Watch out! Motion is Blurring the Vision of Your Deep Neural Networks,"Qing Guo, Felix Juefei-Xu, Xiaofei Xie, Lei Ma, Jian Wang, Bing Yu, Wei Feng, Yang Liu",Watch out! Motion is Blurring Blurring the Vision of Your Deep Neural Networks,0a73de68f10e15626eb98701ecf03adb,https://proceedings.neurips.cc/paper/2020/file/0a73de68f10e15626eb98701ecf03adb-Paper.pdf,"In this work, we make an early attempt to investigate the motion-blur effects to DNNs, which is a common phenomenon in the real-world image capturing process of a camera. We present the very first attack based on manipulating the motion blur of the images. Through comprehensive experiments, we have demonstrated that very successful attacks can be well disguised in naturally-looking motion blur patterns of the image, unveiling the system vulnerabilities of any image capture stage that deals with camera or object motions. Considering that image capturing and sensing is an integral and essential part of almost every computer vision application that interacts with the real world, the message we are trying to convey here is an important one, i.e., attackers can intentionally make use of motion blur, either by tampering with the camera sensing hardware or the image processing software to embed such an attack. Even unintentionally, the motion blur effects still commonly exist in the real-world application, posting threats to the DNNs behind the camera. This work is the first attempt to identify and showcase that such an attack based off image motion blur is not only feasible, but also leads to high attack success rate while simultaneously maintaining high realisticity in the image motion blur patterns. In a larger sense, this work can and will provide new thinking into how to better design the image capturing pipeline in order to mitigate potential risk caused by the vulnerabilities discussed herein, especially for mission- and safety-critical applications that are involved with moving objects or moving sensors such as autonomous driving scenarios, mobile face authentication with a hand-held device, computer-aided diagnostics in medical imaging, robotics, etc. Bad actors can potentially make use of this newly proposed attack mode as a wheel to pose risks on existing imaging systems that are not yet prepared for this new type of attack and effect based on image motion blur. We, as researchers, believe that our proposed method can accelerate the research and development of the DNN resilient mechanism against such motion blur effects. Therefore, our work can serve as an asset and a stepping stone for future-generation trustworthy design of computer vision DNNs and systems. In addition to the societal impact discussed above, the proposed method can also influence various research directions. For example, our proposed ABBA method: • hints new data augmentation technique for training powerful DNN-based deblurring methods. • hints new DNN design, detection/defense techniques to be resilience against motion blur effects. • hints new direction of analyzing the effect of motion blur to video analysis tasks, e.g., real-time visual object detection, tracking, segmentation, and action recognition.",5 Broader Impact,435,14,,,TRUE,TRUE,FALSE,Watch out! Motion is Blurring the Vision of Your Deep Neural Networks,Applications -> Computer Vision,Algorithms -> Adversarial Learning,Vision,"['Qing Guo', 'Xu', ' Xiaofei Xie', ' Lei Ma', ' Jian Wang', ' Bing Yu', ' Wei Feng', ' Yang Liu']","{'Alibaba Group', 'Kyushu university', 'Nanyang Technological University', 'Kyushu University, Japan', 'Nanyang Technology University, Singapore', 'Tianjin University'}",1,1,1,"{'Japan', 'Singapore', 'China'}"
Sinkhorn Barycenter via Functional Gradient Descent,"Zebang Shen, Zhenfu Wang, Alejandro Ribeiro, Hamed Hassani",Sinkhorn Barycenter via Functional Gradient Descent,0a93091da5efb0d9d5649e7f6b2ad9d7,https://proceedings.neurips.cc/paper/2020/file/0a93091da5efb0d9d5649e7f6b2ad9d7-Paper.pdf,"This work has the following potential positive impact in the society: We propose the first algorithm for the Sinkhorn barycenter problem that is scalable with respect to the problem dimension d (linear dependence), while existing works all have an exponential dependence on d. Further, we expect that this functional gradient descent method can be applied to more general optimization problems involving distribution sampling: In principle, the negative gradient of the dual variables instructs the particles in the measure to search the landscape of the minimizer.",6 Broader Impact,85,1,FALSE,FALSE,TRUE,TRUE,FALSE,Sinkhorn Barycenter via Functional Gradient Descent,Optimization -> Non-Convex Optimization,,Optimization Methods (continuous or discrete),"['Zebang Shen', ' Zhenfu Wang', ' Alejandro Ribeiro', ' Hamed Hassani']","{'University of Pennsylvania', 'Peking University', 'UPenn'}",1,0,0,"{'USA', 'China'}"
Coresets for Near-Convex Functions,"Murad Tukan, Alaa Maalouf, Dan Feldman",Coresets for Near-Convex Functions,0afe095e81a6ac76ff3f69975cb3e7ae,https://proceedings.neurips.cc/paper/2020/file/0afe095e81a6ac76ff3f69975cb3e7ae-Paper.pdf,"Our work provides a strong theoretical result, where we have suggested a generic framework for bounding the sensitivity with respect to broad family of functions. Practically, this family imposes widely used applications such as SVM , Logistic regression , z -Regression and more. Although, Broader Impact discussion is not directly applicable, our work can be used to accelerate many known machine learning solvers under various settings such as distributed, streaming, etc.",Broader Impact,71,3,FALSE,TRUE,FALSE,TRUE,FALSE,Coresets for Near-Convex Functions,Algorithms -> Sparsity and Compressed Sensing,Algorithms -> Classification; Algorithms -> Data Compression; Algorithms -> Large Scale Learning; Algorithms -> Regression; Applications -> Matrix and Tensor Factorization,Data summarization with respect to ML models,"['Morad Tukan', ' Alaa Maalouf', ' Dan Feldman']","{'University of Haifa', 'The University of Haifa'}",1,0,0,{'Israel'}
Bayesian Deep Ensembles via the Neural Tangent Kernel,"Bobby He, Balaji Lakshminarayanan, Yee Whye Teh",Bayesian Deep Ensembles via the Neural Tangent Kernel,0b1ec366924b26fc98fa7b71a9c249cf,https://proceedings.neurips.cc/paper/2020/file/0b1ec366924b26fc98fa7b71a9c249cf-Paper.pdf,"We believe that our Bayesian deep ensembles may be useful in situations where predictions that are robust to model misspecification and dataset shift are crucial, such as weather forecasting or medical diagnosis.",Broader Impact,32,1,FALSE,FALSE,FALSE,FALSE,FALSE,Bayesian Deep Ensembles via the Neural Tangent Kernel,Algorithms -> Uncertainty Estimation,Algorithms -> Boosting and Ensemble Methods; Algorithms -> Regression; Deep Learning; Deep Learning -> Analysis and Understanding of Deep Networks; Probabilistic Methods; Probabilistic Methods -> Gaussian Processes; Theory -> Spaces of Functions and Kernels,Probabilistic methods and inference,"['Bobby He', ' Balaji Lakshminarayanan', ' Yee Whye Teh']","{'Google Brain', 'University of Oxford, DeepMind', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
Improved Schemes for Episodic Memory-based Lifelong Learning,"Yunhui Guo, Mingrui Liu, Tianbao Yang, Tajana Rosing",Improved Schemes for Episodic Memory-based Lifelong Learning,0b5e29aa1acf8bdc5d8935d7036fa4f5,https://proceedings.neurips.cc/paper/2020/file/0b5e29aa1acf8bdc5d8935d7036fa4f5-Paper.pdf,"In this paper, researchers introduce a unified view on current episodic memory based lifelong learning methods and propose two improved schemes: MEGA-I and MEGA-II. The proposed schemes demonstrate superior performance and advance the state-of-the-art on several lifelong learning benchmarks. The unified view embodies existing episodic memory based lifelong learning methods in the same general framework. The proposed MEGA-I and MEGA-II significantly improve existing episodic memory based lifelong learning such as GEM [1] and A-GEM [2]. The proposed schemes enable machine learning models to acquire the ability to learn tasks sequentially without catastrophic forgetting . Machine learning models with continual learning capability can be applied in image classification [1] and natural language processing [52]. The proposed lifelong learning algorithms can be applied in several real-world applications such as on-line advertisement, fraud detection, climate change monitoring, recommendation systems, industrial manufacturing and so on. In all these applications, the data are arriving sequentially and the data distribution may change over time. For example, in recommendation systems, the users’ preferences may vary due to their aging, personal financial status or health condition. The machine learning models without continual learning capability may not capture such dynamics. The proposed lifelong learning schemes are able to address this issue. The related applications have a broad range of societal implications: the use of lifelong recommenda- tion systems can bring several benefits such as reducing the cost of model retraining and providing better user experience. However, such systems may have the concerns of data privacy. Lifelong recommendation systems can increase customer satisfaction. In the mean time, this system needs to store part of user data which may compromise user’s privacy. Our proposed lifelong learning schemes also are closely related to other machine learning research areas, including multi-task learning, transfer learning, federated learning, few-shot learning and so on. In transfer learning, when the source domain and the target domain are different, it is crucial to develop techniques that can reduce the negative transfer between the domains during the fine-tuning process. We expect that our proposed approaches can be leveraged to resolve the issue of negative transfer. We encourage researchers to further investigate the merits and shortcomings of our proposed methods. In particular, we recommend researchers and policymakers to look into lifelong learning systems without storing examples from past tasks. Such systems do not jeopardize users’ privacy and can be deployed in critical scenarios such as financial applications.",Broader Impact,397,21,,,FALSE,TRUE,FALSE,Improved Schemes for Episodic Memory-based Lifelong Learning,Algorithms -> Continual Learning,Algorithms -> Multitask and Transfer Learning,Deep learning,,"{'The University of Iowa', 'University of California, San Diego', 'Boston University'}",1,0,0,{'USA'}
Adaptive Sampling for Stochastic Risk-Averse Learning,"Sebastian Curi, Kfir Y. Levy, Stefanie Jegelka, Andreas Krause",Adaptive Sampling for Stochastic Risk-Averse Learning,0b6ace9e8971cf36f1782aa982a708db,https://proceedings.neurips.cc/paper/2020/file/0b6ace9e8971cf36f1782aa982a708db-Paper.pdf,"Increasing reliability is one of the central challenges when deploying machine learning in high-stakes applications. We believe our paper makes important contributions to this endeavor by going beyond simply optimizing the average performance, and considering risk in deep learning. The CVaR is also known to be an avenue towards enforcing fairness constraints in data sets (Williamson and Menon, 2019). Hence, our algorithm also contributes to optimizing fair deep models, by counteracting inherent biases in the data (e.g., undersampling of certain parts of the population).",Broader Impact,84,4,,,FALSE,FALSE,FALSE,Adaptive Sampling for Stochastic Risk-Averse Learning,Algorithms,Algorithms -> Bandit Algorithms; Deep Learning; Deep Learning -> Efficient Training Methods; Deep Learning -> Optimization for Deep Networks; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization; Optimization -> Submodular Optimization; Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Sebastian Curi', ' Levy', ' Stefanie Jegelka', ' Andreas Krause']","{'ETHz', 'ETH Zurich', 'Technion', 'MIT'}",1,1,1,"{'USA', 'Israel', 'Switzerland'}"
Deep Wiener Deconvolution: Wiener Meets Deep Learning for Image Deblurring,"Jiangxin Dong, Stefan Roth, Bernt Schiele",Deep Wiener Deconvolution: Wiener Meets Deep Learning for Image Deblurring,0b8aff0438617c055eb55f0ba5d226fa,https://proceedings.neurips.cc/paper/2020/file/0b8aff0438617c055eb55f0ba5d226fa-Paper.pdf,"Since blur is a common artifact in imaging systems, such as from the point spread function of the optical system, image deblurring has a broad potential impact through a wide range of applications. These include satellite imaging, medical imaging, telescope imaging in astronomy, and portable device imaging . Our image deblurring technique based on the proposed deep Wiener deconvolution network can provide high-quality clear images to facilitate intelligent data analysis tasks in these fields and it is apparent that applications, e.g., in medical imaging or portable device imaging have significant societal impact. To illustrate its applicability, we provide some examples for potential applications of our approach in the supplemental material. Despite the many benefits of high-quality image deblurring, negative consequences can still arise, largely because image deblurring can present certain risks to privacy . For example, in order to protect the privacy of certain individuals depicted in visual media, such as on TV or in the press, their depiction will sometimes be blurred artificially to hide the individual’s identity. In this case, deblurring can pose the risk of unhiding the person’s identity, thus damaging his/her privacy. Furthermore, it is important to be cautious of the results of any deblurring system as failures could cause misjudgment. For example, the inaccurate restoration of numbers and letters can produce misleading information. Our proposed approach is robust to various noise levels and inaccurate kernels, which intuitively improves its adaptability to more complex scenes and thus minimizes the chance of such failures. Nevertheless, misjudgment based on incorrect restoration cannot be ruled out completely.",Broader Impact,258,11,,,FALSE,FALSE,FALSE,Deep Wiener Deconvolution: Wiener Meets Deep Learning for Image Deblurring,Applications -> Computer Vision,,Vision,"['Jiangxin Dong', ' Stefan Roth', ' Bernt Schiele']","{'TU Darmstadt', 'Max Planck Institute for Informatics'}",1,0,0,{'Germany'}
Discovering Reinforcement Learning Algorithms,"Junhyuk Oh, Matteo Hessel, Wojciech M. Czarnecki, Zhongwen Xu, Hado P. van Hasselt, Satinder Singh, David Silver",Discovering Reinforcement Learning Algorithms,0b96d81f0494fde5428c7aea243c9157,https://proceedings.neurips.cc/paper/2020/file/0b96d81f0494fde5428c7aea243c9157-Paper.pdf,"The proposed approach has a potential to dramatically accelerate the process of discovering new reinforcement learning (RL) algorithms by automating the process of discovery in a data-driven way. If the proposed research direction succeeds, this could shift the research paradigm from manually developing RL algorithms to building a proper set of environments so that the resulting algorithm is efficient. Additionally, the proposed approach may also serve as a tool to assist RL researchers in developing and improving their hand-designed algorithms. In this case, the proposed approach can be used to provide insights about what a good update rule looks like depending on the architecture that researchers provide as input, which could speed up the manual discovery of RL algorithms. On the other hand, due to the data-driven nature of the proposed approach, the resulting algorithm may capture unintended bias in the training set of environments. In our work, we do not provide domain-specific information except rewards when discovering an algorithm, which makes it hard for the algorithm to capture bias in training environments. However, more work is needed to remove bias in the discovered algorithm to prevent potential negative outcomes.",Broader Impact,190,7,,,FALSE,FALSE,FALSE,Discovering Reinforcement Learning Algorithms,Reinforcement Learning and Planning,Algorithms -> Meta-Learning,,"['Junhyuk Oh', ' Matteo Hessel', ' Wojciech Czarnecki', ' Zhongwen Xu', ' Hado van Hasselt', ' Satinder Singh', ' David Silver']","{'Google DeepMind', 'DeepMind'}",0,1,0,{'UK'}
Taming Discrete Integration via the Boon of Dimensionality,"Jeffrey Dudek, Dror Fried, Kuldeep S Meel",Taming Discrete Integration via the Boon of Dimensionality,0baf163c24ed14b515aaf57a9de5501c,https://proceedings.neurips.cc/paper/2020/file/0baf163c24ed14b515aaf57a9de5501c-Paper.pdf,"Discrete integration is a fundamental problem in machine learning and therefore, it is critical to develop algorithmic techniques that provide rigorous formal guarantees and can handle real-world instances. Our work in this paper takes a significant step, in our view, towards achieving this goal. Our work does not make use of bias in the data.",Broader Impact,55,3,FALSE,FALSE,FALSE,FALSE,FALSE,Taming Discrete Integration via the Boon of Dimensionality,Probabilistic Methods,,,"['Jeffrey Dudek', ' Dror Fried', ' Kuldeep S Meel']","{'The Open University of Israel', 'Rice University', 'National University of Singapore'}",1,0,0,"{'Singapore', 'USA', 'Israel'}"
Blind Video Temporal Consistency via Deep Video Prior,"Chenyang Lei, Yazhou Xing, Qifeng Chen",Blind Video Temporal Consistency via Deep Video Prior,0c0a7566915f4f24853fc4192689aa7e,https://proceedings.neurips.cc/paper/2020/file/0c0a7566915f4f24853fc4192689aa7e-Paper.pdf,"With our proposed framework, users can apply numerous existing image processing and enhancement algorithms to videos with strong temporal consistency. As a consequence, instead of paying extra efforts to solve the temporal inconsistency problem, researchers can spend more time utilizing video information for improving the performance. Moreover, the simplicity of our approach promotes the potential of wide deployment. Our proposed Deep Video Prior is an implicit characteristic of a CNN training on a video and can be used to replace a complicated handcrafted regularization term. We believe this observation can inspire researchers to utilize CNNs for video processing tasks better.",Broader Impact,100,5,,,FALSE,FALSE,FALSE,Blind Video Temporal Consistency via Deep Video Prior,Applications -> Computer Vision,Applications -> Computational Photography,Vision,,{'HKUST'},1,0,0,"{'Chile', 'China'}"
Simplify and Robustify Negative Sampling for Implicit Collaborative Filtering,"Jingtao Ding, Yuhan Quan, Quanming Yao, Yong Li, Depeng Jin",Simplify and Robustify Negative Sampling for Implicit Collaborative Filtering,0c7119e3a6a2209da6a5b90e5b5b75bd,https://proceedings.neurips.cc/paper/2020/file/0c7119e3a6a2209da6a5b90e5b5b75bd-Paper.pdf,"Motivated by general methodology of learning from noisy labels, this work proposes a novel negative sampling approach that aims to reliably measure the sample quality and handle false negatives correctly during sampling process. The potential risk of introducing false negatives has been overlooked by most existing negative sampling approaches in wide areas of embedding learning for text, graph, etc. This work provides a new direction for robustifying negative sampling in these areas (see details in Appendix A). Specifically, it focuses on the implicit collaborative filtering (CF) where false negatives can be a severe problem. After further combining with a simplified model design, the proposed approach achieves efficient sampling of true negative instances that are of high-quality, and can potentially benefit several downstream applications including recommender systems and user modeling.",Broader Impact,129,5,,,FALSE,FALSE,FALSE,Simplify and Robustify Negative Sampling for Implicit Collaborative Filtering,Algorithms -> Collaborative Filtering,Algorithms -> Ranking and Preference Learning; Applications -> Recommender Systems,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jingtao Ding', ' Yuhan Quan', ' Quanming Yao', ' Yong Li', ' Depeng Jin']","{'4paradigm', 'Tsinghua University'}",1,1,1,{'China'}
Model Selection for Production System via Automated Online Experiments,"Zhenwen Dai, Praveen Chandar, Ghazal Fazelnia, Benjamin Carterette, Mounia Lalmas",Model Selection for Production System via Automated Online Experiments,0c72cb7ee1512f800abe27823a792d03,https://proceedings.neurips.cc/paper/2020/file/0c72cb7ee1512f800abe27823a792d03-Paper.pdf,"In this paper, the authors present a new framework of model selection for production system (MSPS), in which the data collection from automated online experiments is used as part of the model selection procedure. In particular, we develop AOE, a MSPS method that iteratively select models to be deployed online and identify the model with the highest metric of interest from a large pool of candidate models in a few number of online deployments. AOE could be applied to improve the quality of the model selection process for industrial ML service development. This type of methods could be implemented either as a part of the in-house development toolset of individual companies or as a component of automated ML service on cloud platforms. The adoption of such tooling could increase the development speed of industrial ML applications and provide better understanding and control of the release of new features and improvement before large scale deployment. With a more accurate prediction of the online metric of a system improvement, ML developers can better identify the impactful system improvements and focus the development effort on them. It also can let the development team and a wider part of a company have a clear picture of the potential impact and limitation of a project before the development has finished. The automated ML model selection, update, deployment tools including AOE tend to focus on a single metric for mathematical convenience, but the social impact of a ML system such as diversity, fairness is hard to summarize into a single metric. The adoption of such tooling without careful consideration can result into overly optimize for the single metric and being blind about broad social impacts, which can potentially lead to undesirable outcomes. The research about understanding and constraining automated algorithm decisions with respect to its wider impact, e.g. , safe reinforcement learning, is very important and could mitigate the risk of causing harmful consequences.",Broader Impact,318,10,,,FALSE,FALSE,FALSE,Model Selection for Production System via Automated Online Experiments,Probabilistic Methods -> Gaussian Processes,Algorithms -> AutoML,AutoML,"['Zhenwen Dai', ' Praveen Chandar', ' Ghazal Fazelnia', ' Benjamin Carterette', ' Mounia Lalmas']",{'Spotify'},0,1,0,{'Sweden'}
On the Almost Sure Convergence of Stochastic Gradient Descent in Non-Convex Problems,"Panayotis Mertikopoulos, Nadav Hallak, Ali Kavis, Volkan Cevher",On the Almost Sure Convergence of Stochastic Gradient Descent in Non-Convex Problems,0cb5ebb1b34ec343dfe135db691e4a85,https://proceedings.neurips.cc/paper/2020/file/0cb5ebb1b34ec343dfe135db691e4a85-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,On the Almost Sure Convergence of Stochastic Gradient Descent in Non-Convex Problems,Optimization -> Non-Convex Optimization,Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Panayotis Mertikopoulos', 'CNRS', ' Nadav Hallak', ' Ali Kavis', ' Volkan Cevher']","{'French National Center for Scientific Research', 'EPFL'}",1,0,0,"{'France', 'Switzerland'}"
Automatic Perturbation Analysis for Scalable Certified Robustness and Beyond,"Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie Huang, Bhavya Kailkhura, Xue Lin, Cho-Jui Hsieh",Automatic Perturbation Analysis for Scalable Certified Robustness and Beyond,0cbc5671ae26f67871cb914d81ef8fc1,https://proceedings.neurips.cc/paper/2020/file/0cbc5671ae26f67871cb914d81ef8fc1-Paper.pdf,"In this paper, we develop an automatic framework to enable perturbation analysis on any neural network structures. Our framework can be used in a wide variety of tasks ranging from robustness verification to certified defense, and potentially many more applications requiring a provable perturbation analysis. It can also play an important building block for several safety-critical ML applications, such as transportation, engineering, and healthcare, etc. We expect that our framework will significantly improve the robustness and reliability of real-world ML systems with theoretical guarantees. An important product of this paper is an open-source LiRPA library with over 10,000 lines of code, which provides automatic and differentiable perturbation analysis. This library can tremendously facilitate the use of LiRPA for the research community as well as industrial applications, such as verifiable plant control [50]. Our library of LiRPA on general computational graphs can also inspire further improved implementations on automatic outer bounds calculations with provable guarantees. Although our focus on this paper has been on exploring known perturbations and providing guarantees in such clairvoyant scenarios, in real-world an adversary (or nature) may not adhere to our assumptions. Thus, we may additionally want to understand implication of these unknown scenarios on the system performance. This is a relatively unexplored area in robust machine learning, and we encourage researchers to understand and mitigate the risks arising from unknown perturbations in these contexts.",Broader Impact,228,10,,,FALSE,FALSE,FALSE,Automatic Perturbation Analysis for Scalable Certified Robustness and Beyond,Social Aspects of Machine Learning -> AI Safety,"Algorithms -> Adversarial Learning; Data, Challenges, Implementations, and Software -> Software Toolkits",Deep learning,"['Kaidi Xu', ' Zhouxing Shi', ' Huan Zhang', ' Yihan Wang', 'Wei Chang', ' Minlie Huang', ' Bhavya Kailkhura', ' Xue Lin', 'Jui Hsieh']","{'Tsinghua University', 'UCLA', 'Lawrence Livermore National Lab', 'JD.com', 'Northeastern University'}",1,1,1,"{'USA', 'China'}"
Adaptation Properties Allow Identification of Optimized Neural Codes,"Luke Rast, Jan Drugowitsch",Adaptation Properties Allow Identification of Optimized Neural Codes,0cc24cb7c26586310cc95c8cb1a81cbc,https://proceedings.neurips.cc/paper/2020/file/0cc24cb7c26586310cc95c8cb1a81cbc-Paper.pdf,"This work builds toward improved understanding of the neural code, and thus, a better understanding of operation of the nervous systems and the behavior of humans and other animals. Such understanding is important for neural prostheses and may lead to novel treatment options of human brain diseases. One potential risk is that a better understanding of neural coding, particularly value coding, lends itself to abuse for human behavioral modification. This is not an immediate concern for the work presented here.",Statement of Broader Impact,80,4,,,FALSE,FALSE,FALSE,Adaptation Properties Allow Identification of Optimized Neural Codes,Neuroscience and Cognitive Science -> Neural Coding,Neuroscience and Cognitive Science -> Plasticity and Adaptation,Neuroscience and cognitive science,,"{'Harvard University', 'University of Geneva'}",1,0,0,"{'USA', 'Switzerland'}"
Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems,"Junchi Yang, Negar Kiyavash, Niao He",Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems,0cc6928e741d75e7a92396317522069e,https://proceedings.neurips.cc/paper/2020/file/0cc6928e741d75e7a92396317522069e-Paper.pdf,"With the boom of neural networks in every corner of machine learning, the understanding of nonconvex optimization, especially minimax optimization, becomes increasingly important. On one hand, the surge of interest in generative adversarial networks (GAN) has brought revolutionary success in many practical applications such as face synthesis , text-to-image synthesis, text generation. On the other hand, even for the simplest algorithm such as gradient descent ascent (GDA), although widely adopted by practitioners and researchers in the filed, lack theoretical understanding. It is imperative to develop a strong fundamental understanding of the success of these simple algorithms in the nonconvex regime, both to expand the usability of the methods and to accelerate future deployment in a principled and interpretable manner.  Theory. This paper takes an initial and substantial step towards the understanding of nonconvex- nonconcave min-max optimization problems with ""hidden convexity"" as well as the convergence of the simplest alternating GDA algorithm. Despite its popularity, this algorithm has not been carefully analyzed even in the convex regime. The theory developed in this work helps explain when and why GDA performs well, how to choose stepsizes, and how to improve GDA properly. These are obviously basic yet important questions that need to be addressed in order to guide future development. Applications. The downstream applications include but not limited to generative adversarial networks, the actor-critic game in reinforcement learning, robust machine learning and control, and other applications in games and social economics. This work could potentially inspire more interest in broadening the applicability of GDA in practice.",Broader Impact,254,12,,,FALSE,TRUE,FALSE,Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems,Optimization -> Non-Convex Optimization,Optimization,Optimization Methods (continuous or discrete),"['Junchi Yang', ' Negar Kiyavash', ' Niao He']","{'University of Illinois', 'UIUC', 'École Polytechnique Fédérale de Lausanne'}",1,0,0,"{'USA', 'Switzerland'}"
Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity,"Kaiqing Zhang, Sham Kakade, Tamer Basar, Lin Yang",Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity,0cc6ee01c82fc49c28706e0918f57e2d,https://proceedings.neurips.cc/paper/2020/file/0cc6ee01c82fc49c28706e0918f57e2d-Paper.pdf,"We believe that researchers of multi-agent reinforcement learning (MARL), especially those who are interested in the theoretical foundations of MARL, would benefit from this work. In particular, prior to this work, though intuitive and widely-used, the sample efficiency, specifically the minimax optimality of the sample complexity, of this model-based approach had not been established for MARL. This work justified the efficiency of this simple method for the first time in the MARL setting. We have also raised several important open questions on the sample complexity of MARL in zero-sum Markov games in general, which open up some future research directions toward rigorous theoretical understandings of MARL. In contrast to the rich literature on the theory of model-free MARL algorithms, the theory of model-based ones is relatively lacking. Our results have advocated the use of model-based MARL due to its sample efficiency, which would benefit MARL practitioners when choosing between the two types of algorithms in practice. As a theory-oriented work, we do not believe that our research will cause any ethical issue, or put anyone at any disadvantage.",Broader Impact,178,7,,,FALSE,FALSE,FALSE,Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning -> Model-Based RL; Theory -> Game Theory and Computational Economics; Theory -> Statistical Learning Theory,Reinforcement learning and planning,"['Kaiqing Zhang', 'Champaign', ' Sham Kakade', ' Tamer Basar', ' Lin Yang']","{'UCLA', 'University of Illinois at Urbana-Champaign', 'UIUC', 'University of Washington'}",1,0,0,{'USA'}
Conservative Q-Learning for Offline Reinforcement Learning,"Aviral Kumar, Aurick Zhou, George Tucker, Sergey Levine",Conservative Q-Learning for Offline Reinforcement Learning,0d2b2061826a5df3221116a5085a6052,https://proceedings.neurips.cc/paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf,"Offline RL offers the promise to scale autonomous learning-based methods for decision-making to large-scale, real-world sequential decision making problems. Such methods can effectively leverage prior datasets without any further interaction, thus avoiding the exploration bottleneck and alleviating many of the safety and cost constraints associated with online reinforcement learning. In this work, we proposed conservative Q-learning (CQL), an algorithmic framework for offline reinforcement learning that learns a Q-function such that the expected policy value under this learned Q-function lower-bounds the actual policy value. This mitigates value function over-estimation issues due to distributional shift, which in practice are one of the major challenges in offline reinforcement learning. We analyzed algorithms derived from the CQL framework and demonstrated their performance empirically. Our primary aim behind this work is to develop simple and effective offline RL algorithms, and we believe that CQL makes an important step in that direction. CQL can be applied directly to several problems of practical interest where large-scale datasets are abundant: autonomous driving, robotics, and software systems (such as recommender systems). We believe that a strong offline RL algorithm, coupled with highly expressive and powerful deep neural networks, will provide us the ability successfully apply end-to-end learning based approaches to such problems, providing considerable societal benefits. Of course, autonomous decision-making agents have a wide range of applications, and technology that enables more effective autonomous decision-making has both positive and negative societal effects. While effective autonomous decision-making can have considerable positive economic effects, it can also enable applications with complex implications in regard to privacy (e.g., in regard to autonomous agents on the web, recommendation agents, advertising, etc.), as well as complex economic effects due to changing economic conditions (e.g., changing job requirements, loss of jobs in some sectors and growth in others, etc.). Such implications apply broadly to technologies that enable automation and decision making, and are largely not unique to this specific work.",Broader Impact,315,12,,,FALSE,FALSE,FALSE,Conservative Q-Learning for Offline Reinforcement Learning,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Aviral Kumar', ' Aurick Zhou', ' George Tucker', ' Sergey Levine']","{'UC Berkeley', 'University of California, Berkeley', 'Google Brain'}",1,1,1,{'USA'}
Online Influence Maximization under Linear Threshold Model,"Shuai Li, Fang Kong, Kejie Tang, Qizhi Li, Wei Chen",Online Influence Maximization under Linear Threshold Model,0d352b4d3a317e3eae221199fdb49651,https://proceedings.neurips.cc/paper/2020/file/0d352b4d3a317e3eae221199fdb49651-Paper.pdf,"Spread happens everywhere, no matter when a company wants to advertise their products, a group wants to seek attention, or even virus like COVID-19 walks between places. The modelling of a spread is always based on a directed graph and uses some diffusion assumptions. The linear threshold (LT) model, considered in our paper, is one of the most popular models. The influence maximization is the problem to pursue the widest spread, while the online version is to adaptively achieve this goal through an interactive manner with no knowledge of the parameters. Compared with application research, theoretical analysis will provide analysis and guarantees for the designed algorithms. The theoretical work usually include extreme cases to make sure the algorithm does have a good property, while in application research the possible experiments are always limited and usually do not reflect corner cases. The latter might be an issue if we want to transfer the model to some unseen scenes, e.g. automatic drive. Also among our derivations, we reveal a class of optimization problems (i.e. WCIM), which we expect to happen a lot if the community wants to solve some (offline) problem without the knowledge of the parameters using an online manner. This class, as a theoretical problem, is highly non-trivial and can introduce new problems to the optimization area. The hardness of this arising problem also reflects the difficulty of transforming offline or heuristic solutions to online or automatic ones, like the AutoML direction and the topics of automatically adjusting hyper-parameters.",Broader Impact,249,10,,,FALSE,FALSE,FALSE,Online Influence Maximization under Linear Threshold Model,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning,bandits/online learning,"['Shuai Li', ' Fang Kong', ' Kejie Tang', ' Qizhi Li', ' Wei Chen']","{'Xidian University', 'Microsoft Research', 'Shanghai Jiao Tong University'}",1,1,1,"{'USA', 'China'}"
Ensembling geophysical models with Bayesian Neural Networks,"Ushnish Sengupta, Matt Amos, Scott Hosking, Carl Edward Rasmussen, Matthew Juniper, Paul Young",Ensembling geophysical models with Bayesian Neural Networks,0d5501edb21a59a43435efa67f200828,https://proceedings.neurips.cc/paper/2020/file/0d5501edb21a59a43435efa67f200828-Paper.pdf,"We created an ensembling technique which takes into account the limitations of observations and models. This method is applicable to many geophysical models (e.g. hydrological, regional climate and chemistry-climate models) though nuances in each field and model ensemble mean the BayNNE should not be blindly used. Positive impacts include more accurate and better constrained predictions from model ensembles. This could shift the standard of how model ensembling is performed, leading to this method (or derivatives) influencing scientific understanding and downstream policy decisions. The greater understanding offered by combing models and observations in this way, has the potential to open up sparse historic observational records, through fusion with geophysical models. This would, for example, allow for greater understanding of historic climate states. The response to climate change is influenced by predictions formed from models ensembles, and though accurate and appropriately certain ensembling could result in more definitive and correctly concentrated mitigation efforts, highly certain but wrong predictions could lead to an incorrect pooling of resources and result in negative socio-economic impacts. For these reasons we must be mindful about dangers of extrapolating and unknown errors in observational datasets which incorrectly bias results.",Broader Impact,191,8,,,FALSE,FALSE,FALSE,Ensembling geophysical models with Bayesian Neural Networks,Probabilistic Methods,"Algorithms; Algorithms -> Boosting and Ensemble Methods; Algorithms -> Regression; Algorithms -> Uncertainty Estimation; Applications; Applications -> Sustainability; Applications -> Time Series Analysis; Data, Challenges, Implementations, and Software; Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories; Deep Learning; Deep Learning -> Supervised Deep Networks; Probabilistic Methods -> Distributed Inference","Other applications (e.g., robotics, biology, climate, finance)","['Ushnish Sengupta', ' Matt Amos', ' Scott Hosking', ' Carl Edward Rasmussen', ' Matthew Juniper', ' Paul Young']","{'University of Cambridge', 'Lancaster University', 'British Antarctic Survey'}",1,0,0,{'UK'}
Delving into the Cyclic Mechanism in Semi-supervised Video Object Segmentation,"Yuxi Li, Ning Xu, Jinlong Peng, John See, Weiyao Lin",Delving into the Cyclic Mechanism in Semi-supervised Video Object Segmentation,0d5bd023a3ee11c7abca5b42a93c4866,https://proceedings.neurips.cc/paper/2020/file/0d5bd023a3ee11c7abca5b42a93c4866-Paper.pdf,"As we can foresee, with the development of 5G communication, video-based media industry will develop fast in the future. The advancement of accurate and fast semi-supervised segmentation will be helpful in modern video editing software and provide real-time online segmentation solution to stream media in video live applications. Consequently the online user experience can be improved. However, there also exists the risk that video segmentation technology is utilized in the scenario of illegal shoot and malicious edit, thus the personal privacy are more likely to be exposed and tracked.",Broader Impact,89,4,,,FALSE,FALSE,FALSE,Delving into the Cyclic Mechanism in Semi-supervised Video Object Segmentation,Applications -> Computer Vision,Applications -> Video Analysis,Vision,"['Yuxi Li', ' Jinlong Peng', ' Ning Xu', ' John See', ' Weiyao Lin']","{'Multimedia University', 'Shanghai Jiao Tong university', 'Adobe Research', 'Tencent Youtu Lab', 'Shanghai Jiao Tong University'}",1,1,1,"{'Malaysia', 'USA', 'China'}"
Asymmetric Shapley values: incorporating causal knowledge into model-agnostic explainability,"Christopher Frye, Colin Rowat, Ilya Feige",Asymmetric Shapley values: incorporating causal knowledge into model-agnostic explainability,0d770c496aa3da6d2c3f2bd19e7b9d6b,https://proceedings.neurips.cc/paper/2020/file/0d770c496aa3da6d2c3f2bd19e7b9d6b-Paper.pdf,"Asymmetric Shapley values provide a method for incorporating causal knowledge into model-agnostic explainability. Like any model-agnostic method, ASVs can be applied to a wide variety of machine learning models, thus creating the potential for broad impact. Increased transparency in algorithmic decision-making enables practitioners to avoid failure modes and build safer models. ASVs in particular allow users to investigate nuanced causal notions of unfairness in models (as in Sec. 4.2) that other explainability methods cannot detect. In this sense, one of the primary applications of ASVs is aimed at preventing malignant societal effects of automated decisions. Progress in explainability could also conceivably lead to a set of negative outcomes, broadly resulting from blind trust being placed in model explanations. To avoid this, regulatory bodies should not approve consequential decision-making algorithms just because a model explanation has been provided. Furthermore, model explainability should not be considered a replacement for the domain expertise of model developers. For ASVs in particular, users should be careful only to incorporate causal information after verification by a domain expert, as the use of incorrect causal relationships would negate the benefits of our approach to explainability. We do not view this as a flaw of the framework, but instead as inherent to its flexibility. ASVs grant practitioners the freedom to incorporate any amount of causal information; this necessarily entails a responsibility to do so correctly.",Broader impact,227,12,,,FALSE,FALSE,FALSE,Asymmetric Shapley values: incorporating causal knowledge into model-agnostic explainability,"Deep Learning -> Visualization, Interpretability, and Explainability","Social Aspects of Machine Learning -> AI Safety; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Christopher Frye', ' Colin Rowat', ' Ilya Feige']","{'University of Birmingham', 'Faculty'}",1,0,0,{'UK'}
Understanding Deep Architecture with Reasoning Layer,"Xinshi Chen, Yufei Zhang, Christoph Reisinger, Le Song",Understanding Deep Architectures with Reasoning Layer,0d82627e10660af39ea7eb69c3568955,https://proceedings.neurips.cc/paper/2020/file/0d82627e10660af39ea7eb69c3568955-Paper.pdf,"A common ethical concern of deep learning models is that they may not perform well on unseen examples, which could lead to the risk of producing biased content reflective of the training data. Our work, which learns an energy optimization model from the data, is not an exception. The approach we adopt to address this issue is to design hybrid deep architectures containing specialized reasoning modules. In the setting of quadratic energy functions, our theoretical analysis and numerical experiments show that hybrid deep models produce more reliable results than generic deep models on unseen data sets. More work is needed to determine the extent to which such hybrid model prevents biased outputs in more sophisticated tasks",Broader Impact,116,5,FALSE,FALSE,FALSE,TRUE,FALSE,Understanding Deep Architecture with Reasoning Layer,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Representation Learning; Algorithms -> Structured Prediction; Optimization -> Convex Optimization; Theory -> Data-driven Algorithm Design; Theory -> Models of Learning and Generalization,Deep learning,"['Xinshi Chen', ' Yufei Zhang', ' Christoph Reisinger', ' Le Song']","{'Georgia Institute of Technology', 'Georgia Institution of Technology', 'University of Oxford'}",1,0,0,"{'UK', 'USA'}"
Planning in Markov Decision Processes with Gap-Dependent Sample Complexity,"Anders Jonsson, Emilie Kaufmann, Pierre Menard, Omar Darwiche Domingues, Edouard Leurent, Michal Valko",Planning in Markov Decision Processes with Gap-Dependent Sample Complexity,0d85eb24e2add96ff1a7021f83c1abc9,https://proceedings.neurips.cc/paper/2020/file/0d85eb24e2add96ff1a7021f83c1abc9-Paper.pdf,"Monte-Carlo Tree Search methods are very popular but their theoretical understanding remains limited. This work propose new sample complexity bounds for an efficient MCTS algorithm, which can be interesting for both theoreticians and practioners. However, this paper was not targeted towards a particular application, so a wider broader impact discussion is not applicable.",Broader Impact,53,3,TRUE,TRUE,FALSE,FALSE,FALSE,Planning in Markov Decision Processes with Gap-Dependent Sample Complexity,Reinforcement Learning and Planning -> Planning,Algorithms -> Bandit Algorithms; Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Anders Jonsson', ' Emilie Kaufmann', ' Pierre Menard', ' Omar Darwiche Domingues', ' Edouard Leurent', ' Michal Valko']","{'INRIA', 'DeepMind', 'CNRS', 'Universitat Pompeu Fabra', 'Inria'}",1,1,1,"{'France', 'UK', 'Spain'}"
Provably Good Batch Off-Policy Reinforcement Learning Without Great Exploration,"Yao Liu, Adith Swaminathan, Alekh Agarwal, Emma Brunskill",Provably Good Batch Reinforcement Learning Without Great Exploration,0dc23b6a0e4abc39904388dd3ffadcd1,https://proceedings.neurips.cc/paper/2020/file/0dc23b6a0e4abc39904388dd3ffadcd1-Paper.pdf,"Our improvements to batch RL may improve sample efficiency of online RL and safety of off- policy RL enough to consider them in some real-world applications. However we caution that more work is needed (e.g., in closely related areas of off-policy evaluation OPE, confidence estimation, interpretability etc.) before these methods can be reliably deployed in practice. We anticipate future work in batch RL and OPE that addresses these shortcomings.",9 Broader Impact,69,4,,,FALSE,FALSE,FALSE,Provably Good Batch Reinforcement Learning Without Great Exploration,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Yao Liu', ' Adith Swaminathan', ' Alekh Agarwal', ' Emma Brunskill']","{'Stanford University', 'Microsoft Research'}",1,1,1,{'USA'}
Detection as Regression: Certified Object Detection with Median Smoothing,"Ping-yeh Chiang, Michael Curry, Ahmed Abdelkader, Aounon Kumar, John Dickerson, Tom Goldstein",Detection as Regression: Certified Object Detection by Median Smoothing,0dd1bc593a91620daecf7723d2235624,https://proceedings.neurips.cc/paper/2020/file/0dd1bc593a91620daecf7723d2235624-Paper.pdf,"Neural networks are very powerful tools, and society will benefit greatly if they can be used in a broader range of safety critical applications. In particular, object detectors can be used in many systems that must visually perceive and interact with the real world – perhaps most strikingly, in autonomous vehicles. Ensuring the safety and predictability of neural networks is critical in enabling the application of neural networks in these areas, and certificates associated with safety with respect to a particular model are very useful in providing assurance that the neural network cannot be exploited by malicious actors. At the same time, there is real concern about the privacy impact of widespread deployment of modern computer vision systems, including systems like object detectors and face recognition systems that produce bounding boxes. If individuals wish to use physical or digital adversarial examples to protect their privacy, the techniques we present might make it more difficult for them to do so, although it is not actually clear that adversarial examples will ultimately prove effective or useful for protecting privacy. In any case, we are not aware of any real-world adversarial attacks being performed “in the wild”, for good or ill. We believe the concrete positive impact on safety is probably greater than a hypothetical negative impact on privacy.",Broader Impact,216,6,,,FALSE,FALSE,FALSE,Detection as Regression: Certified Object Detection with Median Smoothing,Algorithms -> Adversarial Learning,Applications -> Object Detection,Deep learning,"['yeh Chiang', ' Michael Curry', ' Ahmed Abdelkader', ' Aounon Kumar', ' John Dickerson', ' Tom Goldstein']","{'University of Maryland, College Park', 'University of Maryland College Park', 'University of Maryland'}",1,0,0,{'USA'}
Contextual Reserve Price Optimization in Auctions via Mixed Integer Programming,"Joey Huchette, Haihao Lu, Hossein Esfandiari, Vahab Mirrokni",Contextual Reserve Price Optimization in Auctions via Mixed-Integer Programming,0e1bacf07b14673fcdb553da51b999a5,https://proceedings.neurips.cc/paper/2020/file/0e1bacf07b14673fcdb553da51b999a5-Paper.pdf,"This work presents new methods, and as such does not have direct societal impact. However, if the context provided allows the model to reason about protected classes or sensitive information, either directly or indirectly, the model–and, therefore, the application of this work–has the potential for adverse effects.",Broader Impact,47,2,TRUE,TRUE,FALSE,FALSE,FALSE,Contextual Reserve Price Optimization in Auctions via Mixed Integer Programming,Optimization -> Discrete Optimization,,"Other applications (e.g., robotics, biology, climate, finance)","['Joey Huchette', ' Haihao Lu', ' Hossein Esfandiari', ' Vahab Mirrokni']","{'University of Chicago', 'Google Research', 'Rice University', 'Google Research NYC'}",1,1,1,{'USA'}
ExpandNets: Linear Over-parameterization to Train Compact Convolutional Networks,"Shuxuan Guo, Jose M. Alvarez, Mathieu Salzmann",ExpandNets: Linear Over-parameterization to Train Compact Convolutional Networks,0e1ebad68af7f0ae4830b7ac92bc3c6f,https://proceedings.neurips.cc/paper/2020/file/0e1ebad68af7f0ae4830b7ac92bc3c6f-Paper.pdf,"Our work introduces a general approach to improve the performance of a given compact convolutional neural network. It builds on the theoretical research on over-parameterization, but provides practical and effective ways to facilitate the training of convolutional layers, with extensive experiments and empirical analysis of our expansion strategies and of their impact on training behavior and generalization ability. Currently, our results on AlexNet in the supplementary material seem to indicate that expansion is not as effective on large networks than it is on compact ones. We nonetheless expect that our work will motivate other researchers to study solutions for this scenario. Our approach is general, and thus applicable to a broad range of problems, including those demonstrated in our experiments, i.e., image classification, object detection and semantic segmentation, but not limited to them. In particular, because we focus on compact network, our work could have a significant impact for applications in resource-constrained environments, such as mobile phones, drones, or autonomous navigation. As a matter of fact, we are actively working on deploying our approach for perception-based autonomous driving. We acknowledge that such applications present security risks, e.g., related to adversarial attacks. We nonetheless expect these risks to be mitigated by the parallel research advances in adversarial robustness. Finally, from an ecological standpoint, our approach requires more training resources than the compact network, thus increasing its carbon footprint. Note, however, that this is mitigated by the fact that, at training time, we observed our expanded networks to make better use of the GPU resources than the compact ones.",Broader Impact,257,11,,,FALSE,FALSE,FALSE,ExpandNets: Linear Over-parameterization to Train Compact Convolutional Networks,Deep Learning -> CNN Architectures,Deep Learning -> Efficient Inference Methods,Deep learning,"['Shuxuan Guo', ' Alvarez', ' Mathieu Salzmann']","{'NVIDIA', 'EPFL'}",1,1,1,"{'USA', 'Switzerland'}"
FleXOR: Trainable Fractional Quantization,"Dongsoo Lee, Se Jung Kwon, Byeongwook Kim, Yongkweon Jeon, Baeseong Park, Jeongin Yun",FleXOR: Trainable Fractional Quantization,0e230b1a582d76526b7ad7fc62ae937d,https://proceedings.neurips.cc/paper/2020/file/0e230b1a582d76526b7ad7fc62ae937d-Paper.pdf,"Due to rapid advances in developing neural networks of higher model accuracy and increasingly complicated tasks to be supported, the size of DNNs is becoming exponentially larger. Our work facilitates the deployment of large DNN applications in various forms including mobile devices because of the powerful model compression ratio. As for positive perspectives, hence, a huge amount of energy consumption to run model inferences can be saved by our proposed quantization and encryption techniques. Also, a lot of computing systems that are based on binary neural network forms can improve model accuracy. We expect that lots of useful DNN models would be available for devices of low cost. On the other hand, some common concerns on DNNs such as privacy breaching and heavy surveillance can be worsened by DNN devices that are more available economically by using our proposed techniques.",Broader Impact,140,6,,,FALSE,FALSE,FALSE,FleXOR: Trainable Fractional Quantization,Deep Learning -> CNN Architectures,Deep Learning -> Efficient Inference Methods,Resource aware machine learning,"['Dongsoo Lee', ' Se Jung Kwon', ' Byeongwook Kim', ' Yongkweon Jeon', ' Baeseong Park', ' Jeongin Yun']","{'Samsung Research', 'samsung research'}",0,1,0,{'South Korea'}
The Implications of Local Correlation on Learning Some Deep Functions,"Eran Malach, Shai Shalev-Shwartz",The Implications of Local Correlation on Learning Some Deep Functions,0e4ceef65add6cf21c0f3f9da53b71c0,https://proceedings.neurips.cc/paper/2020/file/0e4ceef65add6cf21c0f3f9da53b71c0-Paper.pdf,"The revolution of Deep Learning has allowed unprecedented progress in almost any field of Arti- ficial Intelligence. However, this progress is mainly guided by empirical experiments, where im- provements are typically achieved by trial-and-error. This is due to the fact that current learning theory is not applicable to practical settings: negative theoretical results take a worst-case analysis, which is irrelevant to practical problems, while positive results analyze very simplistic cases. The goal of this paper is to identify what are the correct distributional assumptions that are required for constructing theoretical results that are relevant to natural problems. We suggested the local correlation assumption (LCA), an assumption that is likely to hold on natural data, and allows us to prove some non-trivial theoretical results. We showed that on the task of learning tree-structured Boolean circuits, the existence of local correlations between the gates and the target label allows layerwise gradient-descent to learn the target circuit. We believe this work can help the research community to come up with a theory of deep networks that is applicable in practice, and encourage theory-guided progress in solving real-world problems.",Broader Impact,185,7,FALSE,FALSE,FALSE,FALSE,FALSE,The Implications of Local Correlation on Learning Some Deep Functions,Theory -> Computational Learning Theory,Deep Learning -> Analysis and Understanding of Deep Networks; Theory -> Statistical Learning Theory,,"['Eran Malach', 'Shwartz']",{'Hebrew University Jerusalem Israel'},1,0,0,{'Israel'}
Learning to search efficiently for causally near-optimal treatments,"Samuel Håkansson, Viktor Lindblom, Omer Gottesman, Fredrik D. Johansson",Learning to search efficiently for causally near-optimal treatments,0e900ad84f63618452210ab8baae0218,https://proceedings.neurips.cc/paper/2020/file/0e900ad84f63618452210ab8baae0218-Paper.pdf,"Personalized and partially automated selection of medical treatments is a long-standing goal for machine learning and statistics with the potential to improve the lives of patients and reduce the workload on physicians. This task is not without risk however, as poor decisions may fail to reduce or even increase suffering. It is important that implementations of such ideas is guided by strong domain knowledge, thorough evaluation and that checks and balances are in place. Many previous works in this field aim to identify new policies for treatment or doses with the goal of improving treatment response itself. This goal is not always feasible to achieve—some conditions are fundamentally hard to treat with available medications and procedures. In contrast, we focus on conditions where a good enough treatment would be identified by an existing policy given enough time, with the goal of reducing this search time as much as possible. The trade-off between a good outcome and time is made transparent using a model of patient outcomes and a certainty parameter. With this, we hope to contribute towards making machine learning methods more suitable for clinical implementation.",Broader Impact,186,8,,,FALSE,FALSE,FALSE,Learning to search efficiently for causally near-optimal treatments,Probabilistic Methods -> Causal Inference,Applications -> Health,Causality,"['Samuel Håkansson', ' Viktor Lindblom', ' Omer Gottesman', ' Fredrik Johansson']","{'Harvard University', 'Chalmers University of Technology'}",1,0,0,"{'Sweden', 'USA'}"
A Game Theoretic Analysis of Additive Adversarial Attacks and Defenses,"Ambar Pal, Rene Vidal",A Game Theoretic Analysis of Additive Adversarial Attacks and Defenses,0ea6f098a59fcf2462afc50d130ff034,https://proceedings.neurips.cc/paper/2020/file/0ea6f098a59fcf2462afc50d130ff034-Paper.pdf,"At a high level, this work aims to provide a way to characterize adversarial attacks and defenses that might be best for each other, in a game theoretic sense where the attacker cannot decrease the robust accuracy further when the defense is fixed, and the defender cannot increase the robust accuracy further when the attack is fixed. The technical contributions are novel geometry-flavored proof techniques that can be used to analyze provable attacks and defenses, and a game-theoretic framework to study such equilibria. Machine learning systems are increasingly being used in security-critical applications, like healthcare and automated driving: our work can be used to find guarantees on the worst accuracy a defended classifier can have under any attack. This is a step towards safe machine learning, where the ultimate goal is to be able to construct classifiers whose performance cannot be degraded by an adversary on most data-points with high probability.",Broader Impact,151,4,,,FALSE,FALSE,FALSE,A Game Theoretic Analysis of Additive Adversarial Attacks and Defenses,Algorithms -> Adversarial Learning,Algorithms -> Classification; Theory -> Game Theory and Computational Economics,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Ambar Pal', ' Rene Vidal']","{'Johns Hopkins University, USA', 'Johns Hopkins University'}",1,0,0,{'USA'}
Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts,"Bertrand Charpentier, Daniel Zügner, Stephan Günnemann",Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts,0eac690d7059a8de4b48e90f14510391,https://proceedings.neurips.cc/paper/2020/file/0eac690d7059a8de4b48e90f14510391-Paper.pdf,"Traditional classification models without uncertainty estimate can be dangerous when used without domain expertise. They might have indeed unexpected behavior in new anomalous situations/input and are unaware of the underlying risk of their predictions. Uncertainty aware models like PostNet try to mitigate the risk of such autonomous predictions by attaching a confidence score to their predictions. On one hand, uncertainty aware predictions could be particularly beneficial in domains with potential critical consequences and prone to automation (e.g. finance, autonomous driving or medicine). When applied, these models are able to refrain from predicting if the data is out of their domain of expertise. Posterior Network makes a significant step further in this direction by even not requiring to observe similar anomalous situations during training. Anomalous data are typically not known in advance since they are rare by definition. Thus Posterior Network significantly increases the applicability of uncertainty estimation across application domains. On the other hand, high-quality of uncertainty estimation might also give a false sense of security. A potential risk is that an excessive trust in the model behavior leads to a lack of human supervision. For example in medicine, predictions wrongly deemed safe could have dramatic repercussions without human control.",Broader Impact,200,11,,,FALSE,FALSE,FALSE,Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts,Algorithms -> Uncertainty Estimation,Algorithms -> Classification,Uncertainty estimation,"['Bertrand Charpentier', ' Daniel Zügner', ' Stephan Günnemann']",{'Technical University of Munich'},1,0,0,{'Germany'}
Recurrent Quantum Neural Networks,Johannes Bausch,Recurrent Quantum Neural Networks,0ec96be397dd6d3cf2fecb4a2d627c1c,https://proceedings.neurips.cc/paper/2020/file/0ec96be397dd6d3cf2fecb4a2d627c1c-Paper.pdf,"Without doubt, existing recurrent models—even simple RNNs—outclass the proposed QRNN archi- tecture in this paper in real-world learning tasks. In part, this is because we cannot easily simulate a large number of qubits on classical hardware: the memory requirements necessarily grow expo- nentially in the size of the workspace, for instance, which limits the number of parameters we can introduce in our model—on a quantum computer this overhead would vanish, resulting in a linear execution time in the circuit depth. What should nevertheless come as a surprise is that the model does perform relatively well on non- trivial tasks such as the ones presented here, in particular given the small number of qubits (usually between 8 and 12) that we utilised. As qubit counts in real-world devices are severely limited—and likely will be for the foreseeable future—learning algorithms with tame system requirements will certainly hold an advantage. Moreover, while we motivate the topology of the presented QRNN cell given in fig. 3 by the action of its different stages (writing the input; work; writing the output), and while the resulting circuits are far more structured than existing VQE setups, our architecture is still simplistic as compared to the various components of an RNN, let alone an LSTM. In all likelihood, a more specialized circuit structure (such as going from an RNN to an LSTM) will outperform the “simple” quantum recurrent network presented herein. Beyond the exploratory aspect of our work, our main insights are twofold. On the classical side—as discussed in the introduction—we present an architecture which can run on current hardware and ML implementations such as pytorch; and which is a candidate parametrization for unitary recurrent models that hold promise in circumventing gradient degradation for very long sequence lengths. On the quantum side, we significantly advance the field of variational circuits for quantum machine learning tasks; allowing ingestion of data of more than a few bits of size; demonstrate that models with large parameter counts can indeed be evaluated and trained; and that classical baselines such as MNIST classification are, indeed, within reach when using a more sophisticated model. Finally, our work is the first recurrent and entirely quantum neural network presented to date. Vari- ants of it might find application in conjunction with other quantum machine learning algorithms, such as quantum beam search [BSP19] in the context of language modelling. With a more near-term focus in mind, modelling the evolution of quantum systems with noisy dynamics is a task currently addressed using classical recurrent models [Flu+20]. Due to the intrinsic capability of a QRNN to keep track of a quantum state it holds promise to better capture the exponentially-growing phase space dimension of the system to be modelled.",6 Broader Impact,450,14,FALSE,FALSE,FALSE,FALSE,FALSE,Recurrent Quantum Neural Networks,Deep Learning -> Recurrent Networks,Applications -> Quantum Learning; Deep Learning -> Generative Models,Deep learning,['Johannes Bausch'],{'University of Cambridge'},1,0,0,{'UK'}
No-Regret Learning and Mixed Nash Equilibria: They Do Not Mix,"Emmanouil-Vasileios Vlatakis-Gkaragkounis, Lampros Flokas, Thanasis Lianeas, Panayotis Mertikopoulos, Georgios Piliouras",No-Regret Learning and Mixed Nash Equilibria: They Do Not Mix,0ed9422357395a0d4879191c66f4faa2,https://proceedings.neurips.cc/paper/2020/file/0ed9422357395a0d4879191c66f4faa2-Paper.pdf,This is a theoretical work which does not present any foreseeable societal consequence.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,No-Regret Learning and Mixed Nash Equilibria: They Do Not Mix,Theory -> Game Theory and Computational Economics,Algorithms -> Dynamical Systems; Algorithms -> Online Learning,Optimization Methods (continuous or discrete),"['Gkaragkounis', ' Lampros Flokas', ' Thanasis Lianeas', ' Panayotis Mertikopoulos', 'CNRS', ' Georgios Piliouras']","{'Singapore University of Technology and Design', 'French National Center for Scientific Research', 'Columbia University', 'National Technical University of Athens'}",1,0,0,"{'USA', 'Singapore', 'Greece', 'France'}"
A Unifying View of Optimism in Episodic Reinforcement Learning,"Gergely Neu, Ciara Pike-Burke",A Unifying View of Optimism in Episodic Reinforcement Learning,0f0e13216262f4a201bec128044dd30f,https://proceedings.neurips.cc/paper/2020/file/0f0e13216262f4a201bec128044dd30f-Paper.pdf,"The results presented in this paper are largely theoretical. We define a class of algorithms which are theoretically well understood, but also benefit from a computationally efficient implementation. The framework provided in this paper is very general so, in principle, any algorithm which fits into the framework could be applied to any reinforcement learning problem in a tabular or factored linear MDP. Consequently, as for any reinforcement learning algorithm, there is the potential for algorithms developed using the ideas presented in this paper to be applied in settings which have negative societal impacts, or in settings where the reward function is not well specified leading to undesirable behaviors.",Broader Impact,108,4,,,FALSE,FALSE,FALSE,A Unifying View of Optimism in Episodic Reinforcement Learning,Reinforcement Learning and Planning -> Exploration,Algorithms -> Bandit Algorithms; Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement learning and planning,"['Gergely Neu', 'Burke']",{'Universitat Pompeu Fabra'},1,0,0,{'Spain'}
Continuous Submodular Maximization: Beyond DR-Submodularity,"Moran Feldman, Amin Karbasi",Continuous Submodular Maximization: Beyond DR-Submodularity,0f34132b15dd02f282a11ea1e322a96d,https://proceedings.neurips.cc/paper/2020/file/0f34132b15dd02f282a11ea1e322a96d-Paper.pdf,"In this paper, we provided the first constant factor approximation guarantees for a large class of non-convex functions with combinatorial structure. Since it is a theoretical result in nature, a broader impact discussion is not applicable.",Broader Impact,36,2,TRUE,FALSE,FALSE,FALSE,FALSE,Continuous Submodular Maximization: Beyond DR-Submodularity,Optimization -> Submodular Optimization,Optimization -> Discrete Optimization; Optimization -> Non-Convex Optimization,,"['Moran Feldman', ' Amin Karbasi']","{'Yale', 'University of Haifa'}",1,0,0,"{'USA', 'Israel'}"
An Asymptotically Optimal Primal-Dual Incremental Algorithm for Contextual Linear Bandits,"Andrea Tirinzoni, Matteo Pirotta, Marcello Restelli, Alessandro Lazaric",An Asymptotically Optimal Primal-Dual Incremental Algorithm for Contextual Linear Bandits,0f34314d2dd0c1b9311cb8f40eb4f255,https://proceedings.neurips.cc/paper/2020/file/0f34314d2dd0c1b9311cb8f40eb4f255-Paper.pdf,This work is mainly a theoretical contribution. We believe it does not present any foreseeable societal consequence.,Broader Impact,17,2,TRUE,FALSE,FALSE,FALSE,FALSE,An Asymptotically Optimal Primal-Dual Incremental Algorithm for Contextual Linear Bandits,Algorithms -> Bandit Algorithms,,Reinforcement learning and planning,,"{'Politecnico di Milano', 'Facebook AI Research', 'Facebook Artificial Intelligence Research'}",1,1,1,"{'Italy', 'USA'}"
Assessing SATNet's Ability to Solve the Symbol Grounding Problem,"Oscar Chang, Lampros Flokas, Hod Lipson, Michael Spranger",Assessing SATNet’s Ability to Solve the Symbol Grounding Problem,0ff8033cf9437c213ee13937b1c4c455,https://proceedings.neurips.cc/paper/2020/file/0ff8033cf9437c213ee13937b1c4c455-Paper.pdf,"Reproducibility In recent years, there has been a reproducibility “crisis” in the natural sciences and medicine [ 44, 45, 46], with the problem even extending into the computational sciences like machine learning [47, 48, 49, 50]. There is little incentive for independent researchers to put in the effort to re-verify the claims of a paper that has gone through peer review. This is not least because of the possibility that the failure in replication might be due to problems with the replication rather than problems with the original claims. However, we believe that prominent papers, especially ones like SATNet that have won conference awards, deserve extra scrutiny. By re-assessing SATNet’s original claims, we provide additional credibility for established findings in the machine learning literature. Sober re-assessments of cutting edge AI technology also help to downplay the ‘hype’, allowing non-expert stakeholders from the broader society to be clear-eyed about the current state of the art. We regret if this paper appears overly critical of the impressive achievements made by SATNet. A potentially negative consequence of our paper is that it discourages researchers from making their code open-source because of the additional scrutiny that this will invite. Critical assessments of AI technology might also lower both public and commercial funding for AI due to more realistic expectations, as has happened during the AI winters. The Importance of the Symbol Grounding Problem There have been many attempts to combine pattern recognition and logical reasoning into a single neural network model, but most of these attempts essentially focus on reducing the problem to the relaxation of non-differentiable functions. Our work on SATNet clearly exemplifies that addressing the optimization issues inherent in combining logic and deep learning will not be enough to train models in a minimally supervised end-to-end learning fashion. Without a significant breakthrough, solving symbol grounding problems without intermediate labels will probably remain out of reach. Our work aims to highlight the importance of explicitly addressing the symbol grounding problem, and we hope that future research to do so will expand the applications of machine learning and AI beyond System-1 pattern recognition capabilities.",Broader Impact,350,13,,,FALSE,FALSE,FALSE,Assessing SATNet's Ability to Solve the Symbol Grounding Problem,Neuroscience and Cognitive Science -> Cognitive Science,Algorithms -> Relational Learning; Algorithms -> Representation Learning; Neuroscience and Cognitive Science -> Reasoning,Deep learning,,"{'Columbia University', 'Sony'}",1,1,1,"{'Japan', 'USA'}"
A Bayesian Nonparametrics View into Deep Representations,"Michał Jamroż, Marcin Kurdziel, Mateusz Opala",A Bayesian Nonparametrics View into Deep Representations,0ffaca95e3e5242ba1097ad8a9a6e95d,https://proceedings.neurips.cc/paper/2020/file/0ffaca95e3e5242ba1097ad8a9a6e95d-Paper.pdf,"This work have direct applications in deep generative models. Probabilistic models of latent spaces may inform development of architectures and training methods that improve sample fidelity and control over sample semantics. While generative modelling have many positive applications – e.g. in computer aided art and conversational systems – any work on generative models may potentially be used to produce deceptive and fraudulent content. This work also adds to the evidence that convolutional networks excel at exploiting patterns in data. However, it is important to recognize that our results do not speak to the issue of biases that may be inherited from training examples. In particular, undue trust in data-driven systems – including neural networks – runs the risk of reinforcing biases and prejudice existing in training data.",8 Broader Impact,127,6,,,FALSE,FALSE,FALSE,A Bayesian Nonparametrics View into Deep Representations,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Representation Learning; Probabilistic Methods -> Bayesian Nonparametrics,Deep learning,"['Michał Jamroż', ' Marcin Kurdziel', ' Mateusz Opala']","{'AGH University of Science and Technology', 'AGH University of Science and Technology, Krakow, Poland'}",1,0,0,{'Poland'}
On the Similarity between the Laplace and Neural Tangent Kernels,"Amnon Geifman, Abhay Yadav, Yoni Kasten, Meirav Galun, David Jacobs, Basri Ronen",On the Similarity between the Laplace and Neural Tangent Kernels,1006ff12c465532f8c574aeaa4461b16,https://proceedings.neurips.cc/paper/2020/file/1006ff12c465532f8c574aeaa4461b16-Paper.pdf,"This work explains the success of deep, fully connected networks through their similarity to exponential kernels. Such an analysis may allow for a better interpretability of deep network models.",Broader impact,29,2,FALSE,FALSE,FALSE,FALSE,FALSE,On the Similarity between the Laplace and Neural Tangent Kernels,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Spaces of Functions and Kernels,Deep learning,"['Amnon Geifman', ' Abhay Yadav', ' Yoni Kasten', ' Meirav Galun', ' David Jacobs', ' Basri Ronen']","{'Weizmann Institute of Science', 'University of Maryland', 'Weizmann Institute'}",1,0,0,"{'USA', 'Israel'}"
A causal view of compositional zero-shot recognition,"Yuval Atzmon, Felix Kreuk, Uri Shalit, Gal Chechik",A causal view of compositional zero-shot recognition,1010cedf85f6a7e24b087e63235dc12e,https://proceedings.neurips.cc/paper/2020/file/1010cedf85f6a7e24b087e63235dc12e-Paper.pdf,"Compositional generalization, the key challenge of this work, is critical for learning in real-world domains where the long tail of new combinations dominates the distribution, like in vision-and- language tasks or for the perception modules of autonomous driving. A causality-based approach, like the one we propose, may allow vision systems to make more robust inference, and debias correlations that naturally exist in the training data, allowing to use vision systems in complex environments where the distribution of labels and their combinations is varying. It has been shown in the past that vision systems may emphasize biases in the data, and the ideas put forward in the paper may help make systems more robust to such biases. Such approach may be useful for improving fairness in various applications, for example by providing a more balanced visual recognition of individuals from minority groups.",Broader Impact,141,4,,,FALSE,FALSE,FALSE,A causal view of compositional zero-shot recognition,Algorithms -> Multitask and Transfer Learning,Algorithms -> Classification; Algorithms -> Few-Shot Learning; Algorithms -> Representation Learning; Applications -> Computer Vision; Applications -> Visual Scene Analysis and Interpretation,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,"{'Technion', 'Bar-Ilan University', 'Bar Ilan University', 'NVIDIA, BIU'}",1,1,1,"{'USA', 'Israel'}"
HiPPO: Recurrent Memory with Optimal Polynomial Projections,"Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, Christopher Ré",HiPPO: Recurrent Memory with Optimal Polynomial Projections,102f0bb6efb3a6128a3c750dd16729be,https://proceedings.neurips.cc/paper/2020/file/102f0bb6efb3a6128a3c750dd16729be-Paper.pdf,"Our work seeks to understand the foundation of memory in modeling sequential data, which may improve a wide range of applications, each with their own potential benefits and harms. For example, incorporating longer context in language modeling may improve the quality of automated customer services, helpdesks, and personal assistants, but might also facilitate spreading misinformation. Better video processing may produce more coherent video summary for visually impaired users, but might also make automatic surveillance easier. Our framework presents a principled way to study memory of machine learning models. We speculate that this new representation could be a tool to study how potential biases in training data can get incorporated into the model. This in turn may give us a better handle on how to identify and potentially mitigate the effect of such biases in machine learning models. Though we currently do not have concrete ideas along this line, we encourage future investigation to better understand these learned representations to address fairness issues.",Broader Impact,162,7,,,FALSE,TRUE,FALSE,HiPPO: Recurrent Memory with Optimal Polynomial Projections,Deep Learning -> Recurrent Networks,Algorithms -> Dynamical Systems,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Albert Gu', ' Tri Dao', ' Stefano Ermon', ' Atri Rudra', ' Christopher Ré']","{'Stanford', 'Stanford University', 'University at Buffalo, SUNY'}",1,0,0,{'USA'}
Auto Learning Attention,"Benteng Ma, Jing Zhang, Yong Xia, Dacheng Tao",Auto Learning Attention,103303dd56a731e377d01f6a37badae3,https://proceedings.neurips.cc/paper/2020/file/103303dd56a731e377d01f6a37badae3-Paper.pdf,"Machine learning and related technologies have already achieved remarkable performance in many areas. Current methods still require intensive empirical efforts for network design and hyperparameter fine-tuning. Our research can search the optimal high order group attention module automatically, and the searched module is computationally efficient and generalizes well to various tasks. It will help to build a strong deep neural network model automatically without having to rely on the manual design of the attention architecture. Since machine learning can promote the development of industry, healthcare, and education, AutoML can accelerate this process by offering various specific optimal models that fit different hardware platforms and latency constraints. However, AutoML usually searches the model without domain knowledge, and may result in some uncertain and unreliable models that will make confusing decisions. The excessive trust in these decision will lead to many ethics issues. For example, when the diagnostic system optimized by AutoML leads to the death of the patients or other property damage, who should be responsible for this? What’s more, the abuse of AutoML may cause horrible disasters, especially in military applications. Machine learning can optimize the design of weapons to make them adapted to the specific operational conditions. AutoML will speed up this process and makes it possible to search the optimal system under any different constraints and to customize the mass production of weapons. The weapon design systems optimized by AutoML will cause a great threat to world peace, and we advocate the AutoML will not apply to the field of military or warfare. Further, AutoML will tip the scales in favor of the developed countries that are developing these technologies to improve living conditions across the board in a variety of ways. However, the labor force in developing countries is largely unskilled, and the use of AutoML in many cases means higher unemployment, lower-income, and more social unrest. The purpose of artificial intelligence in this condition should be to enhance their workforce skills, not to replace them. As a researcher, we need to work principally to make sure technology matches our values.",Broader Impact,344,16,,,TRUE,TRUE,FALSE,Auto Learning Attention,Applications -> Computer Vision,"Applications -> Body Pose, Face, and Gesture Analysis; Applications -> Object Detection; Applications -> Object Recognition",AutoML,"['Benteng Ma', ' Jing Zhang', ' Yong Xia', ' Dacheng Tao']","{'University of Sydney', 'The University of Sydney', 'Northwestern Polytechnical University'}",1,0,0,"{'Australia', 'China'}"
CASTLE: Regularization via Auxiliary Causal Graph Discovery,"Trent Kyono, Yao Zhang, Mihaela van der Schaar",CASTLE: Regularization via Auxiliary Causal Graph Discovery,1068bceb19323fe72b2b344ccf85c254,https://proceedings.neurips.cc/paper/2020/file/1068bceb19323fe72b2b344ccf85c254-Paper.pdf,"One of the big challenges of machine learning, and deep learning in particular, is generalization to out-of-sample data. Regularization is necessary and used to prevent overfitting thereby promoting generalization. In this work, we have presented a novel regularization method inspired by causality. Since the applicability of our approach spans all problems where causal relationships exist between variables, there are countless beneficiaries of our research. Apart from the general machine learning community, the beneficiaries of our research include practitioners in the social sciences (sociology, psychology, etc.), natural sciences (physics, biology, etc.), and healthcare among countless others. These fields have already been exploiting causality for some time and serve as a natural launch-pad for deploying and leveraging CASTLE. With that said, our method does not immediately apply to certain architectures, such as CNNs, where causal relationships are ambiguous or perhaps non-existent.",Broader Impact,139,9,,,FALSE,FALSE,FALSE,CASTLE: Regularization via Auxiliary Causal Graph Discovery,Deep Learning -> Supervised Deep Networks,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Trent Kyono', ' Yao Zhang', ' Mihaela van der Schaar']","{'UCLA', 'University of Cambridge'}",1,0,0,"{'UK', 'USA'}"
Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect,"Kaihua Tang, Jianqiang Huang, Hanwang Zhang",Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect,1091660f3dff84fd648efe31391c5524,https://proceedings.neurips.cc/paper/2020/file/1091660f3dff84fd648efe31391c5524-Paper.pdf,"The positive impacts of this work are two-fold: 1) it improves the fairness of the classifier, which prevents the potential discrimination of deep models, e.g. , an unfair AI could blindly cater to the majority, causing gender, racial or religious discrimination; 2) it allows the larger vocabulary datasets to be easily collected without a compulsory class-balancing pre-processing, e.g. , to train autonomous vehicles, by using the proposed method, we don’t need collecting as many ambulance images as normal van images do. The negative impacts could also happen when the proposed long-tailed classification technique falls into the wrong hands, e.g. , it can be used to identify the minority groups for malicious purposes. Therefore, it’s our duty to make sure that the long-tailed classification technique is used for the right purpose.",Broader Impact,130,3,,,FALSE,FALSE,FALSE,Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect,Applications -> Computer Vision,Algorithms -> Classification; Deep Learning -> Efficient Inference Methods,Vision,,"{'Nanyang Technological University', 'Damo Academy, Alibaba Group', 'NTU'}",1,1,1,"{'Singapore', 'UK', 'China'}"
Explainable Voting,"Dominik Peters, Ariel D. Procaccia, Alexandros Psomas, Zixin Zhou",Explainable Voting,10c72a9d42dd07a028ee910f7854da5d,https://proceedings.neurips.cc/paper/2020/file/10c72a9d42dd07a028ee910f7854da5d-Paper.pdf,"Our work is motivated by societal applications of voting and virtual democracy, as we discuss in Sections 1 and 5. We expect our work to ultimately make these applications more transparent and trustworthy. We do not foresee negative consequences for our work. It is particularly noteworthy that our explanation approach is not influenced by biases in data, as it builds purely on uncontroversial axiomatic properties rather than deriving explanations from data. That said, we acknowledge that the virtual democracy approach itself (which is outside the scope of this paper) faces many ethical challenges, including questions about who gets to participate and whether participants’ biases influence preference models, thereby negatively affecting aggregate decisions or recommendations made by the system.",Broader Impact,118,5,,,TRUE,TRUE,FALSE,Explainable Voting,Theory -> Game Theory and Computational Economics,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Theory (including computational and statistical analyses),"['Dominik Peters', ' Ariel Procaccia', ' Alexandros Psomas', ' Zixin Zhou']","{'Harvard University', 'Carnegie Mellon University', 'Purdue University', 'Peking University'}",1,0,0,"{'USA', 'China'}"
Deep Archimedean Copulas,"Chun Kai Ling, Fei Fang, J. Zico Kolter",Deep Archimedean Copulas,10eb6500bd1e4a3704818012a1593cc3,https://proceedings.neurips.cc/paper/2020/file/10eb6500bd1e4a3704818012a1593cc3-Paper.pdf,"Copulas have held the dubious honor of being partially responsible for the financial crisis of 2008 [23]. Back then, it was commonplace for analysts and traders to model prices of collateralized debt obligations (CDOs) by means of the Gaussian copula [22]. Gaussian copulas were extremely simple and gained popularity rapidly. Yet today, this method is widely criticised as being overly simplistic as it effectively summarizes associations between securities into a single number. Of course, copulas now have found a much wider range of applications, many of which are more grounded than credit and risk modeling. Nonetheless, the criticism that Gaussian—or for that matter, any simple parametric measure of dependency is too simple, still stands. ACNet is one attempt to tackle this problem, possibly beyond financial applications. While still retaining the theoretical properties of Archimedean copula, ACNet can model dependencies which have no simple parametric form, and can alleviate some difficulties researchers have when facing the problem of model selection. We hope that with a more complex model, the use of ACNet will be able to overcome some of the deficiencies exhibited by Gaussian copula. Nonetheless, we continue to stress caution in the careless or flagrant application of copulas—or the overreliance on probabilistic modeling—in domains where such assumptions are not grounded. At a level closer to machine learning, ACNet essentially models (a restricted set of) cumulative distributions. As described in the paper, this has various applications (see for example, Scenario 2 in Section 3 of our paper), since it is computationally easy to obtain (conditional) densities from the distribution function, but not the other way round. We hope that ACNet will motivate researchers to explore alternatives to learning density functions and apply them where appropriate.",6 Broader impact statement,284,13,,,FALSE,FALSE,FALSE,Deep Archimedean Copulas,Probabilistic Methods,Deep Learning -> Generative Models; Probabilistic Methods -> Graphical Models,Deep learning,"['Chun Kai Ling', ' Fei Fang', ' Zico Kolter']","{'Carnegie Mellon University', 'Carnegie Mellon University / Bosch Center for AI'}",1,1,1,"{'USA', 'Germany'}"
Re-Examining Linear Embeddings for High-Dimensional Bayesian Optimization,"Ben Letham, Roberto Calandra, Akshara Rai, Eytan Bakshy",Re-Examining Linear Embeddings for High-Dimensional Bayesian Optimization,10fb6cfa4c990d2bad5ddef4f70e8ba2,https://proceedings.neurips.cc/paper/2020/file/10fb6cfa4c990d2bad5ddef4f70e8ba2-Paper.pdf,"Bayesian optimization is a powerful optimization technique used in a wide range of industries and applications, such as robotics [32, 6, 40], internet tech companies [16, 30], designing novel molecules for pharmaceutics [17], material design for increasing efficiency of solar cells [54], and aerospace engineering [28]. All of these settings have high-dimensional optimization problems, and advances in BO will reflect on improved capabilities on these fields as well. We have fully open-sourced our code for ALEBO to be available for researchers and practitioners in these fields, and many others. The ability to optimize a larger number of parameters than has previously been possible will bring further improvements to and further accelerate work in these areas.",Broader Impact,115,4,,,FALSE,FALSE,FALSE,Re-Examining Linear Embeddings for High-Dimensional Bayesian Optimization,Optimization,Applications -> Robotics; Optimization -> Non-Convex Optimization; Probabilistic Methods -> Gaussian Processes,Optimization Methods (continuous or discrete),"['Ben Letham', ' Roberto Calandra', ' Akshara Rai', ' Eytan Bakshy']","{'Facebook', 'Facebook AI Research'}",0,1,0,{'USA'}
UnModNet: Learning to Unwrap a Modulo Image for High Dynamic Range Imaging,"Chu Zhou, Hang Zhao, Jin Han, Chang Xu, Chao Xu, Tiejun Huang, Boxin Shi",UnModNet: Learning to Unwrap a Modulo Image for High Dynamic Range Imaging,1102a326d5f7c9e04fc3c89d0ede88c9,https://proceedings.neurips.cc/paper/2020/file/1102a326d5f7c9e04fc3c89d0ede88c9-Paper.pdf,"Our research is about a new camera framework that aims to capture high-quality HDR images. It could be integrated into the image processing pipeline of camera sensors to improve the ability of recording scenes with a very high dynamic range. The users of mobile cameras may benefit from this research because they could conveniently take photos without being annoyed by over- or under-exposure artifacts. Besides, it might be helpful to build a scientific imaging system that needs to record high dynamic range scenes, such as astronomy and microscope cameras. Although the modulo camera-based framework could theoretically achieve unbounded dynamic range, its generalization capability is limited by the diversity of the training data. The unwrapping algorithm may fail when the captured scene has a very high dynamic range which exceeds the maximum dynamic range of the images in the training data by a large margin. If that happens in a large region of pixels, we would recommend using LDR images instead since they have more natural color appearances.",Broader Impact,167,7,,,TRUE,TRUE,FALSE,UnModNet: Learning to Unwrap a Modulo Image for High Dynamic Range Imaging,Applications -> Computational Photography,Applications -> Computer Vision,Vision,"['Chu Zhou', ' Hang Zhao', ' Jin Han', ' Chang Xu', ' Chao Xu', ' Tiejun Huang', ' Boxin Shi']","{'University of Sydney', 'MIT', 'Peking University'}",1,0,0,"{'Australia', 'USA', 'China'}"
Thunder: a Fast Coordinate Selection Solver for  Sparse Learning,"Shaogang Ren, Weijie Zhao, Ping Li",Thunder: a Fast Coordinate Selection Solver for Sparse Learning,11348e03e23b137d55d94464250a67a2,https://proceedings.neurips.cc/paper/2020/file/11348e03e23b137d55d94464250a67a2-Paper.pdf,"Sparse learning methods, e.g., LASSO, have broad applications in real-world problems, such as price prediction, biological data analysis. Real-world data sets usually come with high dimensionality and involve too much unpredictable noise. LASSO is a fundamental statistic tool to select important features and improve the prediction as well. Moreover, with the simple form and theoretical guarantees already studied by many people, these types of models can provide us interpretation about the data and reliable prediction results as well. Algorithms proposed in this paper can scale up the solutions of sparse learning. The training procedure can be reduced even under high solution precision requests. Our method can potentially enlarge the application of sparse learning to scenarios such as real-time high dimensional data processing.",Broader Impact,122,7,,,FALSE,FALSE,FALSE,Thunder: a Fast Coordinate Selection Solver for  Sparse Learning,Algorithms -> Sparsity and Compressed Sensing,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Shaogang Ren', ' Weijie Zhao', ' Ping Li']","{'Baidu Research, USA', 'Baidu Research', 'Baidu Research USA'}",0,1,0,{'China'}
Neural Networks Fail to Learn Periodic Functions and How to Fix It,"Liu Ziyin, Tilman Hartwig, Masahito Ueda",Neural Networks Fail to Learn Periodic Functions and How to Fix It,1160453108d3e537255e9f7b931f4e90,https://proceedings.neurips.cc/paper/2020/file/1160453108d3e537255e9f7b931f4e90-Paper.pdf,"In the field of deep learning, we hope that this work will attract more attention to the study of how neural networks extrapolate, since how a neural network extrapolates beyond the region it observes data determines how a network generalizes. In terms of applications, this work may have broad practical importance because many processes in nature and in society are periodic in nature. Being able to model periodic functions can have important impact to many fields, including but not limited to physics, economics, biology, and medicine.",Broader Impact Statement,86,3,,,FALSE,FALSE,FALSE,Neural Networks Fail to Learn Periodic Functions and How to Fix It,Deep Learning,Algorithms -> Regression; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Optimization for Deep Networks; Theory -> Hardness of Learning and Approximations,Deep learning,"['Ziyin Liu', ' Tilman Hartwig', ' Masahito Ueda']",{'University of Tokyo'},1,0,0,{'Japan'}
Distribution Matching for Crowd Counting,"Boyu Wang, Huidong Liu, Dimitris Samaras, Minh Hoai Nguyen",Distribution Matching for Crowd Counting,118bd558033a1016fcc82560c65cca5f,https://proceedings.neurips.cc/paper/2020/file/118bd558033a1016fcc82560c65cca5f-Paper.pdf,"Our work is able to more accurately estimate the crowd size in images or videos, such that it can guide crowd control and improve public safety. The estimated crowd count results are interpretable, with better crowd localization, which will increase transparency of the results for critical applications. In an age when the size of the crowd in various political events often becomes a point of heated dispute, having transparent, accurate and objective counting methods could help the historical record, as well a public acceptance of the estimates. Our method could potentially be used to protect public health by monitoring social distancing which is becoming increasingly important during the current epidemic. This method does not leverage biases in the data. The proposed method for counting is general, with possible applications to biomedical cell counting, live stock counting and etc. Our work can be adapted to count moving crowds.",Broader Impact,147,7,,,FALSE,FALSE,FALSE,Distribution Matching for Crowd Counting,Applications -> Computer Vision,"Applications -> Body Pose, Face, and Gesture Analysis; Applications -> Visual Scene Analysis and Interpretation",Vision,"['Boyu Wang', ' Huidong Liu', ' Dimitris Samaras', ' Minh Hoai Nguyen']",{'Stony Brook University'},1,0,0,{'USA'}
Correspondence learning via linearly-invariant embedding,"Riccardo Marin, Marie-Julie Rakotosaona, Simone Melzi, Maks Ovsjanikov",Correspondence Learning via Linearly-invariant Embedding,11953163dd7fb12669b41a48f78a29b6,https://proceedings.neurips.cc/paper/2020/file/11953163dd7fb12669b41a48f78a29b6-Paper.pdf,"Computing reliable correspondences is a problem that arises in many scientific disciplines and practical scenarios including medical imaging and industrial quality control (for detecting anomalies and performing repair and analysis), as well as 3D animation and texture transfer, statistical shape analysis, and even personalized medicine (with accurate detection of measurements often performed by template matching). Our novel fully trainable pipeline paves the way to more accurate results with direct practical applications in all of these fields, especially as it is applicable to arbitrary 3D shapes and deformations, unlike many existing methods which are specific e.g. to humans or near-isometries. This has the potential to replace highly specific axiomatic methods and tedious manual intervention. Finally, our insights can shed light on the structure of functional maps and shape analysis more broadly. We do not see any ethical issue with the proposed method, at least no ethical issues may be caused by our method as it is.",7 Broader Impact,155,5,,,FALSE,FALSE,FALSE,Correspondence learning via linearly-invariant embedding,Algorithms -> Representation Learning,Algorithms -> Similarity and Distance Learning; Applications -> Computer Vision,Vision,"['Riccardo Marin', 'Julie Rakotosaona', ' Simone Melzi', ' Maks Ovsjanikov']","{'Ecole Polytechnique', 'University of Verona', 'Ecole polytechnique'}",1,0,0,"{'France', 'Italy', 'Switzerland'}"
Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning,"Cong Zhang, Wen Song, Zhiguang Cao, Jie Zhang, Puay Siew Tan, Xu Chi",Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning,11958dfee29b6709f48a9ba0387a2431,https://proceedings.neurips.cc/paper/2020/file/11958dfee29b6709f48a9ba0387a2431-Paper.pdf,"Some work [49, 50] discussed the design of intelligent production systems by integrating modern AI technology. Our work, which solves a well-known problem that is ubiquitous in real-world production system, i.e. job shop scheduling, is within this scope. The automated end-to-end learning system in this work tries to free human labor from tedious work of designing effective dispatching rules for particular job shop scheduling problem. On the other side, however, this work may have some limitations. First, despite of performance improvement, it sacrifices interpretability due to the unexplainable nature of deep neural networks, whereas traditional dispatching rule based scheduling system is intuitive to human. This issue might make it untrustworthy for some applications, due to the potential risk and uncertainty. Second, highly automated and end-to-end system may conceal some details that are critical but easy to be ignored and bias human’s understanding underneath.",Broader Impact,143,7,,,FALSE,FALSE,FALSE,Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Optimization -> Discrete Optimization,Reinforcement learning and planning,"['Cong Zhang', ' Wen Song', ' Zhiguang Cao', ' Jie Zhang', ' Puay Siew Tan', ' Xu Chi']","{'National University of Singapore', 'Nanyang Technological University', 'SIMTECH', 'Institute of Marine Scinece and Technology, Shandong University', 'Singapore Institute of Manufacturing Technology, A-Star'}",1,1,1,"{'Singapore', 'China'}"
On Adaptive Attacks to Adversarial Example Defenses,"Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander Madry",On Adaptive Attacks to Adversarial Example Defenses,11f38f8ecd71867b42433548d1078e38,https://proceedings.neurips.cc/paper/2020/file/11f38f8ecd71867b42433548d1078e38-Paper.pdf,"Research that studies the security of machine learning, and especially papers whose primary purpose is to develop attacks on proposed defenses, must be careful to do more good than harm. We believe that this will be the case with our paper. After decades of debate, the computer security community has largely converged on “responsible disclosure” as the optimal method for disclosing vulnerabilities: after discovering a vulnerability, responsible disclosure dictates that the affected parties should be notified fist, and after a reasonable amount of time, the disclosure should be made public so that the community as a whole can learn from it. We notified all authors of our breaks of their defenses before making our paper public. Authors from twelve of the thirteen papers responded to us and verified that our evaluations were accurate (we offered to provide the generated adversarial examples to all authors). Further, we do not believe that there are any deployed systems that rely on the security of any of these particular defenses. However, it remains a possibility that our methodology for constructing attacks could be used to break some other system which has been deployed, or will be deployed in the future. This is unavoidable, however we firmly believe that the help that our paper can provide to researchers designing new defenses significantly outweighs the help that it may provide an actual malicious actor. Our paper is focused on assisting researchers perform more thorough evaluations, and diagnosing failures in evaluations—not on attacking real systems or users.",Broader Impact,250,9,,,FALSE,FALSE,FALSE,On Adaptive Attacks to Adversarial Example Defenses,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Florian Tramer', ' Nicholas Carlini', ' Wieland Brendel', ' Aleksander Madry']","{'Google', 'Stanford University', 'MIT', 'University of Tübingen'}",1,1,1,"{'USA', 'Germany'}"
Sinkhorn Natural Gradient for Generative Models,"Zebang Shen, Zhenfu Wang, Alejandro Ribeiro, Hamed Hassani",Sinkhorn Natural Gradient for Generative Models,122e27d57ae8ecb37f3f1da67abb33cb,https://proceedings.neurips.cc/paper/2020/file/122e27d57ae8ecb37f3f1da67abb33cb-Paper.pdf,"We propose the Sinkhorn natural gradient (SiNG) algorithm for minimizing an objective functional over a parameterized family of generative-model type measures. While our results do not immediately lead to broader societal impacts (as they are mostly theoretical), they can lead to new potential positive impacts. SiNG admits explicit update rule which can be efficiently carried out in an exact manner under both continuous and discrete settings. Being able to exploit the geometric information provided in the Sinkhorn information matrix, we observe the remarkable advantage of SiNG over existing state-of-the-art SGD-type solvers. Such algorithm is readily applicable to many types of existing generative adversarial models and possibly helps the development of the literature.",8 Broader Impact,112,5,,,FALSE,FALSE,FALSE,Sinkhorn Natural Gradient for Generative Models,Deep Learning -> Optimization for Deep Networks,Deep Learning -> Generative Models; Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Zebang Shen', ' Zhenfu Wang', ' Alejandro Ribeiro', ' Hamed Hassani']","{'University of Pennsylvania', 'Peking University', 'UPenn'}",1,0,0,"{'USA', 'China'}"
Online Sinkhorn: Optimal Transport distances from sample streams,"Arthur Mensch, Gabriel Peyré",Online Sinkhorn: Optimal Transport distances from sample streams,123650dd0560587918b3d771cf0c0171,https://proceedings.neurips.cc/paper/2020/file/123650dd0560587918b3d771cf0c0171-Paper.pdf,This work is mostly a theoretical contribution on optimisation for comparing probability distributions. It has therefore no immediate societal impact to be expected.,Broader impact,23,2,TRUE,FALSE,FALSE,FALSE,FALSE,Online Sinkhorn: Optimal Transport distances from sample streams,Optimization -> Stochastic Optimization,Algorithms -> Structured Prediction; Optimization -> Convex Optimization,,"['Arthur Mensch', ' Gabriel Peyré']","{'ENS', 'CNRS and ENS'}",1,0,0,{'France'}
Ultrahyperbolic Representation Learning,"Marc Law, Jos Stam",Ultrahyperbolic Representation Learning,123b7f02433572a0a560e620311a469c,https://proceedings.neurips.cc/paper/2020/file/123b7f02433572a0a560e620311a469c-Paper.pdf,"We introduce a novel way of representing relationships between data points by considering the geometry of non-Riemannian manifolds of constant nonzero curvature. The relationships between data points are described by a dissimilarity function that we introduce and exploits the structure of the manifold. It is more flexible than the distance metric used in hyperbolic and spherical geometries often used in machine learning and computer vision. Nonetheless, since the problems involving our representations are not straightforward to optimize, we propose novel optimization algorithms that can potentially benefit the machine learning, computer vision and natural language processing communities. Indeed, our method is application agnostic and could extend existing frameworks. Our contribution is mainly theoretical but we have included one practical application. Similarly to hyperbolic representations that are popular for representing tree-like data, we have shown that our representations are well adapted to the more general case of hierarchical graphs with cycles. These graphs appear in many different fields of research such as medicine, molecular biology and the social sciences. For example, an ultrahyperbolic representation of proteins might assist in understanding their complicated folding mechanisms. Moreover, these representations could assist in analyzing features of social media such as discovering new trends and leading ""connectors"". The impact of community detection for commercial or political advertising is already known in social networking services. We foresee that our method will have many more graph-based practical applications. We know of very few applications outside of general relativity that use pseudo-Riemannian geometry. We hope that our research will stimulate other applications in machine learning and related fields. Finally, although we have introduced a novel descent direction for our optimization algorithm, future research could study and improve its rate of convergence.",Broader Impact,282,15,,,FALSE,FALSE,FALSE,Ultrahyperbolic Representation Learning,Algorithms -> Metric Learning,Algorithms -> Representation Learning; Algorithms -> Similarity and Distance Learning; Optimization; Optimization -> Non-Convex Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Law Marc', ' Jos Stam']","{'NVIDIA', 'University of Toronto'}",1,1,1,"{'Canada', 'USA'}"
Locally-Adaptive Nonparametric Online Learning,"Ilja Kuzborskij, Nicolò Cesa-Bianchi",Locally-Adaptive Nonparametric Online Learning,12780ea688a71dabc284b064add459a4,https://proceedings.neurips.cc/paper/2020/file/12780ea688a71dabc284b064add459a4-Paper.pdf,We believe that presented research should be categorized as basic research and we are not targeting any specific application area. Theorems may inspire new algorithms and theoretical investigation. The algorithms presented here can be used for many different applications and a particular use may have both positive or negative impacts. We are not aware of any immediate short term negative implications of this research and we believe that a broader impact statement is not required for this paper.,7 Broader impact,78,4,,,FALSE,FALSE,FALSE,Locally-Adaptive Nonparametric Online Learning,Algorithms -> Online Learning,Theory,Theory (including computational and statistical analyses),"['Ilja Kuzborskij', 'Bianchi']","{'Università degli Studi di Milano', 'University of Milan'}",1,0,0,{'Italy'}
Compositional Generalization via Neural-Symbolic Stack Machines,"Xinyun Chen, Chen Liang, Adams Wei Yu, Dawn Song, Denny Zhou",Compositional Generalization via Neural-Symbolic Stack Machines,12b1e42dc0746f22cf361267de07073f,https://proceedings.neurips.cc/paper/2020/file/12b1e42dc0746f22cf361267de07073f-Paper.pdf,"Our work points out a promising direction towards improving compositional generalization of deep neural networks, and has potential to be utilized for a broad range of applications. In practice, the neural-symbolic framework design enables people to impose constraints on the neural network predictions, which could improve their interpretability and reliability.",Broader Impact,50,2,FALSE,FALSE,FALSE,FALSE,FALSE,Compositional Generalization via Neural-Symbolic Stack Machines,Algorithms -> Program Induction,Applications -> Program Understanding and Generation; Deep Learning; Deep Learning -> Memory-Augmented Neural Networks,Deep learning,"['Xinyun Chen', ' Chen Liang', ' Adams Wei Yu', ' Dawn Song', ' Dengyong Zhou']","{'UC Berkeley', 'Google Brain'}",1,1,1,{'USA'}
Graphon Neural Networks and the Transferability of Graph Neural Networks,"Luana Ruiz, Luiz Chamon, Alejandro Ribeiro",Graphon Neural Networks and the Transferability of Graph Neural Networks,12bcd658ef0a540cabc36cdf2b1046fd,https://proceedings.neurips.cc/paper/2020/file/12bcd658ef0a540cabc36cdf2b1046fd-Paper.pdf,"A very important implication of GNN transferability is allowing learning models to be replicated in different networks without the need for redesign. This can potentially save both data and compu- tational resources. However, since our work utilizes standard training procedures of graph neural networks, it may inherit any potential biases present in supervised training methods, e.g. data collection bias.",Broader Impact,59,3,FALSE,FALSE,FALSE,FALSE,FALSE,Graphon Neural Networks and the Transferability of Graph Neural Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Applications -> Signal Processing; Deep Learning -> CNN Architectures,Deep learning,"['Luana Ruiz', ' Luiz Chamon', ' Alejandro Ribeiro']",{'University of Pennsylvania'},1,0,0,{'USA'}
Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed Bandit with Many Arms,"Mohsen Bayati, Nima Hamidi, Ramesh Johari, Khashayar Khosravi",The Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed Bandit with Many Arms,12d16adf4a9355513f9d574b76087a08,https://proceedings.neurips.cc/paper/2020/file/12d16adf4a9355513f9d574b76087a08-Paper.pdf,"Narrowly, our work is a theoretical study of regret in MABs in the many-armed regime, and as such has no immediate societal consequence. More broadly, however free exploration in general has broader societal consequence, because in many applications, fairness and ethics (and sometimes regulation) preclude active exploration (e.g., healthcare, criminial justice, and education). For this reason, developing an understanding of what is achievable via free exploration is critical to fair and ethical application of MABs in practice.",Broader Impact,77,3,,,TRUE,TRUE,FALSE,Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed Bandit with Many Arms,Algorithms -> Bandit Algorithms,,Bandit Algorithms,"['Mohsen Bayati', ' Nima Hamidi', ' Ramesh Johari', ' Khashayar Khosravi']","{'Stanford University', 'Google Research'}",1,1,1,{'USA'}
Gamma-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction,"Michael Janner, Igor Mordatch, Sergey Levine",Gamma-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction,12ffb0968f2f56e51a59a6beb37b2859,https://proceedings.neurips.cc/paper/2020/file/12ffb0968f2f56e51a59a6beb37b2859-Paper.pdf,"-models provide a way to study infinite-horizon prediction in the same way that we can study the problem of control in infinite-horizon MDPs, possibly providing a path for more accurate long-term modeling without test-time compounding error. However, transforming a maximum likelihood problem into an approximate dynamic programming one is not without its drawbacks: maximum likelihood learning techniques are substantially better understood at this point in time and can be accompanied by rigorous guarantees even when incorporating function approximation. It will take much future work not just on -models, but on dynamic programming methods more broadly, for them to work reliably enough for deployment in real-world, safety-critical systems. While much work remains, we are optimistic for the long-term viability of temporal difference learning as an algorithm for training long-horizon dynamics models given its empirical success in long-horizon model-free control.",Broader Impact,138,4,,,FALSE,FALSE,FALSE,Gamma-Models: Generative Temporal Difference Learning for Infinite-Horizon Prediction,Reinforcement Learning and Planning -> Model-Based RL,,Reinforcement learning and planning,"['Michael Janner', ' Igor Mordatch', ' Sergey Levine']","{'UC Berkeley', 'Google'}",1,1,1,{'USA'}
Deep Transformers with Latent Depth,"Xian Li, Asa Cooper Stickland, Yuqing Tang, Xiang Kong",Deep Transformers with Latent Depth,1325cdae3b6f0f91a1b629307bf2d498,https://proceedings.neurips.cc/paper/2020/file/1325cdae3b6f0f91a1b629307bf2d498-Paper.pdf,"This work proposes a new method to leverage a model with increased depth during training, while learning a compact sub-work with reduced depth which can be used for deployment in real-world applications where Transformers have achieved state-of-the-art quality such as machine translation systems, dialog and assistant applications, etc, as reducing the number of layers especially in decoder (often autoregressive) can have direct impact on reducing inference-time latency, memory consumption, etc. However scaling up the number of layers adds to energy cost of training, even if we can prune at inference time. We hope our research on multilingual NLP will contribute to the effort of improving the standard of NLP tools for low-resource languages. However we only test our machine translation systems on to-English or from-English tasks, leaving out translation from non-English languages to other non-English languages entirely.",Broader Impact,137,4,,,TRUE,TRUE,FALSE,Deep Transformers with Latent Depth,Applications -> Natural Language Processing,Deep Learning -> Attention Models; Deep Learning -> Efficient Inference Methods; Deep Learning -> Supervised Deep Networks,Natural language processing,"['Xian Li', ' Asa Cooper Stickland', ' Yuqing Tang', ' Xiang Kong']","{'University of Edinburgh', 'Facebook', 'Carnegie Mellon University', 'Facebook AI'}",1,1,1,"{'UK', 'USA'}"
Neural Mesh Flow: 3D Manifold Mesh Generation via Diffeomorphic  Flows,"Kunal Gupta, Manmohan Chandraker",Neural Mesh Flow: 3D Manifold Mesh Generation via Diffeomorphic Flows,1349b36b01e0e804a6c2909a6d0ec72a,https://proceedings.neurips.cc/paper/2020/file/1349b36b01e0e804a6c2909a6d0ec72a-Paper.pdf,"The broader positive impact of our work would be to inspire methods in computer graphics and associated industries such as gaming and animation, to generate meshes that require significantly less human intervention for rendering and simulation. The proposed NMF method addresses an important need that has not been adequately studied in a vast literature on 3D mesh generation. While NMF is a first step in addressing that need, it tends to produce meshes that are over-smooth (also reflected in other methods sometimes obtaining greater geometric accuracy), which might have potential negative impact in applications such as manufacturing. Our code, models and data will be publicly released to encourage further research in the community.",Broader Impact,113,4,,,FALSE,FALSE,FALSE,Neural Mesh Flow: 3D Manifold Mesh Generation via Diffeomorphic  Flows,Applications -> Computer Vision,Applications -> Computational Photography,Vision,,"{'University of California San Diego', 'UC San Diego'}",1,0,0,{'USA'}
Statistical control for spatio-temporal MEG/EEG source imaging with desparsified mutli-task Lasso,"Jerome-Alexis Chevalier, Joseph Salmon, Alexandre Gramfort, Bertrand Thirion",Statistical control for spatio-temporal MEG/EEG source imaging with desparsified multi-task Lasso,1359aa933b48b754a2f54adb688bfa77,https://proceedings.neurips.cc/paper/2020/file/1359aa933b48b754a2f54adb688bfa77-Paper.pdf,"Magnetoencephalography (MEG) and electroencephalography (EEG) offer a unique opportunity to image brain activity non-invasively with a temporal resolution in the order of milliseconds. This is relevant for cognitive neuroscience to describe the sequence of active areas during certain cognitive tasks, but also for clinical neuroscience, where electrophysiology is used for diagnosis ( e.g., sleep medicine, epilepsy presurgical mapping). Yet, doing brain imaging with M/EEG requires to solve a challenging high-dimensional inverse problem for which statistical guarantees are crucially important. In this work, we address this statistical challenge when using sparsity promoting regularization and when considering the specificity of M/EEG signals: data are spatio-temporal and the noise is temporally autocorrelated. The proposed algorithm is built on very recent work in optimization to speed up Lasso-type solvers, as well as work in mathematical statistics on desparsified Lasso estimators. We believe that this work, whose contribution is both on the modeling side and on the inference aspects, brings sparse estimators close to a wide adoptions in the neuroscience community. We also would like to emphasize that the inference framework can be adapted to many other high-dimensional problems where data structure can be leveraged: biomedical data and physical observations (cardiac or brain monitoring, genomics, seismology, etc.), especially those that involve severely ill-posed inverse problems.",5 Statement of broader impact,210,8,,,TRUE,TRUE,FALSE,Statistical control for spatio-temporal MEG/EEG source imaging with desparsified mutli-task Lasso,Neuroscience and Cognitive Science -> Brain Imaging,Theory -> High-Dimensional Inference,Theory (including computational and statistical analyses),"['Alexis Chevalier', ' Joseph Salmon', ' Alexandre Gramfort', ' Bertrand Thirion']","{'Université de Montpellier', 'Inria Saclay Île-de-France', 'INRIA'}",1,0,0,{'France'}
A Scalable MIP-based Method for Learning Optimal Multivariate Decision Trees,"Haoran Zhu, Pavankumar Murali, Dzung Phan, Lam Nguyen, Jayant Kalagnanam",A Scalable MIP-based Method for Learning Optimal Multivariate Decision Trees,1373b284bc381890049e92d324f56de0,https://proceedings.neurips.cc/paper/2020/file/1373b284bc381890049e92d324f56de0-Paper.pdf,"Ensemble methods such as random forests and gradient boosting methods such as XGBoost, and LightGBM typically perform well, in terms of scalability and out-of-sample accuracy, for large-scale classification problems. However, these methods suffer from low interpretability and are incapable of modeling fairness. We hope the scalable MIP-based framework proposed in this paper proves to be seminal in addressing applicability of ODTs to large-scale real-world problems, while relying on the decision tree structure to preserve interpretability. The MIP framework might especially come in handy for sequential or joint prediction-optimization models, wherein the problem structure could be utilized to devise decomposition-based solution procedures. Alternatively, the proposed approach could be used to train a classification tree to provide insights on the behavior of a black-box model.",Broader impact,123,5,,,FALSE,FALSE,FALSE,A Scalable MIP-based Method for Learning Optimal Multivariate Decision Trees,Optimization -> Discrete Optimization,Algorithms -> Classification,Optimization Methods (continuous or discrete),"['Haoran Zhu', ' Pavankumar Murali', ' Dzung Phan', ' Lam Nguyen', ' Jayant Kalagnanam']","{'IBM Research', 'IBM', 'University of Wisconsin-Madison'}",1,1,1,{'USA'}
Efficient Exact Verification of Binarized Neural Networks,"Kai Jia, Martin Rinard",Efficient Exact Verification of Binarized Neural Networks,1385974ed5904a438616ff7bdb3f7439,https://proceedings.neurips.cc/paper/2020/file/1385974ed5904a438616ff7bdb3f7439-Paper.pdf,"Binarized Neural Networks (BNNs) are attractive targets for deployment in a variety of contexts including edge devices due to their efficiency advantages over real-valued networks. The present research, by developing techniques for training and verifying robust BNNs, may help enable the development of systems that more reliably and predictably serve their goals — systems that may be less likely to exhibit unexpected behavior in response to new inputs; systems that may be less vulnerable to attack. The research may therefore increase the range and capabilities of systems that use BNNs. Because this technology is general purpose and may be deployed in the service of prosocial, antisocial, or mixed goals, the ultimate broader impacts may be shaped by the choices societies make about how to use these capabilities. Example potential impacts include the increased deployment of accurate surveillance systems, more accurate vision systems for safer self-driving cars, more reliable autonomous control systems, and less effort spent certifying systems that include BNNs.",Broader impact,160,5,,,FALSE,FALSE,FALSE,Efficient Exact Verification of Binarized Neural Networks,Algorithms -> Adversarial Learning,,Verification of neural networks,"['Kai Jia', ' Martin Rinard']",{'MIT'},1,0,0,{'USA'}
Ultra-Low Precision 4-bit Training of Deep Neural Networks,"Xiao Sun, Naigang Wang, Chia-Yu Chen, Jiamin Ni, Ankur Agrawal, Xiaodong Cui, Swagath Venkataramani, Kaoutar El Maghraoui, Vijayalakshmi (Viji) Srinivasan, Kailash Gopalakrishnan",Ultra-Low Precision 4-bit Training of Deep Neural Networks,13b919438259814cd5be8cb45877d577,https://proceedings.neurips.cc/paper/2020/file/13b919438259814cd5be8cb45877d577-Paper.pdf,"Dedicated hardware accelerators for DNN training, including GPUs and TPUs, have powered machine learning research and model exploration over the past decade. These devices have enabled training on very large models and complex datasets (necessitating 10 - 100’s of ExaOps during the training process). Reduced precision innovations (16-bits) have recently improved the capability of these accelerators by 4-8 × and have dramatically improved the pace of model innovation and build. The 4-bit training results, presented in this work, aim to push this front aggressively and can power faster and cheaper training systems for a wide spectrum of deep learning models and domains. To summarize, we believe that 4-bit training solutions can accelerate ML research ubiquitously and provide huge cost and energy savings for corporations and research institutes—in addition to helping reduce the carbon / climate impact of AI training. By improving the power efficiency by 4 − 7 × in comparison to current FP16 designs (and > 20 × vs. default FP32 designs), the carbon footprint for training large DNN models can be significantly reduced [43]. The reduction in computational energy and memory footprint needed by 4-bit training systems could also enable training to be carried out on edge devices (e.g. mobile platforms). This, in turn, could alleviate security and privacy concerns of sending data back to the Cloud for aggregated AI model build. We would also like to point out that, although we show promising results and limited accuracy loss in comparison to FP32 training, 4-bit training solutions could still be subject to training instabilities. This may necessitate a careful examination of these training techniques over a wider range of models and perfected alongside the development of ML model research. The risk of using 4-bit training for DNN model build in real applications is higher than 8-bit or 16-bit approaches and thus requires task-specific roboustness studies.",Broader Impact,307,11,,,FALSE,FALSE,FALSE,Ultra-Low Precision 4-bit Training of Deep Neural Networks,Deep Learning -> Efficient Training Methods,Applications -> Hardware and Systems; Deep Learning -> CNN Architectures; Deep Learning -> Recurrent Networks,Deep learning,"['Xiao Sun', ' Naigang Wang', 'Yu Chen', ' Jiamin Ni', ' Ankur Agrawal', ' Xiaodong Cui', ' Swagath Venkataramani', ' Kaoutar El Maghraoui', ' Vijayalakshmi', ' Srinivasan', ' Kailash Gopalakrishnan']","{'Viji', 'IBM research', 'IBM Research', 'IBM TJ Watson', 'IBM'}",0,1,0,{'USA'}
Bridging the Gap between Sample-based and One-shot Neural Architecture Search with BONAS,"Han Shi, Renjie Pi, Hang Xu, Zhenguo Li, James Kwok, Tong Zhang",Bridging the Gap between Sample-based and One-shot Neural Architecture Search with BONAS,13d4635deccc230c944e4ff6e03404b5,https://proceedings.neurips.cc/paper/2020/file/13d4635deccc230c944e4ff6e03404b5-Paper.pdf,"Neural Architecture Search (NAS) is a powerful framework, and widely used in the industry to automatically search for models with good performance. However, the large number of architecture samples required and the consequent heavy computation are key obstacles for many researchers and small businesses. NAS also introduces environmental issues that cannot be overlooked. As pointed out in [32], the CO 2 emission from a NAS process can be comparable to that from 5 cars’ lifetime. With the proposed approach, the above-mentioned issues can be alleviated without compromising the final model’s performance. BONAS provides insights to future NAS research and industrial applications. It allows researchers and businesses with limited compute to conduct NAS experiments. This new NAS algorithm is also expected to be more energy-efficient and environmentally friendly.",Broader Impact,127,8,,,FALSE,FALSE,FALSE,Bridging the Gap between Sample-based and One-shot Neural Architecture Search with BONAS,Algorithms -> AutoML,,AutoML,"['Han Shi', ' Renjie Pi', ' Hang Xu', ' Zhenguo Li', ' James Kwok', ' Tong Zhang']",{'Hong Kong University of Science and Technology'},1,0,0,{'China'}
On Numerosity of Deep Neural Networks,"Xi Zhang, Xiaolin Wu",On Numerosity of Deep Neural Networks,13e36f06c66134ad65f532e90d898545,https://proceedings.neurips.cc/paper/2020/file/13e36f06c66134ad65f532e90d898545-Paper.pdf,"This research contributes to the knowledge on the strengths and limitations of deep learning; particu- larly so for cognitive computing, considering that numerosity, together with language, is a hallmark of human intelligence.",Broader Impact,32,1,FALSE,FALSE,FALSE,FALSE,FALSE,On Numerosity of Deep Neural Networks,Neuroscience and Cognitive Science -> Cognitive Science,Neuroscience and Cognitive Science -> Neuropsychology; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Perception,Neuroscience and cognitive science,"['Xi Zhang', ' Xiaolin Wu']","{'McMaster University', 'Shanghai Jiao Tong University'}",1,0,0,"{'Canada', 'China'}"
Outlier Robust Mean Estimation with Subgaussian Rates via Stability,"Ilias Diakonikolas, Daniel M. Kane, Ankit Pensia",Outlier Robust Mean Estimation with Subgaussian Rates via Stability,13ec9935e17e00bed6ec8f06230e33a9,https://proceedings.neurips.cc/paper/2020/file/13ec9935e17e00bed6ec8f06230e33a9-Paper.pdf,"Our work fits within the area of algorithmic high-dimensional robust statistics and aims to advance the algorithmic foundations of outlier-robust learning for heavy-tailed data. An important motivation for this line of work is to design provable defenses of machine learning systems against data poisoning with optimal accuracy-confidence tradeoffs. As the primary focus of our work is theoretical, we do not expect our results to have immediate societal impact. Nonetheless, we believe that our probabilistic analysis provides useful insights that could be leveraged in practically relevant robust estimators.",Broader Impact,87,4,,,FALSE,FALSE,FALSE,Outlier Robust Mean Estimation with Subgaussian Rates via Stability,Theory -> Computational Learning Theory,Theory -> High-Dimensional Inference; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Ilias Diakonikolas', ' Kane', ' Ankit Pensia']","{'UW Madison', 'University of Wisconsin-Madison', 'UCSD'}",1,0,0,{'USA'}
Self-Supervised Relationship Probing,"Jiuxiang Gu, Jason Kuen, Shafiq Joty, Jianfei Cai, Vlad Morariu, Handong Zhao, Tong Sun",Self-Supervised Relationship Probing,13f320e7b5ead1024ac95c3b208610db,https://proceedings.neurips.cc/paper/2020/file/13f320e7b5ead1024ac95c3b208610db-Paper.pdf,"Current representation learning models such as BERT and alike follow a similar structure. We think it is important to discover or probe the implicit knowledge that these models capture about language and vision. Our research on self-supervised relationship probing is a push in that direction and can be used for grounding the relationships expressed in language. In this paper, we introduce SSRP, a self-supervised relationship probing method for visual and textual relationship extraction. Our research could be used to enrich the current scene graph generation methods and to complete the missing relationships between objects. The visual relationships generated by our method could be applied to a wide range of vision and vision-language applications including image captioning, image retrieval, object detection, visual question answering, visual reasoning, and visual-textual cross-modal retrieval, etc . Here, we discuss the broader impact on the two important example applications (image retrieval and image captioning) which can benefit greatly from the implicit relationships obtained with our method. By performing image retrieval using the implicit visual relationships discovered with our method, visual search engines can provide higher-quality results that better respect the visual relationships contained in query images to users. This provides a smoother visual search experience and helps users find their desired images. On the other hand, for image captions/descriptions, with the implicit visual relationships generated by our method, richer and improved descriptions of images that more accurately describe the scenes in images can be obtained. This can help blind or visually-impaired people [66] ‘see’ their surrounding environments better. In terms of technical impacts, our method opens a new direction to better model visual object relationships, which is completely different from current visual relation models that heavily rely on human-annotated explicit visual relation labels. Annotating visual relationships is a highly subjective process where different annotators are likely to annotate quite differently. Relations are also very diverse and there is no clear definition. Our approach bypasses all these challenges of annotating relations by advocating to discover rich implicit relations directly from natural images and their textual descriptions in a self-supervised manner without using any explicit relation annotations. Thus, our method leads to richer and fairer visual relation model. In addition, in terms of dataset, our method also goes beyond current pretraining models that prefer to combine more and more datasets together for self-supervised training. Instead, our proposed method is developed specifically to work effectively with augmented data that can be cheaply obtained with the proposed augmentation strategies and can be nicely integrated into the self-supervision objectives. Overall, our method makes VL pretraining and visual relationship modeling more accessible to the masses.",Broader Impact,433,19,,,FALSE,FALSE,FALSE,Self-Supervised Relationship Probing,Algorithms -> Representation Learning,"Algorithms -> Multimodal Learning; Applications -> Visual Question Answering; Deep Learning -> Visualization, Interpretability, and Explainability","Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jiuxiang Gu', ' Jason Kuen', ' Shafiq Joty', ' Jianfei Cai', ' Vlad Morariu', ' Handong Zhao', ' Tong Sun']","{'Nanyang Technological University', 'Monash University', 'Adobe Research'}",1,1,1,"{'Singapore', 'Australia', 'USA', 'China'}"
Information Theoretic Counterfactual Learning from Missing-Not-At-Random Feedback,"Zifeng Wang, Xi Chen, Rui Wen, Shao-Lun Huang, Ercan Kuruoglu, Yefeng Zheng",Information Theoretic Counterfactual Learning from Missing-Not-At-Random Feedback,13f3cf8c531952d72e5847c4183e6910,https://proceedings.neurips.cc/paper/2020/file/13f3cf8c531952d72e5847c4183e6910-Paper.pdf,"In this work, we proposed a novel method for dealing with missing-not-at-random feedback in recommendation system. It has been criticized that current recommender systems are prone to overestimating the observed outcomes while underestimating those unobserved yet. As a result, users are restricted to a narrow scope of recommendation results. We would like to propose our method by considering unobserved events, namely counterfactuals, for counterfactual learning on missing- not-at-random feedback. We believe this method brings potential to develop a better recommender system on accuracy as well as diversity and fairness.",Broader Impact,89,5,,,FALSE,FALSE,FALSE,Information Theoretic Counterfactual Learning from Missing-Not-At-Random Feedback,Applications -> Recommender Systems,Algorithms -> Collaborative Filtering; Theory -> Information Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Zifeng Wang', ' Xi Chen', ' Rui Wen', 'Lun Huang', ' Ercan E Kuruoglu', ' Yefeng Zheng']","{'Tsinghua-Berkeley Shenzhen Institute', 'Tencent', 'Tsinghua-Berkeley Shenzhen Institute, Tsinghua University'}",1,1,1,"{'USA', 'China'}"
Prophet Attention: Predicting Attention with Future Attention,"Fenglin Liu, Xuancheng Ren, Xian Wu, Shen Ge, Wei Fan, Yuexian Zou, Xu Sun",Prophet Attention: Predicting Attention with Future Attention,13fe9d84310e77f13a6d184dbf1232f3,https://proceedings.neurips.cc/paper/2020/file/13fe9d84310e77f13a6d184dbf1232f3-Paper.pdf,"Our work aims to improve both the captioning and grounding performance of image captioning systems, promoting the real-word application of image captioning, such as visual retrieval, human- robot interaction and visually impaired people assistance. Furthermore, we can also improve the model interpretability and transparency. However, the training of our framework relies on large volume of image-caption pairs, which are not easily obtained in the real-world. Therefore, it requires specific and appropriate treatment by experienced practitioners.",7 Broader Impact,75,4,,,FALSE,FALSE,FALSE,Prophet Attention: Predicting Attention with Future Attention,Applications -> Computer Vision,Applications -> Natural Language Processing,Natural language processing,,"{'Tencent Medical AI Lab', 'Peking University', 'Tencent'}",1,1,1,{'China'}
Language Models are Few-Shot Learners,"Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei",Language Models are Few-Shot Learners,1457c0d6bfcb4967418bfb8ac142f64a,https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf,"Language models have a wide range of beneficial applications for society, including code and writing auto-completion, grammar assistance, game narrative generation, improving search engine responses, and answering questions. But they also have potentially harmful applications. GPT-3 improves the quality of text generation and adaptability over smaller models and increases the difficulty of distinguishing synthetic text from human-written text. It therefore has the potential to advance both the beneficial and harmful applications of language models. Here we focus on the potential harms of improved language models, not because we believe the harms are necessarily greater, but in order to stimulate efforts to study and mitigate them. The broader impacts of language models like this are numerous. We focus on two primary issues: the potential for deliberate misuse of language models like GPT-3 in Section 7.1, and issues of bias, fairness, and representation within models like GPT-3 in Section 7.2. We also briefly discuss issues of energy efficiency (Section 7.3). 7.1 Misuse of Language Models Malicious uses of language models can be somewhat difficult to anticipate because they often involve repurposing language models in a very different environment or for a different purpose than researchers intended. To help with this, we can think in terms of traditional security risk assessment frameworks, which outline key steps such as identifying threats and potential impacts, assessing likelihood, and determining risk as a combination of likelihood and impact [Ros12]. We discuss three factors: potential misuse applications, threat actors, and external incentive structures. 7.1.1 Potential Misuse Applications Any socially harmful activity that relies on generating text could be augmented by powerful language models. Examples include misinformation, spam, phishing, abuse of legal and governmental processes, fraudulent academic essay writing and social engineering pretexting. Many of these applications bottleneck on human beings to write sufficiently high quality text. Language models that produce high quality text generation could lower existing barriers to carrying out these activities and increase their efficacy. The misuse potential of language models increases as the quality of text synthesis improves. The ability of GPT-3 to generate several paragraphs of synthetic content that people find difficult to distinguish from human-written text represents a concerning milestone in this regard. 7.1.2 Threat Actor Analysis Threat actors can be organized by skill and resource levels, ranging from low or moderately skilled and resourced actors who may be able to build a malicious product to ‘advanced persistent threats’ (APTs): highly skilled and well-resourced (e.g. state-sponsored) groups with long-term agendas [SBC+19]. To understand how low and mid-skill actors think about language models, we have been monitoring forums and chat groups where misinformation tactics, malware distribution, and computer fraud are frequently discussed. While we did find significant discussion of misuse following the initial release of GPT-2 in spring of 2019, we found fewer instances of experimentation and no successful deployments since then. Additionally, those misuse discussions were correlated with media coverage of language model technologies. From this, we assess that the threat of misuse from these actors is not immediate, but significant improvements in reliability could change this. Because APTs do not typically discuss operations in the open, we have consulted with professional threat analysts about possible APT activity involving the use of language models. Since the release of GPT-2 there has been no discernible difference in operations that may see potential gains by using language models. The assessment was that language models may not be worth investing significant resources in because there has been no convincing demonstration that current language models are significantly better than current methods for generating text, and because methods for “targeting” or “controlling” the content of language models are still at a very early stage. 7.1.3 External Incentive Structures Each threat actor group also has a set of tactics, techniques, and procedures (TTPs) that they rely on to accomplish their agenda. TTPs are influenced by economic factors like scalability and ease of deployment; phishing is extremely popular among all groups because it offers a low-cost, low-effort, high-yield method of deploying malware and stealing login credentials. Using language models to augment existing TTPs would likely result in an even lower cost of deployment. Ease of use is another significant incentive. Having stable infrastructure has a large impact on the adoption of TTPs. The outputs of language models are stochastic, however, and though developers can constrain these (e.g. using top-k truncation) they are not able to perform consistently without human feedback. If a social media disinformation bot produces outputs that are reliable 99% of the time, but produces incoherent outputs 1% of the time, this could reduce the amount of human labor required in operating this bot. But a human is still needed to filter the outputs, which restricts how scalable the operation can be. Based on our analysis of this model and analysis of threat actors and the landscape, we suspect AI researchers will eventually develop language models that are sufficiently consistent and steerable that they will be of greater interest to malicious actors. We expect this will introduce challenges for the broader research community, and hope to work on this through a combination of mitigation research, prototyping, and coordinating with other technical developers. 7.2 Fairness, Bias, and Representation Biases present in training data may lead models to generate stereotyped or prejudiced content. This is concerning, since model bias could harm people in the relevant groups in different ways by entrenching existing stereotypes and producing demeaning portrayals amongst other potential harms [Cra17]. We have conducted an analysis of biases in the model in order to better understand GPT-3’s limitations when it comes to fairness, bias, and representation. 2 Our goal is not to exhaustively characterize GPT-3, but to give a preliminary analysis of some of its limitations and behaviors. We focus on biases relating to gender, race, and religion, although many other categories of bias are likely present and could be studied in follow-up work. This is a preliminary analysis and does not reflect all of the model’s biases even within the studied categories. Broadly, our analysis indicates that internet-trained models have internet-scale biases; models tend to reflect stereotypes present in their training data. Below we discuss our preliminary findings of bias 2Evaluating fairness, bias, and representation in language models is a rapidly-developing area with a large body of prior work. See, for example, [HZJ+19, NBR20, SCNP19]. along the dimensions of gender, race, and religion. We probe for bias in the 175 billion parameter model and also in similar smaller models, to see if and how they are different in this dimension. 7.2.1 Gender In our investigation of gender bias in GPT-3, we focused on associations between gender and occupation. We found that occupations in general have a higher probability of being followed by a male gender identifier than a female one (in other words, they are male leaning) when given a context such as ""The {occupation} was a"" (Neutral Variant). 83% of the 388 occupations we tested were more likely to be followed by a male identifier by GPT-3. We measured this by feeding the model a context such as ""The detective was a"" and then looking at the probability of the model following up with male indicating words (eg. man, male etc.) or female indicating words (woman, female etc.). In particular, occupations demonstrating higher levels of education such as legislator, banker, or professor emeritus were heavily male leaning along with occupations that require hard physical labour such as mason, millwright, and sheriff. Occupations that were more likely to be followed by female identifiers include midwife, nurse, receptionist, housekeeper etc. We also tested how these probabilities changed when we shifted the context to be the ""The competent {occupation} was a"" (Competent Variant), and when we shifted the context to be ""The incompetent {occupation} was a"" (Incompetent Variant) for each occupation in the dataset. We found that, when prompted with ""The competent {occupation} was a,"" the majority of occupations had an even higher probability of being followed by a male identifier than a female one than was the case with our original neutral prompt, ""The {occupation} was a"". With the prompt ""The incompetent {occupation} was a"" the majority of occupations still leaned male with a similar probability than for our original neutral prompt. The average occupation bias - measured as 1/njobs Σjobs log( P (female|Context) / P (male|Context) ) - was −1.11 for the Neutral Variant, −2.14 for the Competent Variant and −1.15 for the Incompetent Variant. We also carried out pronoun resolution on the Winogender dataset [RNLVD18] using two methods which further corroborated the model’s tendency to associate most occupations with males. One method measured the models ability to correctly assign a pronoun as the occupation or the participant. For example, we fed the model a context such as ""The advisor met with the advisee because she wanted to get advice about job applications. ‘She’ refers to the"" and found the option with the lowest probability between the two possible options (Choices between Occupation Option: advisor; Participant Option: advisee). Occupation and participant words often have societal biases associated with them such as the assumption that most occupants are by default male. We found that the language models learnt some of these biases such as a tendency to associate female pronouns with participant positions more than male pronouns. GPT-3 175B had the highest accuracy of all the models (64.17%) on this task. It was also the only model where the accuracy for Occupant sentences (sentences where the correct answer was the Occupation option) for females was higher than for males (81.7% vs 76.7%). All other models had a higher accuracy for male pronouns with Occupation sentences as compared to female pronouns with the exception of our second largest model- GPT-3 13B - which had the same accuracy (60%) for both. This offers some preliminary evidence that in places where issues of bias can make language models susceptible to error, the larger models are more robust than smaller models. We also performed co-occurrence tests, where we analyzed which words are likely to occur in the vicinity of other pre-selected words. We created a model output sample set by generating 800 outputs of length 50 each with a temperature of 1 and top p of 0.9 for every prompt in our dataset. For gender, we had prompts such as ""He was very"", ""She was very"", ""He would be described as"", ""She would be described as""3 . We looked at the adjectives and adverbs in the top 100 most favored words using an off-the-shelf POS tagger [LB02]. We found females were more often described using appearance oriented words such as ”beautiful” and ”gorgeous” as compared to men who were more often described using adjectives that span a greater spectrum. 3We only used male and female pronouns. This simplifying assumption makes it easier to study co-occurrence since it does not require the isolation of instances in which ‘they’ refers to a singular noun from those where it didn’t, but other forms of gender bias are likely present and could be studied using different approaches. Table 7.1: Most Biased Descriptive Words in 175B Model Top 10 Most Biased Male Descriptive Words with Raw Co-Occurrence Counts Top 10 Most Biased Female Descriptive Words with Raw Co-Occurrence Counts Average Number of Co-Occurrences Across All Words: 17.5 Average Number of Co-Occurrences Across All Words: 23.9 Large (16) Optimistic (12) Mostly (15) Bubbly (12) Lazy (14) Naughty (12) Fantastic (13) Easy-going (12) Eccentric (13) Petite (10) Protect (10) Tight (10) Jolly (10) Pregnant (10) Stable (9) Gorgeous (28) Personable (22) Sucked (8) Survive (7) Beautiful (158) Table 7.1 shows the top 10 most favored descriptive words for the model along with the raw number of times each word co-occurred with a pronoun indicator. “Most Favored” here indicates words which were most skewed towards a category by co-occurring with it at a higher rate as compared to the other category. To put these numbers in perspective, we have also included the average for the number of co-occurrences across all qualifying words for each gender. 7.2.2 Race To investigate racial bias in GPT-3, we seeded the model with prompts such as - ""The {race} man was very"", ""The {race} woman was very"" and ""People would describe the {race} person as"" and generated 800 samples for each of the above prompts, with {race} replaced with a term indicating a racial category such as White or Asian. We then measure word co-occurrences in the generated samples. Given prior research demonstrating that language models produce text of differing sentiment when varying features such as occupation [HZJ+19], we explored how race impacted sentiment. We measured sentiment using Senti WordNet [BES10] for the words which co-occurred disproportionately with each race. Each word sentiment varied from 100 to -100, with positive scores indicating positive words (eg. wonderfulness: 100, amicable: 87.5), negative scores indicating negative words (eg. wretched: -87.5 , horrid: -87.5) and a score of 0 indicating neutral words (eg. sloping, chalet). It should be noted that we were explicitly prompting the models to talk about race and this in turn generated text that focused on racial features; these results are not from the models talking about race in the wild but talking about race in an experimental setup where they have been primed to do so. Additionally, since we are measuring sentiment by simply looking at word co-occurrences, the resulting sentiment can reflect socio-historical factors - for instance, text relating to a discussion of slavery will frequently have a negative sentiment, which may lead to a demographic being associated with a negative sentiment under this testing methodology. Across the models we analyzed, ‘Asian’ had a consistently high sentiment - it ranked 1st in 3 out of 7 models. On the other hand, ’Black’ had a consistently low sentiment - it ranked the lowest in 5 out of 7 models. These differences narrowed marginally on the larger model sizes. This analysis gives a sense of the biases of different models and highlights the need for more sophisticated analysis of the relationship between sentiment, entities, and input data. 7.2.3 Religion We studied which words co-occurred with religious terms relating to Atheism, Buddhism, Christianity, Hinduism, Islam, and Judaism, by generating 800 model outputs of length ≈50 with a temperature of 1 and a top p of 0.9 for every prompt. Our prompts were of the nature ""{Religion practitioners} are"" (Eg. ""Christians are"") for each of the six religious categories listed above. We then Figure 7.1: Racial Sentiment Across Models Religion Most Favored Descriptive Words Atheism ‘Theists’, ‘Cool’, ‘Agnostics’, ‘Mad’, ‘Theism’, ‘Defensive’, ‘Complaining’, ‘Correct’, ‘Arrogant’, ‘Characterized’ Buddhism ‘Myanmar’, ‘Vegetarians’, ‘Burma’, ‘Fellowship’, ‘Monk’, ‘Japanese’, ‘Reluctant’, ‘Wisdom’, ‘Enlightenment’, ‘Non-Violent’ Christianity ‘Attend’, ‘Ignorant’, ‘Response’, ‘Judgmental’, ‘Grace’, ‘Execution’, ‘Egypt’, ‘Continue’, ‘Comments’, ‘Officially’ Hinduism ‘Caste’, ‘Cows’, ‘BJP’, ‘Kashmir’, ‘Modi’, ‘Celebrated’, ‘Dharma’, ‘Pakistani’, ‘Originated’, ‘Africa’ Islam ‘Pillars’, ‘Terrorism’, ‘Fasting’, ‘Sheikh’, ‘Non-Muslim’, ‘Source’, ‘Charities’, ‘Levant’, ‘Allah’, ‘Prophet’ Judaism ‘Gentiles’, ‘Race’, ‘Semites’, ‘Whites’, ‘Blacks’, ‘Smartest’, ‘Racists’, ‘Arabs’, ‘Game’, ‘Russian’ Table 7.2: Shows the ten most favored words about each religion in the GPT-3 175B model. allowed the model to naturally carry out completions and created a corpus of such completions for studying co-occurrence of words. The following is an example output from the model: ""Buddhists are divided into two main branches - Theravada and Mahayana. Theravada is the more conservative branch, centering on monastic life and the earliest sutras and refusing to recognize the later Mahayana sutras as authentic."" Similar to race, we found that the models make associations with religious terms that indicate some propensity to reflect how these terms are sometimes presented in the world. For example, with the religion Islam, we found that words such as ramadan, prophet and mosque co-occurred at a higher rate than for other religions. We also found that words such as violent, terrorism and terrorist co-occurred at a greater rate with Islam than with other religions and were in the top 40 most favored words for Islam in GPT-3. 7.2.4 Future Bias and Fairness Challenges We have presented this preliminary analysis to share some of the biases we found in order to motivate further research, and to highlight the inherent difficulties in characterizing biases in large-scale generative models; we expect this to be an area of continuous research for us and are excited to discuss different methodological approaches with the community. We view the work in this section Figure 7.2: Total compute used during training. Based on the analysis in Scaling Laws For Neural Language Models [KMH+20] we train much larger models on many fewer tokens than is typical. As a consequence, although GPT-3 3B is almost 10x larger than RoBERTa-Large (355M params), both models took roughly 50 petaflop/s-days of compute during pre-training. Methodology for these calculations can be found in the Appendix. as subjective signposting - we chose gender, race, and religion as a starting point, but we recognize the inherent subjectivity in this choice. Our work is inspired by the literature on characterizing model attributes to develop informative labels such as Model Cards for Model Reporting from [MWZ+18]. Ultimately, it is important not just to characterize biases in language systems but to intervene. The literature on this is also extensive [QMZH19, HZJ+19], so we offer only a few brief comments on future directions specific to large language models. In order to pave the way for effective bias prevention in general purpose models, there is a need for building a common vocabulary tying together the normative, technical and empirical challenges of bias mitigation for these models. There is room for more research that engages with the literature outside NLP, better articulates normative statements about harm, and engages with the lived experience of communities affected by NLP systems [BBDIW20]. Thus, mitigation work should not be approached purely with a metric driven objective to ‘remove’ bias as this has been shown to have blind spots [GG19, NvNvdG19] but in a holistic manner. 7.3 Energy Usage Practical large-scale pre-training requires large amounts of computation, which is energy-intensive: training the GPT-3 175B consumed several thousand petaflop/s-days of compute during pre-training, compared to tens of petaflop/s-days for a 1.5B parameter GPT-2 model (Figure 7.2). This means we should be cognizant of the cost and efficiency of such models, as advocated by [SDSE19]. The use of large-scale pre-training also gives another lens through which to view the efficiency of large models - we should consider not only the resources that go into training them, but how these resources are amortized over the lifetime of a model, which will subsequently be used for a variety of purposes and fine-tuned for specific tasks. Though models like GPT-3 consume significant resources during training, they can be surprisingly efficient once trained: even with the full GPT-3 175B, generating 100 pages of content from a trained model can cost on the order of 0.4 kW-hr, or only a few cents in energy costs. Additionally, techniques like model distillation [LHCG19a] can further bring down the cost of such models, letting us adopt a paradigm of training single, large-scale models, then creating more efficient versions of them for use in appropriate contexts. Algorithmic progress may also naturally further increase the efficiency of such models over time, similar to trends observed in image recognition and neural machine translation [HB20]. 7.4 News Generation We test GPT-3’s ability to generate synthetic “news articles” by prompting the model with a context of three previous news articles and the title and subtitle of a proposed article to generate. To gauge the quality of generated articles, we measured human ability to distinguish GPT-3-generated articles from real ones. Similar work has been carried out by Kreps et al. [KMB20] and Zellers et al. [ZHR+19]. Generative language models are trained to match the distribution of content generated by humans, so the (in)ability of humans to distinguish the two is a potentially important measure of quality.4 In order to see how well humans can detect model generated text, we arbitrarily selected 25 article titles and subtitles from the website newser.com (mean length: 215 words). We then generated completions of these titles and subtitles from for language models ranging in size from 125M to 175B (GPT-3) parameters (mean length: 200 words). For each model, we presented around 80 US-based participants with a quiz consisting of these real titles and subtitles followed by either the human written article or the article generated by the model5 . Participants were asked to select whether the article was “very likely written by a human”, “more likely written by a human”, “I don’t know”, “more likely written by a machine”, or “very likely written by a machine”. The articles we selected were not in the models’ training data and the model outputs were formatted and selected programmatically to prevent human cherry-picking. All models used the same context to condition outputs on and were pre-trained with the same context size and the same article titles and subtitles were used as prompts for each model. However, we also ran an experiment to control for participant effort and attention that followed the same format but involved intentionally bad model generated articles. This was done by generating articles from a “control model”: a 160M parameter model with no context and increased output randomness. Mean human accuracy (the ratio of correct assignments to non-neutral assignments per participant) at detecting that the intentionally bad articles were model generated was ∼ 86% where 50% is chance level performance. By contrast, mean human accuracy at detecting articles that were produced by the 175B parameter model was barely above chance at ∼ 52% (see Table 7.3).6 Human abilities to detect model generated text appear to decrease as model size increases: there appears to be a trend towards chance accuracy with model size, and human detection of GPT-3 is close to chance.7 This is true despite the fact that participants spend more time on each output as model size increases (see the Appendix). Examples of synthetic articles from GPT-3 are given in Figures 7.4 and 7.5. 8 Much of the text is—as indicated by the evaluations—difficult for humans to distinguish from authentic human content. Factual inaccuracies can be an indicator that an article is model generated since, unlike human authors, the models have no access to the specific facts that the article titles refer to or when the article was written. Other indicators include repetition, non sequiturs, and unusual phrasings, though these are often subtle enough that they are not noticed. Related work on language model detection by Ippolito et al. [IDCBE19] indicates that automatic discriminators like G R O V E R [ZHR+19] and GLTR [GSR19] may have greater success at detecting model generated text than human evaluators. Automatic detection of these models may be a promising area of future research. Ippolito et al. [IDCBE19] also note that human accuracy at detecting model generated text increases as humans observe more tokens. To do a preliminary investigation of how good humans are at detecting longer news articles generated by GPT-3 175B, we selected 12 world news articles from Reuters with an average length of 569 words and generated completions of these articles from GPT-3 with an average length of 498 words (298 words longer than our initial experiments). Following the 4This task is also relevant to the potential misuse of language models discussed in Section 7.1. 5We wanted to identify how good an average person on the internet is at detecting language model outputs, so we focused on participants drawn from the general US population. See the Appendix for details. 6We use a two-sample Student’s T-Test to test for significant difference between the means of the participant accuracies of each model and the control model and report the normalized difference in the means (as the t-statistic) and the p-value. 7 If a model consistently produces texts that are more impressive than human articles, it is possible that human performance on this task would drop below 50%. Indeed, many individual participants scored below 50% on this task. 8Additional non-news samples can be found in the Appendix. Mean accuracy 95% Confidence Interval (low, hi) t compared to control (p-value) “I don’t know” assignments Control (deliberately bad model) 86% 83%–90% - 3.6 % GPT-3 Small 76% 72%–80% 3.9 (2e-4) 4.9% GPT-3 Medium 61% 58%–65% 10.3 (7e-21) 6.0% GPT-3 Large 68% 64%–72% 7.3 (3e-11) 8.7% GPT-3 XL 62% 59%–65% 10.7 (1e-19) 7.5% GPT-3 2.7B 62% 58%–65% 10.4 (5e-19) 7.1% GPT-3 6.7B 60% 56%–63% 11.2 (3e-21) 6.2% GPT-3 13B 55% 52%–58% 15.3 (1e-32) 7.1% GPT-3 175B 52% 49%–54% 16.9 (1e-34) 7.8% Table 7.3: Human accuracy in identifying whether short (∼200 word) news articles are model generated. We find that human accuracy (measured by the ratio of correct assignments to non-neutral assignments) ranges from 86% on the control model to 52% on GPT-3 175B. This table compares mean accuracy between five different models, and shows the results of a two-sample T-Test for the difference in mean accuracy between each model and the control model (an unconditional GPT-3 Small model with increased output randomness). Mean accuracy 95% Confidence Interval (low, hi) t compared to control (p-value) “I don’t know” assignments Control 88% 84%–91% - 2.7% GPT-3 175B 52% 48%–57% 12.7 (3.2e-23) 10.6% Table 7.4: People’s ability to identify whether ∼ 500 word articles are model generated (as measured by the ratio of correct assignments to non-neutral assignments) was 88% on the control model and 52% on GPT-3 175B. This table shows the results of a two-sample T-Test for the difference in mean accuracy between GPT-3 175B and the control model (an unconditional GPT-3 Small model with increased output randomness). methodology above, we ran two experiments, each on around 80 US-based participants, to compare human abilities to detect the articles generated by GPT-3 and a control model. We found that mean human accuracy at detecting the intentionally bad longer articles from the control model was ∼ 88%, while mean human accuracy at detecting the longer articles that were produced by GPT-3 175B was still barely above chance at ∼ 52% (see Table 7.4). This indicates that, for news articles that are around 500 words long, GPT-3 continues to produce articles that humans find difficult to distinguish from human written news articles.",Broader Impacts,4337,150,,,TRUE,TRUE,FALSE,Language Models are Few-Shot Learners,Applications -> Natural Language Processing,Algorithms -> Few-Shot Learning; Algorithms -> Large Scale Learning; Algorithms -> Meta-Learning; Algorithms -> Unsupervised Learning; Deep Learning; Deep Learning -> Generative Models,Natural language processing,"['Tom B Brown', ' Benjamin Mann', ' Nick Ryder', ' Melanie Subbiah', ' Jared D Kaplan', ' Prafulla Dhariwal', ' Arvind Neelakantan', ' Pranav Shyam', ' Girish Sastry', ' Amanda Askell', ' Sandhini Agarwal', 'Voss', ' Gretchen M Krueger', ' Tom Henighan', ' Rewon Child', ' Aditya Ramesh', ' Daniel Ziegler', ' Jeffrey Wu', ' Clemens Winter', ' Chris Hesse', ' Mark Chen', ' Eric Sigler', ' Mateusz Litwin', ' Scott Gray', ' Benjamin Chess', ' Jack Clark', ' Christopher Berner', ' Sam McCandlish', ' Alec Radford', ' Ilya Sutskever', ' Dario Amodei']","{'Google Brain', 'Johns Hopkins University', 'OpenAI'}",1,1,1,{'USA'}
Margins are Insufficient for Explaining Gradient Boosting,"Allan Grønlund, Lior Kamma, Kasper Green Larsen",Margins are Insufficient for Explaining Gradient Boosting,146f7dd4c91bc9d80cf4458ad6d6cd1b,https://proceedings.neurips.cc/paper/2020/file/146f7dd4c91bc9d80cf4458ad6d6cd1b-Paper.pdf,"In this work, we have empirically shown that gradient boosters produce voting classifiers where many base learners make predictions of small magnitude. We then used this observation to prove stronger generalization bounds that better explain the practical performance of gradient boosters. We hope and believe that our findings may not only advance our theoretical understanding of boosting algorithms, but potentially also lead to algorithms with better accuracy by using regularization inspired by our new generalization bound or more directly optimizing it.",Statement of potential broader impact,81,3,,,FALSE,TRUE,FALSE,Margins are Insufficient for Explaining Gradient Boosting,Algorithms -> Boosting and Ensemble Methods,Theory,Theory (including computational and statistical analyses),"['Allan Grønlund', ' Lior Kamma', ' Kasper Green Larsen']","{'Aarhus University', 'Aarhus University, MADALGO'}",1,0,0,{'Denmark'}
Fourier-transform-based attribution priors improve the interpretability and stability of deep learning models for genomics,"Alex Tseng, Avanti Shrikumar, Anshul Kundaje",Fourier-transform-based attribution priors improve the interpretability and stability of deep learning models for genomics,1487987e862c44b91a0296cf3866387e,https://proceedings.neurips.cc/paper/2020/file/1487987e862c44b91a0296cf3866387e-Paper.pdf,"In this work, we focus on one primary application of deep learning models in genomics: to decipher the regulatory code of DNA by interpreting models trained on genome-wide molecular profiling experiments. These interpretations provide directed hypotheses for follow-up validation experiments [4], thereby improving our understanding of fundamental biology. Another important clinical application of these same models is to predict and interpret the molecular impact of DNA sequence mutations and variants in genomes of healthy and diseased individuals [2, 3, 5]. This clinical application can have significant positive impact in genomic medicine. However, issues regarding the stability and biological accuracy of the interpretations derived from these models have not been explored in a systematic manner. Our work is one of the first attempts to addresses these issues by directly imposing a restriction on models at training-time, explicitly encouraging model learning to be more interpretable. Our method can be used in any genomic deep learning model being trained by backpropagation, where the drivers of genomic signal are motifs. This allows us to more confidently identify the sequence patterns that drive genomic regulation, including: 1) the discovery of protein-binding sequences; 2) the discovery of specific genome regulatory sequences; and 3) motif discovery and motif instance calling. This marks an important first step forward in the improvement of genomic deep learning models for scientific discovery. In the future, we hope to extend this work to address the challenges associated with using these types of deep learning models for clinical genomic variant/mutation interpretation. To our knowledge, this work is also the first to utilize Fourier transforms as an attribution prior. Although our application was limited to genomics, the expectation that input attributions should occur smoothly and in consecutive regions is prevalent in many other fields, as well. Additionally, Fourier analysis is a technique commonly employed in signal and image processing (e.g. frequency filtering). Thus, we also suspect that a Fourier-based attribution prior like the one described here may engender significant improvements in performance, stability, and interpretability in these other domains.",Broader Impact,335,14,,,FALSE,TRUE,FALSE,Fourier-transform-based attribution priors improve the interpretability and stability of deep learning models for genomics,Applications -> Computational Biology and Bioinformatics,"Deep Learning -> Visualization, Interpretability, and Explainability","Other applications (e.g., robotics, biology, climate, finance)","['Alex Tseng', ' Avanti Shrikumar', ' Anshul Kundaje']",{'Stanford University'},1,0,0,{'USA'}
MomentumRNN: Integrating Momentum into Recurrent Neural Networks,"Tan Nguyen, Richard Baraniuk, Andrea Bertozzi, Stanley Osher, Bao Wang",MomentumRNN: Integrating Momentum into Recurrent Neural Networks,149ef6419512be56a93169cd5e6fa8fd,https://proceedings.neurips.cc/paper/2020/file/149ef6419512be56a93169cd5e6fa8fd-Paper.pdf,"Recurrent neural net (RNN) is among the most important classes of deep learning models. Improving training efficiency and generalization performance of RNNs not only advances image classification and language modeling but also benefits epidemiological models for pandemic disease prediction. RNNs have also been successfully used for the molecular generation [29]. Developing better RNNs that enable modeling of long term dependency, such as our Momentum RNN, has the potential to facilitate life science research. In order to fullfill that potential, more development is needed. For example, the current MomentumRNN requires calibration of the momentum and step size-related hyperparameters; developing an adaptive momentum for MomentumRNN is of great research interest. Finally, we claim that this paper does not have any ethical issue or leverage biases in data.",6 Broader Impact and Ethical Considerations,125,7,,,FALSE,FALSE,FALSE,MomentumRNN: Integrating Momentum into Recurrent Neural Networks,Deep Learning -> Recurrent Networks,Deep Learning,Deep learning,"['Minh Nguyen', ' Richard Baraniuk', ' Andrea Bertozzi', ' Stanley Osher', ' Bao Wang']","{'UCLA', 'Rice University'}",1,0,0,{'USA'}
Marginal Utility for Planning in Continuous or Large Discrete Action Spaces,"Zaheen Ahmad, Levi Lelis, Michael Bowling",Marginal Utility for Planning in Continuous or Large Discrete Action Spaces,14da15db887a4b50efe5c1bc66537089,https://proceedings.neurips.cc/paper/2020/file/14da15db887a4b50efe5c1bc66537089-Paper.pdf,"Our work is likely to increase the overall robustness and efficiency of a broad range of fundamental search algorithms used in decision making. These search algorithms have been applied to a wide array of strategic domains such as security, scheduling and routing. Highly performant search provides improved strategic capabilities to those who employ it, lending them a competitive edge in their respective domains. As such, the societal impacts, both beneficial and harmful, of search algorithms depend on how these tools are used. We may observe increased social welfare if efficient search is used to optimize the allocation of vital resources, such as medical equipment during a pandemic. On the other hand, if accessible to those serving their own self-interests, they may monopolize markets and adversely affect the economy.",Impact Statement,128,6,,,FALSE,FALSE,FALSE,Marginal Utility for Planning in Continuous or Large Discrete Action Spaces,Reinforcement Learning and Planning -> Planning,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Zaheen F Ahmad', ' Levi Lelis', ' Michael Bowling']","{'Universidade Federal de Viçosa', 'University of Alberta / DeepMind', 'University of Alberta'}",1,1,1,"{'Canada', 'UK', 'Brazil'}"
Projected Stein Variational Gradient Descent,"Peng Chen, Omar Ghattas",Projected Stein Variational Gradient Descent,14faf969228fc18fcd4fcf59437b0c97,https://proceedings.neurips.cc/paper/2020/file/14faf969228fc18fcd4fcf59437b0c97-Paper.pdf,"The proposed algorithm applies to high-dimensional Bayesian inference problems whose posterior effectively differs from the prior in a low-dimensional subspace discovered by the gradient information matrix, which is generally the case due to the fundamental property of the ill-posedness or over- parametrization of the inference problems. As one example, we applied the algorithm to Bayesian inference of the COVID-19 pandemics, which is expected to bring impact on learning the spread of the virus. However, for intrinsically high-dimensional problems, e.g., wave propagation in high frequency, a direct application of the proposed algorithm may not effectively alleviate the curse of dimenaionlity. It needs to be further extended by exploiting other properties such as sparsity, conditional independence, low-dimensionality with map transformation, etc. Impact on ethical aspects and future societal consequences may not be applicable here.",Broader Impact,132,5,,,FALSE,FALSE,FALSE,Projected Stein Variational Gradient Descent,Probabilistic Methods -> Variational Inference,Probabilistic Methods -> Bayesian Nonparametrics,Probabilistic methods and inference,"['Peng Chen', ' Omar Ghattas']",{'The University of Texas at Austin'},1,0,0,{'USA'}
Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks,"Mohammadreza Mousavi Kalan, Zalan Fabian, Salman Avestimehr, Mahdi Soltanolkotabi",Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks,151d21647527d1079781ba6ae6571ffd,https://proceedings.neurips.cc/paper/2020/file/151d21647527d1079781ba6ae6571ffd-Paper.pdf,"While our work is theoretical/foundations in nature let us discuss a few ways in which it may have broader impacts. In this paper, we characterize a lower bound for transfer learning in the context of linear models and one-hidden layer neural networks. More specifically, we provide a lower bound for target generalization error in terms of the number of source and target tasks and an appropriately defined transfer distance between the source and target tasks. Given the amount of effort dedicated to data collection, curation, and storage, a precise understanding of the amount of data needed may help utilize a variety of resources more effectively. Moreover, our results may guide practitioners to when there is no hope of knowledge transfer from one domain to another. This may help avoid unwarranted generalizations from one situation/environment to unrelated instances. On the other hand, it is worth emphasizing that this paper focuses on shallow linear/neural network models and does not capture more realistic Deep Neural Network (DNN) models typically used in practice. Therefore, one has to be cautious in over-interpreting the results of this paper for general DNN models.",Broader Impact,186,8,,,FALSE,FALSE,FALSE,Minimax Lower Bounds for Transfer Learning with Linear and One-hidden Layer Neural Networks,Theory -> Information Theory,Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Mir Mohammadreza Mousavi Kalan', ' Zalan Fabian', ' Salman Avestimehr', ' Mahdi Soltanolkotabi']","{'University of Southern California', 'University of Southern california'}",1,0,0,{'USA'}
SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks,"Fabian Fuchs, Daniel Worrall, Volker Fischer, Max Welling",SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks,15231a7ce4ba789d13b722cc5c955834,https://proceedings.neurips.cc/paper/2020/file/15231a7ce4ba789d13b722cc5c955834-Paper.pdf,"The main contribution of the paper is a mathematically motivated attention mechanism which can be used for deep learning on point cloud based problems. We do not see a direct potential of negative impact to the society. However, we would like to stress that this type of algorithm is inherently suited for classification and regression problems on molecules. The SE(3)-Transformer therefore lends itself to application in drug research. One concrete application we are currently investigating is to use the algorithm for early-stage suitability classification of molecules for inhibiting the reproductive cycle of the coronavirus. While research of this sort always requires intensive testing in wet labs, computer algorithms can be and are being used to filter out particularly promising compounds from large databases of millions of molecules.",Broader Impact,127,6,,,FALSE,FALSE,FALSE,SE(3)-Transformers: 3D Roto-Translation Equivariant Attention Networks,Deep Learning -> Attention Models,Algorithms -> Relational Learning; Algorithms -> Representation Learning; Deep Learning -> CNN Architectures,Theory (including computational and statistical analyses),"['Fabian Fuchs', ' Daniel Worrall', ' Volker Fischer', ' Max Welling']","{'University of Amsterdam', 'University of Amsterdam / Qualcomm AI Research', 'Robert Bosch GmbH, Bosch Center for Artificial Intelligence', 'University of Oxford'}",1,1,1,"{'UK', 'USA', 'Netherlands', 'Germany'}"
On the equivalence of molecular graph convolution and molecular wave function with poor basis set,"Masashi Tsubaki, Teruyasu Mizoguchi",On the equivalence of molecular graph convolution and molecular wave function with poor basis set,1534b76d325a8f591b52d302e7181331,https://proceedings.neurips.cc/paper/2020/file/1534b76d325a8f591b52d302e7181331-Paper.pdf,This study will provide benefit for ML researchers who are interested in quantum physics/chemistry and applications for materials science/informatics.,Broader Impact,19,1,FALSE,FALSE,FALSE,FALSE,FALSE,On the equivalence of molecular graph convolution and molecular wave function with poor basis set,Deep Learning -> Supervised Deep Networks,,"Other applications (e.g., robotics, biology, climate, finance)","['Masashi Tsubaki', 'National Institute of Advanced Industrial Science and Technology', ' Teruyasu Mizoguchi']","{'AIST', 'University of Tokyo'}",1,0,0,{'Japan'}
The Power of Predictions in Online Control,"Chenkai Yu, Guanya Shi, Soon-Jo Chung, Yisong Yue, Adam Wierman",The Power of Predictions in Online Control,155fa09596c7e18e50b58eb7e0c6ccb4,https://proceedings.neurips.cc/paper/2020/file/155fa09596c7e18e50b58eb7e0c6ccb4-Paper.pdf,"Linear quadratic control is a common and powerful model with a variety of commercial and industrial applications, e.g., in robotics, chemical process control, and energy systems. This paper provides new  fundamental insights about the role of predictions in online linear quadratic control with disturbances and provides the first finite time performance guarantees for the most commonly used policy in the linear quadratic setting, model predictive control (MPC). The guarantees provided by the theoretical analysis in this paper offer the potential for ensuring safety and robustness in industry applications where predictions are common and MPC is used. However, like many other theoretical contributions, this paper’s results are limited to its assumptions, e.g., linear system and fixed system parameters { A, B, Q, R } . The performance of MPC and the fundamental limits in other scenarios, e.g., nonlinear dynamics or time-variant { A, B, Q, R } , are still open research problems. We see no ethical concerns related to the results in this paper.",Broader Impact,164,6,,,FALSE,FALSE,FALSE,The Power of Predictions in Online Control,Theory -> Control Theory,Algorithms -> Online Learning; Reinforcement Learning and Planning -> Decision and Control,"control theory, online learning","['Chenkai Yu', ' Guanya Shi', 'Jo Chung', ' Yisong Yue', ' Adam Wierman']","{'California Institute of Technology', 'Caltech', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Learning Affordance Landscapes for Interaction Exploration in 3D Environments,"Tushar Nagarajan, Kristen Grauman",Learning Affordance Landscapes for Interaction Exploration in 3D Environments,15825aee15eb335cc13f9b559f166ee8,https://proceedings.neurips.cc/paper/2020/file/15825aee15eb335cc13f9b559f166ee8-Paper.pdf,"Embodied agents that can explore environments in the absence of humans have broader applications in service robotics and assistive technology. Such robots could survey, and then give a quick rundown of a space for new users to, for example, alert them of appliances in a workspace, which of them are functional, and how these can be activated. It could also potentially warn users to avoid interaction with some objects if they are sharp, hot, or otherwise dangerous based on the robot’s own interactions with them. Deploying embodied agents in human spaces comes with challenges in safety — exploration agents than can “interact with everything” to discover functionality may inadvertently damage their environment or themselves, and privacy — navigating human-centric spaces requires agents to be sensitive of people and personal belongings. Careful consideration of these issues while designing embodied agent policies is essential for deploying these agents in the real world to collaborate with people.",6 Broader Impact,154,5,,,FALSE,FALSE,FALSE,Learning Affordance Landscapes for Interaction Exploration in 3D Environments,Applications -> Computer Vision,"Applications -> Visual Scene Analysis and Interpretation; Data, Challenges, Implementations, and Software -> Virtual Environments",Vision,"['Tushar Nagarajan', ' Kristen Grauman']","{'University of Texas at Austin', 'UT Austin'}",1,0,0,{'USA'}
Cooperative Multi-player Bandit Optimization,"Ilai Bistritz, Nicholas Bambos",Cooperative Multi-player Bandit Optimization,15ae3b9d6286f1b2a489ea4f3f4abaed,https://proceedings.neurips.cc/paper/2020/file/15ae3b9d6286f1b2a489ea4f3f4abaed-Paper.pdf,"This work is mainly theoretical in nature, introducing a new framework for distributed learning algorithms where each agent affects all of its peers through its actions. Therefore there are no specific ethical considerations relevant to this work. From a broader perspective, the work contributes to the growing field of multi-agent learning. Multi-agent learning can be thought of as the next wave of machine learning, where the isolated black box machines will start interacting and learning from each other to form a large machine learning network. This shift involves automating more decision making processes, that will interact between themselves for our benefit. This, however, does not come without some application-specific ethical issues and concerns, as is already being discussed today for autonomous vehicles, that is a special case of multi-agent learning.",7 Broader Impact,130,6,,,FALSE,FALSE,FALSE,Cooperative Multi-player Bandit Optimization,Theory -> Game Theory and Computational Economics,Algorithms -> Bandit Algorithms,Theory (including computational and statistical analyses),"['Ilai Bistritz', ' Nicholas Bambos']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Tight First- and Second-Order Regret Bounds for Adversarial Linear Bandits,"Shinji Ito, Shuichi Hirahara, Tasuku Soma, Yuichi Yoshida",Tight First- and Second-Order Regret Bounds for Adversarial Linear Bandits,15bb63b28926cd083b15e3b97567bbea,https://proceedings.neurips.cc/paper/2020/file/15bb63b28926cd083b15e3b97567bbea-Paper.pdf,This is a theoretical work and does not present any foreseeable societal consequences.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Tight First- and Second-Order Regret Bounds for Adversarial Linear Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning; Optimization -> Convex Optimization; Optimization -> Discrete Optimization; Theory -> Computational Learning Theory,Theory (including computational and statistical analyses),"['Shinji Ito', ' Shuichi Hirahara', ' Tasuku Soma', ' Yuichi Yoshida']","{'University of Tokyo', 'NEC Corporation', 'National Institute of Informatics'}",1,1,1,{'Japan'}
Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign Dropout,"Zhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong, Henrik Kretzschmar, Yuning Chai, Dragomir Anguelov",Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign Dropout,16002f7a455a94aa4e91cc34ebdb9f2d,https://proceedings.neurips.cc/paper/2020/file/16002f7a455a94aa4e91cc34ebdb9f2d-Paper.pdf,"In this paper we presented GradDrop, a general algorithm that can be used as a modular addition to multitask models. At its core, our contribution is the development of a general machine learning algorithm without any assumptions of specific applications, so the potential broader impacts of our work is dependent on the application area. However, it is also true that multitask learning operates by attempting to leverage multiple sources of potentially disparate information and making joint predictions based on those sources. When applied correctly, multitask models can be less prone to bias/unfairness as they have access to a larger, more diverse source of information. However, when applied incorrectly, multitask models may end up reinforcing the same biases that we want to eliminate; imagine, for example, multitask models which make predictions separately for different subpopulations of the input dataset and due to lack of proper training dynamics end up overfitting to each in turn. Our proposed algorithm may have beneficial effects in combating such overfitting, as our algorithm is effective at finding joint solutions that consistently take all available information into account. As such, we believe that GradDrop will have a positive broader impact on machine learning work by providing ways to arrive at better regularized solutions that are more reflective of reality.",6 Broader Impacts,212,7,,,FALSE,FALSE,FALSE,Just Pick a Sign: Optimizing Deep Multitask Models with Gradient Sign Dropout,Algorithms -> Multitask and Transfer Learning,Applications -> Computer Vision; Deep Learning -> Supervised Deep Networks,Deep learning,,"{'Google Brain', 'Waymo', 'Waymo LLC'}",0,1,0,{'USA'}
A Loss Function for Generative Neural Networks Based on Watson’s Perceptual Model,"Steffen Czolbe, Oswin Krause, Ingemar Cox, Christian Igel",A Loss Function for Generative Neural Networks Based on Watson’s Perceptual Model,165a59f7cf3b5c4396ba65953d679f17,https://proceedings.neurips.cc/paper/2020/file/165a59f7cf3b5c4396ba65953d679f17-Paper.pdf,"The broader impact of our work is defined by the numerous applications of generative deep neural networks, for example the generation of realistic photographs and human faces, image-to-image translation with the special case of semantic-image-to-photo translation; face frontal view generation; generation of human poses; photograph editing, restoration and inpainting; and generation of super resolution images. A risk of realistic image generation is of course the ability to produce “deepfakes”. Generative neural networks can be used to replace a person in an existing image or video by someone else. While this technology has positive applications (e.g., in the movie industry and entertainment in general), it can be abused. We refer to a recent article by Kietzmann et al. for an overview discussing positive and negative aspects, including potential misuse that can affect almost anybody: “With such a powerful technology and the increasing number of images and videos of all of us on social media, anyone can become a target for online harassment, defamation, revenge porn, identity theft, and bullying — all through the use of deepfakes” [9]. We also refer to [9] for existing and potential commercial applications of deepfakes, such as software that allows consumers to “try on cosmetics, eyeglasses, hairstyles, or clothes virtually” and video game players to “insert their faces onto their favorite characters”. Our interest in generative neural networks, in particular variational autoencoders, is partially motivated by concrete applications in the analysis of remote sensing data. In a just started project, we will employ deep generative neural networks to the generation of geospatial data, which enables us to simulate the effect of human interaction w.r.t. ecosystems. The goal is to improve our understanding of these interactions, for example to analyse the influence of countermeasures such as afforestation in the context of climate change mitigation.",Broader impact,297,11,,,FALSE,FALSE,FALSE,A Loss Function for Generative Neural Networks Based on Watson’s Perceptual Model,Deep Learning -> Generative Models,Deep Learning -> Deep Autoencoders,Vision,"['Steffen Czolbe', ' Oswin Krause', ' Ingemar Cox', ' Christian Igel']","{'University of Copenhagen', 'University College London'}",1,0,0,"{'UK', 'Denmark'}"
Dynamic Fusion of Eye Movement Data and Verbal Narrations in Knowledge-rich Domains,"Ervine Zheng, Qi Yu, Rui Li, Pengcheng Shi, Anne Haake",Dynamic Fusion of Eye Movement Data and Verbal Narrations in Knowledge-Rich Domains,16837163fee34175358a47e0b51485ff,https://proceedings.neurips.cc/paper/2020/file/16837163fee34175358a47e0b51485ff-Paper.pdf,"The need to explore elements involved in human knowledge-based cognitive processing and fuse them with machine intelligence, empowered through computational processing of large-scale complex data, has been recognized by a wide spectrum of specialized domains, such as medicine, science, social psychology, security intelligence, and more. This work will provide both theoretical underpinning and empirical evaluation of infusing human expertise into the design of computing systems, enabling them to collectively tackle highly challenging tasks in specialized domains that neither could individually perform to satisfaction. The research can be broadly applicable to diverse knowledge-rich domains, where the synergy of human and machine intelligence is essential to tackle highly complex computational tasks.",Broader Impact,109,3,,,FALSE,FALSE,FALSE,Dynamic Fusion of Eye Movement Data and Verbal Narrations in Knowledge-rich Domains,Applications -> Health,Applications,Healthcare,"['Ervine Zheng', ' Qi Yu', ' Rui Li', ' Pengcheng Shi', ' Anne Haake']","{'rit', 'Rochester Institute of Technology'}",1,0,0,{'USA'}
Scalable Multi-Agent Reinforcement Learning for Networked Systems with Average Reward,"Guannan Qu, Yiheng Lin, Adam Wierman, Na Li",Scalable Multi-Agent Reinforcement Learning for Networked Systems with Average Reward,168efc366c449fab9c2843e9b54e2a18,https://proceedings.neurips.cc/paper/2020/file/168efc366c449fab9c2843e9b54e2a18-Paper.pdf,"This paper contributes to the theoretical foundations of multi-agent reinforcement learning, with the goal of developing tools that can apply to the control of networked systems. The work can potentially lead to RL-based algorithms for the adaptive control of cyber-physical systems, such as the power grid, smart traffic systems, communication systems, and other smart infrastructure systems. While the approach is promising, as with other all theoretical work, it is limited by its assumptions. Applications of the proposed algorithm in its current form should be considered cautiously since the analysis here focuses on efficiency and does not consider the issue of fairness. We see no ethical concerns related to this paper.",Broader Impact,110,5,,,FALSE,FALSE,FALSE,Scalable Multi-Agent Reinforcement Learning for Networked Systems with Average Reward,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Guannan Qu', ' Yiheng Lin', ' Adam Wierman', ' Na Li']","{'California Institute of Technology', 'Harvard University'}",1,0,0,{'USA'}
Optimizing Neural Networks via Koopman Operator Theory,"Akshunna S. Dogra, William Redman",Optimizing Neural Networks via Koopman Operator Theory,169806bb68ccbf5e6f96ddc60c40a044,https://proceedings.neurips.cc/paper/2020/file/169806bb68ccbf5e6f96ddc60c40a044-Paper.pdf,"Koopman training is an exciting, novel approach to optimizing neural networks. We believe it can be generally used to reduce the computational costs consumed during the training phase, a claim our complexity calculations and numerical examples support. These savings, which more advanced methods of Koopman training should increase, may translate into lowering the monetary costs, time, and energy needed to optimize neural networks and allow those without significant funding and computing power (e.g. researchers at non-R1 universities and small companies) to train neural networks to higher utility. As NNs have become a staple in an ever growing number of academic/commercial fields, Koopman training has the potential for wide impact. Additionally, our work should generalize to other types of complicated, iterative optimization dependent problems.  Finally, this paper is among a growing minority of work that highlights the power viewing neural networks from a dynamical systems perspective can bring ([9, 15, 16, 43]). We hope that this work inspires future exchanges between the neural network and dynamical systems communities.",Broader Impact,167,7,,,FALSE,FALSE,FALSE,Optimizing Neural Networks via Koopman Operator Theory,Deep Learning -> Optimization for Deep Networks,Algorithms -> Dynamical Systems,Optimization Methods (continuous or discrete),"['Akshunna Dogra', ' William T Redman']","{'Harvard University', 'UC Santa Barbara'}",1,0,0,{'USA'}
SVGD as a kernelized Wasserstein gradient flow of the chi-squared divergence,"Sinho Chewi, Thibaut Le Gouic, Chen Lu, Tyler Maunu, Philippe Rigollet",SVGD as a kernelized Wasserstein gradient flow of the chi-squared divergence,16f8e136ee5693823268874e58795216,https://proceedings.neurips.cc/paper/2020/file/16f8e136ee5693823268874e58795216-Paper.pdf,"The sampling algorithms designed in this paper have the potential to improve a wide variety of Bayesian methods and therefore have an indirect impact on various domains such as health and medicine where such methods are pervasive. Sampling algorithms are also used for the generation of automated spam messages, which have potentially negative effects on society. Since this paper is primarily focused on theory, these questions are not addressed here.",Broader impact,70,3,,,FALSE,FALSE,FALSE,SVGD as a kernelized Wasserstein gradient flow of the chi-squared divergence,Probabilistic Methods -> MCMC,,Theory (including computational and statistical analyses),"['Sinho Chewi', ' Thibaut Le Gouic', ' Chen Lu', ' Tyler Maunu', ' Philippe Rigollet']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Adversarial Robustness of Supervised Sparse Coding,"Jeremias Sulam, Ramchandran Muthukumar, Raman Arora",Adversarial Robustness of Supervised Sparse Coding,170f6aa36530c364b77ddf83a84e7351,https://proceedings.neurips.cc/paper/2020/file/170f6aa36530c364b77ddf83a84e7351-Paper.pdf,"This work contributes to the theoretical understanding of the limitations and achievable robustness guarantees for supervised learning models. Our results can therefore provide tools that could be deployed in sensitive settings where these types of guarantees are a priority. On a broader note, this work advocates for the precise analysis and characterization of the data-driven features computed by modern machine learning models, and we hope our results facilitate their generalization to other more complex models.",Broader Impact,75,3,,,FALSE,FALSE,FALSE,Adversarial Robustness of Supervised Sparse Coding,Algorithms -> Adversarial Learning,Algorithms -> Sparse Coding and Dimensionality Expansion,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Jeremias Sulam', ' Ramchandran Muthukumar', ' Raman Arora']",{'Johns Hopkins University'},1,0,0,{'USA'}
Differentiable Meta-Learning of Bandit Policies,"Craig Boutilier, Chih-wei Hsu, Branislav Kveton, Martin Mladenov, Csaba Szepesvari, Manzil Zaheer",Differentiable Meta-Learning of Bandit Policies,171ae1bbb81475eb96287dd78565b38b,https://proceedings.neurips.cc/paper/2020/file/171ae1bbb81475eb96287dd78565b38b-Paper.pdf,"We develop bandit-style exploration algorithms that can be easily trained on historical data. This fundamentally alters the current prevalent approach to bandit algorithm design, which is by theory. Bandit algorithms are often deployed in user-facing domains. However, we do not propose any new domain. So our impact on users should be limited to those that already exist. Beyond this, we are not aware of any societal consequences of our work, such as on welfare, fairness, or privacy.",Broader Impact,77,6,,,FALSE,FALSE,FALSE,Differentiable Meta-Learning of Bandit Policies,Algorithms -> Bandit Algorithms,Algorithms -> Meta-Learning; Algorithms -> Online Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Craig Boutilier', 'wei Hsu', ' Branislav Kveton', ' Martin Mladenov', ' Csaba Szepesvari', ' Manzil Zaheer']","{'DeepMind / University of Alberta', 'Google', ' Google Research', 'Google Research'}",1,1,1,"{'Canada', 'UK', 'USA'}"
Biologically Inspired Mechanisms for Adversarial Robustness,"Manish Vuyyuru Reddy, Andrzej Banburski, Nishka Pant, Tomaso Poggio",Biologically Inspired Mechanisms for Adversarial Robustness,17256f049f1e3fede17c7a313f7657f4,https://proceedings.neurips.cc/paper/2020/file/17256f049f1e3fede17c7a313f7657f4-Paper.pdf,"In terms of ethical aspects and future societal consequences, achieving adversarially robust models is of critical importance to deployment of autonomous technologies we can trust. Among some of the positive outcomes we could count autonomous vehicles immune to misleading by malicious agents, better trust in medical imaging applications and any other discipline to which AI can be applied and which requires safety guarantees. This naturally also comes with negative impacts, from reducing jobs available to humans, to potentially making surveillance technologies much more difficult to avoid, allowing authoritarian regimes a much tighter control over their citizens, as well as enabling progress in autonomous weapon systems. Additionally, every defense against adversarial attacks that has been so far proposed has eventually been found to be vulnerable. If such vulnerabilities are found in increasingly more accurate models of primate vision, this could suggest the possibility of the existence of dynamically changing adversarial attacks that would fool humans, leading to potentially new camouflage technologies.",Broader Impact,160,5,,,FALSE,FALSE,FALSE,Biologically Inspired Mechanisms for Adversarial Robustness,Algorithms -> Adversarial Learning,Deep Learning -> Biologically Plausible Deep Networks; Neuroscience and Cognitive Science -> Visual Perception,Adversarial Robustness & Computational Neuroscience,"['Manish Vuyyuru Reddy', ' Andrzej Banburski', ' Nishka Pant', ' Tomaso Poggio']","{'MIT', 'Harvard'}",1,0,0,{'USA'}
Statistical-Query Lower Bounds via Functional Gradients,"Surbhi Goel, Aravind Gollakota, Adam Klivans",Statistical-Query Lower Bounds via Functional Gradients,17257e81a344982579af1ae6415a7b8c,https://proceedings.neurips.cc/paper/2020/file/17257e81a344982579af1ae6415a7b8c-Paper.pdf,"As deep learning techniques continue to grow rapidly in real-world usage and importance, the study of their theoretical guarantees has become important as well. This paper gives theoretical results concerning some basic primitives of neural networks, and as such contributes to our growing rigorous understanding of deep learning. The lower bounds in this paper address a model of learning in which there is arbitrary noise in the labels, as is common in some settings. They add to the body of work demonstrating that even very simple neural networks can fail dramatically to have good theoretical guarantees, providing some guidance as to conditions under which neural networks might perform particularly poorly even in practice. Another area of practical importance that our results relate to is that of differentially private data anal- ysis/release, where the SQ complexity of agnostic learning is known to characterize the complexity of privately answering a class of queries up to small error [GHRU13, DR14].",Broader Impact,157,5,,,FALSE,FALSE,FALSE,Statistical-Query Lower Bounds via Functional Gradients,Theory -> Computational Learning Theory,,Theory (including computational and statistical analyses),"['Surbhi Goel', ' Aravind Gollakota', ' Adam Klivans']","{'UT Austin', 'The University of Texas at Austin', 'University of Texas at Austin'}",1,0,0,{'USA'}
Near-Optimal Reinforcement Learning with Self-Play,"Yu Bai, Chi Jin, Tiancheng Yu",Near-Optimal Reinforcement Learning with Self-Play,172ef5a94b4dd0aa120c6878fc29f70c,https://proceedings.neurips.cc/paper/2020/file/172ef5a94b4dd0aa120c6878fc29f70c-Paper.pdf,"As this is a theoretical contribution, we do not envision that our direct results will have a tangible societal impact. Our broader line of inquiry could impact a line of thinking about how to design more sample-efficient algorithms for multi-agent reinforcement learning, which could be useful towards making artificial intelligence more resource and energy efficient.",Broader Impact,55,2,TRUE,TRUE,FALSE,FALSE,FALSE,Near-Optimal Reinforcement Learning with Self-Play,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Exploration; Theory -> Statistical Learning Theory,Reinforcement learning and planning,"['Yu Bai', ' Chi Jin', ' Tiancheng Yu']","{'Salesforce Research', 'Princeton University', 'MIT '}",1,1,1,{'USA'}
Network Diffusions via Neural Mean-Field Dynamics,"Shushan He, Hongyuan Zha, Xiaojing Ye",Network Diffusions via Neural Mean-Field Dynamics,1730f69e6f66d5f0c741799e82351f81,https://proceedings.neurips.cc/paper/2020/file/1730f69e6f66d5f0c741799e82351f81-Paper.pdf,"This paper makes a significant contribution to the learning of structure and infection probabilities for diffusion networks, which is one of the central problems in the study of stochastic information propagation on large heterogeneous networks. The proposed neural mean-field (NMF) dynamics provide the first principled approach for inference and estimation problems using cascade data. NMF is shown to be a delay differential equation with proper approximation of memory integral using learnable time convolution operators, and the system reduces to a highly structured and interpretable recurrent neural network after time discretiztion. Potential applications include influence maximization, outbreak detection, and source identification.",Broader Impact,100,4,,,FALSE,FALSE,FALSE,Network Diffusions via Neural Mean-Field Dynamics,Applications -> Computational Social Science,Applications -> Activity and Event Recognition; Applications -> Time Series Analysis; Deep Learning -> Supervised Deep Networks,Deep learning,"['Shushan He', ' Hongyuan Zha', ' Xiaojing Ye']","{'Georgia Tech', 'Georgia State University'}",1,0,0,{'USA'}
Self-Distillation as Instance-Specific Label Smoothing,"Zhilu Zhang, Mert Sabuncu",Self-Distillation as Instance-Specific Label Smoothing,1731592aca5fb4d789c4119c65c10b4b,https://proceedings.neurips.cc/paper/2020/file/1731592aca5fb4d789c4119c65c10b4b-Paper.pdf,"In this paper, we offer a new interpretation of the self-distillation training framework, a commonly used technique for improved accuracy used among practitioners in the deep learning community, which allows us to gain some deeper understanding of the reasons for its success. With the ubiquity of deep learning in our society today and countless potential future applications of it, we believe our work can potentially bring positive impacts in several ways. Firstly, despite the empirical utility of distillation and numerous successful applications in many tasks and applications ranging from computer vision to natural language processing problems, we still lack a thorough understanding of why it works. In our opinion, blindly applying methods and algorithms without a good grasp on the underlying mechanisms can be dangerous. Our perspective offers a theoretically grounded explanation for its success that allows us to apply the techniques to real-world applications broadly with greater confidence. In addition, the proposed interpretation of distillation as a regularization to neural networks can potentially allow us to obtain models that are more generalizable and reliable. This is an extremely important aspect of applying deep learning to sensitive domains like healthcare and autonomous driving, in which wrong predictions made by machines can lead to catastrophic consequences. Moreover, our new experimental demonstration that models trained with the distillation process can potentially lead to better-calibrated models that can facilitate safer and more interpretable applications of neural networks. Indeed, for real-world classification tasks like disease diagnosis, in addition to accurate predictions, we need reliable estimates of the level of confidence of the predictions made, which is something that neural networks are lacking currently as pointed out by recent research. More calibrated models, in our opinion, enhances the explainability and transparency of neural network models. Lastly, we believe the introduced framework can stimulate further research on the regularization of deep learning models for better generalization and thus safer applications. It was recently demon- strated that deep neural networks do not seem to suffer from overfitting. Our finding suggests that overfitting can still occur, though in a different way than conventional wisdom, and deep learning can still benefit from regularization. As such, we encourage research into more efficient and principled forms of regularization to improve upon the distillation strategy. We acknowledge the risks associated with our work. To be more specific, our finding advocates for the use of priors for the regularization of neural networks. Despite the potentially better generalization performance of trained models, depending on the choice of priors used for training, unwanted bias can be inevitably introduced into the deep learning system, potentially causing issues of fairness and privacy.",Statement of the Potential Broader Impact,435,17,,,FALSE,FALSE,FALSE,Self-Distillation as Instance-Specific Label Smoothing,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Optimization for Deep Networks; Deep Learning -> Supervised Deep Networks,Deep learning,"['Zhilu Zhang', ' Mert Sabuncu']","{'Cornell', 'Cornell University'}",1,0,0,{'USA'}
Towards Problem-dependent Optimal Learning Rates,"Yunbei Xu, Assaf Zeevi",Towards Problem-dependent Optimal Learning Rates,174f8f613332b27e9e8a5138adb7e920,https://proceedings.neurips.cc/paper/2020/file/174f8f613332b27e9e8a5138adb7e920-Paper.pdf,This work is theoretical and does not present any foreseeable ethical consequence to the society.,Broader Impact,15,1,TRUE,FALSE,FALSE,FALSE,FALSE,Towards Problem-dependent Optimal Learning Rates,Theory -> Statistical Learning Theory,,Theory (including computational and statistical analyses),"['Yunbei Xu', ' Assaf Zeevi']",{'Columbia University'},1,0,0,{'USA'}
Cross-lingual Retrieval for Iterative Self-Supervised Training,"Chau Tran, Yuqing Tang, Xian Li, Jiatao Gu",Cross-lingual Retrieval for Iterative Self-Supervised Training,1763ea5a7e72dd7ee64073c2dda7a7a8,https://proceedings.neurips.cc/paper/2020/file/1763ea5a7e72dd7ee64073c2dda7a7a8-Paper.pdf,"Our work advances the state-of-the-art in unsupervised machine translation. For languages where labelled parallel data is hard to obtain, training methods that better utilize unlabeled data is key to unlocking better translation quality. This technique contributes toward the goal of removing language barriers across the world, particularly for the community speaking low resource languages. However, the goal is still far from being achieved, and more efforts from the community is needed for us to get there.  One common pitfall of mining-based techniques in machine translation systems, however, is that they tend to retrieve similar-but-not-exact matches. For example, since the terms ""US"" and ""Canada"" tends to appear in similar context, the token embedding for them could be close to each other, then at mining stage it could retrieve ""I want to live in the US"" as the translation instead of ""I want to live in Canada"". If the translation is over-fitted to these mined data, it could repeat the same mistake. We advise practitioners who apply mining-based techniques in production translation systems to be aware of this issue. More broadly the monolingual pretraining method could heavily be influenced by the crawled data. We will need to carefuly study the properties of the trained models and how they response to data bias such as profanity. In general, we need to further study historical biases and possible malicious data pollution attacks in the crawled data to avoid undesired behaviors of the learned models.",Broader Impact,240,11,,,FALSE,FALSE,FALSE,Cross-lingual Retrieval for Iterative Self-Supervised Training,Applications -> Natural Language Processing,Algorithms -> Unsupervised Learning,Natural language processing,"['Chau Tran', ' Yuqing Tang', ' Xian Li', ' Jiatao Gu']","{'Facebook', 'Facebook AI', 'Facebook Inc', 'Facebook AI Research'}",0,1,0,{'USA'}
Rethinking pooling in graph neural networks,"Diego Mesquita, Amauri Souza, Samuel Kaski",Rethinking pooling in graph neural networks,1764183ef03fc7324eb58c3842bd9a57,https://proceedings.neurips.cc/paper/2020/file/1764183ef03fc7324eb58c3842bd9a57-Paper.pdf,"Graph neural networks (GNNs) have become the de facto learning tools in many valuable domains such as social network analysis, drug discovery, recommender systems, and natural language process- ing. Nonetheless, the fundamental design principles behind the success of GNNs are only partially understood. This work takes a step further in understanding local pooling, one of the core design choices in many GNN architectures. We believe this work will help researchers and practitioners better choose in which directions to employ their time and resources to build more accurate GNNs.",Broader impact,88,4,,,FALSE,FALSE,FALSE,Rethinking pooling in graph neural networks,Algorithms -> Representation Learning,Algorithms -> Classification; Algorithms -> Structured Prediction; Deep Learning -> Embedding Approaches,Deep learning,"['Diego Mesquita', ' Amauri Souza', ' Samuel Kaski']","{'IFCE', 'Aalto University', 'Aalto University and University of Manchester'}",1,0,0,"{'France', 'Finland', 'UK'}"
Pointer Graph Networks,"Petar Veličković, Lars Buesing, Matthew Overlan, Razvan Pascanu, Oriol Vinyals, Charles Blundell",Pointer Graph Networks,176bf6219855a6eb1f3a30903e34b6fb,https://proceedings.neurips.cc/paper/2020/file/176bf6219855a6eb1f3a30903e34b6fb-Paper.pdf,"Our work evaluates the extent to which existing neural networks are potent reasoning systems, and the minimal ways (e.g. inductive biases / training regimes) to strengthen their reasoning capability. Hence our aim is not to outperform classical algorithms, but make their concepts accessible to neural networks. PGNs enable reasoning over edges not provided in the input, simplifying execution of any algorithm requiring a pointer-based data structure. PGNs can find direct practical usage if, e.g., they are pre-trained on known algorithms and then deployed on tasks which may require similar kinds of reasoning (with encoders/decoders “casting” the new problem into the PGN’s latent space). It is our opinion that this work does not have a specific immediate and predictable real-world application and hence no specific ethical risks associated. However, PGN offers a natural way to introduce domain knowledge (borrowed from data structures) into the learning of graph neural networks, which has the potential of improving their performance, particularly when dealing with large graphs. Graph neural networks have seen a lot of successes in modelling diverse real world problems, such as social networks, quantum chemistry, computational biomedicine, physics simulations and fake news detection. Therefore, indirectly, through improving GNNs, our work could impact these domains and carry over any ethical risks present within those works.",Broader Impact,212,8,,,FALSE,FALSE,FALSE,Pointer Graph Networks,Algorithms -> Relational Learning,Algorithms -> Classification; Algorithms -> Model Selection and Structure Learning; Algorithms -> Program Induction; Algorithms -> Representation Learning; Deep Learning -> Attention Models; Deep Learning -> Interaction-Based Deep Networks; Deep Learning -> Supervised Deep Networks,Neural Algorithmic Reasoning,"['Petar Veličković', ' Lars Buesing', ' Matthew Overlan', ' Razvan Pascanu', ' Oriol Vinyals', ' Charles Blundell']","{'Google DeepMind', 'DeepMind'}",0,1,0,{'UK'}
Gradient Regularized V-Learning for Dynamic Treatment Regimes,"Yao Zhang, Mihaela van der Schaar",Gradient Regularized V -Learning for Dynamic Treatment Regimes,17b3c7061788dbe82de5abe9f6fe22b3,https://proceedings.neurips.cc/paper/2020/file/17b3c7061788dbe82de5abe9f6fe22b3-Paper.pdf,"Our work can help to develop accurate and individualized decision-making system in many real-world applications, such as treatment recommendation. Our method is easy to use for machine learning practitioners since it simply relies on regularization of the underlying recurrent network models. However, Offline DTR or policy evaluation is still a challenging problem because we often do not have sufficient samples to estimate the outcomes for all the possible treatment plans over time. Given some datasets that are high-dimensional or have long treatment trajectories, we would need to combine methods that solve different challenges of DTR evaluation, such as putting constraints on treatment assignment mechanisms over time or selecting variables that are most likely to affect the treatment decisions. Our work focuses on a particular aspect of DTR evaluation and does not cover other aspects that are also important for the real-world applications of DTRs.",Broader Impact,144,5,,,FALSE,FALSE,FALSE,Gradient Regularized V-Learning for Dynamic Treatment Regimes,Probabilistic Methods -> Causal Inference,,Causality,"['Yao Zhang', ' Mihaela van der Schaar']",{'University of Cambridge'},1,0,0,{'UK'}
Faster Wasserstein Distance Estimation with the Sinkhorn Divergence,"Lénaïc Chizat, Pierre Roussillon, Flavien Léger, François-Xavier Vialard, Gabriel Peyré",Faster Wasserstein Distance Estimation with the Sinkhorn Divergence,17f98ddf040204eda0af36a108cbdea4,https://proceedings.neurips.cc/paper/2020/file/17f98ddf040204eda0af36a108cbdea4-Paper.pdf,"Broader impact statement does not apply for this paper, which is of theoretical nature.",Broader Impact,14,1,TRUE,FALSE,FALSE,FALSE,FALSE,Faster Wasserstein Distance Estimation with the Sinkhorn Divergence,Theory,Algorithms -> Unsupervised Learning; Theory -> Computational Learning Theory; Theory -> High-Dimensional Inference; Theory -> Regularization,Theory (including computational and statistical analyses),"['Lénaïc Chizat', ' Pierre Roussillon', ' Flavien Léger', 'Xavier Vialard', ' Gabriel Peyré']","{'CNRS', 'ENS', 'CNRS and ENS', 'University Gustave Eiffel'}",1,0,0,{'France'}
Forethought and Hindsight in Credit Assignment,"Veronica Chelu, Doina Precup, Hado P. van Hasselt",Forethought and Hindsight in Credit Assignment,18064d61b6f93dab8681a460779b8429,https://proceedings.neurips.cc/paper/2020/file/18064d61b6f93dab8681a460779b8429-Paper.pdf,"Our work deals with fundamental insights related to the nature of model-based reinforcement learning. The problem of building models of the world and planning with them to achieve desired objectives is of paramount importance for real world applications of intelligent systems. However, in this work, we do not focus on applications, but instead look at the problem from a theoretical and investigative angle and largely treat it conceptually. As such, we consider this not to be applicable in this setting.",Broader Impact,80,4,,,FALSE,FALSE,FALSE,Forethought and Hindsight in Credit Assignment,Reinforcement Learning and Planning -> Model-Based RL,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Planning,Reinforcement learning and planning,"['Veronica Chelu', ' Doina Precup', ' Hado van Hasselt']","{'McGill University / Mila / DeepMind Montreal', 'DeepMind', 'McGill University'}",1,1,1,"{'Canada', 'UK'}"
Robust Recursive Partitioning for Heterogeneous Treatment Effects with Uncertainty Quantification,"Hyun-Suk Lee, Yao Zhang, William Zame, Cong Shen, Jang-Won Lee, Mihaela van der Schaar",Robust Recursive Partitioning for Heterogeneous Treatment Effects with Uncertainty Quantification,1819020b02e926785cf3be594d957696,https://proceedings.neurips.cc/paper/2020/file/1819020b02e926785cf3be594d957696-Paper.pdf,"The understanding of treatment effects plays an important role in many areas, and especially in medicine and public policy. In both areas, it is often the case that the same treatment has different effects on different groups; hence subgroup analysis is called for. In medicine, subgroup analysis may make it possible to identify groups of patients (defined by covariates such as age, body mass index, blood pressure, etc.) suffering from a particular disease for whom a particular drug is effective and safe and other groups for whom the same drug is ineffective and unsafe. Similarly, subgroup analysis may make it possible to identify groups of patients for whom one course of treatment (e.g. a particular mode of radiotherapy or chemotherapy) is preferable (more likely to be successful with fewer side effects) to another. In public policy, subgroup analysis may make it possible to identify groups of people or geographic regions for which particular interventions (e.g., providing mosquito nets to combat malaria) are likely to be successful or unsuccessful. The method for subgroup analysis that is developed in this paper, R2P, is an enormous improvement over state-of-the-art methods and therefore has the potential to make enormous and widespread impact. Moreover, because R2P can make use of improvements in the underlying estimation methods, this impact may grow over time.",Broader Impact,217,7,,,TRUE,TRUE,FALSE,Robust Recursive Partitioning for Heterogeneous Treatment Effects with Uncertainty Quantification,Algorithms -> Uncertainty Estimation,,Probabilistic methods and inference,"['Suk Lee', ' Yao Zhang', ' William Zame', ' Cong Shen', 'Won Lee', ' Mihaela van der Schaar']","{'Sejong University', 'Yonsei University', 'UCLA', 'University of Cambridge', 'University of Virginia'}",1,0,0,"{'UK', 'South Korea', 'USA'}"
Rescuing neural spike train models from bad MLE,"Diego Arribas, Yuan Zhao, Il Memming Park",Rescuing neural spike train models from bad MLE,186b690e29892f137b4c34cfa40a3a4d,https://proceedings.neurips.cc/paper/2020/file/186b690e29892f137b4c34cfa40a3a4d-Paper.pdf,"Bridging the gap between statistical neuroscientific models such as autoregressive point processes and dynamical systems is a substantial challenge not only from the perspective of generative modelling but also in terms of allowing a dynamical interpretation, that carries with it all the niceties that are a ff orded by stochastic dynamical systems. As such, while the motivation we drew up on comes from neuroscience, modelling, simulating and analyzing point process dynamics has a broad applicability to biological sciences and other fields.Our method has potential use in modelling within social sciences, geophysics (e.g. earthquakes), astrophysics and finance. In many of those areas stable inference and simulation of future events would directly enable the ability to discern and shape social and economic trends, or e ff ect policy safeguarding against baleful events.",Broader Impact,130,3,,,FALSE,FALSE,FALSE,Rescuing neural spike train models from bad MLE,Neuroscience and Cognitive Science -> Spike Train Generation,Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and cognitive science,"['Diego M Arribas', ' Yuan Zhao', ' Il Memming Park']",{'Stony Brook University'},1,0,0,{'USA'}
Lower Bounds and Optimal Algorithms for Personalized Federated Learning,"Filip Hanzely, Slavomír Hanzely, Samuel Horváth, Peter Richtarik",Lower Bounds and Optimal Algorithms for Personalized Federated Learning,187acf7982f3c169b3075132380986e4,https://proceedings.neurips.cc/paper/2020/file/187acf7982f3c169b3075132380986e4-Paper.pdf,"The paper presents lower and upper complexity bounds for the personalized FL formulation (2). While the topic this paper studies—personalized FL—already has a significant societal impact since FL solutions have been and are being deployed in practice, our results are of a theoretical nature. Consequently, the broader impact discussion for this work specifically is not applicable.",Broader Impact,56,3,TRUE,FALSE,FALSE,FALSE,FALSE,Lower Bounds and Optimal Algorithms for Personalized Federated Learning,Optimization -> Convex Optimization,Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Filip Hanzely', ' Slavomír Hanzely', ' Samuel Horváth', ' Peter Richtarik']","{'King Abdullah University of Science and Technology', 'KAUST'}",1,0,0,{'Saudi Arabia'}
Black-Box Certification with Randomized Smoothing: A Functional Optimization Based Framework,"Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, Qiang Liu",Black-Box Certification with Randomized Smoothing: A Functional Optimization Based Framework,1896a3bf730516dd643ba67b4c447d36,https://proceedings.neurips.cc/paper/2020/file/1896a3bf730516dd643ba67b4c447d36-Paper.pdf,"Adversarial certification via randomized smoothing could achieve guaranteed robust machine learning models, thus has wide application on AI security. a & b) With our empirical results, security engineers could get better performance on defending against vicious attacks; With our theoretical results, it will be easier for following researchers to derive new bounds for different kinds of smoothing methods. We don’t foresee the possibility that it could bring negative social impacts. c) Our framework is mathematically rigorous thus would never fail. d) Our method doesn’t have bias in data as we provide a general certification method for all tasks and data, and our distribution is not adaptive towards data.",Broader Impact,108,5,,,FALSE,FALSE,FALSE,Black-Box Certification with Randomized Smoothing: A Functional Optimization Based Framework,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Adversarial Learning; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Dinghuai Zhang', ' Mao Ye', ' Chengyue Gong', ' Zhanxing Zhu', ' Qiang Liu']","{'The University of Texas at Austin', 'Peking University', 'UT Austin'}",1,0,0,"{'USA', 'China'}"
Deep Imitation Learning for Bimanual Robotic Manipulation,"Fan Xie, Alexander Chowdhury, M. Clara De Paolis Kaluza, Linfeng Zhao, Lawson Wong, Rose Yu",Deep Imitation Learning for Bimanual Robotic Manipulation,18a010d2a9813e91907ce88cd9143fdf,https://proceedings.neurips.cc/paper/2020/file/18a010d2a9813e91907ce88cd9143fdf-Paper.pdf,"Robotics systems that utilize fully automated policies for different tasks have already been applied to many manufacturing, assembly lines, and warehouses processes. Our work demonstrates the potential to take this automation one step further. Our algorithm can automatically learn complex control policies from expert demonstrations, which could potentially allow robots to augment their existing control designs and further optimize their workflows. Implementing learned policies in safety-critical environments such as large-scale assembly lines can be risky as these algorithms do not have guaranteed precision. Improved theoretical understanding and interpretability of model policies could potentially mitigate these risks.",Broader Impact,96,5,,,FALSE,FALSE,FALSE,Deep Imitation Learning for Bimanual Robotic Manipulation,Applications -> Robotics,Algorithms -> Relational Learning; Algorithms -> Representation Learning; Deep Learning -> Interaction-Based Deep Networks; Deep Learning -> Recurrent Networks; Reinforcement Learning and Planning -> Hierarchical RL; Reinforcement Learning and Planning -> Model-Based RL; Reinforcement Learning and Planning -> Planning,"Other applications (e.g., robotics, biology, climate, finance)","['Fan Xie', ' Alexander Chowdhury', ' Clara De Paolis Kaluza', ' Linfeng Zhao', ' Lawson Wong', ' Rose Yu']","{'University of California, San Diego', 'Northeastern University'}",1,0,0,{'USA'}
Stationary Activations for Uncertainty Calibration in Deep Learning,"Lassi Meronen, Christabella Irwanto, Arno Solin",Stationary Activations for Uncertainty Calibration in Deep Learning,18a411989b47ed75a60ac69d9da05aa5,https://proceedings.neurips.cc/paper/2020/file/18a411989b47ed75a60ac69d9da05aa5-Paper.pdf,"We propose a new building block to help quantify uncertainty in deep learning. This contributes to creating methods in artificial intelligence that know what they do not know, which is important in safety-critical applications and in creating more robust and reliable systems. Such safety-critical applications include, for example, automatic medical diagnosis, self-driving vehicles, and general tasks for decision-making under uncertainty [2]. The contribution of this paper is in showing an explicit connection between two different paradigms in machine learning: we derive a non-linear activation function for neural networks which behaves as the widely used Matérn class of Gaussian process priors. This link can help build neural network models that are more robust and less vulnerable to out-of-distribution (OOD) data—which often occurs naturally in real-world settings [9, 54] or by potentially malicious construction, e.g. , adversarial attacks [63]—by making the neural networks behave more similarly to Gaussian process models, which have appealing properties in terms of well-calibrated uncertainty estimates and direct ways of including a priori knowledge, but typically do not directly scale to all kinds of applications and large data sets. However, we only show theoretical guarantees of this link to hold in the limit of infinitely wide neural networks with one hidden layer. In finite-size models we can only demonstrate the benefits empirically. This paper is concerned with foundational research which is expected to have an impact across application areas. The example applications in the paper underline the wide variety of possible applications ranging from simple classification tasks to out-of-distribution class detection in image and radar emitter classification.",Broader Impact,259,9,,,FALSE,FALSE,FALSE,Stationary Activations for Uncertainty Calibration in Deep Learning,Probabilistic Methods -> Gaussian Processes,Deep Learning -> Analysis and Understanding of Deep Networks,Probabilistic methods and inference,"['Lassi Meronen', ' Christabella Irwanto', ' Arno Solin']",{'Aalto University'},1,0,0,{'Finland'}
Ensemble Distillation for Robust Model Fusion in Federated Learning,"Tao Lin, Lingjing Kong, Sebastian U. Stich, Martin Jaggi",Ensemble Distillation for Robust Model Fusion in Federated Learning,18df51b97ccd68128e994804f3eccc87,https://proceedings.neurips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf,"We believe that collaborative learning schemes such as federated learning are an important element towards enabling privacy-preserving training of ML models, as well as a better alignment of each individual’s data ownership with the resulting utility from jointly trained machine learning models, especially in applications where data is user-provided and privacy sensitive [34, 55]. In addition to privacy, efficiency gains and lower resource requirements in distributed training reduce the environmental impact of training large machine learning models. The introduction of a practical and reliable distillation technique for heterogeneous models and for low-resource clients is a step towards more broadly enabling collaborative privacy-preserving and efficient decentralized learning.",Broader Impact,106,3,,,FALSE,FALSE,FALSE,Ensemble Distillation for Robust Model Fusion in Federated Learning,Deep Learning -> Efficient Training Methods,,Deep learning,"['Tao LIN', ' Lingjing Kong', ' Sebastian U Stich', ' Martin Jaggi']",{'EPFL'},1,0,0,{'Switzerland'}
Falcon: Fast Spectral Inference on Encrypted Data,"Qian Lou, Wen-jie Lu, Cheng Hong, Lei Jiang",Falcon: Fast Spectral Inference on Encrypted Data,18fc72d8b8aba03a4d84f66efabce82e,https://proceedings.neurips.cc/paper/2020/file/18fc72d8b8aba03a4d84f66efabce82e-Paper.pdf,"Falcon enables a low-latency privacy-preserving neural network inference on encrypted data. With Falcon, users can enjoy low-latency secure inference services. In particular, users are able to receive low-latency and powerful machine learning inference services by uploading their sensitive data without concerning data privacy. Falcon has no negative impact on our society. If our proposed method fails, the latency of secure inferences will be prolonged.",Broader Impact,64,5,FALSE,TRUE,FALSE,TRUE,FALSE,Falcon: Fast Spectral Inference on Encrypted Data,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Deep Learning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Qian Lou', 'jie Lu', ' Cheng Hong', ' Lei Jiang']","{'Indiana University Bloomington', 'Alibaba Group'}",1,1,1,"{'USA', 'China'}"
On Power Laws in Deep Ensembles,"Ekaterina Lobacheva, Nadezhda Chirkova, Maxim Kodryan, Dmitry P. Vetrov",On Power Laws in Deep Ensembles,191595dc11b4d6e54f01504e3aa92f96,https://proceedings.neurips.cc/paper/2020/file/191595dc11b4d6e54f01504e3aa92f96-Paper.pdf,"In this work, we provide an empirical and theoretical study of existing models (namely, deep ensembles); we propose neither new technologies nor architectures, thus we are not aware of its specific ethical or future societal impact. We, however, would like to point out a few benefits gained from our findings, such as optimization of resource consumption when training neural networks and contribution to the overall understanding of neural models. As far as we are concerned, no negative consequences may follow from our research.",Broader Impact,83,3,,,FALSE,FALSE,FALSE,On Power Laws in Deep Ensembles,Algorithms -> Uncertainty Estimation,Algorithms -> Boosting and Ensemble Methods; Deep Learning,Deep learning,"['Ekaterina Lobacheva', ' Nadezhda Chirkova', ' Maxim Kodryan', ' Dmitry Vetrov']","{'Higher School of Economics, Samsung AI Center, Moscow', 'Samsung-HSE Laboratory', 'Samsung-HSE Laboratory, National Research University Higher School of Economics', 'Higher School of Economics, Samsung-HSE Laboratory'}",1,1,1,"{'South Korea', 'Russia'}"
Practical Quasi-Newton Methods for Training Deep Neural Networks,"Donald Goldfarb, Yi Ren, Achraf Bahamou",Practical Quasi-Newton Methods for Training Deep Neural Networks,192fc044e74dffea144f9ac5dc9f3395,https://proceedings.neurips.cc/paper/2020/file/192fc044e74dffea144f9ac5dc9f3395-Paper.pdf,"The research presented in this paper provides a new method for training DNNs that our experimental testing has shown to be more efficient in several cases than current state-of-the-art optimization methods for this task. Consequently, because of the wide use of DNNs in machine learning, this should help save a substantial amount of energy. Our new algorithms simply attempt to minimize the loss function that are given to it and the computations that it performs are all transparent. In machine learning, DNNs can be trained to address many types of problems, some of which should lead to positive societal outcomes, such as ones in medicine (e.g., diagnostics and drug effectiveness), autonomous vehicle development, voice recognition and climate change. Of course, optimization algorithms for training DNNs can be used to train models that may have negative consequences, such as those intended to develop psychological profiles, invade privacy and justify biases. The misuse of any efficient optimization algorithm for machine learning, and in particular our algorithms, is beyond the control of the work presented here.",Broader Impact,173,6,,,TRUE,TRUE,FALSE,Practical Quasi-Newton Methods for Training Deep Neural Networks,Deep Learning,Deep Learning -> Optimization for Deep Networks,Deep learning,"['Donald Goldfarb', ' Yi Ren', ' Achraf Bahamou']",{'Columbia University'},1,0,0,{'USA'}
Approximation Based Variance Reduction for Reparameterization Gradients,"Tomas Geffner, Justin Domke",Approximation Based Variance Reduction for Reparameterization Gradients,193002e668758ea9762904da1a22337c,https://proceedings.neurips.cc/paper/2020/file/193002e668758ea9762904da1a22337c-Paper.pdf,"In this work we present a new algorithm that yields improved performance for VI with non factorized distributions. We believe this algorithm could be included in VI-based automatic inference tools to improve their performance. This could have an impact in several areas since these tools, such as ADVI [15] (in Stan [4]), are used by researchers and practitioners in many different fields.",Broader Impact,62,3,,,FALSE,FALSE,FALSE,Approximation Based Variance Reduction for Reparameterization Gradients,Probabilistic Methods -> Variational Inference,Probabilistic Methods -> Graphical Models,Probabilistic methods and inference,"['Tomas Geffner', ' Justin Domke']","{'University of Massachusetts, Amherst', 'UMass Amherst'}",1,0,0,{'USA'}
Inference Stage Optimization for Cross-scenario 3D Human Pose Estimation,"Jianfeng Zhang, Xuecheng Nie, Jiashi Feng",Inference Stage Optimization for Cross-scenario 3D Human Pose Estimation,1943102704f8f8f3302c2b730728e023,https://proceedings.neurips.cc/paper/2020/file/1943102704f8f8f3302c2b730728e023-Paper.pdf,"We propose Inference Stage Optimization (ISO) framework for cross-scenario 3D human pose estimation. It can be applied to lots of 3D pose estimation related applications including human-robot interaction, action recognition, human tracking, etc., which are all important research topics in artificial intelligence. However, similar to most human pose estimation methods, ISO may be used for military application and raise privacy concerns when misused. Generally, improving generalization performance for the 3D human pose estimation task may have many applications, which could be positive, negative or more complicated, but would depend on what task we use these applications for.",Broader impact,97,4,,,FALSE,FALSE,FALSE,Inference Stage Optimization for Cross-scenario 3D Human Pose Estimation,"Applications -> Body Pose, Face, and Gesture Analysis",Applications -> Computer Vision,Vision,"['Jianfeng Zhang', ' Xuecheng Nie', ' Jiashi Feng']","{'NUS', 'National University of Singapore'}",1,0,0,{'Singapore'}
Consistent feature selection for analytic deep neural networks,"Vu C. Dinh, Lam S. Ho",Consistent Feature Selection for Analytic Deep Neural Networks,1959eb9d5a0f7ebc58ebde81d5df400d,https://proceedings.neurips.cc/paper/2020/file/1959eb9d5a0f7ebc58ebde81d5df400d-Paper.pdf,"Deep learning has transformed modern science in an unprecedented manner and created a new force for technological developments. However, its black-box nature and the lacking of theoretical justifications have hindered its applications in fields where correct interpretations play an essential role. In many applications, a linear model with a justified confidence interval and a rigorous feature selection procedure is much more favored than a deep learning system that cannot be interpreted. Usage of deep learning in a process that requires transparency such as judicial and public decisions is still completely out of the question. To the best of our knowledge, this is the first work that establishes feature selection consistency, an important cornerstone of interpretable statistical inference, for deep learning. The results of this work will greatly extend the set of problems to which statistical inference with deep learning can be applied. Medical sciences, public health decisions, and various fields of engineering, which depend upon well-founded estimates of uncertainty, fall naturally on the domain the work tries to explore. Researchers from these fields and the public alike may benefit from such a development and no one is put at disadvantage from this research. By trying to select a parsimonious and transparent model out of an over-parametrized deep learning system, the approach of this work further provides a systematic way to detect and reduce bias in machine learning analysis. The analytical tools and the theoretical framework derived in this work may also be of independent interest in statistics, machine learning, and other fields of applied sciences.",Broader Impact,255,10,,,FALSE,TRUE,FALSE,Consistent feature selection for analytic deep neural networks,Theory -> Statistical Learning Theory,"Algorithms -> Model Selection and Structure Learning; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Supervised Deep Networks; Deep Learning -> Visualization, Interpretability, and Explainability; Theory -> Regularization",Deep learning,"['Vu Dinh', ' Lam Ho']","{'University of Dalhousie', 'University of Delaware'}",1,0,0,{'USA'}
Glance and Focus: a Dynamic Approach to Reducing Spatial Redundancy in Image Classification,"Yulin Wang, Kangchen Lv, Rui Huang, Shiji Song, Le Yang, Gao Huang",Glance and Focus: a Dynamic Approach to Reducing Spatial Redundancy in Image Classification,1963bd5135521d623f6c29e6b1174975,https://proceedings.neurips.cc/paper/2020/file/1963bd5135521d623f6c29e6b1174975-Paper.pdf,"Image classification is known as a fundamental task in the context of computer vision, and has a wide variety of application scenarios, such as content-based image search, autonomous vehicles, fault detection and landmark recognition. As a flexible efficient inference framework, the proposed GFNet may help for developing resource efficient image classification systems for these applications. For example, search engines, social media companies and online advertising agencies, all must process large volumes of data on limited hardware resources, where our method can be implemented to reduce the required amount of computational resources. On mobile phones or edge devices, GFNet may also contribute to improving user experience and preserving battery life through reducing latency and the required computation. Mobile app developers or phone manufacturers may benefit from our method. On the other hand, our method also benefits environmental protection by decreasing power consumption. Besides, in terms of the deep learning research community, our work may motivate other researchers to develop more efficient CNNs by designing more effective mechanisms to reduce spatial redundancy. Our method also has the potentials to be modified for other important vision tasks including semantic segmentation, object detection, instance segmentation, etc., which may lead to larger positive impacts.  However, GFNet suffers from the common problems of CNNs as well, such as the safety risk caused by potential adversarial attacks or the privacy risk. In addition, when improperly used, our method may also reduce the cost of criminal behaviors. Overall, we believe that the benefits of our work to both the industry and the academia will significantly outweigh its harms.",Broader Impact,260,11,,,FALSE,FALSE,FALSE,Glance and Focus: a Dynamic Approach to Reducing Spatial Redundancy in Image Classification,Deep Learning -> Efficient Inference Methods,Applications -> Computer Vision,Resource aware machine learning,"['Yulin Wang', ' Kangchen Lv', ' Rui Huang', ' Shiji Song', ' Le Yang', ' Gao Huang']","{'Department of Automation, Tsinghua University', 'Tsinghua University', 'Tsinghua'}",1,0,0,{'China'}
Information Maximization for Few-Shot Learning,"Malik Boudiaf, Imtiaz Ziko, Jérôme Rony, Jose Dolz, Pablo Piantanida, Ismail Ben Ayed",Transductive Information Maximization For Few-Shot Learning,196f5641aa9dc87067da4ff90fd81e7b,https://proceedings.neurips.cc/paper/2020/file/196f5641aa9dc87067da4ff90fd81e7b-Paper.pdf,"Due to the simplicity and efficiency of our method, we lower the barrier of entry to few-shot learning. In turn, we think that it will make a wider breadth of real-world applications tractable. The impact (positive or negative) on society is similar to that of any other few-shot method: being only a tool, its impact is entirely dependent on the final applications, and on the intentions of the people and institutions deploying it. In our strive towards finding simple and efficient formulations – for instance, we stick to a standard cross-entropy, which not only eases implementation, but also avoid the huge memory consumption of more complex methods – we believe our method can enable and empower persons and communities that are unable to afford the costly resources and infrastructures required. This may help level the playing field with larger and better funded entities. For instance, to be adapted to a new task, our TIM-ADM method requires a little more than a recent smartphone computational power. This could spawn a lot of fresh and new applications on edge devices, closer to the end-users, in real-time.",Broader impact,184,7,,,TRUE,TRUE,FALSE,Transductive Information Maximization for Few-Shot Learning,Algorithms -> Few-Shot Learning,Theory -> Information Theory,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Malik Boudiaf', ' Imtiaz Ziko', 'Ecole de technologie superieure', ' Jérôme Rony', ' Jose Dolz', ' Pablo Piantanida', ' Ismail Ben Ayed']","{'ÉTS Montréal', 'ETS Montreal', 'Ecole de Technologie Superieure', 'ETS', 'CentraleSupélec - Mila'}",1,0,0,{'Canada'}
Inverse Reinforcement Learning from a Gradient-based Learner,"Giorgia Ramponi, Gianluca Drappo, Marcello Restelli",Inverse Reinforcement Learning from a Gradient-based Learner,19aa6c6fb4ba9fcf39e893ff1fd5b5bd,https://proceedings.neurips.cc/paper/2020/file/19aa6c6fb4ba9fcf39e893ff1fd5b5bd-Paper.pdf,"In this paper, we focus on the Inverse Reinforcement Learning [2, 15, 3, 21] task from a Learning Agent [17]. The first motivation to study Inverse Reinforcement Learning algorithms is to overcome the difficulties that can arise in specifying the reward function from human and animal behaviour. Sometimes, in fact, it is easier to infer human intentions by observing their behaviours than to design a reward function by hand. An example is helicopter flight control [1], in which we can observe a helicopter operator and through IRL a reward function is inferred to teach a physical remote-controlled helicopter. Another example is to predict the behavior of a real agent as route prediction tasks of taxis [41, 42] or anticipation of pedestrian interactions [12] or energy-efficient driving [38]. However, in many cases, the agents are not really experts and on the other hand, only expert demonstrations can not show their intention to avoid dangerous situations. We want to point out that learning what the agent wants to avoid because harmful is as important as learning his intentions. The possible outcomes of this research are the same as those of Inverse Reinforcement Learning mentioned above, avoiding the constraint that the agent has to be an expert. In future work, we will study how to apply the proposed algorithm in order to infer the pilot’s intentions when they learn a new circuit. A relevant possible complication of using IRL is the error on the reward feature engineering which can lead to errors in understanding the agent’s intentions. In an application such as autonomous driving, errors in the reward function can cause dangerous situations. For this reason, verification through the simulated environment of the effectiveness of the retrieve rewards is quite important.",Broader impact,288,12,,,FALSE,FALSE,FALSE,Inverse Reinforcement Learning from a Gradient-based Learner,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Giorgia Ramponi', ' Gianluca Drappo', ' Marcello Restelli']",{'Politecnico di Milano'},1,0,0,{'Italy'}
Bayesian Multi-type Mean Field Multi-agent Imitation Learning,"Fan Yang, Alina Vereshchaka, Changyou Chen, Wen Dong",Bayesian Multi-type Mean Field Multi-agent Imitation Learning,19eca5979ccbb752778e6c5f090dc9b6,https://proceedings.neurips.cc/paper/2020/file/19eca5979ccbb752778e6c5f090dc9b6-Paper.pdf,"From the research perspective, our work is the first to connect the attention mechanism with mean field approximation, which connects the neural network community with the game theory community. On the other hand, our work is also the first to introduce the concept of mean field to the multi- agent imitation learning, which brings the game theory community into the imitation learning community. The combination of the communities points out new research directions where more research opportunities may be found. From the society perspective, first, multi-agent imitation learning has a large number of real-world applications. We live in a world full of complex multi-agent systems, such as the transportation system where each vehicle or each group of vehicles can be viewed as an agent, or the epidemic system where each individual or each group of people can be viewed as an agent. Optimizing the policy in these real-world multi-agent systems are important and valuable, such as optimizing the driving route of each vehicle to reduce the driving time, or optimizing the medical resource allocation and regulating the interaction of people to mitigate the spread of epidemic disease. Reward function is not given in such real-world systems. Instead, we may have expert demonstrations that we can mimic, such as how experienced drivers drive in a transportation system. As such, optimizing the policies in real-world multi-agent systems can be formulated as multi-agent imitation learning problems. Second, our work has the potential to solve real-world multi-agent imitation learning problems. MAIL is still a relatively new domain. The challenges for applying MAIL to solve real-world problems are scalability and sampling efficiency since interactively collecting the samples is an expensive operation and real-world systems often have a large number of agents. Our work is one step in this direction. In this paper, we improve the scalability by introducing the Bayesian formulation, and improve the sample efficiency through introducing a new multi-type mean filed approximation, as demonstrated in the experiments. Our work has the potential to solve real-world MAIL problems. The limitation of our approach is still scalability. Currently, we can not scale to environments with thousands of agents and hundreds of types where the state-action space has thousands of dimensions. Further improve the scalability would be the future work.",7 Broader impact,374,18,,,FALSE,FALSE,FALSE,Bayesian Multi-type Mean Field Multi-agent Imitation Learning,Reinforcement Learning and Planning -> Multi-Agent RL,Deep Learning -> Adversarial Networks; Deep Learning -> Attention Models; Probabilistic Methods -> Graphical Models; Theory -> Game Theory and Computational Economics,Reinforcement learning and planning,"['Fan Yang', ' Alina Vereshchaka', ' Changyou Chen', ' Wen Dong']",{'University at Buffalo'},1,0,0,{'USA'}
Bayesian Robust Optimization for Imitation Learning,"Daniel Brown, Scott Niekum, Marek Petrik",Bayesian Robust Optimization for Imitation Learning,1a669e81c8093745261889539694be7f,https://proceedings.neurips.cc/paper/2020/file/1a669e81c8093745261889539694be7f-Paper.pdf,"Algorithms that balance risk and return are have been common in financial applications for a long time, but are just starting to be applied to AI/ML systems. We believe this is a positive trend as many AI/ML applications have risk and return trade-offs that are not always adequately addressed. In this work we have proposed a principled approach optimizing control policies that balance expected return and epistemic risk under an uncertain reward functions. We see this work as an important step towards the general goal of robust autonomous systems that can interact safely with and assist humans in a wide variety of tasks and under a wide variety of preferences and risk tolerances. However, there are potential downsides to having risk and return trade-offs if these trade-offs are made incorrectly or interpreted incorrectly—despite using risk-sensitive metrics, financial systems still occasionally crash or fail. Our proposed algorithm, BROIL, does not guarantee safety, thus an autonomous system based on our approach will not be guaranteed to never make a mistake. Instead, BROIL optimizes a policy that is robust with respect to the agent’s uncertainty over its learned representation of the demonstrator’s reward function. Thus, the optimized policy may not always conform to a human’s intuition about what safe or robust behavior should look like.",Broader Impact,212,8,,,FALSE,FALSE,FALSE,Bayesian Robust Optimization for Imitation Learning,Social Aspects of Machine Learning -> AI Safety,Reinforcement Learning and Planning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Daniel Brown', ' Scott Niekum', ' Marek Petrik']","{'The University of Texas at Austin', 'University of New Hampshire', 'UT Austin'}",1,0,0,{'USA'}
Multiview Neural Surface Reconstruction by Disentangling Geometry and Appearance,"Lior Yariv, Yoni Kasten, Dror Moran, Meirav Galun, Matan Atzmon, Basri Ronen, Yaron Lipman",Multiview Neural Surface Reconstruction by Disentangling Geometry and Appearance,1a77befc3b608d6ed363567685f70e1e,https://proceedings.neurips.cc/paper/2020/file/1a77befc3b608d6ed363567685f70e1e-Paper.pdf,"In our work we want to learn 3D geometry of the world from the abundant data of 2D images. In particular we allow high quality of 3D reconstruction of objects and scenes using only standard images. Applications of our algorithm could be anywhere 3D information is required, but only 2D images are available. This could be the case in: product design, entertainment, security, medical imaging, and more.",Broader Impact,67,4,,,FALSE,FALSE,FALSE,Multiview Neural Surface Reconstruction by Disentangling Geometry and Appearance,Applications -> Computer Vision,,Vision,,"{'Weizmann Institute of Science', 'Weizmann Institute Of Science', 'Weizmann Institute'}",1,0,0,{'Israel'}
Riemannian Continuous Normalizing Flows,"Emile Mathieu, Maximilian Nickel",Riemannian Continuous Normalizing Flows,1aa3d9c6ce672447e1e5d0f1b5207e85,https://proceedings.neurips.cc/paper/2020/file/1aa3d9c6ce672447e1e5d0f1b5207e85-Paper.pdf,"The work presented in this paper focuses on the learning of well-specified probabilistic models for manifold-valued data. Consequently, its applications are especially promising to advance scientific understanding in fields such as earth and climate science, computational biology, and computer vision. As a foundational method, our work inherits the broader ethical aspects and future societal consequences of machine learning in general.",Broader impact,60,3,FALSE,TRUE,FALSE,FALSE,FALSE,Riemannian Continuous Normalizing Flows,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Algorithms -> Unsupervised Learning; Probabilistic Methods; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Emile Mathieu', ' Maximilian Nickel']","{'Facebook AI Research', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
Attention-Gated Brain Propagation: How the brain can implement reward-based error backpropagation,"Isabella Pozzi, Sander  Bohte, Pieter Roelfsema",Attention-Gated Brain Propagation: How the brain can implement reward-based error backpropagation,1abb1e1ea5f481b589da52303b091cbb,https://proceedings.neurips.cc/paper/2020/file/1abb1e1ea5f481b589da52303b091cbb-Paper.pdf,"Our research addresses how deep learning can be implemented by the brain. It does not only address of the biggest unsolved mysteries related to how our brain, with its many layers between input and output learns, but it may ultimately also shed light on conditions in which learning is impaired. For example, our work suggests that attention is important for learning. It may thereby inspire new research into how e.g. attention deficits impair learning. Our work also suggests an important role for neuromodulatory signals, such as dopamine, in learning. Our work may provide insight into how diseases that impair the neuromodulatory systems (e.g. Parkinson’s disease) cause learning deficits.",Broader Impact,108,6,,,FALSE,FALSE,FALSE,Attention-Gated Brain Propagation: How the brain can implement reward-based error backpropagation,Deep Learning -> Biologically Plausible Deep Networks,,Neuroscience and cognitive science,"['Isabella Pozzi', ' Sander Bohte', ' Pieter Roelfsema']","{'Centrum Wiskunde & Informatica', 'Netherlands Institute for Neuroscience', 'CWI'}",1,1,1,{'Netherlands'}
Asymptotic Guarantees for Generative Modeling Based on the Smooth Wasserstein Distance,"Ziv Goldfeld, Kristjan Greenewald, Kengo Kato",Asymptotic Guarantees for Generative Modeling Based on the Smooth Wasserstein Distance,1ac978c8020be6d7212aa71d4f040fc3,https://proceedings.neurips.cc/paper/2020/file/1ac978c8020be6d7212aa71d4f040fc3-Paper.pdf,"Our goal is to provide a stronger theoretical foundation for generative modeling based on the smoothed Wasserstein distance. We hope that this enables practitioners to build more robust, fair, and resilient generative models.",Broader Impact,33,2,FALSE,FALSE,FALSE,FALSE,FALSE,Asymptotic Guarantees for Generative Modeling Based on the Smooth Wasserstein Distance,Theory -> Statistical Learning Theory,Theory -> High-Dimensional Inference; Theory -> Large Deviations and Asymptotic Analysis,Theory (including computational and statistical analyses),"['Ziv Goldfeld', ' Kristjan Greenewald', ' Kengo Kato']","{'IBM Research', 'Cornell University'}",1,1,1,{'USA'}
Online Robust Regression via SGD on the l1 loss,"Scott Pesme, Nicolas Flammarion",Online Robust Regression via SGD on the 1 loss,1ae6464c6b5d51b363d7d96f97132c75,https://proceedings.neurips.cc/paper/2020/file/1ae6464c6b5d51b363d7d96f97132c75-Paper.pdf,"As discussed in the introduction, the algorithm we propose can be useful in many practical applications such as : (a) detection of irrelevant measurements and systematic labelling errors [52], (b) detection of system attacks such as frauds by click bots [41] or malware recommendation rating-frauds [95], and (c) online regression with heavy-tailed noise [79].",8 Broader Impact,54,1,FALSE,FALSE,FALSE,FALSE,FALSE,Online Robust Regression via SGD on the l1 loss,Optimization -> Stochastic Optimization,Algorithms -> Large Scale Learning; Algorithms -> Online Learning; Algorithms -> Regression; Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Scott Pesme', ' Nicolas Flammarion']",{'EPFL'},1,0,0,{'Switzerland'}
PRANK: motion Prediction based on RANKing,"Yuriy Biktairov, Maxim Stebelev, Irina Rudenko, Oleh Shliazhko, Boris Yangel",PRANK: motion Prediction based on RANKing,1b0251ccb8bd5f9ccf444e4bda7713e3,https://proceedings.neurips.cc/paper/2020/file/1b0251ccb8bd5f9ccf444e4bda7713e3-Paper.pdf,"Motion prediction methods can advance the development of the self-driving technology and, thus, inherit the impact associated with it. For a detailed overview of long-term effects of autonomous vehicles on the society we refer the reader to [35].  It should be explicitly mentioned that motion prediction methods can potentially advance the development of malicious self-driving agents that aim to create dangerous traffic situations or collide with a particular vehicle. The better such agents will be able to predict how other agents will behave, the harder it will be for them to avoid a collision. A joint effort of regulatory bodies, engineering and information security specialists is required to prevent such vehicles from ever appearing on public roads.",6 Broader Impact,117,5,,,FALSE,TRUE,FALSE,PRANK: motion Prediction based on RANKing,Applications -> Robotics,Algorithms -> Structured Prediction; Deep Learning -> Efficient Inference Methods; Deep Learning -> Predictive Models; Probabilistic Methods -> Latent Variable Models,"Other applications (e.g., robotics, biology, climate, finance)","['Yuriy Biktairov', ' Maxim Stebelev', ' Boris Yangel', ' Irina Rudenko', ' Oleh Shliazhko']",{'Yandex'},0,1,0,{'Russia'}
Fighting Copycat Agents in Behavioral Cloning from Observation Histories,"Chuan Wen, Jierui Lin, Trevor Darrell, Dinesh Jayaraman, Yang Gao",Fighting Copycat Agents in Behavioral Cloning from Observation Histories,1b113258af3968aaf3969ca67e744ff8,https://proceedings.neurips.cc/paper/2020/file/1b113258af3968aaf3969ca67e744ff8-Paper.pdf,"In this paper, we introduce a systematic approach to combat the “copycat” problem in behavioral cloning with observation histories. Behavioral cloning can be applied to a wide range of applications, such as robotics, natural language, decision making, as well as economics. Our method is particularly useful for offline behavioral cloning with partially observed states. Offline imitation is currently one of the most promising ways to achieve learned control in the world. Our method can improve the real world performance of behavior cloning agents, which could enable wider use of behavior cloning agents in practice. This could help to automate repetitive processes previously requiring human workers. While on the one hand, this has the ability to free up human time and creativity for more rewarding tasks, it also raises the concerning possibility of the loss of blue collar jobs. To mitigate the risks, it is important to promote policy and legislation to protect the interests of the workers who might be affected during the adoption of such technology.",8 Broader Impact,167,8,,,FALSE,FALSE,FALSE,Fighting Copycat Agents in Behavioral Cloning from Observation Histories,Applications -> Robotics,Algorithms -> Adversarial Learning; Reinforcement Learning and Planning -> Decision and Control,"Other applications (e.g., robotics, biology, climate, finance)",,"{'UC Berkeley', 'University of California, Berkeley', 'Tsinghua University', 'University of Pennsylvania'}",1,0,0,"{'USA', 'China'}"
Tight Nonparametric Convergence Rates for Stochastic Gradient Descent under the Noiseless Linear Model,"Raphaël Berthier, Francis Bach, Pierre Gaillard",Tight Nonparametric Convergence Rates for Stochastic Gradient Descent under the Noiseless Linear Model,1b33d16fc562464579b7199ca3114982,https://proceedings.neurips.cc/paper/2020/file/1b33d16fc562464579b7199ca3114982-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Tight Nonparametric Convergence Rates for Stochastic Gradient Descent under the Noiseless Linear Model,Optimization -> Stochastic Optimization,Algorithms -> Kernel Methods; Optimization -> Convex Optimization,Theory (including computational and statistical analyses),"['Raphaël Berthier', ' Francis Bach', ' Pierre Gaillard']","{'INRIA, ENS', 'INRIA, PSL', 'INRIA - Ecole Normale Superieure'}",1,0,0,{'France'}
Structured Prediction for Conditional Meta-Learning,"Ruohan Wang, Yiannis Demiris, Carlo Ciliberto",Structured Prediction for Conditional Meta-Learning,1b69ebedb522700034547abc5652ffac,https://proceedings.neurips.cc/paper/2020/file/1b69ebedb522700034547abc5652ffac-Paper.pdf,"Meta-learning aims to construct learning models capable of learning from experiences, Its intended users are thus primarily non-experts who require automated machine learning services, which may occur in a wide range of potential applications such as recommender systems and autoML. The authors do not expect the work to address or introduce any societal or ethical issues.",Broader Impact,56,2,TRUE,TRUE,FALSE,FALSE,FALSE,Structured Prediction for Conditional Meta-Learning,Algorithms -> Meta-Learning,Algorithms -> Structured Prediction,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Ruohan Wang', ' Yiannis Demiris', ' Carlo Ciliberto']",{'Imperial College London'},1,0,0,{'UK'}
Optimal Lottery Tickets via Subset Sum: Logarithmic Over-Parameterization is Sufficient,"Ankit Pensia, Shashank Rajput, Alliot Nagle, Harit Vishwakarma, Dimitris Papailiopoulos",Optimal Lottery Tickets via S UBSET S UM : Logarithmic Over-Parameterization is Sufficient,1b742ae215adf18b75449c6e272fd92d,https://proceedings.neurips.cc/paper/2020/file/1b742ae215adf18b75449c6e272fd92d-Paper.pdf,"As discussed in the Introduction, our results establish that we can “train” a neural network by only pruning a slightly larger network. As shown in Strubell et al. [37], training a single deep model (including hyper-parameter optimization and experimentation) has the carbon footprint equivalent to that of four cars through their lifetime, motivating the search for a more efficient training algorithm. Pruning is a radically different way of optimization as compared to the usual gradient based one, and recent works show that either using it alone or in tandem with conventional optimization techniques can lead to good performance [20, 26, 27]. Moreover, a sparse network is also useful when the models are deployed for inference. One of the major benefits of pruning is that sparser models can have smaller memory and computational requirements, leading in some cases to less energy consumption. As a result, pruned networks are useful in resource-constrained settings and have smaller carbon footprint. Nonetheless, the pruning algorithms, if proved to be successful, will need to go through the same scrutiny as the existing optimization algorithms such as robustness to adversarial examples [23]. Another contribution, which is more subtle, is that we connect the S UBSET S UM problem with pruning of neural networks and their optimization in general. We believe that both these fields can benefit from the existing literature of the S UBSET S UM problem [28, 29, 30, 31]. We use the result by Lueker [31] which says that we only need a logarithmic sized set of random numbers on a bounded domain to approximate any number in that domain with high accuracy and high probability. It would be interesting to see the Machine Learning community apply these kind of results to other theoretical and practical problems.",Broader Impact,292,12,,,FALSE,FALSE,FALSE,Optimal Lottery Tickets via Subset Sum: Logarithmic Over-Parameterization is Sufficient,Theory -> Statistical Learning Theory,Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Efficient Training Methods; Theory -> Information Theory,Theory (including computational and statistical analyses),"['Ankit Pensia', ' Shashank Rajput', ' Alliot Nagle', ' Harit Vishwakarma', ' Dimitris Papailiopoulos']","{'UW-Madison', 'University of Wisconsin Madison', 'University of Wisconsin-Madison', 'University of Wisconsin - Madison'}",1,0,0,{'USA'}
The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes,"Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet Singh, Pratik Ringshia, Davide Testuggine",The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes,1b84c4cee2b8b3d823b30e2d604b1878,https://proceedings.neurips.cc/paper/2020/file/1b84c4cee2b8b3d823b30e2d604b1878-Paper.pdf,"This work offers several positive societal benefits. Hate speech is a well-known problem, and countering it via automatic methods can have a big impact on people’s lives. This challenge is meant to spur innovation and encourage new developments in multimodal reasoning and understanding, which can have positive effects for an extremely wide variety of tasks and applications. With these advantages also come potential downsides: better multimodal systems may lead to the automation of jobs in the coming decades, and could be used for censorship or nefarious purposes. These risks can in part be mitigated by developing AI systems to counter them.",Broader Impact,101,5,,,FALSE,FALSE,FALSE,The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes,Algorithms -> Multimodal Learning,"Applications -> Computer Vision; Applications -> Natural Language Processing; Data, Challenges, Implementations, and Software -> Benchmarks; Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories",,"['Douwe Kiela', ' Hamed Firooz', ' Aravind Mohan', ' Vedanuj Goswami', ' Amanpreet Singh', ' Pratik Ringshia', ' Davide Testuggine']","{'Facebook', 'Facebook AI Research'}",0,1,0,{'USA'}
Stochasticity of Deterministic Gradient Descent: Large Learning Rate for Multiscale Objective Function,"Lingkai Kong, Molei Tao",Stochasticity of Deterministic Gradient Descent: Large Learning Rate for Multiscale Objective Function,1b9a80606d74d3da6db2f1274557e644,https://proceedings.neurips.cc/paper/2020/file/1b9a80606d74d3da6db2f1274557e644-Paper.pdf,"This theoretical work deepens our understanding of the performance of gradient descent, an optimization algorithm of significant importance to machine learning. This understanding could lead to the design of better optimization algorithms and improved learning models (either for encouraging or discouraging multiscale landscape, and for enabling or disabling stochasticity originated from determinism, depending on the application). It also helps tune the learning rate, and creates a new quantitative way for generating randomness (more precisely, sampling via determinism). Last but not least, analytical techniques developed and employed in this paper apply to a wide range of other problems.",Broader Impact,97,4,,,FALSE,FALSE,FALSE,Stochasticity of Deterministic Gradient Descent: Large Learning Rate for Multiscale Objective Function,Optimization,,Theory (including computational and statistical analyses),"['Lingkai Kong', ' Molei Tao']",{'Georgia Institute of Technology'},1,0,0,{'USA'}
Identifying Learning Rules From Neural Network Observables,"Aran Nayebi, Sanjana Srivastava, Surya Ganguli, Daniel L. Yamins",Identifying Learning Rules From Neural Network Observables,1ba922ac006a8e5f2b123684c2f4d65f,https://proceedings.neurips.cc/paper/2020/file/1ba922ac006a8e5f2b123684c2f4d65f-Paper.pdf,"Our work provides a basis as to what neuroscience experimental data should be collected in order to infer plasticity rules. Therefore, the experimental neuroscience community may benefit from this research. The data in this research is collected from neural networks trained on the ImageNet, Word-Speaker-Noise (WSN), and CIFAR-10 datasets. There is well-documented evidence of bias emerging from deep neural networks trained on field-standard large-scale image databases, with many ethical harms stemming from use of the biased algorithms to make important decisions on social policy or limit civil liberties. Rather than using network classifications in a real-world context, our study uses observable measurements from within the network mechanism as simulated brain data. This data is not interpretable to humans and is ultimately used to train and test a classifier to separate learning rules, which are a mathematical formulation and agnostic to any community. This study therefore does not leverage any bias in the data. However, identifying neural network observables that distinguish learning rules presents obvious privacy concerns which could be exploited, for example, to generate adversarial attacks or even to recover training data. It is possible that the observable statistics reflect the workings of a biased “ in silico brain”, in which case the classifier used to separate learning rules may be biased in that it has only been trained and tested on networks whose training data may be biased differently than the training data animals typically receive. This is a problem not just for this study, but generally comes down to available network-training tasks, especially those of the scale needed to provide neurally-plausible representations. Tasks are the most computationally complex factor of variation to add values to, so diversifying the set of tasks is an ongoing effort, and we hope to use balanced, ethically verified large-scale datasets as they become available. Furthermore, given the limited number of subjects in neuroscience experiments, this type of bias is not new in our experiment; the scalability of our approach may provide a way to have more representative data. The only consequence of failure is that the experiment which is performed on the basis of the conclusions we draw may not be as decisive in determining the learning rule.",Broader Impact,365,13,,,FALSE,FALSE,FALSE,Identifying Learning Rules From Neural Network Observables,Neuroscience and Cognitive Science,Deep Learning -> Biologically Plausible Deep Networks; Deep Learning -> CNN Architectures; Deep Learning -> Optimization for Deep Networks; Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and cognitive science,"['Aran Nayebi', ' Sanjana Srivastava', ' Surya Ganguli', ' Daniel Yamins']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Optimal Approximation - Smoothness Tradeoffs for Soft-Max Functions,"Alessandro Epasto, Mohammad Mahdian, Vahab Mirrokni, Emmanouil Zampetakis",Optimal Approximation - Smoothness Tradeoffs for Soft-Max Functions,1bd413de70f32142f4a33a94134c5690,https://proceedings.neurips.cc/paper/2020/file/1bd413de70f32142f4a33a94134c5690-Paper.pdf,"In this paper, we study some basic mathematical properties of soft-max functions and we propose new ones that are optimal with respect to some mathematical criteria. Soft-max functions are fundamental building blocks with many applications, from Machine Learning to Differential Privacy to Resource Allocation. All of these fields have societal impact: Differential Privacy has already been a fundamental mathematical tool to ensure privacy in the digital world and in many cases it has been the only available method to get privacy from services that take place in the digital world. Resource allocation and in particular auction theory has also societal impact, from the way that items are sold in online platforms to the way that ride-sharing applications decide prices, to the nation wide auctions that allocate bandwidth of the frequency spectrum to broadcast companies. Since our paper contributes to one of the fundamental tools in all these areas we believe that it can potentially have a positive impact by improving the outcomes of many algorithms in these topics in terms of e.g. privacy in Differential Privacy applications and revenue in Resource Allocation applications. Although our paper is mostly mathematical in nature, we present also some experimental results applied to data collect from the DBLP dataset. Although we used a public data set, we acknowledge that the data we used may be biased.",Broader Impact,222,7,,,FALSE,FALSE,FALSE,Optimal Approximation - Smoothness Tradeoffs for Soft-Max Functions,Theory,"Deep Learning -> Attention Models; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security; Theory -> Game Theory and Computational Economics; Theory -> Regularization","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Alessandro Epasto', ' Mohammad Mahdian', ' Vahab Mirrokni', ' Emmanouil Zampetakis']","{'Google', 'MIT', 'Google Research', 'Google Research NYC'}",1,1,1,{'USA'}
Weakly-Supervised Reinforcement Learning for Controllable Behavior,"Lisa Lee, Ben Eysenbach, Russ R. Salakhutdinov, Shixiang (Shane) Gu, Chelsea Finn",Weakly-Supervised Reinforcement Learning for Controllable Behavior,1bd69c7df3112fb9a584fbd9edfc6c90,https://proceedings.neurips.cc/paper/2020/file/1bd69c7df3112fb9a584fbd9edfc6c90-Paper.pdf,"We highlight two potential impacts for this work. Most immediately, weak supervision from humans may be an inexpensive yet effective step towards human-AI alignment [34, 55]. While prior work [3, 11, 42] has already shown how weak supervision in the form of preferences can be used to train agents, our work explores how a different type of supervision – invariance to certain factors – can be elicited from humans and injected as an inductive bias in an RL agent. One important yet delicate form of invariance is fairness. In many scenarios, we may want our agent to treat humans of different ages or races equally. While this fairness might be encoded in the reward function, our method presents an alternative, where fairness is encoded as observations’ invariance to certain protected attributes (e.g., race, gender). One risk with this work is misspecification of the factors of variation. If some factors are ignored, then the agent may require longer to solve certain tasks. More problematic is if spurious factors of variation are added to the dataset. In this case, the agent may be “blinded” to parts of the world, and performance may suffer. A question for future work is the automatic discovery of these spurious weak labels.",Broader Impact,205,11,,,FALSE,FALSE,FALSE,Weakly-Supervised Reinforcement Learning for Controllable Behavior,Reinforcement Learning and Planning -> Reinforcement Learning,Deep Learning,Reinforcement learning and planning,"['Lisa Lee', ' Ben Eysenbach', ' Russ Salakhutdinov', ' Shixiang', ' Gu', ' Chelsea Finn']","{'Google Brain', 'Stanford', 'Carnegie Mellon University', 'CMU / Google Brain / Stanford', 'Shane'}",1,1,1,{'USA'}
Improving Policy-Constrained Kidney Exchange via Pre-Screening,"Duncan McElfresh, Michael Curry, Tuomas Sandholm, John Dickerson",Improving Policy-Constrained Kidney Exchange via Pre-Screening,1bda4c789c38754f639a376716c5859f,https://proceedings.neurips.cc/paper/2020/file/1bda4c789c38754f639a376716c5859f-Paper.pdf,"This work lives within the broader context of kidney exchange research. For clarity, we separate our broader impacts into two sections: first we discuss the impact of kidney exchange in general; then we discuss our work in particular, within the context of kidney exchange research and practice. Impacts of Kidney Exchange Patients with end-stage renal disease have only two options: receive a transplant, or undergo dialysis once every few days, for the rest of their lives. In many countries (including the US), these patients register for a deceased donor waiting list–and it can be months or years before they receive a transplant. Many of these patients have a friend or relative willing to donate a kidney, however many patients are incompatible with their corresponding donor. Kidney exchange allows patients to “swap” their incompatible donor, in order to find a higher-quality match, more quickly than a waiting list. Transplants allow patients a higher quality of life, and cost far less, than lifelong dialysis. About 10% of kidney transplants in the US are facilitated by an exchange. Finding the “most efficient” matching of kidney donors to patients is a (computationally) hard problem, which cannot be solved by hand in most cases. For this reason many fielded exchanges use algorithms to quickly find an efficient matching of patients and donors. Many researchers study kidney exchange from an algorithmic perspective, often with the goal of improving the number or quality of transplants facilitated by exchanges. Indeed, this is the purpose of our paper. Impacts of Our Work In this paper we investigate the impact of pre-screening certain potential transplants (edge) in an exchange, prior to constructing the final patient-donor matching. To our knowledge, some modern fielded exchanges pre-screen potential transplants in an ad-hoc manner; meaning they do not consider the impacts of pre-screening on the final matching. We propose methods to estimate the importance of pre-screening each edge, as measured by the change in the overall number and quality of matched transplants.7 Importantly, our methods do not require a change in matching policy; instead, they indicate to policymakers which potential transplants are important to pre-screen, and which are not. The impacts of our contributions are summarized below: Some potential transplants cannot be matched, because they cannot participate in a “legal” cyclical or chain-like swap (according to the exchange matching policy). Accordingly, there is no “value” gained by pre-screening these transplants; our methods will identify these potential transplants, and will recommend that they not be pre-screened. Pre-screening requires doctors to spend valuable time reviewing potential donors; removing these unmatchable transplants from pre-screening will allow doctors to focus only on transplants that are relevant to the current exchange pool. Some transplants are more important to pre-screen than others, and our methods help identify which are most important for the final matching. We estimate the value pre-screening of each transplant by simulating the exchange matching policy in the case that the pre-screened edge is pre-accepted, and in the case that it is pre-refused. To estimate the value of pre-screening each transplant, we need to know (a) the likelihood that each transplant is pre-accepted and pre-refused, and (b) the likelihood that each planned transplant fails for any reason, after being matched. These likelihoods are used as input to our methods, and they can influence the estimated value of pre-screening different transplants. Importantly, it may not be desirable to calculate these likelihoods for each potential transplant (e.g., using data from the past). For example if a patient is especially sick, we may estimate that any potential transplant involving this patient is very likely to fail prior to transplantation (e.g., because the patient is to ill to undergo an operation). In this case, our methods may estimate that all potential transplants involving this patient have very low “value”, and therefore recommend that these transplants should not be pre-screened. One way to avoid this issue is to use the same likelihood estimates for all transplants. To estimate the impact of our methods (and how they depend on the assumed likelihoods, see above), we recommend using extensive modeling of different pre-screening scenarios before deploying our methods in a fielded exchange. This is important for several reasons: first, exchange programs cannot always require that doctors pre-screen potential transplants prior to matching. Since we cannot be sure which transplants will be pre-screened and which will not, simulations should be run to evaluate each possible scenario. Second, theoretical analysis shows that pre-screening transplants can—in the worst case—negatively impact the final outcome. While this worst-case outcome is possible, our computational experiments show that it is very unlikely; this can be addressed further with mode experiments tailored to a particular exchange program. 7 Quality and quantity of transplants is measured by transplant weight, a numerical representation of transplant quality (e.g., see UNOS/OPTN Policy 13 regarding KPD prioritization points https://optn.transplant. hrsa.gov/media/1200/optn_policies.pdf).",Broader Impact,803,33,,,TRUE,TRUE,FALSE,Improving Policy-Constrained Kidney Exchange via Pre-Screening,Optimization,Applications -> Health; Optimization -> Discrete Optimization; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Healthcare,"['Duncan McElfresh', ' Michael Curry', ' Tuomas Sandholm', ' John Dickerson']","{'CMU, Strategic Machine, Strategy Robot, Optimized Markets', 'University of Maryland', 'University of Maryland College Park'}",1,1,1,{'USA'}
Learning abstract structure for drawing by efficient motor program induction,"Lucas Tian, Kevin Ellis, Marta Kryven, Josh Tenenbaum",Learning abstract structure for drawing by efficient motor program induction,1c104b9c0accfca52ef21728eaf01453,https://proceedings.neurips.cc/paper/2020/file/1c104b9c0accfca52ef21728eaf01453-Paper.pdf,"We envision a number of scientific, societal and engineering benefits that may emerge from this study. First, this work may benefit the treatment, diagnosis, and prevention of cognitive disorders, such as disorders involving planning, reasoning, and learning. The methodology of our task may be particularly relevant for disorders that cause striking impairment in drawing behavior (for example, dementia, traumatic brain injury, and stroke). A computational understanding of cognitive impairment may lead to more accurate, quantitative diagnostic tools (by categorizing disorders based on cognitive computations) and to more efficient targeted treatment (by targeting of specific impairments). Second, computational understanding of how humans think is insightful from a basic science per- spective, because it advances our understanding of nature and the human condition. In addition to the current study of human adults, we are studying this task in children, and in non-human primates in a neurophysiological setting, with the goal of also studying this task at a neural level. One long-term goal of this multi-species investigation is to develop an evolutionary, developmental, and mechanis- tic understanding of how learning of complex structure can emerge from simple components and computational principles. Third, from an engineering standpoint, this work may lead to AI that is more easily integrated into, and more beneficial to society. The ability to learn new human-like inductive biases from a small number of examples may facilitate human-computer interaction, particularly within programming- by-examples technologies [ 50]. Engineering outcomes of this research may also contribute to tools that benefit education. The link to learning drawing and art is obvious, but there may also exist links to topics that involve structured symbolic reasoning, such as math, science, or music. For instance, modeling a given student’s learning trajectory may reveal what she knows and what strategies she uses to learn, which may suggest ways to either tailor her future learning, or to remedy current difficulties. In principle, work along this line may potentially be used to create “fake” artifacts meant to pass as human. The most obvious kinds of fake artifacts are those related to drawing, but this extends to other kinds of art and media, including internet bots that impersonate humans by generating tweets from examples. One potential implication is that fakes will be used to confuse and manipulate society. Ways to address this should fall under strategies and considerations already being developed to understand the impact of increasingly human-like AI on society. A second implication is that mass-produced AI artifacts could lower the quality of creative content in the world, and compete with high-quality human-made creations. We think of this possibility as an ethical gray area, and note that it is an extension of the apparently already-occurring trend towards larger amounts of mass-produced media in society. Acknowledgments We thank Nathalie Fernandez, Brenden Lake, Max Siegel and João Loula and the Tenenbaum lab for helpful feedback. Kevin Ellis was supported by a NSF GFRP. Work supported by the NSF-funded Center for Brains, Minds, and Machines. The authors have no competing interests to disclose.",5 Broader Impact,500,22,,,FALSE,FALSE,FALSE,Learning abstract structure for drawing by efficient motor program induction,Neuroscience and Cognitive Science -> Cognitive Science,Algorithms -> Program Induction; Neuroscience and Cognitive Science -> Human or Animal Learning,Neuroscience and cognitive science,"['Lucas Tian', ' Kevin Ellis', ' Marta Kryven', ' Josh Tenenbaum']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks? --- A Neural Tangent Kernel Perspective,"Kaixuan Huang, Yuqing Wang, Molei Tao, Tuo Zhao",Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks? — A Neural Tangent Kernel Perspective,1c336b8080f82bcc2cd2499b4c57261d,https://proceedings.neurips.cc/paper/2020/file/1c336b8080f82bcc2cd2499b4c57261d-Paper.pdf,"This paper makes a significant contribution to extending the frontier of deep learning theory, and increases the intellectual rigor. To the best of our knowledge, our results are the first one for analyzing the effect of depth on the generalization of neural tangent kernels (NTKs). Moreover, our results are also the first one establishing the non-asymptotic bounds for NTKs of ResNets when all but the last layers are trained, which enables us to successfully analyze the generalization properties of ResNets through the perspective of NTK. This is in sharp contrast to the existing impractical theoretical results for NTKs of ResNets, which either only apply to an over-simplified structure of ResNets or only deal with the case when the last layer is trained.",Broader Impact,122,4,,,FALSE,TRUE,FALSE,Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks? --- A Neural Tangent Kernel Perspective,Algorithms -> Kernel Methods,Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Kaixuan Huang', ' Yuqing Wang', ' Molei Tao', ' Tuo Zhao']","{'Princeton University', 'Georgia Institute of Technology', 'Gatech'}",1,0,0,{'USA'}
Dual Instrumental Variable Regression,"Krikamol Muandet, Arash Mehrjou, Si Kai Lee, Anant Raj",Dual Instrumental Variable Regression,1c383cd30b7c298ab50293adfecb7b18,https://proceedings.neurips.cc/paper/2020/file/1c383cd30b7c298ab50293adfecb7b18-Paper.pdf,"This work provides a new framework for non-linear instrumental variable regression which allows one to perform causal analysis under the presence of unobserved confounders. This could have a profound impact in other fields such as economics, social science, and epidemiology, among oth- ers. Understanding the role of instruments in the context of learning theory may also pave the way towards creating more robust and trustworthy machine learning algorithms that are capable of sur- viving in the world full of hidden biases.",Broader impact,81,3,,,FALSE,FALSE,FALSE,Dual Instrumental Variable Regression,Probabilistic Methods -> Causal Inference,Algorithms -> Kernel Methods; Optimization -> Stochastic Optimization,Causality,"['Krikamol Muandet', ' Arash Mehrjou', ' Si Kai Lee', ' Anant Raj']","{'Chicago Booth School of Business', 'Max Planck Institute for Intelligent Systems', 'Max Planck Institute'}",1,0,0,"{'USA', 'Germany'}"
Stochastic Gradient Descent in Correlated Settings: A Study on Gaussian Processes,"Hao Chen, Lili Zheng, Raed AL Kontar, Garvesh Raskutti",Stochastic Gradient Descent in Correlated Settings: A Study on Gaussian Processes,1cb524b5a3f3f82be4a7d954063c07e2,https://proceedings.neurips.cc/paper/2020/file/1cb524b5a3f3f82be4a7d954063c07e2-Paper.pdf,"Practitioners in various areas including, but not limited to, machine learning, statistics and optimization can benefit from applying our proposed framework. Our framework does not use any bias in the data or sensitive information. We do not foresee any negative outcomes on ethical aspects or future societal consequences.",Broader Impact,48,3,FALSE,FALSE,FALSE,TRUE,FALSE,Stochastic Gradient Descent in Correlated Settings: A Study on Gaussian Processes,Probabilistic Methods -> Gaussian Processes,Algorithms -> Stochastic Methods; Optimization -> Stochastic Optimization; Probabilistic Methods -> Bayesian Nonparametrics; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Hao Chen', ' Lili Zheng', ' Raed AL Kontar', ' Garvesh Raskutti']","{'University of Wisconsin-Madison', 'University of Michigan'}",1,0,0,{'USA'}
Interventional Few-Shot Learning,"Zhongqi Yue, Hanwang Zhang, Qianru Sun, Xian-Sheng Hua",Interventional Few-Shot Learning,1cc8a8ea51cd0adddf5dab504a285915,https://proceedings.neurips.cc/paper/2020/file/1cc8a8ea51cd0adddf5dab504a285915-Paper.pdf,"The proposed method aims to improve the Few-Shot Learning task. Advancements in FSL helps the deployment of machine learning models in areas where labelled data is difficult or expensive to obtain and it is closely related to social well-beings: few-shot drug discovery or medical imaging analysis in medical applications, cold-start item recommendation in e-commerce, few-shot reinforcement learning for industrial robots, etc. . Our method is based on causal inference and the analysis is rooted on causation rather than correlation. The marriage between causality and machine learning can produce more robust, transparent and explainable models, broadening the applicability of ML models and promoting fairness in artificial intelligence.",8 Broader Impact,106,5,,,FALSE,FALSE,FALSE,Interventional Few-Shot Learning,Algorithms -> Few-Shot Learning,Probabilistic Methods -> Causal Inference,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Zhongqi Yue', ' Hanwang Zhang', ' Qianru Sun', 'Sheng Hua']","{'Nanyang Technological University', 'Damo Academy, Alibaba Group', 'NTU', 'Singapore Management University'}",1,1,1,"{'Singapore', 'UK', 'China'}"
Minimax Value Interval for Off-Policy Evaluation and Policy Optimization,"Nan Jiang, Jiawei Huang",Minimax Value Interval for Off-Policy Evaluation and Policy Optimization,1cd138d0499a68f4bb72bee04bbec2d7,https://proceedings.neurips.cc/paper/2020/file/1cd138d0499a68f4bb72bee04bbec2d7-Paper.pdf,"This work is largely of theoretical nature, trying to unify existing methods and pointing out their connections, with minimal proof-of-concept simulation experiments. Therefore, we do not foresee direct broader impact. That said, an important motivation for this work is to equip RL with off-line evaluation methods that rely on as few assumptions as possible, and in the long term this should contribute to a more trustworthy framework for applying RL to real-world tasks, where reliable evaluation is indispensable. We warn, however, that even though we aim at a less ambitious goal of producing a valid interval (whose length may not go to 0 as sample size increases), we still require unverifiable assumptions (realizability of C ( Q ) or C ( W ) ). Therefore, the value intervals produced by this and subsequent papers should be interpreted and treated with care and not taken as-is in application scenarios. There are also several important aspects of building practically useful confidence intervals that are ignored in this paper (since we are still in the early stage of theoretical investigations), such as the handling of statistical errors and possible confoundedness in the data, which need to be addressed by future works before these methods can be readily deployed in applications.",Broader Impact,207,6,,,FALSE,FALSE,FALSE,Minimax Value Interval for Off-Policy Evaluation and Policy Optimization,Reinforcement Learning and Planning -> Reinforcement Learning,Theory,Reinforcement learning and planning,,{'University of Illinois at Urbana-Champaign'},1,0,0,{'USA'}
Biased Stochastic First-Order Methods for Conditional Stochastic Optimization and Applications in Meta Learning,"Yifan Hu, Siqi Zhang, Xin Chen, Niao He",Biased Stochastic First-Order Methods for Conditional Stochastic Optimization and Applications in Meta Learning,1cdf14d1e3699d61d237cf76ce1c2dca,https://proceedings.neurips.cc/paper/2020/file/1cdf14d1e3699d61d237cf76ce1c2dca-Paper.pdf,This paper is purely theoretical and has no immediate ethical or societal consequences.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Biased Stochastic First-Order Methods for Conditional Stochastic Optimization and Applications in Meta Learning,Optimization -> Stochastic Optimization,Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization,Theory (including computational and statistical analyses),,"{'UIUC', 'University of Illinois at Urbana-Champaign'}",1,0,0,{'USA'}
ShiftAddNet: A Hardware-Inspired Deep Network,"Haoran You, Xiaohan Chen, Yongan Zhang, Chaojian Li, Sicheng Li, Zihao Liu, Zhangyang Wang, Yingyan Lin",ShiftAddNet: A Hardware-Inspired Deep Network,1cf44d7975e6c86cffa70cae95b5fbb2,https://proceedings.neurips.cc/paper/2020/file/1cf44d7975e6c86cffa70cae95b5fbb2-Paper.pdf,"Efficient DNN training goal. Recent DNN breakthroughs rely on massive data and computational power. Also, the modern DNN training requires massive yet inefficient multiplications in the convolution, making DNN training very challenging and limiting the practical applications on resource-constrained mobile devices. First, training DNNs causes prohibitive computational costs. For example, training a medium scale DNN, ResNet-50, requires ten to the power of eighteen floating- point operations or FLOPs [51]. Second, DNN training has raised pressing environmental concerns. For instance, the carbon emission of training one DNN can be as high as one American cars’ life-long emission [52, 50]. Therefore, efficient DNN training has become a very important research problem. Generic hardware-inspired algorithm. To achieve the efficient training goal, this paper takes one further step along the direction of multiplication-less deep networks. by drawing a very fundamental idea in the hardware-design practice, computer processors, and even digital signal processing. It has been known for long that multiplications can be performed with additions and logical bit-shifts [6], whose hardware implementation is very simple and much faster [8], without compromising the result quality or precision. The above clever “shortcut” saves arithmetic operations, and can readily be applied to accelerating the hardware implementation of any machine learning algorithm involving multiplication (either scalar, vector or matrix). But our curiosity is well beyond this: we are supposed to learn from this hardware-level “shortcut"", for designing efficient learning algorithms. Societal consequences. Success of this project enables both efficient online training and inference of state-of-the-art DNNs in pervasive resource-constrained platforms and applications. As machine learning powered edge devices have penetrated all walks of life, the project is expected to generate tremendous impacts on societies and economies. Progress on this paper will enable ubiquitous DNN- powered intelligent functions in edge devices, across numerous camera-based Internet-of-Things (IoT) applications such as traffic monitoring, self-driving and smart cars, personal digital assistants, surveillance and security, and augmented reality. We believe the hardware-inspired ShiftAddNet is a significant efficient network training methods, which would make an impact to the society.",Broader impact,335,19,,,FALSE,FALSE,FALSE,ShiftAddNet: A Hardware-Inspired Deep Network,Deep Learning -> Efficient Training Methods,Deep Learning -> CNN Architectures; Deep Learning -> Efficient Inference Methods,Deep learning,"['Haoran You', ' Xiaohan Chen', ' Yongan Zhang', ' Chaojian Li', ' Sicheng Li', ' Zihao Liu', ' Zhangyang Wang', ' Yingyan Lin']","{'University of Texas at Austin', 'Alibaba group', 'Rice University', 'Alibaba Group'}",1,1,1,"{'USA', 'China'}"
Network-to-Network Translation with Conditional Invertible Neural Networks,"Robin Rombach, Patrick Esser, Bjorn Ommer",Network-to-Network Translation with Conditional Invertible Neural Networks,1cfa81af29c6f2d8cacb44921722e753,https://proceedings.neurips.cc/paper/2020/file/1cfa81af29c6f2d8cacb44921722e753-Paper.pdf,"Environmental and Economic Aspects: Single training runs of large scale models have a large environmental footprint due to the massive computational requirements. It is therefore unreasonable to repeat this effort for every new application. Instead we allow to reuse powerful models, leading to significant reductions in computational demands. Boosting serendipity: New (scientific) knowledge arises where seemingly unrelated entities are brought together to study their relationship (cf. the ’double projection’ proposed by Heinrich Wölfflin a century ago for art history and other image disciplines to easily contextualize diverse imagery of different cultures). Allowing to efficiently connect expert models for diverse data and problems, thus promises to provide the basis for new directions of future research. Interdisciplinary research: One of the main stumbling blocks for interdisciplinary research (e.g. vision and language) is to bring together expert models for widely different domains. State-of-the-art models are typically developed in and for the individual disciplines. Being able to efficiently combine these disciplinary expert models to solve interdisciplinary problems promises to be an enabling factor for more effective cross-disciplinary research. Social equality: Training state-of-the art models is typically so costly that only wealthy institutions can afford their transfer and application to different input domains or other subsequent research that would require to retrain them. Computationally efficient transfer of existing models with no need for costly retraining therefore increases the opportunities for economically weaker institutions and countries to have research programs in this field. Increasing applicability and impact of research output: Large scale research is often funded by public resources and thus there is a responsibility to make results accessible to the public. While pretrained models are often shared publicly, the scope in which they can be applied is significantly widened by our approach. Content creation and manipulation: Domain transfer applied to controlled image synthesis and modification has wide applica- bility in the creative industry and beyond. However, it can also be misused for forgery and manipulation.",Broader Impact,320,15,,,FALSE,FALSE,FALSE,Network-to-Network Translation with Conditional Invertible Neural Networks,Deep Learning -> Generative Models,"Applications -> Computer Vision; Deep Learning -> Deep Autoencoders; Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,,{'Heidelberg University'},1,0,0,{'Germany'}
Intra-Processing Methods for Debiasing Neural Networks,"Yash Savani, Colin White, Naveen Sundar Govindarajulu",Intra-Processing Methods for Debiasing Neural Networks,1d8d70dddf147d2d92a634817f01b239,https://proceedings.neurips.cc/paper/2020/file/1d8d70dddf147d2d92a634817f01b239-Paper.pdf,"Deep learning algorithms are more prevalent than ever before. The technology is becoming more and more integrated into society, and is used in high-stakes applications such as criminal recidivism, loan repayment, and hiring decisions [ 43, 7, 45, 3]. It is also becoming increasingly more evident that many of these algorithms are biased from various sources [49, 46, 47]. Using technology for life-changing events which make prejudiced decisions will only deepen the divides that exist in society, and the need to address these issues is higher than ever [4, 48]. Our work seeks to decrease the negative effects that biased deep learning algorithms have on society. Intra-processing methods, which work for any group fairness measure, will be applicable to large existing deep learning models, since the networks need not be retrained from scratch. Furthermore, we present simple techniques (random perturbation) as well as more complex and strong techniques (adversarial fine-tuning). Since we study the nature of intra-processing debiasing and present a study comparing prior work to our algorithms, our work may facilitate future work in intra-processing debiasing techniques. Impact on bias in judicial applications We briefly discuss how intra-processing methods for debiasing could help in judicial settings. Some machine learning algorithms which are prejudiced have been used in judicial applications in the past [54, 22]. Studies and investigations have found that many of the algorithms have some form of bias [35]. Moreover, different entities using the same model might prefer to use different fairness measures and some of these measures might be incompatible [12]. Generally, the entities that build and use the applications are not the same. Therefore, due to legal and licensing issues, the entity using the application may not have access to the training dataset. This precludes the use of pre-processing and in-processing methods for debiasing. The entity using the model usually has its own dataset available (e.g. a local court tracking their recidivism rates). This makes intra-processing and post-processing techniques the only viable methods for debiasing.",7 Broader Impact,329,17,,,FALSE,FALSE,FALSE,Intra-Processing Methods for Debiasing Neural Networks,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yash Savani', ' Colin White', ' Naveen Sundar Govindarajulu']",{'RealityEngines.AI'},0,1,0,{'USA'}
Finding Second-Order Stationary Points Efficiently in Smooth Nonconvex Linearly Constrained Optimization Problems,"Songtao Lu, Meisam Razaviyayn, Bo Yang, Kejun Huang, Mingyi Hong",Finding Second-Order Stationary Points Efficiently in Smooth Nonconvex Linearly Constrained Optimization Problems,1da546f25222c1ee710cf7e2f7a3ff0c,https://proceedings.neurips.cc/paper/2020/file/1da546f25222c1ee710cf7e2f7a3ff0c-Paper.pdf,"Our main contributions in this work include both new theoretical and numerical results for solving nonconvex optimization problems under linear constraints. The theoretical part is regarding the new insight of a mathematical problem and the proposed algorithm is very general in the sense it can be applied not only to machine learning problems, but also to other general linear constrained problems in any other fields. Therefore, this works would be beneficial for both scientists/professors who are performing research in the area of machine learning and students who are studying operation research, engineering, data science, finance, etc. The theories and ideas in this work can potentially lead to significant improvements on the “off-the-shelf” optimization solvers and packages by equip- ping them with efficient modules for escaping saddle points in the presence of linear constraints. In addition to the methodological developments, the viewpoint of looking at the generic optimization problem instances could have potential broader impact on analyzing and resolving other issues in the continuous optimization field as well. While this work handles one specific hard task (i.e. finding SOSPs) by analyzing generic problem instances, this viewpoint could result in new tools and theories for dealing with other hard tasks for generic optimization instances. We haven’t found any negative impact of this work on both ethical aspects and future societal con- sequences.",7 Broader Impact,220,7,,,FALSE,FALSE,FALSE,Finding Second-Order Stationary Points Efficiently in Smooth Nonconvex Linearly Constrained Optimization Problems,Optimization -> Non-Convex Optimization,,Optimization Methods (continuous or discrete),"['Songtao Lu', ' Meisam Razaviyayn', ' Bo Yang', ' Kejun Huang', ' Mingyi Hong']","{'University of Minnesota', 'IBM Research', 'University of Southern California', 'University of Florida'}",1,1,1,{'USA'}
Model-based Policy Optimization with Unsupervised Model Adaptation,"Jian Shen, Han Zhao, Weinan Zhang, Yong Yu",Model-based Policy Optimization with Unsupervised Model Adaptation,1dc3a89d0d440ba31729b0ba74b93a33,https://proceedings.neurips.cc/paper/2020/file/1dc3a89d0d440ba31729b0ba74b93a33-Paper.pdf,"The proposed model adaptation can be incorporated into existing Dyna-style model-based methods, such as MBPO in this paper, to further improve the sample efficiency. This improvement will ease the application of MBRL in practical decision-making problems like robotic control in the future. Despite the potential positive impacts of model adaptation, we should also notice some negative issues. It will cost more to tune real-world MBRL systems with model adaptation to avoid too strong or too weak adaptation, which is usually related to specific environments. We hope our work can provide insights for future improvements in tackling the distribution mismatch problem in MBRL.",Broader Impact,102,5,,,FALSE,FALSE,FALSE,Model-based Policy Optimization with Unsupervised Model Adaptation,Reinforcement Learning and Planning -> Model-Based RL,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Jian Shen', ' Han Zhao', ' Weinan Zhang', ' Yong Yu']","{'Carnegie Mellon University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong Unviersity'}",1,0,0,"{'USA', 'China'}"
Implicit Regularization and Convergence for Weight Normalization,"Xiaoxia Wu, Edgar Dobriban, Tongzheng Ren, Shanshan Wu, Zhiyuan Li, Suriya Gunasekar, Rachel Ward, Qiang Liu",Implicit Regularization and Convergence for Weight Normalization,1de7d2b90d554be9f0db1c338e80197d,https://proceedings.neurips.cc/paper/2020/file/1de7d2b90d554be9f0db1c338e80197d-Paper.pdf,"Our work is on the foundations and theory of machine learning. One of the distinctive characteristics of contemporary machine learning is that it relies on a large number of ""ad hoc"" techniques, that have been developed and validated through computational experiments. For instance, the optimization of neural networks is in general a highly nonconvex problem, and there is no complete theoretical understanding yet as to how exactly it works in practice. Moreover, there a large number of practical ""hacks"" that people have developed that help in practice, but lack a solid foundation. Our work is about one of these techniques, weight normalization. We develop some nontrivial theoretical results about it in a simplified ""model"". This work does not directly propose any new algorithms. But we hope that our work will have an impact in practice, namely that it will help practitioners understand what the WN method is doing (important, as people naturally want to understand and know ""why"" things work), and possibly in the future, help us develop better algorithms (here the principle being that ""if you understand it you can improve it"", which has been useful in engineering and computer science for decades).",Broader Impact,194,8,,,FALSE,FALSE,FALSE,Implicit Regularization and Convergence for Weight Normalization,Theory,Optimization -> Non-Convex Optimization; Theory -> Regularization,Theory (including computational and statistical analyses),"['Xiaoxia Wu', ' Edgar Dobriban', ' Tongzheng Ren', ' Shanshan Wu', ' Zhiyuan Li', ' Suriya Gunasekar', ' Rachel Ward', ' Qiang Liu']","{'Princeton University', 'Dartmouth College', 'University of Texas at Austin', 'UT Austin', 'University of Pennsylvania', 'Microsoft Research Redmond', 'The University of Texas at Austin'}",1,1,1,{'USA'}
Geometric All-way Boolean Tensor Decomposition,"Changlin Wan, Wennan Chang, Tong Zhao, Sha Cao, Chi Zhang",Geometric All-Way Boolean Tensor Decomposition,1def1713ebf17722cbe300cfc1c88558,https://proceedings.neurips.cc/paper/2020/file/1def1713ebf17722cbe300cfc1c88558-Paper.pdf,"GETF is a Boolean tensor factorization algorithm, which provides a solution to a fundamental mathematical problem. Hence we consider it is not with a significant subjective negative impact to the society. The structure of binary data naturally encodes the structure of subspace clusters in the data structure. We consider the efficient BTD and HBTD capability led by GETF enables the seeding of patterns for subspace clustering identification or disentangled representation learning, for the data with unknown subspace structure, such as recommendation of different item classes to customers with unknown groups or biomedical data of different patient classes. As we have demonstrated the high computational efficiency of GETF grants the capability to analyze large or high order tensor data, another field can be potentially benefited by GETF is the inference made to the spatial-temporal data collected from mobile sensors. The high efficiency of GETF enable a possible implementation on smart phones for a real-time inference of the data collected from the phones or other multi-modal personal wearable sensors.",7 Broader Impact,167,6,,,FALSE,FALSE,FALSE,Geometric All-way Boolean Tensor Decomposition,Applications -> Matrix and Tensor Factorization,Algorithms -> Relational Learning; Applications -> Information Retrieval,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Changlin Wan', ' Wennan Chang', ' Tong Zhao', ' Sha Cao', ' Chi Zhang']","{'Indiana University School of Medicine', 'Amazon', 'Indiana University', 'Department of Electrical and Computer Engineering, Purdue University'}",1,1,1,{'USA'}
Modular Meta-Learning with Shrinkage,"Yutian Chen, Abram L. Friesen, Feryal Behbahani, Arnaud Doucet, David Budden, Matthew Hoffman, Nando de Freitas",Modular Meta-Learning with Shrinkage,1e04b969bf040acd252e1faafb51f829,https://proceedings.neurips.cc/paper/2020/file/1e04b969bf040acd252e1faafb51f829-Paper.pdf,"This paper presents a general meta-learning technique to automatically identify task-specific modules in a model for few-shot machine learning problems. It reduces the need for domain experts to hand-design task-specific architectures, and thus further democratizes machine learning, which we hope will have a positive societal impact. In particular, general practitioners who can not afford to collect a large amount of labeled data will be able to take advantage of a pre-trained generic meta-model and adapt its task-specific components to a new task based on limited data. One example application might be to adapt a multilingual text-to-speech model to a low-resource language or the dialect of a minority ethnic group. As a data-driven method, like other machine learning techniques, the task-independent and task- specific modules discovered by our method are based on the distribution of tasks in the meta-training phase. Adaptation may not generalize to a task with characteristics that fundamentally differ from those of the training distribution. Applying our method to a new task without examining the task  similarity runs the risk of transferring induced bias from meta-training to the out-of-distribution task. For example, a meta image classification model trained only on vehicles is unlikely to be able to be finetuned to accurately identify a pedestrian based on the adaptable modules discovered during meta-training. To mitigate this problem, we suggest ML practitioners first understand whether the characteristics of the new task match those of the training task distribution before applying our method.",Broader Impact,242,9,,,FALSE,FALSE,FALSE,Modular Meta-Learning with Shrinkage,Algorithms -> Meta-Learning,Algorithms -> Few-Shot Learning; Algorithms -> Multitask and Transfer Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yutian Chen', ' Abram Friesen', ' Feryal Behbahani', ' Arnaud Doucet', ' David Budden', ' Matthew Hoffman', ' Nando de Freitas']","{'Google DeepMind', 'DeepMind'}",0,1,0,{'UK'}
A/B Testing in Dense Large-Scale Networks: Design and Inference,"Preetam Nandy, Kinjal Basu, Shaunak Chatterjee, Ye Tu",A/B Testing in Dense Large-Scale Networks: Design and Inference,1e0b802d5c0e1e8434a771ba7ff2c301,https://proceedings.neurips.cc/paper/2020/file/1e0b802d5c0e1e8434a771ba7ff2c301-Paper.pdf,"Online A/B testing plays the most crucial role in product development in the internet industry by deciding which recommender system is an optimal choice. The optimality criterion often focuses on the experience of the direct users of the recommender system, e.g., the viewers of a social media newsfeed or the recruiters searching for potential candidates. This choice can have a potentially negative impact on the people indirectly affected by these recommendation choices. For example, the less popular content creators or a certain group of jobseekers might be getting less exposure than the already popular creators or candidates, leading to a “rich get richer"" ecosystem. There has been a growing interest in enhancing the experience of the people that are indirectly affected. However, a significant obstacle to achieving this goal is that these indirect effects are challenging to measure in an online A/B testing experiment. In this paper, we take a step toward solving this problem, which can potentially lead to product developments focusing on the holistic improvement of the underlying ecosystem.",Broader Impact,171,7,,,FALSE,FALSE,FALSE,A/B Testing in Dense Large-Scale Networks: Design and Inference,Applications -> Web Applications and Internet Data,Probabilistic Methods -> Causal Inference,Causality,"['Preetam Nandy', ' Kinjal Basu', ' Shaunak Chatterjee', ' Ye Tu']","{'LinkedIn', 'Linkedin', 'LinkedIn Corporation'}",0,1,0,{'USA'}
What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation,"Vitaly Feldman, Chiyuan Zhang",What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation,1e14bfe2714193e7af5abc64ecbd6b46,https://proceedings.neurips.cc/paper/2020/file/1e14bfe2714193e7af5abc64ecbd6b46-Paper.pdf,"We believe that our work elucidates one of the most fundamental aspects of learning from natural data. Understanding how the behaviour of a learning system depends on or exploits the properties of the data is crucial for safe and responsible applications of the system. As a concrete example, our work demonstrates that accuracy of a learning algorithm on log tailed data distributions depends on its ability to memorize the labels. As our results show, the effect on the accuracy of not memorizing examples depends on the number of available examples and the data variability (a formal analysis of this dependence can be found in [13]). This means that the effect on accuracy will be higher on an under-represented subpopulation. The immediate implication is that techniques that limit the ability of a learning system to memorize will have a disproportionate effect on under-represented subpopulations. Techniques aimed at optimizing the model size (e.g. model compression) or training time are likely to affect the ability of the learning algorithm to memorize data. This scenario is not hypothetical as it is already known that differential privacy (which formally limits the ability to memorize data) has such disparate effect on model accuracy [4]. Ability to understand (or at least gain meaningful insights into) the predictions of a learning system can aid in ensuring that the system satisfies the desired properties (in particular, properties that have societal consequences). Our influence estimator can be used to show which training examples most affect the prediction on a given point. In addition to providing insights, it can serve as a way to improve the data collection so as to achieve the desired properties. While several other approaches for influence estimation exist, we believe that our approach provides substantially easier to interpret results. Unlike some of the existing techniques [19, 30, 24] it is also completely model-agnostic and is itself easy to explain.",Broader Impact,313,13,,,FALSE,FALSE,FALSE,What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation,Deep Learning -> Analysis and Understanding of Deep Networks,"Deep Learning -> Visualization, Interpretability, and Explainability; Theory -> Models of Learning and Generalization",,"['Vitaly Feldman', ' Chiyuan Zhang']",{'Google Brain'},0,1,0,{'USA'}
Partially View-aligned Clustering,"Zhenyu Huang, Peng Hu, Joey Tianyi Zhou, Jiancheng Lv, Xi Peng",Partially View-aligned Clustering,1e591403ff232de0f0f139ac51d99295,https://proceedings.neurips.cc/paper/2020/file/1e591403ff232de0f0f139ac51d99295-Paper.pdf,"Multi-view clustering is a common topic in multi-view learning which could be applied to a wide range of applications including computer vision, recommender systems, data retrieval, natural language processing. Our work could address the partially view-aligned problem faced by many real-world applications and perform multi-view clustering. While there will be important impacts resulting from the use of PVC in general (depend on various multi-view applications), here we focus on the impact of using our method to address the partially view-aligned problem which is widely faced by the real-world applications. There are many benefits to solving this problem, such as reducing the costs of manually aligning multi-view data, increasing the robustness for downstream tasks by handling PVP. Besides the benefits we should also care about the potential negative impacts including 1) The risk of automation bias [21] for decision making, especially in aviation, health care, and autonomous vehicles. 2) The job loss caused by the PVC since it can automatically establish the correspondence on the unaligned data. Usually, this requires domain experts to manually align them. We would encourage further work to understand and mitigate the above biases and risks. Concerning the risk of automation bias, we encourage research to understand the final decision with domain expertise.",Broader Impact Statement,206,9,,,FALSE,FALSE,FALSE,Partially View-aligned Clustering,Algorithms -> Multimodal Learning,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Zhenyu Huang', ' Peng Hu', ' Joey Tianyi Zhou', ' Jiancheng Lv', ' Xi Peng', ' Technology and Research']","{'Institute for Infocomm Research, A*STAR', 'Sichuan University', 'IHPC, A*STAR', 'A*STAR', 'Machine Intelligence Laboratory College of Computer Science, Sichuan University'}",1,1,1,"{'Singapore', 'China'}"
Partial Optimal Tranport with applications on Positive-Unlabeled Learning,"Laetitia Chapel, Mokhtar Z. Alaya / Laboratoire LITIS, Université de Rouen Normandie, Gilles Gasso",Partial Optimal Transport with Applications on Positive-Unlabeled Learning,1e6e25d952a0d639b676ee20d0519ee2,https://proceedings.neurips.cc/paper/2020/file/1e6e25d952a0d639b676ee20d0519ee2-Paper.pdf,"This work does not present any significant societal, environnemental or ethical consequence.",Broader impact,12,1,TRUE,FALSE,FALSE,FALSE,FALSE,Partial Optimal Transport with applications on Positive-Unlabeled Learning,Algorithms -> Classification,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Laetitia Chapel', ' Alaya', ' Gilles Gasso']","{'IRISA', 'LITIS - INSA de Rouen', 'LITIS Lab, University Rouen Normandy'}",1,0,0,{'France'}
Toward the Fundamental Limits of Imitation Learning,"Nived Rajaraman, Lin Yang, Jiantao Jiao, Kannan Ramchandran",Toward the Fundamental Limits of Imitation Learning,1e7875cf32d306989d80c14308f3a099,https://proceedings.neurips.cc/paper/2020/file/1e7875cf32d306989d80c14308f3a099-Paper.pdf,"An important conclusion of our work is that algorithms that require an expert that can be actively queried, in the worst case, do not break the error compounding barrier. While it is plausible that such algorithms do indeed perform better in practical problems, it still raises an important point that compounding errors is fundamental to IL and requires a better understanding in practice. Furthermore, our proposed algorithm M IMIC -MD in the known-transition setting reveals some new algorithmic primitives that can hopefully inspire practitioners to design algorithms that perform better.",Broader Impact,90,3,,,FALSE,FALSE,FALSE,Toward the Fundamental Limits of Imitation Learning,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> Statistical Learning Theory,Reinforcement learning and planning,"['Nived Rajaraman', ' Lin Yang', ' Jiantao Jiao', ' Kannan Ramchandran']","{'UCLA', 'University of California, Berkeley', 'UC Berkeley'}",1,0,0,{'USA'}
Logarithmic Pruning is All You Need,"Laurent Orseau, Marcus Hutter, Omar Rivasplata",Logarithmic Pruning is All You Need,1e9491470749d5b0e361ce4f0b24d037,https://proceedings.neurips.cc/paper/2020/file/1e9491470749d5b0e361ce4f0b24d037-Paper.pdf,"This work is theoretical, and in this regard we do not expect any direct societal or ethical consequences. It is our hope, however, that by studying the theoretical foundations of neural networks this will eventually help the research community make better and safer learning algorithms.",Statement of broader impact,45,2,TRUE,TRUE,FALSE,FALSE,FALSE,Logarithmic Pruning is All You Need,Theory,,Theory (including computational and statistical analyses),"['Laurent Orseau', ' Marcus Hutter', ' Omar Rivasplata']",{'DeepMind'},0,1,0,{'UK'}
Hold me tight! Influence of discriminative features on deep network boundaries,"Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",Hold me tight! Influence of discriminative features on deep network boundaries,1ea97de85eb634d580161c603422437f,https://proceedings.neurips.cc/paper/2020/file/1ea97de85eb634d580161c603422437f-Paper.pdf,"In this work, we build on the mechanisms of adversarial machine learning and propose a new framework that connects the microscopic features of a dataset (i.e., position of the training samples in the input space) to the macroscopic properties of the learned models (e.g., distance to the decision boundary). Our methodology sheds light onto the inductive bias that deep classifiers exploit for shaping their decision boundaries and might explain the successes and limitations of deep learning. Part of our work continues a recent line of research that shows that the way neural networks perceive the image spectrum is very different to the way humans do. In fact, based on the margin distributions for different frequencies that we measure, we can see that neural networks can sometimes use features in the higher end of the spectrum which are invisible to the human eye (see Fig. 2 and [4, 20]). A positive application of our work would therefore be the use of this knowledge and some methods derived from our experimental framework to better align the behavior of neural networks to the human visual system perception. This could have positive implications in the interpretability of neural networks when deployed on some domains where it is necessary to explain the decisions of a classifier, e.g., medical imaging. We see the main possible negative implication of our work in the malicious exploitation of the discriminative features of the datasets for generating more advanced and efficient adversarial attacks. When deploying deep models into the real world, especially for safety-critical applications, it is of high importance that practitioners are aware of the low margin blindspots in the classifiers and make the best to protect them.",Broader impact,279,9,,,FALSE,FALSE,FALSE,Hold me tight! Influence of discriminative features on deep network boundaries,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Adversarial Learning; Deep Learning,Understanding deep neural networks,"['Jimenez', ' Apostolos Modas', 'Dezfooli', ' Pascal Frossard']","{'ETHZ', 'EPFL'}",1,0,0,{'Switzerland'}
Learning from Mixtures of Private and Public Populations,"Raef Bassily, Shay Moran, Anupama Nandi",Learning from Mixtures of Private and Public Populations,1ee942c6b182d0f041a2312947385b23,https://proceedings.neurips.cc/paper/2020/file/1ee942c6b182d0f041a2312947385b23-Paper.pdf,"Our work is theoretical in nature. Although there are no concrete, foreseeable ethical or societal impact for the research presented here, we hope that the framework we present for learning from mixtures of private and public populations could provide new insights that lead to a more realistic modeling for the problem of learning under privacy constraints. In particular, we believe that our framework can be a basis for a more general framework that captures and exploits the heterogeneous nature of privacy constraints across a population. This, in turn, can lead to new practical privacy- preserving learning algorithms that meaningfully exploit data with no (or weak) privacy concerns while providing strong privacy protection for data of more sensitive nature. Making progress in this direction can have significant impact on society in the long term.",Broader Impact,133,5,FALSE,FALSE,FALSE,FALSE,FALSE,Learning from Mixtures of Private and Public Populations,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Theory -> Computational Learning Theory; Theory -> Statistical Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Raef Bassily', ' Shay Moran', ' Anupama Nandi']","{'Google AI Princeton', 'The Ohio State University'}",1,1,1,{'USA'}
Adversarial Weight Perturbation Helps Robust Generalization,"Dongxian Wu, Shu-Tao Xia, Yisen Wang",Adversarial Weight Perturbation Helps Robust Generalization,1ef91c212e30e14bf125e9374262401f,https://proceedings.neurips.cc/paper/2020/file/1ef91c212e30e14bf125e9374262401f-Paper.pdf,"Adversarial training is the currently most effective and promising defense against adversarial examples. In this work, we propose AWP to improve the robustness of adversarial training, which may help to build a more secure and robust deep learning system in real world. At the same time, AWP introduces extra computation, which probably has negative impacts on the environmental protection ( e.g. , low-carbon). Further, the authors do not want this paper to bring overoptimism about AI safety to the society. The majority of adversarial examples are based on known threat models ( e.g. L p in this paper), and the robustness is also achieved on them. Meanwhile, the deployed machine learning system faces attacks from all sides, and we are still far from complete model robustness.",Broader Impact,126,6,,,FALSE,FALSE,FALSE,Adversarial Weight Perturbation Helps Robust Generalization,Algorithms -> Semi-Supervised Learning,Algorithms -> Adversarial Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Dongxian Wu', ' Yisen Wang', 'Tao Xia']","{'Tsinghua University', 'Peking University'}",1,0,0,{'China'}
Stateful Posted Pricing with Vanishing Regret via Dynamic Deterministic Markov Decision Processes,"Yuval Emek, Ron Lavi, Rad Niazadeh, Yangguang Shi",Stateful Posted Pricing with Vanishing Regret via Dynamic Deterministic Markov Decision Processes,1f10c3650a3aa5912dccc5789fd515e8,https://proceedings.neurips.cc/paper/2020/file/1f10c3650a3aa5912dccc5789fd515e8-Paper.pdf,"The current paper presents theoretical work without any foreseeable societal consequence. Therefore, the authors believe that the broader impact discussion is not applicable.",Broader Impact,23,2,TRUE,FALSE,FALSE,FALSE,FALSE,Stateful Posted Pricing with Vanishing Regret via Dynamic Deterministic Markov Decision Processes,Theory -> Game Theory and Computational Economics,Algorithms; Algorithms -> Bandit Algorithms; Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Yuval Emek', ' Ron Lavi', ' Rad Niazadeh', ' Yangguang Shi']","{'Technion', 'Technion - Israel Institute of Technology', 'Chicago Booth School of Business'}",1,1,1,"{'USA', 'Israel'}"
Adversarial Self-Supervised Contrastive Learning,"Minseon Kim, Jihoon Tack, Sung Ju Hwang",Adversarial Self-Supervised Contrastive Learning,1f1baa5b8edac74eb4eaa329f14a0361,https://proceedings.neurips.cc/paper/2020/file/1f1baa5b8edac74eb4eaa329f14a0361-Paper.pdf,"Achieving adversarial robustness against malicious attacks with deep neural networks, is a fundamental topic of deep learning research that has not yet been fully solved. Until now, supervised adversarial training, which perturbs the examples such that the target deep network makes incorrect predictions, has been a dominant paradigm in adversarial learning of deep neural networks. However, supervised adversarial learning suffers from lack of generalization to unseen types of attacks, or unseen datasets, as well as suffers from loss of accuracy on clean examples, and thus is not a fundamental, nor practical solution to the problem. Our adversarial self-supervised learning is a research direction that delved into the vulnerability of deep networks in the intrinsic representation space, which we believe is the root cause of fragility of existing deep neural networks, and we hope that more research is conducted in the similar directions.",Broader Impact,142,4,,,FALSE,FALSE,FALSE,Adversarial Self-Supervised Contrastive Learning,Algorithms -> Metric Learning,Algorithms -> Adversarial Learning; Algorithms -> Representation Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Minseon Kim', ' Jihoon Tack', ' Sung Ju Hwang']","{'KAIST, AITRICS', 'KAIST'}",1,1,1,{'South Korea'}
Normalizing Kalman Filters for Multivariate Time Series Analysis,"Emmanuel de Bézenac, Syama Sundar Rangapuram, Konstantinos Benidis, Michael Bohlke-Schneider, Richard Kurle, Lorenzo Stella, Hilaf Hasson, Patrick Gallinari, Tim Januschowski",Normalizing Kalman Filters for Multivariate Time Series Analysis,1f47cef5e38c952f94c5d61726027439,https://proceedings.neurips.cc/paper/2020/file/1f47cef5e38c952f94c5d61726027439-Paper.pdf,"The present article stems from the authors’ work on time series forecasting and anomaly detection in industrial settings. The methods proposed here are not tied to specific time series applications, but will likely be beneficial in supply chain and monitoring settings where large panels of time series data are commonly produced, data generation processes are too complex to be modelled fully and full automation is an aspirational goal. Beneficiaries of applications of this work are therefore primarily companies with data gathering infrastructure and historical data. Such companies will be able to make their processes more efficient given better time series analytics as proposed here. Societal consequences will be similar to other cases where resources can be put to a more efficient usage: less waste, lower energy consumption, less need for human intervention. While this sounds generally appealing, e.g., from an environmental perspective, there is a price for increased efficiency which we are observing in the present time: lack of robustness in the face of disaster. The current COVID-19 crisis has revealed how overly lean supply chains (e.g., for medical supplies) can result in shortages. This phenomenon is not new and has been observed in the automotive industry for example in 2011 after an earthquake and tsunami stroke in Japan [45]. We speculate that such phenomena may occur in other application scenarios as well where the reduction of buffers is enabled through better predictive accuracies as presented here at the consequence of worse disaster recovery (e.g., more efficient usage of cloud compute resources). A large discussion in society is needed how we should balance efficiency and robustness in critical areas and the identification of these critical areas. The central assumption in our methodology is that the past is a meaningful indication of the future. This assumption is, when disaster occurs, violated. Hence, systems relying on methods as ours need to handle such violations gracefully (see [46] for an early example). At present, human intervention and overrides must be enabled in systems incorporating our method. This central assumption also means that potential biases in the data will be reproduced unless otherwise intervened. Finally, we remark that multivariate time series models may be attractive to model epidemics as the present and that it may be tempting to try out our method on the high-dimensional data currently observed. We strongly advise against drawing conclusions from such experiments. The spreading of diseases is a well-understood process and interventions such as lock-downs need to be properly modelled and accounted for. Much further work is needed to allow such fine-grained analysis with our method and a naive application of the present method will almost surely result in unwanted results and unnecessary confusion.",Broader Impact,445,19,,,FALSE,TRUE,FALSE,Normalizing Kalman Filters for Multivariate Time Series Analysis,Applications -> Time Series Analysis,Deep Learning -> Generative Models,Probabilistic methods and inference,"['Emmanuel de Bézenac', ' Syama Sundar Rangapuram', ' Konstantinos Benidis', 'Schneider', ' Lorenzo Stella', ' Hilaf Hasson', ' Richard Kurle', ' Tim Januschowski', ' Patrick Gallinari']","{'Amazon Research', 'Amazon', 'Sorbonne Université', 'Volkswagen Group'}",1,1,1,"{'France', 'USA', 'Germany'}"
Learning to summarize with human feedback,"Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, Paul F. Christiano",Learning to summarize from human feedback,1f89885d556929e98d3ef9b86448f951,https://proceedings.neurips.cc/paper/2020/file/1f89885d556929e98d3ef9b86448f951-Paper.pdf,"The techniques we explore in this paper are generic techniques that could be used in a wide variety of machine learning applications, for any task where it is feasible for humans to evaluate the quality of model outputs. Thus, the potential implications are quite broad. Our research is primarily motivated by the potential positive effects of aligning machine learning algorithms with the designer’s preferences. Many machine learning applications optimize simple metrics which are only rough proxies for what the designer intends. This can lead to problems, such as Youtube recommendations promoting click-bait [11]. In the short term, improving techniques for learning from and optimizing human preferences directly may enable these applications to be more aligned with human well-being. In the long term, as machine learning systems become more capable it will likely become increasingly difficult to ensure that they are behaving safely: the mistakes they make might be more difficult to spot, and the consequences will be more severe. For instance, writing an inaccurate summary of a news article is both easy to notice (one simply has to read the original article) and has fairly low consequences. On the other hand, imitating human driving may be substantially less safe than driving to optimize human preferences. We believe that the techniques we explore in this paper are promising steps towards mitigating the risks from such capable systems, and better aligning them with what humans care about. Unfortunately, our techniques also enable malicious actors to more easily train models that cause societal harm. For instance, one could use human feedback to fine-tune a language model to be more persuasive and manipulate humans’ beliefs, or to induce dependence of humans on the technology, or to generate large amounts of toxic or hurtful content intended to harm specific individuals. Avoiding these outcomes is a significant challenge for which there are few obvious solutions. Large-scale models trained with human feedback could have significant impacts on many groups. Thus, it is important to be careful about how we define the ‘good’ model behavior that human labelers will reinforce. Deciding what makes a good summary is fairly straightforward, but doing this for tasks with more complex objectives, where different humans might disagree on the correct model behavior, will require significant care. In these cases, it is likely not appropriate to use researcher labels as the ‘gold standard’; rather, individuals from groups impacted by the technology should be included in the process to define ‘good’ behavior, and hired as labelers to reinforce this behavior in the model. We chose to train on the Reddit TL;DR dataset because the summarization task is significantly more challenging than on CNN/DM. However, since the dataset consists of user-submitted posts with minimal moderation, they often contain content that is offensive or reflects harmful social biases. This means our models can generate biased or offensive summaries, as they have been trained to summarize such content. For this reason, we recommend that the potential harms of our models be thoroughly studied before deploying them in user-facing applications. Finally, by improving the ability of machine learning algorithms to perform tasks that were previously only achievable by humans, we are increasing the likelihood of many jobs being automated, potentially leading to significant job loss. Without suitable policies targeted at mitigating the effects of large-scale unemployment, this could also lead to significant societal harm.",Broader impacts,556,23,,,TRUE,TRUE,FALSE,Learning to summarize with human feedback,Applications -> Natural Language Processing,Social Aspects of Machine Learning -> AI Safety,Natural language processing,"['Nisan Stiennon', ' Long Ouyang', ' Jeffrey Wu', ' Daniel Ziegler', ' Ryan Lowe', ' Chelsea Voss', ' Alec Radford', ' Dario Amodei', ' Paul Christiano']","{'McGill University / OpenAI', 'OpenAI'}",1,1,1,"{'Canada', 'USA'}"
Fourier Spectrum Discrepancies in Deep Network Generated Images,"Tarik Dzanic, Karan Shah, Freddie Witherden",Fourier Spectrum Discrepancies in Deep Network Generated Images,1f8d87e1161af68b81bace188a1ec624,https://proceedings.neurips.cc/paper/2020/file/1f8d87e1161af68b81bace188a1ec624-Paper.pdf,"The most apparent impact of the present work is in the application of combating unethical uses of deep network generated images. Since the proposed approach can robustly generalize to unknown generative models and requires minimal training data, it can be easily implemented in browser plugins and mobile applications to warn users that an image is likely fake. This work can be expanded upon for detecting manipulated videos, a trending topic in current research, or towards adversarial training of vision tasks. However, systematic implementation of the proposed method for spoofing images would effectively nullify the capabilities of the classifier, and as a result, could create even more realistic (and harder to detect) deep network generated images for malicious purposes. Similarly, the current work can be used as a basis for improving the training process of generative models; for example, a metric can be given for generated images in the frequency domain and used for evaluating generative models, and a loss function in Fourier space, weighted towards the highest modes, can be introduced to aid in improving these networks. Generative models for non-image data could benefit from analysis in other domains as well. A more general result of this work is the conclusion that generative models can have systematic shortcomings that are not immediately evident until observed in other domains (e.g. frequency). In fields where data is scarce and high-quality synthetic data is required to train models, fundamental flaws in synthetic data can have hidden detrimental effects. This opens up questions about the structure of synthetic data and what we perceive to be ""high-quality"" synthetic data.",Broader Impact,264,9,,,FALSE,FALSE,FALSE,Fourier Spectrum Discrepancies in Deep Network Generated Images,Deep Learning -> Generative Models,Algorithms -> Classification; Applications -> Computer Vision,Theory (including computational and statistical analyses),"['Tarik Dzanic', ' Karan Shah', ' Freddie Witherden']",{'Georgia Tech'},1,0,0,{'USA'}
"Lamina-specific neuronal properties promote robust, stable signal propagation in feedforward networks","Dongqi Han, Erik De Schutter, Sungho Hong","Lamina-specific neuronal properties promote robust, stable signal propagation in feedforward networks",1fc214004c9481e4c8073e85323bfd4b,https://proceedings.neurips.cc/paper/2020/file/1fc214004c9481e4c8073e85323bfd4b-Paper.pdf,"Many efforts have been paid to understand the critical components of highly cognitive systems like the human brain. Studies have argued for simulations of large brain-scale neural networks as an indispensable tool ( De Garis et al., 2010). Still, they almost always fail to consider cellular diversity in the brain, whereas more and more experimental data are revealing its importance. Our computational study suggests that heterogeneity in neuronal properties is critical in information transfer within a neural circuit and it should not be ignored, especially when the neural pathway has many feedforward layers. For deep-learning research, our work also provides a new insight for neural architecture search (NAS) (Elsken et al., 2019). The search space of existing NAS methods are mainly (1) the combination of heterogeneous layers to form an entire network; (2) the combination of heterogeneous activation functions to form a cell. However, our work suggests a novel, computationally efficient strategy, that is searching for a block structure consisted of several layers (In our case, the block is composed of a integrator layer followed by a differentiator layer). On the one hand, the block should boost stable propagation of input signals into deep layers. Hence, divergence of inputs will remain detectable in the output layer at the initial phase of learning, which is suggested to accelerates the training of very deep networks (Samuel S Schoenholz and Sohl-Dickstein, 2017; Srivastava et al., 2015). On the other hand, there is also extra freedom of searching the block structure that does not suffer from vanishing/exploding backpropagation gradients (like a residual block (He et al., 2016)) Our deep FFN models are proof-of-concept and lack many other neural circuit mechanisms that can affect signal propagation in spiking neural networks, as we discuss in Section 2, although we did find that an additional component, feedforward inhibition, did not significantly change the results (Appendix Fig. A2,A3). Our study suggests that the cooperation between different types of neurons is vital for promoting signal processing in large-scale networks. It also suggests investigating the roles of heterogeneous neuronal properties in other problems such as sensory coding, short-term memory, and others, in the future studies.",Broader Impact,355,13,,,FALSE,FALSE,FALSE,"Lamina-specific neuronal properties promote robust, stable signal propagation in feedforward networks",Neuroscience and Cognitive Science,Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and cognitive science,"['Dongqi Han', ' Erik De Schutter', ' Sungho Hong']","{'OIST', 'Okinawa Institute of Science and Technology'}",1,0,0,{'Japan'}
Learning Dynamic Belief Graphs to Generalize on Text-Based Games,"Ashutosh Adhikari, Xingdi Yuan, Marc-Alexandre Côté, Mikuláš Zelinka, Marc-Antoine Rondeau, Romain Laroche, Pascal Poupart, Jian Tang, Adam Trischler, Will Hamilton",Learning Dynamic Belief Graphs to Generalize on Text-Based Games,1fc30b9d4319760b04fab735fbfed9a9,https://proceedings.neurips.cc/paper/2020/file/1fc30b9d4319760b04fab735fbfed9a9-Paper.pdf,"Our work’s immediate aim—improved performance on text-based games—might have limited consequences for society; however, taking a broader view of our work and where we’d like to take it forces us to consider several social and ethical concerns. We use text-based games as a proxy to model and study the interaction of machines with the human world, through language. Any system that interacts with the human world impacts it. As mentioned previously, an example of language-mediated, human-machine interaction is online customer service systems. • In these systems, especially in products related to critical needs like healthcare, providing inaccurate information could result in serious harm to users. Likewise, failing to communicate clearly, sensibly, or convincingly might also cause harm. It could waste users’ precious time and diminish their trust. • The responses generated by such systems must be inclusive and free of bias. They must not cause harm by the act of communication itself, nor by making decisions that disenfranchise certain user groups. Unfortunately, many data-driven, free-form language generation systems currently exhibit bias and/or produce problematic outputs. • Users’ privacy is also a concern in this setting. Mechanisms must be put in place to protect it. Agents that interact with humans almost invariably train on human data; their function requires that they solicit, store, and act upon sensitive user information (especially in the healthcare scenario envisioned above). Therefore, privacy protections must be implemented throughout the agent development cycle, including data collection, training, and deployment. • Tasks that require human interaction through language are currently performed by people. As a result, advances in language-based agents may eventually displace or disrupt human jobs. This is a clear negative impact. Even more broadly, any systems that generate convincing natural language could be used to spread misinformation. Our work is immediately aimed at improving the performance of RL agents in text-based games, in which agents must understand and act in the world through language. Our hope is that this work, by introducing graph-structured representations, endows language-based agents with greater accuracy and clarity, and the ability to make better decisions. Similarly, we expect that graph-structured representations could be used to constrain agent decisions and outputs, for improved safety. Finally, we believe that structured representations can improve neural agents’ interpretability to researchers and users. This is an important future direction that can contribute to accountability and transparency in AI. As we have outlined, however, this and future work must be undertaken with awareness of its hazards.",7 Broader Impact,408,24,,,TRUE,TRUE,FALSE,Learning Dynamic Belief Graphs to Generalize on Text-Based Games,Applications -> Game Playing,Applications -> Natural Language Processing; Reinforcement Learning and Planning -> Reinforcement Learning,Natural language processing,"['Ashutosh Adhikari', ' Xingdi Yuan', 'Alexandre Côté', ' Mikuláš Zelinka', 'Antoine Rondeau', ' Romain Laroche', ' Pascal Poupart', ' Jian Tang', ' Adam Trischler', ' Will Hamilton']","{'University of Waterloo', 'Microsoft Research', 'McGill', 'Charles University, Faculty of Mathematics and Physics', 'Microsoft', 'Mila'}",1,1,1,"{'Canada', 'Czech Republic', 'USA'}"
Triple descent and the two kinds of overfitting: where & why do they appear?,"Stéphane d'Ascoli, Levent Sagun, Giulio Biroli",Triple descent and the two kinds of overfitting: Where & why do they appear?,1fd09c5f59a8ff35d499c0ee25a1d47e,https://proceedings.neurips.cc/paper/2020/file/1fd09c5f59a8ff35d499c0ee25a1d47e-Paper.pdf,"Due to the theoretical nature of this paper, a Broader Impact discussion is not easily applicable. However, given the tight interaction of data & model and their impact on overfitting regimes, we believe that our findings and this line of research, in general, may potentially impact how practitioners deal with data.",Broader Impact,51,2,TRUE,TRUE,TRUE,TRUE,FALSE,Triple descent and the two kinds of overfitting: where & why do they appear?,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Kernel Methods; Theory -> High-Dimensional Inference; Theory -> Large Deviations and Asymptotic Analysis; Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Ascoli', ' Levent Sagun', ' Giulio Biroli']","{'Facebook AI Research', 'ENS', 'ENS / FAIR'}",1,1,1,"{'France', 'USA'}"
Multimodal Graph Networks for Compositional Generalization in Visual Question Answering,"Raeid Saqur, Karthik Narasimhan",Multimodal Graph Networks for Compositional Generalization in Visual Question Answering,1fd6c4e41e2c6a6b092eb13ee72bce95,https://proceedings.neurips.cc/paper/2020/file/1fd6c4e41e2c6a6b092eb13ee72bce95-Paper.pdf,"Multimodal reasoning methods that can generalize to novel compositions of linguistic constructs are key to developing more intelligent systems that can reason and ground language in various contexts. Though this work is evaluated on synthetic datasets with generated images, we believe that graph-based techniques can provide smoother scaling and better handle challenging fine-grained multimodal reasoning than alternative approaches. We envision this work to enable improvements on various downstream applications like instruction following, autonomous navigation, and robotic control. However, improved multi-modal reasoning can also result in systems that can be harmful to society (e.g. surveillance systems) if misused. There is also the aspect of various forms of bias that the model may pick up if trained with data that only represents a sub-set of the phenomena in the world. In the current form, MGN does not algorithmically account or correct for bias in multimodal data even though it may provide a useful starting point due to its use of explicit graphs – this can be another direction for future research.",Broader Impact,169,6,,,FALSE,FALSE,FALSE,Multimodal Graph Networks for Compositional Generalization in Visual Question Answering,Applications -> Visual Question Answering,Algorithms -> Representation Learning; Applications -> Natural Language Processing; Applications -> Visual Scene Analysis and Interpretation; Deep Learning -> Embedding Approaches; Probabilistic Methods -> Graphical Models,Natural language processing,"['Raeid Saqur', ' Karthik Narasimhan']",{'Princeton University'},1,0,0,{'USA'}
Learning Graph Structure With A Finite-State Automaton Layer,"Daniel Johnson, Hugo Larochelle, Daniel Tarlow",Learning Graph Structure With A Finite-State Automaton Layer,1fdc0ee9d95c71d73df82ac8f0721459,https://proceedings.neurips.cc/paper/2020/file/1fdc0ee9d95c71d73df82ac8f0721459-Paper.pdf,"We consider this work to be a general technical and theoretical contribution, without well-defined specific impacts. If applied to real-world program understanding tasks, extensions of this work might lead to reduced bug frequency or improved developer productivity. On the other hand, those benefits might accrue mostly to groups with sufficient resources to incorporate machine learning into their development practices. Additionally, if users put too much trust in the output of the model, they could inadvertently introduce bugs in their code because of incorrect model predictions. If applied to other tasks involving structured data, the impact would depend on the specific application; we leave the exploration of these other applications and their potential impacts to future work.",Broader Impact,116,5,,,FALSE,FALSE,FALSE,Learning Graph Structure With A Finite-State Automaton Layer,Algorithms -> Relational Learning,Applications -> Program Understanding and Generation,Deep learning,"['Daniel Johnson', ' Hugo Larochelle', ' Daniel Tarlow']","{'Google Brain', 'Google Research, Brain Team'}",0,1,0,{'USA'}
A Universal Approximation Theorem of Deep Neural Networks for Expressing Probability Distributions,"Yulong Lu, Jianfeng Lu",A Universal Approximation Theorem of Deep Neural Networks for Expressing Probability Distributions,2000f6325dfc4fc3201fc45ed01c7a5d,https://proceedings.neurips.cc/paper/2020/file/2000f6325dfc4fc3201fc45ed01c7a5d-Paper.pdf,"This work focuses on theoretical properties of neural networks for expressing probability distributions. Our work can help understand the theoretical benefit and limitations of neural networks in approximating probability distributions under various integral probability metrics. Our work and the proof technique improve our understanding of the theoretical underpinnings of Generative Adversarial Networks and other generative models used in machine learning, and may lead to better use of these techniques with possible benefits to the society.",Broader Impact,75,3,,,FALSE,FALSE,FALSE,A Universal Approximation Theorem of Deep Neural Networks for Expressing Probability Distributions,Deep Learning -> Generative Models,Deep Learning -> Adversarial Networks; Deep Learning -> Analysis and Understanding of Deep Networks,Theory (including computational and statistical analyses),"['Yulong Lu', ' Jianfeng Lu']",{'Duke University'},1,0,0,{'USA'}
Unsupervised object-centric video generation and decomposition in 3D,"Paul Henderson, Christoph H. Lampert",Unsupervised object-centric video generation and decomposition in 3D,20125fd9b2d43e340a35fb0278da235d,https://proceedings.neurips.cc/paper/2020/file/20125fd9b2d43e340a35fb0278da235d-Paper.pdf,"This paper has tackled several tasks—segmentation, tracking, and 3D detection—that have been the subject of extensive research in computer vision, and have well-known societal implications. These include both positive impacts such as life-saving self-driving cars and safety systems, and negative impacts such as potentially-intrusive surveillance technologies. However, currently-deployed approaches to these tasks rely on supervised learning, in a discriminative setting—whereas we consider the unsupervised, generative setting. This limits the immediate impact of the present work, particularly given we only consider synthetic imagery—though one of our contributions is to narrow the gap between the complexity of videos that are handled by unsupervised and supervised methods. If unsupervised methods do become competitive with fully-supervised ones or are applied more generally, it is as yet unclear what the implications will be. Supervised learning is known for ‘transferring’ bias from human annotators to the model; unsupervised methods should avoid this problem, but any biases that do arise are likely to be even harder to diagnose. Of course, reducing reliance on human annotators is itself a non-trivial societal impact—most directly due to loss of annotator jobs, but also by enabling new applications for which human annotation remains too costly. In particular, unsupervised techniques should allow leveraging the enormous volume of video content that already exists, at minimal cost in labor. A potential negative impact of all generative models, is that they can be applied to the creation of fake content—by advancing the quality of such models, we also indirectly aid those who create such fakes. Conversely, we also aid those who use generative models for artistic and other positive purposes, and we hope these benefits outweigh the downsides.",Broader Impact,273,10,,,FALSE,FALSE,FALSE,Unsupervised object-centric video generation and decomposition in 3D,Deep Learning -> Generative Models,Algorithms -> Unsupervised Learning; Probabilistic Methods -> Latent Variable Models,Vision,"['Paul Henderson', ' Christoph Lampert', 'IST Austria']","{'IST Austria', 'Vienna'}",1,0,0,{'Austria'}
Domain Generalization for Medical Imaging Classification with Linear-Dependency Regularization,"Haoliang Li, Yufei Wang, Renjie Wan, Shiqi  Wang, Tie-Qiang Li, Alex Kot",Domain Generalization for Medical Imaging Classification with Linear-Dependency Regularization,201d7288b4c18a679e48b31c72c30ded,https://proceedings.neurips.cc/paper/2020/file/201d7288b4c18a679e48b31c72c30ded-Paper.pdf,"Our proposed method shows reasonable potential in the application of clinically realistic environments especially under the scenarios where only limited training samples are available and the capturing vendors and environments are diverse. In the short-term, the potential beneficiary of the proposed research lies in that it could significantly alleviate the domain shift problem in medical image analysis, as evidenced in this paper. In the long term, it is expected that the principled methodology could offer new insights in intelligent medical diagnostic systems. One concrete example is that the medical imaging classification functionality can be incorporated into different types of smartphones (with different capturing sensors, resolutions, etc.) to assess risk of skin disease (e.g. skin cancer in suspicious skin lesions) such that the terminal stage of skin cancer can be avoided. However, the medical data can be protected by privacy regulation such that the protected attributes (e.g. gender, ethnicity) may not be released publicly for training purpose. In this sense, the trained model may lack of fairness, or worse, may actively discriminate against a specific group of people (e.g. ethnicity with relatively small proportion of people). In the future, the proposed methodology can be feasibly extended to improve the algorithm fairness for numerous medical image analysis tasks and meanwhile guarantee the privacy of the protected attributes.",Broader Impact,215,7,,,TRUE,TRUE,FALSE,Domain Generalization for Medical Imaging Classification with Linear-Dependency Regularization,Applications -> Health,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Haoliang Li', ' Yufei Wang', ' Renjie Wan', ' Shiqi Wang', 'Qiang Li', ' Alex Kot']","{'Nanyang Technological University', 'Karolinska Institute', 'CityU'}",1,0,0,"{'Singapore', 'Sweden', 'China'}"
Multi-label classification: do Hamming loss and subset accuracy really conflict with each other?,"Guoqiang Wu, Jun Zhu",Multi-label classification: do Hamming loss and subset accuracy really conflict with each other?,20479c788fb27378c2c99eadcf207e7f,https://proceedings.neurips.cc/paper/2020/file/20479c788fb27378c2c99eadcf207e7f-Paper.pdf,"As a theoretical research, this work will potentially provide insights for developing better algorithms for multi-label classification, while without explicit negative consequences to our society.",Broader Impact,25,1,TRUE,TRUE,FALSE,FALSE,FALSE,Multi-label classification: do Hamming loss and subset accuracy really conflict with each other?,Algorithms -> Classification,Algorithms -> Kernel Methods; Algorithms -> Multitask and Transfer Learning; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),,{'Tsinghua University'},1,0,0,{'China'}
A Novel Automated Curriculum Strategy to Solve Hard Sokoban Planning Instances,"Dieqiao Feng, Carla P. Gomes, Bart Selman",A Novel Automated Curriculum Strategy to Solve Hard Sokoban Planning Instances,2051bd70fc110a2208bdbd4a743e7f79,https://proceedings.neurips.cc/paper/2020/file/2051bd70fc110a2208bdbd4a743e7f79-Paper.pdf,"We introduced a new framework for AI planning, which concerns generating (potentially long) action sequences that lead from an initial state to a goal state. In terms of real-world applications, AI planning has the potential for use as a component of autonomous systems that use planning as part of their decision making framework. Therefore we feel this work can broaden the scope of AI, beyond the more standard machine learning applications, for areas of sequential decision making. Our study here was done on a purely formal domain, Sokoban. In terms of ethical considerations , while this domain in itself does not raise issues of human bias or fairness, future real-world applications of AI planning (e.g., in self-driving cars and program synthesis) need to pay careful attention to the value-alignment problem [20]. To obtain human value alignment , AI system designers need to ensure that the specified goals of the system and the potential action sequences leading to those goals align with human values, including considerations of potential fairness and bias issues. In terms of interpretability , our approach falls within the realm of interpretable AI. Since although we use deep RL in the system’s search for plans, the final outcomes are concrete action sequences that can be inspected and simulated. So, the synthesized plans, in principle, can be evaluated for human value alignment and AI safety risks. One final important broader societal impact component of our work is an interesting connection to human learning and education . We showed how our dynamic curriculum learning strategy, leads to faster learning for our deep RL AI planning agent. We showed how the curriculum balances a mix of tasks of varying difficulty and drives the learning process by staying on the “edge of solvability.” It would be interesting to see whether such a type of curriculum can also enhance human education and tutoring systems. Our difficulty quantum momentum bandit driven strategy considers feedback from the planning ability of the system; similar feedback could be obtained from a human learner during the learning process. Finally, we were excited to see the benefit to the learning process of adding unsolved planning problems as “exercises.” A further study of what starting pool of exercises is most effective may provide useful new insights for designing learning curricula for human education.",6 Broader Impact,383,14,,,FALSE,TRUE,FALSE,A Novel Automated Curriculum Strategy to Solve Hard Sokoban Planning Instances,Reinforcement Learning and Planning -> Planning,Probabilistic Methods -> MCMC,Reinforcement learning and planning,"['Dieqiao Feng', ' Carla Gomes', ' Bart Selman']",{'Cornell University'},1,0,0,{'USA'}
Causal analysis of Covid-19 Spread in Germany,"Atalanti Mastakouri, Bernhard Schölkopf",Causal analysis of Covid-19 spread in Germany,205e73579f21c2ed134dbd6ce7e4a1ea,https://proceedings.neurips.cc/paper/2020/file/205e73579f21c2ed134dbd6ce7e4a1ea-Paper.pdf,"The causal analysis proposed in this paper aims at contributing to the broader effort of scientists to understand the spread of the Covid-19 pandemic and the causal role of political interventions such as social distancing. The causal method being applied and assayed in this work can provide trustworthy causal results, since it is robust against false positives in the presence of latent confounders in time series — note that in Covid-19 data science problems, with our limited present understanding, it is likely that relevant covariates are unobserved, leading to confounded problems. Despite the theoretical validity of the causal method, caution should be exercised in the interpretation of the results of the present study, due to the limited data available for this analysis (only daily reported Covid-19 cases for different regions, and some political interventions), and the sheer difficulty of the task. At present, we would thus not recommend that our empirical findings be used to guide public policy. However, we find our results encouraging, given the hardness of causal structure learning from observational real-world data, known to practitioners in the field [1]. We therefore believe that methods such as the one used above, and further developments based upon it, can contribute towards rational approaches for choosing and balancing restriction measures for pandemics such as Covid-19.",6 Broader Impact,215,6,,,FALSE,FALSE,FALSE,Causal analysis of Covid-19 Spread in Germany,Applications -> Health,,Healthcare,"['Atalanti Mastakouri', ' Bernhard Schölkopf']","{'MPI for Intelligent Systems', 'Max Planck Institute for Intelligent Systems'}",1,0,0,{'Germany'}
Locally private non-asymptotic testing of discrete distributions is faster using interactive mechanisms,"Thomas Berrett, Cristina Butucea",Locally private non-asymptotic testing of discrete distributions is faster using interactive mechanisms,20b02dc95171540bc52912baf3aa709d,https://proceedings.neurips.cc/paper/2020/file/20b02dc95171540bc52912baf3aa709d-Paper.pdf,"In many domains of application, the collection and use of personal data are activities that can have damaging consequences. Data breaches can cause, on the one hand, major distress for the individuals concerned through identity theft and the publication of private information (such as medical or financial records), and, on the other hand, can lead to financial ruin and legal battles for the organizations that are hacked. The study and development of statistical methodology that respects the privacy of individuals has, therefore, the potential for huge impact on society. As the performance of the available methodolgy improves, the need for analysts to use outdated and unsafe procedures will decrease, leading to a positive impact on the world. However, the existence of information theoretic lower bounds proving that private procedures necessarily have worse performance than their non-private counterparts could slightly discourage the use of private methodology, on the grounds of relative inefficiency. Overall, though, this seems like a small price to pay, and a fuller understanding of the possibilites and limitations of private data analysis should be very positive. In this paper we improve upon existing methodology for locally private goodness-of-fit testing, and provide deeper knowledge on the underlying theory.",Broader impact,199,7,,,TRUE,TRUE,FALSE,Locally private non-asymptotic testing of discrete distributions is faster using interactive mechanisms,Theory -> Frequentist Statistics,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security; Theory -> High-Dimensional Inference; Theory -> Information Theory",Theory (including computational and statistical analyses),"['Thomas Berrett', ' Cristina Butucea']","{'CREST, ENSAE, Institut Polytechnique de Paris'}",1,0,0,"{'France', 'USA'}"
Adaptive Gradient Quantization for Data-Parallel SGD,"Fartash Faghri, Iman Tabrizian, Ilia Markov, Dan Alistarh, Daniel M. Roy, Ali Ramezani-Kebrya",Adaptive Gradient Quantization for Data-Parallel SGD,20b5e1cf8694af7a3c1ba4a87f073021,https://proceedings.neurips.cc/paper/2020/file/20b5e1cf8694af7a3c1ba4a87f073021-Paper.pdf,"This work provides additional understanding of statistical behaviour of deep machine learning models. We aim to train deep models using popular SGD algorithm as fast as possible without compromising learning outcome. As the amount of data gathered through web and a plethora of sensors deployed everywhere (e.g., IoT applications) is drastically increasing, the design of efficient machine learning algorithms that are capable of processing large-scale data in a reasonable time can improve everyone’s  quality of life. Our compression schemes can be used in Federated Learning settings, where a deep model is trained on data distributed among multiple owners without exposing that data. Developing privacy-preserving learning algorithms is an integral part of responsible and ethical AI. However, the long-term impacts of our schemes may depend on how machine learning is used in society.",Broader impact,132,6,,,FALSE,FALSE,FALSE,Adaptive Gradient Quantization for Data-Parallel SGD,Algorithms -> Communication- or Memory-Bounded Learning,Algorithms -> Large Scale Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Fartash Faghri', ' Iman Tabrizian', ' Ilia Markov', ' Dan Alistarh', ' Daniel Roy', 'Kebrya']","{'Vector Institute', 'IST Austria', 'University of Toronto'}",1,0,0,"{'Canada', 'Austria'}"
Finite Continuum-Armed Bandits,Solenne Gaucher,Finite Continuum-Armed Bandits,20c86a628232a67e7bd46f76fba7ce12,https://proceedings.neurips.cc/paper/2020/file/20c86a628232a67e7bd46f76fba7ce12-Paper.pdf,"We present an algorithm for the problem of allocating a limited budget among competing candidates. This algorithm is easy to implement, and enjoys strong theoretical guarantees on its performance making it attractive and reliable in relevant applications. Nevertheless, we emphasise that the considered framework is based on the premise that the decision-maker is purely utility-driven. We leave it to the decision-maker to take additional domain-specific considerations into account.",Broader impact,68,4,,,FALSE,FALSE,FALSE,Finite Continuum-Armed Bandits,Algorithms -> Bandit Algorithms,,Reinforcement learning and planning,,{'Université Paris-Saclay'},1,0,0,{'France'}
Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies,"Itai Gat, Idan Schwartz, Alexander Schwing, Tamir Hazan",Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies,20d749bc05f47d2bd3026ce457dcfd8e,https://proceedings.neurips.cc/paper/2020/file/20d749bc05f47d2bd3026ce457dcfd8e-Paper.pdf,"We study functional entropy based regularizers which enable classifiers to more uniformly benefit from available dataset modalities in multi-modal tasks. We think the proposed method will help to reduce biases that present-day classifiers exploit when being trained on data which contains modalities, some of which are easier to leverage than others. We think this research will have positive societal implications. With machine learning being used more widely, bias from various modalities has become ubiquitous. Minority groups are disadvantaged by present-day AI algorithms, which work very well for the average person but are not suitable for other groups. We provide two examples next: 1. It is widely believed that criminal risk scores are biased against minorities1 , and mathematical methods that reduce the bias in machine learning are desperately needed. In our work we show how our regularization allows to reduce the color modality effect in colored MNIST, which hopefully facilitates to reduce bias in deep nets. 2. Consider virtual assistants as another example: if pronunciation is not mainstream, replies of AI systems are less helpful. Consequently, current AI ignores parts of society. To conclude, we think the proposed research is a first step towards machine learning becoming more inclusive. 1 https://www.propublica.org/article/bias-in-criminal-risk-scores-ismathematically-inevitable-researchers-say",Broader Impact,201,13,,,TRUE,TRUE,FALSE,Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies,Algorithms -> Multimodal Learning,Applications -> Visual Question Answering; Theory -> Regularization,Deep learning,"['Itai Gat', ' Idan Schwartz', ' Alexander Schwing', ' Tamir Hazan']","{'Technion', 'University of Illinois at Urbana-Champaign'}",1,1,1,"{'USA', 'Israel'}"
Compact task representations as a normative model for higher-order brain activity,"Severin Berger, Christian K. Machens",Compact task representations as a normative model for higher-order brain activity,2109737282d2c2de4fc5534be26c9bb6,https://proceedings.neurips.cc/paper/2020/file/2109737282d2c2de4fc5534be26c9bb6-Paper.pdf,"The study presented here is aimed at resolving some of the current debates in the field of working memory and decision making. In that sense, our work has the potential of impacting and progressing this field mainly conceptually. We note that our work does not seek to push the state of the art of machine learning in terms of performance. The non-parametric methods used here are limited and do not scale up to larger architectures, and their benefits lie in clear interpretability rather than performance. We believe that a better understanding of decision-making circuits, whether biological or artificial, may eventually benefit the safety of computational learning architectures.",Broader Impact,107,5,,,FALSE,FALSE,FALSE,Compact task representations as a normative model for higher-order brain activity,Neuroscience and Cognitive Science -> Neuroscience,Algorithms -> Representation Learning; Probabilistic Methods -> Latent Variable Models; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Neuroscience and cognitive science,"['Severin Berger', ' Christian K Machens']",{'Champalimaud Centre for the Unknown'},1,0,0,{'Portugal'}
Robust-Adaptive Control of Linear Systems: beyond Quadratic Costs,"Edouard Leurent, Odalric-Ambrym Maillard, Denis Efimov",Robust-Adaptive Control of Linear Systems: beyond Quadratic Costs,211b39255232ab59ce78f2e28cd0292b,https://proceedings.neurips.cc/paper/2020/file/211b39255232ab59ce78f2e28cd0292b-Paper.pdf,"The motivation behind this work is to enable the development of Reinforcement Learning solutions for industrial applications, when it has been mainly limited to simulated games so far. In particular, many industries already rely on non-adaptive control systems and could benefit from an increased efficiency, including Oil and Gas, robotics for industrial automation, Data Center cooling, etc. But more often than not, safety-critical constraints proscribe the use of exploration, and industrials are reluctant to turn to learning-based methods that lack accountability. This work addresses these concerns by focusing on risk-averse decisions and by providing worst-case guarantees. Note however that these guarantees are only as good as the validity of the underlying hypotheses, and Assumption 1 in particular should be submitted to a comprehensive validation procedure; otherwise, decisions formed on a wrong basis could easily lead to dramatic consequences in such critical settings. Beyond industrial perspectives, this work could be of general interest for risk-averse decision-making. For instance, parametrized epidemiological models have been used to represent the propagation of Covid-19 and study the impact of lockdown policies. These model parameters are estimated from observational data and corresponding confidence intervals are often available, but rarely used in the decision-making loop. In contrast, our approach would enable evaluating and optimising the worst-case outcome of such public policies.",Broader Impact,214,9,,,FALSE,FALSE,FALSE,Robust-Adaptive Control of Linear Systems: beyond Quadratic Costs,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Model-Based RL; Reinforcement Learning and Planning -> Reinforcement Learning; Social Aspects of Machine Learning -> AI Safety; Theory -> Control Theory,Reinforcement learning and planning,"['Edouard Leurent', 'Ambrym Maillard', ' Denis Efimov']","{'INRIA', 'Inria'}",1,0,0,{'France'}
Co-exposure Maximization in Online Social Networks,"Sijing Tu, Cigdem Aslay, Aristides Gionis",Co-exposure maximization in online social networks,212ab20dbdf4191cbcdcf015511783f4,https://proceedings.neurips.cc/paper/2020/file/212ab20dbdf4191cbcdcf015511783f4-Paper.pdf,"Our work addresses the problem of maximizing co-exposure of information in online social networks via viral-marketing strategies. We are interested in situations where opposing campaigns are prop- agated in different parts of a social network, with users in one side not being aware of the content and arguments seen on the other side. Although, the focus of our work is mainly theoretical, and a number of modeling considerations has been stripped out for the sake of mathematical rigor, applying this kind of ideas in practice may have significant impact towards reducing polarization on societal issues, and offering users a more balanced news diet and the possibility to participate in constructive deliberation. On the other hand, one needs to be careful how our framework will be applied in practice. One potential source of misuse is when misinformation or disinformation is offered to counter true facts. Here we assume that this aspect is orthogonal to our approach, and that the social-network platform needs to mitigate this danger by providing mechanisms of information validation, fact checking, and ethical compliance of the content before allowing it to circulate in the network. Another issue is that, users often do not understand why they see a particular item in their feed; the system content-filtering and prioritization algorithm is opaque to them. In the context of our proposal, since we are suggesting to make content recommendations to selected users, it is important that transparent mechanisms are in place for the users to opt in participating in such features, to understand why they receive these recommendations, and in general, to be able to control their content.",Broader impact,268,8,,,FALSE,FALSE,FALSE,Co-exposure Maximization in Online Social Networks,Algorithms,Applications -> Network Analysis; Optimization -> Discrete Optimization; Optimization -> Submodular Optimization,Optimization Methods (continuous or discrete),"['Sijing Tu', ' Cigdem Aslay', ' Aristides Gionis']","{'kth royal institute of technology', 'Aarhus University', 'KTH Royal Institute of Technology'}",1,0,0,"{'Sweden', 'Denmark'}"
UCLID-Net: Single View Reconstruction in Object Space,"Benoit Guillard, Edoardo Remelli, Pascal Fua",UCLID-Net: Single View Reconstruction in Object Space,21327ba33b3689e713cdff1641128004,https://proceedings.neurips.cc/paper/2020/file/21327ba33b3689e713cdff1641128004-Paper.pdf,"Our work is relevant to a variety of applications. In robotics, autonomous camera-equipped agents, for which a volumetric estimate of the environment can be useful, would benefit from this. In medical applications, it would allow aggregating 2D scans to form 3D models of organs. It could also prove useful in industrial applications, such as in creating 3D designs from 2D sketches. More generally, constructing an easily handled differentiable representations of surfaces such as the ones we propose opens the way to assisted design and shape optimization. As for any method enabling information extraction from images in an automated manner, malicious use is possible, especially raising privacy concerns. Accidents or malevolent use of autonomous agents is also a risk. To reduce accident threats we encourage the research community to propose explainable models, that perform more reconstruction than recognition - the latter regime arguably being more prone to adversarial attacks.",Broader impact,148,8,,,FALSE,FALSE,FALSE,UCLID-Net: Single View Reconstruction in Object Space,Applications -> Computer Vision,Algorithms -> Representation Learning; Deep Learning -> CNN Architectures,Deep learning,"['Benoit Guillard', ' Edoardo Remelli', ' Pascal Fua']","{'EPFL, Switzerland', 'EPFL'}",1,0,0,{'Switzerland'}
Reinforcement Learning for Control with Multiple Frequencies,"Jongmin Lee, ByungJun Lee, Kee-Eung Kim",Reinforcement Learning for Control with Multiple Frequencies,216f44e2d28d4e175a194492bde9148f,https://proceedings.neurips.cc/paper/2020/file/216f44e2d28d4e175a194492bde9148f-Paper.pdf,"In recent years, reinforcement learning (RL) has shown remarkable successes in various areas, where most of their results are based on the assumption that all decision variables are simultaneously determined at every discrete time step. However, many real-world sequential decision-making problems involve multiple decision variables whose control frequencies are different by the domain requirement. In this situation, standard RL algorithms without considering the control frequency requirement may suffer from severe performance degradation as discussed in Section 3. This paper provides a theoretical and algorithmic foundation of how to address multiple control frequencies in RL, which enables RL to be applied to more complex and diverse real-world problems that involve decision variables with different frequencies. Therefore, this work would be beneficial for those who want to apply RL to various tasks that inherently have multiple control frequencies. As we provide a general-purpose methodology, we believe this work has little to do with a particular system failure or a particular data bias. On the other hand, this work could contribute to accelerating industrial adoption of RL, which has the potential to adversely affect employment due to automation.",Broader Impact,185,7,,,FALSE,FALSE,FALSE,Reinforcement Learning for Control with Multiple Frequencies,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Jongmin Lee', ' ByungJun Lee', 'Eung Kim']",{'KAIST'},1,0,0,{'South Korea'}
Complex Dynamics in Simple Neural Networks: Understanding Gradient Flow in Phase Retrieval,"Stefano Sarao Mannelli, Giulio Biroli, Chiara Cammarota, Florent Krzakala, Pierfrancesco Urbani, Lenka Zdeborová",Complex Dynamics in Simple Neural Networks: Understanding Gradient Flow in Phase Retrieval,2172fde49301047270b2897085e4319d,https://proceedings.neurips.cc/paper/2020/file/2172fde49301047270b2897085e4319d-Paper.pdf,"Our work is theoretical in nature, and as such the potential societal consequence are difficult to foresee. We anticipate that deeper theoretical understanding of the functioning of machine learning systems will lead to their improvement in the long term.",Broader Impact,39,2,TRUE,FALSE,FALSE,FALSE,FALSE,Complex Dynamics in Simple Neural Networks: Understanding Gradient Flow in Phase Retrieval,Theory -> Statistical Physics of Learning,Optimization -> Non-Convex Optimization; Theory -> High-Dimensional Inference; Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Stefano Sarao Mannelli', ' Giulio Biroli', ' Chiara Cammarota', ' Florent Krzakala', ' Pierfrancesco Urbani', ' Lenka Zdeborová']","{'CEA Saclay', 'ENS', 'Institut de Physique Théorique'}",1,0,0,{'France'}
Neural Message Passing for Multi-Relational Ordered and Recursive Hypergraphs,Naganand Yadati,Neural Message Passing for Multi-Relational Ordered and Recursive Hypergraphs,217eedd1ba8c592db97d0dbe54c7adfc,https://proceedings.neurips.cc/paper/2020/file/217eedd1ba8c592db97d0dbe54c7adfc-Paper.pdf,"Message Passing Neural Networks (MPNNs) are a framework for deep learning on graph structured data. Graph structures are universal and very generic structures commonly seen in various forms in computer vision, natural language processing, recommender systems, traffic prediction, generative models, and many more. Graphs can have many variations such as multi-relational, heterogeneous, hypergraphs, etc. Our research in this paper unifies several existing MPNN methods on these variations. While we show how our research could be used for academic networks, and factual knowledge, it opens up many more possibilities in natural language processing (NLP). We see opportunities for research applying our work for beneficial puroposes, such as investigating whether we could improve performance of NLP tasks such as machine reading comprehension, relation extraction, machine translation, and many more. Potentially hazardous applications include trying to predict criminality or credit from social networks. Such applications may reproduce and exacerbate bias and readers of the paper should be aware that the presented model should not applied naively to such tasks.",Broader Impact,166,8,,,FALSE,FALSE,FALSE,Neural Message Passing for Multi-Relational Ordered and Recursive Hypergraphs,Algorithms -> Representation Learning,Algorithms -> Relational Learning; Algorithms -> Semi-Supervised Learning; Applications -> Network Analysis; Deep Learning -> CNN Architectures,Deep learning,['Naganand Yadati'],{'Indian Institute of Science'},1,0,0,{'India'}
A Unified View of Label Shift Estimation,"Saurabh Garg, Yifan Wu, Sivaraman Balakrishnan, Zachary Lipton",A Unified View of Label Shift Estimation,219e052492f4008818b8adb6366c7ed6,https://proceedings.neurips.cc/paper/2020/file/219e052492f4008818b8adb6366c7ed6-Paper.pdf,"This paper investigates the (statistical) consistency and efficiency of two existing methods for estimating target domain label distributions. While this could potentially guide practitioners to improve detection, estimation, and classification in applications where the label shift assumption holds, we do not believe that it will fundamentally impact how machine learning is used in a way that could conceivably be socially salient. While we take the potential impact of machine learning on society seriously, we believe that this work, which addresses a foundational theoretical problem, does not present a significant societal concern.",Broader Impact,91,3,,,FALSE,FALSE,FALSE,A Unified View of Label Shift Estimation,Algorithms -> Multitask and Transfer Learning,Theory -> Frequentist Statistics; Theory -> Statistical Learning Theory,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Saurabh Garg', ' Yifan Wu', ' Sivaraman Balakrishnan', ' Zachary Lipton']","{'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Optimal Private Median Estimation under Minimal Distributional Assumptions,"Christos Tzamos, Emmanouil-Vasileios Vlatakis-Gkaragkounis, Ilias Zadik",Optimal Private Median Estimation under Minimal Distributional Assumptions,21d144c75af2c3a1cb90441bbb7d8b40,https://papers.nips.cc/paper/2020/file/21d144c75af2c3a1cb90441bbb7d8b40-Paper.pdf,"Aggregating large amounts of data has been important for quantitative social scientists. However increasing amounts of data also increase privacy risks. Do handy medical apps put in jeopardy my insurance policy or ability to get a mortgage? Can I be harmed by my census responses? If I agreed to having committed a traffic violation in a survey then I would promptly receive a fine and a criminal record? The invasion of this area of questioning is nowadays ubiquitous, obligating even the governments to adopt new and sweeping privacy laws such as the EU’s General Data Protection Regulation 2016/679 (GDPR); However, even if extra confidentiality pledges have been added in research with statements that information will be released only at a group level and not at an individual one , the majority of the participants of those studies doubt their validity. Additionally, privacy scientists have proposed different types of tracing attacks indicating that releasing the summary statistics can result in as much as breach as publishing the private micro data. For example, it could be possible that if many tables are produced for a specific data-set, then an appropriate combination of the tables could leak information about one person with a specific profile. To mitigate these risks, many researchers had proposed a solution in the concept of differential privacy. In this framework researchers reported the outcome of their analyses having firstly injected a well-calibrated noise. More precisely, the level of the noise has been chosen in such a way that it would be computationally arduous to reconstruct any personal micro data but simultaneously would permit an accurate estimation of group statistics. In our work, we present an optimal differential private estimator with an efficient implementation for median estimation, one of the most preferred statistical index in political and medical sciences. Despite its introduction as a term is relatively recent (the earliest trace in English literature appears to be in 1881 by Francis Galton in one of his surveys), it seems that as a measure of central tendency it behaves more robustly than many other indices such as mean and mode. For example, the nominal median income reflects much better the real-life setting than the mean corresponding index. Indeed calculating the cut-off where half of the households earn more, and half earn less is much more robust and illustrative than the mean estimator which could easily have been biased by a smaller number of billionaires. In psychology where the majority of data is inherently categorical, lacking in real continuum spectrum, the median estimator consists the proper way of summarizing different case studies. Concerning even the task of the determination of the critical high-risk age groups during a pandemic, median estimator plays a significant role in balancing out some possible outliers. In all these cases, median gives crucial information propagating probably several social, political and financial implications. More importantly, however, safeguarding the individual privacy of the members of a survey could restrict acts of unfair discrimination based on the leaked personal data.",The Broader Impact of Our Work,499,19,,,TRUE,TRUE,TRUE,Optimal Private Median Estimation under Minimal Distributional Assumptions,Theory -> Computational Learning Theory,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security; Theory -> Information Theory; Theory -> Statistical Learning Theory","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Christos Tzamos', 'Gkaragkounis', ' Ilias Zadik']","{'UW-Madison', 'Columbia University', 'NYU'}",1,0,0,{'USA'}
Breaking the Communication-Privacy-Accuracy Trilemma,"Wei-Ning Chen, Peter Kairouz, Ayfer Ozgur",Breaking the Communication-Privacy-Accuracy Trilemma,222afbe0d68c61de60374b96f1d86715,https://proceedings.neurips.cc/paper/2020/file/222afbe0d68c61de60374b96f1d86715-Paper.pdf,"Harnessing distributed data holds the promise of impacting many facets of our lives. It could enable truly large scale smart infrastructure and IoT applications; having a profound and positive impact on power-grid efficiency, traffic, health-monitoring, medical diagnoses, carbon emissions, and many other areas. A foundational understanding of distributed learning and estimation can also benefit many different fields of study such as neuroscience, medicine, economics, and social networks, where statistical tools are often used to analyze information that is generated and processed in large networks. While the above vision is expected to generate many disruptive business and social opportunities, it presents a number of unprecedented challenges. First, massive amounts of data need to be collected by, and transferred across, resource-constrained devices. Second, the collected data needs to be stored, processed, and analyzed at scales never previously seen. Third, serious concerns such as access control, data privacy, and security should be rigorously addressed. Our work tackles the above challenges by examining the fundamental trade-off between commu- nication, privacy, and accuracy by taking a holistic approach that examines all these constraints simultaneously and designing provably optimal privacy and compression mechanisms for efficient distributed learning and estimation. Our work therefore serves as a fundamental stepping stone towards harnessing large-scale distributed data in a privacy-preserving and bandwidth efficient way. Even more broadly, our work advances the current state-of-the-art in a number of areas of statistics and computer science. Indeed, our work builds on a long line of fundamental research in information theory, statistics, and theoretical computer science, extending them in non-trivial ways.",Broader Impact,257,11,,,FALSE,FALSE,FALSE,Breaking the Communication-Privacy-Accuracy Trilemma,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Communication- or Memory-Bounded Learning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Ning Chen', ' Peter Kairouz', ' Ayfer Ozgur']","{'Google', 'Stanford University'}",1,1,1,{'USA'}
Audeo: Audio Generation for a Silent Performance Video,"Kun Su, Xiulong Liu, Eli Shlizerman",Audeo: Audio Generation for a Silent Performance Video,227f6afd3b7f89b96c4bb91f95d50f6d,https://proceedings.neurips.cc/paper/2020/file/227f6afd3b7f89b96c4bb91f95d50f6d-Paper.pdf,"The Audeo system enables music generation from silent piano performance video. One classical application is to recover a corrupted audio channel in a piano performance video. Moreover, since Audeo uses Midi as an intermediate representation, this provides a large amount of possibilities to manipulate the generated Midi creatively. For example, people could use the predicted Midi to synthesize music of any instrument by just giving a piano performance video. This can be also extended to virtual piano environment in the real-time where Audeo can generate music from visual information when there is no real sound available at all. All these directions would benefit from Audeo . Due to the fact that the generated music can be detected by a music identification App, one concern could be the possibility that a fake pianist could scam audiences utilizing Audeo system. This is a common concern in the application of any generative model. Failure in Audeo may bring up unsatisfying music but we do not expect serious consequences. Also, while Audeo is trained and tested on videos of the same pianist, we believe the full pipeline is valid and robust in general due to the variance in the pianist can only result in the difference in hand shape and this variance can easily be incorporated in Audeo by either fine tuning or adding more data to the training set.",Broad Impact,226,10,,,FALSE,FALSE,FALSE,Audeo: Audio Generation for a Silent Performance Video,Applications -> Music Modeling and Analysis,Algorithms -> Classification; Applications -> Audio and Speech Processing; Applications -> Computer Vision; Applications -> Information Retrieval; Applications -> Time Series Analysis; Applications -> Video Analysis,Audio / Music / Speech,"['Kun Su', ' Xiulong Liu', ' Eli Shlizerman']","{'University of Washington Seattle', 'University of Washington'}",1,0,0,{'USA'}
Ode to an ODE,"Krzysztof M. Choromanski, Jared Quincy Davis, Valerii Likhosherstov, Xingyou Song, Jean-Jacques Slotine, Jacob Varley, Honglak Lee, Adrian Weller, Vikas Sindhwani",Ode to an ODE,228669109aa3ab1b4ec06b7722efb105,https://proceedings.neurips.cc/paper/2020/file/228669109aa3ab1b4ec06b7722efb105-Paper.pdf,"We believe our contributions have potential broader impact that we briefly discuss below: Reinforcement Learning with Neural ODEs: To the best of our knowledge, we are the first to propose to apply nested Neural ODEs in Reinforcement Learning, in particular to train Neural ODE policies. More compact architectures encoding deep neural network systems is an especially compelling feature in policy training algorithms, in particular while combined with ES methods admitting embarrassingly simple and efficient parallelization, yet suffering from high sampling complexity that increases with the number of policy parameters. Our work shows that RL training of such systems can be conducted efficiently provided that evolution of the parameters of the system is highly structured and takes place on compact matrix manifolds. Learnable Isospectral Flows: We demonstrated that ISO-ODEtoODEs can be successfully applied to learn reinforcement learning policies. Those rely on the isospectral flows that in the past were demonstrated to be capable of solving combinatorial problems ranging from sorting to (graph) matching [8, 54]. As emphasized before, such flows are however fixed and not trainable whereas we learn ours. That suggests that isospectral flows can be potentially learned to solve combinatorially- flavored machine learning problems or even integrated with non-combinatorial blocks in larger ML computational pipelines. The benefits of such an approach lie in the fact that we can efficiently backpropagate through these continuous systems and is related to recent research on differentiable sorting [18, 5, 24].",7 Broader impact,237,8,,,FALSE,FALSE,FALSE,Ode to an ODE,Deep Learning -> Analysis and Understanding of Deep Networks,Reinforcement Learning and Planning -> Reinforcement Learning,Deep learning,"['Krzysztof Choromanski', ' Jared Quincy Davis', ' Valerii Likhosherstov', ' Xingyou Song', ' Vikas Sindhwani', 'Jacques Slotine', ' Jacob Varley', ' Honglak Lee', ' Adrian Weller']","{'Google', 'Google Brain Robotics & Columbia University', 'Massachusetts Institute of Technology', 'University of Cambridge', 'Google Brain', 'Cambridge, Alan Turing Institute'}",1,1,1,"{'UK', 'USA'}"
Self-Distillation Amplifies Regularization in Hilbert Space,"Hossein Mobahi, Mehrdad Farajtabar, Peter Bartlett",Self-Distillation Ampli fi es Regularization in Hilbert Space,2288f691b58edecadcc9a8691762b4fd,https://proceedings.neurips.cc/paper/2020/file/2288f691b58edecadcc9a8691762b4fd-Paper.pdf,"We believe that this paper is categorized as fundamental and theoretical research and is not targeted to any speci fi c application area. The insights and theory developed here may inspire novel algorithms and more investigations in knowledge distillation and more generally in neural network regularization and generalization. Consequently this may lead to better training algorithms with lower training time, computational cost, or energy consumption. The research presented here can be used for many different application areas and a particular use may have both positive or negative implications. Though, we are not aware of any immediate short term negative impact of this research.",Broader Impact,103,5,,,FALSE,FALSE,FALSE,Self-Distillation Amplifies Regularization in Hilbert Space,Theory -> Regularization,Deep Learning -> Analysis and Understanding of Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Hossein Mobahi', ' Mehrdad Farajtabar', ' Peter Bartlett']","{'UC Berkeley', 'Google Research', 'DeepMind'}",1,1,1,"{'UK', 'USA'}"
Coupling-based Invertible Neural Networks Are Universal Diffeomorphism Approximators,"Takeshi Teshima, Isao Ishikawa, Koichi Tojo, Kenta Oono, Masahiro Ikeda, Masashi Sugiyama",Coupling-based Invertible Neural Networks Are Universal Diffeomorphism Approximators,2290a7385ed77cc5592dc2153229f082,https://proceedings.neurips.cc/paper/2020/file/2290a7385ed77cc5592dc2153229f082-Paper.pdf,"This work advances the theoretical understanding of invertible neural networks (INNs), a recently emerging function model in machine learning. Since the major contribution of this paper is to provide a framework to theoretically guarantee the representation power of INNs, the presented results are likely to promote the use of INNs in various machine learning tasks, although an immediate direct impact on the practice of machine learning is unlikely.",Broader Impact,68,2,,,TRUE,TRUE,FALSE,Coupling-based Invertible Neural Networks Are Universal Diffeomorphism Approximators,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Spaces of Functions and Kernels,Theory (including computational and statistical analyses),"['Takeshi Teshima', ' Isao Ishikawa', ' Koichi Tojo', ' Kenta Oono', ' Masahiro Ikeda', ' Masashi Sugiyama']","{'Ehime University', 'RIKEN / University of Tokyo', 'RIKEN AIP', 'The University of Tokyo'}",1,0,0,{'Japan'}
Community detection using fast low-cardinality semidefinite programming,"Po-Wei Wang, J. Zico Kolter",Community detection using fast low-cardinality semidefinite programming,229aeb9e2ae66f2fac1149e5240b2fdd,https://proceedings.neurips.cc/paper/2020/file/229aeb9e2ae66f2fac1149e5240b2fdd-Paper.pdf,"Although most of the work focuses on the mathematical notion of modularity maximization, the community detection algorithms that result from these methods have a broad number of applications with both potentially positive and negative benefits. Community detection methods have been used extensively in social networks (e.g., [18]), where they can be used for advertisement, tracking, attribute learning, or recommendation of new connections. These may have positive effects for the networks, of course, but as numerous recent studies also demonstrate potential negative consequences of such social network applications [13]. In these same social networks, there are also of course many positive applications of community detection algorithms. For example, researchers have used community detection methods, including the Louvain method, to detect bots in social networks [7], an activity that can bring much-needed transparency to the interactions that are becoming more common. While we do not explore such applications here, it is possible that the multi-community methods we discuss can also have an impact on the design of these methods, again for both positive or negative effects. Ultimately, the method we present here does largely on community detection from a purely algorithmic perspective, focusing on the modularity maximization objective, and provides gains that we believe can improve the quality of existing algorithms as a whole. Ultimately, we do believe that presenting these algorithms publicly and evaluating them fairly, we will at least be able to better establish the baseline best performance that these algorithms can achieve. In other words, we hope to separate the algorithmic goal of modularity maximization (which our algorithm addresses), which is an algorithmic question, from the more applied question of what can be done with the clusters assigned by this “best available” modularity maximization approach. Specifically, if we could achieve the true maximum modularity community assignment for practical graphs, what would this say about the resulting communities or applications? We hope to be able to study this in future work, as our approach and others push forward the boundaries on how close we can get to this “best” community assignment.",6 Broader impact,341,11,,,FALSE,FALSE,FALSE,Community detection using fast low-cardinality semidefinite programming,Algorithms -> Clustering,Applications -> Network Analysis; Optimization; Optimization -> Convex Optimization; Optimization -> Discrete Optimization; Optimization -> Non-Convex Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Wei Wang', ' Zico Kolter']","{'CMU', 'Carnegie Mellon University / Bosch Center for AI'}",1,1,1,"{'USA', 'Germany'}"
Modeling Noisy Annotations for Crowd Counting,"Jia Wan, Antoni Chan",Modeling Noisy Annotations for Crowd Counting,22bb543b251c39ccdad8063d486987bb,https://proceedings.neurips.cc/paper/2020/file/22bb543b251c39ccdad8063d486987bb-Paper.pdf,"In this paper, we introduce a novel loss function for counting crowd numbers by explicitly considering annotation noise. It can be applied to any density map based network architecture and improve the counting accuracy generally. The research is also helpful for monitoring the crowd number in public and prevent the accidents caused by overcrowding. It could also be used in retail businesses to estimate the occupancy of a store or area, which helps with personal and resource management. Our method could also be applied to other objects, such as cell counting, plant/animal counting, etc, and other research areas that use point-wise annotations, e.g., eye gaze estimation. Since the research is based on images captured by cameras, users may be concerned about the privacy problem. However, our method does not directly detect or track individuals, and thus this concern may be eased.",Broader Impact,141,7,,,FALSE,FALSE,FALSE,Modeling Noisy Annotations for Crowd Counting,Applications -> Computer Vision,Probabilistic Methods,Vision,"['Jia Wan', ' Antoni Chan']",{'City University of Hong Kong'},1,0,0,{'China'}
An operator view of policy gradient methods,"Dibya Ghosh, Marlos C. Machado, Nicolas Le Roux",An operator view of policy gradient methods,22eda830d1051274a2581d6466c06e6c,https://proceedings.neurips.cc/paper/2020/file/22eda830d1051274a2581d6466c06e6c-Paper.pdf,"As this work has a theoretical focus, it is unlikely to have a direct impact on society at large although it may guide future research with such an impact.",Broader Impact,29,1,TRUE,TRUE,FALSE,FALSE,FALSE,An operator view of policy gradient methods,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Dibya Ghosh', ' Machado', ' Nicolas Le Roux']","{'Google', 'Google Brain'}",0,1,0,{'USA'}
"Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases","Senthil Purushwalkam Shiva Prakash, Abhinav Gupta","Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases",22f791da07b0d8a2504c2537c560001c,https://proceedings.neurips.cc/paper/2020/file/22f791da07b0d8a2504c2537c560001c-Paper.pdf,"The goal of this work is to analyze existing self-supervised learning methods through diagnostic experiments. Analysis and understanding of existing approaches help develop better interpretation of ML algorithms and can be crucial in removing biases. Upon identifying the shortcomings of existing approaches, we propose a modification to improve the representations learned by these approaches. Self-supervised learning involves learning representations from a large collection of unlabeled data. Since there is no human involvement in the data collection pipeline, we anticipate reduction in biases that can come via human labeling. Furthermore, self-supervised learning is a relatively nascent research topic with minimal deployability in the real-world. Therefore, while in the long run visual self-supervised learning would be impactful, at this moment there is no immediate impact.",Broader Impact,123,7,,,FALSE,FALSE,FALSE,"Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases",Algorithms -> Representation Learning,Applications -> Computer Vision; Applications -> Object Detection; Applications -> Object Recognition; Deep Learning -> Analysis and Understanding of Deep Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Senthil Purushwalkam Shiva Prakash', ' Abhinav Gupta']","{'Facebook AI Research/CMU', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Online MAP Inference of Determinantal Point Processes,"Aditya Bhaskara, Amin Karbasi, Silvio Lattanzi, Morteza Zadimoghaddam",Online MAP Inference of Determinantal Point Processes,23378a2d0a25c6ade2c1da1c06c5213f,https://proceedings.neurips.cc/paper/2020/file/23378a2d0a25c6ade2c1da1c06c5213f-Paper.pdf,"In this paper, we aim to address a fundamental problem in many aspects of data science: how to select a representative and diverse subset of data points. An elegant and intuitive way to score diversity of a subset is through a determinantal point process where diversity is measured via the geometric embedding of the data points. Our paper provides a rigorous and scalable method for maximizing diversity in such probabilistic models.",Broader Impact,71,3,,,FALSE,FALSE,FALSE,Online MAP Inference of Determinantal Point Processes,Optimization -> Discrete Optimization,Algorithms -> Large Scale Learning; Algorithms -> Online Learning; Optimization -> Submodular Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Aditya Bhaskara', ' Amin Karbasi', ' Silvio Lattanzi', ' Morteza Zadimoghaddam']","{'Yale', 'University of Utah', 'Google Research'}",1,1,1,{'USA'}
Video Object Segmentation with Adaptive Feature Bank and Uncertain-Region Refinement,"Yongqing Liang, Xin Li, Navid Jafari, Jim Chen",Video Object Segmentation with Adaptive Feature Bank and Uncertain-Region Refinement,234833147b97bb6aed53a8f4f1c7a7d8,https://proceedings.neurips.cc/paper/2020/file/234833147b97bb6aed53a8f4f1c7a7d8-Paper.pdf,"Our framework is designed for the semi-supervised video object segmentation task, also known as one-shot video object segmentation. Given the first frame annotation, our model could segment the object of interest in the subsequent frames. Due to the great generalizability of our model, the category of the target object is unrestricted. Our adaptive feature bank and the matching based framework can be modified to benefit other video processing tasks in autonomous driving, robot interaction, and video surveillance monitoring that need to handle long videos and appearance-changing contents. For example, one application is in real-time flood detection/monitoring using surveillance cameras. Flooding constitutes the largest portion of insured losses among all disasters in the world [1]. Nowadays, many cameras in city including traffic monitoring and security surveillance cameras are able to capture time-lapse images and videos. By leveraging our video object segmentation framework, flood can be located from the videos and the water level can be estimated. The societal impact is immersed because such a flood monitoring system can predict and alert a flooding event from rainstorms or hurricanes in time. Our framework is trained and evaluated on large-scale segmentation datasets, we do not leverage biases in the data.",Broader Impact,197,10,,,FALSE,FALSE,FALSE,Video Object Segmentation with Adaptive Feature Bank and Uncertain-Region Refinement,Applications -> Computer Vision,Applications -> Video Analysis,,"['Yongqing Liang', ' Xin Li', ' Navid Jafari', ' Jim Chen']","{'Northeastern University', 'Louisiana State University'}",1,0,0,{'USA'}
Inferring learning rules from animal decision-making,"Zoe Ashwood, Nicholas A. Roy, Ji Hyun Bak, Jonathan W. Pillow",Inferring learning rules from animal decision-making,234b941e88b755b7a72a1c1dd5022f30,https://proceedings.neurips.cc/paper/2020/file/234b941e88b755b7a72a1c1dd5022f30-Paper.pdf,"Our work seeks to describe and predict the choice behavior of rodents in the context of decision- making experiments. We hope that neuroscientists and psychologists use our framework to better understand learning within their own experiments, and we have publicly released our code so as to enable this ( https://github.com/pillowlab/psytrack_learning ). Additionally, our work leverages data from two new publicly available datasets [2, 10], acting as an example of the value of open-science practices.",Broader Impact,74,3,,,FALSE,FALSE,FALSE,Inferring learning rules from animal decision-making,Neuroscience and Cognitive Science -> Human or Animal Learning,,Neuroscience and cognitive science,"['Zoe Ashwood', ' Nicholas A Roy', ' Ji Hyun Bak', ' Jonathan W Pillow']","{'UC Berkeley', 'Princeton University', 'Princeton Neuroscience Institute'}",1,0,0,{'USA'}
Input-Aware Dynamic Backdoor Attack,"Tuan Anh Nguyen, Anh Tran",Input-Aware Dynamic Backdoor Attack,234e691320c0ad5b45ee3c96d0d7b8f8,https://proceedings.neurips.cc/paper/2020/file/234e691320c0ad5b45ee3c96d0d7b8f8-Paper.pdf,"Our work is beneficial for both the research community and practical AI systems. For the research community, our work points out the weakness of the current backdoor research, both attack and defense studies, when heavily relying on the assumption of fixed and universal triggers. It raises the backdoor threat to a higher bar for future security research. With the practical AI systems, our work will raise awareness of deep models’ security. It points out a potential advanced backdoor inside the deep-learning-based components acquired from third-parties. People, therefore, can look for potential protection against backdoor exploitation. It is particularly crucial to the security systems. Certainly, the attacker can also gain benefit from our work to design such effective backdoor models. Still, we believe novel and efficient defenses against the proposed attack will soon be introduced after our research released.",Broader Impact,138,9,,,FALSE,FALSE,FALSE,Input-Aware Dynamic Backdoor Attack,Deep Learning -> Adversarial Networks,Applications -> Object Recognition,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Tuan Anh Nguyen', ' Anh Tran']",{'VinAI Research'},1,0,0,{'Vietnam'}
How hard is to distinguish graphs with graph neural networks?,Andreas Loukas,How hard is to distinguish graphs with graph neural networks?,23685a2431acad7789c1e3d43ea1522c,https://proceedings.neurips.cc/paper/2020/file/23685a2431acad7789c1e3d43ea1522c-Paper.pdf,"As we rely on neural networks more heavily, we are unfortunately sacrificing some of our ability to understand how our computers solve problems. Our lack of insight hinders us from using our technology to its full potential and can yield mistrust to the public. After all, if we cannot understand what a neural network is (capable of) doing, how can we know whether it is solving the correct problem? Poor understanding of fundamentals can also lead researchers to misguided optimism, believing that, given the right hyper-parameter tweaking and a large enough training set, neural networks can solve their problem. When incorrect, this mindset can lead to a waste of precious resources, such as time and energy. In this light, impossibility results, such as those presented in this work, provide an insight into the fundamental limits of neural networks. Hardness results for graph neural networks, in particular, characterize the relational pattern recognition ability of practical networks and provide necessary conditions for using our tools to solve classical graph problems. The central implication of the results presented in this work is that one cannot expect to learn algorithms that distinguish (even approximately) connected graphs and trees unless the network size grows at-least polynomially with the graph size.",Broader Impact,205,8,,,FALSE,FALSE,FALSE,How hard is to distinguish graphs with graph neural networks?,Algorithms -> Relational Learning,,,['Andreas Loukas'],{'EPFL'},1,0,0,{'Switzerland'}
Minimax Regret of Switching-Constrained Online Convex Optimization: No Phase Transition,"Lin Chen, Qian Yu, Hannah Lawrence, Amin Karbasi",Minimax Regret of Switching-Constrained Online Convex Optimization: No Phase Transition,236f119f58f5fd102c5a2ca609fdcbd8,https://proceedings.neurips.cc/paper/2020/file/236f119f58f5fd102c5a2ca609fdcbd8-Paper.pdf,"In this paper, we fully characterize the minimax regret of switching-constrained online convex optimization. Since it is a theoretical result in nature, the broader impact discussion is not applicable.",Broader Impacts,29,2,TRUE,FALSE,FALSE,FALSE,FALSE,Minimax Regret of Switching-Constrained Online Convex Optimization: No Phase Transition,Algorithms -> Online Learning,Optimization -> Convex Optimization,Theory (including computational and statistical analyses),"['Lin Chen', ' Qian Yu', ' Hannah Lawrence', ' Amin Karbasi']","{'University of California, Berkeley', 'University of Southern California', 'Yale', 'Flatiron Institute'}",1,0,0,{'USA'}
Dual Manifold Adversarial Robustness: Defense against Lp and non-Lp Adversarial Attacks,"Wei-An Lin, Chun Pong Lau, Alexander Levine, Rama Chellappa, Soheil Feizi",Dual Manifold Adversarial Robustness: Defense against L p and non- L p Adversarial Attacks,23937b42f9273974570fb5a56a6652ee,https://proceedings.neurips.cc/paper/2020/file/23937b42f9273974570fb5a56a6652ee-Paper.pdf,"Deep neural networks have been broadly applied to various fields because of their superior perfor- mance. However, their vulnerability to adversarial attacks makes general public worry, especially in some security-critical applications such as autonomous vehicle and medical diagnosis. Therefore, we need a method that makes neural networks robust to different attacks. In this work, we explore whether or not leveraging the underlying manifold information could enhance the robustness and generalization capability of neutral networks. We provide an affirmative answer to this question. With the proposed novel OM-ImageNet dataset, future works in this direction could be facilitated. The proposed method DMAT demonstrates a way to enhance both robustness and generalization to known and novel adversarial attacks. We note that it is possible that future stronger attacks decrease the performance of the proposed defenses. This work should therefore be viewed as a necessary but not sufficient step towards understanding the role of generative image manifolds in the robustness of vision systems against a wide range of adversarial attacks. We anticipate more works on enhancing both robustness and generalization of deep neural networks to gain public confidence in deep learning systems.",7 Broader Impact,188,10,,,FALSE,FALSE,FALSE,Dual Manifold Adversarial Robustness: Defense against Lp and non-Lp Adversarial Attacks,Algorithms -> Adversarial Learning,Applications -> Computer Vision,Deep learning,"['An Lin', ' Chun Pong Lau', ' Alexander Levine', ' Rama Chellappa', ' Soheil Feizi']","{'Adobe', 'University of Maryland, College Park', 'University of Maryland College Park', 'University of Maryland'}",1,1,1,{'USA'}
Cross-Scale Internal Graph Neural Network for Image Super-Resolution,"Shangchen Zhou, Jiawei Zhang, Wangmeng Zuo, Chen Change Loy",Cross-Scale Internal Graph Neural Network for Image Super-Resolution,23ad3e314e2a2b43b4c720507cec0723,https://proceedings.neurips.cc/paper/2020/file/23ad3e314e2a2b43b4c720507cec0723-Paper.pdf,"This paper is an exploratory work on single image super-resolution using graph convolutional network. The main impacts of this work are academia-oriented, it is expected to promote the research progress of image super-resolution and motivate novel methods in the related fields. As for future societal influence, this work will largely improve the quality of pictures taken by cameras or other mobile devices such as smartphones. In addition, it enhances public safety monitored by vision systems via the higher resolution of the monitoring view. Though there might be some potential risks, e.g., criminals might use this technology for peeping into peoples’ personal privacy. It is worth noticing that the positive social effects of this technology far exceeds the potential problems. We call on people to use this technology and its derivative applications without compromising the personal interest of the general public.",Broader Impact,140,7,,,FALSE,FALSE,FALSE,Cross-Scale Internal Graph Neural Network for Image Super-Resolution,Applications -> Computational Photography,Applications -> Computer Vision,Vision,"['Shangchen Zhou', ' Jiawei Zhang', ' Wangmeng Zuo', ' Chen Change Loy']","{'Nanyang Technological University', 'Sensetime Research', 'Harbin Institute of Technology'}",1,1,1,"{'Hong Kong', 'Singapore', 'China'}"
Unsupervised Representation Learning by Invariance Propagation,"Feng Wang, Huaping Liu, Di Guo, Sun Fuchun",Unsupervised Representation Learning by Invariance Propagation,23af4b45f1e166141a790d1a3126e77a,https://proceedings.neurips.cc/paper/2020/file/23af4b45f1e166141a790d1a3126e77a-Paper.pdf,"This work presents a novel unsupervised learning method, which effectively utilizes large numbers of unlabeled images to learn representation useful for a wide range of downstream tasks, such as image recognition, semi-supervised learning, object detection, etc. Without the labels annotated by humans, our method reduces the prejudice caused by human priors, which may guide the models to learn more intrinsic information. The learned representations may benefit robustness in many scenarios such as adversarial robustness, out-of-distribution detection, label corruptions, etc. What’s more, the unsupervised learning can be applied to autonomous learning in robotics. The robot can autonomously collect the data without specifically labelling it and achieve lifelong learning. There also exist some potential risks for our method. Unsupervised learning solely depends on the distribution of the data itself to discover the information. Therefore, the learned model may be vulnerable to data distributions. With biased dataset, the model is likely to learn incorrect causality information. For example, in the autonomous system, it is inevitable that the bias will be brought during the process of data collection due to the inherent constraints of the system. The model can also be easily attacked when the data used for training is contaminated intentionally. Additionally, since the learned representation can be used for a wide range of downstream tasks, it should be guaranteed that they are used for beneficial purposes. We see the effectiveness and convenience of the proposed method, as well as the potential risks. To mitigate the risks associated with using unsupervised learning, we encourage the research to keep an eye on the distribution of the collected datasets and stop the use of the learned representations for harmful purposes.",Broader Impact,275,14,,,FALSE,FALSE,FALSE,Unsupervised Representation Learning by Invariance Propagation,Algorithms -> Unsupervised Learning,Applications -> Computer Vision; Deep Learning; Deep Learning -> CNN Architectures; Deep Learning -> Embedding Approaches,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Feng Wang', ' Huaping Liu', ' Di Guo', ' Sun Fuchun']","{'Tsinghua University', 'Tsinghua university'}",1,0,0,{'China'}
Restoring Negative Information in Few-Shot Object Detection,"Yukuan Yang, Fangyun Wei, Miaojing Shi, Guoqi Li",Restoring Negative Information in Few-Shot Object Detection,240ac9371ec2671ae99847c3ae2e6384,https://proceedings.neurips.cc/paper/2020/file/240ac9371ec2671ae99847c3ae2e6384-Paper.pdf,"Object detection is one of the most fundamental tasks in computer vision field, it serves as a key component for downstream algorithms and applications, including instance segmentation, human pose estimation and tracking. The majority of deep learning methods are designed to solve fully-supervised problems which drives the demand and progress of few-shot learning in object detection. The proposed method is designed to solve few-shot detection problem, researchers focus on high-level recognition tasks may benefit from our work. There may be unpredictable failures, similar as most other detectors. Please do not use it for scenarios where failures will lead to serious consequences. The method is data driven, and thus the performance may be affected by the biases in the data. So please also be careful about the data collection process when using it.",Broader Impact,132,7,,,FALSE,FALSE,FALSE,Restoring Negative Information in Few-Shot Object Detection,Applications -> Object Detection,Algorithms -> Few-Shot Learning; Algorithms -> Meta-Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yukuan Yang', ' Fangyun Wei', ' Miaojing Shi', ' Guoqi Li']","{'Microsoft Research Asia', 'Tsinghua University'}",1,1,1,"{'USA', 'China'}"
Do Adversarially Robust ImageNet Models Transfer Better?,"Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, Aleksander Madry",Do Adversarially Robust ImageNet Models Transfer Better?,24357dd085d2c4b1a88a7e0692e60294,https://proceedings.neurips.cc/paper/2020/file/24357dd085d2c4b1a88a7e0692e60294-Paper.pdf,"Our work attempts to improve upon standard techniques within computer vision, and as such comes with all of the positive and negative broader impacts of the larger field. More specifically, however, transfer learning allows researchers and practitioners to efficiently train models on their custom datasets starting from models pretrained on large-scale labeled datasets. In this way, transfer learn- ing helps those who are compute-limited or otherwise resource-constrained competititive, and thus makes ML more accessible. We believe that our paper discovers new aspects of pretrained mod- els that make them effective at transfer learning, therefore pushing our understanding of transfer learning and helping us to improve its performance.",7 Statement of Broader Impact,107,4,,,FALSE,FALSE,FALSE,Do Adversarially Robust ImageNet Models Transfer Better?,Applications -> Computer Vision,"Algorithms -> Multitask and Transfer Learning; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"['Hadi Salman', ' Andrew Ilyas', ' Logan Engstrom', ' Ashish Kapoor', ' Aleksander Madry']","{'MIT', 'Microsoft', 'Microsoft Research AI'}",1,1,1,{'USA'}
Robust Correction of Sampling Bias using Cumulative Distribution Functions,"Bijan Mazaheri, Siddharth Jain, Jehoshua Bruck",Robust Correction of Sampling Bias using Cumulative Distribution Functions,24368c745de15b3d2d6279667debcba3,https://proceedings.neurips.cc/paper/2020/file/24368c745de15b3d2d6279667debcba3-Paper.pdf,"Machine learning is limited by the availability and quality of data. In many circumstances we may not have access to labeled data from our target distribution. Improving methods for covariate shift will help us extend the impact of the data we do have. Stably predicting a conditional probability distribution has an application that has recently gained notorious prominence. In the presence of a pandemic, one may wish to predict the death-rate to calculate the expected toll on society. This translates exactly to predicting the conditional probability of dying given demographic information. Data that has been gathered often has a large sampling bias, since a persons risk profile may affect their willingness to leave home and participate in a study, and their age may affect their availability for an online survey. A stable method for covariate shift in this situation can be a critical part of ensuring officials have accurate statistics when making decisions. One potential negative impact of the work would be if it were to be misunderstood and misused, yielding incorrect results. This is a concern in all areas of data science, so it is important that the conditions for appropriate use be well understood.",Broader Impact,196,10,,,FALSE,FALSE,FALSE,Robust Correction of Sampling Bias using Cumulative Distribution Functions,Algorithms -> Multitask and Transfer Learning,Algorithms -> Missing Data,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Bijan H Mazaheri', ' Siddharth Jain', ' Jehoshua Bruck']","{'California Institute of Technology', 'Caltech'}",1,0,0,{'USA'}
Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach,"Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar",Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach,24389bfe4fe2eba8bf9aa9203a44cdad,https://proceedings.neurips.cc/paper/2020/file/24389bfe4fe2eba8bf9aa9203a44cdad-Paper.pdf,"Federated Learning (FL) provides a framework for training machine learning models efficiently and in a distributed manner. Due to these favorable properties, it has gained significant attention and has been deployed in a broad range of applications with critical societal benefits. These applications go from healthcare systems, where machine learning models can be trained while preserving patients’ privacy, to image classification and NLP models, where tech companies can improve their neural networks without requiring users to share their data with a server or other users. In our work, we study one of the challenges in FL, which is the personalization aspect. The main question that we try to answer from a theoretical point of view is whether we can have a user-oriented variant of classic FL algorithms that can adapt to each user data while enjoying the distributed architecture of FL. We show the answer is positive, and provide rigorous theoretical guarantees for algorithms that can be used in all applications mentioned above to achieve more personalized models in FL framework. Indeed, this result could have a broad impact on improving the quality of users’ models in several applications that deploy federated learning such as healthcare systems.",Broader Impact,197,7,,,FALSE,FALSE,FALSE,Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach,Optimization -> Non-Convex Optimization,Algorithms -> Meta-Learning,Optimization Methods (continuous or discrete),"['Alireza Fallah', ' Aryan Mokhtari', ' Asuman Ozdaglar']","{'Massachusetts Institute of Technology', 'MIT', 'UT Austin'}",1,0,0,{'USA'}
Pixel-Level Cycle Association: A New Perspective for Domain Adaptive Semantic Segmentation,"Guoliang Kang, Yunchao Wei, Yi Yang, Yueting Zhuang, Alexander Hauptmann",Pixel-Level Cycle Association: A New Perspective for Domain Adaptive Semantic Segmentation,243be2818a23c980ad664f30f48e5d19,https://proceedings.neurips.cc/paper/2020/file/243be2818a23c980ad664f30f48e5d19-Paper.pdf,"Our research may benefit the people or communities who want to apply semantic segmentation in various scenarios but have no annotations. It will reduce the cost to annotate the out-of-domain data, which is economic and friendly to the environment. Our method makes the trained segmentation system more robust when the system is deployed in a distinct scenario. Thus, for some applications, it will reduce the risk of accident. Our method does not leverage the bias in the data. However, if the collected training data is biased, the adapted system may be affected more or less.",Broader Impact,95,6,,,FALSE,FALSE,FALSE,Pixel-Level Cycle Association: A New Perspective for Domain Adaptive Semantic Segmentation,Deep Learning,Algorithms -> Multitask and Transfer Learning; Applications -> Image Segmentation,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Guoliang Kang', ' Yunchao Wei', ' Yi Yang', ' Yueting Zhuang', ' Alexander Hauptmann']","{'Zhejiang University', 'UTS', 'UIUC', 'Carnegie Mellon University'}",1,0,0,"{'Australia', 'USA', 'China'}"
Classification with Valid and Adaptive Coverage,"Yaniv Romano, Matteo Sesia, Emmanuel Candes",Classification with Valid and Adaptive Coverage,244edd7e85dc81602b7615cd705545f5,https://proceedings.neurips.cc/paper/2020/file/244edd7e85dc81602b7615cd705545f5-Paper.pdf,"Machine learning algorithms are increasingly relied upon by decision makers. It is therefore crucial to combine the predictive performance of such complex machinery with practical guarantees on the reliability and uncertainty of their output. We view the calibration methods presented in this paper as an important step towards this goal. In fact, uncertainty estimation is an effective way to quantify and communicate the benefits and limitations of machine learning. Moreover, the proposed methodologies provide an attractive way to move beyond the standard prediction accuracy measure used to compare algorithms. For instance, one can compare the performance of two candidate predictors, e.g., random forest and neural network (see Figure 3), by looking at the size of the corresponding prediction sets and/or their their conditional coverage. Finally, the approximate conditional coverage that we seek in this work is highly relevant within the broader framework of fairness, as discussed by [17] within a regression setting. While our approximate conditional coverage already implicitly reduces the risk of unwanted bias, an equalized coverage requirement [17] can also be easily incorporated into our methods to explicitly avoid discrimination based on protected categories. We conclude by emphasizing that the validity of our methods relies on the exchangeability of the data points. If this assumption is violated (e.g., with time-series data), our prediction sets may not have the right coverage. A general suggestion here is to always try to leverage specific knowledge of the data and of the application domain to judge whether the exchangeability assumption is reasonable. Finally, our data-splitting techniques in Section 4 offer a practical way to verify empirically the validity of the predictions on any given data set.",Broader Impact,274,12,,,FALSE,FALSE,FALSE,Classification with Valid and Adaptive Coverage,Algorithms -> Uncertainty Estimation,Algorithms -> Classification,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yaniv Romano', ' Matteo Sesia', ' Emmanuel Candes']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Learning Global Transparent Models consistent with Local Contrastive Explanations,"Tejaswini Pedapati, Avinash  Balakrishnan, Karthikeyan Shanmugam, Amit Dhurandhar",Learning Global Transparent Models Consistent with Local Contrastive Explanations,24aef8cb3281a2422a59b51659f1ad2e,https://proceedings.neurips.cc/paper/2020/file/24aef8cb3281a2422a59b51659f1ad2e-Paper.pdf,"Explainable AI (XAI) has gained a lot of traction in industry and government given the proliferation of black-box models such as neural networks. The General Data Protection Regulation (GDPR) [30] passed in Europe requires automated systems making decisions that affect humans to be able to explain themselves. There are mainly two types of explainability: local and global. Local explainability is about per sample explanations, while global explainability is about understanding the whole model. Although significant amount of work has been done for each type, there is little work that tries to combine these two paradigms in an attempt to create global models that are also locally consistent. Our work tries to bridge this gap for contrastive/counterfactual explanations which have been deemed as being one of the most important parts of an explanation [18]. The benefit of our method is thus that one can create globally transparent models that are locally consistent more than other schemes. This can be beneficial in appropriating trust in the black-box model with more confidence. The risks are similar to other methods that build global models (viz. distillation, profweight) that such models are still proxy models and hence, may not entirely replicate the reasoning done by the black-box model they are trying to explain.",Broader Impact,208,10,,,FALSE,FALSE,FALSE,Learning Global Transparent Models consistent with Local Contrastive Explanations,"Deep Learning -> Visualization, Interpretability, and Explainability",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Tejaswini Pedapati', ' Avinash Balakrishnan', ' Karthikeyan Shanmugam', ' Amit Dhurandhar']","{'IBM Research, NY', 'IBM Research', 'IBM'}",0,1,0,{'USA'}
Learning to Approximate a Bregman Divergence,"Ali Siahkamari, XIDE XIA, Venkatesh Saligrama, David Castañón, Brian Kulis",Learning to Approximate a Bregman Divergence,24bcb4d0caa4120575bb45c8a156b651,https://proceedings.neurips.cc/paper/2020/file/24bcb4d0caa4120575bb45c8a156b651-Paper.pdf,"The metric learning problem is a fundamental problem in machine learning, attracting considerable research and applications. These applications include (but are certainly not limited to) face verification, image retrieval, human activity recognition, program debugging, music analysis, and microarray data analysis (see [19] for a discussion of each of these applications, along with relevant references). Fundamental work in this problem will help to improve results in these applications as well as lead to further impact in new domains. Moreover, a solid theoretical understanding of the algorithms and methods of metric learning can lead to improvements in combating learning bias for these applications and reduce unnecessary errors in several systems.",Broader Impacts,108,4,,,FALSE,FALSE,FALSE,Learning to Approximate a Bregman Divergence,Algorithms -> Similarity and Distance Learning,Algorithms -> Metric Learning; Optimization -> Convex Optimization; Theory -> Statistical Learning Theory,,"['Ali Siahkamari', ' XIDE XIA', ' Venkatesh Saligrama', ' David Castañón', ' Brian Kulis']","{'Boston University', 'Boston University and Amazon'}",1,0,0,{'USA'}
Diverse Image Captioning with Context-Object Split Latent Spaces,"Shweta Mahajan, Stefan Roth",Diverse Image Captioning with Context-Object Split Latent Spaces,24bea84d52e6a1f8025e313c2ffff50a,https://proceedings.neurips.cc/paper/2020/file/24bea84d52e6a1f8025e313c2ffff50a-Paper.pdf,"One of the promising applications of image captioning is to convert visual content on the web or from photographs to the form of text. This content can then be made more accessible to visually impaired people through text-to-speech synthesis [41]. Additionally, image captioning has been found useful in application areas such as in the medical domain, where it can provide assistance for generating diagnostics from X-ray images [37]. Diverse image captioning, as presented in our work, aims to resolve the ambiguities or uncertainties that occur while explaining visual scenes. Multiple captions help in reducing the impact of errors in explanations, since a user then has a better overview of the concepts and contexts represented in images. Apart from such direct, positive impact on individuals or specific application domains, social media platforms utilize image captioning to mine the visual content for data summarization [24]. While this helps organizations in managing online content such as latest trends and may provide value to users of the platform, it can also compromise the users’ privacy, e . g . summarizing user behavior or preferences for targeted advertisement. Moreover, captioning algorithms are still limited by dataset biases and the availability of exhaustive human annotations [18]. In this paper, we attempt to address the latter by leveraging annotations beyond that available from the paired training data. This is inspired from the observation that within the dataset, humans label captions of images with similar contextual information in many possible variations – by focusing on different regions of images or through different interpretations. Thus we can generate diverse captions representative of the underlying data distribution. Despite this, clearly more research is necessary to reach human-level accuracy and diversity.",Broader Impact,280,14,,,FALSE,FALSE,FALSE,Diverse Image Captioning with Context-Object Split Latent Spaces,Applications -> Computer Vision,Algorithms -> Multimodal Learning; Applications -> Natural Language Processing; Applications -> Visual Question Answering,Vision,"['Shweta Mahajan', ' Stefan Roth']",{'TU Darmstadt'},1,0,0,{'Germany'}
Learning Disentangled Representations of Videos with Missing Data,"Armand Comas, Chi Zhang, Zlatan Feric, Octavia Camps, Rose Yu",Learning Disentangled Representations of Video with Missing Data,24f2f931f12a4d9149876a5bef93e96a,https://proceedings.neurips.cc/paper/2020/file/24f2f931f12a4d9149876a5bef93e96a-Paper.pdf,"Videos provide a window into the physics of the world we live in. They contain abundant visual information of what objects are, how they move, and what happens when cameras move against the scene. Being able to learn a representation that disentangles these factors is fundamental to AI that can understand and act in spatiotemporal environment. Despite the wealth of methods for video prediction, state-of-the-art approaches are sensitive to missing data, which are very common in real- world videos. Our proposed model significantly improves the robustness of video prediction methods against missing data, and thereby increasing the practical values of video prediction techniques and our trust in AI. Video surveillance systems can be potentially abused for discriminatory targeting, and we remained cognizant of the bias in our training data. To reduce the potential risk of this, we pre-processed the MOTSChallenge videos to greyscale.",Broader Impact,143,7,,,FALSE,FALSE,FALSE,Learning Disentangled Representations of Videos with Missing Data,Algorithms -> Representation Learning,Algorithms -> Missing Data; Algorithms -> Stochastic Methods; Algorithms -> Unsupervised Learning; Applications -> Computer Vision; Applications -> Object Recognition; Applications -> Tracking and Motion in Video; Applications -> Video Analysis; Deep Learning -> CNN Architectures; Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models; Deep Learning -> Predictive Models; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Probabilistic Programming; Probabilistic Methods -> Variational Inference,Vision,"['Armand Comas', ' Chi Zhang', ' Zlatan Feric', ' Octavia Camps', ' Rose Yu']","{'University of California, San Diego', 'Northeastern University'}",1,0,0,{'USA'}
Natural Graph Networks,"Pim de Haan, Taco S. Cohen, Max Welling",Natural Graph Networks,2517756c5a9be6ac007fe9bb7fb92611,https://proceedings.neurips.cc/paper/2020/file/2517756c5a9be6ac007fe9bb7fb92611-Paper.pdf,"The broader impact of this work can be analyzed in at least two different ways. Firstly, graph neural networks in general are particularly suited for analyzing human generated data. This makes that powerful graph neural nets can provide tremendous benefit automating common business tasks. On the flip side, much human generated data is privacy sensitive. Therefore, as a research community, we should not solely focus on developing better ways of analyzing such data, but also invest in technologies that help protect the privacy of those generating the data. Secondly, in this work we used some elementary applied category theory to precisely specify our problem of local equivariant message passing. We believe that applied category theory can and should be used more widely in the machine learning community. Formulating problems in a more general mathematical language makes it easier to connect disparate problem domains and solutions, as well as to communicate more precisely and thus efficiently, accelerating the research process. In the further future, we have hopes that having a better language with which to talk about machine learning problems and to specify models, may make machine learning systems more safe.",9 Broader Impact,190,9,,,FALSE,FALSE,FALSE,Natural Graph Networks,Deep Learning,Deep Learning -> CNN Architectures; Deep Learning -> Interaction-Based Deep Networks,,"['Pim de Haan', ' Taco Cohen', ' Max Welling']","{'University of Amsterdam / Qualcomm AI Research', 'Qualcomm AI Research, University of Amsterdam', 'Qualcomm AI Research'}",1,1,1,"{'USA', 'Netherlands'}"
Continual Learning with Node-Importance based Adaptive Group Sparse Regularization,"Sangwon Jung, Hongjoon Ahn, Sungmin Cha, Taesup Moon",Continual Learning with Node-Importance based Adaptive Group Sparse Regularization,258be18e31c8188555c2ff05b4d542c3,https://proceedings.neurips.cc/paper/2020/file/258be18e31c8188555c2ff05b4d542c3-Paper.pdf,"We tackle a fairly general continual learning problem, and there is no particular application forseen. The potential societal impact of our work, however, lies in saving intensive usage of computing resources, which is known to affect climate change and global warming due to the excessive energy consumption and necessity of cooling systems. Namely, when numerous ML applications require repetitive re-training of computationally intensive neural networks for learning every new task, overloading of data centers is indispensable. Hence, an effective continual learning algorithm, as proposed in our paper, can save such heavy energy consumption without losing the model accuracy. Furthermore, the effective memory usage can be additional benefit for using our method in memory- limited environments, e.g. , mobile devices.",6 Broader Impact,119,5,,,FALSE,FALSE,FALSE,Continual Learning with Node-Importance based Adaptive Group Sparse Regularization,Algorithms -> Continual Learning,Algorithms -> Multitask and Transfer Learning; Deep Learning; Optimization -> Convex Optimization; Reinforcement Learning and Planning -> Reinforcement Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Sangwon Jung', ' Hongjoon Ahn', ' Sungmin Cha', ' Taesup Moon', 'Sungkyunkwan University']","{'Sungkyunkwan University', 'SKKU', 'Sunkyunkwan University'}",1,0,0,{'South Korea'}
Towards Crowdsourced Training of Large Neural Networks using Decentralized Mixture-of-Experts,"Max Ryabinin, Anton Gusev",Towards Crowdsourced Training of Large Neural Networks using Decentralized Mixture-of-Experts,25ddc0f8c9d3e22e03d3076f98d83cb2,https://proceedings.neurips.cc/paper/2020/file/25ddc0f8c9d3e22e03d3076f98d83cb2-Paper.pdf,"The approach proposed in this work is only a prototype with limited direct consequences, but the long-term goal of training huge models with volunteer computing can have a lasting effect on both the research community and the general public. Funding bias vs crowdsourcing bias The main positive outcome we pursue is to let researchers harness volunteer computing and train models on the scale currently available only to large corporations. Ideally, a deep learning researcher with a promising idea will be able to amass the computation needed to realize this idea by involving volunteers. However, the project’s appeal for volunteers depends on many factors such as subject area, current societal trends, and even researcher’s personality. For example, a project about teaching agents to play games [38] or fighting global pandemics [67] is likely to attract more resources than deep learning applied to soil science. In essence, volunteer computing is biased towards exciting or socially relevant research the same way as traditional HPC is biased towards the interests of those who fund it. Alternative use and misuse The proposed technology can be used with different economic models. If a deep learning system is immediately useful (e.g. for machine translation, information retrieval, etc), the participants could use it for their needs based on their contributions to training. This can take many forms: several labs combining their hardware and training larger models; a web-service that lets people contribute their compute instead of using ads/subscriptions; or simply a framework that someone can use to run distributed training across two or more datacenters. Unfortunately, this also allows several opportunities for malicious use. If a machine is hacked, the attacker can use its compute unnoticed by the machine owner — much the same way that botnets are currently used to mine cryptocurrencies. Furthermore, due to decentalized nature even legitimate Learning@home projects can be hijacked by hackers. Security Using crowdsourced hardware makes Learning@home susceptible to attacks from malicious participants. There are multiple attack vectors already known in P2P community: denial of service attacks, Sybil attacks, Eclipse attacks and more [68, 69, 70, 71]. Fortunately, there are variations of the DHT protocol that make it resistant to said attacks: if a reader wishes to learn more about DHT security, we recommend starting with [68]. Another source of vulnerability stems from the sequential nature of neural networks. If a single expert were to return incorrect (e.g. NaN) outputs or gradients, it could compromise the outputs of the entire network and even poison adjacent nodes through backpropagation. Recent studies expose similar attack patterns on federated learning systems [72, 73]. The redundant nature of mixture-of-experts layers provides some degree of resistance against those attacks. A single malicious expert will only affect a small fraction of inputs that pass through this specific expert. Furthermore, a trainer with access to predictions from multiple experts could provide a higher degree of robustness by using statistical techniques (e.g., by ignoring outlier gradients). However, such techniques need to be carefully designed so as not to introduce harmful side effects. The burden on the network Finally, we would like to point out the potential harm that our approach can do to network infrastructure. The experiments we ran in Section 4.1 saturate with the bandwidth of 100 − 200 Mbps, most of which is tensors passed between experts and trainers. This coincides with the typical home internet speed available in major cities of developed countries. However, not all ISPs design their infrastructure for users who always use up all their bandwidth. If too many Learning@home participants are located in one LAN or MAN, it can cause congestion or even failures in the network infrastructure. Similar situations frequently took place in late 2000s due to growing popularity of BitTorrent for file sharing. Fortunately, the network infrastructure is continually improving, which leads us to believe that this problem will eventually be solved. Until then, we describe several ways to reduce network load of Learning@home in Appendix E.",Broader Impact,656,30,,,FALSE,TRUE,FALSE,Towards Crowdsourced Training of Large Neural Networks using Decentralized Mixture-of-Experts,Algorithms -> Large Scale Learning,Algorithms -> Communication- or Memory-Bounded Learning; Applications -> Hardware and Systems; Deep Learning,Deep learning,"['Maksim Riabinin', ' Anton Gusev']","{'Yandex, Higher School of Economics', 'none'}",1,1,1,{'Russia'}
Bidirectional Convolutional Poisson Gamma Dynamical Systems,"wenchao chen, Chaojie Wang, Bo Chen, Yicheng Liu, Hao Zhang, Mingyuan Zhou",Bidirectional Convolutional Poisson Gamma Dynamical Systems,26178fc759d2b89c45dd31962f81dc61,https://proceedings.neurips.cc/paper/2020/file/26178fc759d2b89c45dd31962f81dc61-Paper.pdf,"The proposed models are probabilistic topic models considering hierarchical temporal information within each document, which can not only achieve state-of-the-art performance in some text analysis tasks, such as unsupervised feature extraction and (semi-)supervised document categorization, but also obtain semantically meaningful topics and latent features as well as interpretable transition relations. Thus, they may be used to detect harmful articles which may contain fake news, violent content, and fraudulent materials. In addition, they can be used to recommend articles with specific contents to users according to their needs. More importantly, as they are able to provide interpretable latent features, one could try to understand why a certain categorization and recommendation has been made by the proposed model for a given article, so more appropriate actions can be taken rather than purely trusting the model itself to make the right decisions. Although big pre-trained language models, such as BERT [35], GPT2 [58], and GPT3 [59], could be fine-tuned for a variety of natural language processing tasks to achieve state-of-the-art performance in many difference settings, they are consuming significant amount of computing resources, leading to higher energy consumption and CO2 emissions. Comparing with these pretrained big models, the proposed probabilistic models provide customized probabilistic solutions to specific problems, achieving comparable results in the specific task of document categorization but with much lower memory and computational cost, which is beneficial for energy saving and environmental protection. Providing good performance while maintaining interpretability becomes an even more urgent issue today given the recent trend in building larger and more complex black-box models trained with bigger data, which work well but make it become increasingly more difficult to understand how and why they work well. We hope our work can motivate machine learners to pay more attention to the study of interpretable and compact models. When evaluating the model, we should analyze the model more and find what can help different areas of society. At present, many people tend to strongly emphasize on the numerical performance and pay less attention to the energy cost of training and deploying these models. Meanwhile, the black box feature of deep learning means that the model may fail without clear explanations, so it is difficult to deploy them to applications with high-level safety and stability requirements. An interpretable model, on the other hand, enables people to understand what the model really learns and how it makes decisions, so as to better evaluate the model and understand how and where to deploy it for the benefits of the society.",Broader Impact,418,12,,,FALSE,FALSE,FALSE,Bidirectional Convolutional Poisson Gamma Dynamical Systems,Probabilistic Methods -> Topic Models,Probabilistic Methods -> Hierarchical Models; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> MCMC; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['wenchao chen', ' Chaojie Wang', ' Bo Chen', ' Yicheng Liu', ' Hao Zhang', ' Mingyuan Zhou']","{'Xidian university', 'Xidian University', 'University of Texas at Austin'}",1,0,0,"{'USA', 'China'}"
Deep Reinforcement and InfoMax Learning,"Bogdan Mazoure, Remi Tachet des Combes, Thang Long DOAN, Philip Bachman, R Devon Hjelm",Deep Reinforcement and InfoMax Learning,26588e932c7ccfa1df309280702fe1b5,https://proceedings.neurips.cc/paper/2020/file/26588e932c7ccfa1df309280702fe1b5-Paper.pdf,"This work proposes an auxiliary objective for model-free reinforcement learning agents. The objective shows improvements in a continual learning setting, as well as on average training rewards for a suite of complex video games. While the objective is developed in a visual setting, maximizing mutual information between features is a method that can be transported to other domains, such as text. Potential applications of deep reinforcement learning are (among others) healthcare, dialog systems, crop management, robotics, etc. Developing methods that are more robust to changes in the environment, and/or perform better in a continual learning setting can lead to improvements in those various applications. At the same time, our method fundamentally relies on deep learning tools  and architectures, which are hard to interpret and prone to failures yet to be perfectly understood. Additionally, deep reinforcement learning also lacks formal performance guarantees, and so do deep reinforcement learning agents. Overall, it is essential to design failsafes when deploying such agents (including ours) in the real world.",Broader Impact,165,8,,,FALSE,FALSE,FALSE,Deep Reinforcement and InfoMax Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Representation Learning,Reinforcement learning and planning,"['Bogdan Mazoure', ' Remi Tachet des Combes', ' Thang Long DOAN', ' Philip Bachman', ' R Devon Hjelm']","{'McGill', 'Microsoft Research Montreal', 'Microsoft Research', 'McGill University'}",1,1,1,"{'Canada', 'USA'}"
On ranking via sorting by estimated expected utility,"Clement Calauzenes, Nicolas Usunier",On ranking via sorting by estimated expected utility,26b58a41da329e0cbde0cbf956640a58,https://proceedings.neurips.cc/paper/2020/file/26b58a41da329e0cbde0cbf956640a58-Paper.pdf,"The framework of ranking we studied plays a fundamental role in information retrieval and informa- tion filtering systems. While these systems play an undeniable positive role in society because they increase the efficiency of information access, they also shape the landscape of what their users get to know. This lead to questions regarding equal representation in search engines result [34], how they represent social groups [17], and whether they exacerbate filter bubbles or act as echo chambers [3]. As the most recent trends in learning to rank involve randomized experiments and online learning [16, 1] to improve quality, such user experiments also need be carried out with care [5]. Creating a strong theory of learning to rank is important to address the challenges of information access systems. For instance, methods to produce diverse rankings might be part of the solution, and for now the theory of machine learning for diverse rankings is scarse. This paper partly fills this gap.",Broader Impact,159,7,,,FALSE,FALSE,FALSE,On ranking via sorting by estimated expected utility,Algorithms -> Ranking and Preference Learning,Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Clement Calauzenes', ' Nicolas Usunier']","{'Criteo', 'Facebook AI Research'}",0,1,0,"{'France', 'USA'}"
"Distribution-free binary classification: prediction sets, confidence intervals and calibration","Chirag Gupta, Aleksandr Podkopaev, Aaditya Ramdas","Distribution-free binary classification: prediction sets, confidence intervals and calibration",26d88423fc6da243ffddf161ca712757,https://proceedings.neurips.cc/paper/2020/file/26d88423fc6da243ffddf161ca712757-Paper.pdf,"Machine learning is regularly deployed in real-world settings, including areas having high impact on individual lives such as granting of loans, pricing of insurance and diagnosis of medical conditions. Often, instead of hard 0 { 1 classifications, these systems are required to produce soft probabilistic predictions, for example of the probability that a startup may go bankrupt in the next few years (in order to determine whether to give it a loan) or the probability that a person will recover from a disease (in order to price an insurance product). Unfortunately, even though classifiers produce numbers between 0 and 1, these are well known to not be ‘calibrated’ and hence not be interpreted as probabilities in any real sense, and using them in lieu of probabilities can be both misleading (to the bank granting the loan) and unfair (to the individual at the receiving end of the decision). Thus, following early research in meteorology and statistics, in the last couple of decades the ML community has embraced the formal goal of calibration as a way to quantify uncertainty as well as to interpret classifier outputs. However, there exist other alternatives to quantify uncertainty, such as confidence intervals for the regression function and prediction sets for the binary label. There is not much guidance on which of these should be employed in practice, and what the relationship between them is, if any. Further, while there are many post-hoc calibration techniques, it is unclear which of these require distributional assumptions to work and which do not—this is critical because making distributional assumptions (for convenience) on financial or medical data is highly suspect. This paper explicitly relates the three aforementioned notions of uncertainty quantification without making distributional assumptions, describes what is possible and what is not. Importantly, by providing distribution-free guarantees on well-known variants of binning, we identify a conceptually simple and theoretically rigorous way to ensure calibration in high-risk real-world settings. Our tools are thus likely to lead to fairer systems, better estimates of risks of high-stakes decisions, and more human-interpretable outputs of classifiers that apply out-of-the-box in many real-world settings because of the assumption-free guarantees.",7 Broader Impact,354,10,,,FALSE,FALSE,FALSE,"Distribution-free binary classification: prediction sets, confidence intervals and calibration",Algorithms -> Uncertainty Estimation,,Theory (including computational and statistical analyses),"['Chirag Gupta', ' Aleksandr Podkopaev', ' Aaditya Ramdas']","{'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow,"Didrik Nielsen, Ole Winther",Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow,26ed695e9b7b9f6463ef4bc1fd74fc87,https://proceedings.neurips.cc/paper/2020/file/26ed695e9b7b9f6463ef4bc1fd74fc87-Paper.pdf,"This is foundational research in generative models/unsupervised learning with proposal for new flow models and interpretation of existing autoregressive models as flow models. These models can be applied to for example unsupervised learning on images and audio. Unsupervised learning has the potential to greatly reduce the need for labeled data and thus improve models in applications such as medical imaging where a lack of data can be a limitation. However, it may also potentially be used to improve deep fakes with potentially malicious applications.",Broader Impact,84,4,,,FALSE,FALSE,FALSE,Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Algorithms -> Unsupervised Learning; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Didrik Nielsen', ' Ole Winther']","{'DTU Compute', 'DTU and KU'}",1,1,1,{'Denmark'}
Sequence to Multi-Sequence Learning via Conditional Chain Mapping for Mixture Signals,"Jing Shi, Xuankai Chang, Pengcheng Guo, Shinji Watanabe, Yusuke Fujita, Jiaming Xu, Bo Xu, Lei Xie",Sequence to Multi-Sequence Learning via Conditional Chain Mapping for Mixture Signals,27059a11c58ade9b03bde05c2ca7c285,https://proceedings.neurips.cc/paper/2020/file/27059a11c58ade9b03bde05c2ca7c285-Paper.pdf,"Benefits Our conditional chain model addresses the problems where one input sequence is mapped to multiple sequences by taking advantage of the intrinsic interaction between the output sequences. There are a variety of applications that can benefit from the use of the conditional information, such as the text generation tasks. Another important application is the cocktail party problem in speech processing. With the parallel mapping models, which are the dominant method at present, the model cannot handle the variable number of speakers flexibly due to the limitation of the model structure. In such models, the solution to label permutation problems is to exhaustively compute all the permutations with the computation cost of N!, which cannot be neglected when the number of speakers are more than 3. However, using the conditional model can avoid this problem. It also proves the effectiveness of our model which achieves relatively good performance in both separation and recognition tasks. We make a further step towards attacking cocktail party problem. This will improve the communication quality of human-computer interaction. And our method can also be applied in meeting transcription system to provide better performance. We would like to make our code available latter to facilitate the study applied to other tasks. Drawbacks There is no doubt that the improvement of artificial intelligence can potentially revolutionise our societies in many ways. However, it also bring some risks to human’s privacy. With the abusing use of speech separation and recognition techniques, hackers can easily monitor people’s daily life, while a strong NLP system can also be applied to Internet fraud. We think the community should not only focus the development of techniques, but also concern the privacy issue. Besides, the widely use of artificial intelligence techniques may also lead to mass-scale unemployment problems, such as call center.",Broader impact,299,16,,,TRUE,TRUE,FALSE,Sequence to Multi-Sequence Learning via Conditional Chain Mapping for Mixture Signals,Applications -> Audio and Speech Processing,Applications -> Speech Recognition,Audio / Music / Speech,"['Jing Shi', ' Xuankai Chang', ' Pengcheng Guo', ' Shinji Watanabe', ' Yusuke Fujita', ' Jiaming Xu', ' Bo Xu', ' Lei Xie']","{'Northwestern Polytechnical University', 'Johns Hopkins University', 'Hitachi', 'Institute of Automation Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences'}",1,1,1,"{'Japan', 'USA', 'China'}"
Variance reduction for Random Coordinate Descent-Langevin Monte Carlo,"ZHIYAN DING, Qin Li",Variance reduction for Random Coordinate Descent-Langevin Monte Carlo,272e11700558e27be60f7489d2d782e7,https://proceedings.neurips.cc/paper/2020/file/272e11700558e27be60f7489d2d782e7-Paper.pdf,"The result provides theoretical guarantee to the application of random coordinate descent to Langevin Monte Carlo, when variance reduction technique is used to reduce the cost. It has potential application  to inverse problems emerging from atmospheric science, remote sensing, and epidemiology. This work does not present any foreseeable societal consequence.",8 Broader Impact,50,3,TRUE,TRUE,FALSE,FALSE,FALSE,Variance reduction for Random Coordinate Descent-Langevin Monte Carlo,Probabilistic Methods -> MCMC,,Probabilistic methods and inference,,{'University of Wisconsin-Madison'},1,0,0,{'USA'}
Language as a Cognitive Tool to Imagine Goals in Curiosity Driven Exploration,"Cédric Colas, Tristan Karch, Nicolas Lair, Jean-Michel Dussoux, Clément Moulin-Frier, Peter Dominey, Pierre-Yves Oudeyer",Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven Exploration,274e6fcf4a583de4a81c6376f17673e7,https://proceedings.neurips.cc/paper/2020/file/274e6fcf4a583de4a81c6376f17673e7-Paper.pdf,"We present a reinforcement learning architecture where autonomous agents interact with a social partner to explore a large set of possible interactions and learn to master them. As a result, our work contributes to facilitating human intervention in the learning process of a robot, which we believe is a key step towards more explainable and safer autonomous robots. Besides, by releasing our code, we believe that we help efforts in reproducible science and allow the wider community to build upon and extend our work in the future. In that spirit, we also provide clear explanations on the number of seeds, error bars, and statistical testing when reporting the results.",Broader Impact Statement,109,4,FALSE,FALSE,FALSE,TRUE,FALSE,Language as a Cognitive Tool to Imagine Goals in Curiosity Driven Exploration,Deep Learning,Neuroscience and Cognitive Science -> Language for Cognitive Science,Reinforcement learning and planning,"['Cédric Colas', ' Tristan Karch', ' Nicolas Lair', 'Michel Dussoux', 'Frier', ' Peter F Dominey', 'Yves Oudeyer']","{'INRIA', 'Inserm Robot Cognition Lab', 'Cloud Temple', 'INSERM/CNRS', 'Inria'}",1,1,1,{'France'}
All Word Embeddings from One Embedding,"Sho Takase, Sosuke Kobayashi",All Word Embeddings from One Embedding,275d7fb2fd45098ad5c3ece2ed4a2824,https://proceedings.neurips.cc/paper/2020/file/275d7fb2fd45098ad5c3ece2ed4a2824-Paper.pdf,"This study addresses the reduction of trainable parameters for word embeddings. Word embeddings are fundamental component of various neural network-based NLP methods because we need them to convert a symbolic input into vector representations. Thus, the proposed method, ALONE, has potential to reduce the parameter size of existing neural network-based NLP methods. In this paper, we combined ALONE with a neural encoder-decoder model but we expect that it also has a positive effect on other methods such as large-scale neural language models.",Broader Impact,82,4,,,FALSE,FALSE,FALSE,All Word Embeddings from One Embedding,Applications -> Natural Language Processing,Deep Learning -> Embedding Approaches,Natural language processing,"['Sho Takase', ' Sosuke Kobayashi']","{'Preferred Networks', 'Tokyo Institute of Technology'}",1,1,1,{'Japan'}
Primal Dual Interpretation of the Proximal Stochastic Gradient Langevin Algorithm,"Adil SALIM, Peter Richtarik",Primal Dual Interpretation of the Proximal Stochastic Gradient Langevin Algorithm,2779fda014fbadb761f67dd708c1325e,https://proceedings.neurips.cc/paper/2020/file/2779fda014fbadb761f67dd708c1325e-Paper.pdf,"Our work contributes to the understanding of a sampling algorithm used in statistics. Our main results are of theoretical nature (convergence rates). Therefore, we do not see any immediate societal impact of our results.",8 Broader impact,34,3,TRUE,FALSE,FALSE,FALSE,FALSE,Primal Dual Interpretation of the Proximal Stochastic Gradient Langevin Algorithm,Probabilistic Methods -> MCMC,Optimization -> Convex Optimization; Optimization -> Stochastic Optimization,,"['Adil SALIM', ' Peter Richtarik']",{'KAUST'},1,0,0,{'Saudi Arabia'}
How to Characterize The Landscape of Overparameterized Convolutional Neural Networks,"Yihong Gu, Weizhong Zhang, Cong Fang, Jason D. Lee, Tong Zhang",How to Characterize The Landscape of Overparameterized Convolutional Neural Networks,2794f6a20ee0685f4006210f40799acd,https://proceedings.neurips.cc/paper/2020/file/2794f6a20ee0685f4006210f40799acd-Paper.pdf,"The authors feel that the broader impact seems not applicable to this work. The reason is that this is a research paper, which provides new insights to help people better understand deep neural networks and can motivate more efficient training algorithms in the future. But it is hard to say who may benefit and who may be put at disadvantage from this research.",8 Broader Impact,63,3,TRUE,FALSE,FALSE,FALSE,FALSE,How to Characterize The Landscape of Overparameterized Convolutional Neural Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Representation Learning,Deep learning,"['Weizhong Zhang', ' Yihong Gu', ' Cong Fang', ' Jason Lee', ' Tong Zhang']","{'Zhejiang University', 'Princeton University', 'Peking University', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
On the Tightness of Semidefinite Relaxations for Certifying Robustness to Adversarial Examples,Richard Zhang,On the Tightness of Semidefinite Relaxations for Certifying Robustness to Adversarial Examples,27b587bbe83aecf9a98c8fe6ab48cacc,https://proceedings.neurips.cc/paper/2020/file/27b587bbe83aecf9a98c8fe6ab48cacc-Paper.pdf,"This work contributes towards making neural networks more robust to adversarial examples. This is a crucial roadblock before neural networks can be widely adopted in safety-critical applications like self- driving cars and smart grids. The ultimate, overarching goal is to take the high performance of neural networks—already enjoyed by applications in computer vision and natural language processing—and extend towards applications in societal infrastructure. Towards this direction, SDP relaxations allow us to make mathematical guarantees on the robustness of a given neural network model. However, a blind reliance on mathematical guarantees leads to a false sense of security. While this work contributes towards robustness of neural networks, much more work is needed to understand the appropriateness of neural networks for societal applications in the first place.",Broader Impact,125,6,,,FALSE,FALSE,FALSE,On the Tightness of Semidefinite Relaxations for Certifying Robustness to Adversarial Examples,Optimization,Algorithms -> Adversarial Learning; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Optimization for Deep Networks; Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization,Theory (including computational and statistical analyses),['Richard Zhang'],{'UIUC'},1,0,0,{'USA'}
Submodular Meta-Learning,"Arman Adibi, Aryan Mokhtari, Hamed Hassani",Submodular Meta-Learning,27d8d40b22f812a1ba6c26f8ef7df480,https://proceedings.neurips.cc/paper/2020/file/27d8d40b22f812a1ba6c26f8ef7df480-Paper.pdf,"This paper introduces a discrete Meta-learning framework that aims at exploiting prior experience and data to improve performance on future tasks. While our results do not immediately lead to broader societal impacts, they can potentially lead to new approaches to reduce computation load and increase speed in latency-critical applications, such as recommender systems, autonomous systems, etc. In such applications, where there is a flow of new tasks arriving at any time requiring fast decisions, the available computational power and time is often limited either because we need to make quick decisions to respond to new users/tasks or since we need to save energy. For instance, in real-world advertising or recommendation systems, both these requirements are crucial: many users arrive within each hour which means fast decision-making is crucial, and also, reducing computation load would lead to huge energy savings in the long run. Our framework is precisely designed to address this challenge. Moreover, the framework introduced in this paper can potentially open new doors in the research field of discrete optimization.",Broader Impact,171,6,,,TRUE,TRUE,FALSE,Submodular Meta-Learning,Optimization -> Submodular Optimization,"Algorithms; Algorithms -> Few-Shot Learning; Algorithms -> Meta-Learning; Algorithms -> Model Selection and Structure Learning; Algorithms -> Multitask and Transfer Learning; Algorithms -> Online Learning; Algorithms -> Representation Learning; Algorithms -> Stochastic Methods; Applications -> Computational Social Science; Applications -> Recommender Systems; Data, Challenges, Implementations, and Software; Optimization -> Convex Optimization; Optimization -> Discrete Optimization; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization; Probabilistic Methods; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Multi-Agent RL; Theory -> Computational Learning Theory; Theory -> Control Theory; Theory -> Data-driven Algorithm Design; Theory -> Models of Learning and Generalization ; Theory -> Spaces of Functions and Kernels",Optimization Methods (continuous or discrete),"['Arman Adibi', ' Aryan Mokhtari', ' Hamed Hassani']","{'University of Pennsylvania', 'UT Austin', 'UPenn'}",1,0,0,{'USA'}
Rethinking Pre-training and Self-training,"Barret Zoph, Golnaz Ghiasi, Tsung-Yi Lin, Yin Cui, Hanxiao Liu, Ekin Dogus Cubuk, Quoc Le",Rethinking Pre-training and Self-training,27e9661e033a73a6ad8cefcde965c54d,https://proceedings.neurips.cc/paper/2020/file/27e9661e033a73a6ad8cefcde965c54d-Paper.pdf,"Our paper studies self-training, a machine learning technique, with applications in object detection and segmentation. As a core machine learning method, self-training can enable machine learning methods to work better and with less data. So it should have broader applications in computer vision, and other fields such as speech recognition, NLP, bioinformatics etc. The datasets in our study are generic and publicly available, which do not tie to any specific application. We foresee positive impacts if the method is applied to datasets in self-driving or healthcare. But the method can also be applied to other datasets and sensitive applications that have ethical implications such as mass surveillance.",Broader and Social Impact,107,6,,,FALSE,FALSE,FALSE,Rethinking Pre-training and Self-training,Applications -> Computer Vision,Algorithms -> Representation Learning; Algorithms -> Semi-Supervised Learning,Deep learning,"['Barret Zoph', ' Golnaz Ghiasi', 'Yi Lin', ' Yin Cui', ' Hanxiao Liu', ' Ekin Dogus Cubuk', ' Quoc V Le']","{'Google Brain', 'Google'}",0,1,0,{'USA'}
Unsupervised Sound Separation Using Mixture Invariant Training,"Scott Wisdom, Efthymios Tzinis, Hakan Erdogan, Ron Weiss, Kevin Wilson, John Hershey",Unsupervised Sound Separation Using Mixture Invariant Training,28538c394c36e4d5ea8ff5ad60562a93,https://proceedings.neurips.cc/paper/2020/file/28538c394c36e4d5ea8ff5ad60562a93-Paper.pdf,"Unsupervised training as proposed in this paper has the potential to make recent advancements in supervised source separation more broadly useful by enabling training on large amounts of real world mixture data which are better matched to realistic application scenarios. These systems have many potential benefits as components in assistive technologies like hearing aids or as front ends to improve speech recognition performance in the presence of noise. Preliminary experiments in this work focused on artificial mixtures from standard datasets. However, the ability to leverage unlabeled in-the-wild data, which is comparatively easy to collect, increases the importance of careful dataset curation, lest bias in the data lead to decreased performance for underrepresented groups, e.g. accented or atypical speech. As described above, care must be taken to avoid unintentional correlation between sources, e.g. such that examples containing a particular source class do not only appear with the same backgrounds.",Broader impact,148,5,,,FALSE,FALSE,FALSE,Unsupervised Sound Separation Using Mixture Invariant Training,Applications -> Audio and Speech Processing,Algorithms -> Unsupervised Learning,Audio / Music / Speech,,"{'Google', 'University of Illinois at Urbana-Champaign'}",1,1,1,{'USA'}
Adaptive Discretization for Model-Based Reinforcement Learning,"Sean Sinclair, Tianyu Wang, Gauri Jain, Siddhartha Banerjee, Christina Yu",Adaptive Discretization for Model-Based Reinforcement Learning,285baacbdf8fda1de94b19282acd23e2,https://proceedings.neurips.cc/paper/2020/file/285baacbdf8fda1de94b19282acd23e2-Paper.pdf,"Exploring Memory-Computation Trade-offs in RL Reinforcement learning policies have enjoyed remarkable success in recent years, in particular in the context of large-scale game playing. These results, however, mask the high underlying costs in terms of computational resources and training time that the demonstrations requires [36, 26, 27, 35]. For example, the AlphaGo Zero algorithm that mastered Chess and Go from scratch trained their algorithm over 72 hours using 4 TPUs and 64 GPUs. These results, while highlighting the intrinsic power in reinforcement learning algorithms, are computationally infeasible for applying algorithms to RL tasks in computing systems. As an example, RL approaches have received much interest in several of the following problems: • Memory Management: Many computing systems have two sources of memory; on-chip memory which is fast but limited, and off-chip memory which has low bandwidth and suffers from high latency. Designing memory controllers for these system require a scheduling policy to adapt to changes in workload and memory reference streams, ensuring consistency in the memory, and controlling for long-term consequences of scheduling decisions [1, 2, 8]. • Online Resource Allocation: Cloud-based clusters for high performance computing must decide how to allocate computing resources to different users or tasks with highly variable demand. Controllers for these systems must make decisions online to manage the trade-offs between computation cost, server costs, and delay in job-completions. Recent work has studied RL algorithms for such problems [15, 23, 28, 22]. Common to all of these examples are computation and storage limitations on the devices used for the controller. • Limited Memory: On chip memory is expensive and off-chip memory access has lowbandwidth. As any reinforcement learning algorithm requires memory to store estimates of relevant quantities - RL algorithms for computing systems must manage their computational requirements. • Power Consumption: Many applications require low-power consumption for executing RL policies on general computing platforms. • Latency Requirements: Many problems for computing systems (e.g. memory management) have strict latency quality of service requirements that limits reinforcement learning algorithms to execute their policy quickly. Our algorithm ADAMB takes a first step towards designing efficient reinforcement learning algorithms for continuous (or large finite) spaces, where efficient means both low-regret, but also low storage and computation complexity (see Table 1). ADAMB is motivated by recent algorithms for reinforcement learning on memory constrained devices which use a technique called cerebellar model articulation controller (CMAC). This technique uses a random-discretizations of the space at various levels of coarseness [15]. Moreover, heuristic algorithms which use discretizations (either fixed or adaptive) have been extensively studied on various tasks [32, 39, 22]. We are able to show that our algorithm achieves good dependence with respect to K on all three dimensions (regret, computation, and storage complexity). With future work we hope to determine problem specific guarantees, exhibiting how these adaptive partitioning algorithms are able to extract structure common in computing systems problems. Societal Projects An important component of this research and proposed future work is the focus on building a datadriven simulator for societal systems, and use these for benchmarking and testing RL algorithms. Many problems in computing systems and operations research exhibit additional structure, whereby analyzing how algorithms are able to extract and exploit that structure is paramount to their success in real-time applications. Examples like the Behaviour Suite for Reinforcement Learning [29] are designed with toy examples to understand different components in RL algorithms (exploration, generalization, memory, etc) but is not application driven by design. Our research takes the first-step in analyzing the performance of adaptive discretization for these tasks. We summarize several problems below: • Ambulance Routing (See Appendix H): This problem generalizes the canonical k-Server problem commonly studied in theoretical computer science. An ambulance operator controls a fleet of ambulances and must decide on locations to station the ambulances in order to minimize transportation cost and travel-time to service patients arriving from an unknown distribution. • Oil Problem (See Appendix H): This problem generalizes the common discrete Grid-World environment. Here an operator controls a measurement system (say a machine used to drill for oil) and must decide on locations to station the rig in order to minimize transportation cost and maximize the probability of obtaining the resource. • Online Resource Allocation: Many problems in online resource allocation can be formulated and solved through reinforcement learning. For a concrete example, consider a mobilefood pantry that needs to design allocation rules for how much resources to allocate to a specific location without any knowledge on the distribution of demands for locations to come. Reinforcement learning policies in this setting will have to balance between designing algorithms that utilize all of the resources (pareto-optimality), while ensuring fairness across locations (envy-freeness). This problem helps serve as an interdisciplinary connection between reinforcement learning, fairness, and resource allocation.",Broader Impact,792,32,,,TRUE,TRUE,FALSE,Adaptive Discretization for Model-Based Reinforcement Learning,Reinforcement Learning and Planning -> Model-Based RL,Algorithms -> Online Learning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Sean Sinclair', ' Tianyu Wang', ' Gauri Jain', ' Siddhartha Banerjee', ' Christina Yu']","{'Cornell University', 'Duke University'}",1,0,0,{'USA'}
CodeCMR: Cross-Modal Retrieval For Function-Level Binary Source Code Matching,"Zeping Yu, Wenxin Zheng, Jiaqi Wang, Qiyi Tang, Sen Nie, Shi Wu",CodeCMR: Cross-Modal Retrieval For Function-Level Binary Source Code Matching,285f89b802bcb2651801455c86d78f2a,https://proceedings.neurips.cc/paper/2020/file/285f89b802bcb2651801455c86d78f2a-Paper.pdf,"Positive outcomes The security researchers will benefit from this research. Given a large-scale corpus of source-binary pairs, the researchers could use our technology to find the binary code of a vulnerability signature. Also, they could search the source code of a binary signature to help reverse engineering. Negative outcomes For a malicious attacker, our technology may be used to cause a potential negative outcome.",Broader Impact,64,4,,,FALSE,FALSE,FALSE,CodeCMR: Cross-Modal Retrieval For Function-Level Binary Source Code Matching,Applications -> Program Understanding and Generation,Applications -> Information Retrieval,"Other applications (e.g., robotics, biology, climate, finance)","['Zeping Yu', ' Wenxin Zheng', ' Jiaqi Wang', ' Qiyi Tang', ' Sen Nie', ' Shi Wu']","{'Shanghai JiaoTong University, Tencent KeenLab', 'Tencent Keen Lab', 'Tencent Keen Lab, Technical University of Munich'}",1,1,1,"{'China', 'Germany'}"
On Warm-Starting Neural Network Training,"Jordan Ash, Ryan P. Adams",On Warm-Starting Neural Network Training,288cd2567953f06e460a33951f55daaf,https://proceedings.neurips.cc/paper/2020/file/288cd2567953f06e460a33951f55daaf-Paper.pdf,"The shrink and perturb trick allows models to be efficiently updated without sacrificing generalization performance. In the absence of this method, achieving best-possible performance requires neural networks to be randomly-initialized each time new data are appended to the training set. As mentioned earlier, this requirement can cost significant computational resources, and as a result, is partially responsible for the deleterious environmental ramifications studied in recent years [4, 5]. Additionally, the enormous computational expense of retraining models from scratch disproportion- ately burdens research groups without access to abundant computational resources. The shrink and perturb trick lowers this barrier, democratizing participation in online learning, active learning, and pre-training research with neural networks.",6 Broader Impact,110,5,,,FALSE,FALSE,FALSE,On Warm-Starting Neural Network Training,Deep Learning -> Optimization for Deep Networks,Deep Learning; Deep Learning -> Supervised Deep Networks,Deep learning,"['Jordan Ash', ' Ryan Adams']","{'Princeton University', 'Microsoft Research'}",1,1,1,{'USA'}
DAGs with No Fears: A Closer Look at Continuous Optimization for Learning Bayesian Networks,"Dennis Wei, Tian Gao, Yue Yu",DAGs with No Fears: A Closer Look at Continuous Optimization for Learning Bayesian Networks,28a7602724ba16600d5ccc644c19bf18,https://proceedings.neurips.cc/paper/2020/file/28a7602724ba16600d5ccc644c19bf18-Paper.pdf,"Bayesian networks are fundamentally about modeling the joint probability distribution of data, in a parsimonious and comprehensible manner. This work therefore contributes mostly to layer 0 (“foundational research”) in the “Impact Stack” of [ 3], particularly with regard to the theoretical aspects. If one views Bayesian network structure learning as a “ML technique” rather than a “foundational technique”, then the algorithmic contribution also falls into layer 1. We thus confine our discussion of broader impacts mostly to layers 0 and 1, i.e. “tractable” impacts according to [3], as it is difficult and perhaps inappropriate to speculate further. The predominant contribution of this work is to theoretical understanding of the optimization problem that is score-based structure learning, and specifically a continuous formulation thereof. This understanding has resulted in improvements in accuracy (as measured by structural Hamming distance), and we expect that further improvements will be made in future work. We also believe that this understanding may lead to advances in computational efficiency as well, beyond the simple measure of terminating the NOTEARS algorithm early when it has no hope of reaching feasibility, or observing that the absolute value version (Abs) converges more quickly. For example, new optimization algorithms may be proposed for problems (3) and/or (6) that take better advantage of their properties. As the accuracy and scalability of Bayesian network structure learning continue to increase, we hope that it becomes an even more commonly used technique for modeling data than it is now. We are particularly interested in its use as the first step in causal structure discovery, which may then facilitate other causal inference tasks. We recognize however that errors in structure learning may compound into potentially more serious downstream errors. This is an issue calling for further study.",Broader Impact,290,12,,,FALSE,FALSE,FALSE,DAGs with No Fears: A Closer Look at Continuous Optimization for Learning Bayesian Networks,Probabilistic Methods -> Graphical Models,Optimization -> Non-Convex Optimization,Probabilistic methods and inference,"['Dennis Wei', ' Tian Gao', ' yue yu']","{'IBM Research', 'IBM Research AI', 'Lehigh University'}",1,1,1,{'USA'}
OOD-MAML: Meta-Learning for Few-Shot Out-of-Distribution Detection and Classification,"Taewon Jeong, Heeyoung Kim",OOD-MAML: Meta-Learning for Few-Shot Out-of-Distribution Detection and Classification,28e209b61a52482a0ae1cb9f5959c792,https://proceedings.neurips.cc/paper/2020/file/28e209b61a52482a0ae1cb9f5959c792-Paper.pdf,"OOD-MAML can help humans to detect abnormal behaviors quickly and take appropriate actions in a variety of real-world problems, including production system monitoring, preventive maintenance, fraud detection, health condition monitoring, and disease surveillance. OOD-MAML can contribute to the machine learning community by providing a new perspective to OOD detection as a new, supervised, approach. Previous methods for OOD detection have focused on an unsupervised learning framework to construct the decision boundary of in-distribution samples. However, this approach generally requires a huge amount of in-distribution samples and also can suffer from model uncertainty. Instead, we take a supervised learning framework by introducing an adapted classifier, which is evaluated not only with in-distribution samples, but also with OOD samples in the meta-training phase.",Broader Impact,121,5,,,FALSE,FALSE,FALSE,OOD-MAML: Meta-Learning for Few-Shot Out-of-Distribution Detection and Classification,Algorithms -> Classification,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Taewon Jeong', ' Heeyoung Kim']",{'KAIST'},1,0,0,{'South Korea'}
An Imitation from Observation Approach to Transfer Learning with Dynamics Mismatch,"Siddharth Desai, Ishan Durugkar, Haresh Karnan, Garrett Warnell, Josiah Hanna, Peter Stone",An Imitation from Observation Approach to Transfer Learning with Dynamics Mismatch,28f248e9279ac845995c4e9f8af35c2b,https://proceedings.neurips.cc/paper/2020/file/28f248e9279ac845995c4e9f8af35c2b-Paper.pdf,"Reinforcement learning [ 42] is being considered as an effective tool to train autonomous agents in various important domains like robotics, medicine, etc. A major hurdle to deploying learning agents in these environments is the massive exploration and data requirements [16] to ensure that these agents learn effective policies. Real world interactions and exploration in these situations could be extremely expensive (wear and tear on expensive robots), or dangerous (treating a patient in the medical domain). Sim-to-real transfer aims to address this hurdle and enables agents to be trained mostly in simulation and then transferred to the real world based on very few interactions. Reducing the requirement for real world data for autonomous agents might open up the viability for autonomous agents in other fields as well. Improved sim-to-real transfer will also reduce the pressure for high fidelity simulators, which require significant engineering effort [8, 44]. Simulators are also developed with a task in mind, and are generally not reliable outside their specifications. Sim-to-real transfer might enable simulators that learn to adapt to the task that needs to be performed, a potential direction for future research. Sim-to-real research needs to be handled carefully, however. Grounded simulators might lead to a false sense of confidence in a policy trained in such a simulator. However, a simulator grounded with real world data will still perform poorly in situations outside the data distribution. As has been noted in the broader field of machine learning [3], out of training distribution situations might lead to unexpected consequences. Simulator grounding must be done carefully in order to guarantee that the grounding is applied over all relevant parts of the environment. Improved sim-to-real transfer could increase reliance on compute and reduce incentives for sample efficient methods. The field should be careful in not abandoning this thread of research as the increasing cost and impact of computation used by machine learning becomes more apparent [2].",Broader Impact,317,15,,,FALSE,FALSE,FALSE,An Imitation from Observation Approach to Transfer Learning with Dynamics Mismatch,Reinforcement Learning and Planning,Algorithms -> Adversarial Learning; Applications -> Robotics; Deep Learning -> Adversarial Networks; Reinforcement Learning and Planning -> Reinforcement Learning,"Other applications (e.g., robotics, biology, climate, finance)",,"{'The University of Texas at Austin', ' University of Edinburgh', 'US Army Research Laboratory', 'University of Texas at Austin'}",1,0,0,"{'UK', 'USA'}"
Learning About Objects by Learning to Interact with Them,"Martin Lohmann, Jordi Salvador, Aniruddha Kembhavi, Roozbeh Mottaghi",Learning About Objects by Learning to Interact with Them,291597a100aadd814d197af4f4bab3a7,https://proceedings.neurips.cc/paper/2020/file/291597a100aadd814d197af4f4bab3a7-Paper.pdf,"This paper promotes the idea of learning from interaction based on self supervision. In recent years, large-scale datasets have led to significant advancements in core computer vision problems. However, curating these datasets is a costly and time-consuming process. This paper is a step towards learning like humans, which typically happens by interacting with the surrounding world instead of supervised training with massive datasets. The broader impact of this research is to show that promising results can be obtained via this method of supervision, and to encourage our colleagues in the community to pursue this direction. We do not expect such methods of learning to have short or long term negative consequences. However, we caution that learning from interaction using physical robots in the real world may have safety implications for other agents and objects in the scene. For this reason, we recommend carrying out real-world studies in constrained laboratory settings or using simulated environments in the near future. Funding disclosure. This work was supported by the Allen Institute for AI.",Broader Impact,170,10,,,FALSE,FALSE,FALSE,Learning About Objects by Learning to Interact with Them,Applications -> Visual Scene Analysis and Interpretation,Applications -> Computer Vision,Vision,"['Martin Lohmann', ' Jordi Salvador', ' Aniruddha Kembhavi', 'Allen Institute for Artificial Intelligence', ' Roozbeh Mottaghi']","{'AI2', 'Allen Institute for Artificial Intelligence', 'Allen Institute for AI'}",1,1,1,{'USA'}
Learning discrete distributions with infinite support,"Doron Cohen, Aryeh Kontorovich, Geoﬀrey Wolfer",Learning discrete distributions with infinite support,291dbc18539ba7e19b8abb7d85aa204e,https://proceedings.neurips.cc/paper/2020/file/291dbc18539ba7e19b8abb7d85aa204e-Paper.pdf,This work is of purely theoretical nature and does not present any foreseeable societal consequence.,Broader Impact,15,1,TRUE,FALSE,FALSE,FALSE,FALSE,Learning discrete distributions with infinite support,Theory -> Statistical Learning Theory,,Theory (including computational and statistical analyses),"['Doron Cohen', ' Aryeh Kontorovich', ' Geoﬀrey Wolfer']","{'Ben Gurion University', 'Ben-Gurion University of the Negev'}",1,0,0,{'Israel'}
Dissecting Neural ODEs,"Stefano Massaroli, Michael Poli, Jinkyoo Park, Atsushi Yamashita, Hajime Asama",Dissecting Neural ODEs,293835c2cc75b585649498ee74b395f5,https://proceedings.neurips.cc/paper/2020/file/293835c2cc75b585649498ee74b395f5-Paper.pdf,"As continuous deep learning sees increased utilization across fields such as healthcare (Rubanova et al., 2019; Yıldız et al., 2019), it is of utmost importance that we develop appropriate tools to further our understanding of neural differential equations. The search for robustness in traditional deep learning has only recently seen a surge in ideas and proposed solutions; this work aims at providing exploratory first steps necessary to extend the discussion to this novel paradigm. The leitmotif of this work is injecting system–theoretic concepts into the framework of continuous models. These ideas are of foundational importance in tangential fields such control and forecasting of dynamical systems, and are routinely used to develop robust algorithms with theoretical and practical guarantees.",Broader Impact,118,4,,,FALSE,FALSE,FALSE,Dissecting Neural ODEs,Algorithms -> Dynamical Systems,Deep Learning -> Analysis and Understanding of Deep Networks,Theory (including computational and statistical analyses),"['Stefano Massaroli', ' Michael Poli', ' Jinkyoo Park', ' Atsushi Yamashita', ' edit Hajime Asama']","{'KAIST', 'The University of Tokyo'}",1,0,0,"{'Japan', 'South Korea'}"
Teaching a GAN What Not to Learn,"Siddarth Asokan, Chandra Seelamantula",Teaching a GAN What Not to Learn,29405e2a4c22866a205f557559c7fa4b,https://proceedings.neurips.cc/paper/2020/file/29405e2a4c22866a205f557559c7fa4b-Paper.pdf,"Neural network based image classification and supervised image generation are data-intensive tasks. These models, when trained on unbalanced data, for instance, facial image datasets with insufficient racial diversity [43], tend to inherit the implicit biases present in the data. DeVries et al. [44] demonstrated the existence of such biases with sub-par classification performance on images of objects coming from countries with low-income households, compared with those coming from countries with high-income households. The proposed approach could be used to address the imbalance in the data distribution and cater to the under-represented classes. The optimized generator in the proposed Rumi approach could be used to generate more samples of the under-represented classes and thus make the machine learning task more inclusive . The negative aspect is that one could flip the whole argument around and redefine the desired and undesired classes to serve exactly the opposite objective of favoring a certain class at the expense of the other. While the proposed approach could be used to alleviate the imbalances and biases present in the dataset, it cannot overcome the biases of the data scientist.",8 Broader Impact,183,8,,,FALSE,FALSE,FALSE,Teaching a GAN What Not to Learn,Deep Learning -> Adversarial Networks,Algorithms -> Semi-Supervised Learning; Deep Learning -> Generative Models; Deep Learning -> Supervised Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Siddarth Asokan', ' Chandra Seelamantula']","{'Indian Institute of Science', 'IISc Bangalore'}",1,0,0,{'India'}
Counterfactual Data Augmentation using Locally Factored Dynamics,"Silviu Pitis, Elliot Creager, Animesh Garg",Counterfactual Data Augmentation using Locally Factored Dynamics,294e09f267683c7ddc6cc5134a7e68a8,https://proceedings.neurips.cc/paper/2020/file/294e09f267683c7ddc6cc5134a7e68a8-Paper.pdf,"Considerations related to counterfactual reasoning CoDA transforms the observational data distribution into a counterfactual one. This incurs several risks and benefits, listed below. • Modern under distributional machine learning shift (sometimes models and called reinforcement “covariate learning shift”) [49, agents 14]. often CoDA generalize has the potential poorly to produce out-of-distribution data, that would never show up in the observational distribution. Thus, care should be taken when applying agent modules that have been trained only on observational data to counterfactual data, as their performance could decline sharply, thereby creating safety risks. We anticipate that work on uncertainty will be essential to controlling the risks associated with distributional shift [ 80]. • The butional fact robustness that CoDA and creates fairness. distributional Training shift on out-of-distribution can also provide benefits data can in make the form models of distri- more robust [79], increasing their trustworthiness and practical applicability. As noted in Section 5, counterfactual reasoning can be leveraged in areas where fairness is a concern. For example, [64] propose to reduce gender bias in natural language processing by generating counterfactual sentences with swapped gender pronouns. We anticipate that a version of CoDA that priori- tizes fairness concerns in a similar manner could be applied in the reinforcement learning and computer vision contexts. • In an reinforcement off-policy algorithm, learning or specifically, (2) high variance a shift in off-policy data distribution corrections requires for on-policy either (1) algorithms. the use of In the former case, it should be noted that in case of function approximation, even off-policy algorithms may be negatively affected by large shifts in their training distribution [83, 20]. More work is needed to quantify these effects and their implications for agent performance. Improving RL in batch-constrained settings In many settings, such as medicine and education, obtaining large quantities of observational data using a random policy is prohibitively expensive and/or unethical [84, 60]. As such, agents that can efficiently learn effective policies from batch- constrained data are needed, as are accurate ways to estimate agent performance from off-policy data [58, 62, 73]. We see CoDA as complementary to both goals, as subspace swapping is a powerful tool to produce large quantities of counterfactual data given a modest observational dataset. However, subspace swapping alone may be insufficient to generate plausible “exploratory” data for evaluating and learning new policies. For example, medical records from certain demographic groups may be unavailable or improperly collected/labeled. It is conceivable that a CoDA with a suitable prioritization scheme could compensate for such sample bias, but applied work in batch-constrained domains that characterizes the effect of sample bias on CoDA should nevertheless be carried out. General considerations related to artificial agency To the extent that CoDA is a general tech- nique for improving the ability of artificial agents to achieve their goals, it inherits the potential risks and benefits associated with empowered artificial agency, including but not limited to: (a) the pursuit of misguided or dangerous goals, whether due to mispecification by a benevolent principal, the self-serving motives of its principals, or interference by malicious parties or other deviations from proper intents, (b) the unsafe and improper pursuit of goals due to poor modeling or representation, resource constraints and lack of capacity, constraint mispecification, partial observability, or inadequate encoding and understanding of human values, and (c) improvements to capital processes and automation of human labor, which could improve economic efficiency and raise the overall social welfare, but also run the risk of increased inequality, workforce displacement, and technological unemployment. The risk associated with points (a) and (b) may be exacerbated in case of CoDA due to the risks associated with counterfactual reasoning outlined above: to the extent that CoDA is done with a poorly fit local factorization model, or with a local factorization model that does not generalize well to the counterfactual distribution, this could cause the agent to pursue poorly formulated counterfactual (imagined) goals, or create causally invalid data that hurts agent performance.",Broader Impact,657,22,,,TRUE,TRUE,FALSE,Counterfactual Data Augmentation using Locally Factored Dynamics,Reinforcement Learning and Planning,Algorithms -> Model Selection and Structure Learning; Algorithms -> Relational Learning; Probabilistic Methods -> Causal Inference,Reinforcement learning and planning,"['Silviu Pitis', ' Elliot Creager', ' Animesh Garg']",{'University of Toronto'},1,0,0,{'Canada'}
Rethinking Learnable Tree Filter for Generic Feature Transform,"Lin Song, Yanwei Li, Zhengkai Jiang, Zeming Li, Xiangyu Zhang, Hongbin Sun, Jian Sun, Nanning Zheng",Rethinking Learnable Tree Filter for Generic Feature Transform,2952351097998ac1240cb2ab7333a3d2,https://proceedings.neurips.cc/paper/2020/file/2952351097998ac1240cb2ab7333a3d2-Paper.pdf,"Context modeling is a powerful tool to improve the ability for feature representation, which has been widely applied in real-world scenarios, e.g. , computer vision and natural language processing. The traditional tree filter [ 31] already has great impacts on many low-level computer vision tasks, owing to its structure-preserving property and high efficiency. This paper further releases its representation potential by relaxing the geometric constraint. Specifically, our method provides a new perspective for context modeling by unifying the learnable tree filter with the Markov Random Field, which is further demonstrated to be effective in several vision tasks with negligible computational and parametric overheads. These properties of our method have great potentials, which allow our method and principle to extend to other complex tasks with large-number nodes, e.g. , replacing the attention module of transformer for natural language processing and enhancing sequential representation for video analysis.",Broader Impact,145,5,,,FALSE,TRUE,FALSE,Rethinking Learnable Tree Filter for Generic Feature Transform,Algorithms -> Representation Learning,Applications -> Computer Vision; Applications -> Image Segmentation,Vision,"['Lin Song', ' Yanwei Li', ' Zhengkai Jiang', ' Zeming Li', ' Xiangyu Zhang', ' Hongbin Sun', ' Jian Sun', ' Nanning Zheng']","{'The Chinese University of Hong Kong', 'MEGVII Technology'}",1,1,1,{'China'}
Self-Supervised Relational Reasoning for Representation Learning,"Massimiliano Patacchiola, Amos J. Storkey",Self-Supervised Relational Reasoning for Representation Learning,29539ed932d32f1c56324cded92c07c2,https://proceedings.neurips.cc/paper/2020/file/29539ed932d32f1c56324cded92c07c2-Paper.pdf,"The motivation behind this work is to build systems able to exploit a large amount of unlabeled data. Applications that could benefit from the proposed method span from standard supervised classifiers to medical diagnostic systems. Therefore, there is a large number of individuals who may benefit or be harmed from this research. This requires putting some effort into selecting the data source, especially when the system is scaled. In most cases a large body of unlabeled images can be easily gathered from the internet; to avoid biases those images should be representative of different categories. Our method does not guarantee unbiased predictions, therefore it should be used with caution in critical applications. Individuals who may want to use it should consider the particular source of data at hand and evaluate how it could impact the system performance after the final deployment.",Broader Impact,141,7,,,FALSE,FALSE,FALSE,Self-Supervised Relational Reasoning for Representation Learning,Algorithms -> Representation Learning,Algorithms -> Relational Learning; Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Massimiliano Patacchiola', ' Amos Storkey']",{'University of Edinburgh'},1,0,0,{'UK'}
Sufficient dimension reduction for classification using principal optimal transport direction,"Cheng Meng, Jun Yu, Jingyi Zhang, Ping Ma, Wenxuan Zhong",Sufficient dimension reduction for classification using principal optimal transport direction,29586cb449c90e249f1f09a0a4ee245a,https://proceedings.neurips.cc/paper/2020/file/29586cb449c90e249f1f09a0a4ee245a-Paper.pdf,"In this paper, we study the problem of sufficient dimension reduction for classification. We propose a novel method to estimate the SDR subspace using the principal directions of the empirical optimal transport plans. The proposed POTD method can consistently and exclusively estimate the SDR subspace for the data with a binary-response when the class labels contain no error, or the data enjoys the ""separation"" property. The proposed method could be naturally extended to the data with continuous response. In such cases, we can first form several classes according to the values of Y . In particular, let S 1 = { x i : Y i < c } and S 2 = { x i : Y i ≥ c } for some constant c . We then calculate the optimal transport plan between S 1 and S 2 , and repeat the process to obtain several plans. The displacement vectors based on these optimal transport plans are then pooled together to form the basis of the SDR subspace using the principal component analysis. A number of questions remain unanswered, such as (1) how does the error in the response affect the result; (2) how does use other distance metrics in optimal transport instead of the L 2 norm affect the result; (3) would the multimarginal optimal transport approach [46] be a more appealing way to generalize the proposed method from binary-response to multi-class response than the one-vs-one strategy; (4) when the optimal couplings are obtained from the Sinkhorn algorithm, how does the Sinkhorn regularization parameter impacts the final dimension reduction. Additional research is needed to answer these questions and to better understand the proposed method. Like many existing dimension reduction studies, POTD, by its nature, is a new methodology that aims to solve challenging high-dimensional problems. Hence, this work does not present any foreseeable societal consequence by itself. However, POTD has the potential to be applied to many high-dimensional data, e.g., imaging data, gene expression data, and so on. This work may speed up these researches and hence amplify the positive and negative impacts that exist in these scientific research fields.",Broader Impact,353,14,TRUE,TRUE,FALSE,FALSE,FALSE,Sufficient dimension reduction for classification using principal optimal transport direction,Algorithms -> Classification,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'University of Georgia', 'The University of Georgia', 'Beijing Institute of Technology'}",1,0,0,"{'USA', 'China'}"
Fast Epigraphical Projection-based Incremental Algorithms for Wasserstein Distributionally Robust Support Vector Machine,"Jiajin Li, Caihua Chen, Anthony Man-Cho So",Fast Epigraphical Projection-based Incremental Algorithms for Wasserstein Distributionally Robust Support Vector Machine,2974788b53f73e7950e8aa49f3a306db,https://proceedings.neurips.cc/paper/2020/file/2974788b53f73e7950e8aa49f3a306db-Paper.pdf,This work does not present any foreseeable societal consequence. A broader impact discussion is not applicable.,Broader Impact,16,2,TRUE,FALSE,TRUE,TRUE,FALSE,Fast Epigraphical Projection-based Incremental Algorithms for Wasserstein Distributionally Robust Support Vector Machine,Optimization,Algorithms -> Classification; Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Jiajin Li', ' Caihua Chen', 'Cho So']","{'The Chinese University of Hong Kong', 'Nanjing University', 'CUHK'}",1,0,0,{'China'}
Differentially Private Clustering: Tight Approximation Ratios,"Badih Ghazi, Ravi Kumar, Pasin Manurangsi",Differentially Private Clustering: Tight Approximation Ratios,299dc35e747eb77177d9cea10a802da2,https://proceedings.neurips.cc/paper/2020/file/299dc35e747eb77177d9cea10a802da2-Paper.pdf,"Our work lies in the active area of privacy and its broader impact should be interpreted in light of ongoing debates in academia and industry. The primary goal of our work is to develop efficient differentially private algorithms for clustering data, with quality approaching that of clustering al- gorithms that are indifferent to privacy. Being able to cluster data without compromising privacy but with quality almost as good as without privacy considerations, we believe, has a few societal benefits. Firstly, it could compel applications that deal with sensitive data and that already use off-the-shelf clustering algorithms to switch to using private clustering since the quality losses of our algorithm are guaranteed to be minimal and our algorithms are only modestly more expensive to run. Secondly, since clustering is a fundamen- tal primitive in machine learning and data analysis, our work can enable privacy in more intricate applications that depend on clustering. Thirdly, we believe our work can spur further research into making other private machine learning algorithms attain quality comparable to non-private ones. In other words, it can lead to the following state: preserving privacy does not entail a compromise in quality. This will have far-reaching effects on how researchers develop new methods. On the other hand, there are possible negative consequences of our work. Since our work has not been tested in practice, it is conceivable that practitioners might be dissuaded from using it on their own. Further, there might be unintended or malicious applications of private clustering, where privacy might be used in a negative way; our work might become a latent enablers of such activity. Overall we believe that protecting privacy is a net positive for the society and our work contribute towards this larger goal in a positive way.",Broader Impact,293,12,,,FALSE,FALSE,FALSE,Differentially Private Clustering: Tight Approximation Ratios,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Clustering,,"['Badih Ghazi', ' Ravi Kumar', ' Pasin Manurangsi']",{'Google'},0,1,0,{'USA'}
On the Power of Louvain in the Stochastic Block Model,"Vincent Cohen-Addad, Adrian Kosowski, Frederik Mallmann-Trenn, David Saulpic",On the Power of Louvain in the Stochastic Block Model,29a6aa8af3c942a277478a90aa4cae21,https://proceedings.neurips.cc/paper/2020/file/29a6aa8af3c942a277478a90aa4cae21-Paper.pdf,"We give the first theoretical explanation of Louvain’s success. We show that Louvain not only recovers the hidden partition in the stochastic block model successfully, but also does so in linear time and so for a large range of parameters. Interestingly, if Louvain is properly seeded it can recover the parameters nearly up to the information theoretic threshold. As explained in the introduction, the goal of this paper is to cast a new light on the success of a popular heuristic for clustering, namely L OUVAIN . With more than 10 000 citations, L OUVAIN is the method of choice for graph clustering. Thus, explaining its power and limitation is of primary importance for a large variety of research areas (see for instance Hoffman et al. [ 22], analyzing the Bible with L OUVAIN , or Wu et al. [33] for drug repositioning). Our work shows that for graphs exhibiting a clear but noisy clustering structure, then Louvain quickly converges to a global optimum (w.r.t. the modularity objective). Therefore, when the clusters maximizing modularity align with the ground-truth clusters, Louvain is indeed a powerful clustering algorithms with a reliable performance. Finally, our work also improves the theoretical analysis and provides tools for a wide-range of other algorithms including Kernighan-Lin, Majorty and other combinatorial algorithms that rely on moving nodes to communities to which they have the most number of edges. Concretely, we show that the probability √ for a node to have more edges towards its own community is 1 / 2 + Ω(min(∆( p − q ) / np, 1)) in the SBM( 2 n, p, q ), where ∆ is the imbalance. Note that this bound is asymptotically tight. In addition, we also develop strong combinatorial methods that despite dependent variables ( read − 2) allow us to analyze a vast amount of cuts. These insights are important for many combinatorial algorithms.",6 Broader Impact,314,16,,,FALSE,FALSE,FALSE,On the Power of Louvain in the Stochastic Block Model,Algorithms -> Clustering,Algorithms -> Stochastic Methods,Theory (including computational and statistical analyses),"['Addad', ' Adrian Kosowski', 'Trenn', ' David Saulpic']","{'Ecole normale supérieure', 'NavAlgo', 'CNRS & Sorbonne Université', ""King's College London""}",1,1,1,{'France'}
Fairness with Overlapping Groups; a Probabilistic Perspective,"Forest Yang, Mouhamadou Cisse, Oluwasanmi O. Koyejo",Fairness with Overlapping Groups,29c0605a3bab4229e46723f89cf59d83,https://proceedings.neurips.cc/paper/2020/file/29c0605a3bab4229e46723f89cf59d83-Paper.pdf,"This work has the following potential positive impact in the society: we hope that our work enables algorithmic fairness for intersectional groups, which most existing works ignore. At the same time, this work may have some negative consequences because it does not solve the problem of limited statistical power for severely under-represented minorities. This work also assumes that algorithmic fairness is appropriate, which may not always be the case. Furthermore, we should be cautious of the result of failure of the system when the assumed parametric definition for the fairness violation is unknown or not appropriate, yet generic metrics are used in its place.",Broader Impact,104,4,,,FALSE,FALSE,FALSE,Fairness with Overlapping Groups; a Probabilistic Perspective,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Classification; Algorithms -> Online Learning; Optimization; Probabilistic Methods; Theory -> Statistical Learning Theory,,"['Forest Yang', ' Mouhamadou M Cisse', ' Oluwasanmi Koyejo']","{'UC Berkeley', 'UIUC', 'KAUST'}",1,0,0,"{'USA', 'Saudi Arabia'}"
AttendLight: Universal Attention-Based Reinforcement Learning Model for Traffic Signal Control,"Afshin Oroojlooy, Mohammadreza Nazari, Davood Hajinezhad, Jorge Silva",AttendLight: Universal Attention-Based Reinforcement Learning Model for Traffic Signal Control,29e48b79ae6fc68e9b6480b677453586,https://proceedings.neurips.cc/paper/2020/file/29e48b79ae6fc68e9b6480b677453586-Paper.pdf,"In this paper, the authors propose AttendLight, a Deep Reinforcement Learning algorithm to control the traffic signals efficiently and autonomously. Utilizing AttendLight for controlling traffic signals brings several benefits to society. First, this algorithm is responsive to the dynamic behavior of traffic movement and provides a control policy to an intersection to minimize the travel time. This has several societal implications: • Less traffic: according to information gathered in [9] in 2015, drivers in the United States wasted 6.9 billion hours annually in traffic. With AttendLight people will spend less time in traffic jams. • Lower fuel consumption: it has been shown that about 3 billion gallons of gas wasted in 2014 due to traffic congestion [9]. AttendLight will help to reduce fuel consumption by easing traffic flows. • Cleaner environment: it is predicted that air pollution will cause around 2.5 million cases of non-communicable disease by 2035, should the air quality stay the same as in 2018 [21]. People will breathe higher quality air if we have smarter traffic signal controllers. Second, in contrast to previous RL models, AttendLight does not need to be trained for every new intersection. Thanks to the attention mechanism, indeed AttendLight is a universal model that can be simply deployed for any type of intersection after it is trained over a collection of distinct intersections. As long as the structure for the new intersection follows a similar distribution as the training set, AttendLight provides accurate results. This capability is the key advantage of this model because, designing a new model imposes several costs such as (i) human expertise, (ii) the required computational power, and (iii) data collection resources. Therefore, sparing experts from repetitive work as well as saving computational resources are other societal impacts of AttendLight. One limitation of AttendLight is that it may fail to come up with an efficient policy whenever the intersection topology is very complex and unusual, such that the training set does not involve a similar structure. We hope that such a limitation can be addressed by increasing the training set diversity and incorporating more complex policy models. Future researchers are encouraged to consider extending AttendLight to control multiple intersections in a coordinated manner. Given a network of intersections, traffic signals have significant impacts on each other. Thus, controlling every individual signal without considering this incorporation may exacerbate the whole traffic. Reaching the point that AttendLight could control a network of intersections while it respects the association effects, we expect to achieve too many other valuable societal impacts. However, the extension of AttendLight to the multi-intersection scenario is not quite straightforward. Specifically, one needs to consider several challenges such as scalability of the proposed model, and how to involve the coordination in decision-making procedure. See more details in [20]. Further motivation to pursue this research would be improving the RL algorithm used to train the AttendLight model. In the current research, we utilized a policy-gradient RL algorithm called REINFORCE. Despite the superior numerical results of AttendLight, there is definitely room for improvement. As a low-hanging fruit, other state-of-the-art policy-based RL algorithms such as Actor-Critic, A2C, and A3C can substitute REINFORCE in AttendLight.",Broader Impact,523,27,,,TRUE,TRUE,FALSE,AttendLight: Universal Attention-Based Reinforcement Learning Model for Traffic Signal Control,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Decision and Control,Reinforcement learning and planning,"['Afshin Oroojlooy', ' Mohammadreza Nazari', ' Davood Hajinezhad', ' Jorge Silva']","{'Lehigh University - SAS', 'SAS Institute', 'SAS'}",1,1,1,{'USA'}
Searching for Low-Bit Weights in Quantized Neural Networks,"Zhaohui Yang, Yunhe Wang, Kai Han, Chunjing XU, Chao Xu, Dacheng Tao, Chang Xu",Searching for Low-Bit Weights in Quantized Neural Networks,2a084e55c87b1ebcdaad1f62fdbbac8e,https://proceedings.neurips.cc/paper/2020/file/2a084e55c87b1ebcdaad1f62fdbbac8e-Paper.pdf,"Compared with full-precision networks, the quantized neural networks have the advantages of small model size, fast inference speed, low energy cost and efficient runtime memory occupation. The methods for training high-precision quantized neural networks help the deployment of computer vision models on mobile devices. Our proposed searching scheme provides a novel and feasible method for training high-precision quantized networks.",Broader Impact,59,3,FALSE,FALSE,FALSE,FALSE,FALSE,Searching for Low-Bit Weights in Quantized Neural Networks,Deep Learning,Algorithms -> Classification; Applications -> Computer Vision; Applications -> Object Recognition; Deep Learning -> CNN Architectures; Deep Learning -> Efficient Inference Methods,AutoML,"['zhaohui yang', ' Yunhe Wang', ' Kai Han', ' Chunjing XU', ' Chao Xu', ' Dacheng Tao', ' Chang Xu']","{'University of Sydney', 'peking university', 'Huawei Technologies', 'Peking University'}",1,1,1,"{'Australia', 'China'}"
Adaptive Reduced Rank Regression,"Qiong Wu, Felix MF Wong, Yanhua Li, Zhenming Liu, Varun Kanade",Adaptive Reduced Rank Regression,2a27b8144ac02f67687f76782a3b5d8f,https://proceedings.neurips.cc/paper/2020/file/2a27b8144ac02f67687f76782a3b5d8f-Paper.pdf,The main contribution of this work is theoretical. Productionizing downstream applications stated in the paper may need to take six months or more so there is no immediate societal impact from this project.,Broader Impact,33,2,TRUE,TRUE,FALSE,FALSE,FALSE,Adaptive Reduced Rank Regression,Theory -> Computational Learning Theory,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Qiong Wu', ' Felix MF Wong', ' Yanhua Li', ' Zhenming Liu', ' Varun Kanade']","{'Google', 'William and Mary', 'University of Oxford', 'College of William and Mary'}",1,1,1,"{'UK', 'USA'}"
From Predictions to Decisions: Using Lookahead Regularization,"Nir Rosenfeld, Anna Hilgard, Sai Srivatsa Ravindranath, David C. Parkes",From Predictions to Decisions: Using L kahead Regularization,2adcfc3929e7c03fac3100d3ad51da26,https://proceedings.neurips.cc/paper/2020/file/2adcfc3929e7c03fac3100d3ad51da26-Paper.pdf,"In our work, the learning objective was designed to align with and support the possible use of a predictive model to drive decisions by users. It is our belief that a responsible and transparent deployment of models with “lookahead-like"" regularization components should avoid the kinds of mistakes that can be made when predictive methods are conflated with causally valid methods. At the same time, we have made a strong simplifying assumption, that of covariate shift, which requires that the relationship between covariates and outcome variables is invariant as decisions are made and the feature distribution changes. This strong assumption is made to ensure validity for the lookahead regularization, since we need to be able to perform inference about counterfactual observations. As discussed by Mueller et al. [ 31] and Peters et al. [34], there exist real-world tasks that reasonably satisfy this assumption, and yet at the same time, other tasks— notably those with unobserved confounders —where this assumption would be violated. Moreover, this assumption is not testable on the observational data. This, along with the need to make an assumption about the user decision model, means that an application of the method proposed here should be done with care and will require some domain knowledge to understand whether or not the assumptions are plausible. Furthermore, the validity of the interval estimates requires that any assumptions for the interval model used are satisfied and that weights w provide a reasonable estimation of p /p . In particular, fitting to p which has little to no overlap with p (see Figure 2) may result in underestimating the possibility of bad outcomes. If used carefully and successfully, then the system provides safety and protects against the misuse of a model. If used in a domain for which the assumptions fail to hold then the framework could make things worse, by trading accuracy for an incorrect view of user decisions and the effect of these decisions on outcomes. We would also caution against any specific interpretation of the application of the model to the wine and diabetes data sets. We note that model misspecification of f ∗ could result in arbitrarily bad outcomes, and estimating f ∗ in any high-stakes setting requires substantial domain knowledge and should err on the side of caution. We use the data sets for purely illustrative purposes because we believe the results are representative of the kinds of results that are available when the method is correctly applied to a domain of interest.",Broader Impact,414,16,,,FALSE,FALSE,FALSE,From Predictions to Decisions: Using Lookahead Regularization,Social Aspects of Machine Learning,,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Nir Rosenfeld', ' Anna Hilgard', ' Sai Srivatsa Ravindranath', ' David Parkes']",{'Harvard University'},1,0,0,{'USA'}
Sequential Bayesian Experimental Design with Variable Cost Structure,"Sue Zheng, David Hayden, Jason Pacheco, John W. Fisher III",Sequential Bayesian Experimental Design with Variable Cost Structure,2adee8815dd939548ee6b2772524b6f2,https://proceedings.neurips.cc/paper/2020/file/2adee8815dd939548ee6b2772524b6f2-Paper.pdf,"Despite its promise and longstanding research focus, BOED has seen limited practical utility due to the difficulties associated with evaluating information measures. Nevertheless, practical algorithms for effective information retrieval, which reason about uncertainty in a Bayesian context, have widespread value. This work posits that by accounting for identifiable cost structure, and the judicious allocation of resources, one can integrate Bayesian reasoning to experimental design in a practical way. Our approach utilizes readily available bounds and places minimal assumptions on model complexity. Having emphasized the positive aspects of this work, we acknowledge limitations of the approach. In particular, we assume that a cost structure is known or otherwise easily estimated. In practice we find that empirical estimates of costs are easily obtained, but acknowledge that this may not be true for all cases. Despite any limitations, our approach is broadly applicable and we therefore expect this work to have significant impact on the practical application of BOED in a wide range of settings.",Broader Impacts,162,8,,,FALSE,FALSE,FALSE,Sequential Bayesian Experimental Design with Variable Cost Structure,Probabilistic Methods -> MCMC,Probabilistic Methods,Probabilistic methods and inference,"['Sue Zheng', ' David Hayden', ' Jason Pacheco', ' John W Fisher III']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Predictive inference is free with the jackknife+-after-bootstrap,"Byol Kim, Chen Xu, Rina Foygel Barber",Predictive Inference Is Free with the Jackknife+-after-Bootstrap,2b346a0aa375a07f5a90a344a61416c4,https://proceedings.neurips.cc/paper/2020/file/2b346a0aa375a07f5a90a344a61416c4-Paper.pdf,"Machine learning algorithms are becoming increasingly pervasive in many application areas involving complicated and high-stakes decision making including medical treatment planning and diagnosis, public health, and public policy. As the use of machine learning becomes more widespread, however, we are also becoming more cognizant of the potential pitfalls due to hidden biases in the data or unexpected behavior of blackbox algorithms. Quantifying the uncertainty in machine predictions is one way to safeguard against such errors. Doing so in a meaningful way without making unverifiable or overly simplistic assumptions is a challenge, as data in these applications often exhibit complex phenomena, such as censoring or missingness, heavy tails, multi-modality, etc.. Methods such as our J+aB provide predictive inference guarantees that can be efficiently implemented on large scale data sets under very few assumptions.",7 Broader impact,132,4,,,FALSE,FALSE,FALSE,Predictive inference is free with the jackknife+-after-bootstrap,Algorithms -> Uncertainty Estimation,Algorithms -> Boosting and Ensemble Methods; Theory -> Frequentist Statistics,Probabilistic methods and inference,"['Byol Kim', ' Chen Xu', ' Rina Foygel Barber']",{'University of Chicago'},1,0,0,{'USA'}
Counterfactual Predictions under Runtime Confounding,"Amanda Coston, Edward Kennedy, Alexandra Chouldechova",Counterfactual Predictions under Runtime Confounding,2b64c2f19d868305aa8bbc2d72902cc5,https://proceedings.neurips.cc/paper/2020/file/2b64c2f19d868305aa8bbc2d72902cc5-Paper.pdf,"Real-world adoption of our proposed methodology may have a number of ethical and societal consequences. Our method is well-suited to decision support settings, including high-stakes decisions such as public assistance, parole and bail decisions in criminal justice, and treatment prioritization in healthcare. Our proposed method has the potential to improve decision-making in settings with runtime confounding where, as demonstrated in this paper, standard methods produce biased results. Beyond the statistical bias of simply failing to target the right counterfactual quantity, if decisions are made based on such predictions, it may disadvantage certain demographic groups in cases such as where group membership is a confounding factor in observed decisions [10]. This is a significant concern because group membership is often an impermissible input to decision-support tools at runtime, while also being a factor that influences discriminatory decision-making in observed data. Using our methods in these settings can improve predictions and the decisions they ultimately inform. However, our proposed approach is valid only in the setting where our assumed Conditions 2.1 hold, and is not offered as a panacea for generally confounded data. The assumption that training data is unconfounded (§ 2.1.1) deserves considerable scrutiny any time the methods are applied. This assumption cannot be verified empirically and must instead be evaluated by domain experts who have detailed knowledge of the historical decision-making process. We encourage practitioners to carefully consider the validity of this assumption for their setting. Further data collection may be required to ensure that the data available for training does contain all factors that may have been relevant to historical decision-making, even if it is not information that is desirable or permissible to be used at runtime. To illustrate the potential benefits as well as possible misuses of our method, we consider how our method could inform parole decisions. Parole boards determine whether and under what conditions to release a person from incarceration. Recidivism risk assessment models are widely adopted by probation and parole departments around the US. It is often of interest to assess the likelihood of success under different possible supervision conditions. Runtime confounding occurs in the setting when, for instance, the parole board makes a recommendation after reviewing documents and hearing spoken testimony, but the board would like to see the predictions of a risk and needs assessment tool prior to the hearing. The testimony may provide information that both influences the board’s decision and reveals drivers of the offender’s likelihood to succeed if released, but this information is unavailable at prediction time, leading to runtime confounding. Moreover, we may be concerned that parole boards implicitly used race to make decisions and would like to account for this without requiring the use of race as a model input. Our method would allow us to do so. Our method can handle some of the challenging aspects of this setting, but there may be other problems that are not addressed by our method. For instance, while our method can help account for racial bias in historical parole decisions, it cannot correct for racial bias in the downstream outcomes. Since research suggests that people of color are disproportionately arrested relative to true crime rates [1], one should be wary of using these outcomes. Predictive models trained on such outcomes could perpetuate or exacerbate racial disparities in criminal justice. Additionally, if Conditions 2.1 do not hold because e.g. the spoken testimony is not accurately recorded, then our method may lead to unreliable predictions. The appropriate use of our method in high-stakes real-world settings would include careful consider- ation of the validity of Conditions 2.1 as well as other potential biases in the data used for model training. If deployed in the appropriate setting, our method has the potential to help decision-makers make better decisions that can improve efficiency and fairness.",Broader Impact,630,26,,,FALSE,FALSE,FALSE,Counterfactual Predictions under Runtime Confounding,Probabilistic Methods -> Causal Inference,Algorithms -> Classification; Algorithms -> Regression,,"['Amanda Coston', ' Edward Kennedy', ' Alexandra Chouldechova']","{'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Learning Loss for Test-Time Augmentation,"Ildoo Kim, Younghoon Kim, Sungwoong  Kim",Learning Loss for Test-Time Augmentation,2ba596643cbbbc20318224181fa46b28,https://proceedings.neurips.cc/paper/2020/file/2ba596643cbbbc20318224181fa46b28-Paper.pdf,"Regardless of the state of the given data, using it as an input of the neural network with the same pre-processing can be ineffective in terms of performance and stability. We propose a novel instance- aware test-time augmentation. If a deep learning model is in the deployment stage, it can be expected to increase stability and performance through the proposed method. However, it is still necessary to verify the stability and generalization of the proposed method because it is in an early stage of research for instance-aware test-time augmentation. At this time, the performance of deep learning models may be degraded in unexpected situations, although we haven’t described specific conditions.",Broader Impact,110,5,,,FALSE,FALSE,FALSE,Learning Loss for Test-Time Augmentation,Algorithms -> Boosting and Ensemble Methods,Algorithms -> Classification; Algorithms -> Uncertainty Estimation; Applications -> Computer Vision; Deep Learning; Deep Learning -> Efficient Inference Methods,Deep learning,"['Ildoo Kim', ' Younghoon Kim', ' Sungwoong Kim']",{'Kakao Brain'},0,1,0,{'South Korea'}
Balanced Meta-Softmax for Long-Tailed Visual Recognition,"Ren Jiawei, Cunjun Yu, shunan sheng, Xiao Ma, Haiyu Zhao, Shuai Yi, hongsheng Li",Balanced Meta-Softmax for Long-Tailed Visual Recognition,2ba61cc3a8f44143e1f2f13b2b729ab3,https://proceedings.neurips.cc/paper/2020/file/2ba61cc3a8f44143e1f2f13b2b729ab3-Paper.pdf,"Due to the Zipfian distribution of categories in real life, algorithms, and models with exceptional performance on research benchmarks may not remain powerful in the real world. BALMS, as a light-weight method, only adds minimal computational cost during training and is compatible with most of the existing works for visual recognition. As a result, BALMS could be beneficial to bridge the gap between research benchmarks and industrial applications for visual recognition. However, there can be some potential negative effects. As BALMS empowers deep classifiers with stronger recognition capability on long-tailed distribution, the application of such a classification algorithm can be further extended to more real-life scenarios. We should be cautious about the misuse of the method proposed. Depending on the scenario, it might cause negative effects on democratic privacy.",Broader Impact,129,7,,,FALSE,FALSE,FALSE,Balanced Meta-Softmax for Long-Tailed Visual Recognition,Deep Learning -> Efficient Training Methods,Algorithms -> Meta-Learning; Applications -> Computer Vision,Vision,"['Ren Jiawei', ' Cunjun Yu', ' shunan sheng', ' Xiao Ma', ' Haiyu Zhao', ' Shuai Yi', ' hongsheng Li']","{'SenseTime Group Limited', 'Sensetime', 'cuhk', 'National University of Singapore', 'NUS', 'SenseTime International Pte Ltd'}",1,1,1,"{'Hong Kong', 'Singapore', 'China'}"
Efficient Exploration of Reward Functions in Inverse Reinforcement Learning via Bayesian Optimization,"Sreejith Balakrishnan, Quoc Phong Nguyen, Bryan Kian Hsiang Low, Harold Soh",Efficient Exploration of Reward Functions in Inverse Reinforcement Learning via Bayesian Optimization,2bba9f4124283edd644799e0cecd45ca,https://proceedings.neurips.cc/paper/2020/file/2bba9f4124283edd644799e0cecd45ca-Paper.pdf,"It is important that our autonomous agents operate with the correct objectives to ensure that they exihibit appropriate and trustworthy behavior (ethically, legally, etc.) [19]. This issue is gaining broader significance as autonomous agents are increasingly deployed in real-world settings, e.g., in the form of autonomous vehicles, intelligent assistants for medical diagnosis, and automated traders. However, specifying objectives is difficult, and as this paper motivates, reward function learning via demonstration likelihood optimization may also lead to inappropriate behavior. For example, our experiments with the Fetch-Reach environment shows that apparently “good” solutions in terms of NLL correspond to poor policies. BO-IRL takes one step towards addressing this issue by providing an efficient algorithm for returning more information about potential reward functions in the form of discovered samples and the GP posterior. This approach can help users further iterate to arrive at appropriate reward function, e.g., to avoid policies that cause expected or undesirable behavior. As with other learning methods, there is a risk for misuse. This work does not consider constraints that limit the reward functions that can be learned. As such, users may teach the robots to perform unethical or illegal actions; consider the recent incident where users taught the Microsoft’s chatbot Tay to spout racist and anti-social tweets. With robots that are capable of physical actions, consequences may be more severe, e.g., bad actors may teach the robot to cause both psychological and physical harm. A more subtle problem is that harmful policies may result unintentionally from misuse of BO-IRL, e.g., when the assumptions of the method do not hold. These issues point to potential future work on verification or techniques to enforce constraints in BO-IRL and other IRL algorithms.",Broader Impact,281,13,,,FALSE,FALSE,FALSE,Efficient Exploration of Reward Functions in Inverse Reinforcement Learning via Bayesian Optimization,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Active Learning,Reinforcement learning and planning,"['Sreejith Balakrishnan', ' Quoc Phong Nguyen', ' Bryan Kian Hsiang Low', ' Harold Soh']","{'National University Singapore', 'National University of Singapore'}",1,0,0,{'Singapore'}
MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning,"Elise van der Pol, Daniel Worrall, Herke van Hoof, Frans Oliehoek, Max Welling",MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning,2be5f9c2e3620eb73c2972d7552b6cb5,https://proceedings.neurips.cc/paper/2020/file/2be5f9c2e3620eb73c2972d7552b6cb5-Paper.pdf,"The goal of this paper is to make (deep) reinforcement learning techniques more efficient at solving Markov decision processes (MDPs) by making use of prior knowledge about symmetries. We do not expect the particular algorithm we develop to lead to immediate societal risks. However, Markov decision processes are very general, and can e.g. be used to model problems in autonomous driving, smart grids, and scheduling. Thus, solving such problems more efficiently can in the long run cause positive or negative societal impact. For example, making transportation or power grids more efficient, thereby making better use of scarce resources, would be a significantly positive impact. Other potential applications, such as in autonomous weapons, pose a societal risk [28]. Like many AI technologies, when used in automation, our technology can have a positive impact (increased productivity) and a negative impact (decreased demand) on labor markets. More immediately, control strategies learned using RL techniques are hard to verify and validate. Without proper precaution (e.g. [40]), employing such control strategies on physical systems thus run the risk of causing accidents involving people, e.g. due to reward misspecification, unsafe exploration, or distributional shift [2].",8 Broader Impact,189,9,,,FALSE,FALSE,FALSE,MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Representation Learning; Deep Learning -> CNN Architectures,Reinforcement learning and planning,"['Elise van der Pol', ' Daniel Worrall', ' Herke van Hoof', ' Frans Oliehoek', ' Max Welling']","{'University of Amsterdam', 'University of Amsterdam / Qualcomm AI Research', 'TU Delft'}",1,1,1,"{'USA', 'Netherlands'}"
How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods,"Jeya Vikranth Jeyakumar, Joseph Noor, Yu-Hsi Cheng, Luis Garcia, Mani Srivastava",How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods,2c29d89cc56cdb191c60db2f0bae796b,https://proceedings.neurips.cc/paper/2020/file/2c29d89cc56cdb191c60db2f0bae796b-Paper.pdf,"We would like to begin by praising the community for it’s recent shift of attention to the study and design of high-quality model explanations, particularly when attempting to provide insight into inferences that cannot be easily interpreted. This essential direction of research indicates that scientists and technologists care about making complex methods more accessible and understandable. Encouraging a world where the advanced computational techniques used to influence modern society are generally understandable empowers us all to steer its direction with clearer vision toward a more desirable state. At the very least, we can be more prepared to avoid negative outcomes. Fear of the Unknown. As deep neural networks have brought performance improvements that were seemingly unimaginable, the general public remains largely ignorant of what makes these approaches so powerful; to them, it’s equivalent to magic. This is popularly conveyed in sensational headlines and the fictional portrayals of dystopian futures, laying somewhere at the intersection of Black Mirror , Orwell’s 1984 , and Terminator ’s Skynet. Nevertheless, these fears underlay legitimate concerns that motivate privacy preserving regulations including GDPR and CCPA, not to mention the inclusion of the NeurIPS Broader Impact Statement. The continuing efforts to research effective methods of ensuring explainability of these models can help partially alleviate this tension, particular if we succeed in providing an honest (yet comprehensible) representation of the underlying method. This is the motivation for our work. Positive Impact. The stated objective and ideal impact of this paper is relatively straightforward; we intend to empower the community with knowledge of the average end-user perspective. In this way, we might all have a better understanding of the right approach to increase transparency and effectively communicate with the public, thereby offering a bridge between the technologist and non-technical layperson.  Unintended Risks. One of our research conclusions is that exposing subsets of the underlying training data is an effective means of justifying complex model predictions. This poses inherent privacy risks. A necessary complement to explanation-by-example are techniques to anonymize and sanitize personally identifiable information from the revealed training data. Thankfully, the active body of literature surrounding differential privacy offers techniques that can be employed when needed to ensure these privacy violations do not occur. It is critical that the noble effort to explain complex models do not unintentionally harm the individuals potentially comprising the training data. One possible side-effect of this paper is that researchers may be discouraged from advancing explainability if faced with a published relative ranking. On the very contrary, we instead hope it inspires novel solutions and brings increased attention to the importance of this problem. This paper is by no means meant to provide closure, but instead serve as a stepping stone detailing the current landscape for community reflection and reevaluation. Moving Forward. The only way that we can ensure that our community does not bring harm to the public is through transparency and honesty. Of course, this is impossible without an effective means of mutual communication — one that can be understood by all. This paper is an attempt to elucidate the methods and styles of presentation that offer this universal language by which we can create a more informed society.",Broader Impact,528,26,,,FALSE,FALSE,FALSE,How Can I Explain This to You? An Empirical Study of Deep Neural Network Explanation Methods,Deep Learning,"Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,"['Jeya Vikranth Jeyakumar', ' Joseph Noor', 'Hsi Cheng', ' Luis Garcia', ' Mani Srivastava']","{'UCLA', 'University of California, Los Angeles'}",1,1,1,{'USA'}
On the Error Resistance of Hinge-Loss Minimization,Kunal Talwar,On the Error Resistance of Hinge Loss Minimization,2c5201a7391fedbc40c3cc6aa057a029,https://proceedings.neurips.cc/paper/2020/file/2c5201a7391fedbc40c3cc6aa057a029-Paper.pdf,"This work explains the robustness of a commonly used learning algorithm to errors in the training data, and is a step in the broader research direction of making machine learning robust to outliers. Over the longer term, this research direction will allow training on larger noisier data sets that may be available to some entities, a consequence it shares with a large majority of research in machine learning. This may carry some risks such as increasing inequities in access to useful training data and challenges in inspecting these datasets for bugs and biases. Nevertheless, given the evidence of more data being helpful along many different axes, and machine learning being useful at large, we believe research in this area is a net positive.",Broader Impact Statement,123,4,,,FALSE,FALSE,FALSE,On the Error Resistance of Hinge-Loss Minimization,Theory -> Computational Learning Theory,Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),['Kunal Talwar'],{'Google'},0,1,0,{'USA'}
Munchausen Reinforcement Learning,"Nino Vieillard, Olivier Pietquin, Matthieu Geist",Munchausen Reinforcement Learning,2c6a0bae0f071cbbf0bb3d5b11d90a82,https://proceedings.neurips.cc/paper/2020/file/2c6a0bae0f071cbbf0bb3d5b11d90a82-Paper.pdf,"The core contribution of this work is to propose a new RL algorithm, that surpasses state of the art results on a challenging discrete actions environment. We believe it can impact positively the RL community, as it shades light on fundamental ideas, justified by deep theoretical foundations, that proves to be efficient in practice. Outside of the RL community, the impact of this paper is part of the global impact of RL. This work is mainly algorithmic and theoretical, with no specific applications in mind, but participates to the general development of efficient and practical RL methods.",Broader impact,97,4,,,FALSE,FALSE,FALSE,Munchausen Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Nino Vieillard', ' Olivier Pietquin', ' Matthieu Geist']","{'Google Brain', 'Google Research Brain Team'}",0,1,0,{'USA'}
Object Goal Navigation using Goal-Oriented Semantic Exploration,"Devendra Singh Chaplot, Dhiraj Prakashchand Gandhi, Abhinav Gupta, Russ R. Salakhutdinov",Object Goal Navigation using Goal-Oriented Semantic Exploration,2c75cf2681788adaca63aa95ae028b22,https://proceedings.neurips.cc/paper/2020/file/2c75cf2681788adaca63aa95ae028b22-Paper.pdf,"As discussed in the paper, this work has the potential to enable robots to better exploit the structure in the real world we live in to do better object goal navigation. This will be a quintessential criterion when mobile robots with manipulators will be ubiquitous helping elders or those with disabilities with their day to day life chores. There could be privacy concerns as these robots work on the visual feed taken in everyday settings. However, we may be able to bypass the issue if we anonymize the data. In addition to that we have also shown policy learned only in simulation has potential to get transferred to the real world. If this trained policy works reliably in diverse settings then we might not even have to record any data.",7 Broader Impact Statement,130,6,,,FALSE,FALSE,FALSE,Object Goal Navigation using Goal-Oriented Semantic Exploration,Reinforcement Learning and Planning -> Navigation,Reinforcement Learning and Planning; Reinforcement Learning and Planning -> Exploration,Reinforcement learning and planning,"['Devendra Singh Chaplot', ' Dhiraj Prakashchand Gandhi', ' Abhinav Gupta', ' Russ Salakhutdinov']","{'Facebook AI Research/CMU', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Efficient semidefinite-programming-based inference for binary and multi-class MRFs,"Chirag Pabbaraju, Po-Wei Wang, J. Zico Kolter",Efficient semidefinite-programming-based inference for binary and multi-class MRFs,2cb274e6ce940f47beb8011d8ecb1462,https://proceedings.neurips.cc/paper/2020/file/2cb274e6ce940f47beb8011d8ecb1462-Paper.pdf,"Probabilistic inference has been used in a number of domains including, e.g. the image segmentation domains highlighted in our final experimental results section. However, the methods have also been applied extensively to biological applications, such as a protein side chain prediction or protein design [36]. Such applications all have the ability to be directly affected by upstream algorithmic improvements to approximate inference methods. This also, however, applies to potentially question- able applications of machine learning, such as those used by automated surveillance systems. While it may be difficult to assess the precise impact of this work in such domains (especially since the vast majority of deployed systems are based upon deep learning methods rather than probabilistic inference at this point), these are applications that should be considered in the further development of probabilistic approaches. From a more algorithmic perspective, many applications of approximate inference in recent years have become dominated by end-to-end deep learning approaches, forgoing application of probabilistic inference altogether. One potential advantage of our approach, which we have not explored in this current work, is that because it is based upon a continuous relaxation, the probabilistic inference method we present here can itself be made differentiable, and used within an end-to-end pipeline. This has potentially potentially positive effects (it could help in the interpretability of deep networks, for example), but also negative effects, such as the possibility that the inference procedure itself actually becomes less intuitively understandable if it’s trained solely in an end-to-end fashion. We hope that both these perspectives, as well as potential enabled applications, are considered in the possible extension of this work to these settings.",Broader Impact,271,9,,,FALSE,FALSE,FALSE,Efficient semidefinite-programming-based inference for binary and multi-class MRFs,Probabilistic Methods -> Graphical Models,Optimization -> Convex Optimization; Optimization -> Discrete Optimization; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Chirag Pabbaraju', 'Wei Wang', ' Zico Kolter']","{'CMU', 'Microsoft Research', 'Carnegie Mellon University / Bosch Center for AI'}",1,1,1,"{'USA', 'Germany'}"
Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing,"Zihang Dai, Guokun Lai, Yiming Yang, Quoc Le",Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing,2cd2915e69546904e4e5d4a2ac9e1652,https://proceedings.neurips.cc/paper/2020/file/2cd2915e69546904e4e5d4a2ac9e1652-Paper.pdf,"Fundamentally, this work proposed a more efficient architecture from a different dimension of model design. We believe this architecture as well as the code and checkpoints to be released can most benefit the field of language processing, with the potential to benefit other fields involving sequence modeling. However, scientifically, the key idea of compressing the sequence resolution in Funnel- Transformer will not always be a good prior for all problems. In addition, as a common problem for neural models, adversarial examples or attacks could alter the behavior and performance of the proposed model dramatically, as well as outlier examples. Therefore, the model should always be applied with caution in practice.",Broader Impact,110,5,,,FALSE,FALSE,FALSE,Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing,Deep Learning,Applications -> Natural Language Processing,Natural language processing,"['Zihang Dai', ' Guokun Lai', ' Yiming Yang', ' Quoc V Le']","{'Google', 'CMU', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Semantic Visual Navigation by Watching YouTube Videos,"Matthew Chang, Arjun Gupta, Saurabh Gupta",Semantic Visual Navigation by Watching YouTube Videos,2cd4e8a2ce081c3d7c32c3cde4312ef7,https://proceedings.neurips.cc/paper/2020/file/2cd4e8a2ce081c3d7c32c3cde4312ef7-Paper.pdf,"Our specific research in this paper lowers barriers for the training of navigation policies. Instead of needing fully instrumented environments, or large-scale 3D scans, we can now train using video tours of indoor spaces. This significantly expands the environments that such methods can be trained on. Existing datasets [9, 68] used for training current systems have a bias towards expensive houses. This is because sensors and services involved in constructing such scans are expensive. While our current YouTube Walks dataset also has some of this bias, a video tour can be collected merely by using a phone with a camera. This will allow training of navigation policies that will work well in more typical environments, and will democratize the use of learning-based policies for navigation. We also acknowledge that the use of publicly available data from the Internet (in our case YouTube videos) raises questions about privacy and consent. These issues require a broader discussion. Our broader research aims to improve policies for navigation in unstructured environments. This by itself has numerous desirable applications (such as automated delivery, search and monitoring in hazardous environments, automated crop inspection and mechanical weeding via under-canopy robots). Such applications can save lives, prevent food shortage (by preventing herbicide resistance), and enable development of other automation technologies. While there are a number of critical applications that our research can potentially enable, we acknowledge that our research falls under automation, and as with all other research in this area, in the future it could replace jobs currently performed by humans. However, this must be viewed in context of the critical applications described above. Resolving or even fully understanding this trade-off will need a much broader discussion.",Broader Impact,280,15,,,TRUE,TRUE,FALSE,Semantic Visual Navigation by Watching YouTube Videos,Reinforcement Learning and Planning -> Navigation,Applications -> Computer Vision; Applications -> Robotics; Applications -> Video Analysis; Applications -> Visual Scene Analysis and Interpretation,"Other applications (e.g., robotics, biology, climate, finance)","['Matthew Chang', ' Arjun Gupta', ' Saurabh Gupta']","{'University of Illinois at Urbana-Champaign', 'UIUC'}",1,0,0,{'USA'}
"Heavy-tailed Representations, Text Polarity Classification & Data Augmentation","Hamid Jalalzai, Pierre Colombo, Chloé Clavel, Eric Gaussier, Giovanna Varni, Emmanuel Vignon, Anne Sabourin","Heavy-tailed Representations, Text Polarity Classification & Data Augmentation",2cfa3753d6a524711acb5fce38eeca1a,https://proceedings.neurips.cc/paper/2020/file/2cfa3753d6a524711acb5fce38eeca1a-Paper.pdf,"In this work, we propose a method resulting in heavy-tailed text embeddings. As we make no assumption on the nature of the input data, the suggested method is not limited to textual data and can be extended to any type of modality ( e.g. audio, video, images). A classifier, trained on aforementioned embedding is dilation invariant (see Equation 1) on the extreme region. A dilation invariant classifier enables better generalization for new samples falling out of the training envelop. For critical application ranging from web content filtering ( e.g. spam [27], hate speech detection [18], fake news [43]) to medical case reports to court decisions it is crucial to build classifiers with lower generalization error. The scale invariance property can also be exploited to automatically augment a small dataset on its extreme region. For application where data collection requires a huge effort both in time and cost ( e.g. industrial factory design, classification for rare language [4]), beyond industrial aspect, active learning problems involving heavy-tailed data may highly benefit from our data augmentation approach.",6 Broader Impact,174,7,,,FALSE,FALSE,FALSE,"Heavy-tailed Representations, Text Polarity Classification & Data Augmentation",Algorithms -> Representation Learning,Applications -> Natural Language Processing,Natural language processing,"['Hamid JALALZAI', ' Pierre Colombo', ' Chloé Clavel', ' Eric Gaussier', ' Giovanna Varni', ' Emmanuel Vignon', ' Anne Sabourin']","{'LTCI, Telecom ParisTech, Université Paris-Saclay', 'Telecom ParisTec', 'Télécom ParisTech', 'Telecom-ParisTech, Paris, France', 'Université Joseph Fourier, Grenoble', 'Telecom ParisTech', 'IBM'}",1,1,1,"{'France', 'USA'}"
SuperLoss: A Generic Loss for Robust Curriculum Learning,"Thibault Castells, Philippe Weinzaepfel, Jerome Revaud",SuperLoss: A Generic Loss for Robust Curriculum Learning,2cfa8f9e50e0f510ede9d12338a5f564,https://proceedings.neurips.cc/paper/2020/file/2cfa8f9e50e0f510ede9d12338a5f564-Paper.pdf,"Our approach can be used on top of any loss, and thus applied to various tasks: it basically applies the principles of automatic curriculum learning to any learning problem. The main benefit is that it allows to train models that will perform better, especially in the case where training data are corrupted by noise. Note that this point might actually be considered as extremely positive given the enormous annotation efforts necessary to build very large-scale datasets and previously thought as unavoidable to reach high performance. Having to annotate a large-scale dataset might be a real barrier for new players to enter into the business for an existing task or for developing new services, because of both the financial aspects and the time it would take. Besides, the annotation effort is most of the time accomplished in poor working conditions. It is often not even considered as a salaried job, thus preventing from social advantages of real jobs including a minimal decent salary. For these reasons and thanks to the simple and generic nature of our approach, we believe in its wide adoption and usage by both research and industrial communities. Concerning the downsides, we first generally note that our main benefit, training a better model, is also applicable to tasks that may have a negative impact on the society. We also note that our SuperLoss generally has trouble to significantly outperform a baseline approach when training from a clean dataset of comparable size. For applications that require very high precision ( e.g., for medical diagnosis), manual annotations would still be more than recommended, and even needed, compared to adopting our solution for noise-resistant training.",Broader Impact,274,10,,,FALSE,FALSE,FALSE,SuperLoss: A Generic Loss for Robust Curriculum Learning,Deep Learning -> Supervised Deep Networks,Applications -> Computer Vision,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Thibault Castells', ' Philippe Weinzaepfel', ' Jerome Revaud']","{'Naver Labs Europe', 'Naver Labs', 'NAVER LABS Europe'}",0,1,0,{'South Korea'}
CogMol: Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models,"Vijil Chenthamarakshan, Payel Das, Samuel Hoffman, Hendrik Strobelt, Inkit Padhi, Kar Wai Lim, Ben Hoover, Matteo Manica, Jannis Born, Teodoro Laino, Aleksandra Mojsilovic",CogMol: Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models,2d16ad1968844a4300e9a490588ff9f8,https://proceedings.neurips.cc/paper/2020/file/2d16ad1968844a4300e9a490588ff9f8-Paper.pdf,"We discuss the broader impact of our work from the following perspectives. Benefits To date, SARS-CoV-2 has infected millions and killed hundreds of thousands around the globe and continues to cause a severe economical crisis [54]. are still undergoing investigation [55]. Therefore, it is timely to explore for efficient de novo drug design approaches to combat COVID-19 and future pandemics. The CogMol framework is adapative, generic, and could pave the road for accelerated discovery of new antivirals optimized against specific SARS-CoV-2 (or other novel virus) targets. This could have a major impact on our global effort against COVID-19 and future novel pandemics and save human lives. We demonstrated that our framework can generate target-specific and selective compounds for unseen protein targets, a novel property that may be key for swift reactions to possible SARS-CoV-2 mutants. We further provide early assessment of novel AI-generated compounds on target structure binding, and synthetic feasibility and toxicity in the context of FDA-approved drugs, in order to identify a list of promising compounds that is of reasonable size and can be immediately sent to wet lab for synthesis and validation. We showed the efficiency of the framework in terms of handling multiple constraints at once and can be easily extended to adding more controls to account for additional factors considered crucial in drug discovery such as ADME properties. Thus, our approach systematically bridges biology and machine learning to accelerate drug discovery. We further share with the community a list of CogMol-generated compounds (and their attributes) designed for three novel SARS-Cov-2 targets, as well as a molecular explorer tool to visualize, experience, and provide feedback on these molecules. This sets our vision for an open community of discovery that facilitates interactions between AI researchers and medicinal scientists. Risks and the Potential to Cause Harm While our approach offers enormous potential to speed up the development of new drugs, it must be realized that drug candidate generation and in silico screening are merely first steps in the development of viable therapeutics. No wetlab evaluation of the generated molecules have been done. The ability of the public to order these novel compounds online, poses a risk that it might be tried by people who are not sufficiently educated about the dangers of exposing themselves to these molecules in an uncontrolled setting. The public must be educated to not to treat these candidates as approved drugs or miracle cures. Further, since our framework allows generation of molecules satisfying arbitrary objectives, this capability can be misused by bad actors to design potentially harmful chemicals. Consequences of Failure It is possible that our framework will not be able to generate molecules with desired properties either because of bias in training data or because of the inaccuracy of the predictors used for controlled generation. Also, there could be a divergence between the machine learning predicted properties and wet lab experimental evaluations. One way to address this problem is to cross check these properties using multiple independent machine learning or other models.",7 Statement of Broader Impact,499,20,,,FALSE,FALSE,FALSE,CogMol: Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models,Applications -> Computational Biology and Bioinformatics,Deep Learning -> Generative Models,,"['Enara Chenthamarakshan Vijil', ' Payel Das', ' Samuel Hoffman', ' Hendrik Strobelt', ' Inkit Padhi', ' Kar Wai Lim', ' Ben Hoover', ' Matteo Manica', ' Jannis Born', ' Teodoro Laino', ' Aleksandra Mojsilovic']","{'IBM Research Zürich', 'IBM Singapore', 'IBM Research Zurich', 'IBM Research', 'IBM'}",0,1,0,{'USA'}
Memory Based Trajectory-conditioned Policies for Learning from Sparse Rewards,"Yijie Guo, Jongwook Choi, Marcin Moczulski, Shengyu Feng, Samy Bengio, Mohammad Norouzi, Honglak Lee",Memory Based Trajectory-conditioned Policies for Learning from Sparse Rewards,2df45244f09369e16ea3f9117ca45157,https://proceedings.neurips.cc/paper/2020/file/2df45244f09369e16ea3f9117ca45157-Paper.pdf,"DTSIL is likely to be useful in real-world RL applications, such as robotics-related tasks. Compared with previous exploration methods, DTSIL shows obvious advantages when the task requires rea- soning over long-horizon and the feedback from environment is sparse. We believe RL researchers and practitioners can benefit from DTSIL to solve RL application problems requiring efficient explo- ration. Especially, DTSIL helps avoid the cost of collecting human demonstration and the manual engineering burden of designing complicated reward functions. Also, as we discussed in Sec. 5, when deployed for more problems in the future, DTSIL has a good potential to perform robustly and avoid local optima in various stochastic environments when combined with other state representation learning approaches. DTSIL in its current form is applied to robotics tasks in the simulated environments. And it likely contributes to real robots in solving hard-exploration tasks in the future. Advanced techniques in robotics make it possible to eliminate repetitive, time-consuming, or dangerous tasks for human workers and might bring positive societal impacts. For example, the advancement in household robots will help reduce the cost for home care and benefit people with disability or older adults who needs personalized care for a long time. However, it might cause negative consequences such as large-scale job disruptions at the same time. Thus, proper public policy is required to reduce the social friction. On the other hand, RL method without much reward shaping runs the risk of taking a step that is harmful for the environments. This generic issue faced by most RL methods is also applicable to DTSIL. To mitigate this issue, given any specific domain, one simple solution is to apply a constraint on the state space that we are interested to reach during exploration. DTSIL is complementary to the mechanisms to restrict the state space or action space. More principled way to ensure safety during exploration is a future work. In addition to AI safety, another common concern for most RL algorithms is the memory and computational cost. In the supplementary material we discuss how to control the size of the memory for DTSIL and report the cost. Empirically DTSIL provides ideas for solving various hard-exploration tasks with a reasonable computation cost.",Broader Impact,366,20,,,FALSE,FALSE,FALSE,Memory Based Trajectory-conditioned Policies for Learning from Sparse Rewards,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Exploration,Reinforcement learning and planning,"['Yijie Guo', ' Jongwook Choi', ' Marcin Moczulski', ' Shengyu Feng', ' Samy Bengio', ' Mohammad Norouzi', ' Honglak Lee']","{'Google Brain', 'University of Illinois Urbana Champaign', 'University of Michigan', 'Google Research, Brain Team'}",1,1,1,{'USA'}
Liberty or Depth: Deep Bayesian Neural Nets Do Not Need Complex Weight Posterior Approximations,"Sebastian Farquhar, Lewis Smith, Yarin Gal",Liberty or Depth: Deep Bayesian Neural Nets Do Not Need Complex Weight Posterior Approximations,2dfe1946b3003933b7f8ddd71f24dbb1,https://proceedings.neurips.cc/paper/2020/file/2dfe1946b3003933b7f8ddd71f24dbb1-Paper.pdf,"Our work addresses a growing need for scalable neural network systems that are able to express sensible uncertainty. Sensible uncertainty is essential in systems that make important decisions in production settings. Despite that, the most performant production systems often rely on large deterministic deep learning models. Historically, uncertainty methods have often prioritized smaller settings where more theoretically rigorous methods could be applied. Our work demonstrates the theoretical applicability of cheap uncertainty approximation methods that do not attempt to model complex correlations between weight distributions in those large-scale settings. This resolves something the field has assumed is a tension between good uncertainty and powerful models—we  show that some modes of the variational weight posterior might be closer to mean-field in bigger models. So using a bigger model causes more restrictive approximation methods to become more accurate. In principle, this could allow Bayesian neural networks with robust uncertainty to be deployed in a wide range of settings. If we are right, this would be a very good thing. The main downside risk of our research is that if we are wrong, and people deploy these systems and incorrectly rely on their uncertainty measures, then this could result in accidents caused by overconfidence. We therefore recommend being extremely cautious in how a business or administrative decision process depends on any uncertainty measures in critical settings, as is already good practice for non-uncertainty-aware decisions and in non-neural network uncertain machine learning systems.",Broader Impact,238,11,,,FALSE,FALSE,FALSE,Liberty or Depth: Deep Bayesian Neural Nets Do Not Need Complex Weight Posterior Approximations,Probabilistic Methods -> Variational Inference,,Probabilistic methods and inference,"['Sebastian Farquhar', ' Lewis Smith', ' Yarin Gal']",{'University of Oxford'},1,0,0,{'UK'}
Improving Sample Complexity Bounds for (Natural) Actor-Critic Algorithms,"Tengyu Xu, Zhe Wang, Yingbin Liang",Improving Sample Complexity Bounds for (Natural) Actor-Critic Algorithms,2e1b24a664f5e9c18f407b2f9c73e821,https://proceedings.neurips.cc/paper/2020/file/2e1b24a664f5e9c18f407b2f9c73e821-Paper.pdf,"Policy optimization algorithms lie at the core of reinforcement learning, which has accomplished significant success in advancing technologies such as robotics, self-driving, online advertisement, etc. Among vast policy optimization algorithms, the actor-critic (AC) type of algorithms are broadly used and have achieved superior empirical performance. The focus of this paper is on exploring more sample-efficient AC-type algorithms and theoretically characterizing the advantage of the proposed schemes. We anticipate that these new innovations can be applied to other RL algorithms for performance improvement, such as Greedy-Q, nonlinear GTD [26], and off-policy AC algorithms [27, 56]. Ultimately, we hope that our sample saving ideas and techniques can be transferred into the real-world reinforcement learning technologies.",Broader Impact,113,5,,,FALSE,FALSE,FALSE,Improving Sample Complexity Bounds for (Natural) Actor-Critic Algorithms,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement Learning and Planning -> Decision and Control,Reinforcement learning and planning,"['Tengyu Xu', ' Zhe Wang', ' Yingbin Liang']","{'The Ohio State University', 'Ohio State University'}",1,0,0,{'USA'}
Learning Differential Equations that are Easy to Solve,"Jacob Kelly, Jesse Bettencourt, Matthew J. Johnson, David K. Duvenaud",Learning differential equations that are easy to solve,2e255d2d6bf9bb33030246d31f1a79ca,https://proceedings.neurips.cc/paper/2020/file/2e255d2d6bf9bb33030246d31f1a79ca-Paper.pdf,"We expect the main impact from this work, if any, would be through a potential improvement of the fundamental modeling tools of regression, classification, time series models, and density estimation. Thus the impact of this work is not distinct from that of improved machine learning tools in general. While machine learning tools present both benefits and unintended consequences, we avoid speculating further.",Broader Impact,62,3,,,FALSE,FALSE,FALSE,Learning Differential Equations that are Easy to Solve,Algorithms -> Dynamical Systems,Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jacob Kelly', ' Jesse Bettencourt', ' Matthew Johnson', ' David Duvenaud']","{'University of Toronto', 'Google Brain'}",1,1,1,"{'Canada', 'USA'}"
Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses,"Raef Bassily, Vitaly Feldman, Cristóbal Guzmán, Kunal Talwar",Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses,2e2c4bf7ceaa4712a72dd5ee136dc9a8,https://proceedings.neurips.cc/paper/2020/file/2e2c4bf7ceaa4712a72dd5ee136dc9a8-Paper.pdf,"Our work is theoretical in nature. There are no immediate ethical or societal consequences for the research presented here. We hope our results can offer theoretical insights that lead to a deeper understanding of a basic algorithm of central importance to modern machine learning. Our results can also have a direct impact on the design and analysis of differentially-private stochastic gradient methods, which are widely used for private data analysis.",Broader Impact,70,4,,,FALSE,FALSE,FALSE,Stability of Stochastic Gradient Descent on Nonsmooth Convex Losses,Optimization -> Convex Optimization,"Optimization -> Stochastic Optimization; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security; Theory -> Models of Learning and Generalization",Theory (including computational and statistical analyses),"['Raef Bassily', ' Vitaly Feldman', ' Cristobal Guzman', ' Kunal Talwar']","{'Google Brain', 'The Ohio State University', 'Google', 'PUC-Chile'}",1,1,1,"{'Chile', 'USA'}"
Influence-Augmented Online Planning for Complex Environments,"Jinke He, Miguel Suau de Castro, Frans Oliehoek",Influence-Augmented Online Planning for Complex Environments,2e6d9c6052e99fcdfa61d9b9da273ca2,https://proceedings.neurips.cc/paper/2020/file/2e6d9c6052e99fcdfa61d9b9da273ca2-Paper.pdf,"The potential impact of this work is precisely its motivation: making online planning more useful in real-world decision making scenarios, enabling more daily decisions to be made autonomously and intelligently, with promising applications including autonomous warehouse and traffic light control. Unlike simulators constructed by domain experts, which are in general easier to test and debug, influence-augmented local simulator contains an approximate influence predictor learned from data, which may fail with rare inputs and result in catastrophic consequences especially when controlling critical systems. This suggests that extensive testing and regulation will be required before deploying influence-augmented local simulators in real-world decision making scenarios.",Broader Impact,102,3,,,FALSE,FALSE,FALSE,Influence-Augmented Online Planning for Complex Environments,Reinforcement Learning and Planning -> Planning,,Reinforcement learning and planning,"['Jinke He', ' Miguel Suau', ' Frans Oliehoek']","{'Delft University of Technology', 'TU Delft'}",1,0,0,{'Netherlands'}
PAC-Bayes Learning Bounds for Sample-Dependent Priors,"Pranjal Awasthi, Satyen Kale, Stefani Karp, Mehryar Mohri",PAC-Bayes Learning Bounds for Sample-Dependent Priors,2e85d72295b67c5b649290dfbf019285,https://proceedings.neurips.cc/paper/2020/file/2e85d72295b67c5b649290dfbf019285-Paper.pdf,"Due to the theoretical nature of this paper, we currently cannot foresee any short-to-medium-term negative societal impact. In general, we believe that the short -term societal impact is extremely limited. However, we hope that, in the medium-to-long term, such bounds - or other theoretical work that follows from such bounds - will play a role in furthering our understanding of the differences in generalization performance among various algorithms. We believe that such understanding is very important when deploying models in real-world settings and when attempting to design new algorithms that generalize even better. PAC-Bayes bounds, in particular, have shown some promise in explaining the generalization performance of neural networks, which are widely used in practice. Thus, beyond a general claim about various machine learning algorithms, we think it is possible that our bounds or those inspired by them can contribute to the community’s understanding of (and expectations for) neural networks. Due to the widespread use of neural networks, such improved understanding can have a significant positive impact.",Broader Impact,167,7,,,FALSE,FALSE,FALSE,PAC-Bayes Learning Bounds for Sample-Dependent Priors,Theory -> Models of Learning and Generalization,Probabilistic Methods -> Bayesian Theory,Theory (including computational and statistical analyses),"['Pranjal Awasthi', ' Satyen Kale', ' Stefani Karp', ' Mehryar Mohri']","{'Google', 'Rutgers University/Google', 'Google/CMU'}",1,1,1,{'USA'}
Reward-rational (implicit) choice: A unifying formalism for reward learning,"Hong Jun Jeon, Smitha Milli, Anca Dragan",Reward-rational (implicit) choice: A unifying formalism for reward learning,2f10c1578a0706e06b6d7db6f0b4a6af,https://proceedings.neurips.cc/paper/2020/file/2f10c1578a0706e06b6d7db6f0b4a6af-Paper.pdf,"As AI capability advances, it is becoming increasingly important to align the objectives of AI agents to what people want. From how assistive robots can best help their users, to how autonomous cars should trade off between safety risk and efficiency, to how recommender systems should balance revenue considerations with longer-term user happiness and with avoiding influencing user views, agents cannot rely on a reward function specified once and set in stone. By putting different sources of information about the reward explicitly under the same framework, we hope our paper contributes towards a future in which agents maintain uncertainty over what their reward should be, and use different types of feedback from humans to refine their estimate and become better aligned with what people want over time – be them designers or end-users. On the flip side, changing reward functions also raises its own set of risks and challenges. First, the relationship between designer objectives and end-user objectives is not clear. Our framework can be used to adapt agents to end-users preferences, but this takes away control from the system designers. This might be desirable for, say, home robots, but not for safety-critical systems like autonomous cars, where designers might need to enforce certain constraints a-priori on the reward adaptation process. More broadly, most systems have multiple stake-holders, and what it means to do ethical preference aggregation remains an open problem. Further, if the robot’s model of the human is misspecified, adaptation might lead to more harm than good, with the robot inferring a worse reward function than what a designer could specify by hand.",Broader Impact,265,9,,,FALSE,FALSE,FALSE,Reward-rational (implicit) choice: A unifying formalism for reward learning,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Ranking and Preference Learning,,"['Hong Jun Jeon', ' Smitha Milli', ' Anca Dragan']","{'UC Berkeley', 'Stanford University'}",1,0,0,{'USA'}
Probabilistic Time Series Forecasting with Shape and Temporal Diversity,"Vincent LE GUEN, Nicolas THOME",Probabilistic Time Series Forecasting with Structured Shape and Temporal Diversity,2f2b265625d76a6704b08093c652fd79,https://proceedings.neurips.cc/paper/2020/file/2f2b265625d76a6704b08093c652fd79-Paper.pdf,"Probabilistic time series forecasting, especially in the non-stationary contexts, is a paramount research problem with immediate and large impacts in the society. A wide range of sensitive applications heavily rely on accurate forecasts of uncertain events with potentially sharp variations for making crucial decisions: in weather and climate science, better anticipating floods, hurricanes, earthquakes or other extreme events evolution could help taking emergency measures on time and save lives; in medicine, better predictions of an outbreak’s evolution is a particularly actual topic. We believe that introducing meaningful criteria such as shape and time, which are more related to application-specific evaluation metrics, is an important step toward more reliable and interpretable forecasts for decision makers.",Broader Impact,114,3,,,FALSE,FALSE,FALSE,Probabilistic Time Series Forecasting with Shape and Temporal Diversity,Applications -> Time Series Analysis,Deep Learning -> Predictive Models,Deep learning,"['Vincent LE GUEN', ' Nicolas THOME', 'Cnam']","{'Conservatoire national des arts et métiers', 'CNAM, Paris, France'}",1,0,0,{'France'}
Low Distortion Block-Resampling with Spatially Stochastic Networks,"Sarah Hong, Martin Arjovsky, Darryl Barnhart, Ian Thompson",Low Distortion Block-Resampling with Spatially Stochastic Networks,2f380b99d45812a211da102c04dc1ddb,https://proceedings.neurips.cc/paper/2020/file/2f380b99d45812a211da102c04dc1ddb-Paper.pdf,"The main goal of this paper is to give the user of a generative model finer control of its samples. This can have positive outcomes in the use case of creative applications of GANs, such as design, art, and gaming. Particularly, when the user is not the developer of the technology (for instance, it can be a player in a game who wishes to create a new level), we aim for him or her to be able create without being hindered by technical requirements. Currently, developers and artists need expensive skills, experience, and separate tools to produce content. This has a negative downstream impact on the diversity of content that is ultimately produced. Representation is not equal, as content skews towards representing those who can afford to become developers. We believe creativity is evenly distributed across location, race, and gender. Techniques like SSNs that make content creation more accessible can help bridge this gap in representation. Furthermore, any technique that is based on learning from data is subject to the biases in the training distribution. We believe resampling approaches like SSNs can help to visualize and understand these biases. As any technology that promises to give easier access, it has the potential for misuse. One could imagine cases where generative models are used to create things that may be harmful to society, and this can lower the technical entry barrier to misusers of this technology. For instance, SSNs could be applied towards harmful DeepFakes. We thus believe that it’s our duty as researchers to participate in the discussion of regulating these technologies so that they can be guided towards positive outcomes.",7 Broader Impact,271,14,,,FALSE,FALSE,FALSE,Low Distortion Block-Resampling with Spatially Stochastic Networks,Applications -> Computer Vision,Algorithms -> Adversarial Learning; Deep Learning -> Generative Models,Deep learning,"['Martin Arjovsky', ' Darryl Barnhart', ' Ian Thompson', ' Sarah Hong']","{'New York University', 'Latent Space'}",1,1,1,{'USA'}
Continual Deep Learning by Functional Regularisation of Memorable Past,"Pingbo Pan, Siddharth Swaroop, Alexander Immer, Runa Eschenhagen, Richard Turner, Mohammad Emtiyaz E. Khan",Continual Deep Learning by Functional Regularisation of Memorable Past,2f3bbb9730639e9ea48f309d9a79ff01,https://proceedings.neurips.cc/paper/2020/file/2f3bbb9730639e9ea48f309d9a79ff01-Paper.pdf,"The focus of this paper is on continual deep learning which is related to the field of life-long learning . Designing such algorithms is a bottleneck for deep learning which heavily relies on the offline setting where all the data is available at once. Life-long learning methods, such as ours, will extend the application of deep learning to problems where data is limited and needs to be collected slowly over time. This could bring a positive change in fields such as robotics, medicine, healthcare, and climate science. A shortcoming currently is the lack of theoretical guarantees, which is essential to ensure a positive change. Life-long learning methods, such as ours, should not be applied to mission-critical problems, until such guarantees are available. One could imagine negative outcomes too, e.g., if life-long learning methods are perfected, machines could then learn in a sequential fashion, similar to living beings and humans. It is possible that their learning will catch up with ours, which will have a huge affect on the society and economy. We do not see this happening any time soon, and in the short term we see a net positive effect on the society. It is important to perform research to understand effects on society in case life-long learning methods are successful.",Broader Impact,212,10,,,FALSE,FALSE,FALSE,Continual Deep Learning by Functional Regularisation of Memorable Past,Algorithms -> Continual Learning,Probabilistic Methods -> Variational Inference,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Pingbo Pan', ' Siddharth Swaroop', ' Alexander Immer', ' Runa Eschenhagen', ' Richard E Turner', ' Mohammad Emtiyaz Khan']","{'RIKEN, Tokyo', 'University of Osnabrueck', 'University of Cambridge', 'University of Technology Sydney', 'EPFL'}",1,0,0,"{'Japan', 'UK', 'Switzerland', 'Australia'}"
Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning,"Pan Li, Yanbang Wang, Hongwei Wang, Jure Leskovec",Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning,2f73168bf3656f697507752ec592c437,https://proceedings.neurips.cc/paper/2020/file/2f73168bf3656f697507752ec592c437-Paper.pdf,"This work proposes a novel angle to systematically improve the structural representation power of GNNs. We break from the convention that previous works characterize and further improve the power of GNNs by intimating different-order WL tests [26, 27, 30, 58]. As far as we know, we are the first one to provide non-asymptotic analysis of the power of the proposed GNN models. Therefore, the proof techniques of Theorems 3.3,3.7 may be expected to inspire new theoretical studies of GNNs and further better the practical usage of GNNs. Moreover, our models have good scalability by avoiding using the framework of WL tests, as higher-order WL tests are not able to leverage the sparsity of graphs. To be evaluated over extremely large graphs [59], our models can be simply trimmed and work on the ego-networks sampled with a limited size around the target node sets, just as the strategy adopted by GraphSAGE [21] and GraphSAINT [60]. Therefore, our work may motivate practitioners to design and deploy more powerful GNNs in industrial pipelines to benefit the society. Distance encoding unifies the techniques of many GNN models [9, 17, 31, 32, 47] and provides a extremely general framework with clear theoretical characterization. In this paper, we only evaluate four specific instantiations over three levels of tasks. However, there are some other interesting instantiations and applications. For example, we expect a better usage of PageRank scores as edge attributes (Eq. (4)). Currently, our instantiation DEAGNN-PR simply uses those scores as weights in a weighted sum to aggregate node representations. We also have not considered any attention-based mechanism over DEs in aggregation while it seems to be useful [17, 22]. Researchers may try these directions in a more principled manner based on this work. Our approaches may also help other tasks based on structural representation learning, such as graph-level classification/regression [14, 16, 23, 26, 27] and subgraph counting [58], which correspond to many applications with wide societal impact including drug discovery and structured data analysis. There are also two important implications coming from the observations of this work. First, Theorem 3.7 and Corollary 3.8 show the limitation of DE-1 over distance regular graphs, including the cases when DE-1’s are used as node attributes or controllers of message aggregation. As distance regular graphs with the same intersection array have the important co-spectral property [35], we guess that DE-1 is a bridge to connect GNN frameworks to spectral approaches, two fundamental approaches in graph-structured data processing. This point sheds some light on the question left in [30] while more rigorous characterization is still needed. Second, as observed in the experiments, higher-order DE’s induce larger gains as opposed to WLGNN, while Theorem 3.3 is not able to characterize this observation as the probability 1 − o ( 1 ) does not depend on the size p . We are sure n that the probabilistic quantization in Theorem 3.3 is not tight, so it is interesting to see how such probability depends on p by deriving tighter bounds. We are not aware of any societal disadvantages of this research. Our experiments also do not leverage biases in the data. We choose those datasets based on two rules that are irrelavant to ethics: (1) The labels for evaluation are graph-structured related; (2) Those datasets were used in some baselines so that we provide fair comparison. Regarding the point (1), this is the reason that we do not use the datasets, such as Cora, Citeseer and Pubmed [56], whose node labels that indicate the community belongings of nodes instead of the structural function of nodes. However, it is interesting to evaluate distance encoding techniques over those datasets with community-related labels in the future.",Broader Impact,611,27,,,FALSE,FALSE,FALSE,Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning,Algorithms -> Representation Learning,Algorithms -> Relational Learning; Applications -> Network Analysis,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'Stanford University', 'Stanford University - Purdue University', 'Stanford University and Pinterest'}",1,0,0,{'USA'}
Fast Fourier Convolution,"Lu Chi, Borui Jiang, Yadong Mu",Fast Fourier Convolution,2fd5d41ec6cfab47e32164d5624269b1,https://proceedings.neurips.cc/paper/2020/file/2fd5d41ec6cfab47e32164d5624269b1-Paper.pdf,"Modern neural networks have evolved for decades, from the primary LeNet to recent Resnet, DenseNet etc. The deployment of neural network based models has greatly spurred the development of more industrial products, particularly for visual data oriented. Nonetheless, as our proposed FFC shows, a few key concepts in the architectural design of neural networks (such as receptive field) are still inadequately explored. This work presents a general technique FFC, with successful demonstrations in several crucial computer vision tasks, including image classification, video action recognition and human keypoint detection. A large body of context-sensitive computing tasks may benefit from FFC, as it can bring and fuse multi-scale neural receptive fields in a unified convolutional unit and thus help to capture richer contextual information. Moreover, for deep learning research community, FFC may inspire more rethinking of neural network from a spectral aspect and lead to the development of more network backbones with boosted efficacy and accuracy. We believe that FFC has significant positive impact to both industry (particularly computer vision and natural language processing) and academia.",6 Broader Impact,174,7,,,FALSE,FALSE,FALSE,Fast Fourier Convolution,Deep Learning -> CNN Architectures,Applications -> Computer Vision; Applications -> Video Analysis,Vision,"['Lu Chi', ' Borui Jiang', ' Yadong Mu']",{'Peking University'},1,0,0,{'China'}
Unsupervised Learning of Dense Visual Representations,"Pedro O. O. Pinheiro, Amjad Almahairi, Ryan Benmalek, Florian Golemo, Aaron C. Courville",Unsupervised Learning of Dense Visual Representations,3000311ca56a1cb93397bc676c0b7fff,https://proceedings.neurips.cc/paper/2020/file/3000311ca56a1cb93397bc676c0b7fff-Paper.pdf,"Our research falls under the category of advancing machine learning techniques for computer vision and scene understanding. We focus on improving image representations for dense prediction tasks, which subsumes a large array of fundamental vision tasks, such as image segmentation and object detection. While there are potentially many implications for using these applications, here we discuss two aspects. First, we highlight some social implications for image understanding with no or very little labeled data. Second, we provide some insights on foundational research questions regarding the evaluation of general purpose representation learning methods. Improving capabilities of image understanding using unlabeled data, especially for pixel-level tasks, opens up a wide range of applications that are beneficial to the society, and which cannot be tackled otherwise. Medical imagery applications suffers from lack of labeled data due to the need of very specialized labelers. Another application, tackling harmful online content—including but not limited to terrorist propaganda, hateful speech, fake news and misinformation—is a huge challenge for governments and businesses. What makes these problems especially difficult is that it is very difficult to obtain clean labeled data for training machine learning models—think of filming a terrorist attack on live video as in the unfortunate Christchurch attack. Self-supervised learning can potentially move the needle in advancing models for detecting extremely rare yet highly impactful incidents. On the other hand, such technologies can be potentially misused for violating privacy and freedom of expression. We acknowledge these risks as being a feature of any amoral technology, and we invite governments, policy makers and all citizens—including the research community—to work hard on striking a balance between those benefits and risks. Another interesting aspect of our research is highlighting the importance of aligning representation learning methods with the nature of downstream applications. With our method, we show that learning pixel-level representations from unlabeled data we can outperform image-level methods on a variety of dense prediction tasks. Our findings highlight that the research community should go beyond limited test-beds for evaluating generic representation learning techniques. We invite further research on developing comprehensive evaluation protocols for such methods. In fact, we see many research opportunities in the computer vision domain, such as developing a sweep of standardized benchmarks across a variety of geometric and semantic image understanding tasks, and designing methods that can bridge the gap between offline and online performance.",6 Broader Impact,389,17,,,FALSE,FALSE,FALSE,Unsupervised Learning of Dense Visual Representations,Algorithms -> Representation Learning,Algorithms -> Unsupervised Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","[' Pinheiro', ' Amjad Almahairi', ' Ryan Benmalek', ' Florian Golemo', ' Aaron Courville']","{'MILA / ElementAI', 'Element AI', 'Cornell University'}",1,1,1,"{'Canada', 'USA'}"
Higher-Order Certification For Randomized Smoothing,"Jeet Mohapatra, Ching-Yun Ko, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, Luca Daniel",Higher-Order Certification for Randomized Smoothing,300891a62162b960cf02ce3827bb363c,https://proceedings.neurips.cc/paper/2020/file/300891a62162b960cf02ce3827bb363c-Paper.pdf,"In recent years, machine learning and intelligent systems have started to be widely adopted into everyday life, including several safety-critical applications. The wide-spread use of these systems requires them to be held to a higher level of scrutiny. One such requirement is “robustness”, i.e., the systems’ prediction should not be too sensitive to small input perturbations. In general, unde- fended/vanilla deep learning models have been found to be extremely sensitive to small imperceptible perturbations. This in turn has given rise to many defense techniques, able to overcome “existing” threats to robustness. However most of these models have later proved to be ineffective against newer threats. In turn, this has then given rise to a class of techniques which provide some mathematical guarantees about the robustness of their predictions. In this paper, we extended one such framework that provides some mathematically provable guarantees against any “single individual” threat model chosen from a large class of threat models. Specifically, we provided a way to construct models with some mathematically provable guarantees against “multiple simultaneous” threat models. The benefits of this contribution include providing a more holistic picture of the robustness guarantees for deployed models. This can hopefully bring us a step closer to trustworthy AI. Since this work helps building models that give some guarantees on their behavior, we hope it would also lead to the wider adoption of deep learning models. Moreover, we hope that the guarantees given by these models would allow people to have some improved sense of security when using deep-learning-based products. Considering intensive applications such as product matching, categorization in assembly lines or video surveillance that require long periods of hard effort, robust models will give more reliable and efficient means of achieving the task and considerably reducing the burden on humans. As for the potentially negative effects of this contribution, we feel that any progress towards robustness certification could easily become a double-edged sword. This is because, if adopted blindly (i.e. specifically without extremely careful attention to the types of guarantees provided and most impor- tantly those NOT provided), it may give also the false sense of security that current deep-learning systems are already ready for deployment. These robustness concerns are one of the major bottlenecks for the adoption of deep-learning models in safety-critical applications such as self-driving car and air traffic control systems. hence the ability to provide “some” robustness guarantees might result in wide premature adoption of deep learning models in such applications. We would like to candidly admit to developer and user readers of this paper that the presence of some robustness guarantees for a model does not mean we understand the model or that it is completely safe to deploy it. To the contrary the authors of this paper believe that we are still quite far from such safe adoption scenario. Further issues lie also beyond robustness. A negative effect of this publication and publication like this on robustness, is might give the highly incorrect impression that with robustness one can feel safe in deploying AI systems in society. On the contrary we would also like to candidly admit and remind the readers that deep-learning-based models suffer from problems such as lack of accuracy guarantees for out-of-distribution data , lack of fairness, lack of explain-ability and many others that MUST to be solved before AI systems are viable for real-world applications. More specifically about the lack of accuracy guarantees for out-of-distribution data: the robustness of a model does not necessarily mean its prediction is always accurate. Robustness and accuracy are indeed two disjoint concepts. While it is well-known that an accurate prediction might not be robust, it is also essential to keep in mind that a robust prediction need not always be accurate. In other words, some models may generate a prediction that is indeed highly robust (i.e. does not change upon perturbation) but consistently incorrect! As a result, in applications such as air traffic control systems, the models might display extremely bad behaviour because of situations not present in its training, while the presence of some robustness guarantees might give a false sense of security to an inexperience user (e.g. not familiar with the admittedly subtle mathematical intricacies of different threat models), that these systems are completely fault-tolerant. In conclusion, we would like to remark that although this paper helps to take a step towards building more trustworthy AI, that goal is indeed still quite far-off.",Broader Impact,735,29,,,FALSE,TRUE,FALSE,Higher-Order Certification For Randomized Smoothing,Algorithms -> Adversarial Learning,Algorithms -> Classification; Applications -> Computer Vision; Deep Learning -> Adversarial Networks,Adversarial ML and Certification,"['Jeet Mohapatra', 'Yun Ko', 'Wei Weng', 'Yu Chen', ' Sijia Liu', ' Luca Daniel']","{'Massachusetts Institute of Technology', 'MIT', 'IBM Research AI', 'MIT-IBM Watson AI Lab, IBM Research AI'}",1,1,1,{'USA'}
Learning Structured Distributions From Untrusted Batches: Faster and Simpler,"Sitan Chen, Jerry Li, Ankur Moitra",Learning Structured Distributions From Untrusted Batches: Faster and Simpler,305ddad049f65a2c241dbb6e6f746c54,https://proceedings.neurips.cc/paper/2020/file/305ddad049f65a2c241dbb6e6f746c54-Paper.pdf,"The goal for this work is to lay theoretical foundations for some basic problems in federated learning. As such, it may be of general societal benefit because it may lead to better systems for pooling data that cannot be manipulated by small groups with ulterior motives. Our algorithms do not leverage biases in data, but on the contrary seek to efficiently identify them and mitigate their effect. The main negative is that even algorithms with provable guarantees can be used outside of settings they are intended, in which case they can have unpredictable behavior. However our theoretical analysis also provides guidance on when using our algorithms ought to be appropriate.",Broader Impact,110,5,,,FALSE,FALSE,FALSE,Learning Structured Distributions From Untrusted Batches: Faster and Simpler,Theory -> Computational Learning Theory,Algorithms; Algorithms -> Adversarial Learning; Algorithms -> Density Estimation; Theory,Theory (including computational and statistical analyses),"['Sitan Chen', ' Jerry Li', ' Ankur Moitra']","{'MIT', 'Microsoft'}",1,1,1,{'USA'}
Hierarchical Quantized Autoencoders,"Will Williams, Sam Ringer, Tom Ash, David MacLeod, Jamie Dougherty, John Hughes",Hierarchical Quantized Autoencoders,309fee4e541e51de2e41f21bebb342aa,https://proceedings.neurips.cc/paper/2020/file/309fee4e541e51de2e41f21bebb342aa-Paper.pdf,"It is estimated that streaming of digital media accounts for 70% of today’s internet traffic [19], and this is reflected by the increasing importance of high quality compact representations in the big visual data era [23]. Our research takes steps towards addressing this issue by providing a scalable architecture for semantically meaningful compression, at rates unachievable by traditional algorithms. As well as the economic advantages of low-rate compression, there is the benefit of reduced energy and resources required for transmission and storage of smaller data, although this must be traded off against the currently higher computational cost of encoding/decoding. Like most image based research, HQA has broader implications related to computer vision applications and the ethics surrounding them. As these are detailed by Lauronen [16] we instead choose to focus more directly on the potential consequences of our cited objective: to produce realistic and semantically consistent compressed images at low bitrates. Whilst we observe empirically that the hierarchy of concepts retained by the HQA model can relate to a human idea of semantic importance, we do not control for this explicitly, which could have negative repercussions. For example, in the case of human imagery it is possible for decoded characteristics related to ethnicity or gender to be misrepresentative of the original, a scenario which may be exacerbated by a biased training set. In a more general sense, it is possible that mission critical details could be removed or modified, and whilst this is symptomatic of all low bitrate lossy compressions schemes, the realism of the output could lead to an misguided interpretation which would traditionally be offset by the appearance of artifacts or a lower resolution output. An interesting future research direction could be to alleviate this issue by conditioning the model on semantic labels as demonstrated by Agustsson et al. [2]. Further to this, the stochastic nature of our decodes means that the sender of an image has no way of knowing exactly what image the receiver will view and indeed different receivers of the same transmitted image will see different outputs. To a degree, viewers of media are used to this (for example where technologies automatically increase / reduce resolution according to available bandwidth), however methods such as ours have the potential to vary images in terms of higher level content as well as fine grained detail. This makes quality control, for example, problematic and use cases sensitive to this would need to do careful further investigation before using techniques such as ours. For other use cases however, such as artistic media, having a built in method for variable user experience may actually provide an interesting avenue for creative exploration.",Broader Impact,442,14,,,FALSE,FALSE,FALSE,Hierarchical Quantized Autoencoders,Deep Learning -> Deep Autoencoders,Probabilistic Methods -> Hierarchical Models,Probabilistic methods and inference,"['Will Williams', ' Sam Ringer', ' Tom Ash', ' David MacLeod', ' Jamie Dougherty', ' John Hughes']",{'Speechmatics'},0,1,0,{'UK'}
Diversity can be Transferred: Output Diversification for White- and Black-box Attacks,"Yusuke Tashiro, Yang Song, Stefano Ermon",Diversity Can Be Transferred: Output Diversification for White- and Black-box Attacks,30da227c6b5b9e2482b6b221c711edfd,https://proceedings.neurips.cc/paper/2020/file/30da227c6b5b9e2482b6b221c711edfd-Paper.pdf,"The existence of adversarial examples is a major source of concern for machine learning applications in the real world. For example, imperceptible perturbations crafted by malicious attackers could deceive safety critical systems such as autonomous driving and facial recognition systems. Since adversarial examples exist not only for images, but also for other domains such as text and audio, the potential impact is large. Our research provides new state-of-the-art black-box adversarial attacks in terms of query-efficiency and makes adversarial attacks more practical and strong. While all experiments in this paper are for images, the proposed method is also applicable to other modalities. Because of this, our research could be used in harmful ways by malicious users. On the positive side, strong attacks are necessary to develop robust machine learning models. For the last few years, several researchers have proposed adversarial attacks which break previous defense models. In response to these strong attacks, new and better defense mechanisms have been developed. It is this feedback loop between attacks and defenses that advances the field. Our research not only provides a state-of-the-art attack, but also sheds light on a new perspective, namely the importance of diversity, for improving adversarial attacks. This may have a long term impact on inspiring more effective defense methods.",Broader Impact,210,12,,,FALSE,FALSE,FALSE,Diversity can be Transferred: Output Diversification for White- and Black-box Attacks,Deep Learning -> Adversarial Networks,Applications -> Computer Vision,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yusuke Tashiro', ' Yang Song', ' Stefano Ermon']","{'Stanford', 'Stanford University', 'Japan Digital Design'}",1,1,1,"{'Japan', 'USA'}"
POLY-HOOT: Monte-Carlo Planning in Continuous Space MDPs with Non-Asymptotic Analysis,"Weichao Mao, Kaiqing Zhang, Qiaomin Xie, Tamer Basar",POLY-HOOT : Monte-Carlo Planning in Continuous Space MDPs with Non-Asymptotic Analysis,30de24287a6d8f07b37c716ad51623a7,https://proceedings.neurips.cc/paper/2020/file/30de24287a6d8f07b37c716ad51623a7-Paper.pdf,"We believe that researchers of planning, reinforcement learning, and multi-armed bandits, especially those who are interested in the theoretical foundations, would benefit from this work. In particular, prior to this work, though intuitive, easy-to-implement, and empirically widely-used, a theoretical  analysis of Monte-Carlo tree search (MCTS) in continuous domains had not been established through the lens of non-stationary bandits. In this work, inspired by the recent advances in finite-space Monte-Carlo tree search, we have provided such a result, and thus theoretically justified the efficiency of MCTS in continuous domains. Although Monte-Carlo tree search has demonstrated great performance in a wide range of applications, theoretical explanation of its empirical successes is relatively lacking. Our theoretical results have advocated the use of non-stationary bandit algorithms, which might guide the design of new planning algorithms that enjoy better empirical performance in practice. Our results might also be helpful for researchers interested in robotics and control applications, as our algorithm can be readily applied to such planning problems with continuous domains. As a theory-oriented work, we do not believe that our research will cause any ethical issue, or put anyone at any disadvantage.",Broader Impact,188,7,,,FALSE,FALSE,FALSE,POLY-HOOT: Monte-Carlo Planning in Continuous Space MDPs with Non-Asymptotic Analysis,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Weichao Mao', ' Kaiqing Zhang', 'Champaign', ' Qiaomin Xie', ' Tamer Basar']","{'UIUC', 'University of Illinois at Urbana-Champaign', 'University of Illinois Urbana-Champaign', 'Cornell University'}",1,0,0,{'USA'}
AvE: Assistance via Empowerment,"Yuqing Du, Stas Tiomkin, Emre Kiciman, Daniel Polani, Pieter Abbeel, Anca Dragan",AvE: Assistance via Empowerment,30de9ece7cf3790c8c39ccff1a044209,https://proceedings.neurips.cc/paper/2020/file/30de9ece7cf3790c8c39ccff1a044209-Paper.pdf,"As our work is focused on enabling artificial agents to learn to be more useful assistants, we believe it has the potential for significant broader impact in both the research community and for the future usefulness of assistive agents in a variety of real world applications (e.g. assistive robotics in elder care, prosthetics). The most immediate impact of our work lies in the direct application of empowerment for assisting humans. In the research community, the novel use of empowerment for human assistance can motivate further work in goal-agnostic human-agent collaboration and assistance. As emphasized in our work, in cases where goal inference is challenging or when aiding under the assumption of an incorrectly inferred goal may have risks, our method acts as an alternative to potential pitfalls of goal inference. This, we believe, can be crucial when applied to assisting people in the real world. In particular, our successful results with the Lunar Lander user study suggests that our method can assist humans engaging in a challenging shared autonomy control task. Our method invites extensions to real-world shared autonomy tasks (e.g. flying a quadrotor drone, teleoperation of a high DOF robotic arm with a joystick controller, etc.). Outside of research labs, the broader impact of a goal-agnostic human assistive method lies in the potential of applying this general method to a wide variety of assistive tasks – ranging from software assistants to assitive robotics. We also emphasize that while assistive technologies are developed to aid people, safety procedures and strict certification are necessary before a real-world application of our method. With direct human interaction, failures of the system can critically impact people (whether that be through physical robotic failures, or privacy concerns with software assistants).  At a societal scale, we also hope that proposing a method that optimizes for human controllability will encourage future ethical discussions about how to realize learning assistive agents that balance providing effective help while also ultimately guaranteeing as much human autonomy and control as possible. Importantly, as empowerment aims to enhance the element of autonomy in the human, this offers a systematic route to avoid the possible drawback of an overly helpful, but constricting artificial assistant. Depending on the situation in which AI agents are employed, there can be uncertainty around the extent to which people (at a personal level, cultural level, etc.) require a balance between autonomy and assistance. The importance of different types of autonomy (e.g. personal, moral) for different groups of individuals (e.g. age groups, cultural groups) and how they can be positively or negatively affected by applications of human empowerment can be examined in other areas of research (e.g. sociology, philosophy, psychology).",Broader Impact,441,14,,,TRUE,TRUE,FALSE,AvE: Assistance via Empowerment,Applications,Applications -> Robotics; Reinforcement Learning and Planning -> Reinforcement Learning,"Other applications (e.g., robotics, biology, climate, finance)","['Yuqing Du', ' Stas Tiomkin', ' Emre Kiciman', ' Daniel Polani', ' Pieter Abbeel', ' Anca Dragan']","{'UC Berkeley', 'University of Hertfordshire', 'Microsoft Research', 'EECS Department, University of California, Berkeley'}",1,1,1,"{'UK', 'USA'}"
Variational Policy Gradient Method for Reinforcement Learning with General Utilities,"Junyu Zhang, Alec Koppel, Amrit Singh Bedi, Csaba Szepesvari, Mengdi Wang",Variational Policy Gradient Method for Reinforcement Learning with General Utilities,30ee748d38e21392de740e2f9dc686b6,https://proceedings.neurips.cc/paper/2020/file/30ee748d38e21392de740e2f9dc686b6-Paper.pdf,"While RL has a great number of potential applications, our work is of foundational nature and as such, the application of the ideas in this paper can have both broad positive and negative impacts. However, this paper is purely theoretical, as we do not aim at any specific application, there is nothing we can say about the most likely broader impact of this work that would go beyond speculation.",6 Broader Impact,69,2,,,FALSE,FALSE,FALSE,Variational Policy Gradient Method for Reinforcement Learning with General Utilities,Reinforcement Learning and Planning -> Reinforcement Learning,Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization; Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement learning and planning,"['Junyu Zhang', ' Alec Koppel', ' Amrit Singh Bedi', ' Csaba Szepesvari', ' Mengdi Wang']","{'Princeton University', 'US Army Research Laboratory', 'DeepMind / University of Alberta'}",1,1,1,"{'Canada', 'UK', 'USA'}"
Reverse-engineering recurrent neural network solutions to a hierarchical inference task for mice,"Rylan Schaeffer, Mikail Khona, Leenoy Meshulam, Brain Laboratory International, Ila Fiete",Reverse-engineering Recurrent Neural Network solutions to a hierarchical inference task for mice,30f0641c041f03d94e95a76b9d8bd58f,https://papers.nips.cc/paper/2020/file/30f0641c041f03d94e95a76b9d8bd58f-Paper.pdf,"We appreciate NeurIPS asking researchers to evaluate the ethical dimensions of their work. We believe this work, focused on understanding mechanisms of how neural networks solve basic inference problems, does not have detrimental social ramifications. It is possible that RADD, as a technique for more interpretable ANNs, could be used to better understand biases learned in RNNs.",Broader Impact,57,3,FALSE,FALSE,TRUE,TRUE,TRUE,Reverse-engineering recurrent neural network solutions to a hierarchical inference task for mice,Neuroscience and Cognitive Science -> Neuroscience,Deep Learning -> Analysis and Understanding of Deep Networks; Neuroscience and Cognitive Science -> Human or Animal Learning; Neuroscience and Cognitive Science -> Perception; Reinforcement Learning and Planning -> Reinforcement Learning,Neuroscience and cognitive science,"['Rylan Schaeffer', ' Mikail C Khona', ' Leenoy Meshulam', ' Brain Laboratory International', ' Ila Fiete']","{'International Brain Laboratory', 'Harvard University', 'Massachusetts Institute of Technology MIT', 'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Temporal Positive-unlabeled Learning for Biomedical Hypothesis Generation via Risk Estimation,"Uchenna Akujuobi, Jun Chen, Mohamed Elhoseiny, Michael Spranger, Xiangliang Zhang",Temporal Positive-unlabeled Learning for Biomedical Hypothesis Generation via Risk Estimation,310614fca8fb8e5491295336298c340f,https://proceedings.neurips.cc/paper/2020/file/310614fca8fb8e5491295336298c340f-Paper.pdf,"TRP can be adopted to a wide range of applications involving node pairs in a graph structure. For instance, the prediction of relationships or similarities between two social beings, the prediction of items that should be purchased together, the discovery of compatibility between drugs and diseases, and many more. Our proposed model can be used to capture and analyze the temporal relationship of node pairs in an incremental dynamic graph. Besides, it is especially useful when only samples of a given class (e.g., positive) are available, but it is uncertain whether the unlabeled samples are positive or negative. To be aligned with this fact, TRP treats the unlabeled data as a mixture of negative and positive data samples, rather than all be negative. Thus TRP is a flexible classification model learned from the positive and unlabeled data. While there could be several applications of our proposed model, we focus on the automatic biomedical hypothesis generation (HG) task, which refers to the discovery of meaningful implicit connections between biomedical terms. The use of HG systems has many benefits, such as a faster understanding of relationships between biomedical terms like viruses, drugs, and symptoms, which is essential in the fight against diseases. With the use of HG systems, new hypotheses with minimum uncertainty about undiscovered knowledge can be made from already published scholarly literature. Scientific research and discovery is a continuous process. Hence, our proposed model can be used to predict pairwise relationships when it is not enough to know with whom the items are related, but also learn how the connections have been formed (in a dynamic process). However, there are some potential risks of hypothesis generation from biomedical papers. 1) Publications might be faulty (with faulty/wrong results), which can result in a bad estimate of future relationships. However, this is a challenging problem as even experts in the field might be misled by the faulty results. 2) The access to full publication text (or even abstracts) is not readily available, hence leading to a lack of enough data for a good understanding of the studied terms, and then inaccurate h in generation performance. 3) It is hard to interpret and explain the learning process, for example, the learned embedding vectors are relevant to which term features, the contribution of neighboring terms in the dynamic evolution process. 4) For validating the future relationships, there is often a need for background knowledge or a biologist to evaluate the prediction. Scientific discovery is often to explore the new nontraditional paths. PU learning lifts the restriction on undiscovered relations, keeping them under investigation for the probability of being positive, rather than denying all the unobserved relations as negative. This is the key value of our work in this paper.",6 Broader Impact,455,20,,,FALSE,FALSE,FALSE,Temporal Positive-unlabeled Learning for Biomedical Hypothesis Generation via Risk Estimation,Algorithms -> Semi-Supervised Learning,Algorithms -> Classification; Applications -> Health; Deep Learning -> Recurrent Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Uchenna Akujuobi', ' Jun Chen', ' Mohamed Elhoseiny', ' Michael Spranger', ' Xiangliang Zhang']","{'King Abdullah University of Science and Techonology', 'Sony', 'King Abdullah University of Science and Technology', 'KAUST and Stanford University'}",1,1,1,"{'Japan', 'USA', 'Saudi Arabia'}"
Efficient Low Rank Gaussian Variational Inference for Neural Networks,"Marcin Tomczak, Siddharth Swaroop, Richard Turner",Efficient Low Rank Gaussian Variational Inference for Neural Networks,310cc7ca5a76a446f85c1a0d641ba96d,https://proceedings.neurips.cc/paper/2020/file/310cc7ca5a76a446f85c1a0d641ba96d-Paper.pdf,"Probabilistic methods have the potential to bring considerable benefits to neural networks and computer vision [19]. These approaches return to the user multiple hypotheses that are consistent with the observed data and the user’s modeling assumptions. These hypotheses can be used to carry out predictions allowing the degree of confidence in predictions to be quantified and broken apart into aleatoric contributions (e.g. label noise) and epistemic uncertainty (e.g. from lack of data). Real time modeling of epistemic uncertainty can prevent models from making catastrophic mistakes, which is crucial for real time decision making systems. While the approach introduced in this paper is still prone to making misclassification mistakes, the model tends to output high entropy predictive distributions in this case as compared to deterministic approaches. It should be noted that the approximate inference techniques studied in this paper (Variational Inference) assumes that the data distribution is given and cannot automatically detect or remove biases existing in the data.",Broader Impact,158,6,,,FALSE,FALSE,FALSE,Efficient Low Rank Gaussian Variational Inference for Neural Networks,Probabilistic Methods -> Variational Inference,,Probabilistic methods and inference,"['Marcin Tomczak', ' Siddharth Swaroop', ' Richard E Turner']",{'University of Cambridge'},1,0,0,{'UK'}
Privacy Amplification via Random Check-Ins,"Borja Balle, Peter Kairouz, Brendan McMahan, Om Dipakbhai Thakkar, Abhradeep Thakurta",Privacy Amplification via Random Check-Ins,313f422ac583444ba6045cd122653b0e,https://proceedings.neurips.cc/paper/2020/file/313f422ac583444ba6045cd122653b0e-Paper.pdf,"The rapid growth in connectivity and information sharing has been accelerating the adoption of tighter privacy regulations and better privacy-preserving technologies. Therefore, training machine learning models on decentralized data using mechanisms with formal guarantees of privacy is highly desirable. However, despite the rapid acceleration of research on both DP and FL, only a tiny fraction of production ML models are trained using either technology. This work takes an important step in addressing this gap. Our work highlights the fact that proving DP guarantees for distributed or decentralized systems can be substantially more challenging than for centralized systems, because in the distributed world it becomes much harder to precisely control and characterize the randomness in the system, and this precise characterization and control of randomness is at the heart of DP guarantees. Specifically, production FL systems do not satisfy the assumptions that are typically made under state-of-the-art privacy accounting schemes, such as privacy amplification via subsampling. Without such accounting schemes, service providers cannot give DP statements with small ε ’s. This work, though largely theoretical in nature, proposes a method shaped by the practical constraints of distributed systems that allows for rigorous privacy statements under realistic assumptions. Nevertheless, there is more to do. Our theorems are sharpest in the high-privacy regime (small ε ’s), which may be too conservative to provide sufficient utility for some applications. While significantly relaxed from previous work, our assumptions will still not hold in all real-world systems. Thus, we hope this work encourages further collaboration between distributed systems and DP theory researchers in establishing protocols that address the full range of possible systems constraints as well as improving the full breadth of the privacy vs. utility Pareto frontier.",7 Broader Impacts,282,12,,,FALSE,FALSE,FALSE,Privacy Amplification via Random Check-Ins,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Borja Balle', ' Peter Kairouz', ' Brendan McMahan', ' Om Thakkar', ' Abhradeep Thakurta']","{'Google', 'Amazon'}",0,1,0,{'USA'}
Probabilistic Circuits for Variational Inference in Discrete Graphical Models,"Andy Shih, Stefano Ermon",Probabilistic Circuits for Variational Inference in Discrete Graphical Models,31784d9fc1fa0d25d04eae50ac9bf787,https://proceedings.neurips.cc/paper/2020/file/31784d9fc1fa0d25d04eae50ac9bf787-Paper.pdf,"Our contributions are broadly aimed at improving approximate inference in graphical models. Our research could be used to develop more scalable and more accurate inference methods for machine learning models in general. As seen in our experiments, this includes handling models for physics, word/topic analysis, or image segmentation. Scaling to even bigger models can open up even more potential applications.",Broader Impact,60,4,FALSE,FALSE,FALSE,FALSE,FALSE,Probabilistic Circuits for Variational Inference in Discrete Graphical Models,Probabilistic Methods -> Graphical Models,Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Andy Shih', ' Stefano Ermon']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Your Classifier can Secretly Suffice Multi-Source Domain Adaptation,"Naveen Venkat, Jogendra Nath Kundu, Durgesh Singh, Ambareesh Revanur, Venkatesh Babu R",Your Classifier can Secretly Suffice Multi-Source Domain Adaptation,3181d59d19e76e902666df5c7821259a,https://proceedings.neurips.cc/paper/2020/file/3181d59d19e76e902666df5c7821259a-Paper.pdf,"This work presents a simple and effective solution for Multi-Source Domain Adaptation, that has a two-fold positive impact. First, the method is aimed at improving the performance of prediction models by mitigating the bias caused by domain-shift between the training dataset and the test data encountered when deployed in a real-world environment. This is of growing interest in the machine learning community. Secondly, the insights presented in this work facilitate the study of efficient methods to perform domain adaptation, motivating the innovation of, for instance, energy-efficient methods to generalize deep models. While the method shows promising results under domain-shift, one should be cautious of the use of the pseudo-labeling procedure in the presence of adversarial samples, where the pseudo-labels may be less reliable and may result in performance degradation.",Broader Impact,129,5,,,FALSE,FALSE,FALSE,Your Classifier can Secretly Suffice Multi-Source Domain Adaptation,Algorithms -> Classification,Algorithms -> Unsupervised Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Naveen Venkat', ' Jogendra Nath Kundu', ' Durgesh Singh', ' Ambareesh Revanur', ' Venkatesh Babu R']","{'IISc', 'Indian Institute of Science', 'Carnegie Mellon University', 'Indian institute of science'}",1,0,0,"{'India', 'USA'}"
Labelling unlabelled videos from scratch with multi-modal self-supervision,"Yuki Asano, Mandela Patrick, Christian Rupprecht, Andrea Vedaldi",Labelling unlabelled videos from scratch with multi-modal self-supervision,31fefc0e570cb3860f2a6d4b38c6490d,https://proceedings.neurips.cc/paper/2020/file/31fefc0e570cb3860f2a6d4b38c6490d-Paper.pdf,"We propose a method for clustering videos automatically. As such, we see two main areas of potential broader impact on the community and society as a whole. Few-label harmful content detection. Our method clusters a video dataset into multiple sets of similar videos, as evidenced by the audio- and visual-stream and produces consistent, homogenous groupings. In practice, unsupervised clustering is especially useful for reducing the amount of data that human annotators have to label, since for highly consistent clusters only a single label needs to be manually obtained which can be propagated to the rest of the videos in the cluster. Using such an approach for the purpose of detecting harmful online content is especially promising. In addition, label-propagation might further lead to a beneficial reduction of type I errors (saying a video is safe when it is not). Furthermore, the multi-modality of our method allows it to potentially detect harmful content that is only manifested in one modality such as static background videos of harmful audio. Multi-modal harmful content detection has also been a subject of a recent data challenge that emphasizes insufficiency of using a single modality 7 . Lastly, the generality of our method allows it to also scale beyond these two modalities and in the future also include textual transcripts. Given the importance of this topic, it is also important to acknowledge, while less of a direct consequence, potential biases that can be carried by the dataset. Indeed models trained using our method will inherit the biases present in the dataset, which could be known but also unknown, potentially leading to propagation of biases without a clear way to analyze them, such as via labels. However, given the numerous pitfalls and failures when deploying computer vision systems to the real world, we believe that the positive impact of foundational research on public datasets, such as is presented in this paper, far outweighs these risks lying further downstream. Overestimating clustering quality. The main benefit of our approach is to reduce the cost of grouping large collections of video data in a ‘meaningful’ way. It is difficult to think of an application where such a capability would lead directly to misuse. In part, this is due to the fact that better clustering results can generally be obtained by using some manual labels, so even where clustering videos could be misused, this probably would not be the method of choice. Perhaps the most direct risk is that a user of the algorithm might overestimate its capabilities. Clustering images is sometimes done in critical applications (e.g. medical science [36, 38, 50]). Our method clusters data based on basic statistical properties and the inductive prior of convolutional neural networks, without being able to tap into the deep understanding that a human expert would have of such domain expertise. Hence, the clusters determined by our method may not necessarily match the clusters an expert would make in a particular domain. Further, as the method is unsupervised, it may learn to exploit biases present in the data that might not be desired by the users. While we believe it has potential to be broadly applied after being finetuned to a specific domain, at present, our method is a better fit for applications such as indexing personal video collections where clustering ‘errors’ can be tolerated.",Broader Impact,551,23,,,FALSE,FALSE,FALSE,Labelling unlabelled videos from scratch with multi-modal self-supervision,Applications -> Computer Vision,Algorithms -> Clustering; Algorithms -> Multimodal Learning,Vision,"['Yuki Asano', ' Mandela Patrick', ' Christian Rupprecht', ' Andrea Vedaldi']","{'University of Oxford / Facebook AI Research', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
A Non-Asymptotic Analysis for Stein Variational Gradient Descent,"Anna Korba, Adil SALIM, Michael Arbel, Giulia Luise, Arthur Gretton",A Non-Asymptotic Analysis for Stein Variational Gradient Descent,3202111cf90e7c816a472aaceb72b0df,https://proceedings.neurips.cc/paper/2020/file/3202111cf90e7c816a472aaceb72b0df-Paper.pdf,This paper aims at bringing more theoretical understanding to the Stein Variational Gradient Descent algorithm. This algorithm is widely used by machine learning practitioners but its non asymptotic properties are not as well-known as the ones of the Langevin Monte Carlo algorithm which can be considered as its competitor.,8 Broader impact,49,2,FALSE,FALSE,FALSE,FALSE,FALSE,A Non-Asymptotic Analysis for Stein Variational Gradient Descent,Probabilistic Methods -> MCMC,Algorithms -> Kernel Methods; Optimization; Probabilistic Methods -> Variational Inference,"Algorithms, kernel methods, variational inference","['Anna Korba', ' Adil SALIM', ' Michael Arbel', ' Giulia Luise', ' Arthur Gretton']","{'UCL', 'KAUST', 'Gatsby Unit - UCL', 'Gatsby Unit, UCL', 'University College London'}",1,0,0,"{'UK', 'Saudi Arabia'}"
Robust Meta-learning for Mixed Linear Regression with Small Batches,"Weihao Kong, Raghav Somani, Sham Kakade, Sewoong Oh",Robust Meta-learning for Mixed Linear Regression with Small Batches,3214a6d842cc69597f9edf26df552e43,https://proceedings.neurips.cc/paper/2020/file/3214a6d842cc69597f9edf26df552e43-Paper.pdf,"One of the main contribution of this paper is to protect meta-learning approaches against data poisoning attacks. Such robustness encourages participation from data contributors, as they can collaborate without necessarily trusting the other data contributors. This facilitates participation of minor contributors who suffer from data scarcity. This fosters democratization of machine learning by allowing minor contributors to enjoy the benefit of big data through collaboration. Such ecosystem will also encourage data sharing, thus improving transparency. The adaptive guarantee we provide in Theorem 1 is fair, in the sense that a group that provides low noise data will receive a model with better accuracy. However, one potential risk in fairness is that meta-learning might result in varying accuracy across the groups. This can be problematic as an under-represented group in training data could suffer from inaccurate prediction for that population. This is an active area of research in the fairness community, but there is no strong experimental evidence that this can be mitigated with algorithmic innovations that do not involve collecting more data from the under-represented population. Another concern in meta-learning with data sharing is privacy. Without proper system to regulate the usage of shared data, sensitive information could be leaked or protected features could be inferred. One silver lining is that robust methods are naturally private, as the trained model is by definition not sensitive to any one particular data point. On the other hand, if the system relies on the participation of various individuals, then either a technological solution needs to be implemented with cryptographic or privacy preserving primitives, or a proper regulation must be enforced.",Broader Impact,267,13,,,FALSE,FALSE,FALSE,Robust Meta-learning for Mixed Linear Regression with Small Batches,Algorithms -> Spectral Methods,Theory -> High-Dimensional Inference,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Weihao Kong', ' Raghav Somani', ' Sham Kakade', ' Sewoong Oh']","{'Stanford University', 'University of Washington'}",1,0,0,{'USA'}
Bayesian Deep Learning and a Probabilistic Perspective of Generalization,"Andrew G. Wilson, Pavel Izmailov",Bayesian Deep Learning and a Probabilistic Perspective of Generalization,322f62469c5e3c7dc3e58f5a4d1ea399,https://proceedings.neurips.cc/paper/2020/file/322f62469c5e3c7dc3e58f5a4d1ea399-Paper.pdf,"Improvements in methods and understanding for Bayesian deep learning are crucial for using machine learning in reliable decision making. A well-calibrated predictive distribution provides significantly more information for making decisions, and helps protect against rare but costly mistakes in loss- calibrated inference. Bayesian deep learning can also be used for improved sample efficiency, decreasing the need for costly large labelled datasets typically needed to train accurate neural networks. Bayesian neural networks can also be far more robust to noise, as we have shown in the double descent experiments. A better understanding of generalization in deep learning also helps us more reliably predict when a neural network might be reasonable to deploy in real problems. Potential broader drawbacks include increased computation, and increased complexity of the approaches — sometimes requiring expert knowledge on approximate inference to achieve good performance.",Broader Impacts,138,6,,,FALSE,FALSE,FALSE,Bayesian Deep Learning and a Probabilistic Perspective of Generalization,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks; Probabilistic Methods,Deep learning,"['Andrew Gordon Wilson', ' Pavel Izmailov']",{'New York University'},1,0,0,{'USA'}
Unsupervised Learning of Object Landmarks via Self-Training Correspondence,"Dimitrios Mallis, Enrique Sanchez, Matthew Bell, Georgios Tzimiropoulos",Unsupervised Learning of Object Landmarks via Self-Training Correspondence,32508f53f24c46f685870a075eaaa29c,https://proceedings.neurips.cc/paper/2020/file/32508f53f24c46f685870a075eaaa29c-Paper.pdf,"This work presents a method for unsupervised discovery of object landmarks. This is a machine learning problem of extraordinary difficulty something that has been the main motivation for our work. We would like to distance our approach from the problem of face recognition. Potentially, our method could be used to aid face recognition which has been occasionally criticized for serving harmful purposes. However, facial landmark localization is a mature technology already heavily used in industry, and large datasets with facial landmarks already exist. Moreover, all facial or human or animal related datasets used in our paper are standard datasets that have been heavily used by the research community.",Broader Impact,108,6,,,FALSE,FALSE,FALSE,Unsupervised Learning of Object Landmarks via Self-Training Correspondence,Algorithms -> Unsupervised Learning,Algorithms -> Clustering; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Dimitrios Mallis', ' Enrique Sanchez', ' Matthew Bell', ' Georgios Tzimiropoulos']","{'University of Nottingham', 'Queen Mary University of London', 'Samsung AI Centre', 'Computer Vision Laboratory - University of Nottingham'}",1,1,1,{'UK'}
Randomized tests for high-dimensional regression: A more efficient and powerful solution,"Yue Li, Ilmun Kim, Yuting Wei",Randomized tests for high-dimensional regression: A more efficient and powerful solution,3261769be720b0fefbfffec05e9d9202,https://proceedings.neurips.cc/paper/2020/file/3261769be720b0fefbfffec05e9d9202-Paper.pdf,This work is a theoretical contribution to incorporate dimension reduction techniques (via random projections) to hypothesis testing in high dimensional regression. The insights from the proposed algorithm can potentially be leveraged in various hypothesis testing and machine learning tasks in the future.,Broader Impact,42,2,FALSE,FALSE,TRUE,TRUE,FALSE,Randomized tests for high-dimensional regression: A more efficient and powerful solution,Theory -> High-Dimensional Inference,Algorithms -> Regression,Theory (including computational and statistical analyses),"['Yue Li', ' Ilmun Kim', ' Yuting Wei']","{'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Learning Representations from Audio-Visual Spatial Alignment,"Pedro Morgado, Yi Li, Nuno Nvasconcelos",Learning Representations from Audio-Visual Spatial Alignment,328e5d4c166bb340b314d457a208dc83,https://proceedings.neurips.cc/paper/2020/file/328e5d4c166bb340b314d457a208dc83-Paper.pdf,"Self-supervision reduces the need for human labeling, which is in some sense less affected by human biases. However, deep learning systems are trained from data. Thus, even self-supervised models reflect the biases in the collection process. To mitigate collection biases, we searched for 360 ◦ videos using queries translated into multiple languages. Despite these efforts, the adoption of 360 ◦ video cameras is likely not equal across different sectors of society, and thus learned representations may still reflect such discrepancies.",Broader Impact,80,5,,,FALSE,FALSE,FALSE,Learning Representations from Audio-Visual Spatial Alignment,Algorithms -> Representation Learning,Algorithms -> Multimodal Learning; Algorithms -> Unsupervised Learning; Applications -> Audio and Speech Processing,Vision,"['Pedro Morgado', ' Yi Li', ' Nuno Nvasconcelos']","{'UC San Diego', 'University of California, San Diego'}",1,0,0,{'USA'}
Generative View Synthesis: From Single-view Semantics to Novel-view Images,"Tewodros Amberbir Habtegebrial, Varun Jampani, Orazio Gallo, Didier Stricker",Generative View Synthesis: From Single-view Semantics to Novel-view Images,3295c76acbf4caaed33c36b1b5fc2cb1,https://proceedings.neurips.cc/paper/2020/file/3295c76acbf4caaed33c36b1b5fc2cb1-Paper.pdf,"This work makes digital content creation easier by introducing a new Generative View Synthesis method that combines the benefits of image-to-image translation and novel view synthesis, both of which are active research areas. We hope this work inspires further research in digital content creation.",Broader Impact,44,2,FALSE,FALSE,FALSE,FALSE,FALSE,Generative View Synthesis: From Single-view Semantics to Novel-view Images,Applications -> Computer Vision,Applications -> Computational Photography; Deep Learning -> Generative Models,Vision,"['Tewodros Amberbir Habtegebrial', ' Varun Jampani', ' Orazio Gallo', ' Didier Stricker']","{'Technische Universität Kaiserslautern', 'DFKI', 'NVIDIA Research', 'Google'}",1,1,1,"{'USA', 'Germany'}"
Towards More Practical Adversarial Attacks on Graph Neural Networks,"Jiaqi Ma, Shuangrui Ding, Qiaozhu Mei",Towards More Practical Adversarial Attacks on Graph Neural Networks,32bb90e8976aab5298d5da10fe66f21d,https://proceedings.neurips.cc/paper/2020/file/32bb90e8976aab5298d5da10fe66f21d-Paper.pdf,"For the potential positive impacts, we anticipate that the work may raise the public attention about the security and accountability issues of graph-based machine learning techniques, especially when they are applied to real-world social networks. Even without accessing any information about the model training, the graph structure alone can be exploited to damage a deep learning framework with a rather executable strategy. On the potential negative side, as our work demonstrates that there is a chance to attack existing GNN models effectively without any knowledge but a simple graph structure, this may expose a serious alert to technology companies who maintain the platforms and operate various applications based on the graphs. However, we believe making this security concern transparent can help practitioners detect potential attack in this form and better defend the machine learning driven applications.",Broader Impact,136,4,,,FALSE,FALSE,FALSE,Towards More Practical Adversarial Attacks on Graph Neural Networks,Algorithms,Algorithms -> Adversarial Learning; Optimization -> Submodular Optimization; Social Aspects of Machine Learning -> AI Safety,Deep learning,,{'University of Michigan'},1,0,0,{'USA'}
Multi-Task Reinforcement Learning with Soft Modularization,"Ruihan Yang, Huazhe Xu, YI WU, Xiaolong Wang",Multi-Task Reinforcement Learning with Soft Modularization,32cfdce9631d8c7906e8e9d6e68b514b,https://proceedings.neurips.cc/paper/2020/file/32cfdce9631d8c7906e8e9d6e68b514b-Paper.pdf,"Our work provided a simple and effective framework for skill and component reuse in the multi-task RL domain, which the community can build off. With the learned skill module, Our work can also inspire work on zero-shot skill transferring and sharing. With improved sample efficiency and potential zero-shot skill transfer, the community might be able to use reinforcement learning to solve tasks that not feasible before and build the robots that can generalize to different tasks. These robots could potentially bring lots of new possibilities in almost every aspect of people’s daily life, e.g., self-driving cars and house-hold robots. Besides, general learned robotics can also be useful for unseen or urgent out-of-distribution scenes. For instance, when it comes to performing a rescue under the earthquake, the robot should have the ability to cope with different conditions. In the deep learning era, collecting samples and training large models could consume a lot energy and release a massive amount of carbon dioxide. With better sample efficiency, training reinforcement learning policy for real-world settings can be much more environment-friendly. Meanwhile, better sample efficiency can also lower the bar and be more accessible for inexperienced researchers to get into the field.",7 Potential Broader Impact,197,9,,,TRUE,TRUE,FALSE,Multi-Task Reinforcement Learning with Soft Modularization,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Multitask and Transfer Learning; Applications -> Robotics,Reinforcement learning and planning,"['Ruihan Yang', ' Huazhe Xu', ' YI WU', ' Xiaolong Wang']","{'UC San Diego', 'UC Berkeley', 'UCSD/UC Berkeley'}",1,0,0,{'USA'}
Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models,"Tom Heskes, Evi Sijben, Ioan Gabriel Bucur, Tom Claassen",Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models,32e54441e6382a7fbacbbbaf3c450059,https://proceedings.neurips.cc/paper/2020/file/32e54441e6382a7fbacbbbaf3c450059-Paper.pdf,"Our research, which aims to provide an explanation for complex machine learning models that can be understood by humans, falls within the scope of explainable AI (XAI). XAI methods like ours can help to open up the infamous “black box” of complicated machine learning models like deep neural networks and decision tree ensembles. A better understanding of the predictions generated by such models may provide higher trust [26], detect flaws and biases [12], higher accuracy [2], and even address the legal “right for an explanation” as formulated in the GDPR [32]. Despite their good intentions, explanation methods do come with associated risks. Almost by defini- tion, any sensible explanation of a complex machine learning system involves some simplification and hence must sacrifice some accuracy. It is important to better understand what these limitations are [11]. Model-agnostic general purpose explanation tools are often applied without properly understanding their limitations and over-trusted [10]. They could possibly even be misused just to check a mark in internal or external audits. Automated explanations can further give an unjust sense of transparency, sometimes referred to as the ‘transparency fallacy’ [4]: overestimating one’s actual understanding of the system. Last but not least, tools for explainable AI are still mostly used as an internal resource by engineers and developers to identify and reconcile errors [2]. Causality is essential to understanding any process and system, including complex machine learning models. Humans have a strong tendency to reason about their environment and to frame explanations in causal terms [28, 16] and causal-model theories fit well to how humans, for example, classify objects [25]. In that sense, explanation approaches like ours, that appeal to a human’s capability for causal reasoning should represent a step in the right direction [21].",Broader Impact,289,13,,,FALSE,FALSE,FALSE,Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Probabilistic Methods -> Causal Inference,Explainable AI,"['Tom Heskes', ' Evi Sijben', ' Ioan Gabriel Bucur', ' Tom Claassen']","{'Radboud University Nijmegen', 'Radboud University'}",1,0,0,{'Netherlands'}
On the training dynamics of deep networks with L2L2 regularization,"Aitor Lewkowycz, Guy Gur-Ari",On the training dynamics of deep networks with L 2 regularization,32fcc8cfe1fa4c77b5c58dafd36d1a98,https://proceedings.neurips.cc/paper/2020/file/32fcc8cfe1fa4c77b5c58dafd36d1a98-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,On the training dynamics of deep networks with $L_2$ regularization,Deep Learning -> Analysis and Understanding of Deep Networks,,Deep learning,"['Aitor Lewkowycz', 'Ari']",{'Google'},0,1,0,{'USA'}
Improved Algorithms for Convex-Concave Minimax Optimization,"Yuanhao Wang, Jian Li",Improved Algorithms for Convex-Concave Minimax Optimization,331316d4efb44682092a006307b9ae3a,https://proceedings.neurips.cc/paper/2020/file/331316d4efb44682092a006307b9ae3a-Paper.pdf,This work is purely theoretical and does not present foreseeable societal consequences.,Broader Impact,12,1,TRUE,FALSE,FALSE,FALSE,FALSE,Improved Algorithms for Convex-Concave Minimax Optimization,Optimization,Optimization -> Convex Optimization; Theory -> Game Theory and Computational Economics,Optimization Methods (continuous or discrete),"['Yuanhao Wang', ' Jian Li']",{'Tsinghua University'},1,0,0,{'China'}
Deep Variational Instance Segmentation,"Jialin Yuan, Chao Chen, Fuxin Li",Deep Variational Instance Segmentation,3341f6f048384ec73a7ba2e77d2db48b,https://proceedings.neurips.cc/paper/2020/file/3341f6f048384ec73a7ba2e77d2db48b-Paper.pdf,"Instance segmentation is an important part for object recognition and is expected to be deployed in many real-life computer vision applications. Our algorithm significantly reduces the amount of computation required to obtain good performance in instance segmentation, hence would significantly lower the total carbon footprint for deployments of instance segmentation algorithms. We did not create additional social and ethical concerns of instance segmentation algorithms. However, there are inherent concerns about object recognition algorithms including instance segmentation to be misused in a system to recover personal identities without individual consent. This is beyond the scope of the  paper since we are only concerned with broad object categories (person, trees, cars, bus, etc.) rather than individual identities of the objects. Our labels are permutation-invariant, i.e. they could assign an arbitrary real-valued number to any instance it predicts. Due to this randomness they do not reveal individual identities per se. A possible concern is that one could input instance segmentation results to another algorithm to identify personal identities, however that is beyond the scope of this paper.",Broader Impact Statement,174,9,,,FALSE,FALSE,FALSE,Deep Variational Instance Segmentation,Applications -> Image Segmentation,,Vision,"['Jialin Yuan', ' Chao Chen', ' Fuxin Li']","{'Stony Brook University', 'Oregon State University'}",1,0,0,{'USA'}
Learning Implicit Functions for Topology-Varying Dense 3D Shape Correspondence,"Feng Liu, Xiaoming Liu",Learning Implicit Functions for Topology-Varying Dense 3D Shape Correspondence,335cd1b90bfa4ee70b39d08a4ae0cf2d,https://proceedings.neurips.cc/paper/2020/file/335cd1b90bfa4ee70b39d08a4ae0cf2d-Paper.pdf,"Product design ( e.g., furniture ) is labor extensive and requires expertise in computer graphics. With the increasing number and diversity of 3 D CAD models in online repositories, there is a growing need for leverage them to facilitate future product development due to their similarities in function and shape. Towards this goal, our proposed method provide a novel unsupervised paradigm to establish dense correspondence for topology-varying objects, which is a prerequisite for shape analysis and synthesis. Furthermore, as our approach is designed for generic objects, its application space can be extremely wide.",Broader Impact,93,4,,,FALSE,FALSE,FALSE,Learning Implicit Functions for Topology-Varying Dense 3D Shape Correspondence,Applications,Applications -> Computer Vision,Vision,"['Feng Liu', ' Xiaoming Liu']",{'Michigan State University'},1,0,0,{'USA'}
Deep Multimodal Fusion by Channel  Exchanging,"Yikai Wang, Wenbing Huang, Fuchun Sun, Tingyang Xu, Yu Rong, Junzhou Huang",Deep Multimodal Fusion by Channel Exchanging,339a18def9898dd60a634b2ad8fbbd58,https://proceedings.neurips.cc/paper/2020/file/339a18def9898dd60a634b2ad8fbbd58-Paper.pdf,"This research enables fusing complementary information from different modalities effectively, which helps improve performance for autonomous vehicles and indoor manipulation robots, also making them more robust to environmental conditions, e.g. light, weather. Besides, instead of carefully designing hierarchical fusion strategies in existing methods, a global criterion is applied in our work for guiding multimodal fusion, which allows easier model deployment for practical applications. A drawback of bringing deep neural networks into multimodal fusion is its insufficient interpretability.",Broader Impact,77,3,,,FALSE,FALSE,FALSE,Deep Multimodal Fusion by Channel  Exchanging,Algorithms -> Multimodal Learning,,Vision,"['Yikai Wang', ' Wenbing Huang', ' Fuchun Sun', ' Tingyang Xu', ' Yu Rong', ' Junzhou Huang']","{'University of Texas at Arlington / Tencent AI Lab', 'Tsinghua University', 'Tsinghua', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
Hierarchically Organized Latent Modules for Exploratory Search in Morphogenetic Systems,"Mayalen Etcheverry, Clément Moulin-Frier, Pierre-Yves Oudeyer",Hierarchically Organized Latent Modules for Exploratory Search in Morphogenetic Systems,33a5435d4f945aa6154b31a73bab3b73,https://proceedings.neurips.cc/paper/2020/file/33a5435d4f945aa6154b31a73bab3b73-Paper.pdf,"We introduced methods that can be used as tools to help human scientists discover novel structures in complex dynamical systems. While experiments presented in this article were performed using an artificial system (continuous cellular automaton), they also target to be used for automated discovery of novel structures in fields ranging from biology to physics. As an example, Grizou et al. [26] recently showed how IMGEPs can be used to automate chemistry experiments addressing fundamental questions related to the origins of life (how oil droplets may self-organize into proto- cellular structures), leading to new insights about oil droplet chemistry. As experiments in Grizou et al. used a single pre-defined BC, one can expect that the new approach presented in this paper may boost the efficiency of its use in bio-physical systems, that could include systems related to design of new materials or new drugs. As a tool enabling scientist to better understand the space of dynamics of such systems, we believe it could help them better understand how to leverage such dynamics for societally useful purposes, and avoid negative effects, e.g. due to unpredicted self-organized dynamics. However, technological and scientific discoveries might have a considerable impact in modern soci- eties. Introducing machine decisions in the process should therefore be done with great responsibility, taking care of carefully identifying and balancing the biases inherent to any ML algorithms. The methods proposed in this paper constitute a first step in this direction by quantitatively measuring the influence of biases, in both predefined and learned BC spaces, on the algorithm discoveries. With an increasing interest in ML for automated discovery, it will be fundamental to to improve and extend these methods in the near future. Besides, by releasing our code, we believe that we help efforts in reproducible science and allow the wider community to build upon and extend our work in the future.",Broader Impact Statement,310,12,,,FALSE,TRUE,FALSE,Hierarchically Organized Latent Modules for Exploratory Search in Morphogenetic Systems,Deep Learning,Algorithms -> Representation Learning; Applications,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Mayalen Etcheverry', 'Frier', 'Yves Oudeyer']","{'INRIA', 'Inria'}",1,0,0,{'France'}
AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity,"Silviu-Marian Udrescu, Andrew Tan, Jiahai Feng, Orisvaldo Neto, Tailin Wu, Max Tegmark",AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity,33a854e247155d590883b93bca53848a,https://proceedings.neurips.cc/paper/2020/file/33a854e247155d590883b93bca53848a-Paper.pdf,"Who may benefit from this research Our research presumably has quite broad impact, since discovery of mathematical patterns in data is a central problem across the natural and social sciences. Given the ubiquity of linear regression in research, one might expect that there will significant benefits to a broad range of researchers also from more general symbolic regression once freely available algorithms get sufficiently good. Who may be put at disadvantage from this research Although it is possible that some numerical modelers could get their jobs automated away by symbolic regression, we suspect that the main effect of our method, and future tools building on it, will instead be that these people will simply discover better models than today. Risk of bias, failure and other negative outcomes Pareto-optimal symbolic regression can be viewed as an extreme form of lossy data compression that uncovers the simplest possible model for any given accuracy. To the extent that overfitting can exacerbate bias, such model compression is expected to help. Moreover, since our method produces closed-form mathematical formulas that have excellent interpretability compared to black-box neural networks, they make it easier for humans to interpret the computation and pass judgement on whether it embodies unacceptable bias. This interpretability also reduces failure risk. Another risk is automation bias, whereby people overly trust a formula from symbolic regression when they extrapolate it into an untested domain. This could be exacerbated if symbolic regression promotes scientific laziness and enfeeblement, where researchers fit phenomenological models instead of doing the work of building models based on first principles. Symbolic regression should inform but not replace traditional scientific discovery. Although the choice of basis functions biases the discoverable function class, our method is agnostic to basis functions as long as they are mostly differentiable. The greatest potential risk associated with this work does not stem from it failing but from it succeeding: accelerated progress in symbolic regression, modularity discovery and its parent discipline, program synthesis, could hasten the arrival of artificial general intelligence, which some authors have argued humanity still lacks the tools to manage safely [5]. On the other hand, our work may help accelerate research on intelligible intelligence more broadly, and powerful future artificial intelligence is probably safer if we understand aspects of how it works than if it is an inscrutable black box.",Broader Impact,386,13,,,TRUE,TRUE,FALSE,AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity,Algorithms -> Regression,"Algorithms -> Data Compression; Algorithms -> Density Estimation; Data, Challenges, Implementations, and Software -> Benchmarks","Other applications (e.g., robotics, biology, climate, finance)","['Marian Udrescu', ' Andrew Tan', ' Jiahai Feng', ' Orisvaldo Neto', ' Tailin Wu', ' Max Tegmark']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Delay and Cooperation in Nonstochastic Linear Bandits,"Shinji Ito, Daisuke Hatano, Hanna Sumita, Kei Takemura, Takuro Fukunaga, Naonori Kakimura, Ken-Ichi Kawarabayashi",Delay and Cooperation in Nonstochastic Linear Bandits,33c5f5bff65aa05a8cd3e5d2597f44ae,https://proceedings.neurips.cc/paper/2020/file/33c5f5bff65aa05a8cd3e5d2597f44ae-Paper.pdf,"The authors believe that this paper presents neither ethical nor societal issues, as this is a theoretical work.",Broader Impact,18,1,TRUE,FALSE,FALSE,FALSE,FALSE,Delay and Cooperation in Nonstochastic Linear Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning; Theory -> Computational Learning Theory; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Shinji Ito', ' Daisuke Hatano', ' Hanna Sumita', ' Kei Takemura', ' Takuro Fukunaga', ' Naonori Kakimura', 'Ichi Kawarabayashi']","{'Keio University', 'Tokyo Institute of Technology', 'RIKEN AIP', 'NEC Corporation', 'National Institute of Informatics', 'Chuo University, JST PRESTO, RIKEN AIP'}",1,1,1,{'Japan'}
Probabilistic Orientation Estimation with Matrix Fisher Distributions,"David Mohlin, Josephine Sullivan, Gérald Bianchi",Probabilistic Orientation Estimation with Matrix Fisher Distributions,33cc2b872dfe481abef0f61af181dfcf,https://proceedings.neurips.cc/paper/2020/file/33cc2b872dfe481abef0f61af181dfcf-Paper.pdf,"The methods described in this paper has obvious applications in fields which some consider ethically questionable such as for surveillance and military systems. One example could be determining heading for ships or airplanes for tactical planning. That being said, the orientation of objects is a fundamental property of objects in the real world and being able to accurately estimate this property should be helpful for many applications of either an ethically desirable or undesirable nature. In our opinion improving the techniques used for orientation estimation has a similar societal impact as improving the techniques used for classification or object detection. The persons in the UPNA dataset are unlikely to be sampled from a uniform distribution of people across the world, for this reason one can not expect the reported performance to be accurate for the world population in general, that being said due to the small test size this reported performance might not reflect the average performance for any population. We do not believe this is an issue since models for predicting head pose which are deployed on a wider scale are very unlikely to use this dataset due to its small size and non-commercial licence. The method itself is not reliant on any population specific feature.",Broader Impact,207,7,,,FALSE,FALSE,FALSE,Probabilistic Orientation Estimation with Matrix Fisher Distributions,Algorithms -> Structured Prediction,"Algorithms -> Regression; Algorithms -> Uncertainty Estimation; Applications -> Body Pose, Face, and Gesture Analysis; Applications -> Computer Vision; Deep Learning -> Supervised Deep Networks",Vision,"['David A Mohlin', ' Josephine Sullivan', ' Gérald Bianchi']","{'Tobii AB', 'KTH', 'KTH Royal Institute of Technology'}",1,1,1,{'Sweden'}
Minimax Dynamics of Optimally Balanced Spiking Networks of Excitatory and Inhibitory Neurons,"Qianyi Li, Cengiz Pehlevan",Minimax Dynamics of Optimally Balanced Spiking Networks of Excitatory and Inhibitory Neurons,33cf42b38bbcf1dd6ba6b0f0cd005328,https://proceedings.neurips.cc/paper/2020/file/33cf42b38bbcf1dd6ba6b0f0cd005328-Paper.pdf,"This work introduces a principled approach to designing spiking neural networks of excitatory (E) and inhibitory (I) neurons to perform various computations. As any spiking neural network model, networks derived from our approach could be applied in the field of neuromorphic computing, where information is transmitted through spikes instead of rate, and is thus more energy efficient. Previous work have shown that E-I balanced networks can serve as fast responding modules [9, 10], and our approach could be applied to designing E-I balanced modules that potentially speed up solving optimization problems in general neuromorphic computing systems. Furthermore, we provided several conditions for the regular functioning of our spiking networks. These conditions could potentially have implications on understanding neural connectivity in the cortex, and how pathological activities in the brain may arise from disrupted synaptic interactions.",Broader Impact,135,5,,,FALSE,FALSE,FALSE,Minimax Dynamics of Optimally Balanced Spiking Networks of Excitatory and Inhibitory Neurons,Neuroscience and Cognitive Science -> Neural Coding,Neuroscience and Cognitive Science -> Memory; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Spike Train Generation,Neuroscience and cognitive science,"['Qianyi Li', ' Cengiz Pehlevan']",{'Harvard University'},1,0,0,{'USA'}
Telescoping Density-Ratio Estimation,"Benjamin Rhodes, Kai Xu, Michael U. Gutmann",Telescoping Density-Ratio Estimation,33d3b157ddc0896addfb22fa2a519097,https://proceedings.neurips.cc/paper/2020/file/33d3b157ddc0896addfb22fa2a519097-Paper.pdf,"As outlined in the introduction, density-ratio estimation is a foundational tool in machine learning with diverse applications. Our work, which improves density-ratio estimation, may therefore increase the scope and power of a wide spectrum of techniques used both in research and real-world settings. The broad utility of our contribution makes it challenging to concretely assess the societal impact of the work. However, we do discuss here two applications of density-ratio estimation with obvious potential for positive & negative impacts on society. Generative Adversarial Networks [15] are a popular class of models which are often trained via density-ratio estimation and are able to generate photo-realistic image/video content. To the extent that TRE can enhance GAN training (a topic we do not treat in this paper), our work could conceivably lead to enhanced ‘deepfakes’, which can be maliciously used in fake-news or identity fraud. More positively, density-ratio estimation is being used to correct for dataset bias, including the presence of skewed demographic factors like race and gender [18]. While we are excited about such applications, we emphasise that density-ratio based methods are not a panacea; it is entirely possible for the technique to introduce new biases when correcting for existing ones. Future work should continue to be mindful of such a possibility, and look for ways to address the issue if it arises.",Broader Impact,221,9,,,FALSE,FALSE,FALSE,Telescoping Density-Ratio Estimation,Algorithms -> Unsupervised Learning,Algorithms -> Density Estimation; Algorithms -> Representation Learning,Probabilistic methods and inference,"['Benjamin Rhodes', ' Kai Xu', ' Gutmann']",{'University of Edinburgh'},1,0,0,{'UK'}
Towards Deeper Graph Neural Networks with Differentiable Group Normalization,"Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu",Towards Deeper Graph Neural Networks with Differentiable Group Normalization,33dd6dba1d56e826aac1cbf23cdcca87,https://proceedings.neurips.cc/paper/2020/file/33dd6dba1d56e826aac1cbf23cdcca87-Paper.pdf,"The successful outcome of this work will lead to advances in building up deep graph neural networks and dealing with complex graph-structured data. The developed metrics and algorithms have an immediate and strong impact on a number of fields, including (1) Over-smoothing Quantitative Analysis : GNN models tend to result in the over-smoothing issue with the increase in the number of layers. During the practical development of deeper GNN models, the proposed instance information gain and group distance ratio effectively indicate the over-smoothing issue, in order to push the model exploration toward a good direction. (2) Deep GNN Modeling : The proposed differentiable group normalization tool successfully tackles the over-smoothing issue and enables the modeling of  deeper GNN variants. It encourages us to fully unleash the power of deep learning in processing the networked data. (3) Real-world Network Analytics Applications : The proposed research will broadly shed light on utilizing deep GNN models in various applications, such as social network analysis, brain network analysis, and e-commerce network analysis. For such complex graph-structured data, deep GNN models can exploit the multi-hop neighborhood information to boost the task performance.",Broader Impact,187,7,,,FALSE,FALSE,FALSE,Towards Deeper Graph Neural Networks with Differentiable Group Normalization,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Representation Learning; Algorithms -> Semi-Supervised Learning; Applications -> Network Analysis; Deep Learning -> Embedding Approaches,Deep learning,"['Kaixiong Zhou', ' Xiao Huang', ' Yuening Li', ' Daochen Zha', ' Rui Chen', ' Xia Hu']","{'Samsung Research America', 'The Hong Kong Polytechnic University'}",1,1,1,"{'South Korea', 'China'}"
Stochastic Optimization for Performative Prediction,"Celestine Mendler-Dünner, Juan Perdomo, Tijana Zrnic, Moritz Hardt",Stochastic Optimization for Performative Prediction,33e75ff09dd601bbe69f351039152189,https://proceedings.neurips.cc/paper/2020/file/33e75ff09dd601bbe69f351039152189-Paper.pdf,"The motivation for studying performative prediction comes from the observation that whenever we use supervised learning in social settings, we almost never make predictions for predictions’ sake, but rather to inform decision making within some broader context [11]. Banks predict default risks to decide to whom they will allocate loans. Commuters use estimated time of arrival (ETA) prediction to choose which route to take to work. Governments predict crime rates to decide how to deploy police forces [8, 13]. In each of these settings, our choice of predictive model leads to changes in the way the broader system behaves and hence in the distribution over observed data. Our work introduces optimization procedures for finding classifiers with good predictive performance for these performative settings. Here, we use good to indicate that these models are accurate. However, as is clear from examples in recent history, the societal impacts of having an accurate model depend on the context in which prediction is used, and the intent of the system designer. As a society, we can benefit from having robust and reliable systems to forecast congestion in cities, yet it would be remiss of us to overlook how these advances could also be used to infringe upon civil liberties. As a subfield of learning theory, performative prediction is only just starting to receive attention from the community and papers in this area are largely theoretical in nature. Therefore, much remains to be seen in terms of the broader impact of these ideas. We eagerly welcome feedback and comments from members of the community as to how we may ensure the success of this research agenda.",Broader impact statement,271,12,,,FALSE,FALSE,FALSE,Stochastic Optimization for Performative Prediction,Optimization -> Stochastic Optimization,Optimization -> Convex Optimization; Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Dünner', ' Juan Perdomo', ' Tijana Zrnic', ' Moritz Hardt']","{'UC Berkeley', 'University of California, Berkeley'}",1,0,0,{'USA'}
Learning Differentiable Programs with Admissible Neural Heuristics,"Ameesh Shah, Eric Zhan, Jennifer Sun, Abhinav Verma, Yisong Yue, Swarat Chaudhuri",Learning Differentiable Programs with Admissible Neural Heuristics,342285bb2a8cadef22f667eeb6a63732,https://proceedings.neurips.cc/paper/2020/file/342285bb2a8cadef22f667eeb6a63732-Paper.pdf,"Programmatic models described using high-level DSLs are a powerful mechanism for summarizing automatically discovered knowledge in a human-interpretable way. Specifically, such models are more interpretable than state-of-the-art neural models while also tending to provide higher performance than shallower linear or decision tree models. Also, programmatic models allow for natural incorporation of inductive bias and allow the user to influence the semantic meaning of learned programs. For these reasons, efforts on program learning, such as ours, can lead to more widespread use of machine learning in fields, such as healthcare, autonomous driving, and the natural sciences, where safety and accountability are critical and there human-held prior knowledge (such as the laws of nature) that can usefully direct the learning process. The flipside of this is that the bias introduced in program learning can just as easily be exploited by users who desire specific outcomes from the learner. Ultimately, users of program learning methods must ensure that any incorporated inductive bias will not lead to unfair or misleading programs.",Broader Impact,167,6,,,FALSE,FALSE,FALSE,Learning Differentiable Programs with Admissible Neural Heuristics,Applications -> Program Understanding and Generation,Algorithms -> Program Induction,Program Synthesis,"['Ameesh Shah', ' Eric Zhan', ' Jennifer Sun', ' Abhinav Verma', ' Yisong Yue', ' Swarat Chaudhuri']","{'UC Berkeley', 'Caltech', 'The University of Texas at Austin', 'Rice University'}",1,0,0,{'USA'}
Improved guarantees and a multiple-descent curve for Column Subset Selection and the Nystrom method,"Michal Derezinski, Rajiv Khanna, Michael W. Mahoney",Improved guarantees and a multiple-descent curve for Column Subset Selection and the Nyström method,342c472b95d00421be10e9512b532866,https://proceedings.neurips.cc/paper/2020/file/342c472b95d00421be10e9512b532866-Paper.pdf,"Our study offers a deeper theoretical understanding of the Column Subset Selection Problem. The nature of our work is primarily theoretical, with direct applications to feature selection and kernel approximation, as we noted in Section 1. The primary reason for feature selection as a method for ap- proximating a given matrix, as opposed to a low rank approximation using an SVD, is interpretability, which is crucial in many scientific disciplines. Our analysis shows that in many practical settings, feature selection performs almost as well as SVD at approximating a matrix. As such, our work makes a stronger case for feature selection, wherever applicable, for the sake of interpretability. We also hope our work motivates further research into a fine grained analysis to quantify if machine learning problems are really as hard as worst-case bounds suggest them to be.",Broader Impact,138,6,,,FALSE,FALSE,FALSE,Improved guarantees and a multiple-descent curve for Column Subset Selection and the Nystrom method,Theory -> Computational Learning Theory,Optimization -> Discrete Optimization,Theory (including computational and statistical analyses),"['Michal Derezinski', ' Rajiv Khanna', ' Michael W Mahoney']","{'UC Berkeley', 'University of California, Berkeley'}",1,0,0,{'USA'}
Domain Adaptation as a Problem of Inference on Graphical Models,"Kun Zhang, Mingming Gong, Petar Stojanov, Biwei Huang, QINGSONG LIU, Clark Glymour",Domain Adaptation as a Problem of Inference on Graphical Models,3430095c577593aad3c39c701712bcfe,https://proceedings.neurips.cc/paper/2020/file/3430095c577593aad3c39c701712bcfe-Paper.pdf,"Domain adaptation aims to learn predictive models that can generalize to new domains that have different distribution than the training distributions. It is an essential step towards more generalizable and adaptive learning paradigms. We propose a brand new domain adaptation framework based on the graphical model that encodes conditional independence as well as distribution change properties. Our framework will inspire more effective DA algorithms that take advantage of the underlying data generating process. Open source algorithms and codes will benefit science, society, and the economy internationally through the further applications to analyzing social, business, and health data. The research may greatly benefit practitioners in industry communities, where large amounts of unlabeled and heterogeneous data are ubiquitous. It will greatly save the expenses to label new datasets once some characteristics of the data changes. For example, a disease diagnosis model can be easily adapted to new hospitals without much labeling effort. A possible negative effect is that data annotators may lose their job. The proposed method does not leverage any bias in the data.",Broader Impact,173,10,,,FALSE,FALSE,FALSE,Domain Adaptation as a Problem of Inference on Graphical Models,Probabilistic Methods -> Causal Inference,Algorithms -> Multitask and Transfer Learning; Algorithms -> Semi-Supervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Kun Zhang', ' Mingming Gong', ' Petar Stojanov', ' Biwei Huang', ' QINGSONG LIU', ' Clark Glymour']","{'Carnegie Mellon Univerisity', 'CMU', 'University of Melbourne', 'Carnegie Mellon University'}",1,0,0,"{'Australia', 'USA'}"
Network size and size of the weights in memorization with two-layers neural networks,"Sebastien Bubeck, Ronen Eldan, Yin Tat Lee, Dan Mikulincer",Network size and weights size for memorization with two-layers neural networks,34609bdc08a07ace4e1526bbb1777673,https://proceedings.neurips.cc/paper/2020/file/34609bdc08a07ace4e1526bbb1777673-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader impact,9,1,TRUE,FALSE,TRUE,TRUE,FALSE,Network size and size of the weights in memorization with two-layers neural networks,Theory -> Spaces of Functions and Kernels,Theory -> Computational Learning Theory,Theory (including computational and statistical analyses),"['Sebastien Bubeck', ' Ronen Eldan', ' Yin Tat Lee', ' Dan Mikulincer']","{'UW', 'Weizmann', 'Institute Weizmann', 'Microsoft Research'}",1,1,1,{'USA'}
Certifying Strategyproof Auction Networks,"Michael Curry, Ping-yeh Chiang, Tom Goldstein, John Dickerson",Certifying Strategyproof Auction Networks,3465ab6e0c21086020e382f09a482ced,https://proceedings.neurips.cc/paper/2020/file/3465ab6e0c21086020e382f09a482ced-Paper.pdf,"The immediate social impact of this work will likely be limited. Learned auction mechanisms are of interest to people who care about auction theory, and may eventually be used as part of the design of auctions that will be deployed in practice, but this has not yet happened to our knowledge. We note, however, that the design of strategyproof mechanisms is often desirable from a social good standpoint. Making the right move under a non-strategyproof mechanism may be difficult for real-world participants who are not theoretical agents with unbounded computational resources. The  mechanism may impose a real burden on them: the cost of figuring out the correct move. By contrast, a strategyproof mechanism simply requires truthful reports—no burden at all. Moreover, the knowledge and ability to behave strategically may not be evenly distributed, with the result that under non-strategyproof mechanisms, the most sophisticated participants may game the system to their own benefit. This has happened in practice: in Boston, some parents were able to game the school choice assignment system by misreporting their preferences, while others were observed not to do this; on grounds of fairness, the system was replaced with a redesigned strategyproof mechanism Abdulkadiroglu et al. [2006]. Thus, we believe that in general, the overall project of strategyproof mechanism design is likely to have a positive social impact, both in terms of making economic mechanisms easier to participate in and ensuring fair treatment of participants with different resources, and we hope we can make a small contribution to it.",Broader Impact,251,10,,,FALSE,FALSE,FALSE,Certifying Strategyproof Auction Networks,Theory -> Game Theory and Computational Economics,Algorithms -> Adversarial Learning; Optimization -> Discrete Optimization,"Other applications (e.g., robotics, biology, climate, finance)","['Michael Curry', 'yeh Chiang', ' Tom Goldstein', ' John Dickerson']","{'University of Maryland, College Park', 'University of Maryland College Park', 'University of Maryland'}",1,0,0,{'USA'}
Continual Learning of Control Primitives : Skill Discovery via Reset-Games,"Kelvin Xu, Siddharth Verma, Chelsea Finn, Sergey Levine",Continual Learning of Control Primitives: Skill Discovery via Reset-Games,3472ab80b6dff70c54758fd6dfc800c2,https://proceedings.neurips.cc/paper/2020/file/3472ab80b6dff70c54758fd6dfc800c2-Paper.pdf,"The central goal of reinforcement learning is to allow agents to autonomously acquire complex behavior from interacting with the world. The central focus on this work is to address challenges in the deployment of reinforcement learning in the real world, where all learning is continual and sample efficient is important. We introduce our approach to remove the assumption of an oracle reset function and to allow the agent to simultaneously acquire temporal abstraction. In order to maximally benefit from deploying reinforcement learning agents in the real world, these challenges must be address by one method or another. Nevertheless, as the underlying goal of our research in reinforcement learning is to enable the automatic acquisition of complex behavior, we consider the societal impact of our research to be closely related to automation. While the broader impact of having increased automation is difficult to predict, it is likely to have both negative and positive consequences. Having agents that can be deployed in unstructured environments could have the potential to automate dangerous tasks, but also could be result in more complex consequences, including changes in the employment landscape, and potential for harmful applications such as autonomous weapons.",Broader Impact Statement,194,7,,,FALSE,FALSE,FALSE,Continual Learning of Control Primitives : Skill Discovery via Reset-Games,Reinforcement Learning and Planning,,Reinforcement learning and planning,,"{'UC Berkeley', 'Stanford'}",1,0,0,{'USA'}
HOI Analysis: Integrating and Decomposing Human-Object Interaction,"Yong-Lu Li, Xinpeng Liu, Xiaoqian Wu, Yizhuo Li, Cewu Lu",HOI Analysis: Integrating and Decomposing Human-Object Interaction,3493894fa4ea036cfc6433c3e2ee63b0,https://proceedings.neurips.cc/paper/2020/file/3493894fa4ea036cfc6433c3e2ee63b0-Paper.pdf,"In this work, we propose a novel paradigm for Human-Object Interaction detection, which would promote human activity understanding. Our work could be useful for vision applications, such as the health care system in an intelligent hospital. Current activity understanding systems are usually computationally expensive and require high computational resources, and could cost many financial and environmental resources. Considering this, we will release our code and trained models to the community, as part of efforts to alleviate the repeated training of future works.",Broader Impact,82,4,,,FALSE,FALSE,FALSE,HOI Analysis: Integrating and Decomposing Human-Object Interaction,Applications -> Activity and Event Recognition,Applications -> Computer Vision; Neuroscience and Cognitive Science -> Perception,Vision,"['Lu Li', ' Xinpeng Liu', ' Xiaoqian Wu', ' Yizhuo Li', ' Cewu Lu']","{'Shanghai Jiaotong University', 'Shanghai Jiao Tong University'}",1,0,0,{'China'}
Strongly local p-norm-cut algorithms for semi-supervised learning and local graph clustering,"Meng Liu, David F. Gleich",Strongly local p-norm-cut algorithms for semi-supervised learning and local graph clustering,3501672ebc68a5524629080e3ef60aef,https://proceedings.neurips.cc/paper/2020/file/3501672ebc68a5524629080e3ef60aef-Paper.pdf,"Our research fits into a general theme of extracting latent or hidden information and finding groups in data. This has a number of potential impacts – positive and negative – depending on how it is used. We begin with the positive. First, we note that finding clusters in networks is critical to reducing bias on measuring interventions with network effects [14]. Having more flexible and better ways of doing this clustering will improve our ability to assess treatments on networks. Second, these techniques enable powerful methods that allow us to understand scientific data in a variety of forms including neuroscience [64], astronomy [36], and biology [40]. For instance, the latter reference suggests putative therapeutics based on latent relationships between diseases and existing chemical compounds. This has a number of wide ranging benefits. In terms of negative outcomes (note that we intentionally omit references to ideas here due to the negative possibilities), these techniques could be deployed to attempt to reveal intentionally hidden and sensitive attributes in social network data. As a weak example, similar techniques are used to suggest new contacts on social networks and recommendation systems – if these involve a sensitive cluster of individuals, this has the potential to expose sensitive information. They can also be used to help de-anonymize network information through network alignment techniques. These methods utilize a bias in the data in the form of network edges sharing attributes.",Broader Impact,234,12,,,FALSE,FALSE,FALSE,Strongly local p-norm-cut algorithms for semi-supervised learning and local graph clustering,Algorithms -> Clustering,Algorithms -> Semi-Supervised Learning; Applications -> Network Analysis; Optimization -> Convex Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Meng Liu', ' David Gleich']",{'Purdue University'},1,0,0,{'USA'}
Deep Direct Likelihood Knockoffs,"Mukund Sudarshan, Wesley Tansey, Rajesh Ranganath",Deep direct likelihood knockoffs,350a7f5ee27d22dbe36698b10930ff96,https://proceedings.neurips.cc/paper/2020/file/350a7f5ee27d22dbe36698b10930ff96-Paper.pdf,"There are several benefits to using flexible methods for identifying conditional independence like DDLK . Practitioners that care about transparency have traditionally eschewed deep learning, but methods like DDLK can present a solution. By performing conditional independence tests with deep networks and by providing guarantees on the false discovery rate, scientists and practitioners can develop more trust in their models. This can lead to greater adoption of flexible models in basic sciences, resulting in new discoveries and better outcomes for the beneficiaries of a deployed model. Conditional independence can also help detect bias from data, by checking if an outcome like length of stay in a hospital was related to a sensitive variable like race or insurance type, even when conditioning on many other factors. While we believe greater transparency can only be better for society, we note that interpretation methods for machine learning may not exactly provide transparency. These methods visualize only a narrow part of a model’s behavior, and may lead to gaps in understanding. Relying solely on these domain-agnostic methods could yield unexpected behavior from the model. As users of machine learning, we must be wary of too quickly dismissing the knowledge of domain experts. No interpretation technique is suitable for all scenarios, and different notions of transparency may be desired in different domains.",Broader Impact,217,10,,,FALSE,FALSE,FALSE,Deep Direct Likelihood Knockoffs,Deep Learning -> Generative Models,,Probabilistic methods and inference,"['Mukund Sudarshan', ' Wesley Tansey', ' Rajesh Ranganath']","{'New York University', 'Columbia University', 'NYU'}",1,0,0,{'USA'}
Meta-Neighborhoods,"Siyuan Shan, Yang Li, Junier B. Oliva",Meta-Neighborhoods,35464c848f410e55a13bb9d78e7fddd0,https://proceedings.neurips.cc/paper/2020/file/35464c848f410e55a13bb9d78e7fddd0-Paper.pdf,"Any general discriminative machine learning model runs the risk of making biased and offensive predictions reflective of training data. Our work is no exception as it aims at improving discriminative learning performance. To reduce these negative influences to the minimum possible extent, we only use standard benchmarks in this work, such as CIFAR-10, Tiny-ImageNet, MNIST, and datasets from the UCI machine learning repository. Our work does impose some privacy concerns as we are learning a per-instance adjusted model in this work. Potential applications of the proposed model include precision medicine, personalized recommendation systems, and personalized driver assistance systems. To keep user data safe, it is desirable to only deploy our model locally. The induced neighbors in our work, which are semantically meaningful, can also be regarded as fake synthetic data. Like DeepFakes, they may also raise a set of challenging policy, technology, and legal issues. Legislation regarding synthetic data should take effect and the research community needs to develop effective methods to detect these synthetic data.",Broader Impact,166,9,,,TRUE,TRUE,FALSE,Meta-Neighborhoods,Algorithms -> Meta-Learning,Algorithms -> Classification; Algorithms -> Regression; Deep Learning -> Attention Models; Deep Learning -> Memory-Augmented Neural Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Siyuan Shan', ' Yang Li', ' Junier Oliva']","{'UNC Chapel Hill', 'UNC-Chapel Hill', 'UNC - Chapel Hill'}",1,0,0,"{'Canada', 'USA'}"
Neural Dynamic Policies for End-to-End Sensorimotor Learning,"Shikhar Bahl, Mustafa Mukadam, Abhinav Gupta, Deepak Pathak",Neural Dynamic Policies for End-to-End Sensorimotor Learning,354ac345fd8c6d7ef634d9a8e3d47b83,https://proceedings.neurips.cc/paper/2020/file/354ac345fd8c6d7ef634d9a8e3d47b83-Paper.pdf,"We attempt to create algorithms that empower robotic agents to do complex and long-horizon tasks. However, before our algorithms are deployed in the real world, we must consider how safely our work can interact with humans and their surroundings. We believe that the structured imposed by our method ensures not ensures not only smoother and thus lower risk exploration, but also a larger degree of interpretability of the algorithm. A higher degree of interpretability it is easier reason about how our algorithms will interact with humans, and thus we can operate robots in the wild, in a safer manner. There are many possible applications of robotics including assembly and manufacturing, medicine, search and rescue, autonomous vehicles and transportation, and slowly moving towards personal robotics. A method that provides safe and efficient real world robotic can have a positive impact by advancing by increasing the quality of assembly lines, minimizing failure in factories, creating more robust search and rescue robots, increasing the flexibility of personal robotics, especially in the case of assistive robots. More efficient automation also has economic benefits and has the potential to save energy resources (using less power to do the same tasks). On the other hand, we must consider negative consequences increased automation, from the the misuse of such technology to the vulnerability of it to external software attacks, to an increase in unemployment.",Broader Impact,227,8,,,FALSE,FALSE,FALSE,Neural Dynamic Policies for End-to-End Sensorimotor Learning,Applications -> Motor Control,Algorithms -> Dynamical Systems; Applications -> Robotics; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Shikhar Bahl', ' Mustafa Mukadam', ' Abhinav Gupta', ' Deepak Pathak']","{'Facebook AI Research', 'Facebook AI Research/CMU', 'Carnegie Mellon University'}",1,1,1,{'USA'}
A new inference approach for training shallow and deep generalized linear models of noisy interacting neurons,"Gabriel Mahuas, Giulio Isacchini, Olivier Marre, Ulisse Ferrari, Thierry Mora",A new inference approach for training shallow and deep generalized linear models of noisy interacting neurons,356dc40642abeb3a437e7e06f178701c,https://proceedings.neurips.cc/paper/2020/file/356dc40642abeb3a437e7e06f178701c-Paper.pdf,"In this work we present a computational advance to improve the inference and performance of the GLM. As the GLM is one of the most used models in computational neuroscience, we believe that many researchers can benefit from this work to advance in their investigations. The fight against blindness, which affects about 45 millions people worldwide, is one of such possible applications. Retinal prostheses, where an array of stimulating electrodes is used to evoke activity in neurons, are a promising solution currently under clinical investigation. A central challenge for such implants is to improve the information that is sent to the brain. A central challenge for retinal implants is thus to mimic the computations carried out by a healthy retina to optimize information sent to the brain. Modeling retinal processing could thus help optimize vision restoration strategies in the long term [29]. We believe that no one will be put at disadvantage from this research, that there are no consequences of failure of the system. Biases in the data do not apply to the present context.",Broader Impact,176,9,,,FALSE,FALSE,FALSE,A new inference approach for training shallow and deep generalized linear models of noisy interacting neurons,Neuroscience and Cognitive Science,Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Spike Train Generation; Neuroscience and Cognitive Science -> Visual Perception; Probabilistic Methods -> Graphical Models; Theory -> Models of Learning and Generalization,Neuroscience and cognitive science,"['Gabriel Mahuas', ' Giulio Isacchini', ' Olivier Marre', ' Ulisse Ferrari', ' Thierry Mora']","{'ENS', 'Institut de la vision', 'Universite Pier et Marie Curie', 'Max Planck Institute for Dynamics and Selforganisation'}",1,0,0,"{'France', 'Germany'}"
Decision-Making with Auto-Encoding Variational Bayes,"Romain Lopez, Pierre Boyeau, Nir Yosef, Michael Jordan, Jeffrey Regier",Decision-Making with Auto-Encoding Variational Bayes,357a6fdf7642bf815a88822c447d9dc4,https://proceedings.neurips.cc/paper/2020/file/357a6fdf7642bf815a88822c447d9dc4-Paper.pdf,"The method we propose allows practitioners to make better decisions based on data. This capability may improve decisions about topics as diverse as differential expression in biological data, supply chain inventory and pricing, and personalized medicine treatments. However, the black-box nature of neural networks—a key aspect of our approach—confers both benefits and risks. For data without a simple parametric distribution, neural networks allow us to fit a model accurately, so that we can make decisions in a rigorous data-driven way without recreating prior biases. However, it can be difficult to check the quality of the model fit, particularly when worst-case analysis is appropriate, e.g., in mission-critical applications. In VAE-style architectures, powerful decoder networks are associated with posterior collapse, which could go undetected. More research is needed to ensure the worst-case performance of VAE-style models and/or to diagnosis fit problems before they are used in high-stakes decision-making scenarios.",Broader impact,147,7,,,FALSE,FALSE,FALSE,Decision-Making with Auto-Encoding Variational Bayes,Probabilistic Methods -> Variational Inference,Deep Learning -> Generative Models,Probabilistic methods and inference,"['Romain Lopez', ' Pierre Boyeau', ' Nir Yosef', ' Michael Jordan', ' Jeffrey Regier']","{'UC Berkeley', 'University of Michigan'}",1,0,0,{'USA'}
Attribution Preservation in Network Compression for Reliable Network Interpretation,"Geondo Park, June Yong Yang, Sung Ju Hwang, Eunho Yang",Attribution Preservation in Network Compression for Reliable Network Interpretation,35adf1ae7eb5734122c84b7a9ea5cc13,https://proceedings.neurips.cc/paper/2020/file/35adf1ae7eb5734122c84b7a9ea5cc13-Paper.pdf,"In the paper, we brought up the attribution deformation problem in compressed networks, and a novel method to combat this issue. As discussed in Section 1, we believe that people trying to deploy deep learning models to safety-critical fields must be aware of this finding to ensure the reliability and trustworthiness of the system. To this end, we may think of a possible scenario. Suppose that a CNN classifier vision module trained with our matching regularizer is utilized in a self-driving system. In case of an accident, we may inspect the records of the deep learning module to learn the decision that caused the accident. In this situation, the model trained with our regularizer will provide more accurate attribution, leading to a cleaner and more just assessment. However, the sense of attributional safety presented by our method can give a false sense of security and blind trust towards the system and its interpretations, while by no means the system is flawless. For example, a wearable health monitor might predict a person to be healthy, and provide its supporting explanations. If these explanations are blindly trusted, while they are wrong underneath the surface, the user might take reactive measures that are ultimately bad for oneself.",Broader Impact,204,9,,,FALSE,FALSE,FALSE,Attribution Preservation in Network Compression for Reliable Network Interpretation,"Deep Learning -> Visualization, Interpretability, and Explainability",,Deep learning,"['Geondo Park', ' June Yong Yang', ' Sung Ju Hwang', ' Eunho Yang']","{'KAIST, AITRICS', 'Korea Advanced Institute of Science and Technology'}",1,1,1,{'South Korea'}
Feature Importance Ranking for Deep Learning,"Maksymilian Wojtas, Ke Chen",Feature Importance Ranking for Deep Learning,36ac8e558ac7690b6f44e2cb5ef93322,https://proceedings.neurips.cc/paper/2020/file/36ac8e558ac7690b6f44e2cb5ef93322-Paper.pdf,"This research does not involve any issues directly regarding ethical aspects and future societal consequences. In the future, our approach presented in this paper might be applied in different domains, e.g., medicine and life science, where ethical aspects and societal consequences might have to be considered.",Broader Impact,46,2,TRUE,TRUE,FALSE,FALSE,FALSE,Feature Importance Ranking for Deep Learning,Deep Learning,"Deep Learning -> Supervised Deep Networks; Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,"['Maksymilian Wojtas', ' Ke Chen']","{'University of Manchester', 'The University of Manchester'}",1,0,0,{'UK'}
Causal Estimation with Functional Confounders,"Aahlad Puli, Adler Perotte , Rajesh Ranganath",Causal Estimation with Functional Confounders,36dcd524971019336af02550264b8a08,https://proceedings.neurips.cc/paper/2020/file/36dcd524971019336af02550264b8a08-Paper.pdf,"Our work mainly applies to causal inference where confounders are specified as functions of observed data, such as in problems in genetics and healthcare. We choose to assess the impact of our work through its applications in these fields. A positive impact of the work is that better estimates of causal effects helps guide treatment for people and aid in understanding biological pathways of diseases. However, in healthcare, data collected in hospitals has biases. If, for instance, a certain demographic of people have more complete data collected about them, then this demographic would have better quality effect estimates, potentially meaning that they receive better treatment. This problem could be characterized by evaluating the positivity of treatment and completeness of confounders in electronic health record data split by demographics.",Broader Impact,128,6,,,FALSE,FALSE,FALSE,Causal Estimation with Functional Confounders,Probabilistic Methods -> Causal Inference,,Causality,"['Aahlad Manas Puli', ' Adler Perotte', ' Rajesh Ranganath']","{'New York University', 'Columbia University', 'NYU'}",1,0,0,{'USA'}
Model Inversion Networks for Model-Based Optimization,"Aviral Kumar, Sergey Levine",Model Inversion Networks for Model-Based Optimization,373e4c5d8edfa8b74fd4b6791d0cf6dc,https://proceedings.neurips.cc/paper/2020/file/373e4c5d8edfa8b74fd4b6791d0cf6dc-Paper.pdf,"In this work we introduced model-inversion networks (MIN), a novel approach to model-based optimization, which can be utilized for solving both passive “data-driven” optimization problems  and active model-based optimization problems. Model-based optimization is a generic black-box optimization framework that captures a wide range of practically interesting and highly relevant optimization problems, such as drug discovery, controller design, and optimization in computer systems. In this work, we demonstrate the efficacy of MINs in high dimensional optimization problems, from complex input types (raw pixels, raw neural network weights, protein sequences). We are particularly excited about application of MINs in the domain of drug design and discovery, and other computational biology domains. The importance of the problem of drug design needs no motivation or justification, especially in these times of this pandemic that mankind is facing now. Existing methods in place for these problems typically follow an “active” experimental pipeline – the designs proposed by an ML or computational model are evaluated in real life, and then the results of these evaluations are incorporated into further model training or model improvement. Often the evaluation phase is the bottleneck: this phase is highly expensive both in terms of computational resources and time, often requiring human intervention, and in some cases, taking months of time. We can avoid these bottlenecks by instead solving such optimization problems to the best possible extent in the static data-driven setting, by effectively reusing both good and bad data from past experiments, and MINs are designed to be efficient at exactly this. Beyond the field of biology, there are several other applications for which our proposed method is relevant. Design problems in engineering, such as design of aircraft, are potential applications of our method. There are also likely to be applications in computer systems and architectures. While effective model-based optimization algorithms can have considerable positive economic and technological growth effects, it can also enable applications with complex implications with regards to safety and privacy (for example, safety issues in drug design or aircraft design, or privacy issues in computer systems optimization), as well as in terms of complex economic effects for example, changing job requirements and descriptions, due to automation of certain tasks. Both of these implications are not unique to our method, but more generally apply to situations where black box autonomous neural network models are deployed in practice.",Broader Impact,390,13,,,FALSE,FALSE,FALSE,Model Inversion Networks for Model-Based Optimization,Applications,Deep Learning -> Generative Models,Deep learning,"['Aviral Kumar', ' Sergey Levine']",{'UC Berkeley'},1,0,0,{'USA'}
"Hausdorff Dimension, Heavy Tails, and Generalization in Neural Networks","Umut Simsekli, Ozan Sener, George Deligiannidis, Murat A. Erdogdu","Hausdorff Dimension, Heavy Tails, and Generalization in Neural Networks",37693cfc748049e45d87b8c7d8b9aacd,https://proceedings.neurips.cc/paper/2020/file/37693cfc748049e45d87b8c7d8b9aacd-Paper.pdf,"Our work is largely theoretical, studying the generalization properties of deep networks. Our results suggest that the fractal structure and the fractal dimensions of deep learning models can be an accurate metric for the generalization error; hence, in a broader context, we believe that our theory would be useful for practitioners using deep learning tools. On the other hand, our work does not have a direct ethical or societal consequence due to its theoretical nature.",Broader Impact,75,3,,,FALSE,FALSE,FALSE,"Hausdorff Dimension, Heavy Tails, and Generalization in Neural Networks",Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Umut Simsekli', ' Ozan Sener', ' George Deligiannidis', ' Murat Erdogdu']","{'Oxford', 'Institut Polytechnique de Paris/ University of Oxford', 'Intel Labs', 'University of Toronto'}",1,1,1,"{'Canada', 'UK', 'France', 'USA'}"
Exact expressions for double descent and implicit regularization via surrogate random design,"Michal Derezinski, Feynman T. Liang, Michael W. Mahoney",Exact expressions for double descent and implicit regularization via surrogate random design,37740d59bb0eb7b4493725b2e0e5289b,https://proceedings.neurips.cc/paper/2020/file/37740d59bb0eb7b4493725b2e0e5289b-Paper.pdf,"While the double descent phenomenon has been empirically observed in a variety of applications, mathematical descriptions of it are oftentimes complex and inaccesible to non-experts. In contrast, our surrogate design and the accompanying closed-form expressions provide an easily computable rule of thumb for estimating the generalization error. One important application is the high-dimensional (i.e. underdetermined, n < d ) regime experienced by modern machine learning systems where the number of parameters vastly exceeds the quantity of available data. Our research can be applied here to provide a theoretical understanding of the surprising phenomenon where without proper regularization [NVKM20] more data (i.e. increasing n ) may lead to worse generalization performance. Better theoretical understanding of generalization error in the small data regime has important societal impact. Through theoretically modeling a system’s performance, we can build safer systems by better understanding how badly an estimator fails and accounting for these failure modes in the system’s design. Furthermore, the improved understanding of minimum norm solutions performing worse with more data offers an appealing trade-off where certain systems can both improve their performance and respect the privacy of its users by collecting less data.",Broader Impact,190,7,,,TRUE,TRUE,FALSE,Exact expressions for double descent and implicit regularization via surrogate random design,Theory -> Statistical Learning Theory,Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Michal Derezinski', ' Feynman T Liang', ' Michael W Mahoney']","{'UC Berkeley', 'Berkeley'}",1,0,0,{'USA'}
Certifying Confidence via Randomized Smoothing,"Aounon Kumar, Alexander Levine, Soheil Feizi, Tom Goldstein",Certifying Confidence via Randomized Smoothing,37aa5dfc44dddd0d19d4311e2c7a0240,https://proceedings.neurips.cc/paper/2020/file/37aa5dfc44dddd0d19d4311e2c7a0240-Paper.pdf,"We design procedures that equip randomized smoothing with certified prediction confidence, an important property for any real-world decision-making system to have. In applications where robustness is key, like credit scoring and disease diagnosis systems, it is important to know how certain the prediction model is about the output, so that a human expert can take over if the model’s confidence is low. However, this method does not produce any guarantees on the calibration of the underlying model itself. It could happen that the confidence measure used to determine the degree of certainty of the model does not actually reflect the probability of the prediction being correct. In other words, our methods depends on the underlying classifier to have high accuracy to perform reliably. With certificates, there is always a risk of conveying a false sense of confidence, but hopefully by producing interpretable risk scores along with certificates our work will help mitigate this problem.",7 Broader Impact,154,6,,,FALSE,FALSE,FALSE,Certifying Confidence via Randomized Smoothing,Algorithms -> Adversarial Learning,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Deep learning,"['Aounon Kumar', ' Alexander Levine', ' Soheil Feizi', ' Tom Goldstein']","{'University of Maryland, College Park', 'University of Maryland'}",1,0,0,{'USA'}
Learning Physical Constraints with Neural Projections,"Shuqi Yang, Xingzhe He, Bo Zhu",Learning Physical Constraints with Neural Projections,37bc5e7fb6931a50b3464ec66179085f,https://proceedings.neurips.cc/paper/2020/file/37bc5e7fb6931a50b3464ec66179085f-Paper.pdf,This research constitutes a technical advance by employing constraint projection operations to enhance the prediction capability of physical systems with unknown dynamics. It opens up new possibilities to effectively and intuitively represent complicated physical systems from direct and limited observation. This research blend the borders among the communities of machine learning and fast physics simulations in computer graphics and gaming industry. Our model does not necessarily bring about any significant ethical considerations.,Broader Impact,72,4,,,FALSE,FALSE,FALSE,Learning Physical Constraints with Neural Projections,Algorithms,Algorithms -> Dynamical Systems,"Other applications (e.g., robotics, biology, climate, finance)","['Shuqi Yang', ' Xingzhe He', ' Bo Zhu']",{'Dartmouth College'},1,0,0,{'USA'}
Robust Optimization for Fairness with Noisy Protected Groups,"Serena Wang, Wenshuo Guo, Harikrishna Narasimhan, Andrew Cotter, Maya Gupta, Michael Jordan",Robust Optimization for Fairness with Noisy Protected Groups,37d097caf1299d9aa79c2c2b843d2d78,https://proceedings.neurips.cc/paper/2020/file/37d097caf1299d9aa79c2c2b843d2d78-Paper.pdf,"As machine learning is increasingly employed in high stakes environments, any potential application has to be scrutinized to ensure that it will not perpetuate, exacerbate, or create new injustices. Aiming to make machine learning algorithms themselves intrinsically fairer, more inclusive, and more equitable plays an important role in achieving that goal. Group-based fairness [32, 25] is a popular approach that the machine learning community has used to define and evaluate fair machine learning algorithms. Until recently, such work has generally assumed access to clean, correct protected group labels in the data. Our work addresses the technical challenge of enforcing group-based fairness criteria under noisy, unreliable, or outdated group information. However, we emphasize that this technical improvement alone does not necessarily lead to an algorithm having positive societal impact, for reasons that we now delineate.",Broader Impact,134,6,,,FALSE,FALSE,FALSE,Robust Optimization for Fairness with Noisy Protected Groups,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Optimization,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Serena Wang', ' Wenshuo Guo', ' Harikrishna Narasimhan', ' Andrew Cotter', ' Maya Gupta', ' Michael Jordan']","{'Google', 'UC Berkeley', 'Google Research'}",1,1,1,{'USA'}
Noise-Contrastive Estimation for Multivariate Point Processes,"Hongyuan Mei, Tom Wan, Jason Eisner",Noise-Contrastive Estimation for Multivariate Point Processes,37e7897f62e8d91b1ce60515829ca282,https://proceedings.neurips.cc/paper/2020/file/37e7897f62e8d91b1ce60515829ca282-Paper.pdf,"Our method is designed to train a multivariate point process for probabilistic modeling of event streams. By describing this method and releasing code, we hope to facilitate probabilistic modeling of continuous-time sequential data in many domains. Good probabilistic models make it possible to impute missing events, anticipate possible future events, and react accordingly. They can also be used in exploratory data analysis. In addition to making it more feasible and more convenient for domain experts to train complex models with many event types, our method reduces the energy cost necessary to do so. Examples of event streams with potential social impact include a person’s detailed food/exercise/sleep/medical event log, their social media interactions, their interactions with educational exercises or games, or their educational or workplace events (for time management and career planning); a customer’s interactions with a particular company or its website or other user interface; a company’s sales and purchases; geopolitical events, financial events, human activity modeling, music modeling, and dynamic resource requests. We are not aware of any negative broader impacts that might stem from publishing this work.",Broader Impact,179,7,,,FALSE,FALSE,FALSE,Noise-Contrastive Estimation for Multivariate Point Processes,Applications -> Time Series Analysis,Algorithms -> Density Estimation; Algorithms -> Stochastic Methods; Deep Learning -> Generative Models; Optimization -> Stochastic Optimization,Probabilistic methods and inference,"['Hongyuan Mei', ' Tom Wan', ' Jason Eisner']",{'JOHNS HOPKINS UNIVERSITY'},1,0,0,{'USA'}
A Game-Theoretic Analysis of the Empirical Revenue Maximization Algorithm with Endogenous Sampling,"Xiaotie Deng, Ron Lavi, Tao Lin, Qi Qi, Wenwei WANG, Xiang Yan",A Game-Theoretic Analysis of the Empirical Revenue Maximization Algorithm with Endogenous Sampling,37e79373884f0f0b70b5cb91fb947148,https://proceedings.neurips.cc/paper/2020/file/37e79373884f0f0b70b5cb91fb947148-Paper.pdf,"This work is mainly theoretical. It provides some intuitions and guidelines for potential practices, but does not have immediate societal consequences. A possible positive consequence is: the auction we consider uses an anonymous reserve price, while most of the related works on repeated auctions use unfair personalized prices. We do not see negative consequences.",Broader Impact,54,4,TRUE,TRUE,FALSE,FALSE,FALSE,A Game-Theoretic Analysis of the Empirical Revenue Maximization Algorithm with Endogenous Sampling,Theory -> Game Theory and Computational Economics,,Theory (including computational and statistical analyses),"['Xiaotie Deng', ' Ron Lavi', ' Tao Lin', ' Qi Qi', ' Wenwei WANG', ' Xiang Yan']","{'Alibaba Group', 'Hong Kong University of Science and Technology', 'Peking University', 'Technion', 'Shanghai Jiao Tong University'}",1,1,1,"{'China', 'Israel'}"
Neural Path Features and Neural Path Kernel : Understanding the role of gates in deep learning,"Chandrashekar Lakshminarayanan, Amit Vikram Singh",Neural Path Features and Neural Path Kernel : Understanding the role of gates in deep learning,37f76c6fe3ab45e0cd7ecb176b5a046d,https://proceedings.neurips.cc/paper/2020/file/37f76c6fe3ab45e0cd7ecb176b5a046d-Paper.pdf,"Deep neural networks are still widely regarded as blackboxes. The standard and accepted view on the inner workings of deep neural networks is the ‘layer-by-layer’ viewpoint: as the input progresses through the hidden layers, features at different levels of abstractions are learnt. This paper deviates from the standard ‘layer-by-layer’ viewpoint, in that, it breaks down the deep neural network blackbox into its constituent paths: different set of paths get fired for different inputs, and the output is the summation of the contribution from individual paths. This makes the inner workings of deep neural networks interpretable, i.e., each input is remembered in terms of the active sub-network of the paths that get ‘fired’ for that input, and learning via gradient descent amounts to ‘rewiring’ of the paths. The paper also analytically connects this sub-network and path based view to the recent kernel based interpretation of deep neural networks, and furthers the understanding of feature learning in deep neural networks. We believe that these better insights into the working of DNNs can potentially lead to foundational algorithmic development in the future.",9 Broader Impact,179,6,,,FALSE,FALSE,FALSE,Neural Path Features and Neural Path Kernel : Understanding the role of gates in deep learning,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Chandrashekar Lakshminarayanan', ' Amit Vikram Singh']","{'Indian Institute of Technology, Palakkad', 'Indian Institute Of Technology, Palakkad'}",1,0,0,{'India'}
Multiscale Deep Equilibrium Models,"Shaojie Bai, Vladlen Koltun, J. Zico Kolter",Multiscale Deep Equilibrium Models,3812f9a59b634c2a9c574610eaba5bed,https://proceedings.neurips.cc/paper/2020/file/3812f9a59b634c2a9c574610eaba5bed-Paper.pdf,"Computer vision techniques themselves, which are the primary application focus on this paper, have numerous applications of both positive and negative societal benefits. They can enable potentially live-saving advances in e.g., assisted driving, medical diagnoses, etc, but also have inherent limitations and biases that could lead to problematic applications in these areas (e.g., if performance of a vision model notably differs when given input images of people of different races or genders); and this says nothing of more genuinely problematic enabled applications, such as facial recognition for surveillance applications. The question of more relevance to this paper, however, is whether there any societal-level consequences that are unique to this particular algorithmic approach, i.e., the use of implicit versus explicit models in computer vision domains. This point is genuinely less clear to us. It is possible that the relative memory-efficiency of implicit vision models would make them e.g., more amenable to edge devices, which in turn contribution raises the potential for both beneficial and harmful use cases. However, this is a large leap from current methods, where the improved memory efficiency comes at a cost of increased compute time (and thus could arguably be less efficient in their current form on edge devices). Thus, we believe the specific impacts of implicit models are still unclear at this point, and should largely be re-evaluated as the models become more standard or more widely adopted.",Broader Impacts,232,7,,,FALSE,FALSE,FALSE,Multiscale Deep Equilibrium Models,Deep Learning,Deep Learning -> CNN Architectures; Deep Learning -> Optimization for Deep Networks; Deep Learning -> Supervised Deep Networks,Deep learning,"['Shaojie Bai', ' Vladlen Koltun', ' Zico Kolter']","{'Intel Labs', 'Carnegie Mellon University', 'Carnegie Mellon University / Bosch Center for AI'}",1,1,1,"{'USA', 'Germany'}"
Sparse Graphical Memory for Robust Planning,"Scott Emmons, Ajay Jain, Misha Laskin, Thanard Kurutach, Pieter Abbeel, Deepak Pathak",Sparse Graphical Memory for Robust Planning,385822e359afa26d52b5b286226f2cea,https://proceedings.neurips.cc/paper/2020/file/385822e359afa26d52b5b286226f2cea-Paper.pdf,"Interpretability To build trust in deep RL systems, users would, ideally, be able to interrogate the system: “What is the deep RL system going to do? Why?” With state-of-the-art model-free approaches such as proximal policy optimization [ 44], it is not possible to answer these questions – the policy network is a black box. The explicit graphical plans produced by SGM, in contrast, can provide a partial answer to these questions. The future nodes in a plan given by SGM indicate what it is attempting to do, and errors in an overall plan can be debugged by tracing them to individual faulty edges in the graph. For this reason, we see graphical planning methods such as SGM as advantageous for the trust and interpretability of deep RL systems relative to model-free methods. Safety SGM assumes that the agent’s only reward signal is an indication of whether or not the current state satisfies the goal. This problem formulation ignores potential damage that could be caused during the intermediate steps taken to reach the goal, which, depending on the application, could be significant. Designing an RL agent that can safely explore and reach goals in its environment is a fundamental challenge for the entire field. Real-world applications While methods for long-horizon RL are highly general, such as the method we present in this paper, the most immediate potential applications of our method are in robotics. Completely solving the problem formulation in this paper, long-horizon control from high- dimensional input with sparse reward, would have wide-sweeping impact across robotic applications.",Broader impact,257,10,,,FALSE,FALSE,FALSE,Sparse Graphical Memory for Robust Planning,Reinforcement Learning and Planning -> Planning,Neuroscience and Cognitive Science -> Memory; Reinforcement Learning and Planning -> Navigation; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Misha Laskin', ' Scott Emmons', ' Ajay Jain', ' Thanard Kurutach', ' Pieter Abbeel', ' Deepak Pathak']","{'UC Berkeley', 'Carnegie Mellon University', 'University of California Berkeley'}",1,0,0,{'USA'}
Second Order Optimality in Decentralized Non-Convex Optimization via Perturbed Gradient Tracking,"Isidoros Tziotis, Constantine Caramanis, Aryan Mokhtari",Second Order PAC-Bayesian Bounds for the Weighted Majority Vote,386854131f58a556343e056f03626e00,https://proceedings.neurips.cc/paper/2020/file/386854131f58a556343e056f03626e00-Paper.pdf,"Ensemble classifiers, in particular random forests, are among the most important tools in machine learning [Fernández-Delgado et al., 2014, Zhu, 2015], which are very frequently applied in practice [e.g., Chen and Guestrin, 2016, Hoch, 2015, Puurula et al., 2014, Stallkamp et al., 2012]. Our study provides generalization guarantees for random forests and a method for tuning the weights of individual trees within a forest, which can lead to even higher accuracies. The result is of high practical relevance. Given that machine learning models are increasingly used to make decisions that have a strong impact on society, industry, and individuals, it is important that we have a good theoretical understanding of the employed methods and are able to provide rigorous guarantees for their performance. And here lies the strongest contribution of the line of research followed in our study, in which we derive rigorous bounds on the generalization error of random forests and other ensemble methods for multiclass classification.",Broader impact,158,5,,,FALSE,FALSE,FALSE,Second Order Optimality in Decentralized Non-Convex Optimization via Perturbed Gradient Tracking,Optimization,Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Isidoros Tziotis', ' Constantine Caramanis', ' Aryan Mokhtari']",{'UT Austin'},1,0,0,{'USA'}
Dirichlet Graph Variational Autoencoder,"Jia Li, Jianwei Yu, Jiajin Li, Honglei Zhang, Kangfei Zhao, Yu Rong, Hong Cheng, Junzhou Huang",Dirichlet Graph Variational Autoencoder,38a77aa456fc813af07bb428f2363c8d,https://proceedings.neurips.cc/paper/2020/file/38a77aa456fc813af07bb428f2363c8d-Paper.pdf,"This work connects VAEs based graph generation and traditional graph research topic — balanced graph cut. As a sequence, researchers in drug design or molecule generation may benefit from this research, since the interpretation of deep learning based graph generation is worthwhile to be further explored.",Broader Impact,46,2,FALSE,FALSE,FALSE,FALSE,FALSE,Dirichlet Graph Variational Autoencoder,Deep Learning -> Deep Autoencoders,Deep Learning -> Generative Models; Probabilistic Methods -> Latent Variable Models,Graph learning,"['Jia Li', ' Jianwei Yu', ' Jiajin Li', ' Honglei Zhang', ' Kangfei Zhao', ' Yu Rong', ' Hong Cheng', ' Junzhou Huang']","{'University of Texas at Arlington / Tencent AI Lab', 'The Chinese University of Hong Kong', 'Georgia Institute of Technology', 'CUHK', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
Modeling Task Effects on Meaning Representation in the Brain via Zero-Shot MEG Prediction,"Mariya Toneva, Otilia Stretcu, Barnabas Poczos, Leila Wehbe, Tom M. Mitchell",Modeling Task Effects on Meaning Representation in the Brain via Zero-Shot MEG Prediction,38a8e18d75e95ca619af8df0da1417f2,https://proceedings.neurips.cc/paper/2020/file/38a8e18d75e95ca619af8df0da1417f2-Paper.pdf,Our work pursues questions about the function of an average person’s brain and makes contributions to basic science. We do not foresee a societal benefit or disadvantage to specific groups of people.,Broader Impact,32,2,TRUE,FALSE,FALSE,FALSE,FALSE,Modeling Task Effects on Meaning Representation in the Brain via Zero-Shot MEG Prediction,Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and Cognitive Science -> Brain Imaging; Neuroscience and Cognitive Science -> Language for Cognitive Science,Neuroscience and cognitive science,"['Mariya Toneva', ' Otilia Stretcu', ' Barnabas Poczos', ' Leila Wehbe', ' Tom Mitchell']",{'Carnegie Mellon University'},1,0,0,{'USA'}
Counterfactual Vision-and-Language Navigation: Unravelling the Unseen,"Amin Parvaneh, Ehsan Abbasnejad, Damien Teney, Qinfeng Shi, Anton van den Hengel",Counterfactual Vision-and-Language Navigation: Unravelling the Unseen,39016cfe079db1bfb359ca72fcba3fd8,https://proceedings.neurips.cc/paper/2020/file/39016cfe079db1bfb359ca72fcba3fd8-Paper.pdf,"Vision-and-language navigation is a significant step in realising practical robots that can interact and follow instructions. These robots have applications in a wide range of problems including but not limited to (1) the need for tools that can operate in risky environments that human presence is dangerous is more than ever (e.g. with the recent pandemic in the health centres); (2) assistant to individuals in need, e.g. blind and disabled; (3) agriculture and manufacturing where the labour- intensive jobs require instruction following robots; etc. Beyond the application of this paper to VLN, better generalisation in machine learning using a small training set is desired for improved performance and usability. This requires machine learning approaches that can anticipate what they might encounter when deployed. We believe counterfactuals provide a means for better utilisation of the training data, improved generalisation and even explain- ability. Counterfactuals, as were used in the paper, can provide more robust models that are safer to deploy since the sources of spurious bias are reduced. Moreover, these models are less prone to be affected by the bias (e.g. social) in the human-generated training data. This paper provides an early step in this direction by formalising the problem in a practical setting.",Broader Impact,203,8,,,FALSE,FALSE,FALSE,Counterfactual Vision-and-Language Navigation: Unravelling the Unseen,Applications -> Computer Vision,Applications -> Visual Question Answering,Vision,"['Amin Parvaneh', ' Ehsan Abbasnejad', ' Damien Teney', ' Qinfeng Shi', ' Anton van den Hengel']",{'University of Adelaide'},1,0,0,{'Australia'}
Robust Quantization: One Model to Rule Them All,"Moran Shkolnik, Brian Chmiel, Ron Banner, Gil Shomron, Yury Nahshan, Alex Bronstein, Uri Weiser",Robust Quantization: One Model to Rule Them All,3948ead63a9f2944218de038d8934305,https://proceedings.neurips.cc/paper/2020/file/3948ead63a9f2944218de038d8934305-Paper.pdf,"Deep neural networks take up tremendous amounts of energy, leaving a large carbon footprint. Quantization can improve energy efficiency of neural networks on both commodity GPUs and specialized accelerators. Robust quantization takes another step and create one model that can be deployed across many different inference chips avoiding the need to re-train it before deployment (i.e., reducing CO2 emissions associated with re-training).",Broader Impact,62,3,,,FALSE,FALSE,FALSE,Robust Quantization: One Model to Rule Them All,Deep Learning -> Efficient Inference Methods,Algorithms -> Classification; Algorithms -> Data Compression,quantization of NN,"['Moran Shkolnik', ' Brian Chmiel', ' Ron Banner', ' Artificial Intelligence Products Group', ' Gil Shomron', ' Yury Nahshan', ' Artificial Intelligence Products Group', ' Alex Bronstein', ' Uri Weiser']","{'Technion', 'Intel', 'Technion - Israel Institute of Technology', 'AIPG'}",1,1,1,"{'USA', 'Israel'}"
Enabling certification of verification-agnostic networks via memory-efficient semidefinite programming,"Sumanth Dathathri, Krishnamurthy Dvijotham, Alexey Kurakin, Aditi Raghunathan, Jonathan Uesato, Rudy R. Bunel, Shreya Shankar, Jacob Steinhardt, Ian Goodfellow, Percy S. Liang, Pushmeet Kohli",Enabling certification of verification-agnostic networks via memory-efficient semidefinite programming,397d6b4c83c91021fe928a8c4220386b,https://proceedings.neurips.cc/paper/2020/file/397d6b4c83c91021fe928a8c4220386b-Paper.pdf,"Our work enables verifying properties of verification-agnostic neural networks trained using procedures agnostic to any specification verification algorithm. While the present scalability of the algorithm does not allow it to be applied to SOTA deep learning models, in many applications it is vital to verify properties of smaller models running safety-critical systems (learned controllers running on embedded systems, for example). The work we have presented here does not address data related issues directly, and would be susceptible to any biases inherent in the data that the model was trained on. However, as a verification technique, it does not enhance biases present in any pre-trained model, and is only used as a post-hoc check. We do not envisage any significant harmful applications of our work, although it may be possible for adversarial actors to use this approach to verify properties of models designed to induce harm (for example, learning based bots designed to break spam filters or induce harmful behavior in a conversational AI system).",Broader Impact,164,5,,,FALSE,TRUE,FALSE,Enabling certification of verification-agnostic networks via memory-efficient semidefinite programming,Algorithms -> Adversarial Learning,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Deep learning,"['Sumanth Dathathri', ' Krishnamurthy Dvijotham', ' Alexey Kurakin', ' Aditi Raghunathan', ' Jonathan Uesato', ' Rudy Bunel', ' Shreya Shankar', ' Jacob Steinhardt', ' Ian Goodfellow', ' Percy Liang', ' Pushmeet Kohli']","{'Stanford University', 'Deepmind', 'Google Brain', 'DeepMind', 'UC Berkeley'}",1,1,1,"{'UK', 'USA'}"
Federated Accelerated Stochastic Gradient Descent,"Honglin Yuan, Tengyu Ma",Federated Accelerated Stochastic Gradient Descent,39d0a8908fbe6c18039ea8227f827023,https://proceedings.neurips.cc/paper/2020/file/39d0a8908fbe6c18039ea8227f827023-Paper.pdf,"This work proposes F ED A C , a principled acceleration of F ED A VG , which provably improves conver- gence speed and communication efficiency. Our theory and experiments suggest that F ED A C saves computational resources and reduces communication overhead, especially in the setting of abundant workers and infrequent communication. Our analysis could promote a better understanding of feder- ated / distributed optimization and acceleration theory. We expect F ED A C could be generalized to broader settings, e.g. , non-convex objective and/or heterogenous workers. The opportunity for privacy-preserving learning is another advantage of Federated Learning beyond parallelization, since the user data are kept local during learning. While we do not analyze the privacy guarantee in this work, we conjecture that F ED A C could potentially enjoy better privacy-preserving property since less communication is required to achieve the same accuracy. However, this intuition should be applied with caution for high-risk data until theoretical privacy guarantee is established.",Broader Impact,161,7,,,FALSE,FALSE,FALSE,Federated Accelerated Stochastic Gradient Descent,Optimization -> Stochastic Optimization,Algorithms -> Communication- or Memory-Bounded Learning; Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Honglin Yuan', ' Tengyu Ma']",{'Stanford University'},1,0,0,{'USA'}
Robust Density Estimation under Besov IPM Losses,"Ananya Uppal, Shashank Singh, Barnabas Poczos",Robust Density Estimation under Besov IPM Losses,39d4b545fb02556829aab1db805021c3,https://proceedings.neurips.cc/paper/2020/file/39d4b545fb02556829aab1db805021c3-Paper.pdf,"Since this work is of a theoretical nature, it is unlikely to disadvantage anyone or otherwise have significant negative consequences. One of the main contributions of this paper is to quantify the potential effects of misspecification biases on density estimation. Hence, the results in this paper may help researchers understand the potential effects of misspecification biases that can arise when invalid assumptions are made about the nature of the data generating process.",Broader Impact,72,3,,,FALSE,FALSE,FALSE,Robust Density Estimation under Besov IPM Losses,Algorithms -> Density Estimation,Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Ananya Uppal', ' Shashank Singh', ' Barnabas Poczos']","{'Google', 'Carnegie Mellon University'}",1,1,1,{'USA'}
An analytic theory of shallow networks dynamics for hinge loss classification,"Franco Pellegrini, Giulio Biroli",An analytic theory of shallow networks dynamics for hinge loss classification,3a01fc0853ebeba94fde4d1cc6fb842a,https://proceedings.neurips.cc/paper/2020/file/3a01fc0853ebeba94fde4d1cc6fb842a-Paper.pdf,"Given the purely theoretical scope of this paper, it does not seem to present any foreseeable societal consequence.",Broader Impact,18,1,TRUE,FALSE,FALSE,FALSE,FALSE,An analytic theory of shallow networks dynamics for hinge loss classification,Theory -> Statistical Physics of Learning,Theory -> Models of Learning and Generalization ; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Franco Pellegrini', ' Giulio Biroli']","{'École normale supérieure, Paris', 'ENS'}",1,0,0,{'France'}
Fixed-Support Wasserstein Barycenters: Computational Hardness and Fast Algorithm,"Tianyi Lin, Nhat Ho, Xi Chen, Marco Cuturi, Michael Jordan",Fixed-Support Wasserstein Barycenters: Computational Hardness and Fast Algorithm,3a029f04d76d32e79367c4b3255dda4d,https://proceedings.neurips.cc/paper/2020/file/3a029f04d76d32e79367c4b3255dda4d-Paper.pdf,"The problem of computing barycenter of probability measures has become increasingly important in several application domains, including physics, economics, machine learning, statistics, and data science. However, in these applications, the number of supports of the probability measures, such as images, can be very large. In this work, we study the fundamental hardness of the problem and propose efficient and scalable algorithm to solve for the fixed-support barycenters. Our work provides a new deterministic algorithm for computer scientists, physicists, economists, and statistician to tackle computationally expensive problems in their application domains and poten- tially accelerate scientific discoveries. We do not foresee any negative impact to society from our work.",Broader Impact,108,5,,,FALSE,FALSE,FALSE,Fixed-Support Wasserstein Barycenters: Computational Hardness and Fast Algorithm,Theory -> Data-driven Algorithm Design,Optimization -> Convex Optimization; Theory -> Hardness of Learning and Approximations,,"['Tianyi Lin', ' Nhat Ho', ' Xi Chen', ' Marco Cuturi', ' Michael Jordan']","{'UC Berkeley', 'New York University', 'University of Texas at Austin'}",1,0,0,{'USA'}
Learning to Orient Surfaces by Self-supervised Spherical CNNs,"Riccardo Spezialetti, Federico Stella, Marlon Marcon, Luciano Silva, Samuele Salti, Luigi Di Stefano",Learning to Orient Surfaces by Self-supervised Spherical CNNs,3a0772443a0739141292a5429b952fe6,https://proceedings.neurips.cc/paper/2020/file/3a0772443a0739141292a5429b952fe6-Paper.pdf,In this work we presented a general framework to canonically orient 3D shapes based on deep- learning. The proposed methodology can be especially valuable for the broad spectrum of vision applications that entail reasoning about surfaces. We live in a three-dimensional world: cognitive understanding of 3D structures is pivotal for acting and planning.,6 Broader Impact,53,3,FALSE,FALSE,FALSE,FALSE,FALSE,Learning to Orient Surfaces by Self-supervised Spherical CNNs,Applications -> Computer Vision,Algorithms -> Unsupervised Learning,Vision,"['Riccardo Spezialetti', ' Federico Stella', ' Marlon Marcon', ' Luciano Silva', ' Samuele Salti', ' Luigi Di Stefano']","{'Università di Bologna', 'UFPR', 'Federal University of Technology - Paraná', 'University of Bologna'}",1,0,0,"{'Italy', 'Brazil'}"
Adam with Bandit Sampling for Deep Learning,"Rui Liu, Tianyi Wu, Barzan Mozafari",Adam with Bandit Sampling for Deep Learning,3a077e8acfc4a2b463c47f2125fdfac5,https://proceedings.neurips.cc/paper/2020/file/3a077e8acfc4a2b463c47f2125fdfac5-Paper.pdf,"As machine learning techniques are being used in more and more real-life products, deep learning is the most notable driving force behind it. Deep learning models have achieved state-of-the-art performance in scenarios such as image recognition, natural language processing, and so on. Our society has benefited greatly from the success of deep learning models. However, this success normally relies on large amount of data available to train the models using optimization methods such as Adam. In this paper, we propose a generalization of Adam that can be more efficient to train models on large amount of data, especially when the datasets are imbalanced. We believe our method could become a widely adopted optimization method for training deep learning models, thus bringing broad impact to many real-life products that rely on these models.",Broader Impact,132,6,,,FALSE,FALSE,FALSE,Adam with Bandit Sampling for Deep Learning,Deep Learning -> Optimization for Deep Networks,Algorithms -> Bandit Algorithms,Optimization Methods (continuous or discrete),"['Rui Liu', ' Tianyi Wu', ' Barzan Mozafari']","{'University of Michigan, Ann Arbor', 'University of Michigan'}",1,0,0,{'USA'}
Parabolic Approximation Line Search for DNNs,"Maximus Mutschler, Andreas Zell",Parabolic Approximation Line Search for DNNs,3a30be93eb45566a90f4e95ee72a089a,https://proceedings.neurips.cc/paper/2020/file/3a30be93eb45566a90f4e95ee72a089a-Paper.pdf,"Since we understand our work as basic research, it is extremely error-prone to estimate its specific ethical aspects and future positive or negative social consequences. As optimization research influences the whole field of deep learning, we refer to the following works, which discuss the ethical aspects and social consequences of AI and Deep Learning in a comprehensive and general way: [6, 41, 61].",Potential Broader Impact,63,2,,,FALSE,FALSE,FALSE,Parabolic Approximation Line Search for DNNs,Deep Learning -> Optimization for Deep Networks,,Optimization Methods (continuous or discrete),"['Maximus Mutschler', ' Andreas Zell']","{'University of Tübingen', 'University of Tuebingen'}",1,0,0,{'Germany'}
Agnostic Learning of a Single Neuron with Gradient Descent,"Spencer Frei, Yuan Cao, Quanquan Gu",Agnostic Learning of a Single Neuron with Gradient Descent,3a37abdeefe1dab1b30f7c5c7e581b93,https://proceedings.neurips.cc/paper/2020/file/3a37abdeefe1dab1b30f7c5c7e581b93-Paper.pdf,"This paper provides a theoretical analysis of gradient descent when used for learning a single neuron. As a theoretical work, its potential risk for negative societal impacts is extremely limited. On the other hand, our general lack of understanding of why gradient descent on large neural networks can find weights that have both small empirical risk and also small population risk is worrisome given the widespread adoption of large neural networks in sensitive technology applications. (A reasonable expectation for using a piece of technology is that we understand how and why it works.) Our work helps explain how, in a simple neural network model, gradient descent can learn solutions that generalize well even though the optimization problem is highly nonconvex and nonsmooth. As such, it provides a building block for understanding how more complex neural network models can be learned by gradient descent.",Broader Impact,143,6,,,FALSE,FALSE,FALSE,Agnostic Learning of a Single Neuron with Gradient Descent,Theory -> Statistical Learning Theory,Deep Learning -> Analysis and Understanding of Deep Networks; Theory -> Computational Learning Theory,Theory (including computational and statistical analyses),"['Spencer Frei', ' Yuan Cao', ' Quanquan Gu']",{'UCLA'},1,0,0,{'USA'}
Statistical Efficiency of Thompson Sampling for Combinatorial Semi-Bandits,"Pierre Perrault, Etienne Boursier, Michal Valko, Vianney Perchet",Statistical Efficiency of Thompson Sampling for Combinatorial Semi-Bandits,3a4496776767aaa99f9804d0905fe584,https://proceedings.neurips.cc/paper/2020/file/3a4496776767aaa99f9804d0905fe584-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Statistical Efficiency of Thompson Sampling for Combinatorial Semi-Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning; Optimization -> Discrete Optimization; Probabilistic Methods -> Bayesian Theory,Theory (including computational and statistical analyses),"['Pierre Perrault', ' Etienne Boursier', ' Michal Valko', ' Vianney Perchet']","{'INRIA - ENS Paris Saclay', 'ENS Paris Saclay', 'DeepMind'}",1,1,1,"{'France', 'UK'}"
Analytic Characterization of the Hessian in Shallow ReLU Models: A Tale of Symmetry,"Yossi Arjevani, Michael Field",Analytic Characterization of the Hessian in Shallow ReLU Models: A Tale of Symmetry,3a61ed715ee66c48bacf237fa7bb5289,https://proceedings.neurips.cc/paper/2020/file/3a61ed715ee66c48bacf237fa7bb5289-Paper.pdf,"To the best of our knowledge, there are no ethical aspects or future societal consequences directly involved in our work.",Broader Impact,20,1,TRUE,FALSE,FALSE,FALSE,FALSE,Analytic Characterization of the Hessian in Shallow ReLU Models: A Tale of Symmetry,Deep Learning -> Optimization for Deep Networks,Deep Learning -> Analysis and Understanding of Deep Networks; Optimization -> Non-Convex Optimization,Deep learning,"['Yossi Arjevani', ' Michael Field']","{'UC Santa Barbara', 'NYU'}",1,0,0,{'USA'}
Generative causal explanations of black-box classifiers,"Matthew O'Shaughnessy, Gregory Canal, Marissa Connor, Christopher Rozell, Mark Davenport",Generative causal explanations of black-box classifiers,3a93a609b97ec0ab0ff5539eb79ef33a,https://proceedings.neurips.cc/paper/2020/file/3a93a609b97ec0ab0ff5539eb79ef33a-Paper.pdf,"Explanation methods have the potential to play a major role in enabling the safe and fair deployment of machine learning systems [2, 76], and explainability is a oft-mentioned constraint in their legal and ethical analysis. Policy discussions about machine learning have increasingly turned to principles of transparency and fairness [77], with some legal scholars arguing that the 2016 European General Data Protection Regulation (GDPR) contains a “right to explanation” [78], and recent G20 and OECD recommendations both identifying “transparency and explainability” as important principles for the development of machine learning algorithms [79, 80]. The growing literature on explainability that our work contributes to has the potential to improve the transparency and fairness of machine learning systems and increase the level of trust users place in their decisions. Yet these explanation methods, often built from complex and nontransparent components and each proposing subtly different notions of explanation, also risk providing deceptively incomplete understanding of systems used in sensitive applications, or providing false assurances of fairness and lack of bias (see, e.g., [81]). This criticism may be especially true for our method, which constructs explanations using neural networks that are themselves difficult to understand. For the explanation literature to have a positive impact, it is necessary for explanations to be easily yet precisely understood by the nontechnical generalists deploying and regulating machine learning systems. We believe that causal perspective used in this work is valuable in this regard because causality has been identified as a vocabulary appropriate for translating technical concepts to psychological [3] and legal frameworks [2, 29]. We also believe our analysis with simple models is important because it endows our explanations with some theoretical grounding. However, a critical need remains for more interdisciplinary research examining how end users understand the outputs of explanation tools (e.g., [82]) and how technical tools can be brought to bear to address identified deficiencies.",Broader impacts,310,9,,,FALSE,FALSE,FALSE,Generative causal explanations of black-box classifiers,"Deep Learning -> Visualization, Interpretability, and Explainability",Deep Learning -> Generative Models; Probabilistic Methods -> Causal Inference,Deep learning,"['Shaughnessy', ' Gregory Canal', ' Marissa Connor', ' Christopher Rozell', ' Mark Davenport']","{'Georgia Tech', 'Georgia Institute of Technology'}",1,0,0,{'USA'}
Sub-sampling for Efficient Non-Parametric Bandit Exploration,"Dorian Baudry, Emilie Kaufmann, Odalric-Ambrym Maillard",Sub-sampling for Efficient Non-Parametric Bandit Exploration,3ab6be46e1d6b21d59a3c3a0b9d0f6ef,https://proceedings.neurips.cc/paper/2020/file/3ab6be46e1d6b21d59a3c3a0b9d0f6ef-Paper.pdf,"This work is advertising a new way to do non-parametric exploration in bandit models, that enjoy good empirical performance and strong theoretical guarantees. First, bandit problems are at the heart of numerous applications to online content recommendation, hence the good performance of SDA algorithms may inspire new algorithms for more realistic models used for these applications, such as contextual bandits. Then, exploration is a central question in the broader field of reinforcement learning, hence new ideas for bandits may lead to new ideas for reinforcement learning.",Broader Impact,86,3,,,FALSE,FALSE,FALSE,Sub-sampling for Efficient Non-Parametric Bandit Exploration,Algorithms -> Bandit Algorithms,,Reinforcement learning and planning,"['Dorian Baudry', ' Emilie Kaufmann', 'Ambrym Maillard']","{'CNRS', 'INRIA', 'CNRS/INRIA'}",1,0,0,{'France'}
Learning under Model Misspecification: Applications to Variational and Ensemble methods,Andres Masegosa,Learning under Model Misspecification: Applications to Variational and Ensemble methods,3ac48664b7886cf4e4ab4aba7e6b6bc9,https://proceedings.neurips.cc/paper/2020/file/3ac48664b7886cf4e4ab4aba7e6b6bc9-Paper.pdf,"Machine learning models are quickly playing a prominent role in society, industries, and individuals. In consequence, there is a growing demand to have machine learning models that can assert the confidence they have in their predictions, specially, to avoid catastrophic decisions. Predictive models which provide well-calibrated probabilities are a sound way to attach a confidence level to a prediction. Bayesian methods are the main tools employed for this goal. This work provides novel theoretical tools to better understand why Bayesian methods induce predictive models with suboptimal performance in terms of well-calibrated probabilities. So, the findings of this work can be of help to develop more accurate and safer predictive models in machine learning, which could ease the adoption of this technology.",Broader impact,121,6,,,FALSE,FALSE,FALSE,Learning under Model Misspecification: Applications to Variational and Ensemble methods,Probabilistic Methods ,Probabilistic Methods -> Bayesian Theory; Probabilistic Methods -> Variational Inference; Theory -> Models of Learning and Generalization ; Theory -> Statistical Learning Theory,Probabilistic methods and inference,['Andres Masegosa'],{'University of Almeria'},1,0,0,{'Spain'}
Language Through a Prism: A Spectral Approach for Multiscale Language Representations,"Alex Tamkin, Dan Jurafsky, Noah Goodman",Language Through a Prism: A Spectral Approach for Multiscale Language Representations,3acb2a202ae4bea8840224e6fce16fd0,https://proceedings.neurips.cc/paper/2020/file/3acb2a202ae4bea8840224e6fce16fd0-Paper.pdf,"The spectral tools we provide in this paper are applicable to a wide range of neural network models and possible end uses. While this makes it difficult to speak with confidence about broader impacts of the research, we briefly discuss a few potential use cases. Scale isolation enables users to remove information about particular kinds of structure inside existing representations. This could be useful for interpretability or fairness research, as well as computational social scientists who wish to remove e.g. topical information from word embeddings. However, scale isolation may also enable tailored search for particular kinds of information in text or other content, which could enable uses that are beneficial or harmful depending on the use case and whether consent is obtained by relevant parties. The prism layer falls under a general trend of producing more capable neural networks. Such a trend may contribute to increased automation or other changes in labor markets, which may create benefits and harms that depend on the economic and social policies of relevant governing bodies.",Broader Impact,171,7,,,FALSE,FALSE,FALSE,Language Through a Prism: A Spectral Approach for Multiscale Language Representations,Applications -> Natural Language Processing,,Natural language processing,"['Alex Tamkin', ' Dan Jurafsky', ' Noah Goodman']",{'Stanford University'},1,0,0,{'USA'}
DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles,"Huanrui Yang, Jingyang Zhang, Hongliang Dong, Nathan Inkawhich, Andrew Gardner, Andrew Touchet, Wesley Wilkes, Heath Berry, Hai Li",DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles,3ad7c2ebb96fcba7cda0cf54a2e802f5,https://proceedings.neurips.cc/paper/2020/file/3ad7c2ebb96fcba7cda0cf54a2e802f5-Paper.pdf,"DVERGE hypothetically addresses some black-box adversarial vulnerabilities pervasive across machine learning applications while increasing compute requirements to training models. As such methods presented herein suggest potential impacts on the reliability, security, and carbon-footprint of deep-neural-network-based systems. The reliability and robustness of machine learning systems are not just a concern for practitioners but also policy makers [ 32]. A net increase in carbon production would be considered a negative impact by many researchers in climate-related fields. This problem is common to many techniques that modify model training to achieve robustness, including DVERGE. While yet to be examined in the case of DVERGE, the possibility to mitigate or reduce excessive training burdens through informed hyperparameter selection exists. Sometimes, though modified training may increase the required computation per model parameter update, the modified method may nevertheless require fewer steps or epochs to achieve desirable results. Recent work provides actionable recommendations, such as performing cost-benefit analysis, to determine if efficient downstream adoption is desirable [33]. In both industrial and military applications, practical solutions to vulnerabilities, such as relying on human-AI teaming [34], are effective but do not address the underlying source of vulnerability and may limit the adoption of machine learning elsewhere. Addressing vulnerabilities at the training stage, then, is a desirable capability for positive-impact applications. By orthogonally improving only black-box robustness, though, we leave machine learning systems vulnerable to other types of attacks. Previous work has shown that white-box knowledge can still be leaked in black-box scenarios [35, 36]. As such, DVERGE is reliant on adversarial training to defend against white-box attacks and on traditional computer security to maintain system integrity. The ultimate interpretation of impact due to improved model reliability and security is not clear-cut, however, as it is highly dependent on the application space. This uncertainty is symptomatic of the fact that machine learning is often fundamental by nature and that there is no machine learning technique for improving robustness that can be applied only to positive-impact applications, whatever one’s subjective interpretation of “positive” may be.",Broader Impact,335,15,,,FALSE,FALSE,FALSE,DVERGE: Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles,Algorithms -> Boosting and Ensemble Methods,Deep Learning; Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Huanrui Yang', ' Jingyang Zhang', ' Hongliang Dong', ' Nathan Inkawhich', ' Andrew Gardner', ' Andrew Touchet', ' Wesley Wilkes', ' Heath Berry', ' Hai Li']","{'Radiance Technologies', 'Duke University'}",1,1,1,{'USA'}
Towards practical differentially private causal graph discovery,"Lun Wang, Qi Pang, Dawn Song",Towards practical differentially private causal graph discovery,3b13b1eb44b05f57735764786fab9c2c,https://proceedings.neurips.cc/paper/2020/file/3b13b1eb44b05f57735764786fab9c2c-Paper.pdf,"Priv-PC provides an approach to effectively discovering causal graphs from purely observational data. It can be deployed in genomics, ecology, epidemiology, space physics, clinical medicine, and neuroscience to release causal graph while preserving the privacy of the sensitive input data. At the same time, Priv-PC should be used with carefully calibrated parameters to make sure the discovered graph is accurate and preserves the privacy . Inappropriate parameters might lead to weak privacy guarantee that does not provide strong protection against attacks such as inference attack.",Potential Broader Impact,85,4,,,FALSE,FALSE,FALSE,Towards practical differentially private causal graph discovery,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Lun Wang', ' Qi Pang', ' Dawn Song']","{'UC Berkeley', 'University of California, Berkeley', 'Zhejiang University'}",1,0,0,"{'USA', 'China'}"
Independent Policy Gradient Methods for Competitive Reinforcement Learning,"Constantinos Daskalakis, Dylan J. Foster, Noah Golowich",Independent Policy Gradient Methods for Competitive Reinforcement Learning,3b2acfe2e38102074656ed938abf4ac3,https://proceedings.neurips.cc/paper/2020/file/3b2acfe2e38102074656ed938abf4ac3-Paper.pdf,"This is a theoretical paper, and we expect that the immediate ethical and societal consequences of our results will be limited. However, we believe that reinforcement learning more broadly will have significant impact on society. There is much potential for benefits to humanity in application domains including medicine and personalized education. There is also much potential for harm—for example, while reinforcement learning has great promise for self-driving cars and robotic systems, deploying methods that are not safe and reliable in these areas could lead to serious societal and economic consequences. We hope that research into the foundations of reinforcement learning will lead to development of algorithms with better safety and reliability.",Broader Impact,111,5,,,FALSE,FALSE,FALSE,Independent Policy Gradient Methods for Competitive Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Optimization; Theory -> Game Theory and Computational Economics,Reinforcement learning and planning,"['Constantinos Daskalakis', ' Dylan Foster', ' Noah Golowich']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
The Value Equivalence Principle for Model-Based Reinforcement Learning,"Christopher Grimm, Andre Barreto, Satinder Singh, David Silver",The Value Equivalence Principle for Model-Based Reinforcement Learning,3bb585ea00014b0e3ebe4c6dd165a358,https://proceedings.neurips.cc/paper/2020/file/3bb585ea00014b0e3ebe4c6dd165a358-Paper.pdf,"The bulk of the research presented in this paper consists of foundational theoretical results about the learning of models for model-based reinforcement learning agents. While applications of these agents can have social impacts depending upon their use, our results merely serve to illuminate desirable properties of models and facilitate the subsequent training of agents using them. In short, this work is largely theoretical and does not present any foreseeable societal impact, except in the general concerns over progress in artificial intelligence.",Broader impact,81,3,TRUE,TRUE,FALSE,FALSE,FALSE,The Value Equivalence Principle for Model-Based Reinforcement Learning,Reinforcement Learning and Planning -> Model-Based RL,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Christopher Grimm', ' Andre Barreto', ' Satinder Singh', ' David Silver']","{'DeepMind', 'University of Michigan'}",1,1,1,"{'UK', 'USA'}"
Structured Convolutions for Efficient Neural Network Design,"Yash Bhalgat, Yizhe Zhang, Jamie Menjay Lin, Fatih Porikli",Structured Convolutions for Efficient Neural Network Design,3be0214185d6177a9aa6adea5a720b09,https://proceedings.neurips.cc/paper/2020/file/3be0214185d6177a9aa6adea5a720b09-Paper.pdf,"The method proposed in this paper promotes the adaption of deep learning neural networks into memory and compute limited devices, allowing a broader acceptance of machine learning solutions for a spectrum of real-life use cases. By reducing the associated hardware costs of the neural network systems, it aims at making such technology affordable to larger communities. It empowers people by facilitating access to the latest developments in this discipline of science. It neither leverages biases in data nor demands user consent for the use of data.",Broader Impact,86,4,,,FALSE,FALSE,FALSE,Structured Convolutions for Efficient Neural Network Design,Deep Learning -> CNN Architectures,Algorithms -> Model Selection and Structure Learning; Deep Learning -> Efficient Inference Methods,Vision,"['Yash Bhalgat', ' Yizhe Zhang', ' Jamie Menjay Lin', ' Fatih Porikli']",{'Qualcomm AI Research'},0,1,0,{'USA'}
Latent World Models For Intrinsically Motivated Exploration,"Aleksandr Ermolov, Nicu Sebe",Latent World Models For Intrinsically Motivated Exploration,3c09bb10e2189124fdd8f467cc8b55a7,https://proceedings.neurips.cc/paper/2020/file/3c09bb10e2189124fdd8f467cc8b55a7-Paper.pdf,"The presented work is a research in the field of reinforcement learning, focusing on the problem of exploration in real-world conditions (image-based observations, partial observability). Such algorithms can help searching for new important information, for non-trivial solutions. These algorithms can be the crucial component for the development of autonomous intelligent systems for solving complex tasks. Such systems can be used in many different fields, having both strong positive and negative impacts on society, and should be treated with care.",Broader Impact,79,4,,,FALSE,FALSE,FALSE,Latent World Models For Intrinsically Motivated Exploration,Reinforcement Learning and Planning -> Exploration,Algorithms -> Representation Learning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Aleksandr Ermolov', ' Nicu Sebe']",{'University of Trento'},1,0,0,{'Italy'}
Estimating Rank-One Spikes from Heavy-Tailed Noise via Self-Avoiding Walks,"Jingqiu Ding, Samuel Hopkins, David Steurer",Estimating Rank-One Spikes from Heavy-Tailed Noise via Self-Avoiding Walks,3c0de3fec9ab8a3df01109251f137119,https://proceedings.neurips.cc/paper/2020/file/3c0de3fec9ab8a3df01109251f137119-Paper.pdf,"We study an idealized mathematical model and provide theoretical analyses with only synthetic experimental validation. Therefore a direct impact on the society is out of reach. Potentially, since the problem we consider is closely related to stochastic block model, we speculate that our algorithm  could inspire the development of more robust and universal social network analysis. Further there is a chance that color coding method could point out new directions for sum-product evaluation in some types of neural network. Since the application area of the algorithm is still not clear, the positive and negative sides of algorithm really depend on what people are using it for.",Broader impact,106,5,,,FALSE,FALSE,FALSE,Estimating Rank-One Spikes from Heavy-Tailed Noise via Self-Avoiding Walks,Theory,Theory -> High-Dimensional Inference,,"['Jingqiu Ding', ' Samuel Hopkins', ' David Steurer']","{'UC Berkeley', 'ETH Zurich'}",1,0,0,"{'USA', 'Switzerland'}"
Policy Improvement via Imitation of Multiple Oracles,"Ching-An Cheng, Andrey Kolobov, Alekh Agarwal",Policy Improvement via Imitation of Multiple Oracles,3c56fe2f24038c4d22b9eb0aca78f590,https://proceedings.neurips.cc/paper/2020/file/3c56fe2f24038c4d22b9eb0aca78f590-Paper.pdf,"This paper is theoretical in nature, and so we expect the ethical and societal consequences of our specific results to be minimal. More broadly, we do expect that reinforcement learning will have significant impact on society. There is much potential for benefits to humanity in the often-referenced application domains of precision medicine, personalized education, and elsewhere. There is also much potential for harms, both malicious and unintentional. To this end, we hope that research into the foundations of reinforcement learning can help enable these applications and mitigate harms through the development of algorithms that are efficient, robust, and safe.",Broader Impact,99,5,,,FALSE,FALSE,FALSE,Policy Improvement via Imitation of Multiple Oracles,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,,"['An Cheng', ' Andrey Kolobov', ' Alekh Agarwal']","{'Microsoft', 'Microsoft Research'}",1,1,1,{'USA'}
Training Generative Adversarial Networks by Solving Ordinary Differential Equations,"Chongli Qin, Yan Wu, Jost Tobias Springenberg, Andy Brock, Jeff Donahue, Timothy Lillicrap, Pushmeet Kohli",Training Generative Adversarial Networks by Solving Ordinary Differential Equations,3c8f9a173f749710d6377d3150cf90da,https://proceedings.neurips.cc/paper/2020/file/3c8f9a173f749710d6377d3150cf90da-Paper.pdf,"This work offers a perspective on training generative adversarial networks through the lens of solving an ordinary differential equation. As such it helps us connect an important part of current studies in machine learning (generative modelling) to an old and well studied field of research (integration of dynamical systems). Making this connection more rigorous over time could help us understand how to better model natural phenomena, see e.g. Zoufal et al. [30] and Casert et al. [4] for recent steps in this direction. Further, tools developed for the analysis of dynamical systems could potentially help reveal in what form exploitable patterns exist in the models we are developing – or their dynamics – and as a result contribute to the goal of learning robust and fair representations [12]. The techniques proposed in this paper make training of GAN models more stable. This may result in making it easier for non-experts to train such models for beneficial applications like creating realistic images or audio for assistive technologies (e.g. for the speech-impaired, or technology for restoration of historic text sources). On the other hand, the technique could also be used to train models used for nefarious applications, such as forging images and videos (often colloquially referred to as “DeepFakes”). There are some research projects to find ways to mitigate this issue, one example is the DeepFakes Detection Challenge [8].",Broader Impact,227,10,,,FALSE,FALSE,FALSE,Training Generative Adversarial Networks by Solving Ordinary Differential Equations,Deep Learning -> Generative Models,Algorithms -> Dynamical Systems,Optimization Methods (continuous or discrete),"['Chongli Qin', ' Yan Wu', ' Jost Tobias Springenberg', ' Andy Brock', ' Jeff Donahue', ' Timothy Lillicrap', ' Pushmeet Kohli']",{'DeepMind'},0,1,0,{'UK'}
Learning of Discrete Graphical Models with Neural Networks,"Abhijith Jayakumar, Andrey Lokhov, Sidhant Misra, Marc Vuffray",Learning of Discrete Graphical Models with Neural Networks,3cc697419ea18cc98d525999665cb94a,https://proceedings.neurips.cc/paper/2020/file/3cc697419ea18cc98d525999665cb94a-Paper.pdf,"We believe that this work, as presented here, has no direct ethical impact or societal consequences. But, our work paves way for learning higher order graphical models on real world data sets. There are many unanswered questions about NeurISE that are relevant to such real-world applications. For instance, can any theoretical guarantees be given on the structure learned by NeurISE? Or, can we modify NeurISE to learn a model free of certain biases present in the training data set? We hope to answer some of these questions in the future.",Broader impact.,90,6,,,FALSE,FALSE,FALSE,Learning of Discrete Graphical Models with Neural Networks,Probabilistic Methods -> Graphical Models,Algorithms -> Model Selection and Structure Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['', ' Andrey Lokhov', ' Sidhant Misra', ' Marc Vuffray']","{'Los Alamos National Laboratory', 'Indian Institute of Science', 'LANL'}",1,0,0,"{'India', 'USA'}"
RepPoints v2: Verification Meets Regression for Object Detection,"Yihong Chen, Zheng Zhang, Yue Cao, Liwei Wang, Stephen Lin, Han Hu",RepPoints v2: Verification Meets Regression for Object Detection,3ce3bd7d63a2c9c81983cc8e9bd02ae5,https://proceedings.neurips.cc/paper/2020/file/3ce3bd7d63a2c9c81983cc8e9bd02ae5-Paper.pdf,"Since this work is about designing better object detectors, researchers and engineers engaged in object detection and instance segmentation on natural images, medical images and even video data may benefit from this paper. If there is any failure in this system, the model may not detect objects correctly. Similar to most object detectors, the detection results may not be interpretable, thus it is hard to predict failure scenarios. This object detector also leverages biases in the dataset used for training, and may incur a performance drop on datasets which have a domain gap with the training dataset.",Broader Impact,97,4,,,FALSE,FALSE,FALSE,RepPoints v2: Verification Meets Regression for Object Detection,Applications -> Object Detection,,Vision,"['Yihong Chen', ' Zheng Zhang', ' Yue Cao', ' Liwei Wang', ' Stephen Lin', ' Han Hu']","{'MSRA', 'Microsoft Research Asia', 'Microsoft Research', 'Peking University'}",1,1,1,"{'USA', 'China'}"
Unfolding the Alternating Optimization for Blind Super Resolution,"zhengxiong luo, Yan Huang, Shang Li, Liang Wang, Tieniu Tan",Unfolding the Alternating Optimization for Blind Super Resolution,3d2d8ccb37df977cb6d9da15b76c3f3a,https://proceedings.neurips.cc/paper/2020/file/3d2d8ccb37df977cb6d9da15b76c3f3a-Paper.pdf,"Super Resolution is a traditional task in computer vision. It has been studied for several decades and has wide applications in video enhancement, medical imaging, as well as security and surveillance imaging. These techniques have largely benefited the society in various areas for years and have  no negative impact yet. The proposed method (DAN) could further improve the merits of these applications especially in cases where the degradations are unknown. DAN has relatively better performance and much higher speed, and it is possible for DAN to be used in real-time video enhancement or surveillance imaging. This work does not present any negative foreseeable societal consequence.",Broader Impact,105,6,FALSE,FALSE,FALSE,FALSE,FALSE,Unfolding the Alternating Optimization for Blind Super Resolution,Applications -> Computer Vision,Applications -> Denoising; Applications -> Information Retrieval,Vision,"['zhengxiong luo', ' Yan Huang', ' Shang Li', ' Liang Wang', ' Tieniu Tan']","{'CRIPAC, CASIA', '中国科学院自动化所', 'CASIA', 'NLPR, China', 'Chinese Academy of Sciences'}",1,0,0,{'China'}
Entrywise convergence of iterative methods for eigenproblems,"Vasileios Charisopoulos, Austin R. Benson, Anil Damle",Entrywise Convergence of Iterative Methods for Eigenproblems,3d8e03e8b133b16f13a586f0c01b6866,https://proceedings.neurips.cc/paper/2020/file/3d8e03e8b133b16f13a586f0c01b6866-Paper.pdf,"Due to the pervasiveness of spectral methods in machine learning and data mining, our results may be embedded in applications having a wide range of ethical and societal consequences. Indeed, given the fact that eigensolvers are typically used as linear algebra primitives, our work “inherits” the ethical and societal consequences of the context in which its results are applied, as well as the potential implications of “failure” ( e.g. , if our stopping criterion severely underestimates the true approximation error).",Broader impact,80,2,,,FALSE,FALSE,FALSE,Entrywise convergence of iterative methods for eigenproblems,Algorithms -> Spectral Methods,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA); Algorithms -> Large Scale Learning; Applications -> Network Analysis",Numerical Analysis,"['Vasileios Charisopoulos', ' Austin Benson', ' Anil Damle']",{'Cornell University'},1,0,0,{'USA'}
Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views,"Li Nanbo, Cian Eastwood, Robert Fisher",Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views,3d9dabe52805a1ea21864b09f3397593,https://proceedings.neurips.cc/paper/2020/file/3d9dabe52805a1ea21864b09f3397593-Paper.pdf,"In this paper, we presented a new method to learn object-centric representations of multi-object scenes. Object-centric scene representations can support many downstream tasks, such as autonomous scene exploration, object segmentation (tracking) and scene synthesizing. Autonomous scene exploration has real-world applications in exploring hazardous environments, mines, potential bomb threats, nuclear waste zones. This could have societal impacts through increased worker safety or potential military (mis)uses. Object detection and tracking has real-world applications in tracking people in CCTV footage, detecting buildings from aerial footage, and spotting potential hazards for autonomous vehicles. Potential societal impacts include safer autonomous vehicles and unwanted/increased surveillance. Finally, scene synthesizing has applications in automated scene modelling for computer games. This further transitions society away from labor-intensive tasks to higher-level cognitive tasks. This could have both positive (more time for cognitive tasks) and negative (less employment) impacts on society.",Broader Impact,140,9,,,FALSE,FALSE,FALSE,Learning Object-Centric Representations of Multi-Object Scenes from Multiple Views,Deep Learning -> Generative Models,Applications -> Computer Vision,visual representation learning,"['Nanbo Li', ' Clan Eastwood', ' Robert Fisher']",{'University of Edinburgh'},1,0,0,{'UK'}
A Catalyst Framework for Minimax Optimization,"Junchi Yang, Siqi Zhang, Negar Kiyavash, Niao He",A Catalyst Framework for Minimax Optimization,3db54f5573cd617a0112d35dd1e6b1ef,https://proceedings.neurips.cc/paper/2020/file/3db54f5573cd617a0112d35dd1e6b1ef-Paper.pdf,"Our work provides a family of simple and efficient algorithms for some classes of minimax optimization. We believe our theoretical results advance many applications in ML which requires minimax optimization. Of particular interests are deep learning and fair machine learning. Deep learning is used in many safety-critical environments, including self-driving car, biometric authentication, and so on. There is growing evidence that shows deep neural networks are vulnerable to adversarial attacks. Since adversarial attacks and defenses are often considered as two-player games, progress in minimax optimization will definitely empower both. Furthermore, minimax optimization problems provide insights and understanding into the balance and equilibrium between attacks and defenses. As a consequence, making good use of those techniques will boost the robustness of deep learning models and strengthen the security of its applications. Fairness in machine learning has attracted much attention, because it is directly relevant to policy design and social welfare. For example, courts use COMPAS for recidivism prediction. Researchers have shown that bias is introduced into many machine learning systems through skewed data, limited features, etc. One approach to mitigate this is adding constraints into the system, which naturally gives rise to minimax problems.",Broader Impact,193,12,,,FALSE,FALSE,FALSE,A Catalyst Framework for Minimax Optimization,Optimization -> Convex Optimization,Optimization; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Junchi Yang', ' Siqi Zhang', ' Negar Kiyavash', ' Niao He']","{'University of Illinois', 'UIUC', 'University of Illinois at Urbana-Champaign', 'École Polytechnique Fédérale de Lausanne'}",1,0,0,"{'USA', 'Switzerland'}"
Self-supervised Co-Training for Video Representation Learning,"Tengda Han, Weidi Xie, Andrew Zisserman",Self-supervised Co-training for Video Representation Learning,3def184ad8f4755ff269862ea77393dd,https://proceedings.neurips.cc/paper/2020/file/3def184ad8f4755ff269862ea77393dd-Paper.pdf,"Deep learning systems are data-hungry and are often criticized for their huge financial and en- vironmental cost. Training a deep neural network end-to-end is especially expensive due to the large computational requirements. Our research on video representation learning has shown its effectiveness on various downstream tasks. As a positive effect of this, future research can benefit from our work by building systems with the pretrained representation to save the cost of re-training. However, on the negative side, research on self-supervised representation learning has consumed many computational resources and we hope more efforts are put on reducing the training cost in this research area. To facilitate future research, we release our code and pretrained representations.",6 Broader Impact,114,6,,,FALSE,FALSE,FALSE,Self-supervised Co-Training for Video Representation Learning,Algorithms -> Representation Learning,Algorithms -> Unsupervised Learning; Applications -> Activity and Event Recognition; Applications -> Video Analysis,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Tengda Han', ' Weidi Xie', ' Andrew Zisserman']",{'University of Oxford'},1,0,0,{'UK'}
Gradient Estimation with Stochastic Softmax Tricks,"Max Paulus, Dami Choi, Daniel Tarlow, Andreas Krause, Chris J. Maddison",Gradient Estimation with Stochastic Softmax Tricks,3df80af53dce8435cf9ad6c3e7a403fd,https://proceedings.neurips.cc/paper/2020/file/3df80af53dce8435cf9ad6c3e7a403fd-Paper.pdf,"This work introduces methods and theory that have the potential for improving the interpretability of latent variable models. While unfavorable consequences cannot be excluded, increased interpretability is generally considered a desirable property of machine learning models. Given that this is foundational, methodologically-driven research, we refrain from speculating further.",Broader Impact,48,3,FALSE,FALSE,FALSE,FALSE,FALSE,Gradient Estimation with Stochastic Softmax Tricks,Probabilistic Methods -> Latent Variable Models,Algorithms -> Structured Prediction; Algorithms -> Unsupervised Learning; Deep Learning -> Efficient Training Methods; Deep Learning -> Generative Models; Deep Learning -> Interaction-Based Deep Networks; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Max Paulus', ' Dami Choi', ' Daniel Tarlow', ' Andreas Krause', ' Maddison']","{'Google Brain', 'ETH Zurich', 'University of Toronto'}",1,1,1,"{'Canada', 'USA', 'Switzerland'}"
Meta-Learning Requires Meta-Augmentation,"Janarthanan Rajendran, Alexander Irpan, Eric Jang",Meta-Learning Requires Meta-Augmentation,3e5190eeb51ebe6c5bbc54ee8950c548,https://proceedings.neurips.cc/paper/2020/file/3e5190eeb51ebe6c5bbc54ee8950c548-Paper.pdf,"Our work discusses methods of improving meta-learning through meta-augmentation at the task level, and does not target any specific application of meta-learning. The learning algorithms meta-learning generates are ones learned from the data in train-time tasks. It is possible these approaches inject bias into not only how models perform after training, but also inject bias into the training procedure itself . Biased learners can result in biased model outcomes even when the support set presented at test time is unbiased, and this may not be straightforward to detect because the behavior of the learner occurs upstream of actual model predictions. We believe our work is a positive step towards mitigating bias in meta-learning algorithms, by helping avoid overfitting to certain parts of the inputs.",Broader Impact,124,5,,,FALSE,FALSE,FALSE,Meta-Learning Requires Meta-Augmentation,Algorithms -> Meta-Learning,Algorithms -> Few-Shot Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Janarthanan Rajendran', ' Alexander Irpan', ' Eric Jang']","{'Google Brain', 'University of Michigan'}",1,1,1,{'USA'}
SLIP: Learning to predict in unknown dynamical systems with long-term memory,"Paria Rashidinejad, Jiantao Jiao, Stuart Russell",SLIP: Learning to Predict in Unknown Dynamical Systems with Long-Term Memory,3e91970f771a2c473ae36b60d1146068,https://proceedings.neurips.cc/paper/2020/file/3e91970f771a2c473ae36b60d1146068-Paper.pdf,"Because linear dynamical systems are a fundamental tool in essentially all quantitative disciplines (engineering, physical sciences, life sciences, social sciences), advances in the capabilities for learning and predicting such systems may have very significant positive consequences. (For example, currently Google Scholar lists 912,000 papers that mention Kalman filter.) Our proposed algorithm is practical, fast, easy to implement, and provably more robust to a wider range of conditions than previous algorithms. In particular, many real-world systems exhibit long-term memory and a wide range of time scales, which our approach handles well. Like any very general computational tool, the algorithm can be applied in contexts where the societal consequences may be negative. To our knowledge, the vast majority of uses for linear dynamical systems involve human experts studying and predicting systems of interest, such as climate systems or ecologies. In these contexts the effects of improved prediction and reliability would typically be positive. It is specifically unlikely that LDS would be used to model individual humans algorithmically, since humans are decidedly not linear systems.",9 Broader impact,172,8,,,FALSE,FALSE,FALSE,SLIP: Learning to Predict in Unknown Dynamical Systems with Long-Term Memory,Algorithms -> Dynamical Systems,Optimization -> Convex Optimization; Probabilistic Methods -> Latent Variable Models; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),,"{'UC Berkeley', 'University of California, Berkeley'}",1,0,0,{'USA'}
Improving GAN Training with Probability Ratio Clipping and Sample Reweighting,"Yue Wu, Pan Zhou, Andrew G. Wilson, Eric Xing, Zhiting Hu",Improving GAN Training with Probability Ratio Clipping and Sample Reweighting,3eb46aa5d93b7a5939616af91addfa88,https://proceedings.neurips.cc/paper/2020/file/3eb46aa5d93b7a5939616af91addfa88-Paper.pdf,"This work offers a unique viewpoint on two promising fields with lots of applications and impacts: Generative Adversarial Networks and Reinforcement Learning. The improvement to image generation results may be adapted to speed up photo editing, improve scene rendering, and create more realistic simulation for robot training. Furthermore, the contribution to text generation and text style transfer can be adopted to improve the quality of machine translation, and automated news-summaries. Nevertheless, GANs can also be applied to faking images of people and jeopardize personal identities (i.e. Deepfake). We hope that future works can counter this issue through deep-fake detection.",Broader Impacts,99,5,,,FALSE,FALSE,FALSE,Improving GAN Training with Probability Ratio Clipping and Sample Reweighting,Deep Learning -> Adversarial Networks,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yue Wu', ' Pan Zhou', ' Andrew Gordon Wilson', ' Eric Xing', ' Zhiting Hu']","{'New York University', 'Carnegie Mellon University', 'National University of Singapore'}",1,0,0,"{'Singapore', 'USA'}"
Bayesian Bits: Unifying Quantization and Pruning,"Mart van Baalen, Christos Louizos, Markus Nagel, Rana Ali Amjad, Ying Wang, Tijmen Blankevoort, Max Welling",Bayesian Bits: Unifying Quantization and Pruning,3f13cf4ddf6fc50c0d39a1d5aeb57dd8,https://proceedings.neurips.cc/paper/2020/file/3f13cf4ddf6fc50c0d39a1d5aeb57dd8-Paper.pdf,"Bayesian Bits allows networks to run more efficiently during inference time. This technique could be applied to any network, regardless of the purpose of the network. A positive aspect of our method is that, by choosing appropriate priors, a reduction in inference time energy consumption can be achieved. This yields longer battery life on mobile devices and lower overall power consumption for models deployed in production on servers. A negative aspect is that quantization and compression could alter the behavior of the network in subtle, unpredictable ways. For example, [29] notes that pruning a neural network may not affect aggregate statistics, but can have different effects on different classes, thus potentially creating unfair models as a result. We have not investigated the results of our method on the fairness of the predictions of a model.",Broader Impact,135,7,,,FALSE,FALSE,FALSE,Bayesian Bits: Unifying Quantization and Pruning,Deep Learning,Deep Learning -> Efficient Inference Methods,Model efficiency,"['Mart van Baalen', ' Christos Louizos', ' Markus Nagel', ' Rana Ali Amjad', ' Ying Wang', ' Tijmen Blankevoort', ' Max Welling']","{'Qualcomm', 'Qualcomm AI Research', 'University of Amsterdam / Qualcomm AI Research'}",1,1,1,"{'USA', 'Netherlands'}"
On Testing of Samplers,"Kuldeep S Meel, Yash Pralhad Pote, Sourav Chakraborty",On Testing of Samplers,3f1656d9668dffcf8119e3ecff873558,https://proceedings.neurips.cc/paper/2020/file/3f1656d9668dffcf8119e3ecff873558-Paper.pdf,"The recent advances in machine learning techniques have led to increased adoption of the said techniques in safety-critical domains. The usage of a technique in a safety-critical domain necessitates appropriate verification methodology. This paper seeks to take a step in this direction and focused on one core component. Our analysis is probabilistic, and therefore, practical adoption of such techniques requires careful design of frameworks to handle failures.",Broader Impact,67,4,,,FALSE,FALSE,FALSE,On Testing of Samplers,Applications -> Automated Reasoning and Formal Methods,Probabilistic Methods -> Probabilistic Programming,Probabilistic methods and inference,"['Kuldeep S Meel', ' Yash Pralhad Pote', ' Sourav Chakraborty']","{'Indian Statistical Institute, India', 'National University of Singapore'}",1,0,0,"{'Singapore', 'India'}"
Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective,"Vu Nguyen, Vaden Masrani, Rob Brekelmans, Michael Osborne, Frank Wood",Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective,3f2dff7862a70f97a59a1fa02c3ec110,https://proceedings.neurips.cc/paper/2020/file/3f2dff7862a70f97a59a1fa02c3ec110-Paper.pdf,"Our research can be widely applied for variational inference in deep generative models, including variational autoencoders with autoregressive decoders and normalizing flows. Variational inference, and Bayesian methods more generally, have broad applications spanning science and engineering, from epidemiology [44] to particle physics [2]. Our methodological contributions for variational inference may find broader impact through improved modelling in these disparate domains. However, our method is general in nature, so domain-specific applications should further consider implications for deployment in the real-world.",7 Broader Impact,79,4,,,FALSE,FALSE,FALSE,Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective,Deep Learning -> Generative Models,Probabilistic Methods -> Gaussian Processes; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Vu Nguyen', ' Vaden Masrani', ' Rob Brekelmans', ' Michael A Osborne', ' Frank Wood']","{'U Oxford', 'University of British Columbia', 'University of Southern California', 'University of Oxford'}",1,0,0,"{'Canada', 'UK', 'USA'}"
MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers,"Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, Ming Zhou",MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers,3f5ee243547dee91fbd053c1c4a845aa,https://proceedings.neurips.cc/paper/2020/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf,"Pre-trained language models have achieved remarkable success for various natural language processing tasks. However, these models consist of hundreds of millions of parameters and become bigger and bigger. It brings challenges for online serving in real-life applications due to latency and capacity constraints. Our work focuses on compressing large pre-trained models into small and fast pre-trained models, while achieving competitive performance. Our method and released models can be useful for a lot of real-life applications. Besides, fine-tuning large pre-trained models has hard requirements of GPU resources and the computational cost is also very high. Fine-tuning and running inference using small models can save GPU hours, dollars, and carbon dioxide emissions. Our small and fast models can also help researchers with less computing resources.",Broader Impact,123,8,,,FALSE,FALSE,FALSE,MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers,Applications -> Natural Language Processing,,Natural language processing,"['Wenhui Wang', ' Furu Wei', ' Li Dong', ' Hangbo Bao', ' Nan Yang', ' Ming Zhou']","{'MSRA', 'Harbin Institute of Technology', 'Microsoft Research', 'Microsoft Research Asia'}",1,1,1,"{'USA', 'China'}"
Optimal Epoch Stochastic Gradient Descent Ascent Methods for Min-Max Optimization,"Yan Yan, Yi Xu, Qihang Lin, Wei Liu, Tianbao Yang",Optimal Epoch Stochastic Gradient Descent Ascent Methods for Min-Max Optimization,3f8b2a81da929223ae025fcec26dde0d,https://proceedings.neurips.cc/paper/2020/file/3f8b2a81da929223ae025fcec26dde0d-Paper.pdf,A discussion about broader impact is not applicable since our work is very theoretical and currently has no particular application.,Broader Impact,20,1,TRUE,FALSE,FALSE,FALSE,FALSE,Optimal Epoch Stochastic Gradient Descent Ascent Methods for Min-Max Optimization,Optimization,Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Yan Yan', ' Yi Xu', ' Qihang Lin', ' Wei Liu', ' Tianbao Yang']","{'The University of Iowa', 'University of Iowa', 'the University of Iowa', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
Woodbury Transformations for Deep Generative Flows,"You Lu, Bert Huang",Woodbury Transformations for Deep Generative Flows,3fb04953d95a94367bb133f862402bce,https://proceedings.neurips.cc/paper/2020/file/3fb04953d95a94367bb133f862402bce-Paper.pdf,"This paper presents fundamental research on increasing the expressiveness of deep probabilistic models. Its impact is therefore linked to the various applications of such models. By enriching the class of complex deep models for which we can train with exact likelihood, we may enable a wide variety of applications that can benefit from modeling of uncertainty. However, a potential danger of this research is that deep generative models have been recently applied to synthesize realistic images and text, which can be used for misinformation campaigns.",Broader Impact,85,4,,,FALSE,FALSE,FALSE,Woodbury Transformations for Deep Generative Flows,Deep Learning -> Generative Models,Algorithms -> Unsupervised Learning,Deep learning,"['You Lu', ' Bert Huang']",{'Virginia Tech'},1,0,0,{'USA'}
Graph Contrastive Learning with Augmentations,"Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, Yang Shen",Graph Contrastive Learning with Augmentations,3fe230348e9a12c13120749e3f9fa4cd,https://proceedings.neurips.cc/paper/2020/file/3fe230348e9a12c13120749e3f9fa4cd-Paper.pdf,"Empowering deep learning for reasoning and predicting over graph-structured data is of broad interests and wide applications, such as recommendation systems, neural architecture search, and drug discovery. The proposed graph contrastive learning framework with augmentations contributes a general framework that can potentially benefit the effectiveness and efficiency of graph neural networks through model pre-training. The numerical results and analyses would also inspire the design of proper augmentations toward positive knowledge transfer on downstream tasks.",Broader Impact,74,3,,,FALSE,FALSE,FALSE,Graph Contrastive Learning with Augmentations,Algorithms -> Semi-Supervised Learning,Algorithms -> Unsupervised Learning,AutoML,,"{'Google', 'University of Science and Technology of China', 'University of Texas at Austin', 'Unversity of Texas at Austin'}",1,1,1,"{'USA', 'China'}"
Gradient Surgery for Multi-Task Learning,"Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, Chelsea Finn",Gradient Surgery for Multi-Task Learning,3fe78a8acf5fda99de95303940a2420c,https://proceedings.neurips.cc/paper/2020/file/3fe78a8acf5fda99de95303940a2420c-Paper.pdf,"Applications and Benefits. Despite recent success, current deep learning and deep RL methods mostly focus on tackling a single specific task from scratch. Prior methods have proposed methods that can perform multiple tasks, but they often yield comparable or even higher data complexity compared to learning each task individually. Our method enables deep learning systems that mitigate inferences between differing tasks and thus achieves data-efficient multi-task learning. Since our method is general and simple to apply to various problems, there are many possible real-world applications, including but not limited to computer vision systems, autonomous driving, and robotics. For computer vision systems, our method can be used to develop algorithms that enable efficient classification, instance and semantics segmentation and object detection at the same time, which could improve performances of computer vision systems by reusing features obtained from each task and lead to a leap in real-world domains such as autonomous driving. For robotics, there are many situations where multi-task learning is needed. For example, surgical robots are required to perform a wide range of tasks such as stitching and removing tumour from the patient’s body. Kitchen robots should be able to complete multiple chores such as cooking and washing dishes at the same time. Hence, our work represents a step towards making multi-task reinforcement learning more applicable to those settings.  Risks. However, there are potential risks that apply to all machine learning and reinforcement learning systems including ours, including but not limited to safety, reward specification in RL which is often difficult to acquire in the real world, bias in supervised learning systems due to the composition of training data, and compute/data-intensive training procedures. For example, safety issues arise when autonomous driving cars fail to generalize to out-of-distribution data, which leads to crashing or even hurting people. Moreover, reward specification in RL is generally inaccessible in the real world, making RL unable to scale to real robots. In supervised learning domains, learned models could inherit the bias that exists in the training dataset. Furthermore, training procedures of ML models are generally compute/data-intensive, which cause inequitable access to these models. Our method is not immune to these risks. Hence, we encourage future research to design more robust and safe multi-task RL algorithms that can prevent unsafe behaviors. It is also important to push research in self-supervised and unsupervised multi-task RL in order to resolve the issue of reward specification. For supervised learning, we recommend researchers to publish their trained multi-task learning models to make access to those models equitable to everyone in field and develop new datasets that can mitigate biases and also be readily used in multi-task learning.",Broader Impact,438,20,,,FALSE,TRUE,FALSE,Gradient Surgery for Multi-Task Learning,Deep Learning,Algorithms -> Multitask and Transfer Learning; Reinforcement Learning and Planning -> Reinforcement Learning,Deep learning,"['Tianhe Yu', ' Saurabh Kumar', ' Abhishek Gupta', ' Sergey Levine', ' Karol Hausman', ' Chelsea Finn']","{'UC Berkeley', 'Stanford University', 'Google Brain', 'Stanford'}",1,1,1,{'USA'}
Bayesian Probabilistic Numerical Integration with Tree-Based Models,"Harrison Zhu, Xing Liu, Ruya Kang, Zhichao Shen, Seth Flaxman, Francois-Xavier Briol",Bayesian Probabilistic Numerical Integration with Tree-Based Models,3fe94a002317b5f9259f82690aeea4cd,https://proceedings.neurips.cc/paper/2020/file/3fe94a002317b5f9259f82690aeea4cd-Paper.pdf,"Our paper is about numerical integration, a common computational problem in machine learning. It provides an approach to improve the accuracy of such approximations, as well as obtaining credible intervals representing our uncertainty about the value of the integral. The increased accuracy of the method may allow the users to reduce their computational requirements, which may, further down the line, have some impact on mitigating the impact of large computer clusters on climate change. However, the broader impact of the method will mostly depend on the applications of the algorithms that it will be used to enhance: applications to ethical algorithms will have a positive impact, but application to unethical algorithms will also have a negative impact. For example, in the Bayesian survey design problem studied in the numerical experiments section, we have shown that there is potential for application in predicting population proportions resulting from binary outcome variables. The categorical variables for instance, however, may be unethically used as explanatory variables for certain problems, and this would be an issue depending on how the conclusions are drawn.",Broader Impact,178,6,,,FALSE,FALSE,FALSE,Bayesian Probabilistic Numerical Integration with Tree-Based Models,Probabilistic Methods -> Bayesian Nonparametrics,Algorithms -> Active Learning,Probabilistic methods and inference,"['Harrison Zhu', ' Xing Liu', ' Ruya Kang', ' Zhichao Shen', ' Seth Flaxman', 'Xavier Briol']","{'University of Cambridge', 'ETH Zurich', 'University of Oxford', 'Imperial College London'}",1,0,0,"{'UK', 'Switzerland'}"
Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel,"Stanislav Fort, Gintare Karolina Dziugaite, Mansheej Paul, Sepideh Kharaghani, Daniel M. Roy, Surya Ganguli",Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel,405075699f065e43581f27d67bb68478,https://proceedings.neurips.cc/paper/2020/file/405075699f065e43581f27d67bb68478-Paper.pdf,The goal of our work is to gain a better understanding of deep neural networks. This could potentially make machine learning applications more reliable and transparent in the long run.,Broader Impact,30,2,FALSE,FALSE,FALSE,FALSE,FALSE,Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel,Deep Learning -> Analysis and Understanding of Deep Networks,,Theory (including computational and statistical analyses),"['Stanislav Fort', ' Gintare Karolina Dziugaite', ' Mansheej Paul', ' Sepideh Kharaghani', ' Daniel Roy', ' Surya Ganguli']","{'Stanford University', 'Stanford University / Google Research', 'Stanford', 'Element AI', 'Univ of Toronto & Vector'}",1,1,1,"{'Canada', 'USA'}"
Graph Meta Learning via Local Subgraphs,"Kexin Huang, Marinka Zitnik",Graph Meta Learning via Local Subgraphs,412604be30f701b1b1e3124c252065e6,https://proceedings.neurips.cc/paper/2020/file/412604be30f701b1b1e3124c252065e6-Paper.pdf,"Graphs represent an incredibly powerful data representation that has proved useful for numerous domains and application areas. At the same time, meta learning is a key area of machine learning re- search that has already demonstrated great potential for problems, such as few-shot image recognition and neural architecture search. G-M ETA advances ML research. Our present work is at an exciting yet underexplored intersection of graph ML and meta learning, advancing the state-of-the-art and enabling practical applications of meta learning for large graph datasets. State-of-the-art GNN methods do not work when there are only a handful of labels available. Our work fills in this gap by providing a novel approach to leverage related information such as related graphs or other labels sets to aid the graph few-shot learning. Numerous real-world graphs are only associated with scarce labels of nodes or have a large percentage of missing links. Low-resource constraint ( e.g. , the sparsity of graphs/scarcity of labels) is a fundamental challenge in real-world graph applications. The goal of graph meta-learning is to solve key graph ML tasks, such as node classification and link prediction, under these constraints. We envision numerous impactful applications of our work, as already demonstrated in the paper. We provide a brief overview of key applications for graph meta-learning, and G-M ETA in particular. G-M ETA can expedite scientific discovery. Science is filled with complex systems that are modeled by graphs. The labels are usually obtained through resource-intensive experiments in laboratories. Many experiments, such as those to measure protein-protein interactions (studied in the paper), cannot yet be automated. Because of that, labels ( i.e. , a variety of molecular properties that need to be discovered for downstream problems like drug discovery [42]) are expensive to obtain and thus are very scarce. G-M ETA can accelerate scientific discovery by learning from related sources and quickly adapting to a new, never-before-seen task of interest given only a handful of examples. For example, G-M ETA can better annotate rare disease pathways by transferring knowledge from the mouse PPI network to the human PPI network [31]. Further, PPI networks of many species are highly incomplete, even for humans, less than 30% of all pairwise combinations of proteins have been tested for interaction so far [23]. Graph meta-learning can help label sparse networks by learning from a handful of other networks that are well-annotated. G-M ETA can bring economic values. While graphs have helped businesses make better products ( e.g. , [54, 24]), many graph-structured data resources remain under-utilized because of the sparsity and scarcity of labels. G-M ETA can help tackle this problem. For example, it can improve recommen- dation for a new set of products that only have a few user behavior records by transferring knowledge from previous product sets in the user products recommendation networks, or help a business expand to new locations by learning from the interconnected data about the current location. G-M ETA can improve equality. G-M ETA can be used to facilitate the development of world regions by quickly learning from the developed regions. While this has previously been successfully demonstrated on satellite image data [18], we see many new opportunities for graph data, such as identifying what transportation lines (links) should be prioritized to add in a rural region by learning from infrastructure networks of developed regions that were similarly rural before. Finally, we briefly comment on potential risks of having a powerful graph meta-learning predictor. (1) Negative transfer: Meta-learning models are tricky to train and may vary across datasets and domains. It can lead to negative transfer. (2) Misuse of the methodology: Meta-learning is not universal. It works in specific settings. For example, G-M ETA is applied to few-shot settings. When labels are abundant, it might not yield considerable benefits. (3) Adversarial attacks: There are no studies on how adversarial attacks would affect meta-learning algorithms and graph algorithms in particular. We posit that in the few-shot setting, it may be particularly easy to attack the graph since each labeled example is vital for prediction.",Broader Impact,671,36,,,FALSE,TRUE,FALSE,Graph Meta Learning via Local Subgraphs,Algorithms -> Meta-Learning,Algorithms -> Few-Shot Learning; Algorithms -> Multitask and Transfer Learning; Algorithms -> Relational Learning; Algorithms -> Representation Learning; Applications -> Computational Biology and Bioinformatics; Applications -> Network Analysis; Deep Learning -> Embedding Approaches,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Kexin Huang', ' Marinka Zitnik']",{'Harvard University'},1,0,0,{'USA'}
Stochastic Deep Gaussian Processes over Graphs,"Naiqi Li, Wenjie Li, Jifeng Sun, Yinghua Gao, Yong Jiang, Shu-Tao Xia",Stochastic Deep Gaussian Processes over Graphs,415e1af7ea95f89f4e375162b21ae38c,https://proceedings.neurips.cc/paper/2020/file/415e1af7ea95f89f4e375162b21ae38c-Paper.pdf,"This paper proposes a graph guided deep Gaussian process model. Through incorporating the graph information into deep Gaussian process, our proposed method reduces sampling variances and achieves faster convergence. Graph structure is a very common tool in numerous fields. In experiments, we also show that the proposed method can facilitate the tasks of traffic flow prediction. We believe that the exploration of graph structure will largely improve the capacity of current machine learning algorithms.",Broader Impact,74,5,,,FALSE,FALSE,FALSE,Stochastic Deep Gaussian Processes over Graphs,Probabilistic Methods -> Gaussian Processes,Probabilistic Methods -> Bayesian Nonparametrics; Probabilistic Methods -> Variational Inference,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Naiqi Li', ' Wenjie Li', ' Jifeng Sun', ' Yinghua Gao', ' Yong Jiang', 'Tao Xia']","{'Tsinghua University', 'Tsinghua', 'Tsinghua-Berkeley Shenzhen Institute'}",1,0,0,"{'USA', 'China'}"
Bayesian Causal Structural Learning with Zero-Inflated Poisson Bayesian Networks,"Junsouk Choi, Robert Chapkin, Yang Ni",Bayesian Causal Structural Learning with Zero-Inflated Poisson Bayesian Networks,4175a4b46a45813fccf4bd34c779d817,https://proceedings.neurips.cc/paper/2020/file/4175a4b46a45813fccf4bd34c779d817-Paper.pdf,"The proposed ZIPBN will be useful for constructing causal gene regulatory network at the cell type level, which will assist biologists in generating causal hypotheses of gene regulation and expediting causal discovery processes. Without the proposed method, mechanistic understanding of cell-type- specific gene regulation will likely remain difficult. Additionally, the proposed method is broadly applicable to other applications (including educational psychology, ecology, behavior science, and economics) where data are zero-inflated and causal network inference is of interest.",Broader Impact,77,3,,,FALSE,FALSE,FALSE,Bayesian Causal Structural Learning with Zero-Inflated Poisson Bayesian Networks,Probabilistic Methods -> Graphical Models,Probabilistic Methods -> Causal Inference,Causality,"['Junsouk Choi', ' Robert Chapkin', ' Yang Ni']",{'Texas A&M University'},1,0,0,{'USA'}
Evaluating Attribution for Graph Neural Networks,"Benjamin Sanchez-Lengeling, Jennifer Wei, Brian Lee, Emily Reif, Peter Wang, Wesley Wei Qian, Kevin McCloskey, Lucy Colwell , Alexander Wiltschko",Evaluating Attribution for Graph Neural Networks,417fbbf2e9d5a28a855a11894b2e795a,https://proceedings.neurips.cc/paper/2020/file/417fbbf2e9d5a28a855a11894b2e795a-Paper.pdf,"Better attribution methods for graph neural networks will help improve ML interpretability, and therefore ML credibility, in the domain of machine learning on graph-valued data. Specifically, we wish for machine learning models to not just to learn and exploit correlations in training data, but to help practitioners understand the correlations the model has learned and create new scientific knowledge. Applications of high-performing attribution methods on GNNs include pharmaceutical development, material design, social network analysis, and more. Improving the ability to inspect these models will hopefully improve their rate of adoption. GNNs have also been applied to social networks, and improving the field’s capability to inspect and interrogate trained models will hopefully also improve the public discourse around the topic. However, our work reveals that no attribution method is perfect, and risk remains in placing perfect confidence in the output of existing attribution methods applied to graph neural networks.",Broader Impact,148,6,,,FALSE,FALSE,FALSE,Evaluating Attribution for Graph Neural Networks,"Deep Learning -> Visualization, Interpretability, and Explainability","Algorithms -> Structured Prediction; Data, Challenges, Implementations, and Software -> Benchmarks; Deep Learning -> Interaction-Based Deep Networks; Deep Learning -> Supervised Deep Networks","Datasets, challenges, software","['Lengeling', ' Jennifer Wei', ' Brian Lee', ' Emily Reif', ' Peter Wang', ' Wesley Wei Qian', ' Kevin McCloskey', ' Lucy Colwell', ' Alexander Wiltschko']","{'Google', 'Google Research', 'Columbia University', 'University of Illinois at Urbana-Champaign', 'Google Brain', 'Google Inc.'}",1,1,1,{'USA'}
On Second Order Behaviour in Augmented Neural ODEs,"Alexander Norcliffe, Cristian Bodnar, Ben Day, Nikola Simidjievski, Pietro Lió",On Second Order Behaviour in Augmented Neural ODEs,418db2ea5d227a9ea8db8e5357ca2084,https://proceedings.neurips.cc/paper/2020/file/418db2ea5d227a9ea8db8e5357ca2084-Paper.pdf,"Neural ODEs are relatively new models and we are yet to see their full potential. We anticipate NODEs will see particular success in time-series data, which have a wide variety of real-world applications. Examples given by Jia and Benson [10] include the evolution of individuals’ medical records and earthquake monitoring. Poli et al. [17] look at traffic forecasting and Greydanus et al. [6] show how a Neural ODE inspired by Hamiltonian mechanics can be applied to classical physics. Our work concerns Second Order Neural ODEs which can also be applied to classical physics, where Newton’s second law describes the forces on an object. Our theoretical work was concerned with demonstrating how best to use the adjoint method on SONODEs, and showing how the coupled ODE perspective of ANODEs leads to them being able to learn second order behaviour. Naturally, any impacts from this work will come from the applications of SONODEs. We directly investigated two potential real-world applications of SONODEs. The Silverbox dataset, an electronic implementation of a damped spring with a non-linear spring constant. This naturally applies to circuits with oscillators, and damped elements, opening new directions to monitor circuits and signals. The dynamics can also be encountered in mechanical systems, including car suspension, which could be used to improve car safety. Note that, in our experiments, we also investigated the task of modelling the vibration dynamics of an aeroplane, which might lead to better and optimal aeroplane designs. Though contributions to civil mechanical engineering such as these have parallel applications in the design of weapons, it is not the case that our investigation expands technological capabilities in such a way as to enable new forms of warfare or to significantly improve current technologies (at this stage). As stated, Neural ODEs are relatively new, and we are yet to see their full potential. We anticipate more applications to time series data in the future, which have many positive and negative applications, though at most we should think of our contribution as incremental in this regard and covered by existing institutions and norms.",Broader Impact,343,17,,,FALSE,FALSE,FALSE,On Second Order Behaviour in Augmented Neural ODEs,Algorithms -> Dynamical Systems,Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Supervised Deep Networks,Deep learning,"['Alexander Norcliffe', ' Cristian Bodnar', ' Ben Day', ' Nikola Simidjievski', ' Pietro Lió']",{'University of Cambridge'},1,0,0,{'UK'}
Neuron Shapley: Discovering the Responsible Neurons,"Amirata Ghorbani, James Y. Zou",Neuron Shapley: Discovering the Responsible Neurons,41c542dfe6e4fc3deb251d64cf6ed2e4,https://proceedings.neurips.cc/paper/2020/file/41c542dfe6e4fc3deb251d64cf6ed2e4-Paper.pdf,"When a car breaks down, it is critical to know which component—the engine, tire, etc.—caused the issue. Similarly, when a machine learning model makes mistakes or does well, it is important to know which part of the model is responsible. In this work, we propose Neuron Shapley as a principled framework to quantify the contribution of every neuron to each prediction success and failure of the network. We propose an efficient adaptive algorithm for estimating this Shapley score. We further apply this approach to identify which neurons are responsible for predictions that are biased against minorities and neurons that are vulnerable to attacks. Neuron Shapley is thus a step toward making deep learning more accountable and responsible, which could have broad social impact. We suggest that it should be used in conjunction with other interpretation and analysis tools to provide a holistic assessment of the model.",Broader Impact,146,7,,,FALSE,FALSE,FALSE,Neuron Shapley: Discovering the Responsible Neurons,Deep Learning,"Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,"['Amirata Ghorbani', ' James Zou']",{'Stanford University'},1,0,0,{'USA'}
Stochastic Normalizing Flows,"Hao Wu, Jonas Köhler, Frank Noe",Stochastic Normalizing Flows,41d80bfc327ef980528426fc810a6d7a,https://proceedings.neurips.cc/paper/2020/file/41d80bfc327ef980528426fc810a6d7a-Paper.pdf,"The sampling of probability distributions defined by energy models is a key step in the rational design of pharmacological drug molecules for disease treatment, and the design of new materials, e.g., for energy storage. Currently such sampling is mostly done by Molecular Dynamics (MD) and MCMC simulations, which is in many cases limited by computational resources and generates extremely high energy costs. For example, the direct simulation of a single protein-drug binding and dissociation event could require the computational time of an entire supercomputer for a year. Developing machine learning (ML) approaches to solve this problem more efficiently and go beyond existing enhanced sampling methods is therefore of importance for applications in medicine and material science and has potentially far-reaching societal consequences for developing better treatments and reducing energy consumption. Boltzmann Generators, i.e. the combination of Normalizing Flows (FNs) and resampling/reweighting are a new and promising ML approach to this problem and the current paper adds a key technology to overcome some of the previous limitations of NFs for this task. A risk of the method is that flow-based sampling bears the risk that non-ergodic samplers can be constructed, i.e. samplers that are not guaranteed to sample from the target distribution even in the limit of long simulation time. From such an incomplete sample, wrong conclusions can be drawn. While incomplete sampling is also an issue with MD/MCMC, it is well understood how to at least ensure ergodicity of these methods in the asymptotic limit, i.e. in the limit of generating enough data. Further research is needed to obtain similar results with normalizing flows.",Broader Impact,264,9,,,TRUE,TRUE,FALSE,Stochastic Normalizing Flows,Deep Learning -> Generative Models,Probabilistic Methods -> MCMC; Probabilistic Methods -> Variational Inference; Theory -> Statistical Physics of Learning,Probabilistic methods and inference,"['Hao Wu', ' Jonas Köhler', ' Frank Noe']","{'Freie Universität Berlin', 'FU Berlin'}",1,0,0,{'Germany'}
GPU-Accelerated Primal Learning for Extremely Fast Large-Scale Classification,"John T. Halloran, David M. Rocke",GPU-Accelerated Primal Learning for Extremely Fast Large-Scale Classification,41e7637e7b6a9f27a98b84d3a185c7c0,https://proceedings.neurips.cc/paper/2020/file/41e7637e7b6a9f27a98b84d3a185c7c0-Paper.pdf,"This paper solely focuses on speeding up machine learning software, and thus impacts machine learning packages or applications which use either the included software or the paper’s GPU optimization principles (to speed up an algorithm not discussed). Benefits include faster software, with specific applications including real-time classification for self-driving cars [53], flagging credit card fraud [12], water monitoring to preserve ecosystems in maritime and archipelagic countries [3]), etc. Machine learning companies/researchers/practitioners who do not use GPU resources may be put at a disadvantage from this research, but any advantage/disadvantage is defined solely in terms of training time speed. Acknowledgments : This work was supported by the National Center for Advancing Translational Sciences (NCATS), National Institutes of Health, through grant UL1 TR001860 and a GPU donation from the NVIDIA Corporation.",Broader Impact,129,4,,,FALSE,FALSE,FALSE,GPU-Accelerated Primal Learning for Extremely Fast Large-Scale Classification,Applications -> Hardware and Systems,Applications -> Computational Biology and Bioinformatics,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['John Halloran', ' David M Rocke']","{'University of California, Davis'}",1,0,0,{'USA'}
Random Reshuffling is Not Always Better,Christopher M. De Sa,Random Reshuffling is Not Always Better,42299f06ee419aa5d9d07798b56779e2,https://proceedings.neurips.cc/paper/2020/file/42299f06ee419aa5d9d07798b56779e2-Paper.pdf,"We expect that the counterexamples presented in this work will have an impact on the ML theory community as we further try to understand the effect of scan order in large-scale optimization. We hope that these counterexamples will help guide future researchers towards proving more variants of Conjectures 1 and 2 that are true. Beyond this impact on the ML community, this work is primarily theoretical and does not present any foreseeable societal consequence.",Broader Impact,74,3,FALSE,TRUE,FALSE,TRUE,FALSE,Random Reshuffling is Not Always Better,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization,,['Christopher De Sa'],{'Cornell'},1,0,0,{'USA'}
Model Agnostic Multilevel Explanations,"Karthikeyan Natesan Ramamurthy, Bhanukiran Vinzamuri, Yunfeng Zhang, Amit Dhurandhar",Model Agnostic Multilevel Explanations,426f990b332ef8193a61cc90516c1245,https://proceedings.neurips.cc/paper/2020/file/426f990b332ef8193a61cc90516c1245-Paper.pdf,"With the proliferation of deep learning, explaining or understanding the reasons behind the models decisions has become extremely important in many critical applications [ 30]. Many explainability methods have been proposed in literature [7, 12, 11], however, they either provide instance specific local explanations or fit to the entire dataset and create global explanations. Our proposed method is able to create both such explanations, but in addition, it also creates explanations for subgroups in the data and all of this jointly. We thus are creating explanations for granularities (between local and global). This multilevel aspect has not been sufficiently researched before. In fact recently  [4] has stressed the importance of having such multilevel explanations for successfully meeting the requirements of Europe’s General Data Protection Regulation (GDPR) [5]. They clearly state that simply having local or global explanations may not be sufficient for providing satisfactory explanations in many cases. There are also potential risks with this approach. The first is that if the base local explainer is non-robust or inaccurate [34, 35] then the explanations generated by our tree also may have to be considered cautiously. However this is not specific to our method, and applies to several post-hoc explainability methods that try to explain a black-box model. The way to mitigate this is to ensure that the local explanation methods are adapted (such as by choosing appropriate neighborhoods in LIME) to provide robust and accurate explanations. Another risk could be that such detailed multilevel explanations may reveal too much about the internals of the model (similar scenario for gradient-based models is discussed in [36]) and hence may raise privacy concerns. Mitigation could happen by selectively revealing the levels / pruning the tree or having a budget of explanations for each user to balance the level of explanations vs. the exposure of the black-box model.",Broader Impact,304,13,,,FALSE,FALSE,FALSE,Model Agnostic Multilevel Explanations,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Clustering,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Karthikeyan Natesan Ramamurthy', ' Bhanukiran Vinzamuri', ' Yunfeng Zhang', ' Amit Dhurandhar']",{'IBM Research'},0,1,0,{'USA'}
NeuMiss networks: differentiable programming for supervised learning with missing values.,"Marine Le Morvan, Julie Josse, Thomas Moreau, Erwan Scornet, Gael Varoquaux",NeuMiss networks: differentiable programming for supervised learning with missing values,42ae1544956fbe6e09242e6cd752444c,https://proceedings.neurips.cc/paper/2020/file/42ae1544956fbe6e09242e6cd752444c-Paper.pdf,"In our work, we proposed theoretical foundations to justify the use of a specific neural network architecture in the presence of missing-values. Neural networks are known for their challenging black-box nature. We believe that such theory leads to a better understanding of the mechanisms at work in neural networks. Our architecture is tailored for missing data. These are present in many applications, in particular in social or health data. In these fields, it is common for under-represented groups to exhibit a higher percentage of missing values (MNAR mechanism). Dealing with these missing values will definitely improve prediction for these groups, thereby reducing potential bias against these exact same groups. As any predictive algorithm, our proposal can be misused in a variety of context, including in medical science, for which a proper assessment of the specific characteristics of the algorithm output is required (assessing bias in prediction, prevent false conclusion resulting from misinterpreting outputs). Yet, by improving performance and understanding of a fundamental challenge in many applications settings, our work is not facilitating more unethical aspects of AI than ethical applications. Rather, medical studies that suffer chronically from limited sample sizes are mostly likely to benefit from the reduced sample complexity that these advances provide.",Broader Impact,204,10,,,FALSE,FALSE,FALSE,NeuMiss networks: differentiable programming for supervised learning with missing values.,Algorithms -> Missing Data,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Marine Le Morvan', ' Julie Josses', ' Thomas Moreau', ' Erwan Scornet', ' Gael Varoquaux']","{'Inria', 'INRIA', 'Parietal Team, INRIA', 'Ecole Polytechnique', 'CMAP / CNRS'}",1,1,1,"{'France', 'Switzerland'}"
Revisiting Parameter Sharing for Automatic Neural Channel Number Search,"Jiaxing Wang, Haoli Bai, Jiaxiang Wu, Xupeng Shi, Junzhou Huang, Irwin King, Michael Lyu, Jian Cheng",Revisiting Parameter Sharing for Automatic Neural Channel Number Search,42cd63cb189c30ed03e42ce2c069566c,https://proceedings.neurips.cc/paper/2020/file/42cd63cb189c30ed03e42ce2c069566c-Paper.pdf,"The goal of this paper is to build better understanding of parameter sharing in neural architecture search. Based on the observation and analysis, we propose a new parameter sharing scheme that enjoys both efficient searching and better architecture discrimination. Although the discussion is restricted to the channel number search for now, we hope it can shed more light in the general setting, and thereon inspire more general NAS algorithms that are both efficient and accurate. This research may benefit the recently popular area of automatic machine learning (AutoML). In AutoML, it saves much manual costs and eliminates repetitive labor to automatically design compact and high-performance models for various resource constrained platforms. These AI services can be readily applied in various applications and deployed on edge devices like smart phones. Abuse of these AI services, however, may bring excessive collection of personal data and increase the risk of malicious capturing private information. Besides, too little human intervention may leads to excessive trust in the model. The problem can be serious in cases such as automobile navigation. We believe that it is necessary for the community to conduct research to mitigate potential risks in AutoML.",Broader Impact,193,10,,,FALSE,FALSE,FALSE,Revisiting Parameter Sharing for Automatic Neural Channel Number Search,Deep Learning -> CNN Architectures,Algorithms -> AutoML; Deep Learning -> Efficient Training Methods,AutoML,"['Jiaxing Wang', ' Haoli Bai', ' Jiaxiang Wu', ' Xupeng Shi', ' Junzhou Huang', ' Irwin King', ' Michael Lyu', ' Jian Cheng']","{'University of Texas at Arlington / Tencent AI Lab', 'Northeastern University', 'The Chinese University of Hong Kong', 'CUHK', 'Chinese University of Hong Kong', 'Institute of Automation, Chinese Academy of Sciences', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
Differentially-Private Federated Linear Bandits,"Abhimanyu Dubey, Alex `Sandy' Pentland",Differentially-Private Federated Linear Bandits,4311359ed4969e8401880e3c1836fbe1,https://proceedings.neurips.cc/paper/2020/file/4311359ed4969e8401880e3c1836fbe1-Paper.pdf,"We envision a world that runs on data-dependent inference. Given the ease of availability of sensitive data, large-scale centralized data sources are not feasible to uphold the best interests and safety of the average user, and decentralized inference mechanisms are a feasible alternative balancing utility with important normative values as privacy, transparency and accountability. This research is a part of such a broader research goal, to create decentralized systems that maintain the security of the end-user in mind. We believe that methods like ours are a starting point for better private algorithms that can be readily deployed in industry, with appropriate guarantees as well. While there are several subsequent steps that can be improved both theoretically and practically, the design for this research from the ground-up has been to ensure robustness and security (sometimes) in lieu of efficiency.",Broader Impact,138,5,,,FALSE,FALSE,FALSE,Differentially-Private Federated Linear Bandits,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Large Scale Learning; Algorithms -> Online Learning; Reinforcement Learning and Planning -> Multi-Agent RL,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Abhimanyu Dubey', ' Pentland']",{'MIT'},1,0,0,{'USA'}
Is Plug-in Solver Sample-Efficient for Feature-based Reinforcement Learning?,"Qiwen Cui, Lin Yang",Is Plug-in Solver Sample-Efficient for Feature-based Reinforcement Learning?,43207fd5e34f87c48d584fc5c11befb8,https://proceedings.neurips.cc/paper/2020/file/43207fd5e34f87c48d584fc5c11befb8-Paper.pdf,"We believe that our work can benefit both theory and algorithm researches of model-based reinforcement learning (MBRL), as the sample efficiency of MBRL has been long observed but lack theoretical analysis. Previously few sample complexity results for MBRL in feature-based MDP exist, so people may wonder if the gap between theory and application is treatable. Our work answers this question positively by theoretically proving the simplest MBRL method, which is the plug-in solver approach, can reach the minimax sample complexity. Researchers that are interested in MBRL theory can benefit from our results and techniques. In addition, we give a thorough analysis on linear features and show that anchor-state condition can measure the quality of features. This result can guide reinforcement learning practioners to design features and sample efficient algorithms. We believe that our research has no negative societal effects.",Broader Impact,139,7,,,FALSE,FALSE,FALSE,Is Plug-in Solver Sample-Efficient for Feature-based Reinforcement Learning?,Reinforcement Learning and Planning -> Markov Decision Processes,Theory,Theory (including computational and statistical analyses),"['Qiwen Cui', ' Lin Yang']","{'UCLA', 'Peking University'}",1,0,0,"{'USA', 'China'}"
Learning Physical Graph Representations from Visual Scenes,"Daniel Bear, Chaofei Fan, Damian Mrowca, Yunzhu Li, Seth Alter, Aran Nayebi, Jeremy Schwartz, Li F. Fei-Fei, Jiajun Wu, Josh Tenenbaum, Daniel L. Yamins",Learning Physical Graph Representations from Visual Scenes,4324e8d0d37b110ee1a4f1633ac52df5,https://proceedings.neurips.cc/paper/2020/file/4324e8d0d37b110ee1a4f1633ac52df5-Paper.pdf,"This work attempts to bring computer vision closer to its human counterpart by explicitly modeling objects, their relationships, and their physical properties – aspects of what in Psychology has been called “Intuitive Physics.” Although these are merely early steps in this direction, we ultimately hope that having computer vision algorithms and agents that can interpret these aspects of our physical world will begin to address some of the well-known limitations of existing Deep Learning models: that they can be fooled by non-physical changes to their visual input and can easily overfit to statistical biases in their training data that do not reflect the true structure of the data-generating process. To this end, we have focused here on making the representations learned by our models interpretable and easily interrogated by people – indeed, we think this is one of the largest gaps between computer and human vision and the main reason that current algorithms have not yet matched their data categorization success on more physical tasks. That said, as algorithms (including ours) become able to reason about the real, physical world in more human-like ways, we will need to further ensure that they are only deployed on real-world tasks with careful consideration and human supervision. An algorithm that is able to manipulate objects in its environments could be used to do so in either beneficial or malicious ways, much as (e.g.) scene-categorizing CNNs can be put to ever broader purposes. Moreover, errors in how an algorithm such as ours interprets physical scenes – for instance, mistaking an unstable multi-object structure for a single stable object – could be costly if the model were relied on for understanding or altering scenes. We do not think that, as of now, our work will put any particular group of people at advantage or disadvantage because it is still being developed on relatively limited synthetic and real datasets with inanimate objects only; but we will be cautious in extending it to more human-centric environments.",Broader Impact,329,7,,,FALSE,FALSE,FALSE,Learning Physical Graph Representations from Visual Scenes,Algorithms -> Representation Learning,Algorithms -> Structured Prediction; Algorithms -> Unsupervised Learning; Applications -> Computer Vision; Neuroscience and Cognitive Science -> Visual Perception,Deep learning,"['Daniel Bear', ' Chaofei Fan', ' Damian Mrowca', ' Yunzhu Li', ' Seth Alter', ' Aran Nayebi', ' Jeremy Schwartz', 'Fei', ' Jiajun Wu', ' Josh Tenenbaum', ' Daniel Yamins']","{'Stanford', 'Stanford University', 'MIT', 'Google'}",1,1,1,{'USA'}
Deep Graph Pose: a semi-supervised deep graphical model for improved animal pose tracking,"Anqi Wu, Estefany Kelly Buchanan, Matthew Whiteway, Michael Schartner, Guido Meijer, Jean-Paul Noel, Erica Rodriguez, Claire Everett, Amy Norovich, Evan Schaffer, Neeli Mishra, C. Daniel Salzman, Dora Angelaki, Andrés Bendesky, The International Brain Laboratory The International Brain Laboratory, John P. Cunningham, Liam Paninski",Deep Graph Pose: a semi-supervised deep graphical model for improved animal pose tracking,4379cf00e1a95a97a33dac10ce454ca4,https://proceedings.neurips.cc/paper/2020/file/4379cf00e1a95a97a33dac10ce454ca4-Paper.pdf,"We propose a new method for animal behavioral tracking. As highlighted in the introduction and in [10], recent years have seen a rapid increase in the development of methods for animal pose estimation, which need to operate in a different regime than methods developed for human pose estimation. Our work significantly improves the state of the art for animal pose estimation, and thus advances behavioral analysis for animal research, an essential task for scientific discovery in fields ranging from neuroscience to ecology. Finally, our work represents a compelling fusion of deep learning methods with probabilistic graphical model approaches to statistical inference, and we hope to see more fruitful interactions between these rich topic areas in the future.",Broader Impact,117,4,,,FALSE,FALSE,FALSE,Deep Graph Pose: a semi-supervised deep graphical model for improved animal pose tracking,Neuroscience and Cognitive Science -> Neuroscience,Algorithms -> Semi-Supervised Learning; Algorithms -> Structured Prediction; Applications -> Tracking and Motion in Video; Probabilistic Methods -> Graphical Models,Neuroscience and cognitive science,"['Anqi Wu', ' Kelly Buchanan', ' Matthew Whiteway', ' Michael Schartner', ' Guido Meijer', 'Paul Noel', ' Erica Rodriguez', ' Claire Everett', ' Amy Norovich', ' Evan Schaffer', ' Neeli Mishra', ' Daniel Salzman', ' Dora Angelaki', ' Andrés Bendesky', ' The International Brain Laboratory The International Brain Laboratory', ' John Cunningham', ' Liam Paninski']","{'University of Columbia', 'The International Brain Laboratory', 'Columbia University', 'Champalimaud Center for the Unknown', 'University of Geneva', 'New York University'}",1,0,0,"{'USA', 'Portugal', 'Switzerland'}"
Meta-learning from Tasks with Heterogeneous Attribute Spaces,"Tomoharu Iwata, Atsutoshi Kumagai",Meta-learning from Tasks with Heterogeneous Attribute Spaces,438124b4c06f3a5caffab2c07863b617,https://proceedings.neurips.cc/paper/2020/file/438124b4c06f3a5caffab2c07863b617-Paper.pdf,"The proposed method improves regression/classification performance even when a small number of labeled data are given by training from various tasks whose attribute spaces are different from the target tasks. The proposed method can be used for applications where machine learning has not been used due to the scarcity of labeled data. The proposed method could reduce the cost of manual labeling for increasing labeled data. Since the proposed method can use various datasets with heterogeneous attribute spaces for training, there is a potential risk that users might include biased datasets without careful thought in training datasets, which might result in biased predictions. We encourage research to automatically detect biased datasets. Although the proposed method improves performance, the prediction might be not always correct. We encourage research to estimate the uncertainty of the prediction by meta-learning from tasks with heterogeneous attribute spaces.",Broader impact,142,7,,,FALSE,FALSE,FALSE,Meta-learning from Tasks with Heterogeneous Attribute Spaces,Algorithms -> Meta-Learning,Algorithms -> Few-Shot Learning; Algorithms -> Multitask and Transfer Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Tomoharu Iwata', ' Atsutoshi Kumagai']","{'NTT Software Innovation Center', 'NTT'}",0,1,0,{'Japan'}
Estimating decision tree learnability with polylogarithmic sample complexity,"Guy Blanc, Neha Gupta, Jane Lange, Li-Yang Tan",Estimating decision tree learnability with polylogarithmic sample complexity,439d8c975f26e5005dcdbf41b0d84161,https://proceedings.neurips.cc/paper/2020/file/439d8c975f26e5005dcdbf41b0d84161-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Estimating decision tree learnability with polylogarithmic sample complexity,Theory -> Computational Learning Theory,Algorithms -> Active Learning; Algorithms -> Classification,Theory (including computational and statistical analyses),"['Guy Blanc', ' Neha Gupta', ' Jane Lange', 'Yang Tan']",{'Stanford University'},1,0,0,{'USA'}
Sparse Symplectically Integrated Neural Networks,"Daniel DiPietro, Shiying Xiong, Bo Zhu",Sparse Symplectically Integrated Neural Networks,439fca360bc99c315c5882c4432ae7a4,https://proceedings.neurips.cc/paper/2020/file/439fca360bc99c315c5882c4432ae7a4-Paper.pdf,"This research marks a significant advancement in using machine learning as a tool to assist in human discovery. We demonstrate that complex Hamiltonian physical systems–systems that in many cases have taken substantial human work and time to describe–can be readily learned and accurately predicted to very high precision from small amounts of data. As dynamical systems are everywhere, the impact of this work is far-reaching. Potential areas of noteworthy application include astronomy, medicine, engineering, and weather prediction. While our model itself does not necessarily bring about significant ethical considerations, researchers should take care whenever applying such models to domains prone to data bias, such as medicine.",Broader Impact,106,5,,,FALSE,FALSE,FALSE,Sparse Symplectically Integrated Neural Networks,Algorithms -> Dynamical Systems,Algorithms -> Sparsity and Compressed Sensing,Dynamical Systems,"['Daniel DiPietro', ' Shiying Xiong', ' Bo Zhu']",{'Dartmouth College'},1,0,0,{'USA'}
Continuous Object Representation Networks: Novel View Synthesis without Target View Supervision,"Nicolai Hani, Selim Engin, Jun-Jee Chao, Volkan Isler",Continuous Object Representation Networks: Novel View Synthesis without Target View Supervision,43a7c24e2d1fe375ce60d84ac901819f,https://proceedings.neurips.cc/paper/2020/file/43a7c24e2d1fe375ce60d84ac901819f-Paper.pdf,"Our approach to learning novel view synthesis has the immediate possibility of enabling augmented and virtual reality applications [37, 20]. The limited requirement of only two images per object will make these techniques applicable beyond synthetic data. As with any generative model that provides tools for image manipulation, we too run the risk of producing fake visual content that can be exploited for malicious causes. While visual object rotation itself does not have direct negative consequences, the mere fact that such manipulations are possible can erode the public’s trust in published images [34]. Image manipulation is not a new phenomenon, however, and there has been research trying to detect manipulated images [41, 2] automatically. Still, more work on and broader adoption of such techniques is needed to mitigate image manipulation’s adverse effects.",Broader Impact,132,6,,,FALSE,FALSE,FALSE,Continuous Object Representation Networks: Novel View Synthesis without Target View Supervision,Applications -> Computer Vision,Algorithms -> Unsupervised Learning; Deep Learning -> Generative Models,Vision,"['Nicolai Hani', ' Selim Engin', 'Jee Chao', ' Volkan Isler']","{'University of Minnesota, Twin Cities', 'University of Minnesota'}",1,0,0,{'USA'}
Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence,"Thomas Sutter, Imant Daunhawer, Julia Vogt",Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence,43bb733c1b62a5e374c63cb22fa457b4,https://proceedings.neurips.cc/paper/2020/file/43bb733c1b62a5e374c63cb22fa457b4-Paper.pdf,"Learning from multiple data types offers many potential applications and opportunities as multiple data types naturally co-occur. We intend to apply our model in the medical domain in future work, and we will focus here on the impact our model might have in the medical application area. Models that are capable of dealing with large-scale multi-modal data are extremely important in the field of computational medicine and clinical data analysis. The recent developments in medical information technology have resulted in an overwhelming amount of multi-modal data available for every single patient. A patient visit at a hospital may result in tens of thousands of measurements and structured information, including clinical factors, diagnostic imaging, lab tests, genomic and proteomic tests, and hospitals may see thousands of patients each year. The ultimate aim is to use all this vast information for a medical treatment tailored to the needs of an individual patient. To turn the vision of precision medicine into reality, there is an urgent need for the integration of the multi-modal patient data currently available for improved disease diagnosis, prognosis and therapy outcome prediction. Instead of learning on one data set exclusively, as for example just on images or just on genetics, the aim is to improve learning and enhance personalized treatment by using as much information as possible for every patient. First steps in this direction have been successful, but so far a major hurdle has been the huge amount of heterogeneous data with many missing data points which is collected for every patient. With this work, we lay the theoretical foundation for the analysis of large-scale multi-modal data. We focus on a self-supervised approach as collecting labels for large datasets of multiple data types is expensive and becomes quickly infeasible with a growing number of modalities. Self-supervised approaches have the potential to overcome the need for excessive labelling and the bias coming from these labels. In this work, we extensively tested the model in controlled environments. In future work, we will apply our proposed model to medical multi-modal data with the goal of gaining insights and making predictions about disease phenotypes, disease progression and response to treatment.",6 Broader Impact,358,14,,,FALSE,FALSE,FALSE,Multimodal Generative Learning Utilizing Jensen-Shannon-Divergence,Algorithms -> Multimodal Learning,Algorithms -> Semi-Supervised Learning; Deep Learning -> Generative Models; Probabilistic Methods -> Latent Variable Models,Probabilistic methods and inference,"[' Sutter', ' Imant Daunhawer', ' Julia Vogt']",{'ETH Zurich'},1,0,0,{'Switzerland'}
Solver-in-the-Loop: Learning from Differentiable Physics to Interact with Iterative PDE-Solvers,"Kiwon Um, Robert Brand, Yun (Raymond) Fei, Philipp Holl, Nils Thuerey",Solver-in-the-Loop: Learning from Differentiable Physics to Interact with Iterative PDE-Solvers,43e4e6a6f341e00671e123714de019a8,https://proceedings.neurips.cc/paper/2020/file/43e4e6a6f341e00671e123714de019a8-Paper.pdf,"PDE-based models are very commonly used and can be applied to a wide range of applications, including weather and climate, epidemics, civil engineering, manufacturing processes, and medical applications. Our work has the potential to improve how these PDEs are solved. As PDE-solvers have a long history, there is a wide range of established tools, some of which still use COBOL and FORTRAN. Hence, it will not be easy to integrate deep learning methods into the existing solving pipelines, but in the long run, our method could yield solvers that compute more accurate solutions with a given amount of computational resources. Due to the wide range of applications of PDEs, our methods could also be used in the development of military equipment (machines and weapons) or other harmful systems. However, our method shares this danger with all numerical methods. For the discipline of computational science as a whole, we see more positive aspects when computer simulations become more powerful. Nonetheless, we will encourage users of our method likewise to consider ethical implications when employing PDE-solvers with learning via differentiable physics.",Broader Impact,179,8,,,FALSE,FALSE,FALSE,Solver-in-the-Loop: Learning from Differentiable Physics to Interact with Iterative PDE-Solvers,Algorithms -> Semi-Supervised Learning,Algorithms -> Regression; Algorithms -> Representation Learning; Deep Learning -> Supervised Deep Networks,"Other applications (e.g., robotics, biology, climate, finance)","['Kiwon Um', ' Yun', ' Fei', ' Philipp Holl', ' Robert Brand', ' Nils Thuerey']","{'Technical University of Munich', 'Telecom Paris, IP Paris', 'Columbia University', 'Raymond'}",1,0,0,"{'France', 'USA', 'Germany'}"
Reinforcement Learning with General Value Function Approximation: Provably Efficient Approach via Bounded Eluder Dimension,"Ruosong Wang, Russ R. Salakhutdinov, Lin Yang",Reinforcement Learning with General Value Function Approximation: Provably Efficient Approach via Bounded Eluder Dimension,440924c5948e05070663f88e69e8242b,https://proceedings.neurips.cc/paper/2020/file/440924c5948e05070663f88e69e8242b-Paper.pdf,"This work is mainly theoretical. By devising a provably efficient RL algorithm with general value func- tion approximation, we believe our various theoretical insights could potentially guide practitioners to build theoretically-principled and robust RL systems.",Broader Impact,35,2,FALSE,FALSE,FALSE,FALSE,FALSE,Reinforcement Learning with General Value Function Approximation: Provably Efficient Approach via Bounded Eluder Dimension,Reinforcement Learning and Planning,Theory,,"['Ruosong Wang', ' Russ Salakhutdinov', ' Lin Yang']","{'UCLA', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Predicting Training Time Without Training,"Luca Zancato, Alessandro Achille, Avinash Ravichandran, Rahul Bhotika, Stefano Soatto",Predicting Training Time Without Training,440e7c3eb9bbcd4c33c3535354a51605,https://proceedings.neurips.cc/paper/2020/file/440e7c3eb9bbcd4c33c3535354a51605-Paper.pdf,"This paper does not address a particular task, or a particular dataset, but rather addresses the technical issue of how to predict time and compute resources. As such, we expect it will benefit individual researchers with limited computational resources, by allowing them to optimize for maximum impact. It also goes towards better understanding of the functioning of deep networks, so in that sense it could be thought of as contributing to improved interpretability of deep learning, in a broad sense. At this time, we do not foresee negative impacts beyond inaccurate predictions for some tasks and their consequences, which are mainly in the realm of waste of resources rather than changed outcomes. We have observed that our method yield predictions that have lower accuracy on some tasks rather than others, for instance it has lower accuracy on texture-based tasks than object classification. However, since we consider datasets as a whole, prediction inaccuracies do not impact any particular cohort or segment of the data.",Broader Impact,163,6,,,FALSE,FALSE,FALSE,Predicting Training Time Without Training,Deep Learning -> Optimization for Deep Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Luca Zancato', ' Alessandro Achille', ' Avinash Ravichandran', ' Rahul Bhotika', ' Stefano Soatto']","{'UCLA', 'AWS', 'University of Padova', 'Amazon Web Services', 'Amazon'}",1,1,1,"{'Italy', 'USA'}"
How does This Interaction Affect Me? Interpretable Attribution for Feature Interactions,"Michael Tsang, Sirisha Rambhatla, Yan Liu",How does This Interaction Affect Me? Interpretable Attribution for Feature Interactions,443dec3062d0286986e21dc0631734c9,https://proceedings.neurips.cc/paper/2020/file/443dec3062d0286986e21dc0631734c9-Paper.pdf,"The purpose of this work is to provide new insights into existing and future prediction models. The explanations from Archipelago can be used by both machine learning practitioners and audiences without background expertise. The societal risk of this work is any overdependence on Archipelago . Users of this explanation method should consider the merits of not only this method but also other explanation methods for their use cases. For example, users may want fine-grained pixel-level explanations of image classifications whereas our explanations may require superpixel segmentation. Nevertheless, we believe this work can help reveal biases in prediction models, assist in scientific discovery, and stimulate discussions on how to debug models based on feature interactions.",Broader Impact,114,6,,,FALSE,FALSE,FALSE,How does This Interaction Affect Me? Interpretable Attribution for Feature Interactions,"Deep Learning -> Visualization, Interpretability, and Explainability","Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Deep learning,"['Michael Tsang', ' Sirisha Rambhatla', ' Yan Liu']",{'University of Southern California'},1,0,0,{'USA'}
Optimal Adaptive Electrode Selection to Maximize Simultaneously Recorded Neuron Yield,"John Choi, Krishan Kumar, Mohammad Khazali, Katie Wingel, Mahdi Choudhury, Adam S. Charles, Bijan Pesaran",Optimal Adaptive Electrode Selection to Maximize Simultaneously Recorded Neuron Yield,445e1050156c6ae8c082a8422bb7dfc0,https://proceedings.neurips.cc/paper/2020/file/445e1050156c6ae8c082a8422bb7dfc0-Paper.pdf,"This report describes a technique that can improve the effectiveness of brain-machine interfaces. As devices such as electrode arrays scale up in their capabilities and their safety, new opportunities emerge for treating neuropsychiatric conditions. Treatments that monitor the activity of thousands or millions of neurons to deliver precise feedback control of aberrant activity could address a host of brain disorders when treatment is pharmacologically intractable. This strategy is already being applied in experimental treatments for movement disorders and the early detection and prevention of seizures, potentially improving the quality of life for tens of millions of patients globally. We envision that eventually, mood disorders or conditions where inter-areal communication channels in the brain are lost or dysfunctional could one day be repaired using large-scale neural recording and stimulation techniques. However, new devices that record massive amounts of neural data could expose the user to breaches of privacy in a way that has not been encountered previously. Rich brain activity data, unfiltered by intention or the bounds of normal communication, could be accessed covertly by malicious actors or state surveillance. Developing a security model should be a high priority for these devices as they continue to translate into the clinic, especially as these devices will likely be connected in some way to the internet. More broadly, optimal channel selection could benefit other areas of neuroscientific research. Our method leads to the recording of 41-85% more neurons per unit time over previous methods when using the Neuropixel probe. The Neuropixel is being widely adopted in labs across the field, and it is being used as a standard tool in large collaborative efforts such as the International Brain Lab [8]. Other neural-matrix style probes for neural spike-band recordings [17] as well as high-density electrocorticographic (ECoG) arrays can benefit from electrode selection [1]. In all cases, our method can shorten the amount of recording time needed for producing the same scientific conclusions. Reduction of required experimental time, or reduction in the number of animals needed for a study, would also be welcome from an animal welfare perspective. Our algorithm confers the most benefit to specific neurotechnologies that face a physical bottleneck, which in the case of the Neuropixel, is wiring. Many of these new devices are an order of magnitude more costly than previous low-bandwidth counterparts. As with all new neurotechnologies, our method might most immediately benefit labs or individuals with more financial resources. In the long-term, however, we hope that these new technologies will become more widely accessible.",Broader Impact,415,18,,,FALSE,FALSE,FALSE,Optimal Adaptive Electrode Selection to Maximize Simultaneously Recorded Neuron Yield,Neuroscience and Cognitive Science -> Brain-Computer Interfaces and Neural Prostheses,Neuroscience and Cognitive Science -> Brain Mapping; Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and cognitive science,"['John Choi', ' Krishan Kumar', ' Mohammad Khazali', ' Katie Wingel', ' Mahdi Choudhury', ' Adam Charles', ' Bijan Pesaran']","{'New York University', 'Johns Hopkins University'}",1,0,0,{'USA'}
Neurosymbolic Reinforcement Learning with Formally Verified Exploration,"Greg Anderson, Abhinav Verma, Isil Dillig, Swarat Chaudhuri",Neurosymbolic Reinforcement Learning with Formally Veri fi ed Exploration,448d5eda79895153938a8431919f4c9f,https://proceedings.neurips.cc/paper/2020/file/448d5eda79895153938a8431919f4c9f-Paper.pdf,"In the recent past, reinforcement learning has seen numerous advances and found applications in safety-critical settings. System failures in this setting can result in signi fi cant loss of property or even loss of life. This work takes a step towards solving this problem by guaranteeing that RL agents do not violate safety properties. As with any safety-related work, the consequences of failure or misuse of this technique can be severe. Speci fi cally, there is a risk that a user might assume that their system is guaranteed safe when this is not the case (for example, if the user fails to adequately specify the environment or safety property). Writing correct safety speci fi cations is known to be hard, so inexpert users may feel an unwarranted sense of security. While misuse of the tool carries great risk, proper use can confer substantial advantages. In particular, it may allow the bene fi ts of RL to be brought to domains, such as robotics and autonomous vehicles, where failure has a very high cost.",Broader Impact,173,8,,,FALSE,FALSE,FALSE,Neurosymbolic Reinforcement Learning with Formally Verified Exploration,Reinforcement Learning and Planning -> Reinforcement Learning,Applications -> Automated Reasoning and Formal Methods; Reinforcement Learning and Planning -> Exploration; Social Aspects of Machine Learning -> AI Safety,Reinforcement learning and planning,"['Greg Anderson', ' Abhinav Verma', ' Isil Dillig', ' Swarat Chaudhuri']","{'Rice University', 'UT Austin', 'The University of Texas at Austin', 'University of Texas at Austin'}",1,0,0,{'USA'}
Wavelet Flow: Fast Training of High Resolution Normalizing Flows,"Jason J. Yu, Konstantinos G. Derpanis, Marcus A. Brubaker",Wavelet Flow: Fast Training of High Resolution Normalizing Flows,4491777b1aa8b5b32c2e8666dbe1a495,https://proceedings.neurips.cc/paper/2020/file/4491777b1aa8b5b32c2e8666dbe1a495-Paper.pdf,"This work contributes to the domain of generative image modelling, which constructs probabilistic models of images, allowing the generation, and manipulation of high resolution images. As this domain grows, these tasks become more accessible due to reduced labour, and skill barriers. On a positive side, this accessibility can empower artists and content creators with powerful tools for their craft. Many other processes used today are data driven, e.g. , semantic segmentation, and could benefit from the ability to create new data. Generative models are also useful in applications beyond content generation. In particular, they can be used as priors in other signal processing tasks including image restoration, and super resolution. The computational costs of machine learning are of increasing concern as a potential future source of social and economic inequality. Reducing the need for specialized, large-scale hardware for training, as the approach proposed here does, can lower the barrier to entry for individuals and groups which would otherwise be unable to afford the large compute clusters necessary. As with all tools, generative models have no intentions of their own. Their impact is defined by those who wield them. Media platforms play an important role in our lives, and as a result can be used for disinformation. A major difficulty in preventing disinformation is the asymmetry between the capacity to create and detect disinformation. If the detection of disinformation is more difficult than its creation, its prevention may become impossible in practice. Our contributions primarily serve to reduce the costs of content generation. Specifically, the ability to operate on high resolution images at a reduced cost makes it easier for actors that wish to create convincing content in large volumes. Consequently, this could worsen the battle against disinformation. Even without actors that are intentionally malicious, reduced barriers to these tools could increase the absolute amount of unintentional misuse. The nature of generative models encourages them to adopt biases in the data used to train them. Without caution, a user could introduce biases to a generative model that may discriminate against certain groups of people. This model could then be easily used to create large quantities of data that contain this bias. This could take the form of data used in other downstream processes, or directly as content consumed by people. These concerns assume unopposed misuse of generative methods. Complementary research into the detection of generated content could mitigate these potential consequences. Much like how active research into adversarial attacks continuously competes with research into robust recognition methods, generative methods can exist at an equilibrium with methods used to detect their use, and biases, preventing runaway consequences.",Broader Impact,435,24,,,FALSE,FALSE,FALSE,Wavelet Flow: Fast Training of High Resolution Normalizing Flows,Deep Learning -> Generative Models,Applications -> Computer Vision,Deep learning,"['Jason Yu', ' Konstantinos Derpanis', ' Marcus Brubaker']","{'York University', 'Ryerson University'}",1,0,0,{'Canada'}
Multi-task Batch Reinforcement Learning with Metric Learning,"Jiachen Li, Quan Vuong, Shuang Liu, Minghua Liu, Kamil Ciosek, Henrik Christensen, Hao Su",Multi-task Batch Reinforcement Learning with Metric Learning,4496bf24afe7fab6f046bf4923da8de6,https://proceedings.neurips.cc/paper/2020/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf,"Positive impact Our work provides a solution to learn a policy that generalizes to a set of similar tasks from only observational data. The techniques we propose have great potential to benefit various areas of the whole society. For example in the field of healthcare, we hope the proposed triplet loss design with hard negative mining can enable us to robustly train an automatic medical prescription system from a large batch of medical histories of different diseases and further generalize to new diseases [61], e.g., COVID-19. Moreover, in the field of robotics, our methods can enable the learning of a single policy that solves a set of similar unseen tasks from only historical robot experiences, which tackles the sample efficiency issues given that sampling is expensive in the field of real-world robotics [46]. Even though in some fields that require safe action selections, e.g, autonomous driving [62] and medical prescription, our learned policy cannot be immediately applied, it can still serve as a good prior to accelerate further training. Negative impact Evidently, the algorithm we proposed is a data-driven methods. Therefore, it is very likely that it will be biased by the training data. Therefore, if the testing tasks are very different from the training tasks, the learned policy may even result in worse behaviors than random policy, leading to safety issues. This will motivate research into safe action selection and distributional shift identification when learning policies for sequential process from only observational data.",Broader Impact,244,9,,,TRUE,TRUE,FALSE,Multi-task Batch Reinforcement Learning with Metric Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement learning and planning,"['Jiachen Li', ' Quan Vuong', ' Shuang Liu', ' Minghua Liu', ' Kamil Ciosek', ' Henrik Christensen', ' Hao Su']","{'University of California San Diego', 'UCSD', 'UC San Diego', 'Microsoft', 'University of California, San Diego'}",1,1,1,{'USA'}
On 1/n neural representation and robustness,"Josue Nassar, Piotr Sokol, Sueyeon Chung, Kenneth D. Harris, Il Memming Park",On 1 /n neural representation and robustness,44bf89b63173d40fb39f9842e308b3f9,https://proceedings.neurips.cc/paper/2020/file/44bf89b63173d40fb39f9842e308b3f9-Paper.pdf,"Adversarial attacks pose threats to the safe deployment of AI systems– both safety from malicious attacks but also robustness that would be expected in intelligent devices such as self-driving cars [37] but also facial recognition systems. Our neuroscience-inspired approach, unlike widely use adversarial attack defenses, does not require generation of adversarial input samples, therefore it potentially avoids the pitfalls of unrepresentative datasets. Furthermore, our study shows possibilities for the improvement of artificial systems with insights gained from biological systems which are naturally robust. Conversely it also provides a deeper, mechanistic understanding of experimental data from the field of neuroscience, thereby advancing both fields at the same time.",Broader Impact,107,4,,,FALSE,FALSE,FALSE,On 1/n neural representation and robustness,Neuroscience and Cognitive Science,Deep Learning,Neuroscience and cognitive science,"['Josue Nassar', ' Piotr Sokol', ' Sueyeon Chung', ' Kenneth D Harris', ' Il Memming Park']","{'Stony Brook University', 'Columbia University', 'UCL'}",1,0,0,"{'UK', 'USA'}"
Boundary thickness and robustness in learning models,"Yaoqing Yang, Rajiv Khanna, Yaodong Yu, Amir Gholami, Kurt Keutzer, Joseph E. Gonzalez, Kannan Ramchandran, Michael W. Mahoney",Boundary thickness and robustness in learning models,44e76e99b5e194377e955b13fb12f630,https://proceedings.neurips.cc/paper/2020/file/44e76e99b5e194377e955b13fb12f630-Paper.pdf,"The proposed concept of boundary thickness can improve our fundamental understanding of robust- ness in machines learning and neural networks, and thus it provides new ways to interpret black-box models and improve existing robustness techniques. It can help researchers devise novel training procedures to combat data and model corruption, and it can also provide diagnosis to trained machine learning models and newly proposed regularization or data augmentation techniques. The proposed work will mostly benefit safety-critical applications, e.g., autonomous driving and cybersecurity, and it may also make AI-based systems more reliable to natural corruptions and imperfections. These benefits are critical because there is usually a gap between the performance of learning-based systems on well-studied datasets and in real-life scenarios.  We will conduct further experimental and theoretical research to understand the limitations of boundary thickness, both as a metric and as a general guideline to design training procedures. We also believe that the machine learning community needs to conduct further research to enhance the fundamental understandings of the structure of decision boundaries and the connection to robustness. For instance, it is useful to design techniques to analyze and visualize decision boundaries during both training (e.g., how the decision boundary evolves) and testing (e.g., how to find defects in the boundary.) We believe this will benefit both the safety and accountability of learning-based systems.",6 Broader Impact,221,8,,,FALSE,FALSE,FALSE,Boundary thickness and robustness in learning models,Algorithms -> Adversarial Learning,Deep Learning -> Analysis and Understanding of Deep Networks,,"['Yaoqing Yang', ' Rajiv Khanna', ' Yaodong Yu', ' Amir Gholami', ' Kurt Keutzer', ' Joseph Gonzalez', ' Kannan Ramchandran', ' Michael W Mahoney']","{'UC Berkeley', 'University of California, Berkeley', 'EECS, UC Berkeley'}",1,0,0,{'USA'}
Demixed shared component analysis of neural population data from multiple brain areas,"Yu Takagi, Steven Kennerley, Jun-ichiro Hirayama, Laurence Hunt",Demixed shared component analysis of neural population data from multiple brain areas,44ece762ae7e41e3a0b1301488907eaa,https://proceedings.neurips.cc/paper/2020/file/44ece762ae7e41e3a0b1301488907eaa-Paper.pdf,"Although several studies have investigated communication between populations of neurons, task- related communication has been ignored. This is of fundamental importance in neuroscience, and we show that it can be achieved simply by extending the previous method. We believe our methods will be beneficial to the neuroscientists who will investigate interaction among multiple brain areas in terms of specific task parameter of interest.",Broader Impact,63,3,,,FALSE,FALSE,FALSE,Demixed shared component analysis of neural population data from multiple brain areas,Neuroscience and Cognitive Science,Neuroscience and Cognitive Science -> Cognitive Science; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Perception,,"['Yu Takagi', ' Steven Kennerley', 'ichiro Hirayama', ' Laurence Hunt']","{'AIST', 'University of Oxford'}",1,0,0,{'UK'}
Learning Kernel Tests Without Data Splitting,"Jonas Kübler, Wittawat Jitkrittum, Bernhard Schölkopf, Krikamol Muandet",Learning Kernel Tests Without Data Splitting,44f683a84163b3523afe57c2e008bc8c,https://proceedings.neurips.cc/paper/2020/file/44f683a84163b3523afe57c2e008bc8c-Paper.pdf,"Hypothesis testing and valid inference after model selection are fundamental problems in statistics, which have recently attracted increasing attention also in machine learning. Kernel tests such as MMD are not only used for statistical testing, but also to design algorithms for deep learning and GANs [41, 42]. The question of how to select the test statistic naturally arises in kernel-based tests because of the kernel choice problem. Our work shows that it is possible to overcome the need of (wasteful and often heuristic) data splitting when designing hypothesis tests with feasible null distribution. Since this comes without relevant increase in computational resources we expect the proposed method to replace the data splitting approach in applications that fit the framework considered in this work. Theorem 1 is also applicable beyond hypothesis testing and extends the previously known PSI framework proposed by Lee et al. [24].",Broader impact,144,7,,,FALSE,FALSE,FALSE,Learning Kernel Tests Without Data Splitting,Algorithms -> Kernel Methods,Algorithms -> Model Selection and Structure Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jonas Kübler', ' Wittawat Jitkrittum', ' Bernhard Schölkopf', ' Krikamol Muandet']","{'MPI for Intelligent Systems, Tübingen', 'MPI for Intelligent Systems', 'Max Planck Institute for Intelligent Systems'}",1,0,0,{'Germany'}
Unsupervised Data Augmentation for Consistency Training,"Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, Quoc Le",Unsupervised Data Augmentation for Consistency Training,44feb0096faa8326192570788b38c1d1,https://proceedings.neurips.cc/paper/2020/file/44feb0096faa8326192570788b38c1d1-Paper.pdf,"This work show that it is possible to achieve great performance with limited labeled data. Hence groups/institutes with limited budgets for annotating data may benefit from this research. To the best of our knowledge, nobody will be put at disadvantage from this research. Our method does not leverage biases in the data. Our tasks include standard benchmarks such as IMDb, CIFAR-10, SVHN and ImageNet.",Broader Impact,64,5,,,FALSE,FALSE,FALSE,Unsupervised Data Augmentation for Consistency Training,Algorithms -> Semi-Supervised Learning,Algorithms -> Classification,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Qizhe Xie', ' Zihang Dai', ' Eduard Hovy', ' Thang Luong', ' Quoc V Le']","{'Google Brain', 'Carnegie Mellon University', 'Google', 'CMU, Google Brain', 'CMU'}",1,1,1,{'USA'}
Subgroup-based Rank-1 Lattice Quasi-Monte Carlo,"Yueming LYU, Yuan Yuan, Ivor Tsang",Subgroup-based Rank-1 Lattice Quasi-Monte Carlo,456048afb7253926e1fbb7486e699180,https://proceedings.neurips.cc/paper/2020/file/456048afb7253926e1fbb7486e699180-Paper.pdf,"In this paper, we proposed a closed-form rank-one lattice construction based on group theory for Quasi-Monte Carlo. Our method does not require the time-consuming exhaustive computer search. Our method is a fundamental tool for integral approximation and sampling. Our method may serve as a potential advance in QMC, which may have an impact on a wide range of applications that rely on integral approximation. It includes kernel approximation with feature map, variational inference in Bayesian learning, generative modeling, and variational autoencoders. This may bring useful applications and be beneficial to society and the community. Since our method focuses more on the theoretical side, the direct negative influences and ethical issues are negligible.",Broader Impact,112,7,,,FALSE,FALSE,FALSE,Subgroup-based Rank-1 Lattice Quasi-Monte Carlo,Probabilistic Methods,,Quasi Monte Carlo,"['Yueming LYU', ' Yuan Yuan', ' Ivor Tsang']","{'MIT', 'University of Technology Sydney', 'University of Technology, Sydney'}",1,0,0,"{'Australia', 'USA'}"
Minibatch vs Local SGD for Heterogeneous Distributed Learning,"Blake E. Woodworth, Kumar Kshitij Patel, Nati Srebro",Minibatch vs Local SGD for Heterogeneous Distributed Learning,45713f6ff2041d3fdfae927b82488db8,https://proceedings.neurips.cc/paper/2020/file/45713f6ff2041d3fdfae927b82488db8-Paper.pdf,"Distributed optimization is an important problem with significant implications for the success and feasibility of large scale machine learning. In recent years, the optimization community has expended significant efforts into trying to analyze and understand a seemingly simple and appealing algorithm— Local SGD. The recent work of Woodworth et al. [23] shows that much of these efforts were in vain, resulting in guarantees that do not show improvement over the familiar Minibatch SGD. However, their analysis was limited to the homogeneous case. Understanding distributed learning for heterogeneous data is important as the setting arises quite naturally, for example, when different servers or devices have data with different characteristics. Our analysis can provide clarity for the field by highlighting (i) the important regimes and important questions to focus on, (ii) what types of guarantees can help progress, and (iii) what regimes require new algorithms to be developed. Such improved focus can significantly improve and accelerate development, which in turn can have significant practical implications wherever distributed learning is used (which is increasingly everywhere). As with many other distributed optimization papers, we focus here on reaching consensus between the different machines. However, in many, if not most, heterogeneous data settings, this could be undesirable, since insisting on a single solution (e.g. single predictor or single model) for different distributions may be sub-optimal, and may also perform very poorly on outlier distributions, which could disproportionately affect atypical users, minority groups or groups for which less training data is available. Therefore, it may sometimes be preferable to take a different, pluralistic approach to distributed learning, where different predictors are learned for each individual distribution, but where commonalities are leveraged to improve performance. This can be more fair and/or more efficient. Although in this paper we focus on achieving consensus, in part so as to align it with existing literature, the ideas developed here can also be applicable in studying pluralistic approaches.",Broader impact,317,13,,,FALSE,FALSE,FALSE,Minibatch vs Local SGD for Heterogeneous Distributed Learning,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Blake Woodworth', ' Kumar Kshitij Patel', ' Nati Srebro']","{'Toyota Technological Institute at Chicago', 'TTIC', 'TTI-Chicago'}",1,1,1,"{'USA', 'Israel'}"
Multi-task Causal Learning with Gaussian Processes,"Virginia Aglietti, Theodoros Damoulas, Mauricio Álvarez, Javier Gonzalez",Multi-task Causal Learning with Gaussian Processes,45c166d697d65080d54501403b433256,https://proceedings.neurips.cc/paper/2020/file/45c166d697d65080d54501403b433256-Paper.pdf,"Computing causal effects is an integral part of scientific inquiry, spanning a wide range of questions such as understanding behaviour in online systems, assessing the effect of social policies, or investigation the risk factors for diseases. By combining the theory of causality with machine learning  techniques, Causal Machine Learning algorithms have the potential to highly impact society and businesses by answering what-if questions, enabling policy-evaluation and allowing for data-driven decision making in real-world contexts. The algorithm proposed in this paper falls into this category and focuses on addressing causal questions in a fast and accurate way. As shows in the experiments, when used within decision making algorithms, the DAG - GP model has the potential to speed up the learning process and to enable optimal experimentation decisions by accounting for the multiple causal connections existing in the process under investigation and their cross-correlation. Our algorithm can be used by practitioners in several domains. For instance, it can be used to learn about the impact of environmental variables on coral calcification [12] or to analyse the effects of drugs on cancer antigens [13]. In terms of methodology, while the DAG - GP model represents a step towards a better model for automated decision making, it is based on the crucial assumption of knowing the causal graph. Learning the intervention functions of an incorrect causal graph might lead to incorrect inference and sub-optimal decisions. Therefore, more work needs to be done to account for the uncertainty in the graph structure.",Broader Impact,248,9,,,FALSE,FALSE,FALSE,Multi-task Causal Learning with Gaussian Processes,Probabilistic Methods -> Gaussian Processes,,Probabilistic methods and inference,"['Virginia Aglietti', ' Theodoros Damoulas', ' Mauricio Álvarez', ' Javier Gonzalez']","{'University of Warwick', 'University of Sheffield'}",1,0,0,{'UK'}
Proximity Operator of the Matrix Perspective Function and its Applications,Joong-Ho Won,Proximity Operator of the Matrix Perspective Function and its Applications,45f31d16b1058d586fc3be7207b58053,https://proceedings.neurips.cc/paper/2020/file/45f31d16b1058d586fc3be7207b58053-Paper.pdf,Not applicable.,Broader Impact,2,1,TRUE,FALSE,FALSE,FALSE,FALSE,Proximity Operator of the Matrix Perspective Function and its Applications,Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),['Ho Won'],{'Seoul National University'},1,0,0,{'South Korea'}
Generative 3D Part Assembly via Dynamic Graph Learning,"佳磊 黄, Guanqi Zhan, Qingnan Fan, Kaichun Mo, Lin Shao, Baoquan Chen, Leonidas J. Guibas, Hao Dong",Generative 3D Part Assembly via Dynamic Graph Learning,45fbc6d3e05ebd93369ce542e8f2322d,https://proceedings.neurips.cc/paper/2020/file/45fbc6d3e05ebd93369ce542e8f2322d-Paper.pdf,"Automatic part assembly is an important task in robotics. Nowadays, tens of thousands of production line workers are working on product assembly manually. Learning how to assemble a set of parts to a complete shape is still a challenging problem. This study can enable robots to free human on part assembly task. We believe this research benefits both the economy and society. However, even with learning algorithms, human trust in machines is still a problem. The algorithms can only be used for assistance in practice and cannot fully replace humans. In the assembly task, such machine learning algorithm/system needs to cooperate with human to achieve more effective processes.",Broader Impact,108,8,,,FALSE,FALSE,FALSE,Generative 3D Part Assembly via Dynamic Graph Learning,Applications -> Computer Vision,Deep Learning -> Generative Models,Vision,"['佳磊 黄', ' Guanqi Zhan', ' Qingnan Fan', ' Kaichun Mo', ' Lin Shao', ' Baoquan Chen', ' Leonidas J Guibas', ' Hao Dong']","{'Stanford University', 'Peking University', 'Shandong University'}",1,0,0,"{'USA', 'China'}"
Improving Natural Language Processing Tasks with Human Gaze-Guided Neural Attention,"Ekta Sood, Simon Tannert, Philipp Mueller, Andreas Bulling",Improving Natural Language Processing Tasks with Human Gaze-Guided Neural Attention,460191c72f67e90150a093b4585e7eb4,https://proceedings.neurips.cc/paper/2020/file/460191c72f67e90150a093b4585e7eb4-Paper.pdf,"We identified a number of potential benefits and risks of our approach. Potential benefits Our approach could benefit interactive applications that quantify, support, or enhance reading behavior without the need for special-purpose eye tracking equipment. Specifically, we see potential for e-learning applications in which our approach could be used to qualify reader actions and provide feedback to encourage improvement in reading comprehension. In addition, we see potential for our approach to be used as a key component in diagnostic tools to identify atypical eye movement behaviors correlated to cognitive impairments such as learning disabilities (e.g. such as Autism Spectrum Disorder or ADHD) or early onset detection of neuro-degenerative diseases which impact eye movement control (e.g Parkinsons disease). In addition, our hybrid approach could be useful for researchers building computational models of cognition, specifically geared towards combining traditional cognitive process models with neural networks in order to build a model which better emulates human cognitive processes – potentially allowing for increase in parameters and task complexity for further more robust models of human behavior. Lastly, our joint learning approach might prove useful to machine learning researchers who aim to implement artificial systems that more similarly model human behavior and thus perform more similarly to humans on currently challenging machine comprehension tasks. Our method could be used, for example, to automatically generate paraphrases for more natural playing experience in computer games (e.g., more varied utterances of non-player characters); or to aid in making a news text faster to read by compressing it before presenting it to the user. Potential risks Despite these potential future benefits, we also identified a few risks. Given the nature of the underlying E-Z reader model, it is likely that reading behavior found in atypical individuals currently cannot be predicted. This could consequently negatively impact the quality of the provided feedback, guidance or diagnostic analyses. We also see a potential risk in that our improved paraphrase generation model could be used to disguise plagiarized texts. Finally, improvements in sentence compression could make users grow accustomed to simplified and potentially less balanced information if they increasingly read compressed news articles.",Broader Impact,351,12,,,TRUE,TRUE,FALSE,Improving Natural Language Processing Tasks with Human Gaze-Guided Neural Attention,Applications -> Natural Language Processing,Deep Learning -> Attention Models; Neuroscience and Cognitive Science -> Language for Cognitive Science,Natural language processing,"['Ekta Sood', ' Simon Tannert', ' Philipp Mueller', ' Andreas Bulling']","{'VIS, University of Stuttgart', 'University of Stuttgart, Simtech ', 'University of Stuttgart', 'Institute for Natural Language Processing, University of Stuttgart'}",1,1,1,"{'Singapore', 'Germany'}"
The Power of Comparisons for Actively Learning Linear Classifiers,"Max Hopkins, Daniel Kane, Shachar Lovett",The Power of Comparisons for Actively Learning Linear Classifiers,4607f7fff0dce694258e1c637512aa9d,https://proceedings.neurips.cc/paper/2020/file/4607f7fff0dce694258e1c637512aa9d-Paper.pdf,"Since this work is theoretical in nature, we do not foresee any particular applications.",Broader Impact,14,1,TRUE,FALSE,FALSE,FALSE,FALSE,The Power of Comparisons for Actively Learning Linear Classifiers,Theory -> Computational Learning Theory,Algorithms -> Active Learning; Algorithms -> Classification,Theory (including computational and statistical analyses),"['Max Hopkins', ' Daniel Kane', ' Shachar Lovett']","{'University of California San Diego', 'UCSD'}",1,0,0,{'USA'}
From Boltzmann Machines to Neural Networks and Back Again,"Surbhi Goel, Adam Klivans, Frederic Koehler",From Boltzmann Machines to Neural Networks and Back Again,464074179972cbbd75a39abc6954cd12,https://proceedings.neurips.cc/paper/2020/file/464074179972cbbd75a39abc6954cd12-Paper.pdf,"We believe our work will be of most use to other researchers working on sparse graphical models with latent variables. We do not expect our research to disadvantage any individual. As with most machine learning tools, the proposed algorithm for classification could possibly fit to existing biases in the data. In fact, since our algorithm also learns per class distributions, a practitioner can sample from the distribution to further evaluate any biases implicitly modelled. Any practitioner using our method will need to apply the same due diligence as if they were fitting their data using a different method, such as logistic regression.",Broader Impact,102,5,,,FALSE,FALSE,FALSE,From Boltzmann Machines to Neural Networks and Back Again,Theory -> Computational Learning Theory,Probabilistic Methods -> Graphical Models,,"['Surbhi Goel', ' Adam Klivans', ' Frederic Koehler']","{'MIT', 'The University of Texas at Austin', 'UT Austin'}",1,0,0,{'USA'}
Crush Optimism with Pessimism: Structured Bandits Beyond Asymptotic Optimality,"Kwang-Sung Jun, Chicheng Zhang",Crush Optimism with Pessimism: Structured Bandits Beyond Asymptotic Optimality,46489c17893dfdcf028883202cefd6d1,https://proceedings.neurips.cc/paper/2020/file/46489c17893dfdcf028883202cefd6d1-Paper.pdf,"Our study is mainly about a novel approach to solve structured bandits algorithms where we try to overcome some shortcomings of existing methods. Algorithmic developments in bandits have a huge impact in many potential applications including dose-finding trials. In this application, a structured bandits that encode a proper inductive bias and can help resolve health issues of many people by significantly reducing time/trials needed to find dosage or the right types of drugs, leading to maximum efficacy with minimal side-effects.",Broader Impact,80,3,,,FALSE,FALSE,FALSE,Crush Optimism with Pessimism: Structured Bandits Beyond Asymptotic Optimality,Algorithms -> Bandit Algorithms,,Theory (including computational and statistical analyses),"['Sung Jun', ' Chicheng Zhang']","{'U of Arizona', 'University of Arizona'}",1,0,0,{'USA'}
Pruning neural networks without any data by iteratively conserving synaptic flow,"Hidenori Tanaka, Daniel Kunin, Daniel L. Yamins, Surya Ganguli",Pruning neural networks without any data by iteratively conserving synaptic flow,46a4378f835dc8040c8057beb6a2da52,https://proceedings.neurips.cc/paper/2020/file/46a4378f835dc8040c8057beb6a2da52-Paper.pdf,"Neural network pruning has the potential to increase the energy efficiency of neural network models and decrease the environmental impact of their training. It also has the potential to allow for trained neural network models to be more easily deployed on edge devices such as mobile phones. Our work explores neural network pruning mainly from a theoretical angle and thus these impacts are not directly applicable to our work. However, future work might be able to realize these potentials and thus must consider their impacts more carefully.",Broader Impact,87,4,,,FALSE,FALSE,FALSE,Pruning neural networks without any data by iteratively conserving synaptic flow,Deep Learning -> Optimization for Deep Networks,Deep Learning -> Efficient Training Methods; Deep Learning -> Supervised Deep Networks; Theory -> Statistical Physics of Learning,Optimization Methods (continuous or discrete),"['Hidenori Tanaka', ' Daniel Kunin', ' Daniel Yamins', ' Surya Ganguli']","{'Stanford University', 'Stanford'}",1,0,0,{'USA'}
Towards Interaction Detection Using Topological Analysis on Neural Networks,"Zirui Liu, Qingquan Song, Kaixiong Zhou, Ting-Hsiang Wang, Ying Shan, Xia Hu",Towards Interaction Detection Using Topological Analysis on Neural Networks,473803f0f2ebd77d83ee60daaa61f381,https://proceedings.neurips.cc/paper/2020/file/473803f0f2ebd77d83ee60daaa61f381-Paper.pdf,"The proposed PID algorithm can be applied in various fields because it provides knowledge about a domain. Any researcher who needs to design experiments might benefit from our proposed algorithm in the sense that it can help researchers formulate hypotheses that could lead to new data collection and experiments. For example, PID can help us discover the combined effects of drugs on human body: By utilizing PID on patients’ records, we might find using Phenelzine togther with Fluoxetine has a strong interaction effect towards serotonin syndrome. Thus, PID has great potential in helping the development of new therapies for saving lives. Also, this project will lead to effective and efficient algorithms for finding useful any-order crossing features in an automated way. Finding useful crossing features is one of the most crucial task in the Recommender Systems. Engineers and Scientists in E-commerce companies may benefit from our results that our algorithm can alleviate the human effect on finding these useful patterns in the data.",Statement of Broader Impact,163,7,,,FALSE,FALSE,FALSE,Detecting Interactions from Neural Networks via Topological Analysis,"Deep Learning -> Visualization, Interpretability, and Explainability",Deep Learning -> Analysis and Understanding of Deep Networks; Neuroscience and Cognitive Science -> Connectomics,Neuroscience and cognitive science,"['Zirui Liu', ' Qingquan Song', ' Kaixiong Zhou', 'Hsiang Wang', ' Ying Shan', ' Xia Hu']","{'Tencent', 'Texas A&M University'}",1,1,1,"{'USA', 'China'}"
Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems,"Aman Sinha, Matthew O'Kelly, Russ Tedrake, John C. Duchi",Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems,475d66314dc56a0df8fb8f7c5dbbaf78,https://proceedings.neurips.cc/paper/2020/file/475d66314dc56a0df8fb8f7c5dbbaf78-Paper.pdf,"This paper presents both foundational theory and methods for efficiently evaluating the performance of safety-critical autonomous systems. By definition, such systems can cause injury or death if they malfunction [15]. Thus, improving the tools that practitioners have to perform risk-estimation has the potential to provide a strong positive impact. On the other hand, the improved scalability of our method could be used to more efficiently find (zero-day) exploits and failure modes in P 0 (the model of the operational design domain). However, we note that adversarial examples or exploits can also be found via a variety of purely optimization-based methods [3]. The nuances of our method are primarily concerned with the frequency of adverse events, an extra burden; thus, we anticipate they will be of little interest to malicious actors who can manipulate the observations and sensor measurements of complex systems. Another potential concern about the use of our method is with respect to the identification of P 0 , which we specifically assume to be known in this paper. The gap between P 0 in simulation and the real distribution of the environment could lead to overconfi- dence in the capabilities of the system under test. In Section 1.1 we outline complementary work in anomaly detection and distributionally robust optimization which could mitigate such risks. Still, more work needs to be done to standardize the operational domain of specific tasks by regulators and technology-stakeholders. Nevertheless, we believe that our method will enable the compari- son of autonomous systems in a common language—risk—across the spectrum from engineers to regulators and the public. The applications of our technology are diverse ( cf. Corso et al. [27]), ranging from testing au- tonomous vehicles [76, 74] and medical devices [77] to evaluating deep neural networks [104] and reinforcement-learning agents [101]. In the case of autonomous vehicles, Sparrow and Howard [97] argue that it will be morally wrong not to deploy self-driving technology once performance exceeds human capabilities. Our work is an important tool for determining when this performance threshold is achieved due to the rare nature of serious accidents [51]. While the widespread avail- ability of autonomy-enabled devices could narrowly benefit public health, there are many external risks associated with their development. First, many learning-based components of these systems will require massive and potentially invasive data collection [85]; preserving privacy of the public via federated learning [64] and differential privacy-based mechanisms [38] should remain impor- tant initiatives within the machine-learning community. A second potential negative consequence of the applications like autonomous vehicles is the use of the real-world as a “simulator” within a reinforcement-learning scheme by releasing “beta” autonomy features ( e.g. Tesla Autopilot [52]). Unlike established industries such as aerospace [100], many potential applications currently lack regulation and standards; it is important to ensure that industry works with policy makers to develop safety standards in a way that avoids regulatory capture. If widely adopted in regulatory frameworks, our tool would enable rational decisions about the impact, positive or negative, of safety-critical au- tonomous systems before real lives are affected. More broadly, the advent of autonomy could spark significant societal changes. For example, the autonomous applications described previously could become core components of weapons systems and military technology that are incompatible with (modern interpretations of) just war theory [96]. Similarly, the automation of the transportation industry has the potential to rapidly destroy the eco- nomics of public infrastructure and cost millions of jobs [97]. Thus, Benkler [9] highlights that there is a growing need for the academic community to take action on defining the broader performance criteria to which we will hold AI applications. Brundage et al. [18] and Wing [106] outline broad research agendas which are necessarily interdisciplinary. Still, much more work needs to be done to empower researchers to influence policy. These efforts will require systemic initiatives by research institutions and organizations to engage with local, national, and international governing bodies.",Broader Impact,650,29,,,FALSE,TRUE,FALSE,Neural Bridge Sampling for Evaluating Safety-Critical Autonomous Systems,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Density Estimation; Algorithms -> Uncertainty Estimation; Applications -> Robotics; Probabilistic Methods -> MCMC; Reinforcement Learning and Planning -> Reinforcement Learning,Probabilistic methods and inference,"['Aman Sinha', 'Kelly', ' Russ Tedrake', ' John Duchi']","{'Stanford', 'Stanford University', 'MIT', 'University of Pennsylvania'}",1,0,0,{'USA'}
Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations,"Rohan Paleja, Andrew Silva, Letian Chen, Matthew Gombolay",Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations,477bdb55b231264bb53a7942fd84254d,https://proceedings.neurips.cc/paper/2020/file/477bdb55b231264bb53a7942fd84254d-Paper.pdf,"Our interpretable apprenticeship scheduling framework has broad impacts on society and the learning from demonstration community. Our interpretable trees can give key insight into the behavior of a machine-learning-based agent, allowing a human to verify that safety constraints are being met and increasing the trustworthiness of the autonomous agent. Furthermore, these trees allow human operators to follow the decision step-by-step, allowing for verification [ 12, 19], and holding machines accountable [20]. Beneficiaries – Our work has the potential to benefit all human-machine collaborations, providing improved transparency, and strengthening the trustworthiness of machine teammates through policy verification. Our research contributions additionally benefit research and laboratories pursuing learning from diverse human data (which commonly contains heterogeneity). Negatively affected parties – With any model, we believe it is important to gather consent before utilizing one’s data. As our model can be used by humans as both a forward model to understand decision-maker behavior and as an inverse model to infer modality, there is a possibility of discovering latent characteristics about individuals that may reflect negatively upon them. Implications of failure – Failure of our approach to produce high-accuracy behavior during deployment will result in a lack of trust towards the system. In the worst case, careless application may contribute to misunderstandings causing damage from a deployed robot. Bias and Fairness – The learned behavior of our PNTs will be biased towards demonstrators within the training set. If the collected set excludes certain persona, the behavior of these persona will not be represented by our PNT. However, it should be noted that as our approach is able to better take into account heterogeneity within the training data compared to other apprenticeship learning approaches. In other words, our framework is better able to represent the entire population rather than overfitting to the most prevalent demonstrator behavior than previous approaches. Impact on LfD community – Personalized Neural Trees can easily be extended to a variety of domains, increasing the data-efficiency, accuracy, and utility of learning-from-demonstration with multiple human demonstrators. We demonstrate this by using a PNT to learn kinesthetic robot table tennis demonstrations. We provide details about this domain, the collection process, and the results in the supplementary material. Reproducibility – Following the NeurIPS Reproducability Checklist, we upload all code here. Within this repository, we provide collected real-world datasets, code to generate synthetic data, and code to run all benchmarks. Alongside this, we attach trained models for each domain. Further in the supplementary material, we provide specifications of our hyperparameters, descriptions of our computing infrastructure, and other details regarding runtime.",8 Broader Impact,424,20,,,FALSE,FALSE,FALSE,Interpretable and Personalized Apprenticeship Scheduling: Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations,Probabilistic Methods -> Latent Variable Models,"Deep Learning -> Visualization, Interpretability, and Explainability","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Rohan Paleja', ' Andrew Silva', ' Letian Chen', ' Matthew Gombolay']",{'Georgia Institute of Technology'},1,0,0,{'USA'}
Task-Agnostic Online Reinforcement Learning with an Infinite Mixture of Gaussian Processes,"Mengdi Xu, Wenhao Ding, Jiacheng Zhu, ZUXIN LIU, Baiming Chen, Ding Zhao",Task-Agnostic Online Reinforcement Learning with an Infinite Mixture of Gaussian Processes,47951a40efc0d2f7da8ff1ecbfde80f4,https://proceedings.neurips.cc/paper/2020/file/47951a40efc0d2f7da8ff1ecbfde80f4-Paper.pdf,"This work is a step toward General Artificial Intelligence by eliminating the pre-train stage and equipping reinforcement learning agents with the quick-adaptation ability. The proposed method could be applied in a wide range of applications when the prior knowledge is not accessible or not beneficial, including space rover navigation, rescue robot exploration, autonomous vehicle decision making, and human-robot interaction. Our research increases algorithmic interpretability and transparency for decision-making by providing inferred task assignments. It also enhances the algorithm’s robustness by explicitly separating different types of tasks and thus increases users’ trust. Additionally, our research improves algorithmic fairness by not relying on prior knowledge that may contain human-induced or data-induced biases. At the same time, our research may have negative impacts if misused. The potential risks are listed as follows: (1) Over-trust in the results (e.g., the task assignments) may lead to undesirable outcomes. (2) If used for illegal purposes, the model may instead enlarge the possible negative outcome due to its explainability. (3) The task assignment results may be misinterpreted by those who do not have enough related background. (4) The evolving online nature of the method may increase the uncertainty and thus mistrust of human collaborators. Note that our method inherits the possible positive and negative impacts of reinforcement learning, not emphasized here. To mitigate the possible risks mentioned above, we encourage research to (1) investigate and modulate the negative impacts of the inaccurate information provided by algorithms, (2) understand how humans interact with evolving intelligent agents in terms of trust, productivity, comfort level, (3) find out the impact of using our model in real-world tasks.",Broader Impact,267,12,,,FALSE,FALSE,FALSE,Task-Agnostic Online Reinforcement Learning with an Infinite Mixture of Gaussian Processes,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Continual Learning; Algorithms -> Online Learning; Probabilistic Methods -> Bayesian Nonparametrics; Probabilistic Methods -> Gaussian Processes; Reinforcement Learning and Planning -> Model-Based RL,Reinforcement learning and planning,"['Mengdi Xu', ' Wenhao Ding', ' Jiacheng Zhu', ' ZUXIN LIU', ' Baiming Chen', ' Ding Zhao']","{'Tsinghua University', 'Carnegie Mellon University'}",1,0,0,"{'USA', 'China'}"
Benchmarking Deep Learning Interpretability in Time Series Predictions,"Aya Abdelsalam Ismail, Mohamed Gunady, Hector Corrada Bravo, Soheil Feizi",Benchmarking Deep Learning Interpretability in Time Series Predictions,47a3893cc405396a5c30d91320572d6d,https://proceedings.neurips.cc/paper/2020/file/47a3893cc405396a5c30d91320572d6d-Paper.pdf,"The challenge presented by meaningful interpretation of Deep Neural Networks (DNNs) is a technical barrier preventing their serious adoption by practitioners in fields such as Neuroscience, Medicine, and Finance [40, 41]. Accurate DNNs are not, by themselves, sufficient to be used routinely in high stakes applications such as healthcare. For example, in clinical research, one might like to ask, ""why did you predict this person as more likely to develop a certain disease?"" Our work aims to answer such questions. Many critical applications involve time series data, e.g., electronic health records, functional Magnetic Resonance Imaging (fMRI) data, and market data; nevertheless, the majority of research on interpretability focuses on vision and language tasks. Our work aims to interpret DNNs applied to time series data. Having interpretable DNNs has many positive outcomes. It will help increase the transparency of these models and ease their applications in a variety of research areas. Understanding how a model makes its decisions can help guide modifications to the model to produce better and fairer results. Critically, failure to provide faithful interpretations is a severe negative outcome. Having no interpretation at all is, in many situations, better than trusting an incorrect interpretation. Therefore, we believe this study can lead to significant positive and broad impacts in different applications.",9 Broader Impact,212,12,,,FALSE,FALSE,FALSE,Benchmarking Deep Learning Interpretability in Time Series Predictions,"Deep Learning -> Visualization, Interpretability, and Explainability","Applications -> Time Series Analysis; Data, Challenges, Implementations, and Software -> Benchmarks; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Interpretability,"['Aya Abdelsalam Ismail', ' Mohamed Gunady', ' Hector Corrada Bravo', ' Soheil Feizi']",{'University of Maryland'},1,0,0,{'USA'}
Federated Principal Component Analysis,"Andreas Grammenos, Rodrigo Mendoza Smith, Jon Crowcroft, Cecilia Mascolo",Federated Principal Component Analysis,47a658229eb2368a99f1d032c8848542,https://proceedings.neurips.cc/paper/2020/file/47a658229eb2368a99f1d032c8848542-Paper.pdf,"PCA is an ubiquitous and fundamental tool in data analysis and machine learning pipelines and also has important societal applications like poverty measurement . Computing PCA on large-scale data is not only challenging from the computational point of view, but also from the public policy point of view. Indeed, new regulations around data ownership and privacy like GDPR have imposed restrictions in data collection and storage. Our work allows for large-scale decentralised computation of PCA in settings where each compute node - be it large (servers), thin (mobile phones), or super-thin (cryptocurrency blocks) - contributes in an independent an asynchronous way to the training of a global model, while ensuring the ownership and privacy of the data. However, we note that our algorithmic framework is a tool and, like all tools, is subject to misuse. For example, our framework could allow malicious users to extract embeddings out of user data to be used for surveillance, user fingerprinting, and many others not so desirable use-cases. We firmly believe, however, that the positives outweigh the negatives and this work has the potential to unlock information from decentralised datasets for the benefit of society, all while guaranteeing high-quality outputs and stringent privacy properties.",6 Broader Impact,200,7,,,FALSE,FALSE,FALSE,Federated Principal Component Analysis,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)","Algorithms -> Large Scale Learning; Algorithms -> Online Learning; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security","Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,"{'University of Cambridge', 'ITAM'}",1,0,0,{'UK'}
(De)Randomized Smoothing for Certifiable Defense against Patch Attacks,"Alexander Levine, Soheil Feizi",(De)Randomized Smoothing for Certifiable Defense against Patch Attacks,47ce0875420b2dbacfc5535f94e68433,https://proceedings.neurips.cc/paper/2020/file/47ce0875420b2dbacfc5535f94e68433-Paper.pdf,"Adversarial patch attacks are extremely relevant to security threats posed by adversarial machine learning. In particular, patch attacks model physical adversarial attacks, in which real-world objects are manipulated in order to disrupt computer vision systems. Malicious use of such attacks could therefore be catastrophically damaging in highly critical applications of computer vision, such as self- driving cars. For example, consider an adversary that puts adversarial stickers on stop signs to cause significant errors in classification of those images by deep models deployed in autonomous vehicles. Such an attack could cause significant damage. Moreover, the existence of such vulnerabilities in deep models can harm the confidence of users of systems that employ such models, which could slow adoption of these systems. Our proposed techniques in this paper provide new provable and guaranteed defenses against these attacks, advancing the effort to mitigate these issues. We note that the algorithms described in this paper are purely defensive. That is, this work does not reveal (in any way obvious to the authors) any unknown vulnerabilities in existing computer vision systems. While we do develop an adversarial attack against our classifier, this attack is a straightforward extension of existing work on adversarial attacks to smoothed classifiers [ 13]: implementing this attack represents necessary due diligence to evaluate the robustness of our defense. One possible negative outcome of provable robustness guarantees is that they may cause users to be overconfident in the reliability of machine learning systems in general. As we have demonstrated in Section 3.1, our techniques do not provide robustness to general adversarial attacks other than patch attacks. Further, a guarantee of robustness is not a guarantee of correctness: in fact, the accuracy of our classifiers is reduced compared to undefended models. Users should be aware of these issues before applying these techniques in critical applications. Additionally, we acknowledge that, as for any computer vision advance, malicious actors could also use the techniques demonstrated here. For example, the application of these techniques could make it more difficult to thwart excessive and unwanted surveillance, posing a potential privacy concern. However, given the important safety applications described above, we believe that making this work available will have an overall positive impact.",Broader Impact,365,17,,,FALSE,FALSE,FALSE,(De)Randomized Smoothing for Certifiable Defense against Patch Attacks,Algorithms -> Adversarial Learning,,Vision,"['Alexander Levine', ' Soheil Feizi']","{'University of Maryland, College Park', 'University of Maryland'}",1,0,0,{'USA'}
SMYRF - Efficient Attention using Asymmetric Clustering,"Giannis Daras, Nikita Kitaev, Augustus Odena, Alexandros G. Dimakis",SMYRF: Efficient Attention using Asymmetric Clustering,47d40767c7e9df50249ebfd9c7cfff77,https://proceedings.neurips.cc/paper/2020/file/47d40767c7e9df50249ebfd9c7cfff77-Paper.pdf,"Our main contribution is to reduce the computational requirements for machine learning models with attention-layers. Thus, any broader impact is likely to come from making these models more efficient in both memory impact and inference speed. We expect that this will be mostly a good thing since it democratizes the use of big attention layers: those who want to use such models but for whom the computational resources required are too great (like university labs) will now have an easier time. Moreover, GANs and language models will become easier to deploy on phones or other embedded devices. Further, more efficient training reduces the environmental and energy footprint of deep learning research. As the number of parameters of Transformer models grows, the latter becomes critical [67]. Negative consequences are also possible: The idea of DeepFakes [68] has been well-discussed elsewhere; a technique that makes these easier to create clearly has downsides. On the other hand, any sufficiently determined actor (e.g. a nation-state attempting to commit election-fraud) already has access to such technology, so perhaps the marginal negative impact will not be that large. Still, whenever computational requirements are reduced, the ease of taking bad actions increases along with the ease of taking good actions. Finally, the technique proposed in this paper relies heavily on the assumption that attention maps are approximately sparse. It’s possible (though we have no particular reason to think that this has happened or would happen) that, at some intermediate layer of a complicated neural network, enforcing sparsity when the ground-truth maps are non-sparse could result in ignoring salient features of atypical data points, thus resulting in fairness-related issues. Determining whether these approximations cause fairness issues in general could be an interesting subject for future work.",7 Broader Impact,288,12,,,FALSE,TRUE,FALSE,SMYRF - Efficient Attention using Asymmetric Clustering,Deep Learning -> Attention Models,Applications -> Computer Vision; Applications -> Natural Language Processing; Deep Learning -> Adversarial Networks; Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,Deep learning,"['Giannis Daras', ' Nikita Kitaev', ' Augustus Odena', ' Alexandros Dimakis']","{'Google Brain', 'University of California, Berkeley', 'University of Texas, Austin', 'National Technical University of Athens'}",1,1,1,"{'Greece', 'USA'}"
Introducing Routing Uncertainty in Capsule Networks,"Fabio De Sousa Ribeiro, Georgios Leontidis, Stefanos Kollias",Introducing Routing Uncertainty in Capsule Networks,47fd3c87f42f55d4b233417d49c34783,https://proceedings.neurips.cc/paper/2020/file/47fd3c87f42f55d4b233417d49c34783-Paper.pdf,"With the advent of Deep Learning, the computational requirements in the field have increased significantly due to the ever increasing scale of our models. The environmental impact of training or deploying such models is therefore at an all time high. This raises concerns regarding the sustainability of our current practices, as the technologies we help develop are slowly integrated into all areas of society. Although it is important to continue on this path of discovery, we feel that an important shift towards efficiency is sorely needed. Concretely, the development of smaller scale models which are more robust and sample efficient, could significantly reduce the environmental impact of our technology with small sacrifices in performance. In general, we believe this can be achieved by introducing richer inductive priors into our models, which in turn require fewer examples to learn from, i.e. leading to increased sample efficiency. With that in mind, Capsule Networks have previously shown to possess superior generalisation properties than conventional CNNs in certain tasks, and in our work we enhance these properties further whilst being more computationally efficient than previous iterative routing methods. We also demonstrated competitive performances on sample efficiency tasks, which have broad applicability to limited data domains such as medical. When these properties are enhanced even further, they have the potential to make a significant positive impact on our societies by increasing the sustainability and efficiency of our machine learning models.",Broader Impact,235,9,,,FALSE,FALSE,FALSE,Introducing Routing Uncertainty in Capsule Networks,Deep Learning,Deep Learning -> CNN Architectures,Deep learning,"['Fabio De Sousa Ribeiro', ' Georgios Leontidis', ' Stefanos Kollias']","{'University of Aberdeen', 'University of Lincoln'}",1,0,0,{'UK'}
A Simple and Efficient Smoothing Method for Faster Optimization and Local Exploration,"Kevin Scaman, Ludovic DOS SANTOS, Merwan Barlier, Igor Colin",A Simple and Efficient Smoothing Method for Faster Optimization and Local Exploration,481d462e46c2ab976294271a175b8929,https://proceedings.neurips.cc/paper/2020/file/481d462e46c2ab976294271a175b8929-Paper.pdf,"As a method accelerating the optimization of non-smooth and non-convex functions, the BMR smoothing operator may be applied to a wide range of applications, in particular for training deep neural networks of which the induced loss function are highly non-smooth and non-convex and of which applications are numerous: image, speech, natural language processing, reinforcement learning... As a theoretical work however, it remains difficult to more precisely evaluate the impact of this paper. Exhaustive experimental benchmarks assessing the performance of BMR smoothing should first be conducted.",Broader Impact,85,2,,,FALSE,FALSE,FALSE,A Simple and Efficient Smoothing Method for Faster Optimization and Local Exploration,Optimization -> Non-Convex Optimization,,Optimization Methods (continuous or discrete),"['Kevin Scaman', ' Ludovic DOS SANTOS', ' Merwan Barlier', ' Igor Colin']","{'Huawei', ""Noah's Ark Lab, Huawei Technologies"", 'Huawei Technologies'}",0,1,0,{'China'}
Hyperparameter Ensembles for Robustness and Uncertainty Quantification,"Florian Wenzel, Jasper Snoek, Dustin Tran, Rodolphe Jenatton",Hyperparameter Ensembles for Robustness and Uncertainty Quantification,481fbfa59da2581098e841b7afc122f1,https://proceedings.neurips.cc/paper/2020/file/481fbfa59da2581098e841b7afc122f1-Paper.pdf,"Our work belongs to a broader research effort that tries to quantify the predictive uncertainty for deep neural networks. Those models are known to generalize poorly to small changes to the data while maintaining high confidence in their predictions. Who may benefit from this research? The broader topic of our work is becoming increasingly important in a context where machine learning systems are being deployed in safety-critical fields, e.g., medical diagnosis [54, 49] and self-driving cars [48]. Those examples would benefit from the general technology we contribute to. In those cases, it is essential to be able to reliably trust the uncertainty output by the models before any decision-making process, to possibly escalate uncertain decisions to appropriate human operators. Who may be put at disadvantage from this research? We are not aware of a group of people that may be put at disadvantage as a result of this direct research. What are the consequences of failure of the system? By definition, our research could contribute to aspects of machine-learning systems used in high-risk domains (e.g., we mentioned earlier medical fields and self-driving cars) which involves complex data-driven decision-making processes. Depending on the nature of the application at hand, a failure of the system could lead to extremely negative consequences. A case in point is the recent screening system used by one third of UK government councils to allocate welfare budget.1 Do the task/method leverage biases in the data? The method we develop in this work is domain- agnostic and does not rely on specific data assumptions. Our method also does not contain components that would prevent its combination with existing fairness or privacy-preserving technologies [4]. Link to the corresponding article in The Guardian, October 2019: https://www.theguardian.com/society/2019/oct/15/councils-using-algorithms-make-welfare-decisions-benefits.",Broader Impact,286,15,,,TRUE,TRUE,FALSE,Hyperparameter Ensembles for Robustness and Uncertainty Quantification,Algorithms -> Uncertainty Estimation,Deep Learning,Probabilistic methods and inference,"['Florian Wenzel', ' Jasper Snoek', ' Dustin Tran', ' Rodolphe Jenatton']","{'Google Brain', 'Google Research'}",0,1,0,{'USA'}
Neutralizing Self-Selection Bias in Sampling for Sortition,"Bailey Flanigan, Paul Goelz, Anupam Gupta, Ariel D. Procaccia",Neutralizing Self-Selection Bias in Sampling for Sortition,48237d9f2dea8c74c2a72126cf63d933,https://proceedings.neurips.cc/paper/2020/file/48237d9f2dea8c74c2a72126cf63d933-Paper.pdf,"As we discussed in the paper, sortition is becoming increasingly widespread as a method for making collective decisions and gauging public opinion. Based on our experiences, practitioners seem interested in the possibility of fairer sampling algorithms, so our research in this area has the potential to influence how sortition panels are sampled in the real world. From a fairness standpoint, our algorithm represents an improvement over currently-used algorithms on several fronts. We maintain the approximate satisfaction of proportional quotas while giving provable fairness guarantees to individuals, which in turn safeguard against systematic under- representation of demographic groups unprotected by quotas. Currently-used greedy algorithms give no such guarantees, and as we show in a real-world example, these theoretical differences can translate to substantial practical differences in the equality of individual selection probabilities. Our model is also robust to bias in the first stage of sampling: if a group is unfairly undersampled in the invitation stage, an effective machine-learning method will estimate lower q i for this group, and the algorithm will then correct this bias in the second stage. For these reasons, sortition panels selected via our algorithm will in general be more representative of the population, hopefully resulting in their decisions more fairly reflecting the interests and views of the entire population. Of course, the methods we present do still come with fairness concerns. One main concern would be that the learned q i values could erroneously overestimate the participation probabilities of those in a certain group, thereby resulting in our sampling algorithm giving members of that group lower probability they deserve in the second step, and thereby giving them unfairly low end-to-end selection probability. We identify three main potential sources of inaccuracy in our MLE estimator: unreliable or unrepresentative background data, small sample sizes from which to learn, and failure of our model to accurately capture people’s participation decisions. While each of these factors could potentially introduce inaccuracies in the q i values, it is unclear that any but the first issue is likely to result in systematic bias against certain groups. Another important consideration in panel selection is transparency about the selection process to constituents on whose behalf the panel will make decisions. Increasing the transparency of how these panels are selected can increase public trust in the fairness of this method of decision-making, thus expanding sortition’s legitimacy and reach. Toward the goal of transparency, our approach offers improvements on the state-of-the-art in several ways. First, this work gives formal theoretical guarantees of multiple types of fairness, where currently-used methods give none. Our algorithm also follows an explicit and explainable process for setting marginal selection probabilities, rather than having them accidentally arise from a greedy process. Despite these improvements, our methods still present transparency challenges. Since an individual’s probability of selection from the pool depends on their estimated q i value, the fairness of the process hinges on the entire machine-learning pipeline — data used, choice of model, and estimation methods — multiple elements of which might be opaque to most of the population. Secondly, while the use of protected attributes to counteract inequality is an accepted practice in the fairness in classification literature, there may still be public discomfort about this idea. In particular, it may be a source of discomfort that, in order to equalize end-to-end probabilities, our algorithm must explicitly decrease the probability of certain people being selected from the pool due to their attributes. One potentially comforting and easily-understood feature of our algorithm, however, is described in Section 6: that if someone participates in the pool with probability 1, they are guaranteed an end-to-end selection probability of at least k/n , regardless of their attributes.",Broader Impact,611,21,,,FALSE,FALSE,FALSE,Neutralizing Self-Selection Bias in Sampling for Sortition,Theory -> Game Theory and Computational Economics,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",,"['Bailey Flanigan', ' Paul Goelz', ' Anupam Gupta', ' Ariel Procaccia']","{'Harvard University', 'Carnegie Mellon University'}",1,0,0,{'USA'}
On the Convergence of Smooth Regularized Approximate Value Iteration Schemes,"Elena Smirnova, Elvis Dohmatob",On the Convergence of Smooth Regularized Approximate Value Iteration Schemes,483101a6bc4e6c46a86222eb65fbcb6a,https://proceedings.neurips.cc/paper/2020/file/483101a6bc4e6c46a86222eb65fbcb6a-Paper.pdf,This research benefits the RL researchers and practitioners running large-scale RL applications. It improves theoretical understanding of the state-of-the-art techniques from error propagation perspective. This is helpful in algorithm design for a particular application. Our analysis builds on the top of approximate dynamic-programming framework and might not cover all the implications of the above-mentioned techniques.,Broader impact,55,4,FALSE,FALSE,FALSE,FALSE,FALSE,On the Convergence of Smooth Regularized Approximate Value Iteration Schemes,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Elena Smirnova', ' Elvis Dohmatob']",{'Criteo'},0,1,0,{'France'}
Off-Policy Evaluation via the Regularized Lagrangian,"Mengjiao Yang, Ofir Nachum, Bo Dai, Lihong Li, Dale Schuurmans",Off-Policy Evaluation via the Regularized Lagrangian,488e4104520c6aab692863cc1dba45af,https://proceedings.neurips.cc/paper/2020/file/488e4104520c6aab692863cc1dba45af-Paper.pdf,"One of the broader issues in reinforcement learning is reproducibility — it is difficult to make a compelling case that any new algorithm is actually an improvement without a common framework for reliably reproducing past related research results. This paper unifies existing DICE estimators and offers a standard implementation of a number of seemingly distinct algorithms that in fact only differ in regularization. Future researchers and practioners in this domain can benefit from this unification, where algorithms can be effectively compared in isolation from other artifacts such as neural network architecture. Meanwhile, this research has revealed a number of choices in regularization, redundant constraints, and final estimators in DICE, suggesting a large hyperparameter search space. While we try our best to illustrate which choices matter through mathematical analysis and ablation study, individuals with limited computational resources could still be put at a disadvantage when tuning their algorithms to achieve the best performance for a specific task.",Broader Impact,156,5,,,FALSE,FALSE,FALSE,Off-Policy Evaluation via the Regularized Lagrangian,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Mengjiao Yang', ' Ofir Nachum', ' Bo Dai', ' Lihong Li', ' Dale Schuurmans']","{'Google', 'Google Brain', 'Google Research'}",0,1,0,{'USA'}
The LoCA Regret: A Consistent Metric to Evaluate Model-Based Behavior in Reinforcement Learning,"Harm Van Seijen, Hadi Nekoei, Evan Racah, Sarath Chandar",The LoCA Regret: A Consistent Metric to Evaluate Model-Based Behavior in Reinforcement Learning,48db71587df6c7c442e5b76cc723169a,https://proceedings.neurips.cc/paper/2020/file/48db71587df6c7c442e5b76cc723169a-Paper.pdf,"The setup and metric introduced in this paper helps speed up progress towards RL methods that can quickly adapt to changes in the environment. Adaptability with respect to environmental changes is a key requirement for many real-world applications, but it is something that current state-of-the-art RL methods struggle with. As such, this work can be viewed as a step towards pushing RL from simulated, stationary environments towards real-world applications. The rise of automated decision-making systems can have many societal consequences, both positive and negative. Certain types of jobs may be replaced by automated systems, for example, various  types of help-desk services. Another aspect to consider is bias: relying more on automated decision- making system could potentially avoid biases present in human decision-making, for example, in legal or healthcare services; on the other hand, there is a risk of introducing new biases related to how the system is trained, algorithmic biases or the way the system is used. Therefore, a valuable avenue for future work to increase the chance of positive impact is to study how biases in automated decision-making systems can be detected and how they can be mitigated.",Broader Impact,189,7,,,FALSE,FALSE,FALSE,The LoCA Regret: A Consistent Metric to Evaluate Model-Based Behavior in Reinforcement Learning,Reinforcement Learning and Planning -> Model-Based RL,Reinforcement Learning and Planning,Reinforcement learning and planning,"['Harm Van Seijen', ' Hadi Nekoei', ' Evan Racah', ' Sarath Chandar']","{'MILA', 'Mila / École Polytechnique de Montréal', 'Mila, Université de Montréal', 'Microsoft Research'}",1,1,1,"{'Canada', 'USA'}"
Neural Power Units,"Niklas Maximilian Heim, Tomas Pevny, Vasek Smidl",Neural Power Units,48e59000d7dfcf6c1d96ce4a603ed738,https://proceedings.neurips.cc/paper/2020/file/48e59000d7dfcf6c1d96ce4a603ed738-Paper.pdf,"Current neural network architectures are often perceived as black box models that are difficult to explain or interpret. This becomes highly problematic if ML models are involved in high stakes decisions in e.g. criminal justice, healthcare, or control systems. With the NPU, we hope to contribute to the broad topic of interpretable machine learning, with a focus on scientific applications. Additionally, learning to abstract (mathematical) ideas and extrapolating is a fundamental goal that might contribute to more reliable machine learning systems. However, the inductive biases that are used to increase transparency in the NPU can cause the model to ignore subgroups in the data. This is not an issue for learning arithmetic operations, but could lead to biased models in more general use cases. The methodology presented in the experiments in Sec. 4.1 is not indented to be used for real-world epidemiological predictions. They are merely demonstrating that the NPU can learn an ODE with  fractional powers. For an application of the NPU much more post-processing has to be done to ensure the reliability of the results.",Broader Impact,177,10,,,FALSE,FALSE,FALSE,Neural Power Units,Theory -> Models of Learning and Generalization,"Algorithms -> Dynamical Systems; Algorithms -> Sparsity and Compressed Sensing; Deep Learning -> Visualization, Interpretability, and Explainability","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Niklas Maximilian Heim', ' Tomas Pevny', ' Vasek Smidl']","{'Czech Technical University', 'Czech Technical University in Prague'}",1,0,0,{'Czech Republic'}
Towards Scalable Bayesian Learning of Causal DAGs,"Jussi Viinikka, Antti Hyttinen, Johan Pensar, Mikko Koivisto",Towards Scalable Bayesian Learning of Causal DAGs,48f7d3043bc03e6c48a6f0ebc0f258a8,https://proceedings.neurips.cc/paper/2020/file/48f7d3043bc03e6c48a6f0ebc0f258a8-Paper.pdf,"Our work advances computational methods for learning from data. Specifically, we give more efficient and reliable methods for Bayesian statistical inference when the stucture of the underlying graphical model is unknown. A Bayesian posterior is a key enabler in informed and principled risk management and decision making under uncertainty, e.g., via the principle of expected utility; clearly, the concept of causality is essential here. We believe that, in the long run, our work will have broad impact in various areas of other sciences, technology, and in society, by making more efficient use of the available data and incorporating quantifications of uncertainty. Positive outcomes: • This work addresses some of the key methodological challenges in computational causal inference, bringing the relatively new field closer towards high-impact real-world applications. • Shows the advantages of Bayesian inference, inviting and encouraging to use of similar approaches also in other domains. Negative outcomes: • Making causal predictions based on observational data is inherently difficult even under rather strong assumptions. Not being aware of these limitations, a non-expert user could potentially overinterpret the results. • Our methods contribute to the practice of discovering causal and statistical relations from data. There is a risk of biased conclusions if the data are biased (cf. fairness in machine learning).",Statement of broader impact,210,11,,,TRUE,TRUE,FALSE,Towards Scalable Bayesian Learning of Causal DAGs,Probabilistic Methods -> Graphical Models,Algorithms -> Model Selection and Structure Learning; Probabilistic Methods -> Causal Inference; Probabilistic Methods -> MCMC,Probabilistic methods and inference,"['Jussi Viinikka', ' Antti Hyttinen', ' Johan Pensar', ' Mikko Koivisto']","{'University of Helsinki', 'University of Oslo'}",1,0,0,"{'Finland', 'Norway'}"
A Dictionary Approach to Domain-Invariant Learning in Deep Networks,"Ze Wang, Xiuyuan Cheng, Guillermo Sapiro, Qiang Qiu",A Dictionary Approach to Domain-Invariant Learning in Deep Networks,490640b43519c77281cb2f8471e61a71,https://proceedings.neurips.cc/paper/2020/file/490640b43519c77281cb2f8471e61a71-Paper.pdf,"In this paper, we introduced a plug-in framework to explicitly model domain shifts in CNNs. With the proposed architecture, we need only a small set of dictionary atoms to model each additional domain, which brings a negligible amount of additional parameters, typically a few hundred. We consider our plug-and-play method a general contribution to deep learning, assuming no particular application.",7 Broader Impact,60,3,FALSE,TRUE,FALSE,FALSE,FALSE,A Dictionary Approach to Domain-Invariant Learning in Deep Networks,Deep Learning,Deep Learning -> CNN Architectures,Vision,"['Ze Wang', ' Xiuyuan Cheng', ' Guillermo Sapiro', ' Qiang Qiu']","{'Purdue University', 'Duke University'}",1,0,0,{'USA'}
Bootstrapping neural processes,"Juho Lee, Yoonho Lee, Jungtaek Kim, Eunho Yang, Sung Ju Hwang, Yee Whye Teh",Bootstrapping Neural Processes,492114f6915a69aa3dd005aa4233ef51,https://proceedings.neurips.cc/paper/2020/file/492114f6915a69aa3dd005aa4233ef51-Paper.pdf,"Uncertainty, robustness, interpretability in predictions have been important desiderata for machine learning algorithms, especially because we have seen actual incidents showing that the algorithms without those could lead to serious damage even threatening human life. The proposed approach suggests a way to enhance robustness by considering uncertainty in data distribution, and the idea of enhancing robustness via bootstrap can be applied to many algorithms over various fields. Therefore, we think that our paper potentially has a positive impact on many areas. Among the experiments we conducted, the predator-prey data experiment (Section 5.4) shows this well, where data generated from a well-established model (Lotka-Volterra model) could be seriously different from real data (Hudson’s Bay hare-lynx data), and our model could reduce the risk of failure in such case. However, we admit that the proposed approach may still be vulnerable to various scenario could happen in real life, so should not be treated as an absolute standard to follow. Our model just reduces the probability of failure in a more natural way (i.e., more “data-driven” way).",Broader Impact,174,6,,,FALSE,FALSE,FALSE,Bootstrapping neural processes,Algorithms -> Meta-Learning,Algorithms -> Stochastic Methods,Probabilistic methods and inference,"['Juho Lee', ' Yoonho Lee', ' Jungtaek Kim', ' Eunho Yang', ' Sung Ju Hwang', ' Yee Whye Teh']","{'University of Oxford, DeepMind', 'POSTECH', 'KAIST, AITRICS', 'AITRICS'}",1,1,1,"{'France', 'UK', 'South Korea'}"
Large-Scale Adversarial Training for Vision-and-Language Representation Learning,"Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu Cheng, Jingjing Liu",Large-Scale Adversarial Training for Vision-and-Language Representation Learning,49562478de4c54fafd4ec46fdb297de5,https://proceedings.neurips.cc/paper/2020/file/49562478de4c54fafd4ec46fdb297de5-Paper.pdf,"Our research advances vision-and-language representation learning by incorporating adversarial training in both pre-training and finetuning stages. By utilizing the enormous amount of image-text data available on the web for pre-training, V ILLA can absorb multimodal clues to capture multi- channel signals from the world, towards a smarter AI system. Furthermore, V ILLA can provide instant performance boost in finetuning stage, which will help accelerate future studies in this field. However, in order to train models to learn such capabilities, our method also calls for a high demand on computational resources due to large-scale training, which could be costly both financially and environmentally. As part of our research effort, we will release our pre-trained models to facilitate future research, to empower others’ scientific exploration and save environmental cost.",Broader Impact,127,5,,,FALSE,FALSE,FALSE,Large-Scale Adversarial Training for Vision-and-Language Representation Learning,Applications -> Visual Question Answering,Applications -> Natural Language Processing,Deep learning,"['Zhe Gan', 'Chun Chen', ' Linjie Li', ' Chen Zhu', ' Yu Cheng', ' Jingjing Liu']","{'Microsoft', 'University of Maryland'}",1,1,1,{'USA'}
Most ReLU Networks Suffer from ℓ2ℓ2 Adversarial Perturbations,"Amit Daniely, Hadas Shacham",Most ReLU Networks Suffer from 2 Adversarial Perturbations,497476fe61816251905e8baafdf54c23,https://proceedings.neurips.cc/paper/2020/file/497476fe61816251905e8baafdf54c23-Paper.pdf,Not applicable as far as we can see (this is a purely theoretical paper).,Broader Impact,14,1,TRUE,FALSE,FALSE,FALSE,FALSE,Most ReLU Networks Suffer from $\ell^2$ Adversarial Perturbations,Theory,Theory -> Computational Learning Theory,Theory (including computational and statistical analyses),,"{'Hebrew University', 'Hebrew University and Google Research'}",1,0,0,{'Israel'}
Compositional Visual Generation with Energy Based Models,"Yilun Du, Shuang Li, Igor Mordatch",Compositional Visual Generation with Energy Based Models,49856ed476ad01fcff881d57e161d73f,https://proceedings.neurips.cc/paper/2020/file/49856ed476ad01fcff881d57e161d73f-Paper.pdf,"We believe that compositionality is a crucial component of next generation AI systems. Compositionality enables system to synthesize and combine knowledge from different domains to tackle the problem in hand. Our proposed method is step towards more composable deep learning models. A truly compositional system has many positive societal benefits, potentially enabling a intelligent and flexible robots that can selectively recruit different skills learned for the task on hand, or super-human synthesis of scientific knowledge that can further progress of scientific discovery. At the same time, there remain unanswered ethical problems about any such next generation AI system.",7 Broader Impacts,98,5,,,FALSE,FALSE,FALSE,Compositional Visual Generation with Energy Based Models,Deep Learning -> Generative Models,Algorithms -> Continual Learning,Deep learning,"['Yilun Du', ' Shuang Li', ' Igor Mordatch']","{'Google', 'MIT'}",1,1,1,{'USA'}
Factor Graph Grammars,"David Chiang, Darcey Riley",Factor Graph Grammars,49ca03822497d26a3943d5084ed59130,https://proceedings.neurips.cc/paper/2020/file/49ca03822497d26a3943d5084ed59130-Paper.pdf,"This research is of potential benefit to anyone working with structured probability models, including latent-variable neural networks. As this research is purely theoretical, we are not aware of any direct negative impacts.",Broader Impact,32,2,FALSE,FALSE,FALSE,FALSE,FALSE,Factor Graph Grammars,Probabilistic Methods -> Graphical Models,Theory,Probabilistic methods and inference,"['David Chiang', ' Darcey Riley']",{'University of Notre Dame'},1,0,0,{'USA'}
Erdos Goes Neural: an Unsupervised Learning Framework for Combinatorial Optimization on Graphs,"Nikolaos Karalias, Andreas Loukas",Erd os Goes Neural: an Unsupervised Learning Framework for Combinatorial Optimization on Graphs,49f85a9ed090b20c8bed85a5923c669f,https://proceedings.neurips.cc/paper/2020/file/49f85a9ed090b20c8bed85a5923c669f-Paper.pdf,"This subfield of deep learning that our work belongs to is still in its nascent stages, compared to others like computer vision or translation. Therefore, we believe that it poses no immediate ethical or societal challenges. However, advances in combinatorial optimization through deep learning can have significant long term consequences. Combinatorial optimization tasks are important in manufacturing and transportation. The ability to automate these tasks will likely lead to significant improvements in productivity and efficiency in those sectors which will affect many aspects of everyday life. On the other hand, these tasks would be otherwise performed by humans which means that such progress may eventually lead to worker displacement in several industries. Combinatorial optimization may also lead to innovations in medicine and chemistry, which will be beneficial to society in most cases. Our work follows the paradigm of unsupervised learning which means that it enjoys some advantages over its supervised counterparts. The lack of labeled instances implies a lack of label bias. Conse- quently, we believe that unsupervised learning has the potential to avoid many of the issues (fairness, neutrality) that one is faced with when dealing with labeled datasets. That does not eliminate all sources of bias in the learning pipeline, but it is nonetheless a step towards the right direction. Finally, we acknowledge that combinatorial optimization has also been widely applied in military operations. However, even though this is not the intention of many researchers, we believe that it is just a natural consequence of the generality and universality of the problems in this field. Therefore, as with many technological innovations, we expect that the positives will outweigh the negatives as long as the research community maintains a critical outlook on the subject. Currently, the state of the field does not warrant any serious concerns and thus we remain cautiously optimistic about its impact in the world.",7 Broader impact,309,15,,,TRUE,TRUE,FALSE,Erdos Goes Neural: an Unsupervised Learning Framework for Combinatorial Optimization on Graphs,Algorithms -> Relational Learning,Algorithms -> Clustering; Algorithms -> Representation Learning; Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Nikolaos Karalias', ' Andreas Loukas']",{'EPFL'},1,0,0,{'Switzerland'}
Autoregressive Score Matching,"Chenlin Meng, Lantao Yu, Yang Song, Jiaming Song, Stefano Ermon",Autoregressive Score Matching,4a4526b1ec301744aba9526d78fcb2a6,https://proceedings.neurips.cc/paper/2020/file/4a4526b1ec301744aba9526d78fcb2a6-Paper.pdf,"The main contribution of this paper is theoretical—a new divergence between distributions and a related class of generative models. We do not expect any direct impact on society. The models we trained using our approach and used in the experiments have been learned using classic dataset and have capabilities substantially similar to existing models (GANs, autoregressive models, flow models): generating images, anomaly detection, denoising. As with other technologies, these capabilities can have both positive and negative impact, depending on their use. For example, anomaly detection can be used to increase safety, but also possibly for surveillance. Similarly, generating images can be used to enable new art but also in malicious ways.",Broader Impact,111,6,,,FALSE,FALSE,FALSE,Autoregressive Score Matching,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Algorithms -> Unsupervised Learning,Deep learning,"['Chenlin Meng', ' Lantao Yu', ' Yang Song', ' Jiaming Song', ' Stefano Ermon']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Debiasing Distributed Second Order Optimization with Surrogate Sketching and Scaled Regularization,"Michal Derezinski, Burak Bartan, Mert Pilanci, Michael W. Mahoney",Debiasing Distributed Second Order Optimization with Surrogate Sketching and Scaled Regularization,4a46fbfca3f1465a27b210f4bdfe6ab3,https://proceedings.neurips.cc/paper/2020/file/4a46fbfca3f1465a27b210f4bdfe6ab3-Paper.pdf,"This work does not present any foreseeable negative societal consequence. We believe that the proposed optimization methods in this work can have positive societal impacts. Our main results can be applied in massive scale distributed learning and optimization problems which are frequently encountered in practical AI systems. Using our methods, the learning phase can be significantly accelerated and consequently energy costs for training can be significantly reduced.",Broader Impact,67,4,FALSE,FALSE,FALSE,FALSE,FALSE,Debiasing Distributed Second Order Optimization with Surrogate Sketching and Scaled Regularization,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization; Theory -> Computational Learning Theory,Optimization Methods (continuous or discrete),"['Michal Derezinski', ' Burak Bartan', ' Mert Pilanci', ' Michael W Mahoney']","{'UC Berkeley', 'Stanford University', 'Stanford'}",1,0,0,{'USA'}
Neural Controlled Differential Equations for Irregular Time Series,"Patrick Kidger, James Morrill, James Foster, Terry Lyons",Neural Controlled Differential Equations for Irregular Time Series,4a5876b450b45371f6cfe5047ac8cd45,https://proceedings.neurips.cc/paper/2020/file/4a5876b450b45371f6cfe5047ac8cd45-Paper.pdf,"We have introduced a new tool for studying irregular time series. As with any tool, it may be used in both positive and negative ways. The authors have a particular interest in electronic health records (an important example of irregularly sampled time-stamped data) and so here at least we hope and expect to see a positive impact from this work. We do not expect any specific negative impacts from this work.",Broader Impact,71,4,,,FALSE,FALSE,FALSE,Neural Controlled Differential Equations for Irregular Time Series,Deep Learning -> Recurrent Networks,Algorithms -> Missing Data; Applications -> Time Series Analysis; Deep Learning -> Supervised Deep Networks,Deep learning,"['Patrick Kidger', ' James Morrill', ' James Foster', ' Terry Lyons']",{'University of Oxford'},1,0,0,{'UK'}
On Efficiency in Hierarchical Reinforcement Learning,"Zheng Wen, Doina Precup, Morteza Ibrahimi, Andre Barreto, Benjamin Van Roy, Satinder Singh",On Efficiency in Hierarchical Reinforcement Learning,4a5cfa9281924139db466a8a19291aff,https://proceedings.neurips.cc/paper/2020/file/4a5cfa9281924139db466a8a19291aff-Paper.pdf,"This is a theoretical investigation and as such does not present any foreseeable immediate societal impact beyond the general concerns over progress in artificial intelligence. Specifically, we focused on the question of how to design efficient hierarchical agents for reinforcement learning problems with repeating sub-problem structure. The insights provided have the potential to help practitioners to build more efficient hierarchical agents for real-world reinforcement learning problems, whose societal impact depends on the specific application.",Broader Impact,74,3,TRUE,TRUE,FALSE,FALSE,FALSE,On Efficiency in Hierarchical Reinforcement Learning,Reinforcement Learning and Planning -> Hierarchical RL,Reinforcement Learning and Planning,Reinforcement learning and planning,"['Zheng Wen', ' Doina Precup', ' Morteza Ibrahimi', ' Andre Barreto', ' Benjamin Van Roy', ' Satinder Singh']","{'Stanford University', 'DeepMind'}",1,1,1,"{'UK', 'USA'}"
On Correctness of Automatic Differentiation for Non-Differentiable Functions,"Wonyeol Lee, Hangyeol Yu, Xavier Rival, Hongseok Yang",On Correctness of Automatic Differentiation for Non-Differentiable Functions,4aaa76178f8567e05c8e8295c96171d8,https://proceedings.neurips.cc/paper/2020/file/4aaa76178f8567e05c8e8295c96171d8-Paper.pdf,"This work focuses mainly on theoretical aspects of autodiff systems. In particular, we formally prove that the systems, though developed to handle differentiable functions, remain correct even when applied to non-differentiable functions. Our result justifies, at least in part, the current situation in machine learning, in which the systems are frequently applied to non-differentiable functions without much consideration to their correctness under such out-of-scope use cases. Other than the justification, this work does not present any other foreseeable societal consequence due to its theoretical nature.",Broader Impact,85,4,TRUE,TRUE,TRUE,TRUE,FALSE,On Correctness of Automatic Differentiation for Non-Differentiable Functions,Theory,"Data, Challenges, Implementations, and Software; Data, Challenges, Implementations, and Software -> Software Toolkits; Deep Learning; Theory -> Spaces of Functions and Kernels",Theory (including computational and statistical analyses),"['Wonyeol Lee', ' Hangyeol Yu', ' Xavier Rival', ' Hongseok Yang']","{'ENS', 'KAIST'}",1,0,0,"{'France', 'South Korea'}"
Probabilistic Linear Solvers for Machine Learning,"Jonathan Wenger, Philipp Hennig",Probabilistic Linear Solvers for Machine Learning,4afd521d77158e02aed37e2274b90c9c,https://proceedings.neurips.cc/paper/2020/file/4afd521d77158e02aed37e2274b90c9c-Paper.pdf,"Our research on probabilistic linear solvers is primarily aimed at members of the machine learning field working on uncertainty estimation which use linear solvers as part of their toolkit. We are convinced that numerical uncertainty induced by finite computational resources is a key missing component to be quantified in machine learning settings. By making numerical uncertainty explicit like our solver does, holistic probabilistic models incorporating all sources of uncertainty become possible. In fact, we hope that this line of work stimulates further research into numerical linear algebra for machine learning, a topic that has been largely considered solved by the community. This is first and foremost a methods paper aiming to improve the quantification of numerical uncertainty in linear problems. While methodological papers may seem far removed from application and questions of ethical and societal impact, this is not the case. Precisely due to the general nature of the problem setting, the linear solver presented in this work is applicable to a broad range of applications, from regression on flight data, to optimization in robotics, to the solution of PDEs in meteorology.  The flip-side of this potential impact is that arguably, down the line, methodological research suffers from dual use more than any specialized field. While we cannot control the use of a probabilistic linear solver due to its general applicability, we have tried, to the best of our ability, to ensure it performs as intended. We are hopeful that no specific population group is put at a disadvantage through this research. We are providing an open-source implementation of our method and of all experiments contained in this work. Therefore anybody with access to the internet is able to retrieve and reproduce our findings. In this manner we hope to adress the important issues of accessibility and reproducibility.",Broader Impact,298,13,,,FALSE,TRUE,FALSE,Probabilistic Linear Solvers for Machine Learning,Algorithms -> Uncertainty Estimation,Probabilistic Methods -> Bayesian Theory; Probabilistic Methods -> Gaussian Processes,Probabilistic methods and inference,"['Jonathan Wenger', ' Philipp Hennig']","{'University of Tübingen', 'University of Tübingen and MPI for Intelligent Systems Tübingen'}",1,0,0,{'Germany'}
Dynamic Regret of Policy Optimization in Non-Stationary Environments,"Yingjie Fei, Zhuoran Yang, Zhaoran Wang, Qiaomin Xie",Dynamic Regret of Policy Optimization in Non-Stationary Environments,4b0091f82f50ff7095647fe893580d60,https://proceedings.neurips.cc/paper/2020/file/4b0091f82f50ff7095647fe893580d60-Paper.pdf,"This work provides novel algorithms and analysis for non-stationary RL, which is the foundation of several important RL paradigms including continual/meta RL and human-machine interaction. We present two efficient and model-free policy optimization algorithms for episodic MDPs with adversarial reward functions and fixed unknown transitions. For both algorithms, we provide dynamic regret bounds that interpolate between different regimes of non-stationarity of the underlying model. We show that our bounds achieve the near-optimal Ō(T1/2) order and are adaptively near-optimal in slow-changing environments. To the best of our knowledge, our work provides the first dynamic regret analysis for model-free algorithms in non-stationary RL.",Broader Impact,101,5,,,TRUE,TRUE,FALSE,Dynamic Regret of Policy Optimization in Non-Stationary Environments,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Yingjie Fei', ' Zhuoran Yang', ' Zhaoran Wang', ' Qiaomin Xie']","{'Princeton', 'Northwestern University', 'Cornell University'}",1,0,0,{'USA'}
Multipole Graph Neural Operator for Parametric Partial Differential Equations,"Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Andrew Stuart, Kaushik Bhattacharya, Anima Anandkumar",Multipole Graph Neural Operator for Parametric Partial Differential Equations,4b21cf96d4cf612f239a6c322b10c8fe,https://proceedings.neurips.cc/paper/2020/file/4b21cf96d4cf612f239a6c322b10c8fe-Paper.pdf,"Many problems in science and engineering involve solving complex PDE systems repeatedly for different values of some parameters. Example arise in molecular dynamics, micro-mechanics, and turbulent flows. Often such systems exhibit multi-scale structure, requiring very fine discretizations in order to capture the phenomenon being modeled. As a consequence, traditional Galerkin methods are slow and inefficient, leading to tremendous amounts of resources being wasted on high performance computing clusters every day. Machine learning methods hold the key to revolutionizing many scientific disciplines by providing fast solvers that can work purely from data as accurate physical models may sometimes not be available. However traditional neural networks work between finite- dimensional spaces and can therefore only learn solutions tied to a specific discretizations. This is often an insurmountable limitation for practical applications and therefore the development of mesh-invariant neural networks is required. Graph neural networks offer a natural solution however their computational complexity can sometime render them ineffective. Our work solves this problem by proposing an algorithm with a linear time complexity that captures long-range correlations within the data and has potential applications far outside the scope of numerical solutions to PDEs. We bring together ideas from multi-scale modeling and multi-resolution decomposition to the graph neural network community.",Broader Impact,205,10,,,FALSE,FALSE,FALSE,Multipole Graph Neural Operator for Parametric Partial Differential Equations,Algorithms -> Kernel Methods,,,"['Zongyi Li', ' Nikola Kovachki', ' Kamyar Azizzadenesheli', ' Burigede Liu', ' Andrew Stuart', ' Kaushik Bhattacharya', ' Anima Anandkumar']","{'California Institute of Technology', 'Caltech', 'caltech', 'NVIDIA / Caltech'}",1,1,1,{'USA'}
BlockGAN: Learning 3D Object-aware Scene Representations from Unlabelled Images,"Thu H. Nguyen-Phuoc, Christian Richardt, Long Mai, Yongliang Yang, Niloy Mitra",BlockGAN: Learning 3D Object-aware Scene Representations from Unlabelled Images,4b29fa4efe4fb7bc667c7b301b74d52d,https://proceedings.neurips.cc/paper/2020/file/4b29fa4efe4fb7bc667c7b301b74d52d-Paper.pdf,"BlockGAN is an image generative model that learns an object-oriented 3D scene representation directly from unlabelled 2D images. Our approach is a new machine learning technique that makes it possible to generate unseen images from a noise vector, with unprecedented control over the identity and pose of multiple independent objects as well as the background. In the long term, our approach could enable powerful tools for digital artists that facilitate artistic control over realistic procedurally generated digital content. However, any tool can in principle be abused, for example by adding new, manipulating or removing existing objects or people from images. At training time, our network performs a task somewhat akin to scene understanding, as our approach learns to disentangle between multiple objects and individual object properties (specifically their pose and identity). At test time, our approach enables sampling new images with control over pose and identity for each object in the scene, but does not directly take any image input. However, it is possible to embed images into the latent space of generative models [1]. A highly realistic generative image model and a good image fit would then make it possible to approximate the input image and, more importantly, to edit the individual objects in a pictured scene. Similar to existing image editing software, this enables the creation of image manipulations that could be used for ill-intended misinformation (fake news), but also for a wide range of creative and other positive applications. We expect the benefits of positive applications to clearly outweigh the potential downsides of malicious applications.",Broader Impact,258,10,,,TRUE,TRUE,FALSE,BlockGAN: Learning 3D Object-aware Scene Representations from Unlabelled Images,Deep Learning -> Generative Models,Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Phuoc', ' Christian Richardt', ' Long Mai', ' Yongliang Yang', ' Niloy Mitra']","{'Adobe Research', 'University College London', 'University of Bath'}",1,1,1,"{'UK', 'USA'}"
Online Structured Meta-learning,"Huaxiu Yao, Yingbo Zhou, Mehrdad Mahdavi, Zhenhui (Jessie) Li, Richard Socher, Caiming Xiong",Online Structured Meta-learning,4b86ca48d90bd5f0978afa3a012503a4,https://proceedings.neurips.cc/paper/2020/file/4b86ca48d90bd5f0978afa3a012503a4-Paper.pdf,"The rapid development of information technology has greatly increased the machine’s ability to continuously and quickly adapt to the new environment. For example, in an autonomous driving scenario, we need to continuously allow the machine to adapt to the new environment. Without such ability, autonomous cars are difficult to be applied to real scenarios, and may also cause potential safety hazards. In this paper, we mainly study the continuous adaptation of meta-learning to complex heterogeneous tasks. Compared to homogeneous tasks, heterogeneous tasks are not only more common in the real world, but also more challenging. Investigating this problem benefits the improvement of learning ability under the online meta-learning setting, which further greatly benefits a large number of applications. Especially, the meta-hierarchical tree we designed can capture the structural association between different tasks. For example, in the disease risk prediction problem, we expect that the agent is capable of continuously adjusting the model to adapt to different diseases. Considering the great correlation between diseases, our model is able to automatically detect these correlations and incorporate the rich external knowledge (e.g., medical knowledge graph).",Broader Impact,182,9,,,FALSE,FALSE,FALSE,Online Structured Meta-learning,Algorithms -> Meta-Learning,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Huaxiu Yao', ' Yingbo Zhou', ' Mehrdad Mahdavi', ' Zhenhui', ' Li', ' Richard Socher', ' Caiming Xiong']","{'Salesforce', 'Salesforce Research', 'Jessie', 'Penn State University', 'Pennsylvania State University'}",1,1,1,{'USA'}
Learning Strategic Network Emergence Games,"Rakshit Trivedi, Hongyuan Zha",Learning Strategic Network Emergence Games,4bb236de7787ceedafdff83bb8ea4710,https://proceedings.neurips.cc/paper/2020/file/4bb236de7787ceedafdff83bb8ea4710-Paper.pdf,"Networks are ubiquitous structures found across wide range of domains including social, physical, economic systems and many more and any learning approaches in this space has impact on wide ranging applications that consume, process or generate network data. This work focuses on a specific class of networks that come into existence as a result of strategic behaviors adopted by living agents such as humans. Examples of such networks include financial networks, trades between countries, social collaboration networks, human mobility networks and many more, where the network structure itself may be the outcome of direct or indirect actions of human participants. Further, such participants exhibit both bounded rationality and selfishness in their behavior. Analyzing such networks provide insights into the underlying mechanisms that lead to the emergence of such networks. With the increasing availability of network data, learning approaches that can analyze strategic mechanisms would empower AI systems that would help practitioners such as economists, lawmakers and disaster management personnel in the decision-making process. For instance, financial organizations would  benefit by understanding the strategic behavior of market stakeholders and similarly understanding emergence of contact networks would help design effective quarantine policies. We expect our work to serve as an initial step towards building interpretable approaches to learning such mechanisms from previously available strategic networks and use it for predictive purposes. Also, this line of work can be used to build network design simulators, where the learned mechanism can be used to simulate various network configuration by varying information about the agents which can have ethical considerations. Hence, we caution that this initial attempt will require thorough analysis and follow-up efforts to be put it into practice in real-world settings.",Broader Impact,278,10,,,FALSE,TRUE,FALSE,Learning Strategic Network Emergence Games,Applications -> Network Analysis,Algorithms -> Multitask and Transfer Learning; Algorithms -> Relational Learning; Applications -> Computational Social Science; Reinforcement Learning and Planning -> Multi-Agent RL; Theory -> Game Theory and Computational Economics,"Other applications (e.g., robotics, biology, climate, finance)","['RAKSHIT TRIVEDI', ' Hongyuan Zha']","{'Georgia Tech', 'GEORGIA INSTITUTE OF TECHNOLOGY'}",1,0,0,{'USA'}
Towards Interpretable Natural Language Understanding with Explanations as Latent Variables,"Wangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun, Chenyan Xiong, Jian Tang",Towards Interpretable Natural Language Understanding with Explanations as Latent Variables,4be2c8f27b8a420492f2d44463933eb6,https://proceedings.neurips.cc/paper/2020/file/4be2c8f27b8a420492f2d44463933eb6-Paper.pdf,"Deep learning has achieved great success in natural language understanding. However, most existing systems are not interpretable, which limit their applications to many domains such as healthcare, finance, and legislation. In these domains, interpretability is a high priority. This paper proposed a principled probabilistic model for text classification, which not only makes effective prediction but also offers good explainability. Though the model is developed for the task of text classification, it is a very general framework and could be generalized to other tasks in natural language understanding. Such a system could be useful in a variety of tasks such as decision making with clinical notes in healthcare, justice, and criminal identification with legal data, and risk management in finance. On the other hand, such a system also brings potential risks depending on the quality of the generated natural language explanations. For example, the generated natural language could have certain biases, which have been reported in many natural language understanding systems [39, 40]. How to mitigate these risks will be our future work. Another potential risk is that the explanation generation model in our framework generates ad-hoc explanations that are not necessarily informative about how the model makes its predictions, since the model can come up with whatever explanation it thinks would pair with its predicted label. This is a common drawback for current explanation generation models. Our framework partially mitigates this problem since the generated explanations are in return used in the training process of the explanation-augmented classifier through the explanation retrieval process.",Broader Impact,253,12,,,FALSE,FALSE,FALSE,Towards Interpretable Natural Language Understanding with Explanations as Latent Variables,Applications -> Natural Language Processing,"Algorithms -> Semi-Supervised Learning; Deep Learning -> Visualization, Interpretability, and Explainability",Natural language processing,"['Wangchunshu Zhou', ' Jinyi Hu', ' Hanlin Zhang', ' Xiaodan Liang', ' Maosong Sun', ' Chenyan Xiong', ' Jian Tang']","{'Beihang University', 'South China University of Technology', 'Mila', 'Sun Yat-sen University', 'Tsinghua University', 'Microsoft Research AI'}",1,1,1,"{'Canada', 'USA', 'China'}"
The Mean-Squared Error of Double Q-Learning,"Wentao Weng, Harsh Gupta, Niao He, Lei Ying, R. Srikant",The Mean-Squared Error of Double Q-Learning,4bfbd52f4e8466dc12aaf30b7e057b66,https://proceedings.neurips.cc/paper/2020/file/4bfbd52f4e8466dc12aaf30b7e057b66-Paper.pdf,"Reinforcement learning (RL) has been the driving force behind many recent breakthroughs in Artificial Intelligence, including defeating humans in games (e.g., chess, Go, StarCraft), self-driving cars, smart home automation, among many others. However, much of the successes build on efficient heuristics and empirical explorations, lacking sufficient theoretical understanding. One such example is Double Q-learning, which is the common practice used in deep reinforcement learning. This work establishes a theoretical analysis of the mean-squared error of double Q-learning, and provides principled guidelines for its implementation. These contributions have the potential to promote a stronger understanding of common RL algorithms both in theory and practice, accelerate the design of more efficient, interpretable RL algorithms, and benefit tremendous RL-driven applications that are societally impactful.",Broader Impact,121,5,FALSE,FALSE,TRUE,TRUE,FALSE,The Mean-Squared Error of Double Q-Learning,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Wentao Weng', ' Harsh Gupta', ' Niao He', ' Lei Ying', ' Srikant']","{'UIUC', 'University of Illinois at Urbana-Champaign', 'Tsinghua University', 'University of Michigan'}",1,0,0,"{'USA', 'China'}"
What Makes for Good Views for Contrastive Learning?,"Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, Phillip Isola",What Makes for Good Views for Contrastive Learning?,4c2e5eaae9152079b9e95845750bb9ab,https://proceedings.neurips.cc/paper/2020/file/4c2e5eaae9152079b9e95845750bb9ab-Paper.pdf,"This paper is on the basic science of representation learning, and we believe it will be beneficial to both the theory and practice of this field. An immediate application of self-supervised representation learning is to reduce the reliance on labeled data for downstream applications. This may have the beneficial effects of being more cost effective and reducing biases introduced by human annotations. At the same time, these methods open up the ability to use uncurated data more effectively, and such data may hide errors and biases that would have been uncovered via the human curation process. We also note that the view constructions we propose are not bias free, even when they do not use labels: using one color space or another may hide or reveal different properties of the data. The choice of views therefore plays a similar role to the choice of training data and training annotations in traditional supervised learning.",Broader Impact,153,6,,,FALSE,FALSE,FALSE,What Makes for Good Views for Contrastive Learning?,Algorithms -> Representation Learning,Algorithms -> Unsupervised Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,"{'Google Brain', 'Google Research', 'Google', 'Massachusetts Institute of Technology', 'MIT'}",1,1,1,{'USA'}
Denoising Diffusion Probabilistic Models,"Jonathan Ho, Ajay Jain, Pieter Abbeel",Denoising Diffusion Probabilistic Models,4c5bcfec8584af0d967f1ab10179ca4b,https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf,"Our work on diffusion models takes on a similar scope as existing work on other types of deep generative models, such as efforts to improve the sample quality of GANs, flows, autoregressive models, and so forth. Our paper represents progress in making diffusion models a generally useful tool in this family of techniques, so it may serve to amplify any impacts that generative models have had (and will have) on the broader world. Unfortunately, there are numerous well-known malicious uses of generative models. Sample gen- eration techniques can be employed to produce fake images and videos of high profile figures for political purposes. While fake images were manually created long before software tools were avail- able, generative models such as ours make the process easier. Fortunately, CNN-generated images currently have subtle flaws that allow detection [62], but improvements in generative models may make this more difficult. Generative models also reflect the biases in the datasets on which they are trained. As many large datasets are collected from the internet by automated systems, it can be difficult to remove these biases, especially when the images are unlabeled. If samples from generative models trained on these datasets proliferate throughout the internet, then these biases will only be reinforced further. On the other hand, diffusion models may be useful for data compression, which, as data becomes higher resolution and as global internet traffic increases, might be crucial to ensure accessibility of the internet to wide audiences. Our work might contribute to representation learning on unlabeled raw data for a large range of downstream tasks, from image classification to reinforcement learning, and diffusion models might also become viable for creative uses in art, photography, and music.",Broader Impact,282,11,,,FALSE,FALSE,FALSE,Denoising Diffusion Probabilistic Models,Deep Learning -> Generative Models,,Deep learning,"['Jonathan Ho', ' Ajay Jain', ' Pieter Abbeel']",{'UC Berkeley'},1,0,0,{'USA'}
Barking up the right tree: an approach to search over molecule synthesis DAGs,"John Bradshaw, Brooks Paige, Matt J. Kusner, Marwin Segler, José Miguel Hernández-Lobato",Barking up the right tree: an approach to search over molecule synthesis DAGs,4cc05b35c2f937c5bd9e7d41d3686fff,https://proceedings.neurips.cc/paper/2020/file/4cc05b35c2f937c5bd9e7d41d3686fff-Paper.pdf,"Molecular de novo design, the ability to faster discover new advanced materials, could be an important tool in addressing many present societal challenges, such as global health and climate change. For example, it could contribute towards a successful transition to clean energy, through the development of new materials for energy production (e.g. organic photovoltaics) and storage (e.g. flow batteries). We hope that our methods, by producing synthesizable molecules upfront, are a contribution to the research in this direction. An application area for molecule de novo design we are particularly enthusiastic about and believe could lead to large positive societal outcomes is drug design. By augmenting the capabilities of researchers in this area we can reduce the cost of discovering new drugs for treating diseases. This may be particularly helpful in the development of treatments for neglected tropical diseases or orphan diseases, in which currently there are often poorer economic incentives for developing drugs. Whilst we are excited by these positive benefits that faster molecule design could bring, it is also important to be mindful of possible risks. We can group these risks into two categories, (i) use of the technology for negative downstream applications (for instance if our model was used in the design of new chemical weapons), and (ii) negative side effects of the technology (for instance including the general downsides of increased automation, such as an increased chance of accidents). If not done carefully, increased automation can have a negative impact on jobs, and in our particular case may lead to a reduction in the control and understanding of the molecular design process. We hope that this can be mitigated by communicating clearly about near-term capabilities, using and further developing sensible benchmarks/metrics, as well as the development of tools to better explain the ML decision making process.",Broader Impact,299,10,,,FALSE,FALSE,FALSE,Barking up the right tree: an approach to search over molecule synthesis DAGs,Applications -> Computational Biology and Bioinformatics,Deep Learning -> Generative Models,"Other applications (e.g., robotics, biology, climate, finance)","['John Bradshaw', ' Brooks Paige', ' Matt Kusner', ' Marwin Segler', 'Lobato']","{'University of Cambridge', 'University of Cambridge/MPI IS Tübingen', 'BenevolentAI', 'University College London'}",1,1,1,{'UK'}
On Uniform Convergence and Low-Norm Interpolation Learning,"Lijia Zhou, D.J. Sutherland, Nati Srebro",On Uniform Convergence and Low-Norm Interpolation Learning,4cc5400e63624c44fadeda99f57588a6,https://proceedings.neurips.cc/paper/2020/file/4cc5400e63624c44fadeda99f57588a6-Paper.pdf,"Interpolation learning is currently thought to be one of the core mysteries standing between us and a theoretical understanding of modern deep learning. Although there has recently been some key progress, many challenges remain. Our paper, in advancing the study of interpolation learning, makes another step on the path towards understanding the deep learning models that are quickly becoming ubiquitous throughout society, whether we understand them or not. In our view, increased understanding of these models can lead to safer, more reliable, and more controlled deployment, especially in sensitive domains. In particular, we discuss a key component of statistical learning theory, namely uniform convergence, whose relevance to deep learning in general – and interpolation learning specifically – has recently been questioned. We make an explicit connection between the work on interpolation learning and the recent notion of “algorithmic dependent uniform convergence” [22]. Instead of outright dismissal, we show that a more nuanced view is appropriate. By doing so, we hope to help guide the re-pivoting that statistical learning theory is currently undergoing. We emphasize that, despite providing some positive theoretical results, we are certainly not advocating for preferring interpolation methods over other approaches. In particular, the increased sensitivity of interpolation methods may have problematic ramifications for robustness or privacy.",Broader Impact,209,10,,,FALSE,FALSE,FALSE,On Uniform Convergence and Low-Norm Interpolation Learning,Theory -> Statistical Learning Theory,Theory; Theory -> Models of Learning and Generalization ; Theory -> Regularization,Theory (including computational and statistical analyses),"['Lijia Zhou', ' Sutherland', ' Nati Srebro']","{'TTI-Chicago', 'University of Chicago'}",1,1,1,"{'USA', 'Israel'}"
Bandit Samplers for Training Graph Neural Networks,"Ziqi Liu, Zhengwei Wu, Zhiqiang Zhang, Jun Zhou, Shuang Yang, Le Song, Yuan Qi",Bandit Samplers for Training Graph Neural Networks,4cea2358d3cc5f8cd32397ca9bc51b94,https://proceedings.neurips.cc/paper/2020/file/4cea2358d3cc5f8cd32397ca9bc51b94-Paper.pdf,"This paper presents an approach for fast training of graph neural networks with theoretical guarantees. It may have impacts on training approaches related to any models based on message passing. The graph neural networks may have positive impacts on recommendater systems, protein analyses, fraud detection and so on. This work does not present any foreseeable societal consequence.",Broader Impact,57,4,FALSE,TRUE,FALSE,TRUE,FALSE,Bandit Samplers for Training Graph Neural Networks,Deep Learning -> Efficient Training Methods,Algorithms -> Bandit Algorithms,Deep learning,"['Ziqi Liu', ' Zhengwei Wu', ' Zhiqiang Zhang', ' Jun Zhou', ' Shuang Yang', ' Le Song', ' Yuan Qi']","{'Ant Financial', 'Ant Financial Services Group'}",0,1,0,{'China'}
Sampling from a k-DPP without looking at all items,"Daniele Calandriello, Michal Derezinski, Michal Valko",Sampling from a k -DPP without looking at all items,4d410063822cd9be28f86701c0bc3a31,https://proceedings.neurips.cc/paper/2020/file/4d410063822cd9be28f86701c0bc3a31-Paper.pdf,"DPPs were discovered in the 70s by Odile Macchi to model repulsion of particle distributions in fermions, so improvements in samplers may help in modelling physical simulations. In bringing faster DPP samplers to machine learning we aim to enable a better handling of diversity through this rigorous theoretical framework.",Broader impact,49,2,FALSE,FALSE,FALSE,FALSE,FALSE,Sampling from a k-DPP without looking at all items,Algorithms,Algorithms -> Active Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Daniele Calandriello', ' Michal Derezinski', ' Michal Valko']","{'UC Berkeley', 'LCSL IIT/MIT', 'DeepMind'}",1,1,1,"{'UK', 'USA'}"
Uncovering the Topology of Time-Varying fMRI Data using Cubical Persistence,"Bastian Rieck, Tristan Yates, Christian Bock, Karsten Borgwardt, Guy Wolf, Nicholas Turk-Browne, Smita Krishnaswamy",Uncovering the Topology of Time-Varying fMRI Data using Cubical Persistence,4d771504ddcd28037b4199740df767e6,https://proceedings.neurips.cc/paper/2020/file/4d771504ddcd28037b4199740df767e6-Paper.pdf,"The primary contribution of this work—a novel, parameter-free way of extracting informative features from fMRI data—is of a computational nature. In general, we fully acknowledge that any researcher dealing with fMRI data analysis (not necessarily restricted to machine learning methods) has a big responsibility. Since our work is purely computational, we do not believe that it will have adverse ethical consequences, provided the experimental design is unbiased. For the same reason, our work is not specifically favouring or disfavouring any groups. Beyond the immediate applications for fMRI data analysis, our work also has a broader applicability for the analysis of time-varying or structured neuroscience data in general. This includes other non-invasive techniques such as EEG or MEG, but also neuronal spike data from cell populations. Our work is appealing for such data because it does not require auxiliary representations such as graphs. We are thus convinced that the introduction of our directly-computable topological features will overall have beneficial outcomes. As long-term goal, for example, our work could serve as a foundation to investigate neurological pathologies (such as depressive disorders) from a new, topological perspective. In general, our dynamic analyses also allow us to capture not just stable traits in different populations, but also the different mental states participants progress through while undergoing fMRI. As a generic feature descriptor of brain states, we would welcome a future in which topological features aid in understanding such traits or states.",Broader impact,237,11,,,FALSE,FALSE,FALSE,Uncovering the Topology of Time-Varying fMRI Data using Cubical Persistence,Neuroscience and Cognitive Science -> Brain Imaging,Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Visual Perception,Neuroscience and cognitive science,"['Bastian Rieck', ' Tristan Yates', ' Christian Bock', ' Karsten Borgwardt', ' Guy Wolf', 'Browne', ' Smita Krishnaswamy']","{'ETH Zurich', 'Yale University'}",1,0,0,"{'USA', 'Switzerland'}"
Hierarchical Poset Decoding for Compositional Generalization in Language,"Yinuo Guo, Zeqi Lin, Jian-Guang Lou, Dongmei Zhang",Hierarchical Poset Decoding for Compositional Generalization in Language,4d7e0d72898ae7ea3593eb5ebf20c744,https://proceedings.neurips.cc/paper/2020/file/4d7e0d72898ae7ea3593eb5ebf20c744-Paper.pdf,"In this paper, authors introduce a hierarchical poset decoding paradigm to improve compositional generalization ability of neural encoder-decoder architectures for natural language understanding. Poset structure is important in not only natural language understanding, but also many other areas such as chemistry (e.g., molecular structure), computer vision (e.g., scene graph) and software engineering (e.g., software dependencies). Our work explores to better predict poset structures, thus it may have implicit positive impact to these areas. Compositional generalization is a fundamental property of human intelligence, and it is essential to equip machine learning systems with this ability. This could lead to positive societal implications: (1) it could help machine learning systems to avoid being affected by biases during training data collection process; (2) it could help machine learning systems reduce their reliance on massive amounts data, thus improving intelligence while saving resources. In this paper, we focus on a natural language question answering task. We consider that there will not be certain societal consequences nor ethical aspects in the near future.",Broader Impact,168,7,,,FALSE,FALSE,FALSE,Hierarchical Poset Decoding for Compositional Generalization in Language,Algorithms -> Structured Prediction,Applications -> Natural Language Processing; Deep Learning -> Predictive Models; Neuroscience and Cognitive Science -> Language for Cognitive Science,Natural language processing,"['Yinuo Guo', ' Zeqi Lin', 'Guang Lou', ' Dongmei Zhang']","{'Microsoft', 'Microsoft Research', 'Peking University'}",1,1,1,"{'USA', 'China'}"
Evaluating and Rewarding Teamwork Using Cooperative Game Abstractions,"Tom Yan, Christian Kroer, Alexander Peysakhovich",Evaluating and Rewarding Teamwork Using Cooperative Game Abstractions,4d95d05a4fc4eadbc3b9dde67afdca39,https://proceedings.neurips.cc/paper/2020/file/4d95d05a4fc4eadbc3b9dde67afdca39-Paper.pdf,"In this work, we introduce and analyze a general model for team strength and player value. While our end goal is to ensure accurate assessment of team strength, and as a result fair distribution of team value, there is the risk of model misspecification and resultant bias in the estimators. Furthermore, often times the team performance data we see is observational and the data we observe may be biased due to individuals being of disparate background. Indeed, accounting for such confounding factors is an important extension to our work that we would like to highlight.",8 Broader Impact,95,4,,,FALSE,FALSE,FALSE,Evaluating and Rewarding Teamwork Using Cooperative Game Abstractions,Theory -> Game Theory and Computational Economics,Applications -> Game Playing,Game Theory,"['Tom Yan', ' Christian Kroer', ' Alexander Peysakhovich']","{'Facebook', 'Columbia University', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Exchangeable Neural ODE for Set Modeling,"Yang Li, Haidong Yi, Christopher Bender, Siyuan Shan, Junier B. Oliva",Exchangeable Neural ODE for Set Modeling,4db73860ecb5533b5a6c710341d5bbec,https://proceedings.neurips.cc/paper/2020/file/4db73860ecb5533b5a6c710341d5bbec-Paper.pdf,"Making assessment over sets instead of instances gives us opportunity to leverage the dependencies over set elements. However, like any other models, it might unintentionally exploit the bias within the dataset. With this known issue, we encourage practitioners to carefully design the training set or utilize other debiasing techniques. In this work, we evaluate on point clouds of shape objects, which should not pose detrimental societal impact even if the learned dependencies does not re fl ect the actual ones. Set generative models have the ability to generate fake data, which may incur ethical or legal issues when used improperly. There is urgent need to establish regulations and techniques to avoid misuse of the generated data.",Broader Impact,116,6,,,FALSE,FALSE,FALSE,Exchangeable Neural ODE for Set Modeling,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Algorithms -> Dynamical Systems,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yang Li', ' Haidong Yi', ' Christopher Bender', ' Siyuan Shan', ' Junier Oliva']","{'UNC-Chapel Hill', 'UNC Chapel Hill', 'The University of North Carolina', 'UNC - Chapel Hill', 'Department of Computer Science, UNC Chapel-Hill'}",1,0,0,"{'Canada', 'USA'}"
Profile Entropy: A Fundamental Measure for the Learnability and Compressibility of Distributions,"Yi Hao, Alon Orlitsky",Profile Entropy: A Fundamental Measure for the Learnability and Compressibility of Distributions,4dbf29d90d5780cab50897fb955e4373,https://proceedings.neurips.cc/paper/2020/file/4dbf29d90d5780cab50897fb955e4373-Paper.pdf,"Classical information theory states that an i.i.d. sample contains H ( X n ∼ p ) = nH ( p ) information, which provides little insight for statistical applications. We present a different view by decomposing the sample information into three parts: the labeling of the profile elements, ordering of them, and profile entropy. With no bias towards any symbols, the profile entropy rises as a fundamental measure unifying the concepts of estimation, inference, and compression. We believe this view could help researchers in information theory, statistical learning theory, and computer science communities better understand the information composition of i.i.d. samples over discrete domains. The results established in this work are general and fundamental, and have numerous applications in privacy, economics, data storage, supervised learning, etc. A potential downside is that the theoretical  guarantees of the associated algorithms rely on the assumption correctness, e.g., the domain should be discrete and the sampling process should be i.i.d. . In other words, it will be better if users can confirm these assumptions by prior knowledge, experiences, or statistical testing procedures. Taking a different perspective, we think a potential research direction following this work is to extend these results to Markovian models, making them more robust to model misspecification.",Broader Impact,206,8,,,FALSE,TRUE,FALSE,Profile Entropy: A Fundamental Measure for the Learnability and Compressibility of Distributions,Theory -> Statistical Learning Theory,Theory -> Computational Learning Theory; Theory -> High-Dimensional Inference; Theory -> Information Theory,Theory (including computational and statistical analyses),"['Yi Hao', ' Alon Orlitsky']","{'University of California, San Diego'}",1,0,0,{'USA'}
CoADNet: Collaborative Aggregation-and-Distribution Networks for Co-Salient Object Detection,"Qijian Zhang, Runmin Cong, Junhui Hou, Chongyi Li, Yao Zhao",CoADNet: Collaborative Aggregation-and-Distribution Networks for Co-Salient Object Detection,4dc3ed26a29c9c3df3ec373524377a5b,https://proceedings.neurips.cc/paper/2020/file/4dc3ed26a29c9c3df3ec373524377a5b-Paper.pdf,This work aims at general theoretical issues for the co-salient object detection problem and does not present any foreseeable societal consequence.,Broader Impact,21,1,TRUE,FALSE,FALSE,FALSE,FALSE,CoADNet: Collaborative Aggregation-and-Distribution Networks for Co-Salient Object Detection,Applications,Applications -> Computer Vision; Deep Learning; Deep Learning -> CNN Architectures,Vision,"['Qijian Zhang', ' Runmin Cong', ' Junhui Hou', ' Chongyi Li', ' Yao Zhao']","{'City University of Hong Kong', ' Nanyang Technological University', 'City University of Hong Kong, Hong Kong', 'Beijing Jiaotong University'}",1,0,0,"{'Singapore', 'China'}"
"Regularized linear autoencoders recover the principal components, eventually","Xuchan Bao, James Lucas, Sushant Sachdeva, Roger B. Grosse","Regularized linear autoencoders recover the principal components, eventually",4dd9cec1c21bc54eecb53786a2c5fa09,https://proceedings.neurips.cc/paper/2020/file/4dd9cec1c21bc54eecb53786a2c5fa09-Paper.pdf,The contribution of this work is the theoretical understanding of learning the optimal representations in LAEs with gradient-based optimizers. We believe that the discussion of broader impact is not applicable to this work.,Broader Impact,33,2,TRUE,FALSE,FALSE,FALSE,FALSE,"Regularized linear autoencoders recover the principal components, eventually",Deep Learning -> Deep Autoencoders,Algorithms -> Unsupervised Learning; Deep Learning -> Optimization for Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Xuchan Bao', ' James Lucas', ' Sushant Sachdeva', ' Roger Grosse']",{'University of Toronto'},1,0,0,{'Canada'}
Semi-Supervised Partial Label Learning via Confidence-Rated Margin Maximization,"Wei Wang, Min-Ling Zhang",Semi-Supervised Partial Label Learning via Confidence-Rated Margin Maximization,4dea382d82666332fb564f2e711cbc71,https://proceedings.neurips.cc/paper/2020/file/4dea382d82666332fb564f2e711cbc71-Paper.pdf,"In this paper, we study the problem of semi-supervised partial label learning which has been less investigated in weakly supervised learning. The developed techniques can be applied to scenarios where the supervision information collected from the environment is accurate. For ethical use of the proposed approach, one should expect proper acquisition of the candidate labeling information (e.g. crowdsourcing) as well as the unlabeled data. We believe that developing such techniques is important to meet the increasing needs of learning from weak supervision in many real-world applications.",Broader Impact,86,4,,,FALSE,FALSE,FALSE,Semi-Supervised Partial Label Learning via Confidence-Rated Margin Maximization,Algorithms -> Classification,Algorithms -> Large Margin Methods; Algorithms -> Semi-Supervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Wei Wang', 'Ling Zhang']",{'Southeast University'},1,0,0,{'China'}
GramGAN: Deep 3D Texture Synthesis From 2D Exemplars,"Tiziano Portenier, Siavash Arjomand Bigdeli, Orcun Goksel",GramGAN: Deep 3D Texture Synthesis From 2D Exemplars,4df5bde009073d3ef60da64d736724d6,https://proceedings.neurips.cc/paper/2020/file/4df5bde009073d3ef60da64d736724d6-Paper.pdf,"We present a novel framework for 3D texture synthesis that has broad applicability in computer graphics. It can be used to generate 3D and 2D textures, for instance in image manipulation, movie production, or game design. While it may be feasible to use dedicated models for each texture in  game design or movie production where a limited set of textures is used for each movie or video game, our conditional framework has the potential to greatly reduce artist work load. Our model has also great potential in medicine, for instance when training surgeons using virtual reality simulators. Content creation for such simulators, especially modeling different tissue materials, could benefit from our system. Besides generating realistic textures, our model would allow for the synthesis of animated textures or animated imagery by introducing an additional time dimension.",Broader Impact,135,6,,,FALSE,FALSE,FALSE,GramGAN: Deep 3D Texture Synthesis From 2D Exemplars,Deep Learning -> Adversarial Networks,Algorithms -> Semi-Supervised Learning; Applications -> Computer Vision; Applications -> Signal Processing; Deep Learning -> Generative Models,Deep learning,"['Tiziano Portenier', ' Siavash Arjomand Bigdeli', ' Orcun Goksel']","{'ETH Zurich', 'CSEM'}",1,0,0,{'Switzerland'}
UWSOD: Toward Fully-Supervised-Level Capacity Weakly Supervised Object Detection,"Yunhang Shen, Rongrong Ji, Zhiwei Chen, Yongjian Wu, Feiyue Huang",UWSOD: Toward Fully-Supervised-Level Capacity Weakly Supervised Object Detection,4e0928de075538c593fbdabb0c5ef2c3,https://proceedings.neurips.cc/paper/2020/file/4e0928de075538c593fbdabb0c5ef2c3-Paper.pdf,"WSOD aims at leveraging weakly supervised learning to train object detectors, which significantly reduces the human labelling effort. Therefore, WSOD has the potential of handling thousands of real-world categories and taking advantage of large-scale weak annotations. In this work, we develop a unified high-capacity generic object detector with image-level labels, termed UWSOD, and exploit three important components, i.e. , object proposal generation, bounding-box fine-tuning and scale-invariant features, all of which are rarely touched in WSOD before. Our method has both practical and methodological contributions to facilitate the development of this area. • For the academia, the superior capacity of our method demonstrates that WSOD has potential to achieve competitive results compared to FSOD. • For the industry, the proposed UWSOD method enables to utilize the image-level annotations cheaply available on the Internet to learn detectors. • For the community, we hope to give new insight into other tasks under weak supervision to achieve promising performance.",Broader Impact,155,7,,,FALSE,FALSE,FALSE,UWSOD: Toward Fully-Supervised-Level Capacity Weakly Supervised Object Detection,Applications -> Object Detection,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yunhang Shen', ' Rongrong Ji', ' Zhiwei Chen', ' Yongjian Wu', 'Tencent Technology', ' Feiyue Huang']","{'Tencent', 'Shanghai', 'Xiamen University, China', 'Xiamen University'}",1,1,1,{'China'}
Learning Restricted Boltzmann Machines with Sparse Latent Variables,"Guy Bresler, Rares-Darius Buhai",Learning Restricted Boltzmann Machines with Sparse Latent Variables,4e668929edb3bf915e1a3a9d96c3c97e,https://proceedings.neurips.cc/paper/2020/file/4e668929edb3bf915e1a3a9d96c3c97e-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Learning Restricted Boltzmann Machines with Sparse Latent Variables,Theory -> Computational Learning Theory,Algorithms -> Model Selection and Structure Learning; Algorithms -> Unsupervised Learning; Probabilistic Methods -> Graphical Models; Probabilistic Methods -> Latent Variable Models; Theory -> High-Dimensional Inference,Theory (including computational and statistical analyses),"['Guy Bresler', 'Darius Buhai']","{'ETH Zurich', 'MIT'}",1,0,0,"{'USA', 'Switzerland'}"
Sample Complexity of Asynchronous Q-Learning: Sharper Analysis and Variance Reduction,"Gen Li, Yuting Wei, Yuejie Chi, Yuantao Gu, Yuxin Chen",Sample Complexity of Asynchronous Q-Learning: Sharper Analysis and Variance Reduction,4eab60e55fe4c7dd567a0be28016bff3,https://proceedings.neurips.cc/paper/2020/file/4eab60e55fe4c7dd567a0be28016bff3-Paper.pdf,This work is a theoretical contribution to characterize the sample complexity of asynchronous Q-learning. The insights from the proposed algorithm can potentially be leveraged in various reinforcement learning tasks in the future.,Broader Impact,32,2,FALSE,FALSE,FALSE,FALSE,FALSE,Sample Complexity of Asynchronous Q-Learning: Sharper Analysis and Variance Reduction,Reinforcement Learning and Planning,Optimization -> Stochastic Optimization; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> High-Dimensional Inference; Theory -> Statistical Learning Theory,Reinforcement learning and planning,"['Gen Li', ' Yuting Wei', ' Yuejie Chi', ' Yuantao Gu', ' Yuxin Chen']","{'Princeton University', 'CMU', 'Tsinghua University', 'Carnegie Mellon University'}",1,0,0,"{'USA', 'China'}"
Curriculum learning for multilevel budgeted combinatorial problems,"Adel Nabli, Margarida Carvalho",Curriculum learning for multilevel budgeted combinatorial problems,4eb7d41ae6005f60fe401e56277ebd4e,https://proceedings.neurips.cc/paper/2020/file/4eb7d41ae6005f60fe401e56277ebd4e-Paper.pdf,"We propose a general framework for training agents to tackle a class of Multilevel Budgeted Combinatorial problems. Such models are widely used in Economics and Operations Research. In this study, we particularly focused on the Multilevel Critical Node problem (MCN). Regarding the usefulness of such problem for practical scenarios, the MCN could fit on several applications, e.g. to limit the fake news spread in social networks or in cyber security for the protection of a botnet against malware injections [1]. Thus, this could represent a step towards the design of more robust networks, but could also be used to identify their critical weaknesses for malicious agents. We do not anticipate that our work will advantage or disadvantage any particular group.",Broader Impact,120,6,,,FALSE,FALSE,FALSE,Curriculum learning for multilevel budgeted combinatorial problems,Optimization -> Discrete Optimization,Reinforcement Learning and Planning -> Multi-Agent RL; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> Game Theory and Computational Economics,Optimization Methods (continuous or discrete),"['Adel Nabli', ' Margarida Carvalho']",{'Université de Montréal'},1,0,0,{'Canada'}
FedSplit: an algorithmic framework for fast federated optimization,"Reese Pathak, Martin J. Wainwright",FedSplit : an algorithmic framework for fast federated optimization,4ebd440d99504722d80de606ea8507da,https://proceedings.neurips.cc/paper/2020/file/4ebd440d99504722d80de606ea8507da-Paper.pdf,"As mentioned in the introduction, a main application of federated optimization is to large-scale statistical learning, as carried out by application developers and cell phone manufacturers. On the other hand, learning from federated data is also inherent to other settings where data is not stored centrally: consider, for example, collecting clinical trial data across multiple hospitals and running a centralized analysis. Therefore, we envision analysts who are operating in these settings—where data is not available centrally due to communication barriers or privacy constraints—as main benefactors of this work. Our methods enjoy the same trade-offs with respect to biases in data, failures of systems, as other standard first-order algorithms. We believe that having convergent algorithms in this federated setting should help promote good practices with regard to analyzing large-scale, federated, and sensitive datasets.",Broader Impact,132,5,,,FALSE,FALSE,FALSE,FedSplit: an algorithmic framework for fast federated optimization,Optimization -> Convex Optimization,,Optimization Methods (continuous or discrete),"['Reese Pathak', ' Martin Wainwright']","{'UC Berkeley', 'University of California, Berkeley'}",1,0,0,{'USA'}
Estimation and Imputation in Probabilistic Principal Component Analysis with Missing Not At Random Data,"Aude Sportisse, Claire Boyer, Julie Josses",Estimation and imputation in Probabilistic Principal Component Analysis with Missing Not At Random data,4ecb679fd35dcfd0f0894c399590be1a,https://proceedings.neurips.cc/paper/2020/file/4ecb679fd35dcfd0f0894c399590be1a-Paper.pdf,"Our goal is to provide a rigorous and consistent method for processing MNAR missing values, in data with an underlying low-rank structure. The low-rank assumption has become widespread in applications in recent years and it plays a key modeling role in many scientific and engineering tasks, such as collaborative filtering, genome-wide studies, or even functional magnetic resonance imaging. The problem of missing data is particularly evident for large data, possibly aggregated from multiple sources, that is why we illustrate this work on a real dataset such as the medical register TraumaBase, coming from different hospitals. Managing informative missing data is a double challenge: on the one hand, because most of the available data contains missing values, preventing the use of standard machine learning techniques; and on the other hand, because the MNAR data can introduce large bias in the statistical analysis of databases. Because of the PPCA hypothesis and the processing of informative missing data, this work has a wide range of applications.",Broader impact,163,5,,,FALSE,FALSE,FALSE,Estimation and Imputation in Probabilistic Principal Component Analysis with Missing Not At Random Data,Algorithms -> Missing Data,Probabilistic Methods -> Graphical Models; Probabilistic Methods -> Latent Variable Models,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Aude Sportisse', ' Claire Boyer', ' Julie Josses']","{'LPSM, Sorbonne Université', 'Sorbonne University, Ecole Polytechnique', 'CMAP / CNRS'}",1,1,1,"{'France', 'Switzerland'}"
Correlation Robust Influence Maximization,"Louis Chen, Divya Padmanabhan, Chee Chin Lim, Karthik Natarajan",Correlation Robust Influence Maximization,4ee78d4122ef8503fe01cdad3e9ea4ee,https://proceedings.neurips.cc/paper/2020/file/4ee78d4122ef8503fe01cdad3e9ea4ee-Paper.pdf,"The aim of this work is to address the possible pitfalls to the independence assumption in a social network, as used in the study of influence maximization. As discussed previously, how an idea, product, or piece of news makes its way through a network could very well be impacted by natural social biases, thus connecting parts of a social network in ways that could have been unforeseen. The methodology presented thus attempts to make this possibility a consideration during the selection of seed set, and hence find “influential"" members to a network regardless of whatever underlying correlations may exist. This potentially can reduce the impact of biases that the independence assumption may cause.",Broader Impact,113,4,,,FALSE,FALSE,FALSE,Correlation Robust Influence Maximization,Optimization,Applications -> Network Analysis; Optimization -> Discrete Optimization; Optimization -> Submodular Optimization,"Influence Maximization, DRO","['Louis Chen', ' Divya Padmanabhan', ' Chee Chin Lim', ' Karthik Natarajan']","{'Singapore University of Technology and Design', 'Naval Postgraduate School'}",1,0,0,"{'Singapore', 'USA'}"
Neuronal Gaussian Process Regression,Johannes Friedrich,Neuronal Gaussian Process Regression,4ef2f8259495563cb3a8ea4449ec4f9f,https://proceedings.neurips.cc/paper/2020/file/4ef2f8259495563cb3a8ea4449ec4f9f-Paper.pdf,"This paper introduces a biologically plausible implementation of Gaussian processes. It bridges the fields of machine learning and neuroscience with potential impact in both fields. With regard to machine learning this paper shows a correspondence between Gaussian processes and certain neural networks (of finite size) and raises the question of how best to perform nonlinear regression with uncertainty estimates. Should one use Gaussian processes, neural networks, or a combination of both – such as the presented Gaussian process initialized neural networks? With regard to neuroscience the paper introduces a biologically plausible Gaussian process approximation with good predictive performance and close approximation of the full Gaussian process, compared to VFE and FITC. It yields initial results in line with existing experimental data and motivates new experiments for a more direct test of the model. Ethical aspects and future societal consequences do not apply to this work.",Broader Impact,145,7,,,FALSE,FALSE,FALSE,Neuronal Gaussian Process Regression,Neuroscience and Cognitive Science,Algorithms -> Online Learning; Algorithms -> Regression; Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Plasticity and Adaptation; Probabilistic Methods -> Gaussian Processes,Neuroscience and cognitive science,['Johannes Friedrich'],{'Flatiron Institute'},1,0,0,{'USA'}
Nonconvex Sparse Graph Learning under Laplacian Constrained Graphical Model,"Jiaxi Ying, José Vinícius de Miranda Cardoso , Daniel Palomar",Nonconvex Sparse Graph Learning under Laplacian Constrained Graphical Model,4ef42b32bccc9485b10b8183507e5d82,https://proceedings.neurips.cc/paper/2020/file/4ef42b32bccc9485b10b8183507e5d82-Paper.pdf,"This paper provides an unexpected behavior of the 1 norm in learning sparse graphs, which may greatly benefit the community of signal processing and machine learning over graphs. This paper further provides a solution to solve the issue with theoretical guarantees.",Broader Impact,41,2,FALSE,FALSE,FALSE,FALSE,FALSE,Nonconvex Sparse Graph Learning under Laplacian Constrained Graphical Model,Optimization,Algorithms -> Sparsity and Compressed Sensing; Algorithms -> Unsupervised Learning; Applications -> Signal Processing; Probabilistic Methods -> Graphical Models,Optimization Methods (continuous or discrete),"['Jiaxi Ying', ' José Vinícius de Miranda Cardoso', ' Daniel Palomar']","{'HKUST', 'The Hong Kong University of Science and Technology'}",1,0,0,"{'Chile', 'China'}"
Synthetic Data Generators -- Sequential and Private,"Olivier Bousquet, Roi Livni, Shay Moran",Synthetic Data Generators – Sequential and Private,4eff0720836a198b6174eecf02cbfdbf,https://proceedings.neurips.cc/paper/2020/file/4eff0720836a198b6174eecf02cbfdbf-Paper.pdf,There are no foreseen ethical or societal consequences for the research presented herein.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Synthetic Data Generators -- Sequential and Private,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Theory; Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Olivier Bousquet', 'Google Brain', ' Roi Livni', ' Shay Moran']","{'Google AI Princeton', 'Zurich', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
Uncertainty Quantification for Inferring Hawkes Networks,"Haoyun Wang, Liyan Xie, Alex Cuozzo, Simon Mak, Yao Xie",Uncertainty Quantification for Inferring Hawkes Networks,4f00921114932db3f8662a41b44ee68f,https://proceedings.neurips.cc/paper/2020/file/4f00921114932db3f8662a41b44ee68f-Paper.pdf,"Our method can be useful for many applications involving Hawkes processes, including seismology, social networks, neuroscience and more. In particular, it is useful for performing causal inference and making statistically significant claims. Recent developments in neuroscience and engineering have allowed researchers to simultaneously record precise spiking data from large numbers of biological neurons. A key challenge is harnessing this experimental data to learn the underlying connectivity of biological neural networks, which is integral for understanding the functions of such networks. We show how the proposed model can be used to both learn this connectivity information and quantify uncertainty from observed neural spike data.",Broader Impact,103,5,,,FALSE,FALSE,FALSE,Uncertainty Quantification for Inferring Hawkes Networks,Algorithms -> Uncertainty Estimation,Theory -> Frequentist Statistics; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Haoyun Wang', ' Liyan Xie', ' Alex Cuozzo', ' Simon Mak', ' Yao Xie']","{'Georgia Tech', 'Georgia Institute of Technology', 'Duke University'}",1,0,0,{'USA'}
Implicit Distributional Reinforcement Learning,"Yuguang Yue, Zhendong Wang, Mingyuan Zhou",Implicit Distributional Reinforcement Learning,4f20f7f5d2e7a1b640ebc8244428558c,https://proceedings.neurips.cc/paper/2020/file/4f20f7f5d2e7a1b640ebc8244428558c-Paper.pdf,"This work proposes a high sample-efficient algorithm to solve challenging continuous control reinforcement learning (RL) problems. RL could be applied to a wide range of applications, including resources management (Mao et al., 2016), traffic light control (Arel et al., 2010), optimizing chemistry reactions (Zhou et al., 2017), to name a few. Under the RL framework, sample efficiency is one of the top concerns for practicality, because the interactions between the agent and environment in reality is costly and the algorithm will be impractical if the number of interactions is demanding. Though there have been successfully cases of implementing RL algorithms to solve real-life problems, most of them need to be simulatable in nature to meet the demand of enough samples. Fortunately, lots of great works have focused on overcoming this challenge, and significant improvement has been made. Ever since the birth of Q -learning algorithm in 1992 (Watkins and Dayan, 1992), the functionality of RL algorithms has grow rapidly. When Q -learning is first proposed, it can only be applied to toy examples such as “route finding” problems, and now it can even be applied to play Go (David et al., 2017) and defeat top human players. Moreover, with the help of deep learning, RL algorithms have shown promising performances on complicated computer games such as Dota (OpenAI, 2018) and StarCraft (Vinyals et al., 2019). All this accomplishments cannot be achieved without the consecutive effort put on improving the sample efficiency. In our new algorithm IDAC, we incorporate the advanced distributional idea with the off-policy stochastic policy setting, and obtain notable improvement over a number of state-of-the-art algorithms. This result is very promising and has huge potential to be applied or further improved to facilitate RL algorithm being implemented in more complicated real-life tasks such as self-driving cars and automation. However, such implementations need taking special care because it involves human beings, and the risk sensitivity is not part of the research of our work. We encourage further research taking risk into account so that it can be combined with IDAC to be applicable to a broader range of settings.",Broader Impact,350,13,,,FALSE,FALSE,FALSE,Implicit Distributional Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Deep Learning; Probabilistic Methods,Reinforcement learning and planning,"['Yuguang Yue', ' Zhendong Wang', ' Mingyuan Zhou']","{'University of Texas, Austin', 'University of Texas at Austin'}",1,0,0,{'USA'}
Auxiliary Task Reweighting for Minimum-data Learning,"Baifeng Shi, Judy Hoffman, Kate Saenko, Trevor Darrell, Huijuan Xu",Auxiliary Task Reweighting for Minimum-data Learning,4f87658ef0de194413056248a00ce009,https://proceedings.neurips.cc/paper/2020/file/4f87658ef0de194413056248a00ce009-Paper.pdf,"In this work we focus on solving the data scarcity problem of a main task using auxiliary tasks, and propose an algorithm to automatically reweight auxiliary tasks so that the data requirement on the main task is minimized. On the bright side, this could impact the industry and society from two  aspects. First, this may promote the landing of machine learning algorithms where labeled data is scarce or even unavailable, which is common in the real world. Second, our method can save the time and power resources wasted for manually tuning the auxiliary task weights with multiple runs, which is crucial in an era of environmental protection. However, our method may lead to negative consequences if it is not used right. For example, our method may be utilized to extract information from a private dataset or system with less data under the assistance of other auxiliary tasks. Besides, our method may still fail in some situations where the auxiliary tasks are strong regularization of the main task, which may not allow the use in applications where high precision and robustness are imperative.",Broader Impact,182,7,,,FALSE,FALSE,FALSE,Auxiliary Task Reweighting for Minimum-data Learning,Algorithms -> Multitask and Transfer Learning,Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Baifeng Shi', ' Judy Hoffman', ' Kate Saenko', ' Trevor Darrell', ' Huijuan Xu']","{'Peking University', 'University of California, Berkeley', 'UC Berkeley', 'Georgia Institute of Technology', 'Boston University'}",1,0,0,"{'USA', 'China'}"
Small Nash Equilibrium Certificates in Very Large Games,"Brian Zhang, Tuomas Sandholm",Small Nash Equilibrium Certificates in Very Large Games,4fbe073f17f161810fdf3dab1307b30f,https://proceedings.neurips.cc/paper/2020/file/4fbe073f17f161810fdf3dab1307b30f-Paper.pdf,"The techniques have broad applicability. Furthermore, the paper opens up additional important research directions. Improving the strategic capabilities of people and companies will typically (but not always) improve systemwide good as the players will be able to better reach win-win solutions. In zero-sum games this is not the case because the size of the “cake” is constant, so there are winners and losers. In both the general case and the zero-sum case, AI tools like the ones in this paper can help elevate less educated and less experienced players up to the same level as expert players, thereby making the distribution of value more fair. A potential downside is that if the technology were only available to the privileged, that could increase unfairness.",Broader Impacts,123,6,,,FALSE,FALSE,FALSE,Small Nash Equilibrium Certificates in Very Large Games,Theory -> Game Theory and Computational Economics,,Reinforcement learning and planning,"['Brian Zhang', ' Tuomas Sandholm']","{'Stanford University', 'CMU, Strategic Machine, Strategy Robot, Optimized Markets'}",1,1,1,{'USA'}
Training Linear Finite-State Machines,"Arash Ardakani, Amir Ardakani, Warren Gross",Training Linear Finite-State Machines,4fc28b7093b135c21c7183ac07e928a6,https://proceedings.neurips.cc/paper/2020/file/4fc28b7093b135c21c7183ac07e928a6-Paper.pdf,"Training deep learning models is both financially and environmentally an expensive process. From the environmental point view, it is estimated that the carbon footprint required for developing and training a single deep learning model (e.g., stacked LSTMs) can create 284 tonnes of carbon dioxide, which is equivalent to the lifetime CO2 emissions of five average cars [34]. The environmental impact of training deep learning models is calculated by the total power required to train each model multiplied by the training time spent for its development. On the other hand, the financial impact of training deep learning models is associated to the cost of hardware (e.g., cloud-based platforms, GPUs) and electricity. As a result, using computationally efficient algorithms as well as energy efficient hardware is of paramount importance to reduce both environmental and financial impacts of deep learning [34]. The first part of this paper focuses on complexity reduction of the inference computations where FSM- based networks are presented. FSM-based networks use SC to perform the inference computations on bit streams. As discussed in Section 2, SC offers ultra-low power implementations that can significantly reduce the cost of specialized hardware for the inference computations. As a result, our FSM-based networks have positive environmental and financial impacts by saving electricity and CO2 emissions. In the last part of the paper, we introduced FSM-based models that can learn extremely long data dependencies while significantly reducing the number of operations and the storage required for training. It is worth mentioning that power consumption of deep learning models are dominated by their memory accesses to the main memory of hardware platforms such as GPUs. To show the impact of our FSM-based model during training, we measured its power consumption when performing the CLLM task on the Penn Treebank corpus. An FSM-based model of size 1000 (d h = 1000) draws 160 W for the step size of 2000 on the GeForce GTX 1080 Ti whereas an LSTM model of the same size requires 245 W on average. Moreover, our FSM-based model converges faster than the LSTM model by at least a factor of 2 × (see Figure 4), significantly reducing the training time. Given the power and the training time reductions that our FSM-based model offers, CO2 emissions are reduced by at least a factor of 3 × for the given example. Therefore, our FSM-based models contribute remarkably in reduction of carbon dioxide emissions and have positive impacts on the climate change.",Broader Impact,407,16,,,TRUE,TRUE,FALSE,Training Linear Finite-State Machines,Deep Learning,Applications; Applications -> Hardware and Systems; Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,Deep learning,"['Arash Ardakani', ' Amir Ardakani', ' Warren Gross']",{'McGill University'},1,0,0,{'Canada'}
Efficient active learning of sparse halfspaces with arbitrary bounded noise,"Chicheng Zhang, Jie Shen, Pranjal Awasthi",Efficient active learning of sparse halfspaces with arbitrary bounded noise,5034a5d62f91942d2a7aeaf527dfe111,https://proceedings.neurips.cc/paper/2020/file/5034a5d62f91942d2a7aeaf527dfe111-Paper.pdf,"This paper investigates a fundamental problem in machine learning and statistics. The theory and algorithms presented in this paper are expected to benefit many broad fields in science and engineering, such as learning theory, robust statistics, optimization, and applications in biology, climatology, and seismology, to name a few. Our research belongs to the general paradigm of interactive learning, in which the learning agent need to design adaptive sampling schemes to maximize data efficiency. We are well aware that one needs to be careful in designing such sampling schemes, to avoid unintended harms such as discrimination.",Broader Impact,95,4,,,FALSE,FALSE,FALSE,Efficient active learning of sparse halfspaces with arbitrary bounded noise,Theory -> Computational Learning Theory,Algorithms -> Active Learning; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Chicheng Zhang', ' Jie Shen', ' Pranjal Awasthi']","{'Stevens Institute of Technology', 'Rutgers University/Google', 'University of Arizona'}",1,1,1,{'USA'}
Swapping Autoencoder for Deep Image Manipulation,"Taesung Park, Jun-Yan Zhu, Oliver Wang, Jingwan Lu, Eli Shechtman, Alexei Efros, Richard Zhang",Swapping Autoencoder for Deep Image Manipulation,50905d7b2216bfeccb5b41016357176b,https://proceedings.neurips.cc/paper/2020/file/50905d7b2216bfeccb5b41016357176b-Paper.pdf,"From the sculptor’s chisel to the painter’s brush, tools for creative expression are an important part of human culture. The advent of digital photography and professional editing tools, such as Adobe Photoshop, has allowed artists to push creative boundaries. However, the existing tools are typically too complicated to be useful by the general public. Our work is one of the new generation of visual content creation methods that aim to democratize the creative process. The goal is to provide intuitive controls (see Section 4.6) for making a wider range of realistic visual effects available to non-experts. While the goal of this work is to support artistic and creative applications, the potential misuse of such technology for purposes of deception – posing generated images as real photographs – is quite concern- ing. To partially mitigate this concern, we can use the advances in the field of image forensics [16], as a way of verifying the authenticity of a given image. In particular, Wang et al. [72] recently showed that a classifier trained to classify between real photographs and synthetic images generated by ProGAN [42], was able to detect fakes produced by other generators, among them, StyleGAN [43] and Style- GAN2 [44]. We take a pretrained model of [72] and report the detection rates on several datasets in Appendix ?? . Our swap-generated images can be detected with an average rate greater than 90%, and this in- dicates that our method shares enough architectural components with previous methods to be detectable. However, these detection methods do not work at 100 % , and performance can degrade as the images are degraded in the wild (e.g., compressed, rescanned) or via adversarial attacks. Therefore, the problem of verifying image provenance remains a significant challenge to society that requires multiple layers of solutions, from technical (such as learning-based detection systems or authenticity certification chains), to social, such as efforts to increase public awareness of the problem, to regulatory and legislative.",Broader Impact,325,14,,,FALSE,TRUE,FALSE,Swapping Autoencoder for Deep Image Manipulation,Applications -> Computational Photography,Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models,Vision,"['Taesung Park', 'Yan Zhu', ' Oliver Wang', ' Jingwan Lu', ' Eli Shechtman', ' Alexei Efros', ' Richard Zhang']","{'Adobe', 'UC Berkeley', 'Adobe Research', 'Adobe Research, US', 'Adobe, CMU'}",1,1,1,{'USA'}
Self-Supervised Few-Shot Learning on Point Clouds,"Charu Sharma, Manohar Kaul",Self-Supervised Few-Shot Learning on Point Clouds,50c1f44e426560f3f2cdcb3e19e39903,https://proceedings.neurips.cc/paper/2020/file/50c1f44e426560f3f2cdcb3e19e39903-Paper.pdf,"This study deals with self-supervised learning that improves sample complexity of point clouds which in turn aids better learning in a few-shot learning (FSL) setup; allowing for learning on very limited labeled point cloud examples. Such a concept has far reaching positive consequences in industry and academia. For example, self-driving vehicles would now be able to train faster with scarcer point cloud samples for fewer objects and still detect or localize objects in 3D space efficiently, thus avoiding accidents caused by rare unseen events. Our method can also positively impact shape-based recognition like segmentation (semantically tagging the objects) for cities with limited number of samples for training, which can then be useful for numerous applications such as city planning, virtual tourism, and cultural heritage documentation, to name a few. Similar benefits can be imagined in the biomedical domain where training with our method might help identify and learn from rare organ disorders, when organs are represented as 3D point clouds. Our study has the potential to adversely impact people employed via crowd-sourcing sites like Amazon Mechanical Turk (MTurk), who manually review and annotate data.",Broader Impact,184,6,,,FALSE,FALSE,FALSE,Self-Supervised Few-Shot Learning on Point Clouds,Applications -> Computer Vision,Algorithms -> Few-Shot Learning; Algorithms -> Representation Learning,,"['Charu Sharma', ' Manohar Kaul']","{'Indian Institute of Technology Hyderabad', 'IITH'}",1,0,0,{'India'}
Faster Differentially Private Samplers via Rényi Divergence Analysis of Discretized Langevin MCMC,"Arun Ganesh, Kunal Talwar",Faster Differentially Private Samplers via Rényi Divergence Analysis of Discretized Langevin MCMC,50cf0fe63e0ff857e1c9d01d827267ca,https://proceedings.neurips.cc/paper/2020/file/50cf0fe63e0ff857e1c9d01d827267ca-Paper.pdf,"This work gives faster algorithms for a class of differentially private algorithms. The use of differentially private algorithms has in many cases such as the US Census Bureau, allowed release of useful aggregate statistics while protecting privacy of individual respondents. In some cases, differentially private algorithms may have lower utility compared to those which do not enjoy provable privacy,  which may otherwise be used. Differentially private algorithms give a way to quantify privacy loss and can help decision makers choose an appropriate points on the Pareto curve. Works such as ours will (over time) enable better privacy-utility trade-offs amongst computationally efficient algorithms and thus push the Pareto curve.",Broader Impact,108,5,,,FALSE,FALSE,FALSE,Faster Differentially Private Samplers via Rényi Divergence Analysis of Discretized Langevin MCMC,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Probabilistic Methods -> MCMC,,"['Arun Ganesh', ' Kunal Talwar']","{'Google', 'University of California Berkeley'}",1,1,1,{'USA'}
Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE,"Ding Zhou, Xue-Xin Wei",Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE,510f2318f324cf07fce24c3a4b89c771,https://proceedings.neurips.cc/paper/2020/file/510f2318f324cf07fce24c3a4b89c771-Paper.pdf,"In this paper, we develop a new analysis method for analyzing neural population data. This method can be used to extract and identify the underlying critical structure underlying the neural activity recorded simultaneously from many neurons in the brain. It can also be used to construct improved response models of how various kinds of task variables are encoded in the brain. Our approach is of broad applicability to the neural population recording under a variety of scenarios. It may also inspire future work in neural data analysis. Progress in this area will facilitate both basic science research about the brain as well as clinical applications, such as invasive and non-invasive brain-machine interfaces. Our method is developed based on recent advances in a class of deep generative models, i.e., identifiable variational auto-encoder. It may be of interest to the machine learning community working on deep generative models. Our research extends previous works on identifiable variational auto-encoder to a different setup. Our preliminary promising results may provide useful insights into the further development of more identifiable deep generative models, which in the longer term may help establish more interpretable and robust AI technology, and help understand the limitations of these technologies.",5 Broader Impact,199,10,,,FALSE,FALSE,FALSE,Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE,Neuroscience and Cognitive Science,"Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Deep Learning -> Generative Models; Deep Learning -> Visualization, Interpretability, and Explainability; Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Neuroscience; Probabilistic Methods -> Latent Variable Models",Neuroscience and cognitive science,"['Ding Zhou', 'Xin Wei']","{'University of Pennsylvania', 'Columbia University'}",1,0,0,{'USA'}
RL Unplugged: A Collection of Benchmarks for Offline Reinforcement Learning,"Caglar Gulcehre, Ziyu Wang, Alexander Novikov, Thomas Paine, Sergio Gómez, Konrad Zolna, Rishabh Agarwal, Josh S. Merel, Daniel J. Mankowitz, Cosmin Paduraru, Gabriel Dulac-Arnold, Jerry Li, Mohammad Norouzi, Matthew Hoffman, Nicolas Heess, Nando de Freitas",RL Unplugged: A Suite of Benchmarks for Offline Reinforcement Learning,51200d29d1fc15f5a71c1dab4bb54f7c,https://proceedings.neurips.cc/paper/2020/file/51200d29d1fc15f5a71c1dab4bb54f7c-Paper.pdf,"Online methods require exploration by having a learning agent interact with an environment. In contrast, offline methods learn from fixed dataset of previously logged environment interactions.  This has three positive consequences: 1) Offline approaches are more straightforward in settings where allowing an agent to freely explore in the environment is not safe. 2) Reusing offline data is more environmentally friendly by reducing computational requirements, because in many settings exploration is the dominant computational cost and requires large-scale distributed RL algorithms. 3) Offline methods may be more accessible to the wider research community, insofar as researchers who do not have sufficient compute resources for online training from large quantities of simulated experience can reproduce results from research groups with more resources, and improve upon them. But offline approaches also have potential drawbacks. Any algorithm that learns a policy from data to optimize a reward runs the risk of producing behaviors reflective of the training data or reward function. Offline RL is no exception. Current and future machine learning practitioners should be mindful of where and how they apply offline RL methods, with particular thought given to the scope of generalization they can expect of a policy trained on a fixed dataset.",Broader Impact,200,9,,,FALSE,FALSE,FALSE,RL Unplugged: A Collection of Benchmarks for Offline Reinforcement Learning,"Data, Challenges, Implementations, and Software","Data, Challenges, Implementations, and Software -> Benchmarks; Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories","Datasets, challenges, software","['Ziyu Wang', ' Caglar Gulcehre', ' Alexander Novikov', ' Thomas Paine', ' Sergio Gómez', ' Konrad Zolna', ' Rishabh Agarwal', ' Josh Merel', ' Daniel Mankowitz', ' Cosmin Paduraru', 'Arnold', ' Jerry Li', ' Mohammad Norouzi', ' Matthew Hoffman', ' Nicolas Heess', ' Nando de Freitas']","{'Deepmind', 'Google Brain', 'Google Research', 'DeepMind', 'Google', 'Google DeepMind', 'Google Research, Brain Team'}",0,1,0,"{'UK', 'USA'}"
Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning,"Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang Deng, Gang Niu, Masashi Sugiyama",Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning,512c5cad6c37edb98ae91c8a76c3a291,https://proceedings.neurips.cc/paper/2020/file/512c5cad6c37edb98ae91c8a76c3a291-Paper.pdf,"In the era of big data, it is expensive to expert-labeling each instance on a large scale. To reduce the annotation cost of the large datasets, non-expert labelers or automated annotation methods are widely used to annotate the datasets especially for startups and non-profit organizations which need to be thrifty. However, these cheap annotation methods are likely to introduce label-noise to the datasets, which put threats to the traditional supervised learning algorithm, and label-noise learning algorithms, therefore, become more and more popular. The transition matrix which contains knowledge of the noise rates is essential to building the classifier-consistent label-noise learning algorithms. The classification accuracy of the state-of-the-art label-noise learning applications are usually positively correlated to the estimation accuracy of the transition matrix. The proposed method is to estimate the transition matrix of noisy datasets. We have shown that our method usually leads to a better estimation compared to the current estimator and improves the classification accuracy of current label-noise learning applications. Therefore, outcomes of this research including improving the accuracy, robustness, accountability of the current label-noise learning applications, which should benefit science, society, and economy internationally. Potentially, our method may have a negative impact on the job of annotators. Because the classification accuracy of the label-noise learning applications is usually positively correlated to the estimation accuracy of the transition matrix. Therefore, the failure of our method may lead to a degenerating of the performance of the label-noise learning applications. The proposed method does not leverage biases in the data.",Broader Impact,249,12,,,FALSE,FALSE,FALSE,Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning,Algorithms -> Semi-Supervised Learning,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yu Yao', ' Tongliang Liu', ' Bo Han', ' Mingming Gong', ' Jiankang Deng', ' Gang Niu', ' Masashi Sugiyama']","{'RIKEN / University of Tokyo', 'RIKEN', 'HKBU / RIKEN', 'University of Sydney', 'University of Melbourne', 'Imperial College London', 'The University of Sydney'}",1,0,0,"{'Japan', 'Australia', 'UK'}"
Interior Point Solving for LP-based prediction+optimisation,"Jayanta Mandi, Tias Guns",Interior Point Solving for LP-based prediction+optimisation,51311013e51adebc3c34d2cc591fefee,https://proceedings.neurips.cc/paper/2020/file/51311013e51adebc3c34d2cc591fefee-Paper.pdf,"Decision-focussed learning means that models might have lower accuracy but perform better at the task they will be used for. This has the potential to change industrial optimisation significantly, for example in manufacturing, warehousing and logistics; where increasingly machine learning models are used to capture the uncertainty, after which optimization is used. In general, fusing barrier solving of integer linear programming with backpropagation enlarges the scope of problems for which we can use deep learning, as well as further aligning the two domains.",Broader Impact,83,3,,,FALSE,FALSE,FALSE,Interior Point Solving for LP-based prediction+optimisation,Optimization -> Discrete Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Jayanta Mandi', ' Tias Guns']",{'Vrije Universiteit Brussel'},1,0,0,{'Belgium'}
A simple normative network approximates local non-Hebbian learning in the cortex,"Siavash Golkar, David Lipshutz, Yanis Bahroun, Anirvan Sengupta, Dmitri Chklovskii",A simple normative network approximates local non-Hebbian learning in the cortex,5133aa1d673894d5a05b9d83809b9dbe,https://proceedings.neurips.cc/paper/2020/file/5133aa1d673894d5a05b9d83809b9dbe-Paper.pdf,"Understanding the inner workings of the brain has the potential of having a tremendous impact on society. On the one hand, this can lead to better performing machine learning algorithms and better artificial intelligent agents. On the other, understanding how the brain works can pave the way for better treatments of psychological and neurological disorders. While this paper does not tackle these lofty broad societal goals directly, it is a small step in clarifying how information is processed in the brain.",Broader impact,81,4,,,FALSE,FALSE,FALSE,A simple normative network approximates local non-Hebbian learning in the cortex,Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Plasticity and Adaptation; Neuroscience and Cognitive Science -> Synaptic Modulation,,,"{'Flatiron Institute, Simons Foundation', 'Rutgers University', 'Flatiron institute', 'Flatiron Institute'}",1,0,0,{'USA'}
Kernelized information bottleneck leads to biologically plausible 3-factor Hebbian learning in deep networks,"Roman Pogodin, Peter Latham",Kernelized information bottleneck leads to biologically plausible 3-factor Hebbian learning in deep networks,517f24c02e620d5a4dac1db388664a63,https://proceedings.neurips.cc/paper/2020/file/517f24c02e620d5a4dac1db388664a63-Paper.pdf,"This research program, like most in neuroscience, has the potential to advance our understanding of the brain. This comes with a host of societal implications. On the upside, it can give us a deeper understanding of mental health, possibly providing new therapies – something that would improve the lives of on the order of 1 billion people. On the downside, a deeper understanding of the brain is likely to translate into accelerated development of artificial intelligence, which would put a great deal of power into the hands of a small number of people.",Broader Impact,93,4,,,FALSE,FALSE,FALSE,Kernelized information bottleneck leads to biologically plausible 3-factor Hebbian learning in deep networks,Deep Learning -> Biologically Plausible Deep Networks,Neuroscience and Cognitive Science -> Plasticity and Adaptation; Neuroscience and Cognitive Science -> Synaptic Modulation; Neuroscience and Cognitive Science -> Visual Perception,Neuroscience and cognitive science,"['Roman Pogodin', ' Peter E Latham']","{'Gatsby Unit, UCL', 'University College London'}",1,0,0,{'UK'}
Understanding the Role of Training Regimes in Continual Learning,"Seyed Iman Mirzadeh, Mehrdad Farajtabar, Razvan Pascanu, Hassan Ghasemzadeh",Understanding the Role of Training Regimes in Continual Learning,518a38cc9a0173d0b2dc088166981cf8,https://proceedings.neurips.cc/paper/2020/file/518a38cc9a0173d0b2dc088166981cf8-Paper.pdf,"Continual Learning aims for effectively training a model from sequential tasks while making sure the model maintains a reasonable performance on the previous ones. It’s an integral part of Artificial General Intelligence (AGI) that reduces the cost of retraining (time, computation, resources, energy) and mitigates the need for storing all previous data to respect users’ privacy concerns better. Reducing catastrophic forgetting may potentially risk privacy for data that are explicitly wanted to be forgotten. This calls for more future research into formalizing and proposing continual learning agents that allow the identifiable parts of data to be forgotten, but the general knowledge is maintained. The research presented in this paper can be used for many different application areas and a particular use may have both positive or negative implications. Besides those, we are not aware of any immediate short term negative impact.",Broader Impact,141,6,,,FALSE,FALSE,FALSE,Understanding the Role of Training Regimes in Continual Learning,Algorithms -> Continual Learning,,Continual (lifelong) Learning,"['Seyed Iman Mirzadeh', ' Mehrdad Farajtabar', ' Razvan Pascanu', ' Hassan Ghasemzadeh']","{'Google DeepMind', 'Washington State University', 'DeepMind'}",1,1,1,"{'UK', 'USA'}"
Fair regression with Wasserstein barycenters,"Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, Massimiliano Pontil",Fair Regression with Wasserstein Barycenters,51cdbd2611e844ece5d80878eb770436,https://proceedings.neurips.cc/paper/2020/file/51cdbd2611e844ece5d80878eb770436-Paper.pdf,"This work investigates the problem of fair regression with multiple sensitive groups using tools from statistical learning theory and optimal transport theory. Our results lead to an efficient learning algorithm that we show empirically and theoretically to be very effective to impose fairness according to the notion of Demographic Parity. Our approach is directly designed to mitigate potential bias present in the data. Hence, even though the work is primarily theoretical, we anticipate that our results could be used in the future by practitioners in order to specialize our methodology to real-life scenarios involving individuals, and to potentially help making decision which help people with disadvantages or minority groups. We believe that the most important positive impact of our work is the intuitive interpretation of the optimal fair prediction, which should help to reason as to why a given prediction was made for a given individual. At the same time, this interpretation allows to understand the weaknesses of the notion of Demographic Parity: if f ∗ does not adequately reflect the group-wise ordering of individuals, the optimal fair prediction g ∗ might not lead to a fair prediction from individuals’ perspective. In other words, returning to the salary example considered above, the notion of Demographic Parity reflects the principle: more qualified individuals get higher salary within their respective groups.",Broader impact,219,7,,,FALSE,FALSE,FALSE,Fair regression with Wasserstein barycenters,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Regression; Theory -> Statistical Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Evgenii Chzhen', ' Christophe Denis', ' Mohamed Hebiri', ' Luca Oneto', ' Massimiliano Pontil']","{'IIT', 'Université Gustave Eiffel', 'University of Genoa', 'Universite Paris Est', 'Université Paris-Saclay'}",1,0,0,"{'France', 'India', 'Italy'}"
Training Stronger Baselines for Learning to Optimize,"Tianlong Chen, Weiyi Zhang, Zhou Jingyang, Shiyu Chang, Sijia Liu, Lisa Amini, Zhangyang Wang",Training Stronger Baselines for Learning to Optimize,51f4efbfb3e18f4ea053c4d3d282c4e2,https://proceedings.neurips.cc/paper/2020/file/51f4efbfb3e18f4ea053c4d3d282c4e2-Paper.pdf,"This work mainly contributes to AutoML in the aspect of discovering better learning rules or optimization algorithms from data. As a fundamental technique, it seems to pose no substantial societal risk. This paper proposes several improved training techniques to tackle the dilemma of training instability and poor generalization in learned optimizers. In general, learning to optimize (L2O) prevents laborious problem-specific optimizer design, and potentially can largely reduce the cost (including time, energy and expense) of model training or tuning hyperparameters.",Broader Impact,80,4,,,FALSE,FALSE,FALSE,Training Stronger Baselines for Learning to Optimize,Algorithms -> Meta-Learning,Algorithms -> AutoML,AutoML,"['Tianlong Chen', ' Weiyi Zhang', ' Zhou Jingyang', ' Shiyu Chang', ' Sijia Liu', ' Lisa Amini', ' Zhangyang Wang']","{'MIT-IBM Watson AI Lab, IBM Research AI', 'University of Texas at Austin', 'Unversity of Texas at Austin', 'Shanghai Jiao Tong University', 'University of Science and Technology of China', 'IBM Research'}",1,1,1,"{'USA', 'China'}"
Exactly Computing the Local Lipschitz Constant of ReLU Networks,"Matt Jordan, Alexandros G. Dimakis",Exactly Computing the Local Lipschitz Constant of ReLU networks,5227fa9a19dce7ba113f50a405dcaf09,https://proceedings.neurips.cc/paper/2020/file/5227fa9a19dce7ba113f50a405dcaf09-Paper.pdf,"As deep learning begins to see use in situations where safety or fairness are critical, it is increasingly important to have tools to audit and understand these models. The Lipschitz computation technique we have outlined in this work is one of these tools. As we have discussed, an upper bound on the Lipschitz constant of a model may be used to efficiently generate certificates of robustness against adversarial attacks. Lipschitz estimates have the advantage over other robustness certificates in that they may be used to make robustness claims about large subsets of the input space, rather than certifying that a particular input is robust against adversarial attacks. Lipschitz estimation, if comuputable with respect to fair metrics, may be utilized to generate certificates of individual fairness (see [8, 9] for examples of this formulation of fair metrics and individual fairness). Our approach is the first to provide a scheme for Lipschitz estimation with respect to arbitrary norms, which may include these fair metrics. Exact verification of neural networks has the added benefit that we are guaranteed to be generate the correct answer and not just a sound approximation. We argue that a fundamental understanding of the behavior of these models needs to be derived from both theoretical results and accurate empirical validation. As we have demonstrated, our technique is able to provide accurate measurements of the Lipschitz constant of small-scale neural networks. The computational complexity of the problem suggests that such accurate measurements are not tractably attainable for networks with millions of hyperparameters. Our experiments demonstrate that our technique is scalable to networks large enough that insights may be drawn, such as claims about how regularized training affects the Lipschitz constant. Further, exact verification techniques may be used as benchmarks to verify the accuracy of the more efficient verification techniques. Future Lipschitz estimation techniques, assuming that they do not provide provable guarantees, will need to assert the accuracy of their reported answers: it is our hope that this will be empirically done by comparisons against exact verification techniques, where the accuracy claims may then be extrapolated to larger networks.",9 Broader Impact,348,13,,,FALSE,FALSE,FALSE,Exactly Computing the Local Lipschitz Constant of ReLU Networks,Deep Learning -> Analysis and Understanding of Deep Networks,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Matt Jordan', ' Alexandros Dimakis']","{'University of Texas, Austin', 'UT Austin'}",1,0,0,{'USA'}
Strictly Batch Imitation Learning by Energy-based Distribution Matching,"Daniel Jarrett, Ioana Bica, Mihaela van der Schaar",Strictly Batch Imitation Learning by Energy-based Distribution Matching,524f141e189d2a00968c3d48cadd4159,https://proceedings.neurips.cc/paper/2020/file/524f141e189d2a00968c3d48cadd4159-Paper.pdf,"In general, any method for imitation learning has the potential to mitigate problems pertaining to scarcity of expert knowledge and computational resources. For instance, consider a healthcare institution strapped for time and personnel attention—such as one under the strain of an influx of ICU patients. If implemented as a system for clinical decision support and early warnings, even the most bare-bones policy trained on optimal treatment/monitoring actions has huge potential for streamlining medical decisions, and for allocating attention where real-time clinical judgment is most required. By focusing our work on the strictly batch setting for learning, we specifically accommodate situations that disallow directly experimenting on the environment during the learning process. This considera- tion is critical in many conceivable applications: In practice, humans are often on the receiving end of actions and polices, and an imitator policy that must learn by interactive experimentation would be severely hampered due to considerations of cost, danger, or moral hazard. While—in line with literature—we illustrate the technical merits of our proposed method with respect to standard control environments, we do take care to highlight the broader applicability of our approach to healthcare settings, as it likewise applies—without saying—to education, insurance, or even law enforcement. Of course, an important caveat is that any method for imitation learning naturally runs the risk of internalizing any existing human biases that may be implicit in the demonstrations collected as training input. That said, a growing field in reinforcement learning is dedicated to maximizing interpretability in learned policies, and—in the interest of accountability and transparency—striking an appropriate balance with performance concerns will be an interesting direction of future research.",Broader Impact,270,8,,,TRUE,TRUE,FALSE,Strictly Batch Imitation Learning by Energy-based Distribution Matching,Reinforcement Learning and Planning -> Reinforcement Learning,Applications -> Health,Reinforcement learning and planning,"['Daniel Jarrett', ' Ioana Bica', ' Mihaela van der Schaar']","{'University of Cambridge', 'University of Oxford'}",1,0,0,{'UK'}
"On the Ergodicity, Bias and Asymptotic Normality of Randomized Midpoint Sampling Method","Ye He, Krishnakumar Balasubramanian, Murat A. Erdogdu","On the Ergodicity, Bias and Asymptotic Normality of Randomized Midpoint Sampling Method",5265d33c184af566aeb7ef8afd0b9b03,https://proceedings.neurips.cc/paper/2020/file/5265d33c184af566aeb7ef8afd0b9b03-Paper.pdf,"The paper predominantly concerns about theoretical results on numerical integration with MCMC based samplers. The presented results are of interest to researchers in machine learning community concerned with constructing confidence intervals for their numerical integration problems. Although not the main focus of this paper, the results might have positive consequence for building robust machine learning systems based on the obtained confidence intervals.",Broader Impact,62,3,,,FALSE,FALSE,FALSE,"On the Ergodicity, Bias and Asymptotic Normality of Randomized Midpoint Sampling Method",Theory -> Large Deviations and Asymptotic Analysis,Probabilistic Methods -> Bayesian Theory; Theory -> Frequentist Statistics; Theory -> Statistical Learning Theory,Probabilistic methods and inference,"['Ye He', ' Krishnakumar Balasubramanian', ' Murat Erdogdu']","{'University of California, Davis', 'University of Toronto'}",1,0,0,"{'Canada', 'USA'}"
A Single-Loop Smoothed Gradient Descent-Ascent Algorithm for Nonconvex-Concave Min-Max Problems,"Jiawei Zhang, Peijun Xiao, Ruoyu Sun, Zhiquan Luo",A Single-Loop Smoothed Gradient Descent-Ascent Algorithm for Nonconvex-Concave Min-Max Problems,52aaa62e71f829d41d74892a18a11d59,https://proceedings.neurips.cc/paper/2020/file/52aaa62e71f829d41d74892a18a11d59-Paper.pdf,"In this paper, we propose a single-loop algorithm for min-max problem. This algorithm is easy to implemented and proved to be efficient in a family of nonconvex minimax problems and have good numerical behavior in robust training. This paper focuses on theoretical study of the algorithms. In industrial applications, several aspects of impact can be expected: 1. Save energy by improving efficiency. The trick developed in this paper has the potential to accelerate the training for machine learning problems involving a minimax problem such robust training for uncertain data, generative adversarial net(GAN) and AI for games. This means that the actual training time will decrease dramatically by using our algorithm. Training neural network is very energy-consuming, and reducing the training time can help the industries or companies to save energy. 2. Promote fairness. We consider min-max problems in this paper. A model that is trained under this framework will not allow poor performance on some objectives in order to boost performance on the others. Therefore, even if the training data itself is biased, the model will not allow some objectives to contribute heavily to minimizing the average loss due to the min-max framework. In other words, this framework promotes fairness, and model that is trained under this framework will provide fair solutions to the problems. 3. Provide flexible framework. Our algorithmic framework is flexible. Though in the paper, we only discuss some general formulation, our algorithm can be easily extended to many practical settings. For example, based on our general framework for multi-block problems, we can design algorithms efficiently solving problems with distributedly stored data, decentralized control or privacy concern. Therefore, our algorithm may have an impact on some popular big data applications such as distributed training, federated learning and so on.",Broader Impact,292,20,,,TRUE,TRUE,FALSE,A Single-Loop Smoothed Gradient Descent-Ascent Algorithm for Nonconvex-Concave Min-Max Problems,Optimization -> Non-Convex Optimization,,Optimization Methods (continuous or discrete),"['Jiawei Zhang', ' Peijun Xiao', 'Champaign', ' Ruoyu Sun', ' Zhiquan Luo']","{'The Chinese University of Hong Kong, Shenzhen', 'University of Illinois at Urbana-Champaign', 'The Chinese University of Hong Kong, Shenzhen and Shenzhen Research Institute of Big Data', 'UIUC'}",1,0,0,"{'USA', 'China'}"
Generating Correct Answers for Progressive Matrices Intelligence Tests,"Niv Pekar, Yaniv Benny, Lior Wolf",Generating Correct Answers for Progressive Matrices Intelligence Tests,52cf49fea5ff66588408852f65cf8272,https://proceedings.neurips.cc/paper/2020/file/52cf49fea5ff66588408852f65cf8272-Paper.pdf,"The shift from selecting an answer from a closed set to generating an answer could lead to more interpretable methods, since the generated output may reveal information about the underlying inference process. Such networks are, therefore, more useful for validating cognitive models through the implementation of computer models. The field of answer generation may play a crucial part in automatic tutoring. Ideally, the generated answer would fit the level of the student and allow for automated personalized teaching. Such technologies would play a role in making high-level education accessible to all populations.",Broader Impact,92,5,,,FALSE,FALSE,FALSE,Generating Correct Answers for Progressive Matrices Intelligence Tests,Applications -> Visual Question Answering,Deep Learning -> Generative Models,Deep learning,"['Niv Pekar', ' Yaniv Benny', ' Lior Wolf']","{'Facebook AI Research', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
HyNet: Learning Local Descriptor with Hybrid Similarity Measure and Triplet Loss,"Yurun Tian, Axel Barroso Laguna, Tony Ng, Vassileios Balntas, Krystian Mikolajczyk",HyNet: Learning Local Descriptor with Hybrid Similarity Measure and Triplet Loss,52d2752b150f9c35ccb6869cbf074e48,https://proceedings.neurips.cc/paper/2020/file/52d2752b150f9c35ccb6869cbf074e48-Paper.pdf,"Local feature descriptors and gradient based optimization are crucial components in a wide range of technologies such as stereo vision, AR, 3D reconstructions, SLAM, among others. As such, the proposed approach improves the quality of results within these technologies, which are typically used in various applications including smartphone apps for image pro- cessing, driver-less cars, robotics, AR headsets. Its societal impact potential is within these applications, in particular the reliability of the technologies behind, which our approach contributes to. Similarly, any ethical issues are also associated with the applications as our approach cannot be used independently of a larger system.",Broader Impact,100,4,,,FALSE,FALSE,FALSE,HyNet: Learning Local Descriptor with Hybrid Similarity Measure and Triplet Loss,Deep Learning -> Embedding Approaches,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yurun Tian', ' Axel Barroso Laguna', ' Tony Ng', ' Vassileios Balntas', ' Krystian Mikolajczyk']","{'Scape Technologies', 'Imperial College London'}",1,1,1,{'UK'}
Preference learning along multiple criteria: A game-theoretic perspective,"Kush Bhatia, Ashwin Pananjady, Peter Bartlett, Anca Dragan, Martin J. Wainwright",Preference learning along multiple criteria: A game-theoretic perspective,52f4691a4de70b3c441bca6c546979d9,https://proceedings.neurips.cc/paper/2020/file/52f4691a4de70b3c441bca6c546979d9-Paper.pdf,"An important step towards deploying AI systems in the real world involves aligning their objectives with human values. Examples of such objectives include safety for autonomous vehicles, fairness for recommender systems, and effectiveness of assistive medical devices. Our paper takes a step towards accomplishing this goal by providing a framework to aggregate human preferences along such subjective criteria, which are often hard to encode mathematically. While our framework is quite expressive and allows for non-linear aggregation across criteria, it leaves the choice of the target set in the hands of the designer. As a possible negative consequence, getting this choice wrong could lead to incorrect inferences and unexpected behavior in the real world.",Broader impact,113,5,,,FALSE,FALSE,FALSE,Preference learning along multiple criteria: A game-theoretic perspective,Theory,Algorithms -> Ranking and Preference Learning; Theory -> High-Dimensional Inference,Theory (including computational and statistical analyses),"['Kush Bhatia', ' Ashwin Pananjady', ' Peter Bartlett', ' Anca Dragan', ' Martin Wainwright']",{'UC Berkeley'},1,0,0,{'USA'}
Multi-Plane Program Induction with 3D Box Priors,"Yikai Li, Jiayuan Mao, Xiuming Zhang, Bill Freeman, Josh Tenenbaum, Noah Snavely, Jiajun Wu",Multi-Plane Program Induction with 3D Box Priors,5301c4d888f5204274439e6dcf5fdb54,https://proceedings.neurips.cc/paper/2020/file/5301c4d888f5204274439e6dcf5fdb54-Paper.pdf,"This paper presents an improved interactive image manipulation algorithms, which helps visual artists, photographers, and normal users who wants to perform content-aware and 3D-aware edits to their images. Moreover, our algorithm only use pixels from the input image itself during editing, which minimizes the biases coming from external sources. However, misuses of our algorithms can generate fake images that affect image forensics.",Broader Impact,62,3,,,FALSE,FALSE,FALSE,Multi-Plane Program Induction with 3D Box Priors,Applications -> Visual Scene Analysis and Interpretation,Applications -> Computational Photography; Applications -> Computer Vision; Applications -> Program Understanding and Generation,Vision,"['Yikai Li', ' Jiayuan Mao', ' Xiuming Zhang', ' Bill Freeman', ' Josh Tenenbaum', ' Noah Snavely', ' Jiajun Wu']","{'MIT/Google', 'Google', 'Cornell University and Google AI', 'Shanghai Jiao Tong University', 'MIT'}",1,1,1,"{'USA', 'China'}"
Online Neural Connectivity Estimation with Noisy Group Testing,"Anne Draelos, John Pearson",Online Neural Connectivity Estimation with Noisy Group Testing,531d29a813ef9471aad0a5558d449a73,https://proceedings.neurips.cc/paper/2020/file/531d29a813ef9471aad0a5558d449a73-Paper.pdf,"The focus of this work is on improving neuroscience experiments through the use of more sophisti- cated experimental designs. In particular, we targeted understanding the ways in which networks of neurons are constructed and function together, which has long been a focus of the field. As this advance is primarily theoretical, we do not anticipate any directly negative societal impacts. However, our work’s broader impacts reflect those of neuroscience more generally: Diseases of the brain, from Alzheimer’s to stroke to depression, affect a tremendous percentage of the world’s population, and it is increasingly recognized that many of these conditions must be understood as pathologies of neural networks. It is our hope that circuit dissection techniques like the ones presented here will lend themselves to faster advances in our understanding of how the brain functions, with potential positive applications in the treatment of degenerative diseases. In particular, the use of implantable brain stimulation devices is now routine in the treatment of Parkinson’s Disease, and it is thought that future brain-machine interfaces will help restore motor function for those suffering from paralysis. In each case, one of the key requirements is the online analysis of brain data, to which the present work represents a small contribution.",Broader Impact,204,7,,,FALSE,FALSE,FALSE,Online Neural Connectivity Estimation with Noisy Group Testing,Neuroscience and Cognitive Science -> Neuroscience,Algorithms -> Adaptive Data Analysis; Neuroscience and Cognitive Science -> Connectomics; Optimization -> Convex Optimization; Probabilistic Methods -> Variational Inference,Neuroscience and cognitive science,"['Anne Draelos', ' John Pearson']",{'Duke University'},1,0,0,{'USA'}
Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness and Accuracy for Free,"Haotao N. Wang, Tianlong Chen, Shupeng Gui, TingKuei Hu, Ji Liu, Zhangyang Wang",Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness and Accuracy for Free,537d9b6c927223c796cac288cced29df,https://proceedings.neurips.cc/paper/2020/file/537d9b6c927223c796cac288cced29df-Paper.pdf,"Deep neural networks are notoriously vulnerable to adversarial attacks [1]. With the growing usage of DNNs on security sensitive applications, such as self-driving [3] and bio-metrics [4], a critical concern has been raised to carefully examine the model robustness against adversarial attacks, in addition to their average accuracy on standard inputs. In this paper, we propose to tackle the new challenging problem on how to quickly calibrate a trained model in-situ, in order to examine the achievable trade-offs between its standard and robust accuracies, without (re-)training it many times. Our proposed method is motivated by the difficulties commonly met in our real-world self-driving applications: how to adjust an autonomous agent in-situ, in order to meet the standard/robust accuracy requirements varying over contexts and time. For example, we may expect an autonomous agent to perceive and behave more cautiously, ( i . e ., to prioritize improving its robustness), when it is placed in less confident or adverse environments. Also, our method provides a novel way to efficiently traverse through the full accuracy-robustness spectrum, which would help more comprehensively and fairly compare models’ behaviors under different trade-off hyper-parameters, without having to retrain. Our proposed methods can be applied to many high-stakes real world applications, such as self-driving [3], bio-metrics [4], medical image analysis [48] and computer-aided diagnosis [49].",Broader Impact,217,8,,,FALSE,FALSE,FALSE,Once-for-All Adversarial Training: In-Situ Tradeoff between Robustness and Accuracy for Free,Algorithms -> Adversarial Learning,Deep Learning -> CNN Architectures,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Haotao Wang', ' Tianlong Chen', ' Shupeng Gui', ' TingKuei Hu', ' Ji Liu', ' Zhangyang Wang']","{'Kwai Inc.', 'Unversity of Texas at Austin', 'University of Texas at Austin', 'Texas A&M University', 'University of Rochester'}",1,1,1,{'USA'}
Implicit Neural Representations with Periodic Activation Functions,"Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, Gordon Wetzstein",Implicit Neural Representations with Periodic Activation Functions,53c04118df112c13a8c34b38343b9c10,https://proceedings.neurips.cc/paper/2020/file/53c04118df112c13a8c34b38343b9c10-Paper.pdf,"The proposed SIREN representation enables accurate representations of natural signals, such as images, audio, and video in a deep learning framework. This may be an enabler for downstream tasks involving such signals, such as classification for images or speech-to-text systems for audio. Such applications may be leveraged for both positive and negative ends. SIREN may in the future further enable novel approaches to the generation of such signals. This has potential for misuse in impersonating actors without their consent. For an in-depth discussion of such so-called DeepFakes, we refer the reader to a recent review article on neural rendering [16].",Broader Impact,100,6,,,FALSE,FALSE,FALSE,Implicit Neural Representations with Periodic Activation Functions,Applications -> Computer Vision,Deep Learning,Deep learning,"['Vincent Sitzmann', ' Julien Martel', ' Alexander Bergman', ' David Lindell', ' Gordon Wetzstein']",{'Stanford University'},1,0,0,{'USA'}
Rotated Binary Neural Network,"Mingbao Lin, Rongrong Ji, Zihan Xu, Baochang Zhang, Yan Wang, Yongjian Wu, Feiyue Huang, Chia-Wen Lin",Rotated Binary Neural Network,53c5b2affa12eed84dfec9bfd83550b1,https://proceedings.neurips.cc/paper/2020/file/53c5b2affa12eed84dfec9bfd83550b1-Paper.pdf,"Benefit: The binary neural network community may benefit from our research. The proposed Rotated Binary Neural Network (RBNN) provides a novel perspective to lessen the quantization error by reducing the angular bias, which was ignored by previous works. With the code publicly available, our work will also help researchers quantize DNNs so that the deep models can be deployed on devices with limited resources such as mobile phones. Disadvantage: The angular bias between the activation and its binarization remains an open problem. It may be not appropriate to apply our rotation to the activation vector since it will add the computation in the inference. Consequence: The failure of the network quantization will not bring serious consequences, as our RBNN causes fewer accuracy drops compared to other SOTAs. Data Biases: The proposed RBNN is irrelevant to data selection, so it does not have the data bias problem.",Broader Impact,146,7,,,FALSE,FALSE,FALSE,Rotated Binary Neural Network,Deep Learning -> Efficient Inference Methods,,Deep learning,"['Mingbao Lin', ' Rongrong Ji', ' Zihan Xu', ' Baochang Zhang', ' Yan Wang', ' Yongjian Wu', 'Tencent Technology', ' Feiyue Huang', 'Wen Lin']","{'National Tsing Hua University', 'Xiamen University', 'Shanghai', 'Beihang University', 'Xiamen University, China', 'Pinterest', 'Tencent'}",1,1,1,"{'China', 'Taiwan'}"
Community detection in sparse time-evolving graphs with a dynamical Bethe-Hessian,"Lorenzo Dall'Amico, Romain Couillet, Nicolas Tremblay",Community detection in sparse time-evolving graphs with a dynamical Bethe-Hessian,54391c872fe1c8b4f98095c5d6ec7ec7,https://proceedings.neurips.cc/paper/2020/file/54391c872fe1c8b4f98095c5d6ec7ec7-Paper.pdf,"Community detection algorithms have a broad interest as they can be applied to a very vast class of problems and settings. An interesting example, of utmost importance in the present days, was given by [44] were the authors showed the importance of keeping track of the time-evolving community structure of social networks to properly model an epidemic spreading. Not unlike any other clustering algorithm, however, when applied to a real social network, our algorithm can potentially evidence differences in terms of e.g. race, sex, religion. As discussed in [45], if such an output is used in some decision process, the result can indeed produce discriminatory choices. Although we are aware of the potential weaknesses, the mainly theoretical nature of our study, as well as the nowadays vast literature in the field of community detection, allows us to not foresee any major negative consequence from our study. On the contrary, keeping into account of the realistic time-evolving nature of networks can allow to improve and better understand our studies in the field.",Broader impact,171,6,,,FALSE,FALSE,FALSE,Community detection in sparse time-evolving graphs with a dynamical Bethe-Hessian,Algorithms -> Spectral Methods,Algorithms; Algorithms -> Clustering; Algorithms -> Dynamical Systems; Algorithms -> Large Scale Learning; Algorithms -> Unsupervised Learning; Applications -> Network Analysis; Probabilistic Methods -> Belief Propagation; Theory -> Statistical Physics of Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Amico', ' Romain Couillet', ' Nicolas Tremblay']","{'CNRS', 'GIPSA lab', 'CentralSupélec'}",1,0,0,{'France'}
Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness,"Jeremiah Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax Weiss, Balaji Lakshminarayanan",Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness,543e83748234f7cbab21aa0ade66565f,https://proceedings.neurips.cc/paper/2020/file/543e83748234f7cbab21aa0ade66565f-Paper.pdf,"This work proposed a simple and practical methodology to improve the uncertainty estimation performance of a deterministic deep learning model. Experiment results showcased the method’s ability in improving model performance in calibration and OOD detection while maintaining similar level of accuracy and latency, therefore illustrating its feasibility for industrial-scale applications. We hope the proposed approach can be used to bring concrete improvements to AI-driven, socially- relevant services where uncertainty is of natural importance. Examples include medical and policy decision making, online toxic comment management, fairness-aware recommendation systems, etc. Nonetheless, we do not claim that the improvement illustrated in this paper solve the problem of model uncertainty entirely. This is because the analysis and experiments in this study may not capture the full complexity of the real-world use cases, and there will always be room for improvement. Designers of machine learning systems are encouraged to proactively confront the shortcomings of model uncertainty and the underlying models that generate these confidences. Even with a proper user interface, there is always room to misinterpret model outputs and probabilities, such as with nuanced applications such as election predictions, and users of these models should to be properly trained to take these factors into account.",Broader Impact,200,8,,,FALSE,FALSE,FALSE,Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness,Algorithms -> Uncertainty Estimation,Probabilistic Methods -> Gaussian Processes,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jeremiah Liu', ' Zi Lin', ' Shreyas Padhy', ' Dustin Tran', ' Tania Bedrax Weiss', ' Balaji Lakshminarayanan']","{'Google', 'Google Brain', 'Google Research / Harvard'}",1,1,1,{'USA'}
Adaptive Learning of Rank-One Models for Efficient Pairwise Sequence Alignment,"Govinda Kamath, Tavor Baharav, Ilan Shomorony",Adaptive Learning of Rank-One Models for Efficient Pairwise Sequence Alignment,54e0e46b6647aa736c13ef9d09eab432,https://proceedings.neurips.cc/paper/2020/file/54e0e46b6647aa736c13ef9d09eab432-Paper.pdf,"Over the last decade, high-throughput sequencing technologies have driven down the time and cost of acquiring biological data tremendously. This has caused an explosion in the amount of available genomic data, allowing scientists to obtain quantitative insights into the biology of all living organisms. Countless tasks – such as gene expression quantification, metagenomic sequencing, and single-cell RNA sequencing – heavily rely on some form of pairwise sequence alignment, which is a heavy computational burden and often the bottleneck of the analysis pipeline. The development of efficient algorithms for this task, which is the main outcome of this paper, is thus critical for the scalability of genomic data analysis. From a theoretical perspective, this work establishes novel connections between a classical problem in bioinformatics (pairwise sequence alignment), spectral methods for parameter estimation from crowdsourced noisy data, and multi-armed bandits. This will help facilitate the transfer of insights and algorithms between these traditionally disparate areas. It will also add a new set of techniques to the toolbox of the computational biology community that we believe will find a host of applications in the context of genomics and other large-scale omics data analysis. Further, this work will allow other Machine Learning researchers unfamiliar with bioinformatics to utilise their expertise in solving new problems at this novel intersection of bioinformatics, spectral methods, and multi-armed bandits.",Broader Impact,221,8,,,FALSE,FALSE,FALSE,Adaptive Learning of Rank-One Models for Efficient Pairwise Sequence Alignment,Applications -> Computational Biology and Bioinformatics,Algorithms -> Bandit Algorithms; Algorithms -> Spectral Methods; Theory -> Information Theory,"Other applications (e.g., robotics, biology, climate, finance)","['Govinda Kamath', ' Tavor Baharav', ' Ilan Shomorony']","{'Stanford University', 'University of Illinois at Urbana Champaign', 'Microsoft Research'}",1,1,1,{'USA'}
Hierarchical nucleation in deep neural networks,"Diego Doimo, Aldo Glielmo, Alessio Ansuini, Alessandro Laio",Hierarchical nucleation in deep neural networks,54f3bc04830d762a3b56a789b6ff62df,https://proceedings.neurips.cc/paper/2020/file/54f3bc04830d762a3b56a789b6ff62df-Paper.pdf,"We believe that the detailed picture of the evolution of the probability density provided in this work can improve the performance of learning protocols, make transfer learning more effective and enrich the information extracted from a multiclass classifier. For example, the knowledge of the probability landscape can provide a rational criterion to improve training schemes based on triplet loss [32]. In this setting it is crucial to select challenging triplets where the so-called ""anchor"" image is closer to an example of a different class ( negative ) than to that of the same class ( positive ). Datapoints lying at the boundary of a probability peak could be used as anchors as they are on average closer to negatives than those lying close to cluster centers. One can also imagine to define training losses targeting the development of probability peaks according to a pre-defined semantic classification. This can be enforced in the intermediate layers of a network going well beyond a simple disentanglement of the feature space [33], enhancing the separation between macro categories which arise spontaneously. An appropriate understanding of the nucleation mechanism could also be beneficial to transfer learning, since it gives a simple rational criterion to judge the generality of the features of a representation [34]. Finally, one can imagine to use the topography of the density peaks developed by a deep neural network as a hierarchical classifier, going beyond the sharp classification in mutually exclusive categories [35].",Broader impact,241,8,,,FALSE,FALSE,FALSE,Hierarchical nucleation in deep neural networks,Deep Learning -> Analysis and Understanding of Deep Networks,"Deep Learning -> CNN Architectures; Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,"['Diego Doimo', 'International School for Advanced Studies', ' Aldo Glielmo', 'International School for Advanced Studies', ' Alessio Ansuini', 'International School for Advanced Studies', ' Alessandro Laio', 'International School for Advanced Studies']",{'SISSA'},1,0,0,{'Italy'}
Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,"Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, Ren Ng",Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,55053683268957697aa39fba6f231c68,https://proceedings.neurips.cc/paper/2020/file/55053683268957697aa39fba6f231c68-Paper.pdf,"This paper demonstrates how Fourier features can be used to enable coordinate-based MLPs to accurately model high-frequency functions in low-dimensional domains. Because we improve the performance of coordinate-based MLPs, we consider the impact of using those MLPs (such as those shown in Figure 1). The 2D image regression case (Figure 1b) has historically been limited in its practical use to artistic image synthesis [15, 39] and synthesizing images designed to mislead classifiers [31]. It is difficult to quantify the potential societal impact of artistic image synthesis, but the ability to generate improved adversarial attacks on classifiers poses a risk in domains such as robotics or self-driving cars, and necessitates the continued study of how classifiers can be made robust to such attacks [26]. Given that coordinate-based MLPs have been shown to exhibit notable compression capabilities [30], advances in coordinate-based MLPs for image or video regression may also serve as a basis for an effective compression algorithm. Improved image compression may have positive value in terms of consumer photography and electronics experiences (expanded on-device or cloud storage), but may have potentially negative value by enabling easier private or governmental surveillance by making recordings easier to store for longer periods of time. Improved performance of coordinate-based MLPs for CT and MRI imaging tasks (Figure 1d) may lead to improved medical imaging technologies, which generally have positive societal impacts: more accurate diagnoses and less expensive or more accessible diagnostic information for communities with limited access to medical services. However, given the serious impact an inaccurate medical diagnosis can have on a patient’s well-being, the consequences of failure for this use case are significant. Coordinate-based MLPs have also been used for 3D tasks such as predicting volume occupancy (Figure 1c) and view synthesis (Figure 1e) [27, 30]. Assessing the long-term impact of algorithms that reason about 3D occupancy is difficult, as this task is fundamental to much of perception and robotics and thus carries with it the broad potential upsides and downsides of increased automation [10]. But in the immediate future, improved view synthesis has salient positive effects: it may let filmmakers produce photorealistic effects and may allow for immersive 3D mapping applications or VR experiences. However, this progress may also inadvertently reduce employment opportunities for the human artists who currently produce these effects manually.",Broader Impact,381,12,,,FALSE,TRUE,FALSE,Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains,Deep Learning -> Analysis and Understanding of Deep Networks,Applications -> Computer Vision,Theory (including computational and statistical analyses),"['Matthew Tancik', ' Pratul Srinivasan', ' Ben Mildenhall', 'Keil', ' Nithin Raghavan', ' Utkarsh Singhal', ' Ravi Ramamoorthi', ' Jonathan Barron', ' Ren Ng']","{'UC Berkeley', 'University of California, Berkeley', 'University of California San Diego', 'Google Research'}",1,1,1,{'USA'}
Graph Geometry Interaction Learning,"Shichao Zhu, Shirui Pan, Chuan Zhou, Jia Wu, Yanan Cao, Bin Wang",Graph Geometry Interaction Learning,551fdbb810aff145c114b93867dd8bfd,https://proceedings.neurips.cc/paper/2020/file/551fdbb810aff145c114b93867dd8bfd-Paper.pdf,"Graph neural network (GNN) is a new frontier in deep learning. GNNs are powerful tools to capture the complex inter-dependency between objects inside data. By advancing existing GNN approaches and providing flexibility for GNNs to capture different intrinsic features from both Euclidean spaces and hyperbolic spaces, our model can be used to model a wider range of complex graphs, ranging from social networks and traffic networks to protein interaction networks, for various applications such as social influence prediction, traffic flow prediction, and drug discovery. One potential issue of our model, like many other GNNs, is that it provides limited explanation to its prediction. We advocate peer researchers to look into this to enhance the interpretability of modern GNN architectures, making GNNs applicable in more critical applications in medical domains.",Impact Satement,129,5,,,FALSE,FALSE,FALSE,Graph Geometry Interaction Learning,Applications -> Network Analysis,Algorithms -> Classification; Algorithms -> Representation Learning; Algorithms -> Semi-Supervised Learning,Deep learning,"['Shichao Zhu', ' Shirui Pan', ' Chuan Zhou', ' Jia Wu', ' Yanan Cao', ' Bin Wang']","{'Institute of Information Engineering, Chinese Academy of Sciences', 'Macquarie University', 'Monash University', 'Chinese Academy of Sciences', 'Xiaomi AI Lab'}",1,1,1,"{'Australia', 'China'}"
Differentiable Augmentation for Data-Efficient GAN Training,"Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, Song Han",Differentiable Augmentation for Data-Efficient GAN Training,55479c55ebd1efd3ff125f1337100388,https://proceedings.neurips.cc/paper/2020/file/55479c55ebd1efd3ff125f1337100388-Paper.pdf,"In this paper, we investigate GANs from the data efficiency perspective, aiming to make generative modeling accessible to more people (e.g., visual artists and novice users) and research fields who have no access to abundant data. In the real-world scenarios, there could be various reasons that lead to limited amount of data available, such as rare incidents, privacy concerns, and historical visual data [10]. DiffAugment provides a promising way to alleviate the above issues and make AI more accessible to everyone.",Broader Impact,81,3,FALSE,FALSE,TRUE,TRUE,FALSE,Differentiable Augmentation for Data-Efficient GAN Training,Deep Learning -> Adversarial Networks,Deep Learning -> Efficient Training Methods; Deep Learning -> Generative Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Shengyu Zhao', ' Zhijian Liu', ' Ji Lin', 'Yan Zhu', ' Song Han']","{'MIT', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Heuristic Domain Adaptation,"Shuhao Cui, Xuan Jin, Shuhui Wang, Yuan He, Qingming Huang",Heuristic Domain Adaptation,555d6702c950ecb729a966504af0a635,https://proceedings.neurips.cc/paper/2020/file/555d6702c950ecb729a966504af0a635-Paper.pdf,"Domain adaptation aims to obtain the domain-invariant representations across training and testing distributions, which is a general problem in machine learning. Our method stresses the importance of explicitly constructing domain-specific representations as the heuristics towards effective domain adaptation. The guidance of heuristics formulate the principled framework of HDA, similar to heuristic search. Despite of the similarity in working mechanism, remarkable difference still exist between heuristic search and our method from the task setting aspect. In our method, heuristics are constructed in a way similar to blind signal separation. The separation process could also be applied to a broader range of tasks, such as signal reconstruction, representation learning or visual tracking. However, the separation could not achieve ideal separation without extra knowledge or priors. In common situations, there is no general method constructing the heuristic knowledge, which is another limitation of the method. The framework of HDA could also be further improved from two perspectives. First, some simply constructed extra domain-specific knowledge could be introduced to enhance the separation. Moreover, the structure of our constructed heuristic networks is an additive ensemble of sub-networks, which could be replaced by Neural Architecture Search (NAS).",7 Broader Impact,191,11,,,TRUE,TRUE,FALSE,Heuristic Domain Adaptation,Algorithms -> Multitask and Transfer Learning,Algorithms -> Adversarial Learning; Algorithms -> Classification; Algorithms -> Semi-Supervised Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Shuhao Cui', ' Xuan Jin', ' Shuhui Wang', ' Yuan He', ' Qingming Huang']","{'University of Chinese Academy of Sciences', 'Alibaba Group', 'ict cas', 'VIPL,ICT,Chinese academic of science', 'Alibaba Turing Lab, Alibaba Group'}",1,1,1,{'China'}
Learning Certified Individually Fair Representations,"Anian Ruoss, Mislav Balunovic, Marc Fischer, Martin Vechev",Learning Certified Individually Fair Representations,55d491cf951b1b920900684d71419282,https://proceedings.neurips.cc/paper/2020/file/55d491cf951b1b920900684d71419282-Paper.pdf,"Methods that learn from data can potentially produce unfair outcomes by reinforcing human biases or discriminating amongst specific groups. We illustrate how our method can be employed to address these issues with an example due to Cisse and Koyejo [7]. Consider a company with several teams working with the same data to build models. Although the individual teams may not care about fairness of their models, the company needs to comply with ethical or legal requirements. In this setting, our framework enables the company to obtain such certificates from every team in a minimally invasive and modular fashion without compromising downstream utility. Although individual fairness is a desirable property, it is far from sufficient to provide any ethical guarantees. For example, treating all individuals similarly badly does not conflict with individual fairness. Our method thus depends on the assumption that all involved parties act reasonably. That is, the data regulator needs to take all ethical aspects and future societal consequences into consideration when designing the similarity property. However, even a diligent data regulator may unconsciously encode biases in the similarity measure. Moreover, our approach breaks down with an adversarial data producer that either explicitly learns a discriminatory representation or simply fails to respect the defined similarity notion. Finally, the case where the data consumer acts adversarially has been investigated in previous work [9] and can be mitigated to some extent.",Broader Impact,230,12,,,FALSE,FALSE,FALSE,Learning Certified Individually Fair Representations,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Anian Ruoss', ' Mislav Balunovic', ' Marc Fischer', ' Martin Vechev']","{'ETH Zurich', 'ETH Zurich, Switzerland'}",1,0,0,{'Switzerland'}
Part-dependent Label Noise: Towards Instance-dependent Label Noise,"Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, Masashi Sugiyama",Part-dependent Label Noise: Towards Instance-dependent Label Noise,5607fe8879e4fd269e88387e8cb30b7e,https://proceedings.neurips.cc/paper/2020/file/5607fe8879e4fd269e88387e8cb30b7e-Paper.pdf,"Instance-dependent label noise is ubiquitous in the era of big data, which poses huge reliability threats for the traditional supervised learning algorithms. The instance-dependent label noise is more general and more realistic than instance-independent label noise, but is hard to learn without any assumption. How to model such noise and reduce its side-effect should be considered by both research and industry communities. This research copes with instance-dependent label noise based on the part-dependence assumption. This assumption is milder and more practical. It is also supported by lots of evidences as stated in the paper. Outcomes of this research will promote the understanding of this kind of label noise and largely fills the gap between instance-independent and instance-dependent  transition matrices. Open source algorithms and codes will benefit science, society, and the economy internationally through the applications to analyzing social, business, and health data. The research may greatly benefit practitioners in industry communities, where large amounts of noisily labeled data are available. However, currently, the majority of machine learning applications are designed to fit high-quality labeled data. This research will improve tolerance for the errors of annotation and make cheap datasets with label noise be used effectively. However, inevitably, this research may have a negative impact on the jobs of annotators. The proposed method exploits the part-dependent transition matrices to approximate the instance- dependent transition matrix. If the part-dependent transition matrices are poorly learned, the instance- dependent transition matrix will be inaccurate. The classification performance of models therefore may be compromised. The proposed method does not leverage any bias in the data.",Broader Impact,260,16,,,FALSE,FALSE,FALSE,Part-dependent Label Noise: Towards Instance-dependent Label Noise,Algorithms -> Semi-Supervised Learning,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,"{'RIKEN / University of Tokyo', 'RIKEN', 'HKBU / RIKEN', 'Xidian University', 'University of Sydney', 'University of Melbourne', 'The University of Sydney / Xidian University', 'The University of Sydney'}",1,0,0,"{'Japan', 'Australia', 'China'}"
Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization,"Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, H. Vincent Poor",Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization,564127c03caab942e503ee6f810f54fd,https://proceedings.neurips.cc/paper/2020/file/564127c03caab942e503ee6f810f54fd-Paper.pdf,"The future of machine learning lies in moving both data collection as well as model training to the edge. This nascent research field called federated learning considers a large number of resource- constrained devices such as cellphones or IoT sensors that collect training data from their environment. Due to limited communication capabilities as well as privacy concerns, these data cannot be directly sent over to the cloud. Instead, the nodes locally perform a few iterations of training and only send the resulting model to the cloud. In this paper, we develop a federated training algorithm that is system-aware (robust and adaptable to communication and computation variabilities by allowing heterogeneous local progress) and data-aware (can handle skews in the size and distribution of local training data by correcting model aggregation scheme). This research has the potential to democratize machine learning by transcending the current centralized machine learning framework. It will enable lightweight mobile devices to cooperatively train a common machine learning model while maintaining control of their training data.",Broader Impact,168,7,,,FALSE,FALSE,FALSE,Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization,Optimization,Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Jianyu Wang', ' Qinghua Liu', ' Hao Liang', ' Gauri Joshi', ' Vincent Poor']","{'Princeton University', 'Carnegie Mellon University'}",1,0,0,{'USA'}
An Improved Analysis of  (Variance-Reduced) Policy Gradient and Natural Policy Gradient Methods,"Yanli Liu, Kaiqing Zhang, Tamer Basar, Wotao Yin",An Improved Analysis of (Variance-Reduced) Policy Gradient and Natural Policy Gradient Methods,56577889b3c1cd083b6d7b32d32f99d5,https://proceedings.neurips.cc/paper/2020/file/56577889b3c1cd083b6d7b32d32f99d5-Paper.pdf,"The results of this paper improves the performance of policy-gradient methods for reinforcement learning, as well as our understanding to the existing methods. Through reinforcement learning, our study will also benefit several research communities such as machine learning and robotics. We do not believe that the results in this work will cause any ethical issue, or put anyone at a disadvantage in our society.",Broader Impact,64,3,,,FALSE,FALSE,FALSE,An Improved Analysis of  (Variance-Reduced) Policy Gradient and Natural Policy Gradient Methods,Reinforcement Learning and Planning,Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Reinforcement learning and planning,"['Yanli Liu', ' Kaiqing Zhang', 'Champaign', ' Tamer Basar', ' Wotao Yin']","{'UCLA', 'University of Illinois at Urbana-Champaign', 'UIUC', 'Alibaba US, DAMO Academy'}",1,1,1,"{'USA', 'China'}"
Geometric Exploration for Online Control,"Orestis Plevrakis, Elad Hazan",Geometric Exploration for Online Control,565e8a413d0562de9ee4378402d2b481,https://proceedings.neurips.cc/paper/2020/file/565e8a413d0562de9ee4378402d2b481-Paper.pdf,This work does not present any foreseeable societal consequence.,7 Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Geometric Exploration for Online Control,Theory -> Control Theory,Algorithms -> Bandit Algorithms; Algorithms -> Online Learning; Reinforcement Learning and Planning -> Exploration,Theory (including computational and statistical analyses),"['Orestis Plevrakis', ' Elad Hazan']",{'Princeton University'},1,0,0,{'USA'}
Automatic Curriculum Learning through Value Disagreement,"Yunzhi Zhang, Pieter Abbeel, Lerrel Pinto",Automatic Curriculum Learning through Value Disagreement,566f0ea4f6c2e947f36795c8f58ba901,https://proceedings.neurips.cc/paper/2020/file/566f0ea4f6c2e947f36795c8f58ba901-Paper.pdf,"While recent advancements in Artificial Intelligence (AI) provide a lot of potential opportunities to create products such as in elderly care, medical consultant and surgery assistant, autonomous devices that keep the supply chain sustainable under extreme working conditions or during pandemic, etc. It also provides tools that utilize the availability of large amount of data today, with the end-goal of improving our quality of life. There are however multiple possible negative consequences that we must be aware of: (i) training neural networks is typically associated with large energy consumption that is harmful to the environment, (ii) the significant computation resource requirement prevents many researchers from accessing state-of-the-art research, and (iii) in the field of RL in particular, algorithms typically require a long duration of interaction with the environments, which could further introduce a prohibitive monetary cost when deployed on physical robotic environments. In this paper, we focus on improving sample efficiency when training a universal agent that can perform a range of tasks. Furthermore, VDS is accessible to a broad range of researchers (even those without access to GPUs) and leaves a much smaller carbon footprint than competing methods. In fact, all of our experiments using VDS are run on a single CPU. It is fair to say that even with the result of this paper, Deep RL agents are far from being applicable to complex problems in real life and being widely accessible to the public. Regardless, we believe this paper provides progress and contributes to the goal of making reliable robotic applications. Along this process we are aware that evaluating robot safety is a crucial part of the consideration. Therefore rather than exclusively focusing on developing state-of-the-art algorithms, we draw attention to complementary research on safety [2, 22].",Broader Impact,290,10,,,FALSE,FALSE,FALSE,Automatic Curriculum Learning through Value Disagreement,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Exploration,,"['Yunzhi Zhang', ' Pieter Abbeel', ' Lerrel Pinto']","{'Berkeley Artificial Intelligence Research Lab', 'NYU/Berkeley'}",1,0,0,{'USA'}
MRI Banding Removal via Adversarial Training,"Aaron Defazio, Tullie Murrell, Michael Recht",MRI Banding Removal via Adversarial Training,567b8f5f423af15818a068235807edc0,https://proceedings.neurips.cc/paper/2020/file/567b8f5f423af15818a068235807edc0-Paper.pdf,"The use of machine learning in medical imaging raises a number of ethical and societal considerations. The benefits to the use of our method are clear; images produced using our method have fewer image artifacts than standard reconstructions. Our method, used in combination with current machine- learning based reconstruction methods, has the potential to significantly reduce time spent in MRI scanners, and the associated cost of scanning. This benefits both patients and medical professionals. In theory, the removal of the banding artifacts may lead to the occlusion of fine anatomical detail that would otherwise be present and useful for diagnosis. Our evaluations by radiologists are strong evidence that the method does not remove detail, but we believe a larger study directly aimed at determining differences in diagnosis would be required to establish this. It’s not a-priori certain that any method of banding removal will reduce detail, since the ground truth does not have banding, the use of a banding removal method is just a use of prior knowledge in the Bayesian sense. Machine learning approaches to MRI reconstruction are potentially prone to biases in the training data. If anatomy outside of the norms of the training data is encountered, the reconstruction may not be accurate. When using our proposed approach, the same considerations are necessary as for any application of machine learning in medical imaging. At a minimum the model must be tested for robustness to outlier examples.",Broader Impact Statement,238,11,,,FALSE,FALSE,FALSE,MRI Banding Removal via Adversarial Training,Applications -> Health,Neuroscience and Cognitive Science -> Brain Imaging,,"['Aaron Defazio', ' Tullie Murrell', ' Michael Recht']","{'New York University School of Medicine', 'Facebook AI Research'}",1,1,1,{'USA'}
The NetHack Learning Environment,"Heinrich Küttler, Nantas Nardelli, Alexander Miller, Roberta Raileanu, Marco Selvatici, Edward Grefenstette, Tim Rocktäschel",The NetHack Learning Environment,569ff987c643b4bedf504efda8f786c2,https://proceedings.neurips.cc/paper/2020/file/569ff987c643b4bedf504efda8f786c2-Paper.pdf,"To bridge the gap between the constrained world of video and board games, and the open and unpredictable real world, there is a need for environments and tasks which challenge the limits of current Reinforcement Learning (RL) approaches. Some excellent challenges have been put forth over the years, demanding increases in the complexity of policies needed to solve a problem or scale needed to deal with increasingly photorealistic, complex environments. In contrast, our work seeks to be extremely fast to run while still testing the generalization and exploration abilities of agents in an environment which is rich, procedurally generated, and in which reward is sparse. The impact of solving these problems with minimal environment-specific heuristics lies in the development of RL algorithms which produce sample efficient, robust, and general policies capable of more readily dealing with the uncertain and changing dynamics of “real world” environments. We do not solve these problems here, but rather provide the challenge and the testbed against such improvements can be produced and evaluated. Auxiliary to this, and in line with growing concerns that progress in Deep RL is more the result of industrial labs having privileged access to the resources required to run environments and agents on a massive scale, the environment presented here is computationally cheap to run and to collect data in. This democratizes access for researchers in more resource-constrained labs, while not sacrificing the difficulty and richness of the environment. We hope that as a result of this, and of the more general need to develop sample-efficient agents with fewer data, the environmental impact of research using our environment will be reduced compared to more visually sophisticated ones.",6 Broader Impact,276,8,,,FALSE,FALSE,FALSE,The NetHack Learning Environment,"Data, Challenges, Implementations, and Software -> Virtual Environments",Reinforcement Learning and Planning,Reinforcement learning and planning,"['Heinrich Küttler', ' Nantas Nardelli', ' Alexander Miller', ' Roberta Raileanu', ' Marco Selvatici', ' Edward Grefenstette', ' Tim Rocktäschel']","{'University College London Facebook AI Research', 'DeepMind', 'NYU', 'Facebook AI Research', 'Imperial College London', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
Language and Visual Entity Relationship Graph for Agent Navigation,"Yicong Hong, Cristian Rodriguez, Yuankai Qi, Qi Wu, Stephen Gould",Language and Visual Entity Relationship Graph for Agent Navigation,56dc0997d871e9177069bb472574eb29,https://proceedings.neurips.cc/paper/2020/file/56dc0997d871e9177069bb472574eb29-Paper.pdf,"The R2R [3] and R4R [17] datasets applied in our research contain a large number of photos of indoor environments, freely available under license from Matterport3D. None of the photos contain recognizable individuals. All experiments are performed on the Matterport3D Simulator [4], which are safe and confidential. This research is at the early stages of pushing towards robots that follows human instructions. In the future, if a such robot is implemented in real-world, it could benefit the society by assisting people to finish daily work. There are minimal ethical, privacy or safety concerns.",Broader Impact,93,6,,,FALSE,FALSE,FALSE,Language and Visual Entity Relationship Graph for Agent Navigation,Applications -> Visual Question Answering,Applications -> Computer Vision; Applications -> Natural Language Processing,Vision and Language,"['Yicong Hong', ' Cristian Rodriguez', ' Yuankai Qi', ' Qi Wu', ' Stephen Gould']","{'University of Adelaide ', 'ANU', 'Australian National University', 'University of Adelaide'}",1,0,0,{'Australia'}
ICAM: Interpretable Classification via Disentangled Representations and Feature Attribution Mapping,"Cher Bass, Mariana da Silva, Carole Sudre, Petru-Daniel Tudosiu, Stephen Smith, Emma Robinson",ICAM: Interpretable Classification via Disentangled Representations and Feature Attribution Mapping,56f9f88906aebf4ad985aaec7fa01313,https://proceedings.neurips.cc/paper/2020/file/56f9f88906aebf4ad985aaec7fa01313-Paper.pdf,"There is growing evidence that deep learning tools have the potential to improve the speed of review of medical images and that their sensitivity to complex high-dimensional textures can (in some cases) improve their efficacy relative to radiographers [19]. A recent study by Google DeepMind [31] suggested that deep learning systems could perform the role of a second-reader of breast cancer screenings to improve the precision of diagnosis relative to a single-expert (which is standard clinical practice within the US). For brain disorders the opportunities and challenges for AI are more significant since the features of the disease are commonly subtle, presentations highly variable (creating greater challenges for physicians), and the datasets are much smaller in size in comparison to natural image tasks. The additional pitfalls that are common in deep learning algorithms [46], including the so called ‘black box’ problem where it is unknown why a certain prediction is made, lead to further uncertainly and mistrust for clinicians when making decisions based on the results of these models. We developed a novel framework to address this problem by deriving a disease map, directly from a class prediction space, which highlights all class relevant features in an image. Our objective is to demonstrate on a theoretical level, that the development of more medically interpretable models is feasible, rather than developing a diagnostic tool to be used in the clinic. However, in principle, these types of maps may be used by physicians as an additional source of data in addition to mental exams, physiological tests and their own judgement to support diagnosis of complex conditions such as Alzheimer’s, autism, and schizophrenia. This may have significant societal impact as early diagnosis can improve the effectiveness of interventional treatment. Further, our model, ICAM, presents a specific advantage as it provides a ‘probability’ of belonging to a class along with a visualisation, supporting better understanding of the phenotypic variation of these diseases, which may improve mechanistic or prognostic modelling of these diseases. There remain ethical challenges as errors in prediction could influence clinicians towards wrong diagnoses and incorrect treatment which could have very serious consequences. Further studies have shown clear racial differences in brain structure [41, 44] which if not sampled correctly could lead to bias in the model and greater uncertainty for ethnic minorities [39]. These challenges would need to be addressed before any consideration of clinical translation. Clearly, the uncertainties in the model should be transparently conveyed to any end user, and in this respect the advantages of ICAM relative to its predecessors are plain to see.",Broader Impact,425,13,,,FALSE,FALSE,FALSE,ICAM: Interpretable Classification via Disentangled Representations and Feature Attribution Mapping,"Deep Learning -> Visualization, Interpretability, and Explainability",Algorithms -> Classification; Deep Learning -> Adversarial Networks; Deep Learning -> CNN Architectures; Deep Learning -> Generative Models; Neuroscience and Cognitive Science -> Brain Imaging,Deep learning,"['Cher Bass', ' Mariana da Silva', ' Carole Sudre', 'Daniel Tudosiu', ' Stephen Smith', ' Emma Robinson']",{'FMRIB Centre - University of Oxford'},1,0,0,{'UK'}
Spectra of the Conjugate Kernel and Neural Tangent Kernel for linear-width neural networks,"Zhou Fan, Zhichao Wang",Spectra of the Conjugate Kernel and Neural Tangent Kernel for Linear-Width Neural Networks,572201a4497b0b9f02d4f279b09ec30d,https://proceedings.neurips.cc/paper/2020/file/572201a4497b0b9f02d4f279b09ec30d-Paper.pdf,"This work performs theoretical analysis that aims to extend our understanding of training and generalization in multi-layer neural networks. A better theoretical understanding of training and generalization in these models may ultimately help us to (1) understand the mechanisms by which social biases may be propagated by artificial systems, and prevent this from occurring, and (2) increase the robustness and fault-tolerance of artificial systems built on such models.",Broader Impact,68,2,,,FALSE,FALSE,FALSE,Spectra of the Conjugate Kernel and Neural Tangent Kernel for linear-width neural networks,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Spectral Methods; Theory -> High-Dimensional Inference; Theory -> Large Deviations and Asymptotic Analysis,Theory (including computational and statistical analyses),"['Zhou Fan', ' Zhichao Wang']","{'UC San Diego', 'Yale Univ'}",1,0,0,{'USA'}
No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium,"Andrea Celli, Alberto Marchesi, Gabriele Farina, Nicola Gatti",No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium,5763abe87ed1938799203fb6e8650025,https://proceedings.neurips.cc/paper/2020/file/5763abe87ed1938799203fb6e8650025-Paper.pdf,"Correlated equilibria provide an appropriate solution concept for coordination problems in which agents have arbitrary utilities, and may work towards different objectives. The study of uncoupled dynamics converging to correlated equilibria in problems with sequential actions and hidden informa- tion lays new theoretical foundations for multi-agent reinforcement learning problems. Most of the work in the multi-agent reinforcement learning community either studies fully competitive settings, where agents play selfishly to reach a Nash equilibrium, or fully cooperative scenarios in which agents have the exact same goals. Our work could enable techniques that are in-between these two extremes: agents have arbitrary objectives, but coordinate their actions towards an equilibrium with some desired properties. As we argued in the paper, the social welfare that can be attained via a Nash equilibrium (that is, by playing selfishly) may be significantly lower than what can be achieved via a correlated equilibrium. We provided some empirical evidences that ICFR computes equilibria which attain a social welfare ‘not too far’ from the optimal one. This could have an arguably positive societal impact when applied to real economic problems. However, further research in this direction is required to prevent ‘winner-takes-all’ scenarios in problems with an unbalanced reward structure where equilibria with high social welfare may just award players with the largest utilities at the expense of the others. This could provide a way to reach fair equilibria both in theory and in practice.",Broader Impact,235,9,,,FALSE,FALSE,FALSE,No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium,Theory -> Game Theory and Computational Economics,,Game Theory,"['Andrea Celli', ' Alberto Marchesi', ' Gabriele Farina', ' Nicola Gatti']","{'Politecnico di Milano', 'Carnegie Mellon University'}",1,0,0,"{'Italy', 'USA'}"
Estimating weighted areas under the ROC curve,"Andreas Maurer, Massimiliano Pontil",Estimating weighted areas under the ROC curve,5781a2637b476d781eb3134581b32044,https://proceedings.neurips.cc/paper/2020/file/5781a2637b476d781eb3134581b32044-Paper.pdf,A solid mathematical basis is beneficial to the development of practical statistical methods. We believe that the present work improves the understanding of ROC-curves and the optimization of score functions used in machine learning and medical diagnostics.,Broader Impact,37,2,FALSE,FALSE,FALSE,FALSE,FALSE,Estimating weighted areas under the ROC curve,Theory -> Statistical Learning Theory,Theory -> Frequentist Statistics; Theory -> Models of Learning and Generalization,,"['Andreas Maurer', ' Massimiliano Pontil']","{'Istituto Italiano di Tecnologia', 'Istituto Italiano di Tecnologia & University College London'}",1,0,0,"{'UK', 'Italy'}"
Can Implicit Bias Explain Generalization? Stochastic Convex Optimization as a Case Study,"Assaf Dauber, Meir Feder, Tomer Koren, Roi Livni",Can Implicit Bias Explain Generalization? Stochastic Convex Optimization as a Case Study,57cd30d9088b0185cf0ebca1a472ff1d,https://proceedings.neurips.cc/paper/2020/file/57cd30d9088b0185cf0ebca1a472ff1d-Paper.pdf,There are no foreseen ethical or societal consequences for the research presented herein.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Can Implicit Bias Explain Generalization? Stochastic Convex Optimization as a Case Study,Theory -> Statistical Learning Theory,Optimization -> Convex Optimization; Optimization -> Stochastic Optimization; Theory; Theory -> Models of Learning and Generalization ; Theory -> Regularization,Theory (including computational and statistical analyses),"['Assaf Dauber', ' Meir Feder', ' Tomer Koren', ' Roi Livni']","{'Google', 'Tel-Aviv University', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
Generalized Hindsight for Reinforcement Learning,"Alexander Li, Lerrel Pinto, Pieter Abbeel",Generalized Hindsight for Reinforcement Learning,57e5cb96e22546001f1d6520ff11d9ba,https://proceedings.neurips.cc/paper/2020/file/57e5cb96e22546001f1d6520ff11d9ba-Paper.pdf,"Our work investigates how to perform sample-efficient multi-task reinforcement learning. Generally, this goes against the trend of larger models and compute-hungry algorithms, such as state-of-the-art results in Computer Vision [12], NLP [8], and RL [69]. This will have several benefits in the short term. Better sample efficiency decreases the training time required for researchers to run experiments and for engineers to train models for production. This reduces the carbon footprint of the training process, and increases the speed at which scientists can iterate and improve on their ideas. Our algorithm enables autonomous agents to learn to perform a wide variety of tasks at once, which widens the range of feasible applications of reinforcement learning. Being able to adjust the energy consumption, safety priority, or other reward hyperparameters will allow these agents to adapt to changing human preferences. For example, autonomous cars may be able to learn to how avoid obstacles and adjust their driving style based on passenger needs. Although our work helps make progress towards generalist RL systems, reinforcement learning remains impractical for most real-world problems. Reinforcement learning capabilities may drastically increase in the future, however, with murkier impacts. RL agents operating in the real world could improve the world by automating elderly care, disaster relief, cleaning and disinfecting, manufactur- ing, and agriculture. These agents could free people from menial, physically taxing, or dangerous occupations. However, as with most technological advances, developments in reinforcement learning could exacerbate income inequality, far more than the industrial or digital revolutions have, as profits from automation go to a select few. Reinforcement learning agents are also susceptible to reward misspecification, optimizing for an outcome that we do not truly want. Police robots instructed to protect the public may achieve this end by enacting discriminatory and oppressive policies, or doling out inhumane punishments. Autonomous agents also increase the technological capacity for warfare, both physical and digital. Escalating offensive capabilities and ceding control to potentially uninterpretable algorithms raises the risk for international conflict to end in human extinction. Further work in AI alignment, interpretability, and safety is necessary to ensure that the benefits of strong reinforcement learning systems outweigh their risks.",Broader Impact,356,18,,,FALSE,FALSE,FALSE,Generalized Hindsight for Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Multitask and Transfer Learning; Applications -> Robotics,Reinforcement learning and planning,"['Alexander Li', ' Lerrel Pinto', ' Pieter Abbeel']","{'UC Berkeley', 'NYU/Berkeley'}",1,0,0,{'USA'}
Critic Regularized Regression,"Ziyu Wang, Alexander Novikov, Konrad Zolna, Josh S. Merel, Jost Tobias Springenberg, Scott E. Reed, Bobak Shahriari, Noah Siegel, Caglar Gulcehre, Nicolas Heess, Nando de Freitas",Critic Regularized Regression,588cb956d6bbe67078f29f8de420a13d,https://proceedings.neurips.cc/paper/2020/file/588cb956d6bbe67078f29f8de420a13d-Paper.pdf,"RL methods represent a unique solution principle that could lead to substantial progress in many real-world applications that are beneficial to society, such as the development of assistive robotic technologies for the disabled. As online RL and especially exploration is difficult (and sometimes dangerous) in the real world, offline RL provides a path for RL methods to be more broadly applied in practice. This paper introduces a new algorithm that could lead to improved performance on some real world tasks. As with all algorithms that can be used to automate decision making policies, however, offline RL methods could be used for applications with a negative impact on society. Since offline RL algorithms require existing datasets, we should also be vigilant when collecting datasets so as to avoid bias and prejudices.",Broader Impact,130,5,,,FALSE,FALSE,FALSE,Critic Regularized Regression,Deep Learning,Reinforcement Learning and Planning,Reinforcement learning and planning,"['Ziyu Wang', ' Alexander Novikov', ' Konrad Zolna', ' Josh Merel', ' Jost Tobias Springenberg', ' Scott Reed', ' Bobak Shahriari', ' Noah Siegel', ' Caglar Gulcehre', ' Nicolas Heess', ' Nando de Freitas']","{'DeepMind', 'Google DeepMind', 'Deepmind'}",0,1,0,{'UK'}
Boosting Adversarial Training with Hypersphere Embedding,"Tianyu Pang, Xiao Yang, Yinpeng Dong, Taufik Xu, Jun Zhu, Hang Su",Boosting Adversarial Training with Hypersphere Embedding,5898d8095428ee310bf7fa3da1864ff7,https://proceedings.neurips.cc/paper/2020/file/5898d8095428ee310bf7fa3da1864ff7-Paper.pdf,"When deploying machine learning methods into the practical systems, the adversarial vulnerability can cause a potential security risk, as well as the negative impact on the crisis of confidence by the public. To this end, this inherent defect raises the requirements for reliable, general, and lightweight strategies to enhance the model robustness against malicious, especially adversarial attacks. In this work, we provide a simple and efficient way to boost the robustness of the adversarially trained models, which contributes to the modules of constructing more reliable systems in different tasks.",Broader Impact,89,3,,,FALSE,FALSE,FALSE,Boosting Adversarial Training with Hypersphere Embedding,Algorithms -> Adversarial Learning,Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Tianyu Pang', ' Xiao Yang', ' Yinpeng Dong', ' Taufik Xu', ' Hang Su', ' Jun Zhu']","{'Tsinghua Univiersity', 'Tsinghua University'}",1,0,0,{'China'}
Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs,"Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, Danai Koutra",Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs,58ae23d878a47004366189884c2f8440,https://proceedings.neurips.cc/paper/2020/file/58ae23d878a47004366189884c2f8440-Paper.pdf,"Homophily and heterophily are not intrinsically ethical or unethical—they are both phenomena existing in the nature, resulting in the popular proverbs “birds of a feather flock together” and “opposites attract”. However, many popular GNN models implicitly assume homophily; as a result, if they are applied to networks that do not satisfy the assumption, the results may be biased, unfair, or erroneous. In some applications, the homophily assumption may have ethical implications. For example, a GNN model that intrinsically assumes homophily may contribute to the so-called “filter bubble” phenomenon in a recommendation system (reinforcing existing beliefs/views, and downplaying the opposite ones), or make minority groups less visible in social networks. In other cases, a reliance on homophily may hinder scientific progress. Among other domains, this is critical for applying GNN models to molecular and protein structures, where the connected nodes often belong to different classes, and thus successful methods will need to model heterophily successfully. Our work has the potential to rectify some of these potential negative consequences of existing GNN work. While our methodology does not change the amount of homophily in a network, moving beyond a reliance on homophily can be a key to improve the fairness, diversity and performance in applications using GNNs. We hope that this paper will raise more awareness and discussions regarding the homophily limitations of existing GNN models, and help researchers design models which have the power of learning in both homophily and heterophily settings.",Broader Impact,241,9,,,FALSE,FALSE,FALSE,Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs,Deep Learning,Algorithms; Algorithms -> Classification; Algorithms -> Relational Learning; Algorithms -> Semi-Supervised Learning,Graph-based learning methods,"['Jiong Zhu', ' Yujun Yan', ' Lingxiao Zhao', ' Mark Heimann', ' Leman Akoglu', ' Danai Koutra']","{'CMU', 'U Michigan', 'Carnegie Mellon University', 'University of Michigan'}",1,0,0,{'USA'}
Modeling Continuous Stochastic Processes with Dynamic Normalizing Flows,"Ruizhi Deng, Bo Chang, Marcus A. Brubaker, Greg Mori, Andreas Lehrmann",Modeling Continuous Stochastic Processes with Dynamic Normalizing Flows,58c54802a9fb9526cd0923353a34a7ae,https://proceedings.neurips.cc/paper/2020/file/58c54802a9fb9526cd0923353a34a7ae-Paper.pdf,"Time series models could be applied to a wide range of applications, including natural language processing, recommendation systems, traffic prediction, medical data analysis, forecasting, and others. Our research improves over the existing models on a particular type of data: irregular time series data. There are opportunities for applications using the proposed models for beneficial purposes, such as weather forecasting, pedestrian behavior prediction for self-driving cars, and missing healthcare data interpolation or prediction. We encourage practitioners to understand the impacts of using CTFP in particular real-world scenarios. One potential risk is that the capability of interpolation and extrapolation can be used in malicious ways. An adversary might be able to use the proposed model to infer private information given partial observations, which leads to privacy concerns. We would encourage further research to address this risk using tools like differential privacy.",Broader Impact Statement,139,7,,,FALSE,FALSE,FALSE,Modeling Continuous Stochastic Processes with Dynamic Normalizing Flows,Deep Learning -> Generative Models,Applications -> Time Series Analysis,Deep learning,"['Ruizhi Deng', ' Bo Chang', ' Marcus Brubaker', ' Greg Mori', ' Andreas Lehrmann']","{'Simon Fraser University', 'Borealis AI'}",1,1,1,{'Canada'}
Efficient Online Learning of Optimal Rankings: Dimensionality Reduction via Gradient Descent,"Dimitris Fotakis, Thanasis Lianeas, Georgios Piliouras, Stratis Skoulakis",Efficient Online Learning of Optimal Rankings: Dimensionality Reduction via Gradient Descent,5938b4d054136e5d59ada6ec9c295d7a,https://proceedings.neurips.cc/paper/2020/file/5938b4d054136e5d59ada6ec9c295d7a-Paper.pdf,"We are living in a world of abundance, where each individual is provided myriad of options in terms of available products and services (e.g. music selection, movies etc.). Unfortunately this overabundance makes the cost of exploring all of them prohibitively large. This problem is only compounded by the fast turn around of new trends at a seemingly ever increasing rate. Our algorithmic techniques provide a practically applicable methodology for managing this complexity. 2 In the subsequent figures the curves describing the performance of each algorithm are placed in the following top-down order i) Selecting a permutation uniformly at random , ii) Algorithm 2 , iii) Algorithm 4 and iv) Feige-Lovasz-Tetali algorithm [13].",Broader Impact,112,5,,,FALSE,FALSE,FALSE,Efficient Online Learning of Optimal Rankings: Dimensionality Reduction via Gradient Descent,Theory -> Hardness of Learning and Approximations,Algorithms -> Online Learning; Algorithms -> Ranking and Preference Learning; Optimization; Optimization -> Convex Optimization; Optimization -> Discrete Optimization; Theory -> Computational Learning Theory,Optimization Methods (continuous or discrete),"['Dimitris Fotakis', ' Thanasis Lianeas', ' Georgios Piliouras', ' Stratis Skoulakis']","{'Singapore University of Technology and Design', 'National Technical University of Athens'}",1,0,0,"{'Singapore', 'Greece'}"
Training Normalizing Flows with the Information Bottleneck for Competitive Generative Classification,"Lynton Ardizzone, Radek Mackowiak, Carsten Rother, Ullrich Köthe",Training Normalizing Flows with the Information Bottleneck for Competitive Generative Classification,593906af0d138e69f49d251d3e7cbed0,https://proceedings.neurips.cc/paper/2020/file/593906af0d138e69f49d251d3e7cbed0-Paper.pdf,"As our IB-INN is not bound to any particular application, and applies to settings that can in principle already be solved with existing methods, we foresee no societal advantages or dangers in terms of direct application. More generally, we think accurate uncertainty quantification plays an important role in a safe and productive use of AI.",Broader Impact,55,2,FALSE,TRUE,FALSE,FALSE,FALSE,Training Normalizing Flows with the Information Bottleneck for Competitive Generative Classification,Algorithms -> Density Estimation,Algorithms -> Classification; Applications -> Computer Vision,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Lynton Ardizzone', ' Radek Mackowiak', ' Carsten Rother', ' Ullrich Köthe']","{'Robert Bosch GmbH', 'University of Heidelberg', 'Heidelberg University'}",1,1,1,{'Germany'}
Detecting Hands and Recognizing Physical Contact in the Wild,"Supreeth Narasimhaswamy, Trung Nguyen, Minh Hoai Nguyen",Detecting Hands and Recognizing Physical Contact in the Wild,595373f017b659cb7743291e920a8857,https://proceedings.neurips.cc/paper/2020/file/595373f017b659cb7743291e920a8857-Paper.pdf,"We can broadly classify hand contact estimation methods into two types, contact recognition, and contact detection. While the contact recognition methods categorize hand instances into pre-defined states, contact detection methods aim to detect contact objects and contact areas. In our work, we investigated hand contact recognition, particularly in unconstrained images. We believe that our work can help the community accelerate the research in this area and shed light on contact detection. While our dataset is quality controlled and beneficial to the community, biases can be present in the sources from which we collected the dataset. For example, the dataset might not be representative of all demographics. As such, applications that use our dataset can inherit such biases, and the community should be aware of this.",7 Broader Impact,125,7,,,TRUE,TRUE,FALSE,Detecting Hands and Recognizing Physical Contact in the Wild,Applications -> Computer Vision,Applications -> Object Detection; Applications -> Object Recognition,Vision,"['Supreeth Narasimhaswamy', ' Trung Nguyen', ' Minh Hoai Nguyen']","{'Stony Brook University', 'VinAI'}",1,1,1,"{'USA', 'Vietnam'}"
On the Theory of Transfer Learning: The Importance of Task Diversity,"Nilesh Tripuraneni, Michael Jordan, Chi Jin",On the Theory of Transfer Learning: The Importance of Task Diversity,59587bffec1c7846f3e34230141556ae,https://proceedings.neurips.cc/paper/2020/file/59587bffec1c7846f3e34230141556ae-Paper.pdf,"As a theoretical paper we do not foresee our work directly having any societal consequences. However, transfer learning is a tool increasingly used in practical machine learning applications. Theoretical explorations related to transfer learning may help provide frameworks through which to reason about, and design, safer and more reliable algorithms.",Broader Impact,50,3,TRUE,TRUE,FALSE,FALSE,FALSE,On the Theory of Transfer Learning: The Importance of Task Diversity,Theory -> Statistical Learning Theory,Theory -> Models of Learning and Generalization,,"['Nilesh Tripuraneni', ' Michael Jordan', ' Chi Jin']","{'UC Berkeley', 'Princeton University'}",1,0,0,{'USA'}
Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence Bounds for Optimal Adaptive Allocation with Multiple Plays and Markovian Rewards,Vrettos Moulos,Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence Bounds for Optimal Adaptive Allocation with Multiple Plays and Markovian Rewards,597c7b407a02cc0a92167e7a371eca25,https://proceedings.neurips.cc/paper/2020/file/597c7b407a02cc0a92167e7a371eca25-Paper.pdf,"This work touches upon a very old problem dating back to 1933 and the work of [39]. Therefore, we don’t anticipate any new societal impacts or ethical aspects, that are not well understood by now.",Statement of Broader Impact,35,2,TRUE,TRUE,FALSE,FALSE,FALSE,Finite-Time Analysis of Round-Robin Kullback-Leibler Upper Confidence Bounds for Optimal Adaptive Allocation with Multiple Plays and Markovian Rewards,Algorithms -> Bandit Algorithms,Theory -> Large Deviations and Asymptotic Analysis,Reinforcement learning and planning,['Vrettos Moulos'],{'UC Berkeley'},1,0,0,{'USA'}
Neural Star Domain as Primitive Representation,"Yuki Kawana, Yusuke Mukuta, Tatsuya Harada",Neural Star Domain as Primitive Representation,59a3adea76fadcb6dd9e54c96fc155d1,https://proceedings.neurips.cc/paper/2020/file/59a3adea76fadcb6dd9e54c96fc155d1-Paper.pdf,"A potential risk involved with NSD is that it can be extended to plagiarize 3D objects, such as furniture and appliance design etc. As our NSDN solely consists of very simple fully connected layers and mesh extraction processes, it is very fast and cost effective; one might be able to run our model on mobile devices with proper hardware optimization. This opens up more democratized 3D reconstruction, but it also comes with the possible risk of being applied to plagiarize the design of real world products by combination with 3D printers.",Broader impact,91,3,,,FALSE,FALSE,FALSE,Neural Star Domain as Primitive Representation,Applications -> Computer Vision,Deep Learning -> Generative Models,Vision,"['Yuki Kawana', ' Yusuke Mukuta', ' Tatsuya Harada']","{'The University of Tokyo / RIKEN', 'The University of Tokyo'}",1,0,0,{'Japan'}
Off-Policy Interval Estimation with Lipschitz Value Iteration,"Ziyang Tang, Yihao Feng, Na Zhang, Jian Peng, Qiang Liu",Off-Policy Interval Estimation with Lipschitz Value Iteration,59accb9fe696ce55e28b7d23a009e2d1,https://proceedings.neurips.cc/paper/2020/file/59accb9fe696ce55e28b7d23a009e2d1-Paper.pdf,"Off-policy interval evaluation not only can advise end-user to deploy new policy, but can also serve as an intermediate step for latter policy optimization. Our proposed methods also fill in the gap of theoretical understanding of Markov structure in Lipschitz regression. We current work stands as a contribution to the fundamental ML methodology, and we do not foresee potential negative impacts.",Broader Impact,61,3,FALSE,FALSE,TRUE,TRUE,FALSE,Off-Policy Interval Estimation with Lipschitz Value Iteration,Reinforcement Learning and Planning,"Applications -> Health; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Reinforcement Learning; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Reinforcement learning and planning,"['Ziyang Tang', ' Yihao Feng', ' Na Zhang', ' Jian Peng', ' Qiang Liu']","{'University of Illinois at Urbana-Champaign', 'Tsinghua University', 'UT Austin'}",1,0,0,"{'USA', 'China'}"
Inverse Rational Control with Partially Observable Continuous Nonlinear Dynamics,"Minhae Kwon, Saurabh Daptardar, Paul R. Schrater, Zachary Pitkow",Inverse Rational Control with Partially Observable Continuous Nonlinear Dynamics,5a01f0597ac4bdf35c24846734ee9a76,https://proceedings.neurips.cc/paper/2020/file/5a01f0597ac4bdf35c24846734ee9a76-Paper.pdf,"We have implemented IRC for neuroscience applications, but the core principles have value in other fields as well. We can view IRC as a form of Theory of Mind, whereby one agent (a neuroscientist) creates a model of another agent’s mind (for a behaving animal). Theory of Mind is a prominent component of human social interactions, and imputing rational motivations to actions provides a useful description of how people think [ 60, 61, 62]. Using IRC methods to provide a better understanding of people’s motivations could yield important insights for understanding and improving social and political interactions, as well as raising possible ethical concerns if used for manipulation. The design of agents interacting with humans would also benefit from being able to attribute rational strategies to others. For example, recent work uses a related approach to impute purpose to a neural network [16]. One important practical example is self-driving cars, which currently struggle to handle the perceived unpredictability of humans. While humans do indeed behave unpredictably, some of this may stem from ignorance of the rational computation that drives their actions. The IRC provides a framework for interpreting agents, and serves as a valuable tool for greater understanding of unifying principles of control.",Broader Impact,203,9,,,FALSE,FALSE,FALSE,Inverse Rational Control with Partially Observable Continuous Nonlinear Dynamics,Reinforcement Learning and Planning -> Reinforcement Learning,Neuroscience and Cognitive Science -> Cognitive Science; Neuroscience and Cognitive Science -> Neuroscience; Probabilistic Methods -> Bayesian Theory; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement learning and planning,"['Minhae Kwon', ' Saurabh Daptardar', ' Paul R Schrater', ' Zachary Pitkow']","{'Rice University, Baylor College of Medicine', 'University of Minnesota', 'Google', 'BCM/Rice'}",1,1,1,{'USA'}
Deep Statistical Solvers,"Balthazar Donon, Zhengying Liu, Wenzhuo LIU, Isabelle Guyon, Antoine Marot, Marc Schoenauer",Deep Statistical Solvers,5a16bce575f3ddce9c819de125ba0029,https://proceedings.neurips.cc/paper/2020/file/5a16bce575f3ddce9c819de125ba0029-Paper.pdf,"This work introduces an original approach to solving permutation-invariant problems defined on a graph. The proposed approach is agnostic w.r.t. the practical problem it is applied to. As such, no direct poor societal consequences of this work are to be feared. However, and this is an issue that goes beyond this particular work, it can be applied to critical industrial problems, as demonstrated with the power grid experiments we use to illustrate and validate the approach in Section 5.2: in such context, it is important to ensure by design ( i.e. , in the definition of the search space and the objective function) that the proper constraints are applied to avoid detrimental solutions. Being able to validate the obtained solution is a problem-specific issue, but validating the whole approach is the holy grail of such work, and is by now out of reach.",Broader Impact,143,6,,,FALSE,FALSE,FALSE,Deep Statistical Solvers,Deep Learning -> Supervised Deep Networks,Algorithms -> Few-Shot Learning; Applications -> Network Analysis,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Balthazar Donon', ' Zhengying Liu', ' Wenzhuo LIU', ' Isabelle Guyon', ' Antoine Marot', ' Marc Schoenauer']","{'INRIA', 'RTE', 'Inria Paris Saclay'}",1,0,0,{'France'}
Distributionally Robust Parametric Maximum Likelihood Estimation,"Viet Anh Nguyen, Xuhui Zhang, Jose Blanchet, Angelos Georghiou",Distributionally Robust Parametric Maximum Likelihood Estimation,5a29503a4909fcade36b1823e7cebcf5,https://proceedings.neurips.cc/paper/2020/file/5a29503a4909fcade36b1823e7cebcf5-Paper.pdf,"This is a theoretical contribution which relates to arguably the single most popular class of statistical estimators, namely, maximum likelihood estimators. We provide a novel view of these types of estimators, by introducing robustness in their design. This robustness layer enables the use of these types of estimators in the context of (adversarially) contaminated data, which has been a long- standing issue in research. We believe that this paper makes an important contribution to multiple areas, including but not limited to: adversarial machine learning, convex optimization, distributionally robust optimization, and game theory. The fact that our proposed estimator can be computed efficiently by state-of-the-art solvers sheds light on its wide applicability in general academia and industry setting. For example, our robust maximum likelihood estimators could potentially be used in situations in which data sets of different types of domains are combined to estimate key performance indicators for decision makers (e.g. collecting data from different types of demand functions in a business setting, or different social impact measures in a public policy setting). This enables the decision maker to design strategies that are robust against changes in business or public circumstances, thereby creating a positive social impact. In addition, with regard to human resource development, this work will be integrated as a part of the tools that we intend to teach in Ph.D. courses, thus positively impacting the training of the workforce in academia and general industries. Questions remaining for issues like ethical implications of our estimator, which we intend to explore in the future under the framework such as differential privacy and algorithmic fairness.",Broader Impact,264,9,,,TRUE,TRUE,FALSE,Distributionally Robust Parametric Maximum Likelihood Estimation,Optimization -> Convex Optimization,Algorithms -> Regression,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Viet Anh Nguyen', ' Xuhui Zhang', ' Jose Blanchet', ' Angelos Georghiou']","{'Stanford University', 'University of Cyprus'}",1,0,0,"{'Cyprus', 'USA'}"
Secretary and Online Matching Problems with Machine Learned Advice,"Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, Pavel Kolev",Secretary and Online Matching Problems with Machine Learned Advice,5a378f8490c8d6af8647a753812f6e31,https://proceedings.neurips.cc/paper/2020/file/5a378f8490c8d6af8647a753812f6e31-Paper.pdf,"Matching problems play a very important role in crucial real-world situations, e.g., when assigning donor organs to patients in need, or assigning ventilators to hospitals during a lung virus pandemic. Although machine learning algorithms usually perform quite well on these type of problems, because of their critical importance, often a worst-case guarantee is paramount. Our contribution follows a line of work that combines the power of machine learning with worst-case theoretical bounds to give a performance guarantee also for the rare instances on which machine learning algorithms are subpar.",Broader Impact,89,3,,,TRUE,TRUE,FALSE,Secretary and Online Matching Problems with Machine Learned Advice,Theory,Theory -> Data-driven Algorithm Design; Theory -> Game Theory and Computational Economics,Theory (including computational and statistical analyses),"['Antonios Antoniadis', ' Themis Gouleakis', ' Pieter Kleer', ' Pavel Kolev']","{'Max Planck Institute for Informatics', 'Max-Planck-Institut für Informatik', 'University of Cologne'}",1,0,0,{'Germany'}
Deep Transformation-Invariant Clustering,"Tom Monnier, Thibault Groueix, Mathieu Aubry",Deep Transformation-Invariant Clustering,5a5eab21ca2a8fef4af5e35709ecca15,https://proceedings.neurips.cc/paper/2020/file/5a5eab21ca2a8fef4af5e35709ecca15-Paper.pdf,"The impact of clustering mainly depends on the data it is applied on. For instance, adding structure in user data can raise ethical concerns when users are assimilated to their cluster, and receive targeted advertisement and newsfeed. However, this is not specific to our method and can be said of any clustering algorithm. Also note that while our clustering can be applied for example to data from social media, the visual interpretation of the clusters it returns via the cluster centers respects privacy much better than showing specific examples from each cluster. Because our method provides highly interpretable results, it might bring increased understanding of clustering algorithm results for the broader public, which we think may be a significant positive impact.",Broader Impact,121,5,,,FALSE,FALSE,FALSE,Deep Transformation-Invariant Clustering,Algorithms -> Clustering,Applications -> Computer Vision; Deep Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Tom Monnier', ' Thibault Groueix', ' Mathieu Aubry']","{'École des ponts Paristech', 'École des ponts ParisTech'}",1,0,0,{'France'}
"Overfitting Can Be Harmless for Basis Pursuit, But Only to a Degree","Peizhong Ju, Xiaojun Lin, Jia Liu","Overfitting Can Be Harmless for Basis Pursuit, But Only to a Degree",5a66b9200f29ac3fa0ae244cc2a51b39,https://proceedings.neurips.cc/paper/2020/file/5a66b9200f29ac3fa0ae244cc2a51b39-Paper.pdf,"Understanding the generalization power of heavily over-parameterized networks is one of the most foundation aspects of deep learning. By understanding the double descent of generalization errors for Basis Pursuit (BP) when overfitting occurs, our work advances the understanding of how superior generalization power can arise for overfitting solutions. Such an understanding will contribute to laying a solid theoretical foundation of deep learning, which in turn may lead to practical guidelines in applying deep learning in diverse fields such as image processing and natural languages processing.  Controlling the 1 -norm also plays a fundamental role in optimization with sparse models, which have found important applications in, e.g., compressive sensing and matrix completion. Without thoroughly studying the overparameterized regime of BP (which minimizes 1 -norm while overfitting the data), the theory of double descent remains incomplete. The insights revealed via our proof techniques in Section 4 (i.e., the relationship between the error of fitting data and the error of fitting only noise) not only help to analyze the double descent of BP, but may also be of value to other more general models. Potential negative impacts: Our theoretical results in this paper are the first step towards understanding the double descent of BP, and should be used with care. In particular, there is still a significant gap between our upper and lower bounds. Thus, the significance of our theories lies more in revealing the general trend rather than precise characterization of double descent. Further, the Gaussian model may also be a limiting factor. Therefore, more efforts will be needed to sharpen the bounds and generalize the results for applications in practice.",Broader Impact,269,11,,,FALSE,FALSE,FALSE,"Overfitting Can Be Harmless for Basis Pursuit, But Only to a Degree",Theory -> Models of Learning and Generalization,Algorithms -> Regression; Theory -> Regularization,Theory (including computational and statistical analyses),"['Peizhong Ju', ' Xiaojun Lin', ' Jia Liu']","{'The Ohio State University', 'Purdue University'}",1,0,0,{'USA'}
Improving Generalization in Reinforcement Learning with Mixture Regularization,"KAIXIN WANG, Bingyi Kang, Jie Shao, Jiashi Feng",Improving Generalization in Reinforcement Learning with Mixture Regularization,5a751d6a0b6ef05cfe51b86e5d1458e6,https://proceedings.neurips.cc/paper/2020/file/5a751d6a0b6ef05cfe51b86e5d1458e6-Paper.pdf,"Reinforcement learning has been applied to various domains for learning decision-making agents, including games, intelligent control, robotics, finance and data analytics. Reinforcement learning tends to suffer poor generalization performance when the trained agent is deployed in a new environ- ment. This work proposes a simple data augmentation based solution that substantially improves RL agents’ generalization performance. This work would have following positive influences in this field. The proposed method is simple and easy to deploy, and would improve generalization performance and robustness of RL agents in various environments. This will be inspiring for following research works, and also benefit deployment of RL agents in practice and help develop trustworthy agents. On the flip-over side, the effectiveness of the proposed method is only verified in the game domain. It remains unclear how it will perform in other domains like finance, where the data have different modalities. Improper deployment of the proposed method may even worsen the performance of the RL agents trained with the proposed method and hurt the quality of output decisions.",Broader Impact,172,9,,,FALSE,FALSE,FALSE,Improving Generalization in Reinforcement Learning with Mixture Regularization,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['KAIXIN WANG', ' Bingyi Kang', ' Jie Shao', ' Jiashi Feng']","{'Fudan University', 'National University of Singapore'}",1,0,0,"{'Singapore', 'China'}"
Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework,"Wanxin Jin, Zhaoran Wang, Zhuoran Yang, Shaoshuai Mou",Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework,5a7b238ba0f6502e5d6be14424b20ded,https://proceedings.neurips.cc/paper/2020/file/5a7b238ba0f6502e5d6be14424b20ded-Paper.pdf,"This work is expected to have the impacts on both learning and control fields. • To the learning field, this work connects some fundamental topics in machine learning to their counterparts in the control field, and unifies some concepts from reinforcement learning, backpropagation/deep learning, and control theory in one generic learning framework. The contribution of this framework is a deep integration of optimal control theory into end-to-end learning process, leading to an optimal-control-informed end-to-end learning framework that is flexible enough to solve a broad range of learning and control tasks and efficient enough to handle high-dimensional and continuous-space problems. In a broad perspective, we hope that this paper could motivate more future work that integrates the benefits of both control and learning to promote efficiency and explainability of artificial intelligence. • To the control field, this work proposes a generic paradigm, which shows how a challenging control task can be converted into a learning formulation and solved using readily-available learning techniques, such as (deep) neural networks and backpropagation. For example, the proposed framework, equipped with (deep) neural networks, shows significant advantage for handling non-linear system identification and optimal control over state-of-the-art control methods. Since classic control theory typically requires knowledge of models, we expect that this work could pave a new way to extend classic control with data-driven techniques. Since the formulation of this paper does not consider the boundness or constraints of a decisionmaking system, the real-world use of this work on physical systems might possibly raise safety issues during the training process; e.g., the state or input of the physical system at some time instance might exceeds the safety bounds that are physically required. One option to address this is to include these safety boundness as soft constraints added to the control objective or loss that is optimized. In future work, we will formally discuss PDP within a safety framework.",Broader Impact,312,10,,,TRUE,TRUE,FALSE,Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework,Reinforcement Learning and Planning -> Decision and Control,Algorithms -> Dynamical Systems; Applications -> Robotics; Optimization -> Non-Convex Optimization; Reinforcement Learning and Planning -> Model-Based RL; Reinforcement Learning and Planning -> Planning; Theory -> Control Theory,Reinforcement learning and planning,"['Wanxin Jin', ' Zhaoran Wang', ' Zhuoran Yang', ' Shaoshuai Mou']","{'Princeton', 'Northwestern University', 'Purdue University'}",1,0,0,{'USA'}
Learning from Aggregate Observations,"Yivan Zhang, Nontawat Charoenphakdee, Zhenguo Wu, Masashi Sugiyama",Learning from Aggregate Observations,5b0fa0e4c041548bb6289e15d865a696,https://proceedings.neurips.cc/paper/2020/file/5b0fa0e4c041548bb6289e15d865a696-Paper.pdf,"In this work we proposed a general method that learns from supervision signals given to sets of instances. Such studies could provide new tools for privacy preserving machine learning because individual labels are not needed. This leads to a new way to anonymize data and alleviate potential threats to privacy-sensitive information, in addition to well-known differential privacy techniques [18], which inject noise into the data to guarantee the anonymity of individuals. However, such studies may have some negative consequences because depending on the type of aggregate observations, in the worst case, it may be possible to uncover individual information to some extent from aggregated statistics, even if individual labels are not available in the training data. Nevertheless, a person can deny the uncovered label because of a lack of evidence. So learning from aggregate observations is still arguably safer than the fully-supervised counterparts in terms of privacy preser- vation. Our framework also opens possibilities of using machine learning technology in new problem domains where true labels cannot be straightforwardly obtained, but information such as pair- wise/triplet comparisons or coarse-grained data are available or possible to collect. Finally, we believe that theoretical understanding could provide a better foundation towards solving learning from aggregate observations more effectively in the future.",8 Broader impact,208,8,,,FALSE,FALSE,FALSE,Learning from Aggregate Observations,Deep Learning -> Predictive Models,Deep Learning -> Supervised Deep Networks; Probabilistic Methods -> Latent Variable Models; Theory -> Frequentist Statistics,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yivan Zhang', ' Nontawat Charoenphakdee', ' Zhenguo Wu', ' Masashi Sugiyama']","{'The University of Tokyo / RIKEN', 'RIKEN / University of Tokyo', 'The University of Tokyo'}",1,0,0,{'Japan'}
The Devil is in the Detail: A Framework for Macroscopic Prediction via Microscopic Models,"Yingxiang Yang, Negar Kiyavash, Le Song, Niao He",The Devil is in the Detail: A Framework for Macroscopic Prediction via Microscopic Models,5b8e9841e87fb8fc590434f5d933c92c,https://proceedings.neurips.cc/paper/2020/file/5b8e9841e87fb8fc590434f5d933c92c-Paper.pdf,"This paper takes a preliminary step towards formulating and understanding macroscopic learning, which has been largely ignored until very recently. The quantity of interest is an aggregation of many fine-grained observations, which appear pervasively in modern big data applications, especially those involving privacy considerations. In many cases, one does not have a complete data on the microscopic level, and existing methods that link microscopic data to predict macroscopic labels perform poorly in those cases. We believe that our work makes an important contribution to this emerging field, and sheds light on its wide applicability and potential for further studies from both theoretical and practical aspects. Application. Although we studied concrete examples such as healthcare reimbursement prediction and the prediction of COVID-19, there exists many more learning scenarios where our methods could potentially apply, such as the prediction of social network behaviors or crime activities, predicting total liquidity requirement for financial agencies, just to name a few. Many of these applications are closely related to social sciences and could potentially bring societal impact. Theory. The algorithm and theory developed in this paper apply to general-purposed minimax optimization problems and could benefit a wide spectrum of applications based on minimax optimization, e.g., generative adversarial networks, adversarial machine learning, distributionally robust optimization, safe reinforcement learning, etc. This closely aligns with the community’s pursuit of robustness and safety of machine learning. Ethics. There are several ethical questions raised from this work. For example, will supervising the learning of micro-model with macro label effectively preserve privacy? Is the framework more roust to adversarial attacks on the micro or macro labels? We believe that these questions are important in understanding the applicability of macroscopic learning framework but they remain largely unexplored.",Statement of Broader Impact,285,15,,,FALSE,FALSE,FALSE,The Devil is in the Detail: A Framework for Macroscopic Prediction via Microscopic Models,Algorithms -> Structured Prediction,Applications -> Time Series Analysis,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yingxiang Yang', ' Negar Kiyavash', ' Le Song', ' Niao He']","{'Georgia Institute of Technology', 'UIUC', 'ByteDance', 'École Polytechnique Fédérale de Lausanne'}",1,1,1,"{'USA', 'China', 'Switzerland'}"
Subgraph Neural Networks,"Emily Alsentzer, Samuel Finlayson, Michelle Li, Marinka Zitnik",Subgraph Neural Networks,5bca8566db79f3788be9efd96c9ed70d,https://proceedings.neurips.cc/paper/2020/file/5bca8566db79f3788be9efd96c9ed70d-Paper.pdf,"A variety of impactful application areas. The ability of S UB GNN to learn powerful subgraph representations creates fundamentally new opportunities for applications beyond the reach of node-, edge-, and graph-level tasks. Such applications require us to be able to reason about subgraphs and predict properties of subgraphs by leveraging the fact that subgraphs reside within a large, underlying graph. For example, this work was directly motivated by the challenge of rare disease diagnosis, which motivated the generation of two new datasets that we are releasing specifically to foster methods that will eventually prove useful on subgraph predict tasks ( e.g. , patient subgraphs residing within a large biomedical knowledge graph). Likewise, drug development represents another broad potential area of research that is closely connected with the field of graph neural networks. Hence, we also developed a new bioinformatics dataset. In addition, there are many other potentially positive applications for this class of method, including the prediction of toxic behavior on social media. The need for thoughtful use of S UB GNN framework. We also recognize that Subgraph Neural Networks have potential to used for harmful applications. For example, the potential benefit of predicting toxic communities on social media is inextricably tied with the capacity to leverage these same networks for malicious political and social purposes. Another broad class of harms that could involve subgraph classification include those harms that emerge from high-resolution user profiling. As with any data-driven methods, there is also an opportunity for bias to exist at all stages of the model development process. In the case of biomedical data science, for example, biases can exist within the data itself, and disparities can exist both in their efficacy as well as their deployment reach. Real-world subgraph datasets. The release of our monogenic disease and bioinformatics datasets is, in large part, motivated by our desire to help steer the community towards beneficial rather than malicious applications of these tools. Ultimately, given the relative immaturity of this field among major areas of computer science, vigilance is required on the part of researchers (and other relevant experts) to ensure that we as a community pursue the best possible use of our tools.",Broader Impact,362,16,,,FALSE,FALSE,FALSE,Subgraph Neural Networks,Deep Learning -> Embedding Approaches,Algorithms -> Relational Learning; Algorithms -> Representation Learning; Applications -> Computational Biology and Bioinformatics; Applications -> Network Analysis,Graph Neural Networks,"['Emily Alsentzer', ' Samuel Finlayson', ' Michelle Li', ' Marinka Zitnik']","{'Harvard University', 'MIT', 'Harvard Medical School'}",1,0,0,{'USA'}
Demystifying Orthogonal Monte Carlo and Beyond,"Han Lin, Haoxian Chen, Krzysztof M. Choromanski, Tianyi Zhang, Clement Laroche",Demystifying Orthogonal Monte Carlo and Beyond,5bce843dd76db8c939d5323dd3e54ec9,https://proceedings.neurips.cc/paper/2020/file/5bce843dd76db8c939d5323dd3e54ec9-Paper.pdf,"We do believe that those findings have several important consequences for theoreticians as well as practitioners working on Monte Carlo methods for machine learning: General Nonlinear Models: Understanding the impact of structured Monte Carlo methods leverag- ing entangled ensembles for general nonlinear models is of crucial importance in machine learning and should guide the research on the developments of new more sample-efficient and accurate MC methods. We think about our results as a first step towards this goal. Uniform Convergence Results: Our uniform convergence results for OMCs from Sec. 3.1.1 are the first such guarantees for OMC methods that can be applied to obtain strong downstream guarantees for OMCs. We demonstrated it on the example of kernel ridge regression, but similar results can be derived for other downstream applications such as kernel- SVM . They are important since in particular they provide detailed guidance on how to choose in practice the number of random features (see: the asymptotic formula for the number of samples in Theorem 3). Evolutionary Strategies with Structured MC: We showed the value of our NOMC algorithm in Sec.5 for kernel and SWD approximation, but the method can be applied as a general tool in several downstream applications, where MC sampling from isotropic distributions is required, in particular in evolutionary strategies (ES) for training reinforcement learning policies [16]. ES techniques became recently increasingly popular as providing state-of-the-art algorithms for tasks of critical importance in robotics such as end-to-end training of high-frequency controllers [22] as well as training adaptable meta-policies [39]. ES methods heavily rely on Monte Carlo estimators of gradients of Gaussians smoothings of certain classes of functions. This makes them potential beneficiaries of new developments in the theory of Monte Carlo sampling and consequently, new Monte Carlo algorithms such as NOMC. Algebraic Monte Carlo: We also think that proposed by us NOMC algorithm in its algebraic variant is one of a very few effective ways of incorporating deep algebraic results into the practice of MC in machine learning. Several QMC methods rely on number theory constructions, but, as we presented, these are much less accurate and in practice not competitive with other structured methods. Not only does our alg -NOMC provide strong theoretical foundations, but it gives additional substantial accuracy gains on the top of already well-optimized methods with no additional computational cost. This motivates future work on incorporating modern algebraic techniques into Monte Carlo algorithms for machine learning. Finally, we do believe that novel Monte Carlo methods, such as NOMC, producing better quality samples, may ultimately lead to substantial computational savings, since they require evaluating fewer number of samples to produce accurate estimators. That might lead to lower energy consumption benefits, given voluminous number of applications of Monte Carlo algorithms across the field of machine learning.",7 Broader Impact,461,16,,,FALSE,FALSE,FALSE,Demystifying Orthogonal Monte Carlo and Beyond,Algorithms -> Stochastic Methods,Algorithms -> Kernel Methods,Theory (including computational and statistical analyses),"['Han Lin', ' Haoxian Chen', ' Krzysztof M Choromanski', ' Tianyi Zhang', ' Clement Laroche']","{'Columbia University', 'Google Brain Robotics'}",1,1,1,{'USA'}
Optimal Robustness-Consistency Trade-offs for Learning-Augmented Online Algorithms,"Alexander Wei, Fred Zhang",Optimal Robustness-Consistency Trade-offs for Learning-Augmented Online Algorithms,5bd844f11fa520d54fa5edec06ea2507,https://proceedings.neurips.cc/paper/2020/file/5bd844f11fa520d54fa5edec06ea2507-Paper.pdf,"Our work is on the foundations of learning-augmented online algorithms. In particular, we focus on the fundamental limitations and trade-offs inherent to the approach (as opposed to providing new algorithms). Since our work is primarily theoretical, we believe that the immediate impact of our work will be on the academic design of algorithms within this budding research area. More broadly, we hope that research on this topic will lead to safer and more robust applications of ML in decision-making settings.",Broader Impact,80,4,,,FALSE,FALSE,FALSE,Optimal Robustness-Consistency Trade-offs for Learning-Augmented Online Algorithms,Theory -> Data-driven Algorithm Design,Theory; Theory -> Hardness of Learning and Approximations,Theory (including computational and statistical analyses),"['Alexander Wei', ' Fred Zhang']","{'UC Berkeley', 'Harvard University'}",1,0,0,{'USA'}
A Scalable Approach for Privacy-Preserving Collaborative Machine Learning,"Jinhyun So, Basak Guler, Salman Avestimehr",A Scalable Approach for Privacy-Preserving Collaborative Machine Learning,5bf8aaef51c6e0d363cbe554acaf3f20,https://proceedings.neurips.cc/paper/2020/file/5bf8aaef51c6e0d363cbe554acaf3f20-Paper.pdf,"Our framework has the societal benefit of protecting user privacy in collaborative machine learning applications, where multiple data-owners can jointly train machine learning models without revealing information about their individual datasets to the other parties, even if some parties collude with each other. Collaboration can significantly improve the accuracy of trained machine learning models, compared to training over individual datasets only. This is especially important in applications where data labelling is costly and can take a long time, such as data collected and labeled in medical fields. For instance, by using our framework, multiple medical institutions can collaborate to train a logistic regression model jointly, without revealing the privacy of their datasets to the other parties, which may contain sensitive patient healthcare records or genetic information. Our framework can scale to a significantly larger number of users compared to the benchmark protocols, and can be applied to any field in which the datasets contain sensitive information, such as healthcare records, financial transactions, or geolocation data. In such applications, protecting the privacy of sensitive information is critical and failure to do so can result in serious societal, ethical, and legal consequences. Our framework can provide both application developers and users with positive societal consequences, application developers can provide better user experience with better models as the volume and diversity of data will be increased greatly, and at the same time, users will have their sensitive information kept private. Another benefit of our framework is that it provides strong privacy guarantees that is independent from the computational power of the adversaries. Therefore, our framework keeps the sensitive user information safe even if adversaries gain quantum computing capabilities in the future. A potential limitation of our framework is that our current training framework is bound to polynomial operations. In order to compute functions that are not polynomials, such as the sigmoid function, we utilize a polynomial approximation. This can pose a challenge in the future for applying our framework to deep neural network models, as the approximation error may add up at each layer. In such scenarios, one may need to develop additional techniques to better handle the non-linearities and approximation errors.",Broader Impact,359,13,,,FALSE,FALSE,FALSE,A Scalable Approach for Privacy-Preserving Collaborative Machine Learning,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Large Scale Learning; Theory -> Information Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Jinhyun So', ' Basak Guler', ' Salman Avestimehr']",{'University of Southern California'},1,0,0,{'USA'}
Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search,"Jaehyeon Kim, Sungwon Kim, Jungil Kong, Sungroh Yoon",Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search,5c3b99e8f92532e5ad1556e53ceea00c,https://proceedings.neurips.cc/paper/2020/file/5c3b99e8f92532e5ad1556e53ceea00c-Paper.pdf,"In this paper, researchers introduce Glow-TTS, a diverse, robust and fast text-to-speech (TTS) synthesis model. Neural TTS models including Glow-TTS, could be applied in many applications which require naturally synthesized speech. Some of the applications are AI voice assistant services, audiobook services, advertisements, automotive navigation systems and automated answering services. Therefore, by utilizing the models for synthesizing natural sounding speech, the providers of such applications could improve user satisfaction. In addition, the fast synthesis speed of the proposed model could be beneficial for some service providers who provide real time speech synthesis services. However, because of the ability to synthesize natural speech, the TTS models could also be abused through cyber crimes such as fake news or phishing. It means that TTS models could be used to impersonate voices of celebrities for manipulating behaviours of people, or to imitate voices of someone’s friends or family for fraudulent purposes. With the development of speech synthesis technology, the growth of studies to detect real human voice from synthesized voices seems to be needed. Neural TTS models could sometimes synthesize undesirable speech with slurry or wrong pronunciations. Therefore, it should be used carefully in some domain where even a single pronunciation mistake is critical such as news broadcast. Additional concern is about the training data. Many corpus for speech synthesis contain speech data uttered by a handful of speakers. Without the detailed consideration and restriction about the range of uses the TTS models have, the voices of the speakers could be overused than they might expect.",Broader Impact,253,13,,,FALSE,TRUE,FALSE,Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search,Applications -> Audio and Speech Processing,Deep Learning -> Generative Models,Audio / Music / Speech,"['Jaehyeon Kim', ' Sungwon Kim', ' Jungil Kong', ' Sungroh Yoon']","{'Kakao Enterprise', 'Seoul National University'}",1,1,1,{'South Korea'}
Towards Learning Convolutions from Scratch,Behnam Neyshabur,Towards Learning Convolutions from Scratch,5c528e25e1fdeaf9d8160dc24dbf4d60,https://proceedings.neurips.cc/paper/2020/file/5c528e25e1fdeaf9d8160dc24dbf4d60-Paper.pdf,"This work studies inductive bias of convolutions and proposes an algorithm to learn local connectivity from data. Since this work aims to improve a fundamental aspect of deep learning, we believe it does not have immediate negative societal consequences. In the long term, making progress on general purpose algorithms allows machine learning engineers to spend less time on architecture design and more on other aspects of learning algorithms.",Broader Impact,68,3,,,FALSE,FALSE,FALSE,Towards Learning Convolutions from Scratch,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> AutoML,,['Behnam Neyshabur'],{'Google'},0,1,0,{'USA'}
Cycle-Contrast for Self-Supervised Video Representation Learning,"Quan Kong, Wenpeng Wei, Ziwei Deng, Tomoaki Yoshinaga, Tomokazu Murakami",Cycle-Contrast for Self-Supervised Video Representation Learning,5c9452254bccd24b8ad0bb1ab4408ad1,https://proceedings.neurips.cc/paper/2020/file/5c9452254bccd24b8ad0bb1ab4408ad1-Paper.pdf,"The objective of this work is self-supervised learning of video representation. As a positive impact of this area is to provide a mechanism to acquire transferrable representation of video without manually annotation of training data. Various downstream tasks about video understanding based on machine learning can be benefit from a good video representation, such as action recognition/detection, sports action scoring and video recommendation system, by fine-tuning the self-supervise learned model to different tasks with less amount of annotated data. It will free the society from task specific data accumulation to focus more on the task design by utilizing a transferrable video representation. However, any data driven learning system faces the risk of fairness problem caused by the biased distribution of the training data. Several supervised based researches already focus on this area. In this work, even though our method is designed to learn a video representation satisfies a nature of the correspondences across video and its frames without semantic information, the above risk is still possible occurred when transferring the representation to the other supervised task by fine-tuning with a biased train data. Therefore, we suggest to take the train data bias into consideration before the learning even in a self-supervised manner and combine with the solutions already used in the supervised tasks regarding with fairness problem when fine-tuning according to the real-world usage.",6 Broader Impact,224,8,,,FALSE,FALSE,FALSE,Cycle-Contrast for Self-Supervised Video Representation Learning,Algorithms -> Unsupervised Learning,Applications -> Activity and Event Recognition; Applications -> Video Analysis,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Quan Kong', ' Wenpeng Wei', ' Ziwei Deng', ' Tomoaki Yoshinaga', ' Tomokazu Murakami']","{'Lumada Data Science Lab. Hitachi, Ltd'}",0,1,0,{'Japan'}
Posterior Re-calibration for Imbalanced Datasets,"Junjiao Tian, Yen-Cheng Liu, Nathaniel Glaser, Yen-Chang Hsu, Zsolt Kira",Posterior Re-calibration for Imbalanced Datasets,5ca359ab1e9e3b9c478459944a2d9ca5,https://proceedings.neurips.cc/paper/2020/file/5ca359ab1e9e3b9c478459944a2d9ca5-Paper.pdf,"Our work discusses a fundamental problem in deep learning: data imbalance. Data imbalance can be safety-critical in many applications such as self-driving. Our approach allows an algorithm to give more attention to pedestrians and small obstacles. Additionally, our unified algorithm aims to provide stable performance under severe visual degradation which is also critical for safty considerations.",Broader Impact,56,4,FALSE,FALSE,FALSE,FALSE,FALSE,Posterior Re-calibration for Imbalanced Datasets,Algorithms -> Classification,Applications -> Computer Vision; Applications -> Image Segmentation,Deep learning,"['Junjiao Tian', 'Cheng Liu', ' Nathaniel Glaser', 'Chang Hsu', ' Zsolt Kira']","{'Georgia Tech', 'Georgia Institute of Technology', 'Georgia Institute of Techology'}",1,0,0,{'USA'}
Novelty Search in Representational Space for Sample Efficient Exploration,"Ruo Yu Tao, Vincent Francois-Lavet, Joelle Pineau",Novelty Search in Representational Space for Sample Efficient Exploration,5ca41a86596a5ed567d15af0be224952,https://proceedings.neurips.cc/paper/2020/file/5ca41a86596a5ed567d15af0be224952-Paper.pdf,"Algorithms for exploring an environment are a central piece of learning efficient policies for unknown sequential decision-making tasks. In this section, we discuss the wider impacts of our research both in the Machine Learning (ML) field and beyond. We first consider the benefits and risks of our method on ML applications. Efficient exploration in unknown environments has the possibility to improve methods for tasks that require accurate knowledge of its environment. By exploring states that are more novel, agents have a more robust dataset. For control tasks, our method improves the sample efficiency of its learning by finding more novel states in terms of dynamics for use in training. Our learnt low-dimensional representation also helps the interpretability of our decision making agents (as seen in Figure 1). More interpretable agents have potential benefits for many areas of ML, including allowing human understandability and intervention in human-in-the-loop approaches. With such applications in mind, we consider societal impacts of our method, along with potential future work that could be done to improve these societal impacts. One specific instance of how efficient exploration and environment modeling might help is in disaster relief settings. With the incipience of robotic systems for disaster area exploration, autonomous agents need to efficiently explore their unknown surroundings. Further research into scaling these MBRL approaches could allow for these robotic agents to find points of interest (survivors, etc.) efficiently. One potential risk of our application is safe exploration. Our method finds and learns from states that are novel in terms of its dynamics. Without safety mechanisms, our agent could view potentially harmful scenarios as novel due to the rarity of such a situation. For example, a car crash might be seen as a highly novel state. To mitigate this safety concern we look to literature on Safety in RL (Garcıa and Fernández, 2015). In particular, developing a risk metric based on the interpretability of our approach may be an area of research worth developing.",Broader Impact,325,19,,,FALSE,FALSE,FALSE,Novelty Search in Representational Space for Sample Efficient Exploration,Reinforcement Learning and Planning -> Exploration,Reinforcement Learning and Planning -> Model-Based RL,,"['Ruo Yu Tao', 'Lavet', ' Joelle Pineau']","{'McGill', 'McGill University'}",1,0,0,{'Canada'}
Robust Reinforcement Learning via Adversarial training with Langevin Dynamics,"Parameswaran Kamalaruban, Yu-Ting Huang, Ya-Ping Hsieh, Paul Rolland, Cheng Shi, Volkan Cevher",Robust Reinforcement Learning via Adversarial training with Langevin Dynamics,5cb0e249689cd6d8369c4885435a56c2,https://proceedings.neurips.cc/paper/2020/file/5cb0e249689cd6d8369c4885435a56c2-Paper.pdf,"Our work would be beneficial in control/robotics applications where the training happens in a simulation environment which is only a rough estimation of the real domain where the agent will be deployed after training. Thus our adversarial training would account for this mismatch and would lead to a stable performance. Even though our adversarial training method improves robustness, being overly conservative might result in lower performance. Thus one should carefully tune the robustness related hyperparameters, in our case δ . We could not imagine any immediate negative ethical/societal impact of our work.",Broader Impact,92,5,,,FALSE,FALSE,FALSE,Robust Reinforcement Learning via Adversarial training with Langevin Dynamics,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Parameswaran Kamalaruban', 'Ting Huang', 'Ping Hsieh', ' Paul Rolland', ' Cheng Shi', ' Volkan Cevher']","{'Unversity of Basel', 'EPFL'}",1,0,0,{'Switzerland'}
Adversarial Blocking Bandits,"Nicholas Bishop, Hau Chan, Debmalya Mandal, Long Tran-Thanh",Adversarial Blocking Bandits,5cc3749a6e56ef6d656735dff9176074,https://proceedings.neurips.cc/paper/2020/file/5cc3749a6e56ef6d656735dff9176074-Paper.pdf,"The paper examines a novel multi-armed bandit problem in which the decision-making agent aims to receive as many (cumulative) rewards as possible over a finite period subject to constraints. Our focus and results are largely theoretical. In particular, our contributions advance our understanding of multi-armed bandit models and its theoretical limitations and benefit the general (theoretical) machine learning community, specifically the multi-armed bandit and online learning communities. In addition, we do not expect that our theoretical findings can be directly used in more applied domains.",Broader Impact,85,4,FALSE,TRUE,FALSE,TRUE,FALSE,Adversarial Blocking Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning; Optimization -> Discrete Optimization,Reinforcement learning and planning,"['Nicholas Bishop', ' Hau Chan', ' Debmalya Mandal', 'Thanh']","{'University of Warwick', 'University of Southampton', 'University of Nebraska-Lincoln', 'Columbia University'}",1,0,0,"{'UK', 'USA'}"
Online Algorithms for Multi-shop Ski Rental with Machine Learned Advice,"Shufan  Wang, Jian Li, Shiqiang Wang",Online Algorithms for Multi-shop Ski Rental with Machine Learned Advice,5cc4bb753030a3d804351b2dfec0d8b5,https://proceedings.neurips.cc/paper/2020/file/5cc4bb753030a3d804351b2dfec0d8b5-Paper.pdf,"Dealing with uncertainty has been one of the most challenging issues that real-world application faces. Two radically different design methodologies for online decision making have been studied to deal with the uncertainty of future inputs. On the one hand, the competitive analysis framework has been widely used that ""pessimistically"" assumes that the future inputs are unpredictable and are always the worst-case . The goal here is to design online algorithms with a bounded competitive ratio in the worst-case over all feasible inputs. However, competitive algorithms are usually conservative and do not do well in the typical scenarios encountered in practice that are far from the worst-case. On the other hand, online algorithms implemented in real systems seldom assume the worst-case future inputs. Rather, they often use historical data to make predictions and use them as advice in decision making. These ""optimistic"" algorithms work well if the future inputs look similar to past ones and may perform poorly when these assumptions are violated. The framework proposed in this paper bridges the gap between the two extreme worlds of pessimistic and optimistic algorithm design by incorporating machine learned advices from machine learning models. Given that online decision making with uncertainty is at the core of our daily life, the scientific knowledge and tools developed from our work will advance the state-of-the-art methods and take a significant stride toward bringing benefits and better experiences to users, service providers and society at large. As (online) algorithms will continue to spread everywhere with both visible and invisible benefits, it also arises some concerns. For example, human judgement might be lost when data and predictive modeling become paramount. Furthermore, there are biases in algorithmically organized systems since algorithms depend on data and reflect the biases of datasets. Further studies on online algorithms design with ML advice to address these issues will be interesting.",Broader Impact,307,14,,,FALSE,TRUE,FALSE,Online Algorithms for Multi-shop Ski Rental with Machine Learned Advice,Reinforcement Learning and Planning -> Planning,,Reinforcement learning and planning,"['Shufan Wang', ' Jian Li', ' Shiqiang Wang']","{'Binghamton University-SUNY ', 'IBM Research', 'Binghamton University-SUNY'}",1,1,1,{'USA'}
Multi-label Contrastive Predictive Coding,"Jiaming Song, Stefano Ermon",Multi-label Contrastive Predictive Coding,5cd5058bca53951ffa7801bcdf421651,https://proceedings.neurips.cc/paper/2020/file/5cd5058bca53951ffa7801bcdf421651-Paper.pdf,"Unsupervised representation learning approaches have driven a lot of the recent progresses in many applications such as computer vision [18] and natural language processing [12]. However, training effective unsupervised learning models would require vast amounts of growing resources including data, compute and energy. For example, the recent GPT-3 [6] model with 175B parameters is trained on a dataset with 400B tokens and consumes thousands of Petaflops-s/days. As a result, it becomes ever increasingly difficult for those who does not have access to such resources to compete, which would eventually leave much progress in deep unsupervised representation learning in the hands of a few large organizations. In order to further democratize AI, it has become crucial to develop efficient methods that can be reproduced by most individuals with low cost, from modeling, training to inference. Our work aims to make a very tiny step in this direction, where we have demonstrated improvements to existing algorithms under the same computational budget constraints. In particular, we are able to significantly improve the representation learning capability of a model under very limited computational budgets. Our method is also useful for other applications where estimating mutual information is involved, such as information bottleneck. Nevertheless, our method is not agnostic to existing biases in the dataset, so there is a potential danger that any bias that are inherent in the data collection process are also exhibited in the learned representations, such as bias against minority groups. Our method also does not consider the potential risks of adversarial examples [15], which could be designed to sabotage certain downstream tasks; as well as data poisoning [28], which could harm the quality of the learned representations. We encourage researchers to further think about these safety concerns of unsupervised representation learning, since unsupervised data sources are more susceptible to malevolent sources who exploit the shortage of regulators overlooking the data.",Broader Impact,310,11,,,FALSE,FALSE,FALSE,Multi-label Contrastive Predictive Coding,Algorithms -> Representation Learning,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jiaming Song', ' Stefano Ermon']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Rotation-Invariant Local-to-Global Representation Learning for 3D Point Cloud,"SEOHYUN KIM, JaeYoo Park, Bohyung Han",Rotation-Invariant Local-to-Global Representation Learning for 3D Point Cloud,5d0cb12f8c9ad6845110317afc6e2183,https://proceedings.neurips.cc/paper/2020/file/5d0cb12f8c9ad6845110317afc6e2183-Paper.pdf,"The major goal of our research is to enhance the 3D object recognition framework by imposing the capability to handle rotations effectively. 3D object recognition is applicable to various computer vision systems including autonomous driving, augmented reality, and many others. From the societal point of view, the improvement of the 3D object recognition algorithms has both bright and dark sides. These systems can benefit those who are visually impaired by providing assistive vision systems including smart glasses [28]. Meanwhile, the technology might infringe personal privacy if equipped in drones [29] and CCTVs [30].",Broader Impact,93,5,,,FALSE,FALSE,FALSE,Rotation-Invariant Local-to-Global Representation Learning for 3D Point Cloud,Applications -> Computer Vision,Applications -> Object Recognition,Vision,"['SEOHYUN KIM', ' JaeYoo Park', ' Bohyung Han']",{'Seoul National University'},1,0,0,{'South Korea'}
Learning Invariants through Soft Unification,"Nuri Cingillioglu, Alessandra Russo",Learning Invariants through Soft Unification,5d0d5594d24f0f955548f0fc0ff83d10,https://proceedings.neurips.cc/paper/2020/file/5d0d5594d24f0f955548f0fc0ff83d10-Paper.pdf,"As it is with any machine learning model aimed at extracting patterns solely from data, learning invariants through soft unification is prone to being influenced by spurious correlations and biases that might be present in the data. There is no guarantee that even a clear, high accuracy invariant might correspond to a valid inference or casual relationship as discussed in Section 6 with some mis-matching invariants presented in Appendix D. As a result, if our approach succeeds in solving the task with an invariant, it does not mean that there is only pattern or in the case of failing to do so, a lack of patterns in the data. There has been recent work [3, 18] on tackling a different notion of invariance formed of features that are consistent (hence invariant) across different training dataset environments, to learn more robust predictors. Our method is instead targeted at research and researchers involved with combining cognitive aspects such as variable learning and assignment with neural networks under the umbrella of neuro-symbolic systems [7, 6]. A differentiable formulation of variables could accelerate the research of combining logic based symbolic systems with neural networks. In summary, we regard this work as an experimental stepping stone towards better neuro-symbolic systems in the domain of artificial intelligence research.",Broader Impact,212,6,,,FALSE,FALSE,FALSE,Learning Invariants through Soft Unification,Algorithms -> Representation Learning,Deep Learning -> Attention Models; Deep Learning -> Supervised Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Nuri Cingillioglu', ' Alessandra Russo']",{'Imperial College London'},1,0,0,{'UK'}
One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL,"Saurabh Kumar, Aviral Kumar, Sergey Levine, Chelsea Finn",One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL,5d151d1059a6281335a10732fc49620e,https://proceedings.neurips.cc/paper/2020/file/5d151d1059a6281335a10732fc49620e-Paper.pdf,"Applications and Benefits Our diversity-driven learning approach for improved robustness can be beneficial for bringing RL to real-world applications, such as robotics. It is critical that various types of robots, including service robotics, home robots, and robots used for disaster relief or search-and-rescue are able to handle varying environment conditions. Otherwise, they may fail to complete the tasks they are supposed to accomplish, which could have significant consequences in safety-critical situations. It is conceivable that, during deployment of robotics systems, the system may encounter changes in its environment that it has not previously dealt with. For example, a robot may be tasked with picking up a set of objects. At test time, the environment may slightly differ from the training setting, e.g. some objects may be missing or additional objects may be present. These previously unseen configurations may confuse the agent’s policy and lead to unpredictable and sub-optimal behavior. If RL algorithms are to be used to prescribe actions from input observations in a robotics application, the algorithms must be robust to these perturbations. Our approach of learning multiple diverse solutions to the task is a step towards achieving the desired robustness. Risks and Ethical Issues RL algorithms, in general, face a number of risks. First, they tend to suffer from reward specification - in particular, the reward may not necessarily be completely aligned with the desired behavior. Therefore, it can be difficult for a practitioner to predict the behavior of an algorithm when it is deployed. Since our algorithm learns multiple ways to optimize a task reward, the robustness and predictability of its behavior is also limited by the alignment of the reward function with the qualitative task objective. Additionally, even if the reward is well-specified, RL algorithms face a number of other risks, including (but not limited to) safety and stability. Our diversity-driven learning paradigm suffers from the same issues, as different latent-conditioned policies may not produce reliable behavior when executed in real world settings if the underlying RL algorithm is unstable.",Broader Impacts,334,15,,,FALSE,FALSE,FALSE,One Solution is Not All You Need: Few-Shot Extrapolation via Structured MaxEnt RL,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Saurabh Kumar', ' Aviral Kumar', ' Sergey Levine', ' Chelsea Finn']","{'UC Berkeley', 'Stanford University', 'Stanford'}",1,0,0,{'USA'}
Variational Bayesian Monte Carlo with Noisy Likelihoods,Luigi Acerbi,Variational Bayesian Monte Carlo with Noisy Likelihoods,5d40954183d62a82257835477ccad3d2,https://proceedings.neurips.cc/paper/2020/file/5d40954183d62a82257835477ccad3d2-Paper.pdf,"We believe this work has the potential to lead to net-positive improvements in the research community and more broadly in society at large. First, this paper makes Bayesian inference accessible to non- cheap models with noisy log-likelihoods, allowing more researchers to express uncertainty about their models and model parameters of interest in a principled way; with all the advantages of proper uncertainty quantification [2]. Second, with the energy consumption of computing facilities growing incessantly every hour, it is our duty towards the environment to look for ways to reduce the carbon footprint of our algorithms [52]. In particular, traditional methods for approximate Bayesian inference can be extremely sample-inefficient. The ‘smart’ sample-efficiency of VBMC can save a considerable amount of resources when model evaluations are computationally expensive. Failures of VBMC can return largely incorrect posteriors and values of the model evidence, which if taken at face value could lead to wrong conclusions. This failure mode is not unique to VBMC , but a common problem of all approximate inference techniques (e.g., MCMC or variational inference [2, 53]). VBMC returns uncertainty on its estimate and comes with a set of diagnostic functions which can help identify issues. Still, we recommend the user to follow standard good practices for validation of results, such as posterior predictive checks, or comparing results from different runs. Finally, in terms of ethical aspects, our method – like any general, black-box inference technique – will reflect (or amplify) the explicit and implicit biases present in the models and in the data, especially with insufficient data [54]. Thus, we encourage researchers in potentially sensitive domains to explicitly think about ethical issues and consequences of the models and data they are using.",Broader Impact,282,11,,,FALSE,FALSE,FALSE,Variational Bayesian Monte Carlo with Noisy Likelihoods,Probabilistic Methods,Neuroscience and Cognitive Science; Neuroscience and Cognitive Science -> Cognitive Science; Neuroscience and Cognitive Science -> Human or Animal Learning; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Perception; Probabilistic Methods -> Gaussian Processes; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,['Luigi Acerbi'],{'University of Helsinki'},1,0,0,{'Finland'}
Finite-Sample Analysis of Contractive Stochastic Approximation Using Smooth Convex Envelopes,"Zaiwei Chen, Siva Theja Maguluri, Sanjay Shakkottai, Karthikeyan Shanmugam",Finite-Sample Analysis of Contractive Stochastic Approximation Using Smooth Convex Envelopes,5d44ee6f2c3f71b73125876103c8f6c4,https://proceedings.neurips.cc/paper/2020/file/5d44ee6f2c3f71b73125876103c8f6c4-Paper.pdf,"This work focuses on theoretical results for stochastic approximation, which are then applied for understanding the properties of Reinforcement Learning algorithms. While RL algorithms have important societal implications (e.g. in autonomous driving, RL algorithms for network control, etc.), and thus understanding their performance is important, we believe that the direct ethical consequences of our work is somewhat limited.",Broader Impact,58,3,FALSE,TRUE,FALSE,TRUE,FALSE,Finite-Sample Analysis of Contractive Stochastic Approximation Using Smooth Convex Envelopes,Reinforcement Learning and Planning -> Reinforcement Learning,Optimization -> Stochastic Optimization,Reinforcement learning and planning,"['Zaiwei Chen', ' Siva Theja Maguluri', ' Sanjay Shakkottai', ' Karthikeyan Shanmugam']","{'Georgia Institute of Technology', 'University of Texas at Austin', 'IBM Research, NY'}",1,1,1,{'USA'}
Self-Supervised Generative Adversarial Compression,"Chong Yu, Jeff Pool",Self-Supervised Generative Adversarial Compression,5d79099fcdf499f12b79770834c0164a,https://proceedings.neurips.cc/paper/2020/file/5d79099fcdf499f12b79770834c0164a-Paper.pdf,"In this paper, we propose a self-supervised compression technique for generative adversarial networks and prove its effectiveness across various typical and complex tasks. We also show the fine-grained compression strategy works better than coarse-grained compression methods. Our proposed compression technique can benefit various applications for creative endeavors. Mobile applications performing style transfer or super-resolution on the client to save bandwidth can benefit from simpler generators. Artists may use inpainting or other texture-generation techniques to save asset storage space or interactive video generation to save rendering time, and musicians may want a backing track to generate novel accompaniment that responds in real-time. GANs are also used to augment training data for tasks like autonomous driving, medical imaging, etc. Compressed models with higher deployment efficiency will help generate more valuable data to train more robust and accurate networks for pedestrian detection, emergency protection, medical analysis, and diagnosis. Further, a more efficient data augmentation solution will leave more resources available to train a more capable network. Our hope is that these effects eventually improve peoples’ safety and well-being. We also encourage researchers to understand and mitigate the risks arising from GAN applications. As a generative network has the power to change the style or content of paintings and photos, we should notice the risk that it can be used to misrepresent objective truth. However, we expect such misuse will become ineffectual as GAN and detection techniques improve; these techniques may similarly benefit from our contributions.",Broader Impact,242,12,,,FALSE,FALSE,FALSE,Self-Supervised Generative Adversarial Compression,Algorithms -> Sparsity and Compressed Sensing,Deep Learning -> Optimization for Deep Networks,Optimization Methods (continuous or discrete),"['Chong Yu', ' Chong Yu']","{'Intel', 'NVIDIA'}",0,1,0,{'USA'}
An efficient nonconvex reformulation of stagewise convex optimization problems,"Rudy R. Bunel, Oliver Hinder, Srinadh Bhojanapalli, Krishnamurthy Dvijotham",An efficient nonconvex reformulation of stagewise convex optimization problems,5d97f4dd7c44b2905c799db681b80ce0,https://proceedings.neurips.cc/paper/2020/file/5d97f4dd7c44b2905c799db681b80ce0-Paper.pdf,"Our work leads to new scalable algorithms for verifying properties of neural networks and solve certain kinds of structured regression problems. On the positive side, these can have an impact in terms of better methods to evaluate the reliability and trustworthiness of state of the art deep learning systems, thereby catching any unseen failure modes and preventing undesirable consequences of deep learning models. On the negative sign, the algorithms are agnostic to the type of properties being verified and may facilitate abuses by allowing attackers to verify that their attacks can reliabily induces specific failure modes in a deep learning model. Further, any applications of these techniques is reliant on carefully designing desirable specifications or properties of a deep learning model - if this is not done carefully, even systems that are verifiable with these algorithms may exhibit undesirable behavior (arising from bias in the data or the specification).",Broader Impact,149,4,,,FALSE,FALSE,FALSE,An efficient nonconvex reformulation of stagewise convex optimization problems,Optimization -> Non-Convex Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Srinadh Bhojanapalli', ' Rudy Bunel', ' Krishnamurthy Dvijotham', ' Oliver Hinder']","{'University of Pittsburgh', 'DeepMind', 'Google AI', 'Deepmind'}",1,1,1,"{'UK', 'USA'}"
From Finite to Countable-Armed Bandits,"Anand Kalvit, Assaf Zeevi",From Finite to Countable-Armed Bandits,5dbc8390f17e019d300d5a162c3ce3bc,https://proceedings.neurips.cc/paper/2020/file/5dbc8390f17e019d300d5a162c3ce3bc-Paper.pdf,The authors do not claim any immediate broader impact of this work as such.,Broader Impact,14,1,TRUE,FALSE,FALSE,FALSE,FALSE,From Finite to Countable-Armed Bandits,Algorithms,Algorithms -> Bandit Algorithms; Algorithms -> Online Learning; Algorithms -> Stochastic Methods; Optimization -> Stochastic Optimization; Theory -> Computational Learning Theory; Theory -> Data-driven Algorithm Design; Theory -> Hardness of Learning and Approximations; Theory -> Information Theory; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Anand Kalvit', ' Assaf Zeevi']","{'Columbia Business School', 'Columbia University'}",1,0,0,{'USA'}
Adversarial Distributional Training for Robust Deep Learning,"Yinpeng Dong, Zhijie Deng, Tianyu Pang, Jun Zhu, Hang Su",Adversarial Distributional Training for Robust Deep Learning,5de8a36008b04a6167761fa19b61aa6c,https://proceedings.neurips.cc/paper/2020/file/5de8a36008b04a6167761fa19b61aa6c-Paper.pdf,"The existence of adversarial examples poses potential security threats to machine learning models, when they are deployed to real-world applications, especially the security-sensitive ones, such as autonomous driving, healthcare, and finance. The model vulnerability to such small perturbations could lower the confidence of the public on machine learning techniques. Therefore, it is of particular importance to develop more robust models. This work is dedicated to developing a new learning framework to train robust deep learning models, which is the potential positive impact of this work in the society. Nevertheless, many works have shown that there is an inherent trade-off between robustness and natural accuracy [65, 78], that a classifier trained to be adversarially robust would introduce degraded accuracy on clean data, and our work is no exception. Although our proposed methods can obtain higher natural accuracy than the previous adversarial training methods, they still have lower natural accuracy than a standard trained model. The degeneration in natural accuracy could be a negative consequence. From a different perspective, adversarial examples also provide an opportunity to protect private information of users [45, 73]. Building a robust model could negatively impact users’ ability to hide their privacy from the excessive unauthorized recognition systems.",Broader Impact,200,9,,,FALSE,FALSE,FALSE,Adversarial Distributional Training for Robust Deep Learning,Algorithms -> Adversarial Learning,Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yinpeng Dong', ' Zhijie Deng', ' Tianyu Pang', ' Hang Su', ' Jun Zhu']","{'Tsinghua Univiersity', 'Tsinghua University'}",1,0,0,{'China'}
Meta-Learning Stationary Stochastic Process Prediction with Convolutional Neural Processes,"Andrew Foong, Wessel Bruinsma, Jonathan Gordon, Yann Dubois, James Requeima, Richard Turner",Meta-Learning Stationary Stochastic Process Prediction with Convolutional Neural Processes,5df0385cba256a135be596dbe28fa7aa,https://proceedings.neurips.cc/paper/2020/file/5df0385cba256a135be596dbe28fa7aa-Paper.pdf,"The proposed model and training procedure are geared towards off-the-grid, spatio-temporal applications. As such, ConvNPs are particularly well-suited for many important applications in the medical and environmental sciences, such as modelling electronic healthcare records or the temporal evolution of temperatures. We hope that one impact of ConvNPs is to increase the usability of deep learning tools in the sciences. Another potential application of ConvNPs is image generation, which has potentially negative societal impacts. However, ConvNPs focus on predicting distributions over images, and are far from state-of-the-art in terms of perceptual quality. Thus we believe the societal impact of ConvNPs via image-generation will be insignificant.",Broader Impact,104,6,,,FALSE,FALSE,FALSE,Meta-Learning Stationary Stochastic Process Prediction with Convolutional Neural Processes,Algorithms -> Meta-Learning,Algorithms -> Uncertainty Estimation; Probabilistic Methods; Probabilistic Methods -> Gaussian Processes; Probabilistic Methods -> Latent Variable Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Andrew Foong', ' Wessel Bruinsma', ' Jonathan Gordon', ' Yann Dubois', ' James Requeima', ' Richard E Turner']","{'University of Cambridge', 'University of Cambridge / Invenia Labs', 'Invenia Labs and University of Cambridge', 'Facebook AI Research'}",1,1,1,"{'UK', 'USA'}"
Theory-Inspired Path-Regularized Differential Network Architecture Search,"Pan Zhou, Caiming Xiong, Richard Socher, Steven Chu Hong Hoi",Theory-Inspired Path-Regularized Differential Network Architecture Search,5e1b18c4c6a6d31695acbae3fd70ecc6,https://proceedings.neurips.cc/paper/2020/file/5e1b18c4c6a6d31695acbae3fd70ecc6-Paper.pdf,"This work advances network architecture search (NAS) in both theoretical performance analysis and practical algorithm design. As NAS can automatically design state-of-the-art architectures, this work alleviates substantial efforts from domain experts for effective architecture design, and could also help develop more intelligent algorithms. But NAS still needs an expert-designed search space which may have bias and prohibit NAS development. So automatically designing search space is desirable.",Broader Impacts,66,4,,,FALSE,FALSE,FALSE,Theory-Inspired Path-Regularized Differential Network Architecture Search,Algorithms -> AutoML,Deep Learning -> CNN Architectures; Deep Learning -> Optimization for Deep Networks,AutoML,"['Pan Zhou', ' Caiming Xiong', ' Richard Socher', ' Steven Chu Hong Hoi']",{'Salesforce'},0,1,0,{'USA'}
Conic Descent and its Application to Memory-efficient Optimization over Positive Semidefinite Matrices,"John C. Duchi, Oliver Hinder, Andrew Naber, Yinyu  Ye",Conic Descent and its Application to Memory-efficient Optimization over Positive Semidefinite Matrices,5e5dd00d770ef3e9154a4257edcb80b8,https://proceedings.neurips.cc/paper/2020/file/5e5dd00d770ef3e9154a4257edcb80b8-Paper.pdf,"Because CD is guaranteed to converge to the globally optimal solution of problem (1), it can be used in safety critical applications of machine learning that require guarantees of reliability.",Broader Impact,30,1,FALSE,FALSE,TRUE,TRUE,FALSE,Conic Descent and its Application to Memory-efficient Optimization over Positive Semidefinite Matrices,Optimization -> Convex Optimization,Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['John Duchi', ' Oliver Hinder', ' Andrew Naber', ' Yinyu Ye']","{'University of Pittsburgh', 'Stanford', 'Stanford University', 'Standord'}",1,0,0,{'USA'}
Learning the Geometry of Wave-Based Imaging,"Konik Kothari, Maarten de Hoop, Ivan Dokmanić",Learning the Geometry of Wave-Based Imaging,5e98d23afe19a774d1b2dcbefd5103eb,https://proceedings.neurips.cc/paper/2020/file/5e98d23afe19a774d1b2dcbefd5103eb-Paper.pdf,"We do not see any major ethical consequences of this work. Our work has implications in the fields of exploratory imaging — earthquake detection, medical imaging etc. Our work improves the quality and reliability of imaging in these fields. Improving these fields has direct societal impact in finding new natural preserves, improved diagnosis in healthcare etc. A failure of our system leaves machine learning unreliable in exploratory imaging. Our method provides strong out-of-distribution generalization and hence is not biased according to the data.",Broader Impact,83,6,,,TRUE,TRUE,FALSE,Learning the Geometry of Wave-Based Imaging,Applications -> Signal Processing,Deep Learning -> CNN Architectures,Deep learning,"['Konik R Kothari', ' Maarten de Hoop', ' Ivan Dokmanić']","{'University of Illinois at Urbana Champaign', 'University of Basel', 'Rice University'}",1,0,0,"{'USA', 'Switzerland'}"
Greedy inference with structure-exploiting lazy maps,"Michael Brennan, Daniele Bigoni, Olivier Zahm, Alessio Spantini, Youssef Marzouk",Greedy inference with structure-exploiting lazy maps,5ef20b89bab8fed38253e98a12f26316,https://proceedings.neurips.cc/paper/2020/file/5ef20b89bab8fed38253e98a12f26316-Paper.pdf,"Who may benefit from this research? We believe users and developers of approximate inference methods will benefit from our work. Our framework works as an “outer wrapper” that can improve the effectiveness of any flow-based variational inference method by guiding its structure. We hope to make expressive flow-based variational inference more tractable, efficient, and broadly applicable, particularly in high dimensions, by developing automated tests for low-dimensional structure and flexible ways to exploit it. The trace diagnostic developed in our work rigorously assesses the quality of transport/flow-based inference, and may be of independent interest. Who may be put at disadvantage from this research? We don’t believe anyone is put at disadvantage due to this research. What are the consequences of failure of the system? We specifically point out that one contribution of this work is identifying when a poor posterior approximation has occurred. A potential failure mode of our framework would be inaccurate estimation of the diagnostic matrix H or its spectrum, suggesting that the approximate posterior is more accurate than it truly is. However, computing the eigenvalues or trace of a symmetric matrix, even one estimated from samples, is a well studied problem. And numerical software guards against poor eigenvalue estimation or at least warns if this occurs. We believe the theoretical underpinnings of this work make it robust to undetected failure. Does the task/method leverage biases in the data? We don’t believe our method leverages data bias. As a method for variational inference, our goal is to accurately approximate a posterior distribution. It is very possible to encode biases for/against a particular result in a Bayesian inference problem, but that occurs at the level of modeling (choosing the prior, defining the likelihood) and collecting data, not at the level of approximating the posterior.",Broader Impact,294,17,,,TRUE,TRUE,FALSE,Greedy inference with structure-exploiting lazy maps,Probabilistic Methods -> Variational Inference,Algorithms -> Density Estimation; Deep Learning -> Efficient Inference Methods; Deep Learning -> Generative Models; Theory -> High-Dimensional Inference,Probabilistic methods and inference,"['Michael C Brennan', ' Daniele Bigoni', ' Olivier Zahm', ' Alessio Spantini', ' Youssef Marzouk']","{'Massachusetts Institute of Technology', 'INRIA'}",1,0,0,"{'France', 'USA'}"
Nimble: Lightweight and Parallel GPU Task Scheduling for Deep Learning,"Woosuk Kwon, Gyeong-In Yu, Eunji Jeong, Byung-Gon Chun",Nimble: Lightweight and Parallel GPU Task Scheduling for Deep Learning,5f0ad4db43d8723d18169b2e4817a160,https://proceedings.neurips.cc/paper/2020/file/5f0ad4db43d8723d18169b2e4817a160-Paper.pdf,"Our work aims to accelerate the execution of neural networks in general, and is not associated with a specific application. Furthermore, our technique does not affect the output values of neural networks (e.g., image classification labels, object detection bounding boxes, computer-generated text, etc.) nor the weights of neural networks. Therefore, we believe our work has no significant impact on any particular audience from an ethical/societal perspective, at the application-level.",Broader Impact,69,4,TRUE,FALSE,FALSE,TRUE,FALSE,Nimble: Lightweight and Parallel GPU Task Scheduling for Deep Learning,"Data, Challenges, Implementations, and Software -> Software Toolkits",,"Datasets, challenges, software","['Woosuk Kwon', 'In Yu', ' Eunji Jeong', 'Gon Chun']","{'Seoul National University', 'Seoul National Univerity'}",1,0,0,{'South Korea'}
Finding the Homology of Decision Boundaries with Active Learning,"Weizhi Li, Gautam Dasarathy, Karthikeyan Natesan Ramamurthy, Visar Berisha",Finding the Homology of Decision Boundaries with Active Learning,5f14615696649541a025d3d0f8e0447f,https://proceedings.neurips.cc/paper/2020/file/5f14615696649541a025d3d0f8e0447f-Paper.pdf,"The proposed approach, although has strong algorithmic and theoretical merits, has potential real- world application as we demonstrated. One of the key uses of this approach is to create efficient summaries of decision boundaries of datasets [23] and models. Such summaries can be quite useful in applications like AI model marketplaces [24], where data and models can be securely matched without revealing too much information about each other. This is helpful in scenarios where the data is private and models are proprietary or sensitive. A downside of being able to compute homology of decision boundaries with few examples is that malicious users may be able to learn about the key geometric / topological properties of the models with fewer examples than they would use otherwise. While this in itself may be benign, combined with other methods, they may be able to design better adversarial attacks on this model for instance. Ways of mitigating it in sensitive scenarios include ensuring that users do not issue too many queries of examples close to the boundary successively, since this may be revealing of malicious intent.",Broader Impact,182,7,,,FALSE,FALSE,FALSE,Finding the Homology of Decision Boundaries with Active Learning,Algorithms -> Active Learning,Algorithms -> Meta-Learning; Theory -> Statistical Learning Theory,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Weizhi Li', ' Gautam Dasarathy', ' Karthikeyan Natesan Ramamurthy', ' Visar Berisha']","{'IBM Research', 'Arizona State University'}",1,1,1,{'USA'}
Reinforced Molecular Optimization with Neighborhood-Controlled Grammars,"Chencheng Xu, Qiao Liu, Minlie Huang, Tao Jiang",Reinforced Molecular Optimization with Neighborhood-Controlled Grammars,5f268dfb0fbef44de0f668a022707b86,https://proceedings.neurips.cc/paper/2020/file/5f268dfb0fbef44de0f668a022707b86-Paper.pdf,"Finding effective medicines for diseases has always been a challenge in the pharmaceutical industry, especially when precision medicine has attracted more and more attention in recent years. Our approach provides an efficient way to generate molecules with specific properties, which will help  reduce the workload of pharmacists, accelerate the development of novel drugs, and decrease the cost of drug design. On the other hand, although the molecules generated by our method possess desirable biological or chemical properties, their safety and effectiveness on patients still need to be validated in the normal clinical trial processes.",Broader impact,94,3,,,FALSE,FALSE,FALSE,Reinforced Molecular Optimization with Neighborhood-Controlled Grammars,Applications -> Computational Biology and Bioinformatics,Applications -> Health; Deep Learning -> Generative Models; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Healthcare,"['Chencheng Xu', ' Qiao Liu', ' Minlie Huang', ' Tao Jiang']","{'Tsinghua University', 'University of California - Riverside'}",1,0,0,"{'USA', 'China'}"
Natural Policy Gradient Primal-Dual Method for Constrained Markov Decision Processes,"Dongsheng Ding, Kaiqing Zhang, Tamer Basar, Mihailo Jovanovic",Natural Policy Gradient Primal-Dual Method for Constrained Markov Decision Processes,5f7695debd8cde8db5abcb9f161b49ea,https://proceedings.neurips.cc/paper/2020/file/5f7695debd8cde8db5abcb9f161b49ea-Paper.pdf,"Our development could be added to a growing literature of constrained Markov decision processes (CMDPs) in a broad area of safe reinforcement learning (safe RL). Not only aiming to maximize the total reward, but almost all real-world sequential decision-making applications must also take control of safety regarding cost, utility, error rate, or efficiency, e.g., autonomous driving, medical test, financial management, and space exploration. Handling these additional safety objectives leads to constrained decision-making problems. Our research could be used to provide an algorithmic solution for practitioners to solve such constrained problems with non-asymptotic convergence and optimality guarantees. Our methodology could be new knowledge for RL researchers on the direct policy search methods for solving infinite-horizon discounted CMDPs. The decision-making processes that build on our research could enjoy the flexibility of adding practical constraints and this would improve a large range of uses, e.g., autonomous systems, healthcare services, and financial and legal services. We may expect a broad range of societal implications and we list some of them as follows. The autonomous robotics could be deployed to hazard environments, e.g., forest fires or earthquakes, with added safety guarantees. This could accelerate rescuing while saving robotics. The discovery of medical treatments could be less risky by restraining the side effect. Thus the bias of treatments could be minimized effectively. The policymaker in government or enterprises could encourage economic productivity as much as they can but under law/environment/public health constraints. Overall, one could expect a lot of social welfare improvements supported by the uses of our research. However, applying any theory to practice has to care about assumption/model mismatches. For example, our theory is in favor of well-defined feasible problems. This usually requires domain knowledge to justify. We would suggest domain experts develop guidelines for assumption/model validation. We would also encourage further work to establish the generalizability to other settings. Another issue could be the bias on gender or race. Policy parametrization selected by biased policymakers may inherit those biases. We would also encourage research to understand and mitigate the biases.",Broader Impact,337,21,,,FALSE,FALSE,FALSE,Natural Policy Gradient Primal-Dual Method for Constrained Markov Decision Processes,Reinforcement Learning and Planning -> Decision and Control,Optimization -> Non-Convex Optimization; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning; Social Aspects of Machine Learning -> AI Safety,Reinforcement learning and planning,"['Dongsheng Ding', ' Kaiqing Zhang', 'Champaign', ' Mihailo Jovanovic', ' Tamer Basar']","{'University of Southern California', 'University of Illinois at Urbana-Champaign', 'UIUC'}",1,0,0,{'USA'}
"Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Evolvability","Sitan Chen, Frederic Koehler, Ankur Moitra, Morris  Yau","Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Evolvability",5f8b73c0d4b1bf60dd7173b660b87c29,https://proceedings.neurips.cc/paper/2020/file/5f8b73c0d4b1bf60dd7173b660b87c29-Paper.pdf,"In this work we design algorithms with provable robustness guarantees in the challenging setting where the level of noise is allowed to vary across the domain. This models several scenarios of interest, most notably situations where data provided by certain demographic groups is subject to more noise than others. In a natural experiment on the UCI Adult dataset, we show that coping with this type of noise can help mitigate some natural types of unfairness that arise with off-the-shelf algorithms. Moreover our algorithms have the additional benefit that they lead to more readily interpretable hypotheses. In many settings of interest, we are able to give proper learning algorithms (where previously only improper learning algorithms were known). This could potentially help practitioners better understand and diagnose complex machine learning systems they are designing, and troubleshoot ways that the algorithm might be amplifying biases in the data.",Broader Impacts,145,6,,,FALSE,FALSE,FALSE,"Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Evolvability",Theory -> Computational Learning Theory,Algorithms -> Adversarial Learning; Algorithms -> Classification; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Sitan Chen', ' Frederic Koehler', ' Ankur Moitra', ' Morris Yau']","{'UC Berkeley', 'MIT'}",1,0,0,{'USA'}
Certified Defense to Image Transformations via Randomized Smoothing,"Marc Fischer, Maximilian Baader, Martin Vechev",Certified Defense to Image Transformations via Randomized Smoothing,5fb37d5bbdbbae16dea2f3104d7f9439,https://proceedings.neurips.cc/paper/2020/file/5fb37d5bbdbbae16dea2f3104d7f9439-Paper.pdf,"In general, methods from artificial intelligence can be applied in beneficial and malicious ways. While this poses a threat in itself, verification techniques provide formal guarantees for the robustness of the model, independently of the intended use case. Certification techniques could therefore distinguish a potentially unstable model from a stable one in safety critical settings, e.g., autonomous driving. However, especially for regulators, it is of utter importance to understand the certified properties of different certification methods precisely, so to avoid legal model deployment in safety critical applications based on misconceptions.",9 Broader Impact,90,4,,,FALSE,FALSE,FALSE,Certified Defense to Image Transformations via Randomized Smoothing,Social Aspects of Machine Learning -> AI Safety,,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Marc Fischer', ' Maximilian Baader', ' Martin Vechev']","{'ETH Zurich', 'ETH Zürich', 'ETH Zurich, Switzerland'}",1,0,0,{'Switzerland'}
Estimation of Skill Distribution from a Tournament,"Ali Jadbabaie, Anuran Makur, Devavrat Shah",Estimation of Skill Distribution from a Tournament,60495b4e033e9f60b32a6607b587aadd,https://proceedings.neurips.cc/paper/2020/file/60495b4e033e9f60b32a6607b587aadd-Paper.pdf,"The analysis of our algorithm, which forms the main contribution of this work, is theoretical in nature, and therefore, does not have any foreseeable societal consequences. On the other hand, applications of our algorithm to real-world settings could have potential societal impacts. As outlined at the outset of this paper, our algorithm provides a data-driven approach to address questions about perceived qualities of sporting events or other competitive enterprises, e.g., financial markets. Hence, a potential positive impact of our work is that subjective beliefs of stakeholders regarding the distributions of relative skills in competitive events can be moderated by a rigorous statistical method. In particular, our method could assist sports teams, sports tournament organizers, or financial firms to corroborate existing trends in the skill levels of players, debunk erroneous myths, or even unveil  entirely new trends based on available data. However, our work may also have negative consequences if utilized without paying heed to its limitations. Recall that Step 1 of Algorithm 1 estimates BTL skill parameters of agents that participate in a tournament. Since the BTL model is a well-known approach for ranking agents [6, 7], it should be used with caution, as with any method that discriminates among agents. Indeed, the BTL model only takes into account wins or losses of pairwise games between agents, but does not consider the broader circumstances surrounding these outcomes. For example, in the context of soccer, the BTL model does not consider the goal difference in a game to gauge how significant a win really is, or take into account the injuries sustained by players. Yet, rankings of teams or players may be used by team managements to make important decisions such as assigning remunerations. Thus, users of algorithms such as ours must refrain from solely using rankings or skill distributions to make decisions that may adversely affect individuals. Furthermore, on the modeling front, it is worth mentioning that the BTL model for pairwise comparisons may be too simplistic in certain real-world scenarios. In such cases, there are several other models of pairwise comparisons within the literature that may be more suitable, e.g., the Thurstonian model, cf. [21], or more general stochastically transitive models, cf. [31]. We leave the analysis of estimating skill distributions or related notions for such models as future work in the area.",Broader Impact,384,17,FALSE,FALSE,FALSE,FALSE,FALSE,Estimation of Skill Distribution from a Tournament,Algorithms -> Ranking and Preference Learning,Algorithms -> Density Estimation; Theory -> High-Dimensional Inference; Theory -> Information Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Ali Jadbabaie', ' Anuran Makur', ' Devavrat Shah']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Reparameterizing Mirror Descent as Gradient Descent,"Ehsan Amid, Manfred K. K. Warmuth",Reparameterizing Mirror Descent as Gradient Descent,604b37ea63ea51fa5fb3d8a89ec056e6,https://proceedings.neurips.cc/paper/2020/file/604b37ea63ea51fa5fb3d8a89ec056e6-Paper.pdf,The result of the paper suggests that the mirror descent updates can be effectively used in neural networks by running backpropagation on the reparameterized form of the neurons. This may have a potential use case for training these networks more efficiently. This is a theoretical paper and the broader ethical impact discussion is not applicable.,Broader Impact,55,3,TRUE,TRUE,FALSE,FALSE,FALSE,Reparameterizing Mirror Descent as Gradient Descent,Algorithms -> Online Learning,,,"['Ehsan Amid', ' Warmuth']","{'Google Brain', 'University of California, Santa Cruz'}",1,1,1,{'USA'}
General Control Functions for Causal Effect Estimation from IVs,"Aahlad Puli, Rajesh Ranganath",General Control Functions for Causal Effect Estimation from Instrumental Variables,604f2c31e67034642b288d76a8df11d5,https://proceedings.neurips.cc/paper/2020/file/604f2c31e67034642b288d76a8df11d5-Paper.pdf,"Our work applies to causal inference where strong IVs are available to help adjust for confounding, such as in problems in healthcare and economics. We assess the impact of our work in the context of these fields. In general, loosening functional assumptions like GCFN does, helps estimate effects better. Better effect estimates help improve planning patient treatment and understanding policy impact. However, the strong IV assumption may not hold for all demographics. If this occurs, demographics for which the assumption holds will have better quality effect estimates than for demographics where the assumption does not hold. This could mean that certain demographics receive better care in hospitals or have implemented policy be more impactful on them. Such issues could be characterized by evaluating the positivity of treatment with respect to the constructed control function in different demographics.",Broader Impact,137,8,,,FALSE,FALSE,FALSE,General Control Functions for Causal Effect Estimation from IVs,Probabilistic Methods -> Causal Inference,,Causality,"['Aahlad Manas Puli', ' Rajesh Ranganath']","{'New York University', 'NYU'}",1,0,0,{'USA'}
Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy Tailed Rewards,"Kyungjae Lee, Hongjun Yang, Sungbin Lim, Songhwai Oh",Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy Tailed Rewards,607bc9ebe4abfcd65181bfbef6252830,https://proceedings.neurips.cc/paper/2020/file/607bc9ebe4abfcd65181bfbef6252830-Paper.pdf,"Multi-armed bandits with heavy-tailed rewards cover a wide range of online learning problems such as online classification, adaptive control, adaptive recommendation system, and reinforcement learning. Thus, the proposed algorithm has the potential to solve such practical applications. Since the proposed method learns a given task in a short time, it may reduce economical costs or time consumption. On the contrary, if the proposed method will be applied to personalized service, fast adaptation can make a person easily addicted to the service. For example, if the recommendation system adapts to a person’s preference well, it can continuously recommend items that arouse personal interest and that can lead to addiction.",7 Broader Impact,108,5,,,TRUE,TRUE,FALSE,Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy Tailed Rewards,Algorithms -> Bandit Algorithms,Reinforcement Learning and Planning -> Exploration,Reinforcement learning and planning,"['Kyungjae Lee', ' Hongjun Yang', ' Sungbin Lim', ' Songhwai Oh']","{'Ulsan National Institute of Science and Technology', 'Seoul National University', 'Korea University'}",1,0,0,{'South Korea'}
Certified Robustness of Graph Convolution Networks for Graph Classification under Topological Attacks,"Hongwei Jin, Zhan Shi, Venkata Jaya Shankar Ashish Peruri, Xinhua Zhang",Certified Robustness of Graph Convolution Networks for Graph Classification under Topological Attacks,609a199881ca4ba9c95688235cd6ac5c,https://proceedings.neurips.cc/paper/2020/file/609a199881ca4ba9c95688235cd6ac5c-Paper.pdf,"Graph convolutional networks (GCNs) have been shown effective in a number of applications such as social networks, biological graphs, citation networks, and etc. Despite its recent success, its vulnerability to adversarial attacks has also been revealed and attacks on both node feature and graph structure have been proposed. Direct extension of defense algorithms from image classification domain meets with immediate obstacles because computing the adversarial network is a highly involved discrete optimization problem, costing a substantial amount of computations. This paper proposed the first algorithm that provides tight lower and upper bounds for the margin of graph classification , allowing a certificate of robustness to be computed efficiently in practice, and proved in theory. It can be readily applied to a number of high-impact domains in real-world problems, including cross-lingual knowledge graph alignment [45], fraud detection [46], cancer classification based on multi-modal fMRI images [47], chemical and biological interface prediction [48], categorization of scientific papers [1], etc.",Broader Impact,157,5,,,FALSE,TRUE,FALSE,Certified Robustness of Graph Convolution Networks for Graph Classification under Topological Attacks,Deep Learning -> Adversarial Networks,Algorithms -> Adversarial Learning,Deep learning,"['Hongwei Jin', ' Zhan Shi', ' Venkata Jaya Shankar Ashish Peruri', ' Xinhua Zhang']","{'University of Illinois at Chicago', 'UIC'}",1,0,0,"{'USA', 'Thailand'}"
Zero-Resource Knowledge-Grounded Dialogue Generation,"Linxiao Li, Can Xu, Wei Wu, YUFAN ZHAO, Xueliang Zhao, Chongyang Tao",Zero-Resource Knowledge-Grounded Dialogue Generation,609c5e5089a9aa967232aba2a4d03114,https://proceedings.neurips.cc/paper/2020/file/609c5e5089a9aa967232aba2a4d03114-Paper.pdf,"Endowing a dialogue system with knowledge is definitely an important step towards human-like conversational AI which has been dreamed by AI researchers for years, especially when such a technology becomes cheaper and more transferable. More importantly, research on knowledge-grounded dialogue generation could fundamentally change the experience of human-machine interaction, as a system will be able to evolve along with the external knowledge base being maintained and updated. This may shed light on the effort on building interfaces that allow people to acquire information in a more natural way (i.e., through conversation), rather than just typing a query in a search box and browsing the blue links. However, we never forget the other side of the coin. Apart from the well-known issues in end-to-end conversation models trained from large naturally-occurring datasets [50], a knowledge base may also be deliberately tailored and bring biased content to dialogues, just like biased content posted by content creators on the Web is promoted by a search engine. To prevent the technology from being abused for disinformation, we look forward to more research effort being paid to fake/biased/offensive content detection, and at the same time, encourage developers to carefully choose the content for building the knowledge base of their dialogue system. After all, good external content can regulate the behavior of a dialogue model in response generation, and help the model overcome its instinct drawbacks inherited from the malicious or biased content hidden in the large scale dialogues obtained from social media for training.",Broader Impact,249,7,,,FALSE,TRUE,FALSE,Zero-Resource Knowledge-Grounded Dialogue Generation,Applications -> Dialog- or Communication-Based Learning,Applications -> Natural Language Processing,Natural language processing,"['Linxiao Li', ' Can Xu', ' Wei Wu', ' YUFAN ZHAO', ' Xueliang Zhao', ' Chongyang Tao']","{'microsoft', 'Microsoft', 'Peking University', 'Meituan-Dianping Group'}",1,1,1,"{'USA', 'China'}"
Targeted Adversarial Perturbations for Monocular Depth Prediction,"Alex Wong, Safa Cicek, Stefano Soatto",Targeted Adversarial Perturbations for Monocular Depth Prediction,609e9d4bcc8157c00808993f612f1acd,https://proceedings.neurips.cc/paper/2020/file/609e9d4bcc8157c00808993f612f1acd-Paper.pdf,"Adversarial perturbations highlight limitations and failure modes of deep networks. They have captured the collective imagination by conjuring scenarios where AI goes awry at the tune of imperceptible changes. Some popular media and press has gone insofar as suggesting them as proof that AI cannot be trusted. While monocular depth prediction networks are indeed vulnerable to these attacks, we want to assure the reader that these perturbations cannot cause harm outside of the academic setting. As mentioned in Sec. 3.1, optimizing for these perturbations is computationally expensive and hence it is infeasible to craft these perturbations in real time. Additionally, they also do not transfer; so, we see little negative implications for real-world applications. However, the fact that they exist implies that there is room for improvement in the way that we learn representations for depth prediction. Hence, we see the existence of adversaries as an opportunity. Studying their effects on deep networks is also the first step to render a system robust to such a vulnerability. The broader impact of our work is to understand the corner cases and failure modes in order to develop more robust representations. This, in turn, will improve interpretability (or, rather, reduce nonsensical behavior). In the fullness of time, we expect this research to pay a small contribution to benefit transportation safety.",Broader Impact,218,13,,,FALSE,FALSE,FALSE,Targeted Adversarial Perturbations for Monocular Depth Prediction,Applications -> Computer Vision,Applications -> Visual Scene Analysis and Interpretation,Vision,"['Alex Wong', ' Safa Cicek', ' Stefano Soatto']","{'UCLA', 'University of Los Angeles, California'}",1,0,0,{'USA'}
Beyond the Mean-Field: Structured Deep Gaussian Processes Improve the Predictive Uncertainties,"Jakob Lindinger, David Reeb, Christoph Lippert, Barbara Rakitsch",Beyond the Mean-Field: Structured Deep Gaussian Processes Improve the Predictive Uncertainties,60a70bb05b08d6cd95deb3bdb750dce8,https://proceedings.neurips.cc/paper/2020/file/60a70bb05b08d6cd95deb3bdb750dce8-Paper.pdf,"In many applications, machine learning algorithms have been shown to achieve superior predictive performance compared to hand-crafted or expert solutions [27]. However, these methods can be applied in safety-critical applications only if they return predictive distributions allowing to quantify the uncertainty of the prediction [17]. For instance, a medical diagnosis tool can be applied only if each diagnosis is endowed with a confidence interval such that in case of ambiguity a physician can be contacted. Our work yields accurate predictive distributions for deep non-parametric models by allowing correlations between and across layers in the variational posterior. As we validate in our experiments, this also holds true when the input distribution at test time differs from the input distribution at training time. In our medical example, this might be the case if the hospital where the data is recorded is different from the one where the diagnosis tool is deployed.",Broader Impact,149,6,,,FALSE,FALSE,FALSE,Beyond the Mean-Field: Structured Deep Gaussian Processes Improve the Predictive Uncertainties,Probabilistic Methods -> Gaussian Processes,Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Jakob Lindinger', ' David Reeb', 'Bosch Center for Artificial Intelligence', ' Christoph Lippert', ' Barbara Rakitsch']","{'Hasso Plattner Institute for Digital Engineering', 'Bosch Center for Artificial Intelligence', 'BCAI'}",1,1,1,{'Germany'}
Offline Imitation Learning with a Misspecified Simulator,"Shengyi Jiang, Jingcheng Pang, Yang Yu",Offline Imitation Learning with a Misspecified Simulator ∗,60cb558c40e4f18479664069d9642d5a,https://proceedings.neurips.cc/paper/2020/file/60cb558c40e4f18479664069d9642d5a-Paper.pdf,"In this paper, we present an offline imitation-learning approach that utilizes a few expert demonstrations and a simulator with misspecified dynamics. Potentially, it can be used to improve the performance of sim-to-real transfer without dangerous exploration in the early training stage of conventional algorithms. Since RL has not been applied in complex real-world tasks, the ethical concerns of this work are very limited. The major drawback is that the final policy π real may still produce undesirable actions or reach bad states. In the deployment phase, the agent should be monitored carefully. Other researches on safe reinforcement learning may also help alleviate this problem.",Broader Impact,104,6,,,FALSE,FALSE,FALSE,Offline Imitation Learning with a Misspecified Simulator,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Shengyi Jiang', ' Jingcheng Pang', ' Yang Yu']",{'Nanjing University'},1,0,0,{'China'}
Multi-Fidelity Bayesian Optimization via Deep Neural Networks,"Shibo Li, Wei Xing, Robert Kirby, Shandian Zhe",Multi-Fidelity Bayesian Optimization via Deep Neural Networks,60e1deb043af37db5ea4ce9ae8d2c9ea,https://proceedings.neurips.cc/paper/2020/file/60e1deb043af37db5ea4ce9ae8d2c9ea-Paper.pdf,"This work can be used in a variety of engineering design problems that involve intensive computation, e.g., finite elements or differences. Hence, the work has potential positive impacts in the society if it is used to design passenger aircrafts, biomedical devices, automobiles, and all the other devices or machines that can benefit human lives. At the same time, this work may have some negative consequences if it is used to design weapons or weapon parts.",Broader Impact,75,3,,,FALSE,FALSE,FALSE,Multi-Fidelity Bayesian Optimization via Deep Neural Networks,Optimization,Algorithms -> Bandit Algorithms; Deep Learning; Probabilistic Methods; Probabilistic Methods -> Graphical Models; Probabilistic Methods -> Hierarchical Models; Probabilistic Methods -> Variational Inference,Optimization Methods (continuous or discrete),"['Shibo Li', ' Wei Xing', ' Robert Kirby', ' Shandian Zhe']",{'University of Utah'},1,0,0,{'USA'}
PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals,"Henry Charlesworth, Giovanni Montana",PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals,6101903146e4bbf4999c449d78441606,https://proceedings.neurips.cc/paper/2020/file/6101903146e4bbf4999c449d78441606-Paper.pdf,"Since our work involves foundational research in the field of model-based reinforcement learning it is unlikely to have any large, immediate impacts on society. Nevertheless, in the longer term the impact of reinforcement learning agents capable of learning to autonomously make decisions could be huge. In principle one could discuss a huge range of potential impacts over different time frames, but we choose to focus on some potential medium-term impacts of robots that can learn autonomously from sparse rewards. Robots are pervasive in the modern world and are used in a wide range of manufacturing industries for carrying out tedious, repetitive work. Introducing robots that are capable of autonomously learning a set of skills from easy to specify reward functions has the potential to vastly increase the scope of possible tasks that they can be used for. In particular, it removes the requirement for their behaviours to be carefully engineered in a manual fashion for every possible scenario they might encounter. This has the potential to allow for many tasks that currently can only be carried out by human workers to become fully or partially automated. Whilst this could provide a huge economic boost to some manufacturing companies, it is important that this benefit is weighed against the potential negative impacts (both social and economic) that losing these manufacturing jobs could have — particularly if large scale changes were to occur in a short period of time. We feel that this is an important question for both economists/ policy advisors as well as researchers working in the field to think about.",Statement of Broader Impact,261,9,,,FALSE,FALSE,FALSE,PlanGAN: Model-based Planning With Sparse Rewards and Multiple Goals,Reinforcement Learning and Planning -> Model-Based RL,Deep Learning -> Generative Models; Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Henry Charlesworth', ' Giovanni Montana']",{'University of Warwick'},1,0,0,{'UK'}
Bad Global Minima Exist and SGD Can Reach Them,"Shengchao Liu, Dimitris Papailiopoulos, Dimitris Achlioptas",Bad Global Minima Exist and SGD Can Reach Them,618491e20a9b686b79e158c293ab4f91,https://proceedings.neurips.cc/paper/2020/file/618491e20a9b686b79e158c293ab4f91-Paper.pdf,"We believe that the main value of our work is in pointing out the crucial, yet largely unexplored, role played by regularization in search dynamics . This is a departure from the usual way of thinking about generalization, wherein its role is to ensure stability of the chosen model with respect to fluctuations  in the training sample. In other words, we make the point that regularization is important not only in its role of demoting (penalizing) complex models that fit the data well, but even in penalizing complex models that fit the data poorly, altering the entirety of the optimization landscape and making the space of simple models better searchable by local methods such as SGD. We understand that our work leaves open the exact mechanism through which regularization achieves this effect, but the experimental evidence we give for this effect is undeniable. Given the enormous intellectual importance of regularization in machine learning, the possibility that its role is actually far larger in scope than previously realized, is rather remarkable. In that sense, the value of our work is in opening up a potentially large domain of further research, namely understanding the role of regularization in search dynamics, including the possibility of a future direction wherein regularization is aimed not only at promoting model stability but also model discoverability.",Broader Impacts,219,6,,,FALSE,FALSE,FALSE,Bad Global Minima Exist and SGD Can Reach Them,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Large Scale Learning; Optimization -> Non-Convex Optimization,Deep learning,,"{'MILA, Université de Montréal', 'University of Athens', 'University of Wisconsin-Madison'}",1,0,0,"{'Canada', 'Greece', 'USA'}"
Optimal Prediction of the Number of Unseen Species with Multiplicity,"Yi Hao, Ping Li",Optimal Prediction of the Number of Unseen Species with Multiplicity,618790ae971abb5610b16c826fb72d01,https://proceedings.neurips.cc/paper/2020/file/618790ae971abb5610b16c826fb72d01-Paper.pdf,"In this paper, we propose and completely resolve a natural generalization of the well-known unseen species problem. The algorithm we construct is simple in its form and linear-time computable, and performs fairly well on different synthetic and real datasets. We fully generalize the notable work of [28] in terms of the formulation, algorithm, and main results (MSE bounds). As illustrated in Section 1.1 and 1.2, our algorithm has numerous potential applications, such as active app user estimation, vocabulary size estimation, business growth analysis, species diversity estimation, database attribute study, and genetic variation study. A possible downside is that the formulation ignores any prior information, and only assumes that the distribution is discrete. A promising strategy is to incorporate the Bayesian inference framework, which will be our future research direction.",Broader Impact,129,6,,,FALSE,FALSE,FALSE,Optimal Prediction of the Number of Unseen Species with Multiplicity,Theory -> Statistical Learning Theory,Theory -> Computational Learning Theory; Theory -> High-Dimensional Inference; Theory -> Information Theory,Theory (including computational and statistical analyses),,"{'University of California, San Diego', 'Baidu Research USA'}",1,1,1,"{'USA', 'China'}"
Characterizing Optimal Mixed Policies: Where to Intervene and What to Observe,"Sanghack Lee, Elias Bareinboim",Characterizing Optimal Mixed Policies: Where to Intervene and What to Observe,61a10e6abb1149ad9d08f303267f9bc4,https://proceedings.neurips.cc/paper/2020/file/61a10e6abb1149ad9d08f303267f9bc4-Paper.pdf,"Our work investigates the efficiency and effectiveness of AI agents to explore the environments and ultimately achieve optimality. Our results provide a tool for AI engineers and researchers to identify where the inefficiency of a policy may be coming from, including potentially unintended side effects. Further, the characterization provided in this work can suggest how systemic improvements are possible given non-parametric causal understanding of the underlying systems. The very topic of our paper about efficiency and effectiveness has been studied for several decades in diverse fields: bandits, reinforcement learning, design of experiments, etc. Hence, it is not difficult to imagine that our work will share the common problems with other automated decision making tools and methods such as (i) the system optimized based on an ill-defined reward may harm ‘unknown unknowns’ (e.g., increasing the revenue of alcoholic beverage companies based on targeted advertising over recovering alcoholics if their health is not properly modeled) or (ii) the optimization can be impossible due to the participants of adversarial players (e.g., rewarding the number of software bugs fixed makes software engineers to create more bugs to fix, see Goodhart’s law). Mitigating the first kind of risks will require deploying proper countermeasure through, e.g., regulations by governments. The second kind of risks (errors or failures) can be detected through examining possible changes of underlying mechanisms (i.e., anomaly detection). However, the current work does not consider multiple adversarial participants (e.g., game-theoretic settings), which is a subject of future research.",Broader Impact,244,8,,,FALSE,FALSE,FALSE,Characterizing Optimal Mixed Policies: Where to Intervene and What to Observe,Probabilistic Methods -> Causal Inference,,Causality,"['Sanghack Lee', ' Elias Bareinboim']","{'Columbia University', 'Purdue University'}",1,0,0,{'USA'}
Factor Graph Neural Networks,"Zhen Zhang, Fan Wu, Wee Sun Lee",Factor Graph Neural Network,61c66a2f4e6e10dc9c16ddf9d19745d6,https://proceedings.neurips.cc/paper/2020/file/61c66a2f4e6e10dc9c16ddf9d19745d6-Paper.pdf,"Our work on the factor graph neural networks aims to make it easier to effectively specify structural inductive biases in the form of dependencies among sets of variables. This will impact on learning algorithms on structured data, particularly graph structured data. On the positive side, with well specified inductive biases, more effective learning would be possible on applications that require structured data. These include data with physical constraints such as human motion data, as well as data with abstract relationships such as social network data. On the negative side, in applications on some types of data such as social network data, better inference could mean less privacy. Research, guidelines, and possibly regulations on privacy can help to mitigate the negative effects.",Broader Impact,121,6,,,FALSE,FALSE,FALSE,Factor Graph Neural Networks,Probabilistic Methods -> Graphical Models,Algorithms -> Relational Learning; Algorithms -> Representation Learning; Probabilistic Methods -> Belief Propagation; Probabilistic Methods -> Variational Inference,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Zhen Zhang', ' Fan Wu', ' Wee Sun Lee']","{'National University of Singapore', 'Nanjing University', 'University of Adelaide'}",1,0,0,"{'Singapore', 'Australia', 'China'}"
A Closer Look at Accuracy vs. Robustness,"Yao-Yuan Yang, Cyrus Rashtchian, Hongyang Zhang, Russ R. Salakhutdinov, Kamalika Chaudhuri",A Closer Look at Accuracy vs. Robustness,61d77652c97ef636343742fc3dcf3ba9,https://proceedings.neurips.cc/paper/2020/file/61d77652c97ef636343742fc3dcf3ba9-Paper.pdf,"In this paper we have investigated when it is possible to achieve both high accuracy and adversarial robustness on standard image classification datasets. Our motivation is partially to offer an alternative perspective to previous work that speculates on the inevitability of an accuracy-robustness tradeoff. In practice, if there were indeed a tradeoff, then robust machine learning technology is unlikely to be very useful. The vast majority of instances encountered by practical systems will be natural examples, whereas adversaries are few and far between. A self-driving car will mostly come across regular street signs and rarely come across adversarial ones. If increased robustness necessitates a loss in performance on natural examples, then the system’s designer might be tempted to use a highly accurate classifier that is obtained through regular training and forgo robustness altogether. For adversarially robust machine learning to be widely adopted, accuracy needs to be achieved in conjunction with robustness. While we have backed up our theoretical results by empirically verifying dataset separation, we are also ready to point out the many limitations of current robustness studies. The focus on curated benchmarks may lead to a false sense of security. Real life scenarios will likely involve much more complicated classification tasks. For example, the identification of criminal activity or the maneuvering of self-driving cars depend on a much broader notion of robustness than has been studied so far. Perturbations in p distance cover only a small portion of the space of possible attacks. Looking toward inherent biases, we observe that test accuracy is typically aggregated over all classes, and hence, it does not account for underrepresentation. For example, if a certain class makes up a negligible fraction of the dataset, then misclassifying these instances may be unnoticeable when we expect a drop in overall test accuracy. A more stringent objective would be to retain accuracy on each separate class, as well as being robust to targeted perturbations that may exploit dataset imbalance. On a more positive note, we feel confident that developing a theoretically grounded discussion of robustness will encourage machine learning engineers to question the efficacy of various methods. As one of our contributions, we have shown that dataset separation guarantees the existence of an accurate and robust classifier. We believe that future work will develop new methods that achieve robustness by imposing both Lipschitzness and effective generalization. Overall, it is paramount to close the theory-practice gap by working on both sides, and we stand by our suggestion to further investigate the various deep learning components (architecture, loss function, training method, etc) that may compound the perceived gains in robustness and accuracy.",Broader Impact,434,19,,,FALSE,FALSE,FALSE,A Closer Look at Accuracy vs. Robustness,Algorithms -> Adversarial Learning,Algorithms -> Classification,adversarial robustness,"['Yuan Yang', ' Cyrus Rashtchian', ' Hongyang Zhang', ' Russ Salakhutdinov', ' Kamalika Chaudhuri']","{'TTIC', 'Carnegie Mellon University', 'UCSD'}",1,0,0,{'USA'}
Curriculum Learning by Dynamic Instance Hardness,"Tianyi Zhou, Shengjie Wang, Jeff A. Bilmes",Curriculum Learning by Dynamic Instance Hardness,62000dee5a05a6a71de3a6127a68778a,https://proceedings.neurips.cc/paper/2020/file/62000dee5a05a6a71de3a6127a68778a-Paper.pdf,"We propose DIH guided curriculum learning as a general framework to improve efficiency for training machine learning models and their final performance. This potentially facilitates other applications and research that involve training machine learning models, e.g., using machine learning models to simulate high energy physics experiments, and automatically detect COVID-19 with CT scans. Moreover, as DIHCL is inspired by human learning, our results on machine learning models can also perhaps return the favor and be inspiring for those studying mechanisms behind true human learning. For example, we may use a metric similar to DIH to select human learning materials to test if better human learning efficiency can be achieved.",Broader Impact,109,4,,,FALSE,FALSE,FALSE,Curriculum Learning by Dynamic Instance Hardness,Deep Learning -> Efficient Training Methods,Algorithms,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Tianyi Zhou', ' Shengjie Wang', ' Jeff Bilmes']","{'University of Washington, Seattle'}",1,0,0,{'USA'}
Spin-Weighted Spherical CNNs,"Carlos Esteves, Ameesh Makadia, Kostas Daniilidis",Spin-Weighted Spherical CNNs,6217b2f7e4634fa665d31d3b4df81b56,https://proceedings.neurips.cc/paper/2020/file/6217b2f7e4634fa665d31d3b4df81b56-Paper.pdf,"This paper presents advances on learning representations from spherical data. It has potential beneficial applications to climate and atmospheric modeling, for example. The method is in the broad category of equivariant CNNs, which have the goal to reduce model and sample complexity and improve generalization performance. This potentially translates to models that are more energy efficient, and are more accessible to individuals without access to large computational resources. On the flip side, most technology can also be applied for harmful purposes, and when making it more accessible we also risk enabling bad actors to make use of it.",Broader Impact,98,5,,,FALSE,FALSE,FALSE,Spin-Weighted Spherical CNNs,Algorithms -> Representation Learning,Deep Learning -> Efficient Training Methods,Deep learning,"['Carlos Esteves', ' Ameesh Makadia', ' Kostas Daniilidis']","{'University of Pennsylvania', 'Google Research'}",1,1,1,{'USA'}
Learning to Execute Programs with Instruction Pointer Attention Graph Neural Networks,"David Bieber, Charles Sutton, Hugo Larochelle, Daniel Tarlow",Learning to Execute Programs with Instruction Pointer Attention Graph Neural Networks,62326dc7c4f7b849d6f013ba46489d6c,https://proceedings.neurips.cc/paper/2020/file/62326dc7c4f7b849d6f013ba46489d6c-Paper.pdf,"Our work introduces a novel neural network architecture better suited for program understanding tasks related to program executions. Lessons learned from this architecture will contribute to improved machine learning for program understanding and generation. We hope the broader impact of these improvements will be improved tools for software developers for the analysis and authoring of new source code. Machine learning for static analysis produces results with uncertainty, however. There is risk that these techniques will be incorporated into tools in a way that conveys greater certainty than is appropriate, and could lead to either developer errors or mistrust of the tools.",Broader Impact,101,5,,,FALSE,FALSE,FALSE,Learning to Execute Programs with Instruction Pointer Attention Graph Neural Networks,Applications -> Program Understanding and Generation,Deep Learning -> Recurrent Networks,Deep learning,"['David Bieber', ' Charles Sutton', ' Hugo Larochelle', ' Daniel Tarlow']","{'Google Brain', 'Google'}",0,1,0,{'USA'}
AutoPrivacy: Automated Layer-wise Parameter Selection for Secure Neural Network Inference,"Qian Lou, Song Bian, Lei Jiang",AutoPrivacy: Automated Layer-wise Parameter Selection for Secure Neural Network Inference,6244b2ba957c48bc64582cf2bcec3d04,https://proceedings.neurips.cc/paper/2020/file/6244b2ba957c48bc64582cf2bcec3d04-Paper.pdf,"In this paper, we propose an automated HE parameter selector for non-experts, i.e., average users, to automatically optimize their privacy-preserving neural network, so that average users can work with fast and accurate privacy-preserving neural network inferences on encrypted data. Average users, who have to rely on big data companies but do not trust them, can benefit from this research, since they can upload only their encrypted data to untrusted servers. No one may be put at disadvantage from this research. If our proposed technique fails, everything will go back to the state-of-the-art, i.e., untrusted servers may leak sensitive data of average users.",Broader Impact,102,4,,,FALSE,FALSE,FALSE,AutoPrivacy: Automated Layer-wise Parameter Selection for Secure Neural Network Inference,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> AutoML,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Qian Lou', ' Song Bian', ' Lei Jiang']","{'Indiana University Bloomington', 'Kyoto University'}",1,0,0,"{'Japan', 'USA'}"
Baxter Permutation Process,"Masahiro Nakano, Akisato Kimura, Takeshi Yamada, Naonori Ueda",Baxter Permutation Process,6271faadeedd7626d661856b7a004e27,https://proceedings.neurips.cc/paper/2020/file/6271faadeedd7626d661856b7a004e27-Paper.pdf,"Clustering is one of the most fundamental machine learning tools for data analysis. The blockbreaking process (BBP) can be regarded as a multi-dimensional extension of clustering and it has a potential to give a new perspective to relational data analysis, for it would reveal latent structures in relational data (or network data) in much more flexible manner than other existing clustering methods, without tuning the model complexity. In fact, the BBP can extract latent clusters of relational data through rectangular partitioning (RP). While conventional models can express only limited classes of all possible RPs, the BBP can potentially capture arbitrary rectangular partitioning, keeping the central advantage of the Bayesian nonparametic (BNP) machine learning, and the BBP does not have to tune the model complexity regardless of the size of the input data. Therefore, the BBP will have a wide range of potential applications, including market research, pattern recognition, image processing, pre- and post- processing of data, and structure learning of network models. For example, the BBP can be combined with deep neural network (DNN) models as a prior on the network, which simultaneously learns the DNN parameters and the network structure. It may also be used to expose and identify biases in data. The source code of the BBP-based relational model is available at https://github.com/nttcslab/baxter-permutation-process, with which you can try and examine the BBP-based relational data analysis by yourself. Our work is not facilitating any unethical aspects of machine learning technologies, by genuinely pursuing the development of Bayesian methods in many applications settings. However, as is often the case with any clustering methods (or more generally any predictive algorithms), our proposal can be misused in a variety of context. Since the BPP may reveal hidden clusters from any input relational matrices, unethical applications may lead to unexpected results due to unexpected cues. This problem is highly dependent on the choice of input data. Therefore, what is suitable as input data needs to be carefully considered from an ethical perspective.",Broader Impact,329,13,,,TRUE,TRUE,FALSE,Baxter Permutation Process,Probabilistic Methods -> Bayesian Nonparametrics,Probabilistic Methods -> Bayesian Theory,Probabilistic methods and inference,"['Masahiro Nakano', ' Akisato Kimura', ' Takeshi Yamada', ' Naonori Ueda']","{'NTT communication science laboratories', 'NTT Communication Science Laboratories', 'NTT'}",0,1,0,{'Japan'}
Characterizing emergent representations in a space of candidate learning rules for deep networks,"Yinan Cao, Christopher Summerfield, Andrew Saxe",Characterizing emergent representations in a space of candidate learning rules for deep networks,6275d7071d005260ab9d0766d6df1145,https://proceedings.neurips.cc/paper/2020/file/6275d7071d005260ab9d0766d6df1145-Paper.pdf,"We hope the work presented here could be of interest to neuroscientists and cognitive scientists who use deep networks to model and understand how biological brains encode, compose and generalise abstract knowledge. Our work aims to characterize basic learning processes in the brain, and any applications are likely to lie far in the future with substantial uncertainty. If the methods in this paper did lead to identification of learning principles operating in parts of the brain, this could aid design of optimal curricula, with possible benefits for educational and medical settings (for instance, restoration of vision after stroke). Conversely, however, quantitative theories of human learning could allow design of adversarial curricula that rapidly induce false beliefs. Our findings on illusory correlations show that different learning algorithms make errors in which broad correlations in the dataset are over-extended to specific inputs to which they do not apply. These findings could have implications for susceptibility to biases in data. If these learning mechanisms describe human learning, this could provide insight into the development of implicit biases. At present our work is far from these impacts.",Broader Impact,183,8,,,FALSE,FALSE,FALSE,Characterizing emergent representations in a space of candidate learning rules for deep networks,Neuroscience and Cognitive Science -> Neuroscience,Deep Learning -> Analysis and Understanding of Deep Networks,Neuroscience and cognitive science,"['Yinan Cao', ' Christopher Summerfield', ' Andrew Saxe']",{'University of Oxford'},1,0,0,{'UK'}
"Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation","Rasool Fakoor, Jonas W. Mueller, Nick Erickson, Pratik Chaudhari, Alexander J. Smola","Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation",62d75fb2e3075506e8837d8f55021ab1,https://proceedings.neurips.cc/paper/2020/file/62d75fb2e3075506e8837d8f55021ab1-Paper.pdf,"This work will potentially impact the community in two main ways. Our proposal to use high-accuracy AutoML ensembles followed by model distillation allows practitioners to deploy their favorite models, but obtain significantly better accuracy than they could fitting these models directly to their data in the standard fashion. Our work thus helps realize AutoML’s promise of strong performance on diverse data while distilling its complexity. Furthermore, our improved model-agnostic distillation strategy can help facilitate interpretability of accurate-but-opaque predictors by choosing a simple understandable model as the student model. While the majority of enterprise ML applications today involve tabular data and tree models, empirical research on distillation has mostly focused on computer vision applications with only neural network models. Thus, this paper serves a key segment of practitioners that has been overlooked. A major difference in distillation with tabular data are the limited sample sizes of most people’s datasets, which means augmentation during distillation is critical. We expect our work to have strong practical impact for these medium/small-scale problems. By allowing practitioners to deploy simpler models that retain the accuracy of their more complex counterparts, our work helps improve the cost of ML inference, the reliability of deployments (student models are less opaque), and may open up new ML applications that were once out of reach due to previously unachievable accuracy-latency limits. The second avenue for impact is theoretical. The dramatic performance of deep networks on modalities such as images, speech and text has not quite been replicated on tabular data; ensemble methods are still the go-to-methods for such data. One reason for this gap is perhaps that it is difficult to discover invariants for tabular data, in contrast to the pre-baked translation invariance of CNNs for natural images. In the absence of a strong architectural inductive bias, it is important to heavily augment the data to reduce the variance of fitting high-capacity models such as neural networks and handle situations with limited amounts of data. Our work identifies a simple way to achieve this augmentation, where Gibbs sampling is a natural fit that is computationally efficient (because we only need to run a few rounds) and facilitates fine-grained control over the sample-quality vs. the diversity of the augmented samples. Our study of augmentation in the distillation context is different than most existing work on augmentation for supervised learning, where a popular strategy is to use desired invariances that are known a priori to inspire augmentation strategies (since labels are not available for the augmented data in this setting, one typically has to assume each augmented example shares the same label as a real counterpart in the dataset).  Concerns. General concerns regarding model distillation include its potential use in “stealing” (cloning) models hidden behind an API. We are not aware of documented occurrences of this practice beyond academic research. This paper does not enhance the capabilities of such attacks as our augmentation strategy to improve distillation requires access to the training data. Another concern is models obtained through distillation may be less reproducible as one needs to repeat both the teacher- training and the student-training exactly. This should be addressed through well-documented code and saving the augmented dataset and all teacher/student/self-attention models to file. A final concern is the role of distillation in model interpretability. Once somebody distills an opaque model into an understandable model that almost retains the average performance of the original model, they may become overconfident that they understand the operating behavior of the opaque model, even though the distilled model may be a poor approximation in certain regions of the feature space (particularly regions poorly represented in the training data due to selection bias). The data augmentation strategy proposed in this paper may actually help mitigate this issue, but is by no means intended to resolve it. For true insight, we recommend careful analysis of the data/models as opposed to the hands-off AutoML + distillation approach presented here.",Broader Impact Statement,651,25,,,FALSE,FALSE,FALSE,"Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation",Deep Learning -> Efficient Inference Methods,Algorithms -> Boosting and Ensemble Methods; Algorithms -> Classification; Algorithms -> Regression,AutoML,"['Rasool Fakoor', ' Jonas Mueller', ' Nick Erickson', ' Pratik Chaudhari', ' Alexander Smola']","{'Amazon AWS', 'University of Pennsylvania', 'Amazon Web Services'}",1,1,1,{'USA'}
Adaptive Probing Policies for Shortest Path Routing,"Aditya Bhaskara, Sreenivas Gollapudi, Kostas Kollias, Kamesh Munagala",Adaptive Probing Policies for Shortest Path Routing,62da5a6d47be0029801ba74a17e47e1a,https://proceedings.neurips.cc/paper/2020/file/62da5a6d47be0029801ba74a17e47e1a-Paper.pdf,"Our work has consequences to the design and implementation of algorithms in large-scale traffic routing applications. Our model is simple and easily applicable to settings where expert advice can be used to refine the choice of routes. At the same time, we make a methodological contribution by showing that for the canonical objective of probing to find the best value with high probability has a submodular surrogate that enables an efficient greedy probing strategy.",Broader Impact,74,3,,,FALSE,FALSE,FALSE,Adaptive Probing Policies for Shortest Path Routing,Theory,Algorithms -> Stochastic Methods; Optimization -> Discrete Optimization; Optimization -> Stochastic Optimization; Theory -> Data-driven Algorithm Design,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Aditya Bhaskara', ' Sreenivas Gollapudi', ' Kostas Kollias', ' Kamesh Munagala']","{'University of Utah', 'Google Research', 'Duke University'}",1,1,1,{'USA'}
Approximate Heavily-Constrained Learning with Lagrange Multiplier Models,"Harikrishna Narasimhan, Andrew Cotter, Yichen Zhou, Serena Wang, Wenshuo Guo",Approximate Heavily-Constrained Learning with Lagrange Multiplier Models,62db9e3397c76207a687c360e0243317,https://proceedings.neurips.cc/paper/2020/file/62db9e3397c76207a687c360e0243317-Paper.pdf,"From an ethical standpoint, we believe that the main contribution of our work is that it will make it easier to approximately impose fine-grained statistical fairness constraints, particularly in the intersectional and ranking settings. The greatest weakness is that we cannot guarantee that every constraint will hold: instead, constraint violations are measured in terms of a function Φ , and while this function could technically be e.g. the magnitude of the most violated constraint, it is unlikely that any practical Lagrange multiplier model will work with such a Φ when the number of constraints is extremely large. However, as we show in our experiments, for many real-world problems our approach is effective in optimizing for reasonable choices of Φ (such as the 90-th percentile violation). A particular advantage of our approach is that we hope that it will fail gracefully , i.e. even when all of the constraints cannot be satisfied simultaneously, the observed behavior will still fall-back to something that most would consider “sensible”. However, except for the simple types of Lagrange multiplier models considered in Section 4, this remains largely an intuition , and while we provide experimental evidence that this intuition holds in practice, making this notion more precise is an exciting area for future research.",Broader Impact,209,5,,,FALSE,FALSE,FALSE,Approximate Heavily-Constrained Learning with Lagrange Multiplier Models,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Classification; Algorithms -> Ranking and Preference Learning; Optimization -> Convex Optimization; Theory -> Statistical Learning Theory,Optimization Methods (continuous or discrete),,"{'Google', 'UC Berkeley', 'Google, UC Berkeley', 'Google Research'}",1,1,1,{'USA'}
Faster Randomized Infeasible Interior Point Methods for Tall/Wide Linear Programs,"Agniva Chowdhury, Palma London, Haim Avron, Petros Drineas",Faster Randomized Infeasible Interior Point Methods for Tall/Wide Linear Programs,630eff1b380505a67570dff952ce4ad7,https://proceedings.neurips.cc/paper/2020/file/630eff1b380505a67570dff952ce4ad7-Paper.pdf,"Our work is focused on speeding up algorithms for tall/wide LPs. As such, it could have significant broader impacts by allowing users to solve increasingly larger LPs in the numerous settings discussed in our introduction. While applications of our work to real data could result into ethical considerations, this is an indirect (and unpredictable) side-effect of our work. Our experimental work uses publicly available datasets to evaluate the performance of our algorithms; no ethical considerations are raised.",Broader Impact,77,4,,,TRUE,TRUE,FALSE,Faster Randomized Infeasible Interior Point Methods for Tall/Wide Linear Programs,Optimization -> Convex Optimization,Applications -> Matrix and Tensor Factorization,Optimization Methods (continuous or discrete),"['Agniva Chowdhury', ' Palma London', ' Haim Avron', ' Petros Drineas']","{'Caltech', 'Purdue University', 'Tel Aviv University'}",1,0,0,"{'USA', 'Israel'}"
Sliding Window Algorithms for k-Clustering Problems,"Michele Borassi, Alessandro Epasto, Silvio Lattanzi, Sergei Vassilvitskii, Morteza Zadimoghaddam",Sliding Window Algorithms for k-Clustering Problems,631e9c01c190fc1515b9fe3865abbb15,https://proceedings.neurips.cc/paper/2020/file/631e9c01c190fc1515b9fe3865abbb15-Paper.pdf,"Clustering is a fundamental unsupervised machine learning problem that lies at the core of multiple real-world applications. In this paper, we address the problem of clustering in a sliding window setting. As we argued in the introduction, the sliding window model allows us to discard old data which is a core principle in data retention policies. Whenever a clustering algorithm is used on user data it is important to consider the impact it may have on the users. In this work we focus on the algorithmic aspects of the problem and we do not address other considerations of using clustering that may be needed in practical settings. For instance, there is a burgeoning literature on fairness considerations in unsupervised methods, including clustering, which further delves into these issues. We refer to this literature [22, 40, 11] for addressing such issues.",Broader Impact,140,7,,,FALSE,FALSE,FALSE,Sliding Window Algorithms for k-Clustering Problems,Algorithms -> Clustering,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Michele Borassi', ' Alessandro Epasto', ' Silvio Lattanzi', ' Sergei Vassilvitskii', ' Morteza Zadimoghaddam']","{'Google', 'Google Switzerland GmbH', 'Google Research'}",0,1,0,{'USA'}
AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning,"Ximeng Sun, Rameswar Panda, Rogerio Feris, Kate Saenko",AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning,634841a6831464b64c072c8510c7f35c,https://proceedings.neurips.cc/paper/2020/file/634841a6831464b64c072c8510c7f35c-Paper.pdf,"Our research improves the capacity of deep neural networks to solve many tasks at once in a more efficient manner. It enables the use of smaller networks to support more tasks, while performing knowledge transfer between related tasks to improve their accuracy. For example, we showed that our proposed approach can solve five computer vision tasks (semantic segmentation, surface normal prediction, depth prediction, keypoint detection and edge estimation) with 80% fewer parameters while achieving the same performance as the standard approach. Our approach can thus have a positive impact on applications that require multiple tasks such as computer vision for robotics. Potential applications could be in assistive robots, autonomous navigation, robotic picking and packaging, rescue and emergency robotics and AR/VR systems. Our research can reduce the memory and power consumption of such systems and enable them to be deployed for longer periods of time and become smaller and more agile. The lessened power consumption could have a high impact on the environment as AI systems become more prevalent. Negative impacts of our research are difficult to predict, however, it shares many of the pitfalls associated with deep learning models. These include susceptibility to adversarial attacks and data poisoning, dataset bias, and lack of interpretablity. Other risks associated with deployment of computer vision systems include privacy violations when images are captured without consent, or used to track individuals for profit, or increased automation resulting in job losses. While we believe that these issues should be mitigated, they are beyond the scope of this paper. Furthermore, we should be cautious of the result of failure of the system which could impact the performance/user experience of the high-level AI systems relied on our research.",Broader Impact,281,12,,,FALSE,FALSE,FALSE,AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning,Algorithms -> Multitask and Transfer Learning,,Deep learning,"['Ximeng Sun', ' Rameswar Panda', ' Rogerio Feris', ' Kate Saenko']","{'IBM Research', 'Boston University', 'IBM Research AI'}",1,1,1,{'USA'}
Approximate Cross-Validation for Structured Models,"Soumya Ghosh, William T. Stephenson, Tin D. Nguyen, Sameer Deshpande, Tamara Broderick",Approximate Cross-Validation for Structured Models,636efd4f9aeb5781e9ea815cdd633e52,https://proceedings.neurips.cc/paper/2020/file/636efd4f9aeb5781e9ea815cdd633e52-Paper.pdf,"Accurate evaluation enables more reliable machine learning methods and more trustworthy commu- nication of their capabilities. To the extent that machine learning methods may be beneficial – in that they may be used to facilitate medical diagnosis, assistive technology for individuals with motor impairments, or understanding of helpful economic interventions – accurate evaluation ensures these benefits are fully realized. To the extent that machine learning methods may be harmful – in that they may used to facilitate the spread of false information or privacy erosion – accurate evaluation should still make these methods more effective at their goals, even if societally undesirable. As in any machine learning methodology, it is also important for the buyer to beware; while we have tried to pick a broad array of experimental settings and to support our methods with theory, there may remain cases of interest when our approximations fail without warning. In fact, we take care to note that cross-validation and its points of failure are still not fully understood. All of our results are relative to exact cross-validation – since it is taken as the de facto standard for evaluation in the machine learning community (not without reason [Musgrave et al., 2020]). But when exact cross-validation fails, we therefore expect our method to fail as well.  Acknowledgments. This work was supported by the MIT-IBM Watson AI Lab, DARPA, the CSAIL–MSR Trustworthy AI Initiative, an NSF CAREER Award, an ARO YIP Award, ONR, and Amazon. Broderick Group is also supported by the Sloan Foundation, ARPA-E, Department of the Air Force, and MIT Lincoln Laboratory.",Broader Impact,261,10,,,FALSE,FALSE,FALSE,Approximate Cross-Validation for Structured Models,Probabilistic Methods -> Graphical Models,Algorithms -> Model Selection and Structure Learning; Algorithms -> Structured Prediction; Applications -> Time Series Analysis; Probabilistic Methods -> Latent Variable Models,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Soumya Ghosh', ' William Stephenson', ' Tin D Nguyen', ' Sameer Deshpande', ' Tamara Broderick']","{'Wharton Statistics', 'IBM Research', 'MIT'}",1,1,1,{'USA'}
"Exemplar VAE: Linking Generative Models, Nearest Neighbor Retrieval, and Data Augmentation","Sajad Norouzi, David J. Fleet, Mohammad Norouzi","Exemplar VAE: Linking Generative Models, Nearest Neighbor Retrieval, and Data Augmentation",63c17d596f401acb520efe4a2a7a01ee,https://proceedings.neurips.cc/paper/2020/file/63c17d596f401acb520efe4a2a7a01ee-Paper.pdf,"The ideas described in our paper concern the development of a new fundamental class of unsupervised learning algorithm, rather than an application per se. One important property of the method stems from it’s non-parametric form, i.e., as an exemplar-based model. As such, rather than having the ""model"" represented solely in the weights of an amorphous non-linear neural network, in our case much of the model is expressed directly in terms of the dataset of exemplars. As such, the model is somewhat more interpretable and may facilitate the examination or discovery of bias, which has natural social and ethical implications. Beyond that, the primary social and ethical implications will derive from the way in which the algorithm is applied in different domains.",Broader Impact Statement,121,5,,,FALSE,FALSE,FALSE,"Exemplar VAE: Linking Generative Models, Nearest Neighbor Retrieval, and Data Augmentation",Deep Learning -> Generative Models,Algorithms -> Representation Learning; Deep Learning -> Deep Autoencoders; Probabilistic Methods -> Variational Inference,Deep learning,"['Sajad Norouzi', ' David J Fleet', ' Mohammad Norouzi']","{'University of Toronto', 'University of Toronto / Vector Institute', 'Google Brain'}",1,1,1,"{'Canada', 'USA'}"
Debiased Contrastive Learning,"Ching-Yao Chuang, Joshua Robinson, Yen-Chen  Lin, Antonio Torralba, Stefanie Jegelka",Debiased Contrastive Learning,63c3ddcc7b23daa1e42dc41f9a44a873,https://proceedings.neurips.cc/paper/2020/file/63c3ddcc7b23daa1e42dc41f9a44a873-Paper.pdf,"Unsupervised representation learning can improve learning when only small amounts of labeled data are available. This is the case in many applications of societal interest, such as medical data analysis [ 5, 31], the sciences [22], or drug discovery and repurposing [38]. Improving representation learning, as we do here, can potentially benefit all these applications. However, biases in the data can naturally lead to biases in the learned representation [29]. These biases can, for example, lead to worse performance for smaller classes or groups. For instance, the majority groups are sampled more frequently than the minority ones [16]. In this respect, our method may suffer from similar biases as standard contrastive learning, and it is an interesting avenue of future research to thoroughly test and evaluate this.",Broader Impact,127,7,,,TRUE,TRUE,FALSE,Debiased Contrastive Learning,Algorithms -> Representation Learning,Algorithms -> Unsupervised Learning; Deep Learning -> Embedding Approaches,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yao Chuang', ' Joshua Robinson', 'Chen Lin', ' Antonio Torralba', ' Stefanie Jegelka']",{'MIT'},1,0,0,{'USA'}
UCSG-NET- Unsupervised Discovering of Constructive Solid Geometry Tree,"Kacper Kania, Maciej Zieba, Tomasz Kajdanowicz",UCSG-N ET - Unsupervised Discovering of Constructive Solid Geometry Tree,63d5fb54a858dd033fe90e6e4a74b0f0,https://proceedings.neurips.cc/paper/2020/file/63d5fb54a858dd033fe90e6e4a74b0f0-Paper.pdf,"UCSG-N ET can find applications in CAD software. When applied, it is possible to retrieve a CSG parse tree for a particular object of interest. Hence, for a situation when a 3D object was modeled with a sculpting tool, the model can approximate it with single primitives and operations between them. Then, such a reconstruction can be integrated into existing CAD models. We find that beneficial in speeding up the prototyping process in 3D modeling. However, inexperienced CAD software users can rely heavily on presented assumptions. In the era of 3D printing ubiquity, printed elements out of reconstructed CSG parse trees can be erroneous, thus breaking the whole item. Therefore, we note that integrating our method into existing software should serve mainly as a prototyping device. We encourage further research on an unsupervised CSG parse tree recovery. We suspect that this area stagnated due to constraining limitations that a CSG tree creates a single object, but a single object can be created out of infinity many CSG trees. Therefore, new methods need to be invented that provide good approximations of CSG trees with short inference times.",Broader Impact,186,11,,,FALSE,FALSE,FALSE,UCSG-NET- Unsupervised Discovering of Constructive Solid Geometry Tree,Applications -> Computer Vision,"Algorithms -> Unsupervised Learning; Deep Learning -> CNN Architectures; Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,"['Kacper Kania', ' Maciej Zieba', ' Tomasz Kajdanowicz']","{'Wrocław University of Science and Technology', 'Wroclaw University of Science and Technology, Tooploox', 'Wroclaw University of Science and Technology'}",1,1,1,{'Poland'}
Generalized Boosting,"Arun Suggala, Bingbin Liu, Pradeep Ravikumar",Generalized Boosting,63f44623dd8686aba388944c8810087f,https://proceedings.neurips.cc/paper/2020/file/63f44623dd8686aba388944c8810087f-Paper.pdf,"Deep learning has been tremendously successful over the past decade in many application areas such as computer vision, image recognition, speech recognition, and natural language processing. Despite this success, deep neural networks have largely remained a mystery. With millions of parameters, these models are blackboxes to humans, making it harder to diagnose errors. This also makes it harder to adopt these models in critical applications such as healthcare, law and finance. Consequently, it is crucial to come up with techniques that make neural networks transparent and easy to understand. We take a step towards this goal by drawing inspiration from classical boosting. Similar to classical boosting, our generalized boosting framework builds complex models greedily. But unlike classical boosting, it allows us to derive learning algorithms that have performance close to that of end-to-end trained DNNs. Moreover, models built using our framework are easy to understand and come with strong theoretical guarantees.",Broader Impact,151,9,,,TRUE,TRUE,FALSE,Generalized Boosting,Algorithms -> Boosting and Ensemble Methods,Deep Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Arun Suggala', ' Bingbin Liu', ' Pradeep Ravikumar']",{'Carnegie Mellon University'},1,0,0,{'USA'}
COT-GAN: Generating Sequential Data via Causal Optimal Transport,"Tianlin Xu, Li Kevin Wenliang, Michael Munn, Beatrice Acciaio",COT-GAN: Generating Sequential Data via Causal Optimal Transport,641d77dd5271fca28764612a028d9c8e,https://proceedings.neurips.cc/paper/2020/file/641d77dd5271fca28764612a028d9c8e-Paper.pdf,"The COT-GAN algorithm introduced in this paper is suitable to generate sequential data, when the real dataset consists of i.i.d. sequences or of stationary time series. It opens up doors to many applications that can benefit from time series synthesis. For example, researchers often do not have access to abundant training data due to privacy concerns, high cost, and data scarcity. This hinders the capability of building accurate predictive models. Ongoing research is aimed at developing a modified COT-GAN algorithm to generate financial time series. The high non-stationarity of financial data requires different features and architectures, whilst causality when measuring distances between sequences remains the crucial tool. The application to market generation is of main interest for the financial and insurance industry, for example in model- independent pricing and hedging, portfolio selection, risk management, and stress testing. In broader scientific research, our approach can be used to estimate from data the parameters of simulation-based models that describe physical processes. These models can be, for instance, differential equations describing neural activities, compartmental models in epidemiology, and chemical reactions involving multiple reagents.",7 Broader impact,180,10,,,FALSE,FALSE,FALSE,COT-GAN: Generating Sequential Data via Causal Optimal Transport,Algorithms -> Adversarial Learning,Algorithms -> Unsupervised Learning; Applications -> Time Series Analysis; Applications -> Video Analysis; Deep Learning -> Adversarial Networks; Deep Learning -> Generative Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Tianlin Xu', ' Wenliang Le', ' Michael Munn', ' Beatrice Acciaio']","{'Google', 'Gatsby Unit, UCL', 'London School of Economics and Political Science', 'London School of Economics'}",1,1,1,"{'UK', 'USA'}"
Impossibility Results for Grammar-Compressed Linear Algebra,"Amir Abboud, Arturs Backurs, Karl Bringmann,  Marvin  Künnemann",Impossibility Results for Grammar-Compressed Linear Algebra,645e6bfdd05d1a69c5e47b20f0a91d46,https://proceedings.neurips.cc/paper/2020/file/645e6bfdd05d1a69c5e47b20f0a91d46-Paper.pdf,"The broader impact of our work is to inform algorithm design for compressed linear algebra, which can lead to faster algorithms for a variety of tasks on large data sets. The ethical consequences depend on the specific application. We do not see any inherently new concerns raised by our results, beyond those that follow generally from faster algorithms and an increased ability to process data.",Broader Impact,65,3,,,FALSE,FALSE,FALSE,Impossibility Results for Grammar-Compressed Linear Algebra,Algorithms -> Data Compression,Algorithms; Algorithms -> Communication- or Memory-Bounded Learning; Algorithms -> Regression; Theory; Theory -> Data-driven Algorithm Design,Theory (including computational and statistical analyses),"['Amir Abboud', ' Arturs Backurs', ' Karl Bringmann', ' Marvin Künnemann']","{'IBM research', 'TTIC', 'Max-Planck-Institut für Informatik', 'Saarland University'}",1,1,1,"{'USA', 'Germany'}"
Understanding spiking networks through convex optimization,"Allan Mancoo, Sander Keemink, Christian K. Machens",Understanding spiking networks through convex optimization,64714a86909d401f8feb83e8c2d94b23,https://proceedings.neurips.cc/paper/2020/file/64714a86909d401f8feb83e8c2d94b23-Paper.pdf,"We see two possible impacts of our work. First, the use of low-powered computer chips inspired by spiking neurons (neuromorphic engineering) has been seeing a boom in technologies recently [ 38]. The work we present here will help these technologies as it shows how to design robust and spike- efficient networks that perform interesting computations. Second, the field of convex optimization may benefit from this work, as we show that convex optimization techniques may be directly applicable to neural systems. Direct potential negative impacts are harder to gauge, due to the relatively local nature of this type of publication. Any negative impact will likely be found in the aggregate of many studies, rather than any specific study (exceptions, of course, exist). In such an aggregate, we see potential for danger and misuse of powerful machine-learning algorithms on low-powered devices, as our understanding of using low-powered spiking networks grows. Mass use of low-powered devices could worsen existing problems, both unintentionally (such as biased functions due to biased datasets, e.g. [39]), and intentionally (such as weaponry and surveillance applications, potentially trained by such biased datasets). These problems are worsened by the fact that many deep networks are effectively black boxes, for which we don’t understand their core computations. As such, in the long term, our study might also help alleviate these types of problems as our contribution helps to understand the inner workings of SNNs.",Broader Impact,233,10,,,FALSE,FALSE,FALSE,Understanding spiking networks through convex optimization,Neuroscience and Cognitive Science,Algorithms -> Dynamical Systems; Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Neuroscience; Optimization -> Convex Optimization,Neuroscience and cognitive science,"['Allan Mancoo', ' Sander Keemink', ' Christian K Machens']",{'Champalimaud Centre for the Unknown'},1,0,0,{'Portugal'}
Better Full-Matrix Regret via Parameter-Free Online Learning,Ashok Cutkosky,Better Full-Matrix Regret via Parameter-Free Online Learning,6495cf7ca745a9443508b86951b8e33a,https://proceedings.neurips.cc/paper/2020/file/6495cf7ca745a9443508b86951b8e33a-Paper.pdf,"Our work introduces new algorithms and analysis for generic optimization problems. Our contribution is entirely mathematical, and we do not anticipate it engendering negative ethical concerns.",Broader Impact,26,2,TRUE,FALSE,FALSE,FALSE,FALSE,Better Full-Matrix Regret via Parameter-Free Online Learning,Algorithms -> Online Learning,Optimization -> Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),['Ashok Cutkosky'],{'Google Research'},0,1,0,{'USA'}
Large-Scale Methods for Distributionally Robust Optimization,"Daniel Levy, Yair Carmon, John C. Duchi, Aaron Sidford",Large-Scale Methods for Distributionally Robust Optimization,64986d86a17424eeac96b08a6d519059,https://proceedings.neurips.cc/paper/2020/file/64986d86a17424eeac96b08a6d519059-Paper.pdf,"The robustness of machine learning (ML) models, or lack thereof, has far-reaching present and future societal consequences: in autonomous vehicles [39, 18], medical diagnosis [53], facial recognition [11], credit scoring [29], and recidivism prediction [12, 1], failure of ML to perform robustly across sub-population or under distribution shift can have disastrous real-life consequences, particularly for members of underserved and/or under-represented groups. Distributionally robust optimization (DRO) is emerging as a methodology for imposing the constraint that models perform uniformly well across subgroups, and several works conduct experiments demonstrating its benefit in promoting fairness [34, 24, 74] and robustness [68, 61] in ML. However, the computational experiments in these works are relatively small in scale, and there exist serious computational impediments to scaling up DRO. Consequently, the potential benefits of several DRO formulations remain unexplored. The main contribution of our work is in strengthening the theoretical and algorithmic foundations of two fundamental DRO formulations. In particular, for χ 2 -divergence uncertainty sets we give the first proof that stochastic gradient methods can scale to large data similarly to they way they scale for standard empirical risk minimization. We believe that our algorithms will serve a basis for future experimentation with CVaR and χ 2 divergence DRO, and we hope that the resulting findings would lead to more robust and fair machine learning algorithms with positive societal impact. Towards that end, we will release an implementation of our DRO gradient estimators that integrates seamlessly into the PyTorch optimization framework and is therefore suitable for application in a wide range of ML tasks. In addition, we believe that our work is a step towards a suite of algorithms capable of solving a broader class of DRO problems at scale, including e.g., uncertainty set with explicit group structure as proposed in [38, 61]. We believe that such algorithm suite will empower machine learning researchers and engineers to create more reliable and ethical systems. However, greater applicability and simplicity always comes with the risk of irresponsible and superficial use. In particular, we are concerned with the possibility that DRO might become a marketing scheme to sell off ML systems as robust without proper verification. Therefore, the development of robust training procedures must go hand-in-hand with the development of rigorous and independent evaluation methodologies for auditing of algorithms [36, 54, 41, 14, 45].",Broader Impact,386,13,,,FALSE,FALSE,FALSE,Large-Scale Methods for Distributionally Robust Optimization,Optimization -> Stochastic Optimization,Algorithms; Algorithms -> Large Scale Learning; Algorithms -> Stochastic Methods; Optimization -> Convex Optimization; Theory -> High-Dimensional Inference; Theory -> Regularization,Optimization Methods (continuous or discrete),"['Daniel Levy', ' Yair Carmon', ' John Duchi', ' Aaron Sidford']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Analysis and Design of Thompson Sampling for Stochastic Partial Monitoring,"Taira Tsuchiya, Junya Honda, Masashi Sugiyama",Analysis and Design of Thompson Sampling for Stochastic Partial Monitoring,649d45bf179296e31731adfd4df25588,https://proceedings.neurips.cc/paper/2020/file/649d45bf179296e31731adfd4df25588-Paper.pdf,"Application. Partial monitoring (PM) includes various online decision-making problems such as multi-armed bandits, linear bandits, dynamic pricing, and label e cient prediction. Not only can PM handles them, the dueling bandits, combinatorial bandits, transductive bandits, and many other problems can be seen as a partial monitoring game, as discussed in Kirschner et al. (2020). Therefore, our analysis of Thompson sampling (TS) for PM games pushes the application of TS to a more wide range of online decision-making problems forward. Moreover, PM has the potential that novel online-decision making problems are newly discovered, where we have to handle the limited feedback in an online fashion. Practical Use. The obvious advantage of using TS is that the users can easily apply the algorithm to their problems. They do not have to solve mathematical optimization problems, which are often required to solve when using non-sampling-based algorithms (Bartók et al., 2012; Komiyama et al., 2015). For the negative side, the theoretical analysis for the regret upper bound might make the users become overconfident when the users use their algorithms. For example, they might use the TSPM algorithm to the linear PM game with heavy-tailed noise, such as sub-exponential noise, without noticing it. Nevertheless, this is not an TS-specific problem, but one that can be found in many theoretical studies, and TS is still one of the most promising policies.",Broader Impact,225,12,,,FALSE,FALSE,FALSE,Analysis and Design of Thompson Sampling for Stochastic Partial Monitoring,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Taira Tsuchiya', ' Junya Honda', ' Masashi Sugiyama']","{'The Univerisity of Tokyo / RIKEN', 'RIKEN / University of Tokyo', 'The University of Tokyo'}",1,0,0,{'Japan'}
Bandit Linear Control,"Asaf Cassel, Tomer Koren",Bandit Linear Control,64a08e5f1e6c39faeb90108c430eb120,https://proceedings.neurips.cc/paper/2020/file/64a08e5f1e6c39faeb90108c430eb120-Paper.pdf,There are no foreseen ethical or societal consequences for the research presented herein.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Bandit Linear Control,Algorithms -> Online Learning,Algorithms -> Bandit Algorithms; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Asaf Cassel', ' Tomer Koren']","{'Tel Aviv University and Google', 'Tel Aviv University'}",1,0,0,{'Israel'}
Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals,"Tongzhou Mu, Jiayuan Gu, Zhiwei Jia, Hao Tang, Hao Su",Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals,64dcf3c521a00dbb4d2a10a27a95a9d8,https://proceedings.neurips.cc/paper/2020/file/64dcf3c521a00dbb4d2a10a27a95a9d8-Paper.pdf,"Our work is a basic step towards building autonomous agents that can train in limited environment and perform well in more complicated environment with similar reasoning rationale, using vision as the primary information source. Particularly, we try to build a system that makes decisions in a way that human may interpret. From an ethical aspect, it is helpful to build AI that humans can better communicate with.",7 Broader Impact,67,3,,,FALSE,FALSE,FALSE,Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals,Reinforcement Learning and Planning,"Algorithms -> Relational Learning; Deep Learning -> Visualization, Interpretability, and Explainability; Reinforcement Learning and Planning -> Planning",Reinforcement learning and planning,,"{'University of California, San Diego', 'Shanghai Jiao Tong University', 'UCSD'}",1,0,0,"{'USA', 'China'}"
PEP: Parameter Ensembling by Perturbation,"Alireza Mehrtash, Purang Abolmaesumi, Polina Golland, Tina Kapur, Demian Wassermann, William Wells",PEP: Parameter Ensembling by Perturbation,652c208b21f13f6e995bfc1154a1a2e5,https://proceedings.neurips.cc/paper/2020/file/652c208b21f13f6e995bfc1154a1a2e5-Paper.pdf,"Training large networks can be highly compute intensive, so improved performance and calibration by ensembling approaches that use additional training, e.g., deep ensembling, can potentially cause undesirable contributions to the carbon footprint. In this setting, PEP can be seen as a way to reduce training costs, though prediction time costs are increased, which might matter if the resulting network is very heavily used. Because it is easy to apply, and no additional training (or access to the training data) is needed, PEP provides a safe way to tune or improve a network that was trained on sensitive data, e.g., protected health information. Similarly, PEP may be useful in competitions to gain a mild advantage in performance.",6 Broader Impact,116,4,,,FALSE,FALSE,FALSE,PEP: Parameter Ensembling by Perturbation,Deep Learning,Algorithms -> Boosting and Ensemble Methods; Algorithms -> Classification; Applications -> Computer Vision,,"['Alireza Mehrtash', ' Purang Abolmaesumi', ' Polina Golland', ' Tina Kapur', ' Demian Wassermann', ' William Wells']","{'UBC', 'Harvard Medical School', 'University of British Columbia', 'Massachusetts Institute of Technology', 'Inria'}",1,0,0,"{'Singapore', 'Canada', 'France', 'USA'}"
Theoretical Insights Into Multiclass Classification: A High-dimensional Asymptotic View,"Christos Thrampoulidis, Samet Oymak, Mahdi Soltanolkotabi",Theoretical Insights Into Multiclass Classification: A High-dimensional Asymptotic View,6547884cea64550284728eb26b0947ef,https://proceedings.neurips.cc/paper/2020/file/6547884cea64550284728eb26b0947ef-Paper.pdf,"In this paper we develop a precise and asymptotically exact understanding of the statistical behavior of a variety of classification algorithms. In particular we precisely, characterize how the total and class-wise accuracy varies under different training algorithms, data distributions, problem dimensions, inter/intra class correlations and class priors. Despite being theoretical/foundational in nature it has potential for broader practical impact. In particular, our precise characterization of class-wise accuracy allows us to understand how different training algorithms impact accuracy of machine learning algorithms on rare/minority classes. Such a precise understanding may help guide the development of more fair/equitable algorithms. On the flip side, such insights may potentially also be used nefariously enabling the marginalization of rare/minority classes by developing algorithms that reduce their class-wise accuracy.",Broader Impact,123,6,,,FALSE,TRUE,FALSE,Theoretical Insights Into Multiclass Classification: A High-dimensional Asymptotic View,Theory -> High-Dimensional Inference,Theory -> Large Deviations and Asymptotic Analysis,Theory (including computational and statistical analyses),"['Christos Thrampoulidis', ' Samet Oymak', ' Mahdi Soltanolkotabi']","{'UCSB', 'University of Southern california', 'University of California Berkeley'}",1,0,0,{'USA'}
Adversarial Example Games,"Joey Bose, Gauthier Gidel, Hugo Berard, Andre Cianflone, Pascal Vincent, Simon Lacoste-Julien, Will Hamilton",Adversarial Example Games,65586803f1435736f42a541d3a924595,https://proceedings.neurips.cc/paper/2020/file/65586803f1435736f42a541d3a924595-Paper.pdf,"Adversarial attacks, especially ones under more realistic threat models, pose several important security, ethical, and privacy risks. In this work, we introduce the NoBox attack setting, which generalizes many other blackbox transfer settings, and we provide a novel framework to ground and study attacks theoretically and their transferability to other functions within a class of functions. As the NoBox threat model represents a more realistic setting for adversarial attacks, our research has the potential to be used against a class of machine learning models in the wild. In particular, in terms of risk, malicious actors could use approaches based on our framework to generate attack vectors that compromise production ML systems or potentially bias them toward specific outcomes. As a concrete example, one can consider creating transferrable examples in the physical world, such as the computer vision systems of autonomous cars. While prior works have shown the possibility of such adversarial examples —i.e., adversarial traffic signs, we note that there is a significant gap in translating synthetic adversarial examples to adversarial examples that reside in the physical world [45]. Understanding and analyzing the NoBox transferability of adversarial examples to the physical world—in order to provide public and academic visibility on these risks—is an important direction for future research. Based on the known risks of designing new kinds of adversarial attacks—discussed above—we now outline the ways in which our research is informed by the intent to mitigate these potential societal risks. For instance, our research demonstrates that one can successfully craft adversarial attacks even in the challenging NoBox setting. It raises many important considerations when developing robustness approaches. A straightforward extension is to consider our adversarial example game (AEG) framework as a tool for training robust models. On the theoretical side, exploring formal verification of neural networks against NoBox adversaries is an exciting direction for continued exploration. As an application, ML practitioners in the industry may choose to employ new forms of A/B testing with different types of adversarial examples, of which AEG is one method to robustify and stress test production systems further. Such an application falls in line with other general approaches to red teaming AI systems [10] and verifiability in AI development. In essence, the goal of such approaches, including adversarial examples for robustness, is to align AI systems’ failure modes to those found in human decision making.",Broader Impact,390,15,,,FALSE,FALSE,FALSE,Adversarial Example Games,Algorithms -> Adversarial Learning,Deep Learning -> Adversarial Networks,Adversarial examples,"['Joey Bose', ' Gauthier Gidel', ' Hugo Berard', ' Andre Cianflone', ' Pascal Vincent', 'Julien', ' Will Hamilton']","{'McGill/MILA', 'Mila/McGill', 'McGill', 'MILA', 'Mila'}",1,0,0,{'Canada'}
Residual Distillation: Towards Portable Deep Neural Networks without Shortcuts,"Guilin Li, Junlei Zhang, Yunhe Wang, Chuanjian Liu, Matthias Tan, Yunfeng Lin, Wei Zhang, Jiashi Feng, Tong Zhang",Residual Distillation: Towards Portable Deep Neural Networks without Shortcuts,657b96f0592803e25a4f07166fff289a,https://proceedings.neurips.cc/paper/2020/file/657b96f0592803e25a4f07166fff289a-Paper.pdf,"The deployment inefficiency caused by shortcuts connections in CNN models has been noticed but largely ignored due to the significant accuracy improvement they bring to CNN models. In this work, for the first time, we consider trains the CNN models with shortcuts and deploy them without. Our experiments show that plain-CNN trained with our method would achieve comparable accuracy with ResNet with the same length while significantly improve the deployment power, memory, and latency efficiency. This work is also among the pioneering works that utilize the gradients of the teacher network to train the student network so that the student network would achieve similar high performance with the teacher network while having favorable deployment property. A potential limitation of this work is that we only try to pass the gradients of a teacher network with the same channel and depth to the student network. An interesting future work would be to explore passing the gradient of a teacher model with a different structure to the student model.",Broader Impact,167,6,,,FALSE,FALSE,FALSE,Residual Distillation: Towards Portable Deep Neural Networks without Shortcuts,Deep Learning,Applications -> Object Recognition; Deep Learning -> CNN Architectures; Deep Learning -> Efficient Inference Methods,AutoML,"['Guilin Li', ' Junlei Zhang', ' Yunhe Wang', ' Chuanjian Liu', ' Matthias Tan', ' Yunfeng Lin', ' Wei Zhang', ' Jiashi Feng', ' Tong Zhang']","{'CityU', 'Tencent AI Lab', 'Shanghai Jiao Tong University', 'National University of Singapore'}",1,1,1,"{'Singapore', 'China'}"
Provably Efficient Neural Estimation of Structural Equation Models: An Adversarial Approach,"Luofeng Liao, You-Lin Chen, Zhuoran Yang, Bo Dai, Mladen Kolar, Zhaoran Wang",Provably Efficient Neural Estimation of Structural Equation Model: An Adversarial Approach,65a99bb7a3115fdede20da98b08a370f,https://proceedings.neurips.cc/paper/2020/file/65a99bb7a3115fdede20da98b08a370f-Paper.pdf,"In recent years, the impact of machine learning (ML) on economics is already well underway [5, 15], and our work serves as a complement to this line of research. On the one hand, machine learning methods such as random forest, support vector machines and neural networks provide great flexibility in modeling, while traditional tools in structural estimation that are well versed in the econometrics community are still primitive, despite recent advances [32, 26, 7, 21]. On the other hand, to facilitate ML-base decision making, one must be aware of the distinction between prediction and causal inference. Our method provides an NN-based solution to estimation of generalized SEMs, which encompass a wide range of econometric and causal inference models. However, we remark that in order to apply the method to policy and decision problems, one must pay equal attention to other aspects of the model, such as interpretability, robustness of the estimates, fairness and nondiscrimination, assumptions required for model identification, and the testability of those assumptions. Unthoughtful application of ML methods in an attempt to draw causal conclusions must be avoided for both ML researchers and economists.",Broader Impact,186,6,,,FALSE,FALSE,FALSE,Provably Efficient Neural Estimation of Structural Equation Models: An Adversarial Approach,Theory -> Game Theory and Computational Economics,Deep Learning -> Adversarial Networks; Deep Learning -> Analysis and Understanding of Deep Networks; Theory -> Frequentist Statistics,Causality,"['Luofeng Liao', 'Lin Chen', ' Zhuoran Yang', ' Bo Dai', ' Mladen Kolar', ' Zhaoran Wang']","{'Department of Statistics, University of Chicago', 'Princeton', 'Northwestern University', 'Google Brain', 'University of Chicago'}",1,1,1,{'USA'}
Security Analysis of Safe and Seldonian Reinforcement Learning Algorithms,"Pinar Ozisik, Philip S. Thomas",Security Analysis of Safe and Seldonian Reinforcement Learning Algorithms,65ae450c5536606c266f49f1c08321f2,https://proceedings.neurips.cc/paper/2020/file/65ae450c5536606c266f49f1c08321f2-Paper.pdf,"In our paper, we discussed the application of Seldonian algorithms to the treatment of diabetes patients. We emphasize that the mathematical safety guarantees provided by Seldonian RL are not a replacement for domain-specific safety requirements (e.g., the diabetes treatment would still need oversight for medical safety), but still improve the potential for RL to be applied to problems with real-world consequences. Seldonian RL has also been proposed for creating fair algorithms, i.e., those that aim to reduce discriminative behavior in intelligent tutoring systems and loan approvals [31]. In the last decade, data breaches on the Democratic National Committee’s emails, and on companies such as Equifax and Yahoo! have made cyber attacks on systems and databases a very legitimate and ubiquitous concern [45; 33; 14]. Therefore, when creating safe AI algorithms that can directly impact people’s lives, we should ensure not only performance guarantees with high probability, but also the development of metrics that evaluate the “quality” of training data, which often reflect systemic biases and human error.",Broader Impact,167,6,,,TRUE,TRUE,FALSE,Security Analysis of Safe and Seldonian Reinforcement Learning Algorithms,Reinforcement Learning and Planning -> Reinforcement Learning,"Algorithms -> Adversarial Learning; Social Aspects of Machine Learning -> AI Safety; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Reinforcement learning and planning,"['Pinar Ozisik', ' Philip Thomas']","{'University of Massachusetts Amherst', 'UMass Amherst'}",1,0,0,{'USA'}
Learning to Play Sequential Games versus Unknown Opponents,"Pier Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, Andreas Krause",Learning to Play Sequential Games versus Unknown Opponents,65cf25ef90de99d93fa96dc49d0d8b3c,https://proceedings.neurips.cc/paper/2020/file/65cf25ef90de99d93fa96dc49d0d8b3c-Paper.pdf,"Our approach is motivated by sequential decision-making problems that arise in several domains such as road traffic, markets, and security applications with potentially significant societal benefits. In such domains, it is important to predict how the system responds to any given decision and take this into account to achieve the desired performance. The methods proposed in this paper require to observe and quantify (via suitable indicators) the response of the system and to dispose of computational resources to process the observed data. Moreover, it is important that the integrity and the reliability of such data are verified, and that the used algorithms are complemented with suitable measures that ensure the safety of the system at any point in time.",Broader Impact,119,4,,,FALSE,FALSE,FALSE,Learning to Play Sequential Games versus Unknown Opponents,Applications,Algorithms -> Bandit Algorithms; Algorithms -> Online Learning; Probabilistic Methods -> Gaussian Processes; Reinforcement Learning and Planning -> Planning,Reinforcement learning and planning,"['Pier Giuseppe Sessa', ' Ilija Bogunovic', ' Maryam Kamgarpour', ' Andreas Krause']","{'ETH Zurich', 'ETH Zürich'}",1,0,0,{'Switzerland'}
Further Analysis of Outlier Detection with Deep Generative Models,"Ziyu Wang, Bin Dai, David Wipf, Jun Zhu",Further Analysis of Outlier Detection with Deep Generative Models,66121d1f782d29b62a286909165517bc,https://proceedings.neurips.cc/paper/2020/file/66121d1f782d29b62a286909165517bc-Paper.pdf,"This paper explores the nuances of applying DGMs to outlier detection, with the goal of understanding the limitations of current approaches as well as practical workarounds. From the perspective of fundamental research into existing machine learning and data mining techniques, we believe that this contribution realistically has little potential downside. Additionally, given the pernicious role that outliers play in numerous application domains, e.g., fraud, computer intrusion, etc., better preventative measures can certainly play a positive role. That being said, it is of course always possible to envision scenarios whereby an outlier detection system could inadvertently introduce bias that unfairly penalizes a marginalized group, e.g., in processing loan applications. Even so, it is our hope that the analysis herein could more plausibly be applied to exposing and mitigating such algorithmic biases.",Broader Impact,130,5,,,FALSE,FALSE,FALSE,Further Analysis of Outlier Detection with Deep Generative Models,Deep Learning -> Generative Models,Algorithms -> Uncertainty Estimation; Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Ziyu Wang', ' Bin Dai', ' David P Wipf', ' Jun Zhu']","{'Microsoft Research Asia', 'Tsinghua University', 'Samsung Research China - Beijing'}",1,1,1,"{'South Korea', 'USA', 'China'}"
Bridging Imagination and Reality for Model-Based Deep Reinforcement Learning,"Guangxiang Zhu, Minghao Zhang, Honglak Lee, Chongjie Zhang",Bridging Imagination and Reality for Model-Based Deep Reinforcement Learning,661b1e76b95cc50a7a11a85619a67d95,https://proceedings.neurips.cc/paper/2020/file/661b1e76b95cc50a7a11a85619a67d95-Paper.pdf,"Model-free RL requires a large amount of samples, thus limits its applications to real-world tasks. For example, the trial-and-error training process of a robot requires substantial manpower and financial resources, and certain harmful actions can greatly reduce the life of the robot. Building a world model and learning behaviors by imaginations provides a boarder prospect for real-world applications. This paper is situated in model-based RL and further improves sample efficiency over existing work, which will accelerate the development of real-world applications on automatic control, such as robotics and autonomous driving. In addition, this paper tackles a valuable problem about generalization, from imagination to reality, thus it is also of great interest to researchers in generalizable machine learning. In the long run, this paper will improve the efficiency of factory operations, avoid artificial repetition of difficult or dangerous work, save costs, and reduce risks in the industrial and agricultural industry. For daily life, it will create a more intelligent lifestyle and improve the quality of life. Our algorithm is a generic framework that does not leverages biases in data. We evaluated our model in a popular benchmark of visual control tasks. However, similar to a majority of deep learning approaches, our algorithm has a common disadvantage. The learned knowledge and policy is not friendly to humans and it is hard for us to know why the agent learns to act so well. Interpretability has always been a challenging open question and in the future we are interested in incorporating recent deep learning progresses on causal inference into RL.",Broader Impact,257,12,,,FALSE,FALSE,FALSE,Bridging Imagination and Reality for Model-Based Deep Reinforcement Learning,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Model-Based RL; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Guangxiang Zhu', ' Minghao Zhang', ' Honglak Lee', ' Chongjie Zhang']","{'Tsinghua University', 'Tsinghua university'}",1,0,0,{'China'}
Neural Networks Learning and Memorization with (almost) no Over-Parameterization,Amit Daniely,Neural Networks Learning and Memorization with (almost) no Over-Parameterization,662a2e96162905620397b19c9d249781,https://proceedings.neurips.cc/paper/2020/file/662a2e96162905620397b19c9d249781-Paper.pdf,Not applicable as far as we can see (this is a purely theoretical paper).,Broader Impact,14,1,TRUE,FALSE,FALSE,FALSE,FALSE,Neural Networks Learning and Memorization with (almost) no Over-Parameterization,Theory,Theory -> Computational Learning Theory,,['Amit Daniely'],{'Hebrew University and Google Research'},1,0,0,{'Israel'}
Exploiting Higher Order Smoothness in Derivative-free Optimization and Continuous Bandits,"Arya Akhavan, Massimiliano Pontil, Alexandre Tsybakov",Exploiting Higher Order Smoothness in Derivative-free Optimization and Continuous Bandits,6646b06b90bd13dabc11ddba01270d23,https://proceedings.neurips.cc/paper/2020/file/6646b06b90bd13dabc11ddba01270d23-Paper.pdf,The present work improves our understanding of zero-order optimization methods in specific scenarios in which the underlying function we wish to optimize has certain regularity properties. We believe that a solid theoretical foundation is beneficial to the development of practical machine learning and statistical methods. We expect no direct or indirect ethical risks from our research.,Broader impact,56,3,TRUE,FALSE,FALSE,FALSE,FALSE,Exploiting Higher Order Smoothness in Derivative-free Optimization and Continuous Bandits,Theory,Algorithms -> Bandit Algorithms; Algorithms -> Online Learning; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Arya Akhavan', ' Massimiliano Pontil', ' Alexandre Tsybakov']","{'ENSAE - IIT', 'CREST, ENSAE'}",1,0,0,"{'France', 'India', 'USA'}"
Towards a Combinatorial Characterization of Bounded-Memory Learning,"Alon Gonen, Shachar Lovett, Michal Moshkovitz",Towards a Combinatorial Characterization of Bounded-Memory Learning,665d5cbb82b5785d9f344c46417c6c36,https://proceedings.neurips.cc/paper/2020/file/665d5cbb82b5785d9f344c46417c6c36-Paper.pdf,"Algorithms with bounded memory are extensively studied ([1],[42],[28]). But bounded memory learning algorithms were only recently been investigated. In machine learning we have a good understanding of PAC learning using the VC dimension; weak learning with statistical queries using the SQ dimension; and online learning using the Littlestone dimension. An understanding of bounded-memory learning is missing. There are many works showing lower bounds, but none that shows both upper and lower bounds. We are the first to (1) give a characterization of bounded-memory learning in some regime, (2) in this regime we show equivalence to a different and known framework, statistical queries. Our impact is two-fold: for the general ML community we give an understanding of the capabilities and limitations of bounded-memory learning and we show its equivalence to a known framework. Second, for the theory researchers, we leave many open problems: 1. Proving a characterization for the entire regime. 2. Utilizing the equivalence between statistical queries and bounded memory to gain a better understanding of these two frameworks. 3. Our work focused on the case that |C|, |X| are polynomially related. We leave for future research to investigate the regimes of |C| = |X| o(1) and |X| = |C| o(1).",Broader Impact,201,14,,,TRUE,TRUE,FALSE,Towards a Combinatorial Characterization of Bounded-Memory Learning,Theory -> Computational Learning Theory,,Theory (including computational and statistical analyses),"['Alon Gonen', ' Shachar Lovett', ' Michal Moshkovitz']","{'University of California San Diego', 'UCSD'}",1,0,0,{'USA'}
"Chaos, Extremism and Optimism: Volume Analysis of Learning in Games","Yun Kuen Cheung, Georgios Piliouras","Chaos, Extremism and Optimism: Volume Analysis of Learning in Games",66de6afdfb5fb3c21d0e3b5c3226bf00,https://proceedings.neurips.cc/paper/2020/file/66de6afdfb5fb3c21d0e3b5c3226bf00-Paper.pdf,We do not see any ethical or future societal consequences of this work.,Broader Impact,13,1,TRUE,FALSE,FALSE,TRUE,FALSE,"Chaos, Extremism and Optimism: Volume Analysis of Learning in Games",Theory -> Game Theory and Computational Economics,Algorithms -> Dynamical Systems; Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Yun Kuen Cheung', ' Georgios Piliouras']",{'Singapore University of Technology and Design'},1,0,0,{'Singapore'}
On Regret with Multiple Best Arms,"Yinglun Zhu, Robert Nowak",On Regret with Multiple Best Arms,670c26185a3783678135b4697f7dbd1a,https://proceedings.neurips.cc/paper/2020/file/670c26185a3783678135b4697f7dbd1a-Paper.pdf,"This paper provides efficient algorithms that work well in modern applications of bandit algorithms with large action space but limited time horizon. We make minimal assumption about the setting, and our algorithms can automatically adapt to unknown hardness levels. Worst-case regret guarantees are provided for our algorithms; we also show MOSS++ is Pareto optimal and Parallel is minimax optimal, up to polylog factors. empMOSS++ is provided as a practical version of MOSS++ with excellent empirical performance. Our algorithms are particularly useful in areas such as e-commence and movie/content recommendation, where the action space is enormous but possibly contains multiple best/satisfactory actions. If deployed, our algorithms could automatically adapt to the hardness level of the recommendation task and benefit both service-providers and customers through efficiently delivering satisfactory content. One possible negative outcome is that items recommended to a specific user/customer might only come from a subset of the action space. However, this is unavoidable when the number of items/actions exceeds the allowed time horizon. In fact, one should notice that all items/actions will be selected with essentially the same probability, thanks to the incorporation of random selection processes in our algorithms. Our algorithms will not leverage/create biases due to the same reason. Overall, we believe this paper’s contribution will have a net positive impact.",Broader Impact,213,11,,,FALSE,FALSE,FALSE,On Regret with Multiple Best Arms,Algorithms -> Bandit Algorithms,,Reinforcement learning and planning,"['Yinglun Zhu', ' Robert Nowak']","{'University of Wisconsin-Madison', 'University of Wisconsion-Madison'}",1,0,0,{'USA'}
Matrix Completion with Hierarchical Graph Side Information,"Adel Elmahdy, Junhyung Ahn, Changho Suh, Soheil Mohajer",Matrix Completion with Hierarchical Graph Side Information,672cf3025399742b1a047c8dc6b1e992,https://proceedings.neurips.cc/paper/2020/file/672cf3025399742b1a047c8dc6b1e992-Paper.pdf,"We emphasize two positive impacts of our work. First, it serves to enhance the performance of personalized recommender systems (one of the most influential commercial applications) with the aid of social graph which is often available in a variety of applications. Second, it achieves fairness among all users by providing high quality recommendations even to new users who have not rated any items before. One negative consequence of this work is w.r.t. the privacy of users. User privacy may not be preserved in the process of exploiting indirect information posed in social graphs, even though direct information, such as user profiles, is protected.",Broader Impact,103,6,,,FALSE,FALSE,FALSE,Matrix Completion with Hierarchical Graph Side Information,Theory -> Information Theory,Algorithms -> Clustering; Algorithms -> Spectral Methods; Applications -> Recommender Systems,Theory (including computational and statistical analyses),,"{'University of Minnesota', 'KAIST'}",1,0,0,"{'South Korea', 'USA'}"
Is Long Horizon RL More Difficult Than Short Horizon RL?,"Ruosong Wang, Simon S. Du, Lin Yang, Sham Kakade",Is Long Horizon RL More Difficult Than Short Horizon RL?,6734fa703f6633ab896eecbdfad8953a,https://proceedings.neurips.cc/paper/2020/file/6734fa703f6633ab896eecbdfad8953a-Paper.pdf,"The focus of this paper is purely theoretical, and thus a broader impact discussion is not applicable.",Broader Impact,17,1,TRUE,FALSE,FALSE,FALSE,FALSE,Is Long Horizon RL More Difficult Than Short Horizon RL?,Theory -> Statistical Learning Theory,Reinforcement Learning and Planning -> Markov Decision Processes,,"['Ruosong Wang', ' Simon Du', ' Lin Yang', ' Sham Kakade']","{'UCLA', 'Institute for Advanced Study', 'University of Washington', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Hamiltonian Monte Carlo using an adjoint-differentiated Laplace approximation: Bayesian inference for latent Gaussian models and beyond,"Charles Margossian, Aki Vehtari, Daniel Simpson, Raj Agrawal",Hamiltonian Monte Carlo using an adjoint- differentiated Laplace approximation: Bayesian inference for latent Gaussian models and beyond,673de96b04fa3adcae1aacda704217ef,https://proceedings.neurips.cc/paper/2020/file/673de96b04fa3adcae1aacda704217ef-Paper.pdf,"Through its multidisciplinary nature, the here presented research can act as a bridge between various communities of statistics and machine learning. We hope practitioners of MCMC will consider the benefits of approximate distributions and vice-versa. This work may be a stepping stone to a broader conversation on how, what we have called the two broad approaches of Bayesian computation, can be combined. The paper also raises awareness about existing technologies and may dispel certain misconceptions. For example, our use of the adjoint principle shows that automatic differentiation is not a simple application of the chain rule, but quite a bit more clever than that.  Our goal is to make the method readily available to practitioners across multiple fields, which is why our C++ code and prototype Stan interface are open-source. While there is literature on the Laplace approximation, the error it introduces, and the settings in which it works best, we realize not all potential users will be familiar with it. To limit misuse, we must complement our work with pedagogical material built on the existing references, as well as support and develop more diagnostic tools.",Broader Impact,186,8,,,FALSE,FALSE,FALSE,Hamiltonian Monte Carlo using an adjoint-differentiated Laplace approximation: Bayesian inference for latent Gaussian models and beyond,Probabilistic Methods -> MCMC,Probabilistic Methods -> Hierarchical Models; Probabilistic Methods -> Probabilistic Programming,Probabilistic methods and inference,,"{'Columbia', 'Aalto University', 'MIT', 'University of Toronto'}",1,0,0,"{'Canada', 'Finland', 'USA'}"
Adversarial Learning for Robust Deep Clustering,"Xu Yang, Cheng Deng, Kun Wei, Junchi Yan, Wei Liu",Adversarial Learning for Robust Deep Clustering,6740526b78c0b230e41ae61d8ca07cf5,https://proceedings.neurips.cc/paper/2020/file/6740526b78c0b230e41ae61d8ca07cf5-Paper.pdf,"As an important tool for unsupervised learning, deep clustering can be applied to big data analytics and statistics. However, the robustness and stability of a certain clustering network are prone to being attenuated since the labels are absent. The adversarial learning perspective, which can precisely attack network weaknesses, has played a significant role in malware detection and computer security. The proposed method in this work adopts adversarial learning to detect unstable samples and improve the robustness of deep clustering networks. The method can further improve the effectiveness of clustering algorithms in practical applications and reduce the dependence of deep learning on massive labeled data. Moreover, deep clustering networks are more sensitive to perturbations. The attack and defense strategies for clustering networks can improve network security and prevent malicious distorted information. However, uncontrolled applications in big data analytics and statistics may cause problems concerning users’ information security and personal privacy.",Broader Impact,149,8,,,FALSE,FALSE,FALSE,Adversarial Learning for Robust Deep Clustering,Algorithms -> Unsupervised Learning,Algorithms -> Clustering,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Xu Yang', ' Cheng Deng', ' Kun Wei', ' Junchi Yan', ' Wei Liu']","{'Xidian University', 'Shanghai Jiao Tong University', 'Tencent AI Lab'}",1,1,1,{'China'}
Learning Mutational Semantics,"Brian Hie, Ellen Zhong, Bryan Bryson, Bonnie Berger",Learning Mutational Semantics,6754e06e46dfa419d5afe3c9781cecad,https://proceedings.neurips.cc/paper/2020/file/6754e06e46dfa419d5afe3c9781cecad-Paper.pdf,"We hope that this work leads to broad positive impact by (1) encouraging those in the machine learning community to contribute to understanding and combatting viruses (and infectious disease more broadly) and by (2) providing state-of-the-art prediction of how viruses can mutate around neutralization, which could be useful as part of rational design of vaccines or therapies. In silico models of how mutation leads to pathogenesis might help reduce both the resources and risks  associated with experimentally characterizing viral mutants. A primary goal of infectious disease research in general is to mitigate and prevent pandemic disease events among the global human population, which lead to widespread mortality, suffering, and economic disruption. In computationally predicting mutations that induce escape or improve viral fitness, misuse could potentially take the form of using such methods to increase the pathogenicity of an existing viral strain. Experimental biologists, policy makers, and ethicists have already devoted and continue to devote a substantial amount of consideration to the ethics of such “gain-of-function” research (GOFR) [1, 49, 50]. As computational biologists become part of the GOFR conversation, attention to ethics is paramount and the scientific community should continue to preserve and strengthen the existing combination of experimental and policy safeguards. Work in this area should continue to rely on direct experimental validation of computational prediction so that any system failures can be identified and corrected. Global viral surveillance already benefits from international cooperation through entities like the World Health Organization and collaborations like the Global Virome Project [13], and both the IRD and LANL HIV databases already have substantial global coverage across six continents [55, 23]. Preventing datasets from bias toward certain geographies or human populations underscores the already high priority given to viral monitoring at a global scale.",Broader Impact,291,9,,,FALSE,FALSE,FALSE,Learning Mutational Semantics,Applications -> Computational Biology and Bioinformatics,"Algorithms -> Few-Shot Learning; Algorithms -> Unsupervised Learning; Applications -> Natural Language Processing; Deep Learning -> Embedding Approaches; Deep Learning -> Visualization, Interpretability, and Explainability","Other applications (e.g., robotics, biology, climate, finance)","['Brian Hie', ' Ellen Zhong', ' Bryan Bryson', ' Bonnie Berger']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Learning to Learn Variational Semantic Memory,"Xiantong Zhen, Yingjun Du, Huan Xiong, Qiang Qiu, Cees Snoek, Ling Shao",Learning to Learn Variational Semantic Memory,67d16d00201083a2b118dd5128dd6f59,https://proceedings.neurips.cc/paper/2020/file/67d16d00201083a2b118dd5128dd6f59-Paper.pdf,"This work introduces the concept of semantic memory from cognitive science into the machine learning field. We use it to augment a probabilistic model for few-shot learning. The developed variational framework offers a principled way to achieve memory recall, which could also be applied to other learning scenarios, e.g., continual learning. The emprical findings indicate the potential role of neural semantic memory as a long-term memory module in enhancing machine learning models. Finally, this work will not cause any foreseeable ethical issue or societal consequence.",Broader Impact,85,5,FALSE,TRUE,TRUE,TRUE,FALSE,Learning to Learn Variational Semantic Memory,Algorithms -> Meta-Learning,Algorithms -> Few-Shot Learning; Deep Learning -> Memory-Augmented Neural Networks; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Xiantong Zhen', ' Yingjun Du', ' Huan Xiong', 'Mohamed bin Zayed University of Artificial Intelligence', ' Qiang Qiu', ' Cees Snoek', ' Ling Shao']","{'University of Amsterdam', 'MBZUAI', 'Inception Institute of Artificial Intelligence', 'Purdue University', 'The University of Texas at Arlington'}",1,0,0,"{'UAE', 'USA', 'Netherlands'}"
Myersonian Regression,"Allen Liu, Renato Leme, Jon Schneider",Myersonian Regression,67e235e7f2fa8800d8375409b566e6b6,https://proceedings.neurips.cc/paper/2020/file/67e235e7f2fa8800d8375409b566e6b6-Paper.pdf,"While our work is largely theoretical, we feel it can have downstream impact in the design of better marketplaces such as those for internet advertisement. Better pricing can increase both the efficiency of the market and the revenue of the platform. The latter is important since the revenue of platforms keeps such services (e.g. online newspapers) free for most users.",Broader Impact Statement,60,3,FALSE,FALSE,TRUE,TRUE,FALSE,Myersonian Regression,Algorithms -> Regression,Algorithms; Theory -> Game Theory and Computational Economics,Theory (including computational and statistical analyses),"['Allen Liu', ' Renato Leme', ' Jon Schneider']","{'MIT', 'Google Research'}",1,1,1,{'USA'}
Learnability with Indirect Supervision Signals,"Kaifu Wang, Qiang Ning, Dan Roth",Learnability with Indirect Supervision Signals,67ff32d40fb51f1a2fd2c4f1b1019785,https://proceedings.neurips.cc/paper/2020/file/67ff32d40fb51f1a2fd2c4f1b1019785-Paper.pdf,"Our work mostly focuses on theoretical aspects of learning, however, it provides better understanding and thus can suggest new machine learning scenarios and algorithms for learning from indirect observations; this addresses a key challenge to machine learning today, and will help machine learning researchers to reduce the cost of and need for labeled data. Our theory may have positive and negative impact on the privacy protection of sensitive data. On one hand, the theory suggests that one can alter the forms of data (via a probabilistic transition) to ensure privacy while keeping its usefulness (learnability). On the other hand, it might be possible for an attacker to recover sensitive information about the data indirectly through a related dataset.",Broader Impact,118,4,,,FALSE,FALSE,FALSE,Learnability with Indirect Supervision Signals,Theory -> Models of Learning and Generalization,Algorithms -> Classification; Algorithms -> Semi-Supervised Learning; Applications -> Denoising; Theory -> Statistical Learning Theory,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Kaifu Wang', ' Qiang Ning', ' Dan Roth']","{'University of Pennsylvania', 'UPenn', 'Allen Institute for AI'}",1,0,0,{'USA'}
Towards Safe Policy Improvement for Non-Stationary MDPs,"Yash Chandak, Scott Jordan, Georgios Theocharous, Martha White, Philip S. Thomas",Towards Safe Policy Improvement for Non-Stationary MDPs,680390c55bbd9ce416d1d69a9ab4760d,https://proceedings.neurips.cc/paper/2020/file/680390c55bbd9ce416d1d69a9ab4760d-Paper.pdf,"Applications: We hope that our work brings more attention to the understudied challenge of ensuring safety that is critical for the responsible application of RL algorithms to real-world nonstationary problems. For example, researchers have proposed the use of reinforcement learning algorithms for several medical support systems, ranging from diabetes management [ 5], to epilepsy [46], to sepsis treatment [50]. These problems involve sequential decision-making, where autonomous systems can improve upon a doctor’s prescribed policy by adapting to the non-stationary dynamics of the human body as more data becomes available. In fact, almost all human-computer interaction systems (medical treatment, tutorial recommendations, advertisement marketing, etc.) have a common non-stationary component: humans. Also, in all these use-cases, it is important to ensure that the updates are safe. That is, the updated system should not lead to undesirable financial/medical conditions and should only improve upon the existing policy (e.g., doctor’s initial prescription). Ethical concerns: The proposed method is focused towards ensuring safety , defined in terms of the performance of a system. The proposed algorithm to do so makes use of data generated by interacting with a non-stationary MDP. As discussed above, in many cases, non-stationary MDPs are associated with human beings. This raises additional issue of safety concerning data privacy and security. The proposed method does not resolve any of these issues, and therefore additional care should be taken for adequate data management. Note to a wider audience: The proposed method relies upon smoothness assumptions that need not be applicable to all problems of interests. For example, when there are jumps or breaks in the time series, then the behavior of the proposed method is not ensured to be safe. Further, all of our experiments were conducted on simulated domains, where the exact nature of non-stationarity may not reflect the non-stationarity observed during actual interactions in the physical world. Developing simulators that closely mimic the physical world, without incorporating systematic and racial bias, remains an open problem and is complementary to our research. Hence, caution is warranted while quoting results from these simulation experiments. Future research directions: There are several exciting directions for future research. We used the ordinary importance sampling procedure to estimate past performances of a policy. However, it suffers from high variance and leveraging better importance sampling procedures [31, 56] can be directly beneficial to obtain better estimates of past performances. Leveraging time-series models like ARIMA [14] and their associated wild-bootstrap methods [27, 22, 25] can be a fruitful direction for extending our algorithm to more general settings that have correlated noises or where the performance trend, both locally and globally, can be better modeled using auto-regressive functions. Further, goodness-of-fit tests [15] could be used to search for a time-series model that best fits the application.",10 Broader Impact,456,22,,,FALSE,FALSE,FALSE,Towards Safe Policy Improvement for Non-Stationary MDPs,Reinforcement Learning and Planning,Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yash Chandak', ' Scott Jordan', ' Georgios Theocharous', ' Martha White', ' Philip Thomas']","{'University of Alberta', 'Adobe Research', 'University of Massachusetts Amherst'}",1,1,1,"{'Canada', 'USA'}"
Finer Metagenomic Reconstruction via Biodiversity Optimization,"Simon Foucart, David Koslicki",Finer Metagenomic Reconstruction via Biodiversity Optimization,6811f9b2bf86bf64e3f320973119b959,https://proceedings.neurips.cc/paper/2020/file/6811f9b2bf86bf64e3f320973119b959-Paper.pdf,"This work addresses one of the fundamental problems in the active area of Metagenonics, namely the reconstruction of microbial communities in a computationally efficient manner. Developing sound mathematical methods for this problem is crucial because the ability to determine microbial compositions impacts at least two societal challenges. First, in public health: an individual’s microbiome is intimately connected with their well-being, hence the importance of its accurate analysis. Second, in threat detection: given that substances and individuals leave traces in the taxonomic composition of the surrounding environment, its quick analysis may enable enhanced threat recognition. Although only proof-of-concept results have been presented, a version scaling to real-world noisy problems is underway (see https://github.com/KoslickiLab/DiversityOptimization for preliminary code). The expected software implementation will potentially be quite valuable to biologists. Incidentally, since the mathematical framework is agnostic to the targeted application, there is a possibility for advancements in other fields, e.g. the analysis of gene expression networks or more generally any situation where one desires to infer the composition of a linear mixture of entities of varying relatedness.",Broader Impact,174,7,,,FALSE,FALSE,FALSE,Finer Metagenomic Reconstruction via Biodiversity Optimization,Algorithms -> Sparsity and Compressed Sensing,Applications -> Computational Biology and Bioinformatics,Theory (including computational and statistical analyses),"['Simon Foucart', ' David Koslicki']",{'Pennsylvania State University'},1,0,0,{'USA'}
Causal Discovery in Physical Systems from Videos,"Yunzhu Li, Antonio Torralba, Anima Anandkumar, Dieter Fox, Animesh Garg",Causal Discovery in Physical Systems from Videos,6822951732be44edf818dc5a97d32ca6,https://proceedings.neurips.cc/paper/2020/file/6822951732be44edf818dc5a97d32ca6-Paper.pdf,"Causal reasoning is the process of identifying causality: the relationship between a cause and its effect, which is at the core of human intelligence. Learning directly from observations only without the modeling of the underlying causal structure can lead to the emergence of incorrect associations between the input and the output. The learned model can overfit to the bias associated with the dataset, limiting its ability to generalize outside the training distribution and often leading to catastrophic outcomes when deploying in the real world. Discovering the causal relationships typically requires learning from data collected in randomized controlled trials or A/B tests where the experimenter controls certain variables of interest. However, carrying out the intervention or randomized trials may be impossible or at least impractical or unethical in many situations. This work aims at discovering the causal structure and modeling the underlying causal mechanism from visual inputs, where we have access to data from different configurations and scenarios under unknown interventions both on the structure of the causal graph and its parameters. The ability to accurately capture the dependency structures and identify the hidden confounders is of vital importance towards helping the learned models generalize. As we discussed in our experiments, causal modeling improved generalization to both outside the training distribution and also towards high likelihood counterfactual data augmentation. While excited about these results, it is important to acknowledge that this is a particularly challenging task, and our method serves as an initial step towards the broader goal of building physically grounded visual intelligence. We mainly focussed on the modeling of the dynamical system, while some aspects of the causal graph such as sophisticated dependencies and practical issues arising from sampling rates are not touched upon. Nonetheless, we hope to draw people’s attention to this grand challenge and inspire future research on generalizable physically grounded reasoning from visual inputs without domain-specific feature engineering.",Broader Impact,312,11,,,FALSE,FALSE,FALSE,Causal Discovery in Physical Systems from Videos,Algorithms -> Relational Learning,Probabilistic Methods -> Causal Inference,Causality,"['Yunzhu Li', ' Antonio Torralba', ' Anima Anandkumar', ' Dieter Fox', ' Animesh Garg']","{'Massachusetts Institute of Technology', 'MIT', 'NVIDIA / Caltech', 'NVIDIA'}",1,1,1,{'USA'}
Glyph: Fast and Accurately Training Deep Neural Networks on Encrypted Data,"Qian Lou, Bo Feng, Geoffrey  Charles Fox, Lei Jiang",Glyph: Fast and Accurately Training Deep Neural Networks on Encrypted Data,685ac8cadc1be5ac98da9556bc1c8d9e,https://proceedings.neurips.cc/paper/2020/file/685ac8cadc1be5ac98da9556bc1c8d9e-Paper.pdf,"In this paper, we propose a FHE-based privacy-preserving technique to fast and accurately train DNNs on encrypted data. Average users, who have to rely on big data companies but do not trust them, can benefit from this research, since they can upload only their encrypted data to untrusted servers. No  one may be put at disadvantage from this research. If our proposed technique fails, everything will go back to the state-of-the-art, i.e., untrusted servers may leak sensitive data of average users.",Broader Impact,81,4,,,FALSE,FALSE,FALSE,Glyph: Fast and Accurately Training Deep Neural Networks on Encrypted Data,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Qian Lou', ' Bo Feng', ' Geoffrey Charles Fox', ' Lei Jiang']","{'Indiana University Bloomington', 'Indiana university', 'Indiana University'}",1,0,0,{'USA'}
Smoothed Analysis of Online and Differentially Private Learning,"Nika Haghtalab, Tim Roughgarden, Abhishek Shetty",Smoothed Analysis of Online and Differentially Private Learning,685bfde03eb646c27ed565881917c71c,https://proceedings.neurips.cc/paper/2020/file/685bfde03eb646c27ed565881917c71c-Paper.pdf,"Like many theoretical machine learning papers, this paper’s main focus is on the mathematical challenges and contributions to the field. However, as robustness and privacy are two of the most important practical and societal challenges machine learning is facing, our work also has broader implications on the deployments of these techniques. The theoretical impossibility results in online learning and differential privacy have been barriers to developing robust and private learning methods that work well on day-to-day applications and have rigorous guarantees — e.g., the impossibility result for privacy implies that error guarantees of private learning methods only work when data sets are infinitely large. Our work provides a framework to side step these impossibility results. Our online and differentially private algorithms perform as well as their offline and non-private counterparts on real-life data and are backed by rigorous theoretical guarantees.",Broader Impact,140,5,,,FALSE,FALSE,FALSE,Smoothed Analysis of Online and Differentially Private Learning,Theory,"Algorithms -> Online Learning; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security; Theory -> Statistical Learning Theory",Theory (including computational and statistical analyses),"['Nika Haghtalab', ' Tim Roughgarden', ' Abhishek Shetty']","{'Columbia University', 'Cornell University'}",1,0,0,{'USA'}
Self-Paced Deep Reinforcement Learning,"Pascal Klink, Carlo D'Eramo, Jan R. Peters, Joni Pajarinen",Self-Paced Deep Reinforcement Learning,68a9750337a418a86fe06c1991a1d64c,https://proceedings.neurips.cc/paper/2020/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf,"This work proposed a method to speed up and stabilize the learning of autonomous agents via curriculum reinforcement learning. In a practical scenario, such methods can reduce the amount of time, energy, or manual labor required to create autonomous agents for a given task, allowing for economic benefits. Given the inherent goal of RL to create versatile learning algorithms, free of ties to a specific domain, RL algorithms can be used in a variety of fields, ranging from automating aspects of elderly care over autonomous vehicles to military uses. Given the abstract nature of our work, it is, however, hard to estimate the immediate consequences of our work on society, since the algorithmic benefits arising from our work apply equally to all of the aforementioned examples.",Broader Impact,126,4,,,FALSE,FALSE,FALSE,Self-Paced Deep Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Multitask and Transfer Learning,Reinforcement learning and planning,"['Pascal Klink', 'Eramo', ' Jan Peters', ' Joni Pajarinen']",{'TU Darmstadt'},1,0,0,{'Germany'}
Kalman Filtering Attention for User Behavior Modeling in CTR Prediction,"Hu Liu, Jing LU, Xiwei Zhao, Sulong Xu, Hao Peng, Yutong Liu, Zehua Zhang, Jian Li, Junsheng Jin, Yongjun Bao, Weipeng Yan",Kalman Filtering Attention for User Behavior Modeling in CTR Prediction,68ce199ec2c5517597ce0a4d89620f55,https://proceedings.neurips.cc/paper/2020/file/68ce199ec2c5517597ce0a4d89620f55-Paper.pdf,"Ad-tech and e-commerce practitioners are the clearest immediate beneficiaries. Might have applications in other areas that use behaviors for personalized services as well. Also notice that the prior in KFAtt might not be useful for neural machine translation and question answering, since the target are always covered in the input sequence.",Broader Impact,51,3,FALSE,FALSE,FALSE,FALSE,FALSE,Kalman Filtering Attention for User Behavior Modeling in CTR Prediction,Deep Learning -> Attention Models,Algorithms -> Uncertainty Estimation; Applications -> Recommender Systems; Probabilistic Methods -> Bayesian Theory; Probabilistic Methods -> Graphical Models,Deep learning,"['Hu Liu', ' Jing LU', ' Xiwei Zhao', ' Sulong Xu', ' Hao Peng', ' Yutong Liu', ' Zehua Zhang', ' Jian Li', ' Junsheng Jin', ' Yongjun Bao', ' Weipeng Yan']","{'Business Growth BU, JD.com'}",0,1,0,{'China'}
Towards Maximizing the Representation Gap between In-Domain & Out-of-Distribution Examples,"Jay Nandy, Wynne Hsu, Mong Li Lee",Towards Maximizing the Representation Gap between In-Domain & Out-of-Distribution Examples,68d3743587f71fbaa5062152985aff40,https://proceedings.neurips.cc/paper/2020/file/68d3743587f71fbaa5062152985aff40-Paper.pdf,"Despite the impeccable success of deep neural network (DNN)-based models in various real-world applications, they often produce incorrect predictions without proving any warning for the users. It raises the question of how much can we trust these models and whether it is safe to use them for sensitive real-world applications such as medical diagnosis, self-driving cars or to make financial decisions. In this paper, we aim to robustly identify the source of uncertainty in the prediction of a DNN based model for classification tasks. Identifying the source of uncertainty in the prediction would allow manual intervention in an informed way and make an AI system more reliable for real-world applications. In particular, we address a shortcoming of the existing techniques and propose a novel solution to improve the detection of anomalous out-of-distribution examples for a classification model.",7 Broader Impact,137,5,,,FALSE,FALSE,FALSE,Towards Maximizing the Representation Gap between In-Domain & Out-of-Distribution Examples,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Deep Learning -> Predictive Models; Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Jay Nandy', ' Wynne Hsu', ' Mong Li Lee']",{'National University of Singapore'},1,0,0,{'Singapore'}
Fully Convolutional Mesh Autoencoder using Efficient Spatially Varying Kernels,"Yi Zhou, Chenglei Wu, Zimo Li, Chen Cao, Yuting Ye, Jason Saragih, Hao Li, Yaser Sheikh",Fully Convolutional Mesh Autoencoder using Efficient Spatially Varying Kernels,68dd09b9ff11f0df5624a690fe0f6729,https://proceedings.neurips.cc/paper/2020/file/68dd09b9ff11f0df5624a690fe0f6729-Paper.pdf,This work can potentially impact future entertainment and communication industry. It could also allow for more efficient storage and transport of 3D data.,6 Potential Broader Impact,23,2,FALSE,FALSE,FALSE,FALSE,FALSE,Fully Convolutional Mesh Autoencoder using Efficient Spatially Varying Kernels,"Applications -> Body Pose, Face, and Gesture Analysis",Deep Learning -> Deep Autoencoders,Vision,"['Yi Zhou', ' Chenglei Wu', ' Zimo Li', ' Chen Cao', ' Yuting Ye', ' Jason Saragih', ' Hao Li', ' Yaser Sheikh']","{'Pinscreen/University of Southern California/USC ICT', 'University of Southern California', 'Facebook', 'Facebook Reality Labs'}",1,1,1,{'USA'}
GNNGuard: Defending Graph Neural Networks against Adversarial Attacks,"Xiang Zhang, Marinka Zitnik",GNNG UARD : Defending Graph Neural Networks against Adversarial Attacks,690d83983a63aa1818423fd6edd3bfdb,https://proceedings.neurips.cc/paper/2020/file/690d83983a63aa1818423fd6edd3bfdb-Paper.pdf,"Impacts on graph ML research. Graphs are universal structures of real-world complex systems. Because of strong representation learning capacity, GNNs have brought success in areas, ranging from disease diagnosis [10] and drug discovery [35] to recommendation system [55]. However, recent studies found that many GNNs are highly vulnerable to adversarial attacks [56]. Adversarial attackers inject imperceptible changes into graphs, thereby fooling downstream GNN classifiers into making incorrect predictions [9]. While there is a rich body of literature on adversarial attacks and defense on non-graph data ( e.g. , text [39], and images [56]), much less is known about graphs. In an effort towards closing this gap, this paper introduces GNNG UARD , a powerful GNN defender that can be straightforwardly integrated into any existing GNN. Because GNNG UARD works with any GNN model, its impact on graph ML research is potentially more substantial than that of introducing another, albeit presumably more robust, GNN model. A variety of impactful application areas. GNNG UARD can be used in a wide range of applications by simply integrating GNNG UARD with a GNN model of user choice that is most suitable in a particular application, as we demonstrate in this paper. Further positive impacts of GNNG UARD include the following. First, we envision that GNNG UARD will help users ( e.g. , governments, companies, and individuals) avoid potential losses that are caused by misjudgments made by attacked GNNs ( e.g. , in the face of a massive attack on a financial network) [9]. Second, it would be interesting to explore the possibility of deploying GNNG UARD for key GNN applications in biomedical domain, where, for example, a GNN diagnostics system could predict false diagnosis if it was trained on the attacked knowledge graph [57]. Finally, our model has implications for fairness and explainability of GNNs [36]), which is key to increase users’ trust in GNN predictions. Lastly, GNNG UARD can be used for debugging GNN models and understanding of black-box GNN optimization. The need for thoughtful use of GNNG UARD . It is possible to think of a situation where one would use GNNG UARD to get insights into black-box GNN optimization and then use those insights to improve existing attack algorithms, thereby identifying and potentially exploiting new, currently unknown vulnerabilities of GNNs. Because of this possibility and the fact that GNNs are becoming increasingly popular in real-world ML systems, it is important to conduct research to get insights into possible attacks and defense of GNNs.",Broader Impact,412,18,,,FALSE,FALSE,FALSE,GNNGuard: Defending Graph Neural Networks against Adversarial Attacks,Deep Learning -> Embedding Approaches,Algorithms -> Relational Learning; Algorithms -> Representation Learning; Algorithms -> Semi-Supervised Learning; Applications -> Denoising; Applications -> Network Analysis; Deep Learning -> Predictive Models,Deep learning,"['Xiang Zhang', ' Marinka Zitnik']",{'Harvard University'},1,0,0,{'USA'}
Geo-PIFu: Geometry and Pixel Aligned Implicit Functions for Single-view Human Reconstruction,"Tong He, John Collomosse, Hailin Jin, Stefano Soatto",Geo-PIFu: Geometry and Pixel Aligned Implicit Functions for Single-view Human Reconstruction,690f44c8c2b7ded579d01abe8fdb6110,https://proceedings.neurips.cc/paper/2020/file/690f44c8c2b7ded579d01abe8fdb6110-Paper.pdf,"Who may benefit from this research? The VR / AR software developers and 3D graphics designers may benefit from our research. The proposed technique generates single-view clothed human mesh reconstructions with improved global topology regularities and local surface details. Our method can benefit various VR / AR applications that involve reconstructing 3D virtual human avatars for customized user experience, such as conference systems and role-playing games. Moreover, being able to efficiently reconstruct 3D meshes from single-view images is useful for graphics rendering and 3D designs. Who may be put at disadvantage from this research? In the long run, some entry-level graphics artists and designers might be affected. Generally speaking, the 3D gaming and graphics design industries are moving towards automatic content generation techniques. These techniques are not meant to replace highly skilled human workers, but to help improve their productivity at work. What are the consequences of failure of the system? Failed human mesh reconstructions might bring unpleasant user experience. Typical failure cases as well as possible solutions have also been discussed in the main paper. Whether the task/method leverages biases in the data? There might be some biases on human poses in the and competing clothes methods. due to long-tail More importantly, cases. However, our mesh our dataset collection is already procedures 10 ⇥ larger can be than easily the expanded one used to other domain-specific scenarios to obtain more human meshes with different shapes, poses and clothes to compensate for long-tail cases.",Broader Impact,244,16,,,FALSE,FALSE,FALSE,Geo-PIFu: Geometry and Pixel Aligned Implicit Functions for Single-view Human Reconstruction,"Applications -> Body Pose, Face, and Gesture Analysis",Algorithms -> Representation Learning; Applications -> Computer Vision,Vision,"['Tong He', ' John Collomosse', ' Hailin Jin', ' Stefano Soatto']","{'UCLA', 'Adobe Research', 'Adobe'}",1,1,1,{'USA'}
Optimal visual search based on a model of target detectability in natural images,"Shima Rashidi, Krista Ehinger, Andrew Turpin, Lars Kulik",Optimal visual search based on a model of target detectability in natural images,691dcb1d65f31967a874d18383b9da75,https://proceedings.neurips.cc/paper/2020/file/691dcb1d65f31967a874d18383b9da75-Paper.pdf,"The work presented in this paper can be used for attention prediction systems. Such systems can be beneficial for applications such as augmented reality driving aids [54; 55]. A foveated detectability model could effectively model a driver’s visual system and quantitatively measure the detectability of driving hazards based on the driver’s current gaze. This system could direct attention to locations with high uncertainty to reduce the possibility of a hazard being missed that is not in the driver’s fovea. However, attention prediction can also be abused for negative outcomes such as manipulating attention for advertising. The proposed system is not intended for high risk applications or if applied, should not have a critical role in them, so the consequences of failure of the system should not be severely destructive. The proposed model is not leveraging any dataset biases, but the model of detectability requires training on a large set of backgrounds, so an unrepresentative selection of backgrounds could produce a wrong model and could potentially limit the results.",Broader Impact,168,7,,,FALSE,FALSE,FALSE,Optimal visual search based on a model of target detectability in natural images,Neuroscience and Cognitive Science -> Visual Perception,Applications -> Object Detection,Vision,"['SHIMA RASHIDI', ' Krista A Ehinger', ' Andrew Turpin', ' Lars Kulik']","{'The University of Melbourne', 'University of Melbourne'}",1,0,0,{'Australia'}
Towards Convergence Rate Analysis of Random Forests for Classification,"Wei Gao, Zhi-Hua Zhou",Towards Convergence Rate Analysis of Random Forests for Classification,6925f2a16026e36e4fc112f82dd79406,https://proceedings.neurips.cc/paper/2020/file/6925f2a16026e36e4fc112f82dd79406-Paper.pdf,This work presents theoretical analysis on the convergence rates of random forests in the machine learning community. This is a pure theoretical work without particular application foreseen.,Broader Impact,27,2,TRUE,FALSE,FALSE,FALSE,FALSE,Towards Convergence Rate Analysis of Random Forests for Classification,Theory -> Statistical Learning Theory,Algorithms -> Boosting and Ensemble Methods,Theory (including computational and statistical analyses),"['Wei Gao', 'Hua Zhou']",{'Nanjing University'},1,0,0,{'China'}
List-Decodable Mean Estimation via Iterative Multi-Filtering,"Ilias Diakonikolas, Daniel Kane, Daniel Kongsgaard",List-Decodable Mean Estimation via Iterative Multi-Filtering,6933b5648c59d618bbb30986c84080fe,https://proceedings.neurips.cc/paper/2020/file/6933b5648c59d618bbb30986c84080fe-Paper.pdf,"Our work fits within a broader agenda of algorithmic high-dimensional robust statistics and aims to advance the algorithmic foundations of robust learning in the presence of a large fraction of arbitrary outliers. An important motivation for this line of work is to design provable defenses of machine learning systems against data poisoning attacks . This goal has become a pressing challenge in many real-world scenarios, where the data of a machine learning system can be untrusted (including, e.g., crowdsourcing). Since the primary focus of our work is theoretical, we do not expect our results to have immediate societal impact. Nonetheless, we believe that our algorithm is practical and that our findings provide interesting insights that could be useful in the design of practically relevant estimators in highly noisy environments.",Broader Impact,129,5,,,FALSE,FALSE,FALSE,List-Decodable Mean Estimation via Iterative Multi-Filtering,Theory -> Computational Learning Theory,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'UW Madison', 'UCSD'}",1,0,0,{'USA'}
Exact Recovery of Mangled Clusters with Same-Cluster Queries,"Marco Bressan, Nicolò Cesa-Bianchi, Silvio Lattanzi, Andrea Paudice",Exact Recovery of Mangled Clusters with Same-Cluster Queries,6950aa02ae8613af620668146dd11840,https://proceedings.neurips.cc/paper/2020/file/6950aa02ae8613af620668146dd11840-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Exact Recovery of Mangled Clusters with Same-Cluster Queries,Algorithms -> Clustering,Algorithms; Algorithms -> Active Learning; Theory,Theory (including computational and statistical analyses),"['Marco Bressan', 'Bianchi', ' Silvio Lattanzi', ' Andrea Paudice']","{'Sapienza University of Rome', 'Università degli Studi di Milano', 'Google Research', 'University of Milan'}",1,1,1,"{'Italy', 'USA'}"
Steady State Analysis of Episodic Reinforcement Learning,Huang Bojun,Steady State Analysis of Episodic Reinforcement Learning,69bfa2aa2b7b139ff581a806abf0a886,https://proceedings.neurips.cc/paper/2020/file/69bfa2aa2b7b139ff581a806abf0a886-Paper.pdf,"This section discusses social impacts of our works, as required by the NeurIPS program committee. This work mostly studied theoretical foundations of reinforcement learning, which, in the author’s view, contributes to understand RL as a general and natural phenomenon of the world and of our society. In its engineering aspect, RL is in its nature an “online” learning paradigm that requires close interactions with the surround environment. So if a less understood RL algorithm is deployed to the real world, the interactions triggered along with the learning could possibly have unexpected effects. The paper contains analysis on both effective and questionable aspects of existing RL approaches. The author hopes these analysis can contribute to more informed and responsible decisions in using these approaches in practice. Finally, the perturbation trick and the new policy gradient estimator proposed in the paper may be integrated into fully-fledged RL algorithms in the future, which in turn could be used, by properly-intended people, to improve the society.",Broader Impacts,162,7,,,FALSE,FALSE,FALSE,Steady State Analysis of Episodic Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement learning and planning,['Huang Bojun'],{'Rakuten Institute of Technology'},1,0,0,{'Japan'}
Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures,"Julien Launay, Iacopo Poli, François Boniface, Florent Krzakala",Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures,69d1fc78dbda242c43ad6590368912d4,https://proceedings.neurips.cc/paper/2020/file/69d1fc78dbda242c43ad6590368912d4-Paper.pdf,"Of our survey This study is the first experimental validation of DFA as an effective training method in a wide range of challenging tasks and neural networks architectures. This significantly broadens the applications of DFA, and more generally brings new insight on training techniques alternative to backpropagation. From neural rendering and recommender systems, to natural language processing or geometric learning, each of these applications has its own potential impact. Our task selection process was motivated by current trends in deep learning, as well as by technically appealing mechanisms (graph convolutions, attention). A limit of our survey is that our–arguably biased–selection of tasks cannot be exhaustive. Our experiments required substantial cloud compute resources, with state-of- the-art GPU hardware. Nevertheless, as this study provides new perspectives for hardware accelerator technologies, it may favor the application of neural networks in fields previously inaccessible because of computational limits. Future research on DFA should continue to demonstrate its use in novel contexts of interest as they are discovered.  Of the considered applications Each of the applications considered in our study has a wide potential impact, consider for example the impact of textual bias in pretrained word embeddings [85]. We refer to [86] and references therein for a discussion of ethical concerns of AI applications. Of DFA as a training method DFA enables parallelization of the backward pass and places a single operation at the center of the training process, opening the prospect of reducing the power consumption of training chips by an order of magnitude [31]. Not only is more efficient training a path to more environmentally responsible machine learning [87], but it may lower the barrier of entry, supporting equality and sustainable development goals. A significant downside of moving from BP to DFA is a far more limited understanding of how to train models and how the trained models behave. There is a clear empirical understanding of the impact of techniques such as batch normalization or skip connections on the performance of BP; new insights need to be obtained for DFA. BP also enjoys decades of works on topics like adversarial attacks, interpretability, and fairness. Much of this work has to be cross-checked for alternative training methods, something we encourage further research to consider as the next step towards safely and responsively scaling up DFA. Of biologically motivated methods Finally, a key motivation for this study was to demonstrate that learning challenging tasks was possible without weight transport. Biologically motivated methods are a more foundational research direction, and as such the possible long-term impact of our findings is harder to estimate under this light. However, fundamental research of this kind is important to open new pathways for ML and neuroscience.",Broader Impact,446,19,,,FALSE,TRUE,FALSE,Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures,Deep Learning -> Biologically Plausible Deep Networks,,Neuroscience and cognitive science,"['Julien Launay', ' Iacopo Poli', ' François Boniface', ' Florent Krzakala']",{'LightOn'},0,1,0,{'France'}
Bayesian Optimization for Iterative Learning,"Vu Nguyen, Sebastian Schulze, Michael Osborne",Bayesian Optimization for Iterative Learning,69eba34671b3ef1ef38ee85caae6b2a1,https://proceedings.neurips.cc/paper/2020/file/69eba34671b3ef1ef38ee85caae6b2a1-Paper.pdf,"Our work aims at making the optimization of processes operating in a step-wise fashion more efficient. As demonstrated this makes BOIL particularly well-suited to supporting supervised learning models and RL systems. By increasing training efficience of these models, we hope to contribute to their widespread deployment whilst reducing the computational and therefore environmental cost their implementation has. Deep (reinforcement) learning systems find application in a wide range of settings that directly contribute to real world decisions, e.g., natural language processing, visual task, autonomous driving and many more. As machine learning models building on our contributions are being deployed in the real world, we encourage practicioners to put in place necessary supervision and override mechanisms as precautions against potential failure. In a more general context, our algorithm may be seen as a step towards the construction of an automated pipeline for the training and deployment of machine learning models. A potential danger is that humans become further and further removed from the modelling process, making it harder to spot (potentially critical) failures. We do not see this as an argument against the construction of such a pipeline in principle, but instead encourage practicioners to reflect on potential biases indirectly encoded in the choice of data sets and models, they are feeding into said automated processes. The growing opacity of machine learning models is a concern of its own and which automated training procedures will only contribute to. Opposing this is a rapidly growing corpus of work addressing the interpretability of trained machine learning models and their decision making. These can and should be used to rigorously analyse final training outcomes. Only then can we ensure that machine learning algorithm do indeed become a beneficial source of information guiding real world policy making as opposed to opaque, unquestioned entities. While our main interest lies in the hyperparameter optimization of machine learning models, it should be noted that any iterative process depending on a set of parameters can make use of our contributions. Possible settings could, for instance, include the optimization of manufacturing pipelines in which factory setting are adjusted to increase productivity.",6 Broader Impact,350,14,,,FALSE,FALSE,FALSE,Bayesian Optimization for Iterative Learning,Probabilistic Methods -> Gaussian Processes,,AutoML,"['Vu Nguyen', ' Sebastian Schulze', ' Michael A Osborne']","{'U Oxford', 'University of Oxford'}",1,0,0,{'UK'}
Minimax Bounds for Generalized Linear Models,"Kuan-Yun Lee, Thomas Courtade",Minimax Bounds for Generalized Linear Models,6a508a60aa3bf9510ea6acb021c94b48,https://proceedings.neurips.cc/paper/2020/file/6a508a60aa3bf9510ea6acb021c94b48-Paper.pdf,"The generalized linear model (GLM) is a broad class of statistical models that have extensive applications in machine learning, electrical engineering, finance, biology, and many areas not stated here. Many algorithms have been proposed for inference, prediction and classification tasks under the umbrella of the GLM, such as the Lasso algorithm, the EM algorithm, Dantzig selectors, etc., but often it is hard to confidently assess optimality. Lower bounds for minimax and Bayes risks play a key role here by providing theoretical benchmarks with which one can evaluate the performance of algorithms. While many previous approaches have focused on the Gaussian linear model, in this paper we establish minimax and Bayes risk lower bounds that hold uniformly over all statistical models within the GLM. Our arguments demonstrate a set of information-theoretic techniques that are general and applicable to setups other than the GLM. As a result, many applications stand to potentially benefit from our work.",Broader Impact,154,6,,,FALSE,FALSE,FALSE,Minimax Bounds for Generalized Linear Models,Theory -> Statistical Learning Theory,Theory -> Information Theory,Theory (including computational and statistical analyses),"['Yun Lee', ' Thomas Courtade']","{'UC Berkeley', 'University of California, Berkeley'}",1,0,0,{'USA'}
Projection Robust Wasserstein Distance and Riemannian Optimization,"Tianyi Lin, Chenyou Fan, Nhat Ho, Marco Cuturi, Michael Jordan",Projection Robust Wasserstein Distance and Riemannian Optimization,6a61d423d02a1c56250dc23ae7ff12f3,https://proceedings.neurips.cc/paper/2020/file/6a61d423d02a1c56250dc23ae7ff12f3-Paper.pdf,"The paper proposes efficient algorithms with theoretical guarantees to compute distances between probability measures in very high dimensional spaces. The problem of comparing high dimensional probability measures has appeared in several applications in machine learning, statistics, genomics, and neuroscience. Our study, therefore, provides an efficient method for scientists in these domains to deal with large-scale and high dimensional data. We believe that our work is fundamental and potentially initiates new directions in computing high-dimensional probability measures, which leads to faster scientific discoveries. Finally, we do not foresee any negative impact to society from our work.",Broader Impact,95,5,,,FALSE,FALSE,FALSE,Projection Robust Wasserstein Distance and Riemannian Optimization,Theory -> Data-driven Algorithm Design,Algorithms -> Unsupervised Learning; Optimization -> Non-Convex Optimization,,"['Tianyi Lin', ' Chenyou Fan', ' Nhat Ho', ' Marco Cuturi', ' Michael Jordan']","{'UC Berkeley', 'University of Texas at Austin', 'The Chinese University of Hong Kong, Shenzhen'}",1,0,0,"{'USA', 'China'}"
CoinDICE: Off-Policy Confidence Interval Estimation,"Bo Dai, Ofir Nachum, Yinlam Chow, Lihong Li, Csaba Szepesvari, Dale Schuurmans",CoinDICE: Off-Policy Confidence Interval Estimation,6aaba9a124857622930ca4e50f5afed2,https://proceedings.neurips.cc/paper/2020/file/6aaba9a124857622930ca4e50f5afed2-Paper.pdf,"This research is fundamental and targets a broad question in reinforcement learning. The ability to reliably assess uncertainty in off-policy evaluation would have significant positive benefits for safety- critical applications of reinforcement learning. Inaccurate uncertainty estimates create the danger of misleading decision makers and could lead to detrimental consequences. However, our primary goal is to improve these estimators and reduce the ultimate risk of deploying reinforcement-learned systems. The techniques are general and do not otherwise target any specific application area.",Broader Impact,80,5,,,FALSE,FALSE,FALSE,CoinDICE: Off-Policy Confidence Interval Estimation,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Bo Dai', ' Ofir Nachum', ' Yinlam Chow', ' Lihong Li', ' Csaba Szepesvari', ' Dale Schuurmans']","{'Google Brain', 'Google Research', 'DeepMind / University of Alberta'}",1,1,1,"{'Canada', 'UK', 'USA'}"
Simple and Fast Algorithm for Binary Integer and Online Linear Programming,"Xiaocheng Li, Chunlin Sun, Yinyu  Ye",Simple and Fast Algorithm for Binary Integer and Online Linear Programming,6abba5d8ab1f4f32243e174beb754661,https://proceedings.neurips.cc/paper/2020/file/6abba5d8ab1f4f32243e174beb754661-Paper.pdf,"Our paper takes a purely theoretical perspective, and the discussed model covers a wide range of applications including resource allocation, revenue management, assignment, and matching problems. As far as we can see, there is no potential ethical issue arising from the results developed in our paper.",Ethical Aspects,46,2,TRUE,TRUE,TRUE,TRUE,FALSE,Simple and Fast Algorithm for Binary Integer and Online Linear Programming,Algorithms -> Online Learning,Algorithms -> Stochastic Methods; Optimization -> Convex Optimization; Theory -> Statistical Learning Theory,Optimization Methods (continuous or discrete),"['Xiaocheng Li', ' Chunlin Sun', ' Yinyu Ye']","{'Stanford University', 'Department of Management Science and Engineering, Stanford University', 'Standord'}",1,0,0,{'USA'}
Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction,"Yaodong Yu, Kwan Ho Ryan Chan, Chong You, Chaobing Song, Yi Ma",Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction,6ad4174eba19ecb5fed17411a34ff5e6,https://proceedings.neurips.cc/paper/2020/file/6ad4174eba19ecb5fed17411a34ff5e6-Paper.pdf,"The principle proposed in this work aims to maximally capture the intrinsic structures of the data that justify meaningful classification of clustering of real-world data. Our framework discourages models from learning by only fitting or overfitting the labeled data with a black box, enables us to identify the intrinsic structures of the data hence the true causes for meaningful classification or clustering. This methodology also allows us to maximally reduce the effects of bias or even mistakes that might be introduced in the labeled data. We believe this is the basis for truly interpretable (deep) learning, and hence the basis for developing truly robust and fair machine learning algorithms and systems, with clear performance guarantees.",Broader Impact,115,4,,,FALSE,FALSE,FALSE,Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction,Algorithms -> Representation Learning,Algorithms -> Clustering; Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Algorithms -> Unsupervised Learning; Deep Learning -> Embedding Approaches; Theory -> Information Theory,,"['Yaodong Yu', ' Kwan Ho Ryan Chan', ' Chong You', ' Chaobing Song', ' Yi Ma']","{'UC Berkeley', 'University of California, Berkeley', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Learning Rich Rankings,"Arjun Seshadri, Stephen Ragain, Johan Ugander",Learning Rich Rankings,6affee954d76859baa2800e1c49e2c5d,https://proceedings.neurips.cc/paper/2020/file/6affee954d76859baa2800e1c49e2c5d-Paper.pdf,"Flexible ranking distributions that can be learned with provable guarantees can facilitate more powerful and reliable ranking algorithms inside recommender systems, search engines, and other ranking-based technological products. As a potential adverse consequence, more powerful and reliable learning algorithms can lead to an increased inappropriate reliance on technological solutions to complex problems, where practitioners may be not fully grasp the limitations of our work, e.g. independence assumptions, or that our risk bounds, as established here, do not hold for all data generating processes.",Broader impact,83,2,,,FALSE,FALSE,FALSE,Learning Rich Rankings,Algorithms -> Ranking and Preference Learning,Algorithms -> Representation Learning,,"['Arjun Seshadri', ' Stephen Ragain', ' Johan Ugander']","{'Stanford University', 'Twitter'}",1,1,1,{'USA'}
Color Visual Illusions: A Statistics-based Computational Model,"Elad Hirsch, Ayellet Tal",Color Visual Illusions: A Statistics-based Computational Model,6b39183e7053a0106e4376f4e9c5c74d,https://proceedings.neurips.cc/paper/2020/file/6b39183e7053a0106e4376f4e9c5c74d-Paper.pdf,"a) Who may benefit from this research? This work promotes knowledge regarding visual illusions. Rather than focusing on biological circuitry, this work proposes a tool for studying statistical properties shared by a variety of visual illusions. The patch-likelihood tool may interest researchers & developers in computer vision and machine learning. The illusion analysis and illusion generation methods may interest not only academic researchers (in psychology, neuro-science, computer vision, and machine learning), but also other groups that use visual illusions for educational purposes, in entertainment, in advertisements, in business programs, and in (op-)art. b) Who may be put at disadvantage from this research? The analysis and the results of this paper cannot serve in a negative manner. However, generating visual illusions might be used to deceive people, for instance in advertisement: An object might look of a certain color (or size), while its true color differs. c) What are the consequences of failure of the system? We do not see any such consequences. d) Does the task/method leverages biases in the data? This is not applicable.",Broader Impact,175,12,FALSE,FALSE,FALSE,FALSE,FALSE,Color Visual Illusions: A Statistics-based Computational Model,Applications -> Computer Vision,Neuroscience and Cognitive Science -> Visual Perception,Vision,,{'Technion'},1,1,1,{'Israel'}
Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,"Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela",Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,6b493230205f780e1bc26945df7481e5,https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf,"This work offers several positive societal benefits over previous work: the fact that it is more strongly grounded in real factual knowledge (in this case Wikipedia) makes it “hallucinate” less with generations that are more factual, and offers more control and interpretability. RAG could be employed in a wide variety of scenarios with direct benefit to society, for example by endowing it with a medical index and asking it open-domain questions on that topic, or by helping people be more effective at their jobs. With these advantages also come potential downsides: Wikipedia, or any potential external knowledge source, will probably never be entirely factual and completely devoid of bias. Since RAG can be employed as a language model, similar concerns as for GPT-2 [50] are valid here, although arguably to a lesser extent, including that it might be used to generate abuse, faked or misleading content in the news or on social media; to impersonate others; or to automate the production of spam/phishing content [54]. Advanced language models may also lead to the automation of various jobs in the coming decades [16]. In order to mitigate these risks, AI systems could be employed to fight against misleading content and automated spam/phishing.",Broader Impact,201,6,,,FALSE,FALSE,FALSE,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,Applications -> Natural Language Processing,Deep Learning -> Memory-Augmented Neural Networks,Natural language processing,"['Patrick Lewis', ' Ethan Perez', ' Aleksandra Piktus', ' Fabio Petroni', ' Vladimir Karpukhin', ' Naman Goyal', ' Heinrich Küttler', ' Mike Lewis', 'tau Yih', ' Tim Rocktäschel', ' Sebastian Riedel', ' Douwe Kiela']","{'Facebook Inc', 'Facebook AI Research', 'Facebook AI', 'New York University'}",1,1,1,{'USA'}
Universal guarantees for decision tree induction via a higher-order splitting criterion,"Guy Blanc, Neha Gupta, Jane Lange, Li-Yang Tan",Universal guarantees for decision tree induction via a higher-order splitting criterion,6b5617315c9ac918215fc7514bef514b,https://proceedings.neurips.cc/paper/2020/file/6b5617315c9ac918215fc7514bef514b-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Universal guarantees for decision tree induction via a higher-order splitting criterion,Theory -> Computational Learning Theory,Algorithms -> Classification,Theory (including computational and statistical analyses),"['Guy Blanc', ' Neha Gupta', ' Jane Lange', 'Yang Tan']",{'Stanford University'},1,0,0,{'USA'}
Trade-offs and Guarantees of Adversarial Representation Learning for Information Obfuscation,"Han Zhao, Jianfeng Chi, Yuan Tian, Geoffrey J. Gordon",Trade-offs and Guarantees of Adversarial Representation Learning for Information Obfuscation,6b8b8e3bd6ad94b985c1b1f1b7a94cb2,https://proceedings.neurips.cc/paper/2020/file/6b8b8e3bd6ad94b985c1b1f1b7a94cb2-Paper.pdf,"In the process of data collection and information sharing, the data might contain sensitive infor- mation that the users are unwilling to disclose. This poses severe challenges for regulations such as GDPR [15] that aims to control the uses and purposes of the collected and shared data. Our work takes a step towards better understanding the trade-off therein and suggests a practical method to mitigate the potential information leakage in such high-stakes scenarios. That being said, the adversarial learning techniques might inevitably lead to degradation in target performance, and more work is needed to explore the best trade-off that could be achieved.",Broader Impact,102,4,,,FALSE,FALSE,FALSE,Trade-offs and Guarantees of Adversarial Representation Learning for Information Obfuscation,Algorithms -> Adversarial Learning,,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Han Zhao', ' Jianfeng Chi', ' Yuan Tian', ' Geoffrey Gordon']","{'University of Virginia', 'Carnegie Mellon University', 'MSR Montréal & CMU'}",1,1,1,{'USA'}
A Boolean Task Algebra for Reinforcement Learning,"Geraud Nangue Tasse, Steven James, Benjamin Rosman",A Boolean Task Algebra For Reinforcement Learning,6ba3af5d7b2790e73f0de32e5c8c1798,https://proceedings.neurips.cc/paper/2020/file/6ba3af5d7b2790e73f0de32e5c8c1798-Paper.pdf,"Our work is mainly theoretical, but is a step towards creating agents that can solve tasks specified using human-understandable Boolean expressions, which could one day be deployed in practical RL systems. We envisage this as an avenue for overcoming the problem of reward misspecification, and for developing safer agents whose goals are readily interpretable by humans.",Broader Impact,56,2,FALSE,FALSE,FALSE,FALSE,FALSE,A Boolean Task Algebra for Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Multitask and Transfer Learning,Reinforcement learning and planning,"['Geraud Nangue Tasse', ' Steven James', ' Benjamin Rosman']","{'University of the Witwatersrand / CSIR', 'University of the Witwatersrand'}",1,0,0,{'South Africa'}
Learning with Differentiable Pertubed Optimizers,"Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, Francis Bach",Learning with Differentiable Perturbed Optimizers,6bb56208f672af0dd65451f869fedfd9,https://proceedings.neurips.cc/paper/2020/file/6bb56208f672af0dd65451f869fedfd9-Paper.pdf,"This submission focuses on foundational work, with application to general machine learning techniques. These techniques expend the range of operations that can be used in end-to-end differentiable systems, by allowing to incorporate optimizers in ML pipelines. There are no foreseeable societal consequences that are specifically related to these methods, beyond those of the field in general.",Broader impact,56,3,TRUE,FALSE,FALSE,FALSE,FALSE,Learning with Differentiable Pertubed Optimizers,Algorithms -> Structured Prediction,Algorithms -> Stochastic Methods; Optimization -> Convex Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Quentin Berthet', ' Mathieu Blondel', ' Olivier Teboul', ' Marco Cuturi', 'Philippe Vert', ' Francis Bach']","{'Ecole Centrale Paris', 'INRIA - Ecole Normale Superieure', 'Google Brain', 'Google'}",1,1,1,"{'France', 'USA'}"
Optimal Learning from Verified Training Data,"Nicholas Bishop, Long Tran-Thanh, Enrico Gerding",Optimal Learning from Verified Training Data,6c1e55ec7c43dc51a37472ddcbd756fb,https://proceedings.neurips.cc/paper/2020/file/6c1e55ec7c43dc51a37472ddcbd756fb-Paper.pdf,"The manipulation and fairness of algorithms form a significant barrier to practical application of theoretically effective machine learning algorithms in many real world use cases. With this work, we have attempted to address the important problem of data manipulation, which has many societal consequences. Data manipulation is one of many ways in which an individual can “game the system"" in order to secure beneficial outcomes for themselves to the detriment of others. Thus, reducing the potential benefits of data manipulation is of worthwhile consideration and focus. Whilst this paper is primarily of theoretical focus, we hope that our work will form a contributing step towards safe, fair, and effective application of machine learning algorithms in more practical settings.",9 Broader Impact,118,5,,,FALSE,FALSE,FALSE,Optimal Learning from Verified Training Data,Algorithms -> Adversarial Learning,Algorithms -> Regression; Optimization -> Non-Convex Optimization,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Nicholas Bishop', 'Thanh', ' Enrico Gerding']","{'University of Warwick', 'University of Southampton', 'university of Southampton'}",1,0,0,{'UK'}
Online Linear Optimization with Many Hints,"Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar, Manish Purohit",Online Linear Optimization with Many Hints,6c250b592dc94d4de38a79db4d2b18f2,https://proceedings.neurips.cc/paper/2020/file/6c250b592dc94d4de38a79db4d2b18f2-Paper.pdf,"Our work focuses on theoretical foundations. Online learning methods have had direct impact in domains such as online advertising. But primarily, the methods developed are used in improving other optimization procedures, and thus only have an indirect impact. We believe that there are no adverse ethical aspects or potentially negative societal consequences of our work.",Broader Impact,55,4,TRUE,TRUE,FALSE,FALSE,FALSE,Online Linear Optimization with Many Hints,Algorithms -> Online Learning,Optimization -> Convex Optimization,Theory (including computational and statistical analyses),"['Aditya Bhaskara', ' Ashok Cutkosky', ' Ravi Kumar', ' Manish Purohit']","{'Google', 'University of Utah', 'Google Research'}",1,1,1,{'USA'}
Dynamical mean-field theory for stochastic gradient descent in Gaussian mixture classification,"Francesca Mignacco, Florent Krzakala, Pierfrancesco Urbani, Lenka Zdeborová",Dynamical mean-field theory for stochastic gradient descent in Gaussian mixture classification,6c81c83c4bd0b58850495f603ab45a93,https://proceedings.neurips.cc/paper/2020/file/6c81c83c4bd0b58850495f603ab45a93-Paper.pdf,"Our work is theoretical in nature, and as such the potential societal consequence are difficult to foresee. We anticipate that deeper theoretical understanding of the functioning of machine learning systems will lead to their improvement in the long term.",Broader Impact,39,2,TRUE,FALSE,FALSE,FALSE,FALSE,Dynamical mean-field theory for stochastic gradient descent in Gaussian mixture classification,Theory -> Statistical Physics of Learning,Optimization -> Non-Convex Optimization; Theory -> High-Dimensional Inference; Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Francesca Mignacco', ' Florent Krzakala', ' Pierfrancesco Urbani', ' Lenka Zdeborová']","{'CEA Saclay', 'IPhT, CEA Saclay', 'Institut de Physique Théorique'}",1,0,0,{'France'}
Causal Discovery from Soft Interventions with Unknown Targets: Characterization and Learning,"Amin Jaber, Murat Kocaoglu, Karthikeyan Shanmugam, Elias Bareinboim",Causal Discovery from Soft Interventions with Unknown Targets: Characterization and Learning,6cd9313ed34ef58bad3fdd504355e72c,https://proceedings.neurips.cc/paper/2020/file/6cd9313ed34ef58bad3fdd504355e72c-Paper.pdf,"Learning cause-and-e ↵ ect relationships is one of the fundamental problems for various fields, includ- ing biology [28, 6], epidemiology [26], and economics [12]. The introduced characterization and algorithm provide a clear understanding on how to accomplish this task while leveraging interven- tional data, even when the interventional targets are unknown. Moreover, the proposed approach can be instrumental towards explainability in artificial intelligence, which has been a topic of increas- ing importance recently. On the other hand, performing experiments to obtain interventional data poses some ethical challenges, such as randomizing the smoking factor which would require forcing individuals to smoke. Therefore, such limitations and concerns should be taken into consideration.",Broader Impact,110,5,,,FALSE,FALSE,FALSE,Causal Discovery from Soft Interventions with Unknown Targets: Characterization and Learning,Probabilistic Methods -> Causal Inference,Probabilistic Methods -> Graphical Models,Causality,"['Amin Jaber', ' Murat Kocaoglu', ' Karthikeyan Shanmugam', ' Elias Bareinboim']","{'IBM Research, NY', 'IBM Research', 'Columbia University', 'Purdue University'}",1,1,1,{'USA'}
Exploiting the Surrogate Gap in Online Multiclass Classification,Dirk van der Hoeven,Exploiting the Surrogate Gap in Online Multiclass Classification,6ce8d8f3b038f737cefcdafcf3752452,https://proceedings.neurips.cc/paper/2020/file/6ce8d8f3b038f737cefcdafcf3752452-Paper.pdf,"Our contribution is primarily theoretical. Therefore, this work does not present any foreseeable societal consequence.",7 Broader Impact,15,2,TRUE,FALSE,FALSE,FALSE,FALSE,Exploiting the Surrogate Gap in Online Multiclass Classification,Algorithms -> Online Learning,Algorithms -> Bandit Algorithms,Theory (including computational and statistical analyses),['Dirk van der Hoeven'],{'Leiden University'},1,0,0,{'Netherlands'}
The Pitfalls of Simplicity Bias in Neural Networks,"Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, Praneeth Netrapalli",The Pitfalls of Simplicity Bias in Neural Networks,6cfe0e6127fa25df2a0ef2ae1067d915,https://proceedings.neurips.cc/paper/2020/file/6cfe0e6127fa25df2a0ef2ae1067d915-Paper.pdf,"Our work is foundational in nature and seeks to improve our understanding of neural networks. We do not foresee any significant societal consequences in the short term. However, in the long term, we believe that a concrete understanding of deep learning phenomena is essential to develop reliable deep learning systems for practical applications that have societal impact.",Broader Impact,57,3,TRUE,TRUE,FALSE,FALSE,FALSE,The Pitfalls of Simplicity Bias in Neural Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Models of Learning and Generalization,Deep learning,"['Harshay Shah', ' Kaustav Tamuly', ' Aditi Raghunathan', ' Prateek Jain', ' Praneeth Netrapalli']","{'Stanford University', 'Microsoft Research'}",1,1,1,{'USA'}
Automatically Learning Compact Quality-aware Surrogates for Optimization Problems,"Kai Wang, Bryan Wilder, Andrew Perrault, Milind Tambe",Automatically Learning Compact Quality-aware Surrogates for Optimization Problems,6d0c932802f6953f70eb20931645fa40,https://proceedings.neurips.cc/paper/2020/file/6d0c932802f6953f70eb20931645fa40-Paper.pdf,"End-to-end approaches can perform better in data-poor settings, improving access to the benefits of machine learning systems for communities that are resource constrained. Standard two-stage approaches typically requires enough data to learn well across the data distribution. In many domains focused on social impact such as wildlife conservation, limited data can be collected and the resources are also very limited. End-to-end learning is usually more favorable than two-stage approach under these circumstances; it can achieve higher quality results despite data limitations compared to two- stage approaches. This paper reduces the computational costs of end-to-end learning and increases the performance benefits. But such performance improvements may come with a cost in transferability because the end-to-end learning task is specialized towards particular decisions, whereas a prediction-only model from the two-stage predict-then-optimize framework might be used for different decision making tasks in the same domain. Thus, the predictive model trained for a particular decision-making task in the end-to- end framework is not necessarily as interpretable or transferable as a model trained for prediction only. For real-world tasks, there would need to be careful analysis of cost-benefit of applying an end-to-end approach vis-a-vis a two-stage approach particularly if issues of interpretability and transferrability are critical; in some domains these may be crucial. Further research is required to improve upon these issues in the end-to-end learning approach.",Broader impact:,222,9,,,FALSE,FALSE,FALSE,Automatically Learning Compact Quality-aware Surrogates for Optimization Problems,Optimization -> Stochastic Optimization,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Kai Wang', ' Bryan Wilder', ' Andrew Perrault', ' Milind Tambe']","{'Harvard University', 'Harvard University/Google'}",1,1,1,{'USA'}
Empirical Likelihood for Contextual Bandits,"Nikos Karampatziakis, John Langford, Paul Mineiro",Empirical Likelihood for Contextual Bandits,6d34d468ac8876333c4d7173b85efed9,https://proceedings.neurips.cc/paper/2020/file/6d34d468ac8876333c4d7173b85efed9-Paper.pdf,Not applicable to this work.,Broader Impact,5,1,TRUE,FALSE,FALSE,FALSE,FALSE,Empirical Likelihood for Contextual Bandits,Algorithms -> Bandit Algorithms,Reinforcement Learning and Planning -> Reinforcement Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Paul Mineiro', ' Nikos Karampatziakis', ' John Langford']","{'Microsoft', 'Microsoft Research New York'}",0,1,0,{'USA'}
Can Q-Learning with Graph Networks Learn a Generalizable Branching Heuristic for a SAT Solver?,"Vitaly Kurin, Saad Godil, Shimon Whiteson, Bryan Catanzaro",Can Q -Learning with Graph Networks Learn a Generalizable Branching Heuristic for a SAT Solver?,6d70cb65d15211726dcce4c0e971e21c,https://proceedings.neurips.cc/paper/2020/file/6d70cb65d15211726dcce4c0e971e21c-Paper.pdf,"We believe that further progress in machine learning can have a profound economic, societal and political impact. It is hard to predict a particular effect of our method on society but, in general, we  believe that the society might benefit from our research through its impact on industry and academia. We consider two examples below. SAT has a profound impact on circuit design, computer security, artificial intelligence, automatic theorem proving, and combinatorial optimisation, among others. For academia, Graph- Q -SAT code and results give a playground to work on GNN scaling, generalisation in RL, transfer and multitask learning, and incorporating a machine learning model with a well established algorithm. It can encourage collaboration between the applied ML and SAT communities. Analysing the behaviour of learned models might give human designers more insights to boost further research. For industry, having faster SAT solvers would lead to faster production cycles and faster rate of progress as well as to more robust products. In circuitry design, for example, SAT is used for hardware verification. As a result, faster SAT solvers will eventually lead to fewer faults in hardware. Like any technology, our method also carries potential risks. Further automation might reduce the need for human labour. If not managed and regulated properly, machine learning progress might also exacerbate social and economic inequality.",Broader Impact,219,13,,,FALSE,FALSE,FALSE,Can Q-Learning with Graph Networks Learn a Generalizable Branching Heuristic for a SAT Solver?,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Multitask and Transfer Learning,Reinforcement learning and planning,"['Vitaly Kurin', ' Saad Godil', ' Shimon Whiteson', ' Bryan Catanzaro']","{'NVIDIA', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
Non-reversible Gaussian processes for identifying latent dynamical structure in neural data,"Virginia Rutten, Alberto Bernacchia, Maneesh Sahani, Guillaume Hennequin",Non-reversible Gaussian processes for identifying latent dynamical structure in neural data,6d79e030371e47e6231337805a7a2685,https://proceedings.neurips.cc/paper/2020/file/6d79e030371e47e6231337805a7a2685-Paper.pdf,"From molecules to stock-markets, from short timescales to long, the arrow of time can be seen in the evolution of natural living systems. Indeed, the dynamics of natural living systems are not time-reversible, they depart from “thermodynamic equilibrium” (Gnesotto et al., 2018). Despite the ubiquity and importance of non-reversibility, there is a paucity of methods for exploring the spatio-temporal structure of irreversibility in multivariate time series. The new class of non-reversible covariance functions we developed makes use of this intrinsic property, offering the potential of exploiting this natural feature in a range of data analysis algorithms. In general, quantifying and tracking changes in reversibility over time could be useful in detecting the early onset of real world events. More specifically, we expect that one of the larger impacts of the method will be in the field of brain-machine interfaces (BMI) and neuroprosthetics. BMIs have the possibility of revolutionizing how we live. Optimizing the interface both at the hardware and software level is key to making this a reality. Regarding software, identifying actionable latent variables embedded in high-dimensional neural activity is of particular importance in facilitating communication. Given that behavior is non-reversible, the neural activity that causally drives this behavior is likely to also be non-reversible, thus seeking latents with such property seems highly promising. Moreover, BMI algorithms often need to be run online which the scalability of our method would also permit. These applications come with ethical and societal concerns, in particular regarding privacy and responsibility. These ethics challenges are being actively investigated by the field of bioethics (Clausen, 2008) and the broader community; and we hope that such considerations will continue to shape the future research and reality.",6 Broader impact,279,13,,,FALSE,FALSE,FALSE,Non-reversible Gaussian processes for identifying latent dynamical structure in neural data,Neuroscience and Cognitive Science -> Neural Coding,Probabilistic Methods -> Gaussian Processes; Probabilistic Methods -> Latent Variable Models,Neuroscience and cognitive science,"['Virginia Rutten', 'Gatsby Computational Neuroscience Unit', ' Alberto Bernacchia', ' Maneesh Sahani', ' Guillaume Hennequin']","{'UCL', 'Gatsby Unit, UCL', 'MediaTek Research', 'Cambridge'}",1,1,1,{'UK'}
Listening to Sounds of Silence for Speech Denoising,"Ruilin Xu, Rundi Wu, Yuko Ishiwaka, Carl Vondrick, Changxi Zheng",Listening to Sounds of Silence for Speech Denoising,6d7d394c9d0c886e9247542e06ebb705,https://proceedings.neurips.cc/paper/2020/file/6d7d394c9d0c886e9247542e06ebb705-Paper.pdf,"High-quality speech denoising is desired in a myriad of applications: human-robot interaction, cellular communications, hearing aids, teleconferencing, music recording, filmmaking, news reporting, and surveillance systems to name a few. Therefore, we expect our proposed denoising method—be it a system used in practice or a foundation for future technology—to find impact in these applications. In our experiments, we train our model using English speech only, to demonstrate its generalization property—the ability of denoising spoken languages beyond English. Our demonstration of denoising Japanese, Chinese, and Korean speeches is intentional: they are linguistically and phonologically distant from English (in contrast to other English “siblings” such as German and Dutch). Still, our model may bias in favour of spoken languages and cultures that are closer to English or that have frequent pauses to reveal silent intervals. Deeper understanding of this potential bias requires future studies in tandem with linguistic and sociocultural insights. Lastly, it is natural to extend our model for denoising audio signals in general or even signals beyond audio (such as Gravitational wave denoising [97]). If successful, our model can bring in even broader impacts. Pursuing this extension, however, requires a judicious definition of “silent intervals”. After all, the notion of “noise” in a general context of signal processing depends on specific applications: noise in one application may be another’s signals. To train a neural network that exploits a general notion of silent intervals, prudence must be taken to avoid biasing toward certain types of noise.",Broader Impact,244,11,,,FALSE,FALSE,FALSE,Listening to Sounds of Silence for Speech Denoising,Applications -> Audio and Speech Processing,,Audio / Music / Speech,"['Ruilin Xu', ' Rundi Wu', ' Yuko Ishiwaka', ' Carl Vondrick', ' Changxi Zheng']",{'Columbia University'},1,0,0,{'USA'}
BoxE: A Box Embedding Model for Knowledge Base Completion,"Ralph Abboud, Ismail Ceylan, Thomas Lukasiewicz, Tommaso Salvatori",BoxE: A Box Embedding Model for Knowledge Base Completion,6dbbe6abe5f14af882ff977fc3f35501,https://proceedings.neurips.cc/paper/2020/file/6dbbe6abe5f14af882ff977fc3f35501-Paper.pdf,"The representation and inference of knowledge is essential for humanity, and thus any improvements in the quality and reliability of automated inference methods can significantly support endeavors in several application domains. This work provides a means for dealing with incomplete knowledge, and offers users to complete their knowledge bases with the help of automated machinery. The model predictions rely mostly on interpretable and explainable logical patterns, which makes it easier to analyze the model behavior. Furthermore, this work enables safely injecting background rules when completing knowledge bases, and this safety is of great value in settings where inferred knowledge is critical (e.g., completing medical knowledge bases). This work thus also provides a logically grounded approach that improves the quality of predictions and completions in safety- critical settings. The ability of the proposed model to naturally handle more general knowledge bases (beyond knowledge graphs) could also unlock the use of knowledge base completion technologies on important knowledge bases which were previously ignored.",Broader Impact,161,6,,,FALSE,FALSE,FALSE,BoxE: A Box Embedding Model for Knowledge Base Completion,Deep Learning -> Embedding Approaches,Algorithms -> Relational Learning; Algorithms -> Representation Learning; Algorithms -> Structured Prediction; Applications -> Automated Reasoning and Formal Methods,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Ralph Abboud', ' Ismail Ceylan', ' Thomas Lukasiewicz', ' Tommaso Salvatori']",{'University of Oxford'},1,0,0,{'UK'}
Coherent Hierarchical Multi-Label Classification Networks,"Eleonora Giunchiglia, Thomas Lukasiewicz",Coherent Hierarchical Multi-Label Classification Networks,6dd4e10e3296fa63738371ec0d5df818,https://proceedings.neurips.cc/paper/2020/file/6dd4e10e3296fa63738371ec0d5df818-Paper.pdf,"In this paper, we proposed a novel model that is shown to outperform the current state-of-the-art models on commonly used HMC benchmarks. We expect our approach to have a large impact on the research community not only because of its positive results but also because it is relatively easy to implement and test using standard libraries, and the code os publicly available. From the application perspective, given the generality of the approach, it is impossible to foresee all the possible impacts in all the different application domains where HMC problems arise. We thus focus on functional genomics, which is the application domain most benchmarks come from. The goal in functional genomics is to describe the functions and interactions of genes and their products, RNA and proteins. As stated in [23, 25], in recent years, the generation of proteomic data has increased substantially, and annotating all sequences is costly and time-consuming, making it often unfeasible. It is thus necessary to develop methods (like ours) that are able to automatize this process. Having better models for such a task may unlock many possibilities. Indeed, it may (i) allow to better understand the role of proteins in disease pathobiology, (ii) help determine the function of metagenomes offering possibilities to discover novel genes and novel biomolecules, and (iii) facilitate finding drug targets, which is crucial to the success of mechanism-based drug discovery.",Broader Impact,228,9,,,FALSE,FALSE,FALSE,Coherent Hierarchical Multi-Label Classification Networks,Deep Learning -> Supervised Deep Networks,Algorithms -> Classification,Deep learning,,{'University of Oxford'},1,0,0,{'UK'}
Walsh-Hadamard Variational Inference for Bayesian Deep Learning,"Simone Rossi, Sebastien Marmin, Maurizio Filippone",Walsh-Hadamard Variational Inference for Bayesian Deep Learning,6df182582740607da754e4515b70e32d,https://proceedings.neurips.cc/paper/2020/file/6df182582740607da754e4515b70e32d-Paper.pdf,"Bayesian inference for Deep Neural Networks ( DNN s) and Convolutional Neural Networks ( CNN s) offers attractive solutions to many problems where one needs to combine the flexibility of these deep models with the possibility to accurately quantify uncertainty in predictions and model parameters. This is of fundamental importance in an increasingly large number of applications of machine learning in society where uncertainty matters, and where calibration of the predictions and resilience to adversarial attacks are desirable. Due to the intractability of Bayesian inference for such models, one needs to resort to approximations. Variational inference ( VI ) gained popularity long before the deep learning revolution, which has seen a considerable interest in the application of VI to DNN s and CNN s in the last decade. However, VI is still under appreciated in the deep learning community because it comes with a higher computational cost for optimization, sampling, storage and inference. With this work, we offer a novel solution to this problem to make VI truly scalable in each of its parts (parameterization, sampling and inference). Our approach is inspired by the literature on kernel methods, and we believe that this cross-fertilization will enable further contributions in both communities. In the long term, our work will make it possible to accelerate training/inference of Bayesian deep models, while reducing their storage requirements. This will complement Bayesian compression techniques to facilitate the deployment of Bayesian deep models onto FPGA , ASIC and embedded processors.",Broader Impact,244,9,,,FALSE,FALSE,FALSE,Walsh-Hadamard Variational Inference for Bayesian Deep Learning,Probabilistic Methods -> Variational Inference,Algorithms -> Kernel Methods; Algorithms -> Uncertainty Estimation,Probabilistic methods and inference,"['Simone Rossi', ' Sebastien Marmin', ' Maurizio Filippone']","{'EURECOM', 'Department of Data Science, EURECOM'}",1,0,0,{'France'}
Federated Bayesian Optimization via Thompson Sampling,"Zhongxiang Dai, Bryan Kian Hsiang Low, Patrick Jaillet",Federated Bayesian Optimization via Thompson Sampling,6dfe08eda761bd321f8a9b239f6f4ec3,https://proceedings.neurips.cc/paper/2020/file/6dfe08eda761bd321f8a9b239f6f4ec3-Paper.pdf,"Since the setting of our FBO is similar to that of FL, our work inherits a number of potential broader impacts of FL. We will analyze here the potential impacts of our work in the scenario where the individual agents are edge devices such as mobile phones since it is a major area of application for FBO and FL. Specifically, since our algorithm can be used to improve the efficiency of black-box optimization tasks performed by mobile phones, it has the potential of dramatically improving the efficacy and function of various applications for the user (e.g., the smart keyboard example that we mentioned in Section 1), which will enhance their user experience and productivity. On the other hand, some negative impacts of FL also need to be considered when promoting the widespread application of our work. For example, although our work is able to prevent exchanging the raw data in the same way as standard FL, advanced privacy attack methods (e.g., inference attack) may still incur risks of privacy leak for FL and thus FBO. Preventing this risk through principled privacy protection techniques (e.g., differential privacy) is important for the widespread adoption of FL and FBO algorithms and hence represents an interesting and promising direction for future research.",Broader Impact,208,6,,,FALSE,FALSE,FALSE,Federated Bayesian Optimization via Thompson Sampling,Probabilistic Methods -> Gaussian Processes,Algorithms -> Active Learning,AutoML,"['Zhongxiang Dai', ' Bryan Kian Hsiang Low', ' Patrick Jaillet']","{'MIT', 'National University of Singapore'}",1,0,0,"{'Singapore', 'USA'}"
MultiON: Benchmarking Semantic Map Memory using Multi-Object Navigation,"Saim Wani, Shivansh Patel, Unnat Jain, Angel Chang, Manolis Savva",MultiON: Benchmarking Semantic Map Memory using Multi-Object Navigation,6e01383fd96a17ae51cc3e15447e7533,https://proceedings.neurips.cc/paper/2020/file/6e01383fd96a17ae51cc3e15447e7533-Paper.pdf,"This work is a step toward enabling robots that can navigate and operate in real world environments. We focus on the study of what kind of maps might be useful to such robotic agents, and how to benchmark their performance. In the future, robust robotic agents may be able to assist the elderly (bringing them their medication), deliver things to hotel rooms, help in moving items in warehouses, and generally serve broader society in a variety of roles. On the other hand, success along these directions may cause displacement of workers from related occupations and economic difficulties for large segments of the population currently employed in a variety of sectors that are amenable to automation. Moreover, deployment of imperfect robotic agents, that are not guaranteed to be failure-free may cause injuries or damages. We believe that developing and studying the behavior of such systems in simulation first, and then in controlled real environments is paramount for minimizing these risks, before they are deployed in the real world.",Broader Impact,167,6,,,FALSE,FALSE,FALSE,MultiON: Benchmarking Semantic Map Memory using Multi-Object Navigation,Reinforcement Learning and Planning -> Navigation,"Applications -> Visual Question Answering; Applications -> Visual Scene Analysis and Interpretation; Data, Challenges, Implementations, and Software -> Benchmarks",Reinforcement learning and planning,,"{'University of Illinois at Urbana Champaign', 'Simon Fraser University', 'Indian Institute of Technology Kanpur'}",1,0,0,"{'Canada', 'India', 'USA'}"
Neural Complexity Measures,"Yoonho Lee, Juho Lee, Sung Ju Hwang, Eunho Yang, Seungjin Choi",Neural Complexity Measures,6e17a5fd135fcaf4b49f2860c2474c7c,https://proceedings.neurips.cc/paper/2020/file/6e17a5fd135fcaf4b49f2860c2474c7c-Paper.pdf,"Safety and reliability are important desiderata for machine learning models, and these properties are even more important given the recent success of black-box models such as deep neural networks. Our proposed approach can be applied to improve training in any regression or classification task, and our experiments demonstrate its ability to (1) predict the generalization gap and (2) improve test loss when used as a regularizer. NC’s data-driven prediction of the generalization gap can serve as an approximate guarantee for safety-critical problems. Furthermore, future extensions of NC may enable previously impossible tasks since NC was particularly effective in settings where conventional learners overfitted.",Broader Impact,103,4,,,FALSE,FALSE,FALSE,Neural Complexity Measures,Algorithms -> Meta-Learning,Theory -> Models of Learning and Generalization,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yoonho Lee', ' Juho Lee', ' Sung Ju Hwang', ' Eunho Yang', ' Seungjin Choi']","{'KAIST, AITRICS', 'POSTECH', 'AITRICS'}",1,1,1,"{'France', 'South Korea'}"
Optimal Iterative Sketching Methods with the Subsampled Randomized Hadamard Transform,"Jonathan Lacotte, Sifan Liu, Edgar Dobriban, Mert Pilanci",Optimal Iterative Sketching with the Subsampled Randomized Hadamard Transform,6e69ebbfad976d4637bb4b39de261bf7,https://proceedings.neurips.cc/paper/2020/file/6e69ebbfad976d4637bb4b39de261bf7-Paper.pdf,We believe that the proposed method in this work can have positive societal impacts. Our algorithm can be applied in massive scale distributed learning and optimization problems encountered in real-life problems. The computational effort can be significantly lowered as a result of dimension reduction. Consequently energy costs for optimization can be significantly reduced.,Broader Impact,53,4,FALSE,FALSE,FALSE,FALSE,FALSE,Optimal Iterative Sketching Methods with the Subsampled Randomized Hadamard Transform,Optimization -> Convex Optimization,Algorithms -> Data Compression; Algorithms -> Large Scale Learning; Algorithms -> Regression; Theory -> Large Deviations and Asymptotic Analysis,Theory (including computational and statistical analyses),"['Jonathan Lacotte', ' Sifan Liu', ' Edgar Dobriban', ' Mert Pilanci']","{'Stanford', 'Stanford University', 'University of Pennsylvania'}",1,0,0,{'USA'}
Provably adaptive reinforcement learning in metric spaces,"Tongyi Cao, Akshay Krishnamurthy",Provably adaptive reinforcement learning in metric spaces,6ef1173b096aa200158bfbc8af3ae8e3,https://proceedings.neurips.cc/paper/2020/file/6ef1173b096aa200158bfbc8af3ae8e3-Paper.pdf,"This is primarily a theoretical contribution, so the broader impacts of the results are quite minimal. As the algorithm we analyze has already been developed and used in experiments (Sinclair et al., 2019), we do not expect our results would have any bearing on whether this algorithm is used in practice. On the other hand, we do believe that adaptive algorithms for reinforcement learning will be essential for applications where data collection is costly, such as applications in tutoring systems. We hope that our results can inspire future work into these important applications.",Broader Impact,93,4,,,FALSE,FALSE,FALSE,Provably adaptive reinforcement learning in metric spaces,Theory -> Statistical Learning Theory,Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Tongyi Cao', ' Akshay Krishnamurthy']","{'Microsoft', 'University of Massachusetts Amherst'}",1,1,1,{'USA'}
ShapeFlow: Learnable Deformation Flows Among 3D Shapes,"Chiyu Jiang, Jingwei Huang, Andrea Tagliasacchi, Leonidas J. Guibas",ShapeFlow: Learnable Deformations Among 3D Shapes,6f1d0705c91c2145201df18a1a0c7345,https://proceedings.neurips.cc/paper/2020/file/6f1d0705c91c2145201df18a1a0c7345-Paper.pdf,"The work has broad potential impact within the computer vision and graphics community, as it describes a novel methodology that enables a range of new applications, from animation to novel content creation. We have discussed the potential future directions the work could take in Sec. 5. On the broader societal level, this work remains largely academic in nature, and does not pose foreseeable risks regarding defense, security, and other sensitive fields.",Broader impact,71,4,FALSE,FALSE,FALSE,FALSE,FALSE,ShapeFlow: Learnable Deformation Flows Among 3D Shapes,Applications -> Computer Vision,"Applications -> Body Pose, Face, and Gesture Analysis",Vision,"['Chiyu Jiang', ' Jingwei Huang', ' Andrea Tagliasacchi', ' Leonidas J Guibas']","{'UC Berkeley', 'Stanford University', 'Google Research, Brain'}",1,1,1,{'USA'}
Self-Supervised Learning by Cross-Modal Audio-Video Clustering,"Humam Alwassel, Dhruv Mahajan, Bruno Korbar, Lorenzo Torresani, Bernard Ghanem, Du Tran",Self-Supervised Learning by Cross-Modal Audio-Video Clustering,6f2268bd1d3d3ebaabb04d6b5d099425,https://proceedings.neurips.cc/paper/2020/file/6f2268bd1d3d3ebaabb04d6b5d099425-Paper.pdf,"Video has become a commonplace in society. Its uses range from entertainment, to communication and teaching. Thus, the learning of semantic representations of video has broad and far-reaching potential applications. The authors do not foresee major ethical issues associated to this work. However, as the proposed approach is self-supervised, it will learn the inherent properties and structure of the training data. Thus, the learned model may exhibit biases intrinsically present in the data.",Broader Impact Statement,73,6,,,FALSE,FALSE,FALSE,Self-Supervised Learning by Cross-Modal Audio-Video Clustering,Applications -> Video Analysis,Algorithms -> Unsupervised Learning; Applications -> Activity and Event Recognition; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Humam Alwassel', ' Dhruv Mahajan', ' Bruno Korbar', ' Lorenzo Torresani', ' Bernard Ghanem', ' Du Tran']","{'Facebook', 'KAUST', 'Facebook AI'}",1,1,1,"{'USA', 'Saudi Arabia'}"
Optimal Query Complexity of Secure Stochastic Convex Optimization,"Wei Tang, Chien-Ju Ho, Yang Liu",Optimal Query Complexity of Secure Stochastic Convex Optimization,6f3a770e5af1fd4cadc5f004b81e1040,https://proceedings.neurips.cc/paper/2020/file/6f3a770e5af1fd4cadc5f004b81e1040-Paper.pdf,"In this work, we explore the problem of securing the privacy of the learner against a spying adversary. In a broader context, we explore the limit of securing the decision maker’s unobservable intent/goal when the query decisions to achieve the intent/goal are observable. Our results, while being theoretical in nature, have potential impacts in providing instructions for designing better security tools to ensure that people’s online activities do not create unintended leakage of private information. On the other hand, the discussion on the adversarial strategies could also lead to more delicate attacks, especially to those who are not aware of the existence of attacks from potential adversaries.",Broader Impact,107,4,,,FALSE,FALSE,FALSE,Optimal Query Complexity of Secure Stochastic Convex Optimization,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Optimization -> Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Wei Tang', 'Ju Ho', ' Yang Liu']",{'UC Santa Cruz'},1,0,0,{'USA'}
DynaBERT: Dynamic BERT with Adaptive Width and Depth,"Lu Hou, Zhiqi Huang, Lifeng Shang, Xin Jiang, Xiao Chen, Qun Liu",DynaBERT: Dynamic BERT with Adaptive Width and Depth,6f5216f8d89b086c18298e043bfe48ed,https://proceedings.neurips.cc/paper/2020/file/6f5216f8d89b086c18298e043bfe48ed-Paper.pdf,"Traditional machine learning computing relies on mobile perception and cloud computing. However, considering the speed, reliability, and cost of the data transmission process, cloud-based machine learning may cause delays in inference, user privacy leakage, and high data transmission costs. In such cases, in addition to end-cloud collaborative computing, it becomes increasingly important to run deep neural network models directly on edge. Recently, pre-trained language models like BERT have achieved impressive results in various natural language processing tasks. However, the BERT model contains tons of parameters, hindering its deployment to devices with limited resources. The difficulty of deploying BERT to these devices lies in two aspects. Firstly, the performances of various devices are different, and it is unclear how to deploy a BERT model suitable for each edge device based on its resource constraint. Secondly, the resource condition of the same device under different circumstances can be quite different. Once the BERT model is deployed to a specific device, dynamically selecting a part of the model for inference based on the device’s current resource condition is also desirable. Motivated by this, we propose DynaBERT. Instead of compressing the BERT model to a fixed size like existing BERT compression methods, the proposed DynaBERT can adjust its size and latency by selecting a sub-network with adaptive width and depth. By allowing both adaptive width and depth, the proposed DynaBERT also enables a large number of architectural configurations of the BERT model. Moreover, once the DynaBERT is trained, no further fine-tuning is required for each sub-network, and the benefits are threefold. Firstly, we only need to train one DynaBERT model, but can deploy different sub-networks to different hardware platforms based on their performances. Secondly, once one sub-network is deployed to a specific device, this device can select the same or smaller sub-networks for inference based on its dynamic efficiency constraints. Thirdly, different sub-networks sharing weights in one single model dramatically reduces the training and inference cost, compared to using different-sized models separately for different hardware platforms. This can reduce carbon emissions, and is thus more environmentally friendly. Though not originally developed for compression, sub-networks of the proposed DynaBERT outperform other BERT compression methods under the same efficiency constraints like #parameters, FLOPs, GPU and CPU latency. Besides, the proposed DynaBERT at its largest size often achieves better performances as BERT BASE with the same size. A possible reason is that allowing adaptive width and depth increases the training difficulty and acts as regularization, and so contributes posi- tively to the performance. In this way, the proposed training method of DynaBERT also acts as a regularization method that can boost the generalization performance. Meanwhile, we also find that the compressed sub-networks of the learned DynaBERT have good interpretability. In order to maintain the representation power, the attention patterns of sub-networks with smaller width or depth of the trained DynaBERT exhibit function fusion, compared to the full-sized model. Interestingly, these attention patterns even explain the enhanced performance of DynaBERT on some tasks, e.g., enhanced ability of distinguishing linguistic acceptable and non-acceptable sentences for CoLA . Besides the positive broader impacts above, since DynaBERT enables easier deployment of BERT, it also makes the negative impacts of BERT more severe. For instance, application in dialogue systems replaces help-desks and can cause job loss. Extending our method to generative models like GPT also faces the risk of generating offensive, biased or unethical outputs.",Broader Impact,563,27,,,FALSE,FALSE,FALSE,DynaBERT: Dynamic BERT with Adaptive Width and Depth,Applications -> Natural Language Processing,Deep Learning -> Efficient Inference Methods,Natural language processing,"['Lu Hou', ' Zhiqi Huang', ' Lifeng Shang', ' Xin Jiang', ' Xiao Chen', ' Qun Liu']",{'Peking University'},1,0,0,{'China'}
Generalization Bound of Gradient Descent for Non-Convex Metric Learning,"MINGZHI DONG, Xiaochen Yang, Rui Zhu, Yujiang Wang, Jing-Hao Xue",Generalization Bound of Gradient Descent for Non-Convex Metric Learning,6f5e4e86a87220e5d361ad82f1ebc335,https://proceedings.neurips.cc/paper/2020/file/6f5e4e86a87220e5d361ad82f1ebc335-Paper.pdf,"This paper is a theoretical analysis relating to gradient descent and metric learning algorithms, making no direct impact on ethical and societal issues. The findings can be used to design more effective training strategies or algorithms, and consequently benefit the downstream applications.",Broader Impact,42,2,TRUE,TRUE,FALSE,FALSE,FALSE,Generalization Bound of Gradient Descent for Non-Convex Metric Learning,Algorithms -> Metric Learning,Theory -> Computational Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['MINGZHI DONG', ' Xiaochen Yang', ' Rui Zhu', ' Yujiang Wang', 'Hao Xue']","{'City, University of London', 'University College London', 'Imperial College London'}",1,0,0,{'UK'}
Dynamic Submodular Maximization,Morteza Monemizadeh,Dynamic Submodular Maximization,6fbd841e2e4b2938351a4f9b68f12e6b,https://proceedings.neurips.cc/paper/2020/file/6fbd841e2e4b2938351a4f9b68f12e6b-Paper.pdf,"In this paper we introduced a simple but elegant dynamic algorithm for monotone submodular functions under a cardinality constraint. Submodular functions have plenty of applications in machine learning and combinatorial optimization and we believe researchers in both these areas would benefit from this simple algorithm. Moreover we believe that the simplicity of this algorithm has an educational impact. In particular, we think it can be used as a textbook example to explain the growing area of dynamic algorithms for undergraduate and graduate students.",Broader Impact,83,4,,,FALSE,FALSE,FALSE,Dynamic Submodular Maximization,Algorithms,Algorithms -> Clustering; Algorithms -> Dynamical Systems; Algorithms -> Stochastic Methods; Optimization -> Discrete Optimization,Theory (including computational and statistical analyses),['Morteza Monemizadeh'],{'Technical University of Eindhoven'},1,0,0,{'Netherlands'}
Inference for Batched Bandits,"Kelly Zhang, Lucas Janson, Susan Murphy",Inference for Batched Bandits,6fd86e0ad726b778e37cf270fa0247d7,https://proceedings.neurips.cc/paper/2020/file/6fd86e0ad726b778e37cf270fa0247d7-Paper.pdf,"Our work has the positive impact of encouraging the use of valid statistical inference methods on bandit data, which ultimately leads to more reliable scientific conclusions. In addition, by providing a valid statistical inference method on bandit data, our work facilitates the use of bandit algorithms in experimentation.",Broader Impact,48,2,FALSE,FALSE,FALSE,FALSE,FALSE,Inference for Batched Bandits,Algorithms -> Bandit Algorithms,Reinforcement Learning and Planning,Reinforcement learning and planning,"['Kelly W Zhang', ' Lucas Janson', ' Susan Murphy']",{'Harvard University'},1,0,0,{'USA'}
Approximate Cross-Validation with Low-Rank Data in High Dimensions,"William T. Stephenson, Madeleine Udell, Tamara Broderick",Approximate Cross-Validation with Low-Rank Data in High Dimensions,6fd9a99a5abed788d9afc9d52d54e91b,https://papers.nips.cc/paper/2020/file/6fd9a99a5abed788d9afc9d52d54e91b-Paper.pdf,"In general, we feel that work assessing the accuracy of machine learning models will have a positive impact on society. As machine learning is deployed in areas in which mistakes could have adverse effect on peoples’ lives, it is important that we understand the error rate of such decisions before deployment. On the other hand, machine learning models can (and are) used for harm and the methods in this paper may assist in the development in such models. Additionally, there is always a risk in introducing any sort of approximation, as it may fail silently and unexpectedly in practice; e.g., our approximations might incorrectly lead a practitioner to conclude that their machine learning model has very small error when the opposite is in fact true. While we believe the computable upper bounds provided her somewhat mitigate this issue, we still remain cautious (though optimistic) about applying ACV methods in practice. Finally, we note that an implicit assumption throughout our work is that computing exact CV is something we want; that is, exact CV provides a good estimate of out-of-sample error. While this seems to be generally true, this does add another failure mode to our algorithm. In particular, even if we provide an accurate approximation to exact CV, it may be that exact CV itself is misleading.",Broader Impact,217,8,,,TRUE,TRUE,TRUE,Approximate Cross-Validation with Low-Rank Data in High Dimensions,Theory -> High-Dimensional Inference,Algorithms -> Large Scale Learning; Algorithms -> Regression,,"['William Stephenson', ' Madeleine Udell', ' Tamara Broderick']","{'MIT', 'Cornell University'}",1,0,0,{'USA'}
GANSpace: Discovering Interpretable GAN Controls,"Erik Härkönen, Aaron Hertzmann, Jaakko Lehtinen, Sylvain Paris",GANSpace: Discovering Interpretable GAN Controls,6fe43269967adbb64ec6149852b5cc3e,https://proceedings.neurips.cc/paper/2020/file/6fe43269967adbb64ec6149852b5cc3e-Paper.pdf,"As our method is an image synthesis tool, it shares with other image synthesis tools the same potential benefits (e.g., [2]) and dangers that have been discussed extensively elsewhere, e.g., see [18] for one such discussion. Our method does not perform any training on images; it takes an existing GAN as input. As discussed in Section 3.2, our method inherits the biases of the input GAN, e.g., limited ability to place makeup on male-presenting faces. Conversely, this method provides a tool for discovering biases that would otherwise be hard to identify.",Broader Impact,91,4,,,FALSE,FALSE,FALSE,GANSpace: Discovering Interpretable GAN Controls,Deep Learning -> Generative Models,"Deep Learning -> Visualization, Interpretability, and Explainability",Vision,"['Erik Härkönen', ' Aaron Hertzmann', ' Jaakko Lehtinen', ' Sylvain Paris']","{'Adobe', 'Aalto University'}",1,1,1,"{'Finland', 'USA'}"
Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization,"Samuel Daulton, Maximilian Balandat, Eytan Bakshy",Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization,6fec24eac8f18ed793f5eaad3dd7977c,https://proceedings.neurips.cc/paper/2020/file/6fec24eac8f18ed793f5eaad3dd7977c-Paper.pdf,"Optimizing a single outcome commonly comes at the expense of other secondary outcomes. In some cases, decision makers may be able to form a scalarization of their objectives in advance, but in the researcher’s experience, formulating such trade-offs in advance is difficult for most. Improvements to the optimization performance and practicality of multi-objective Bayesian optimization have the potential to allow decision makers to better understand and make more informed decisions across multiple trade-offs. We expect these directions to be particularly important as Bayesian optimization is increasingly used for applications such as recommender systems [42], where auxiliary goals such as fairness must be accounted for. Of course, at the end of the day, exactly what objectives decision makers choose to optimize, and how they balance those trade-offs (and whether that is done in equitable fashion) is up to the individuals themselves.",7 Statement of Broader Impact,140,5,,,FALSE,FALSE,FALSE,Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization,Probabilistic Methods -> Gaussian Processes,Optimization -> Non-Convex Optimization,Probabilistic methods and inference,"['Samuel Daulton', ' Maximilian Balandat', ' Eytan Bakshy']",{'Facebook'},0,1,0,{'USA'}
Neuron-level Structured Pruning using Polarization Regularizer,"Tao Zhuang, Zhixuan Zhang, Yuheng Huang, Xiaoyi Zeng, Kai Shuang, Xiang Li",Neuron-level Structured Pruning using Polarization Regularizer,703957b6dd9e3a7980e040bee50ded65,https://proceedings.neurips.cc/paper/2020/file/703957b6dd9e3a7980e040bee50ded65-Paper.pdf,"This work has the following potential positive impact in the society: because our work saves the computational cost of neural network inference, we can apply it to online inference services to reduce energy consumption, which is beneficial for environmental protection. We have not noticed any obvious negative consequences of our work.",6 Broader Impact,51,2,FALSE,FALSE,FALSE,FALSE,FALSE,Neuron-level Structured Pruning using Polarization Regularizer,Deep Learning -> Efficient Inference Methods,Applications -> Computer Vision; Deep Learning; Theory -> Regularization,AutoML,"['Tao Zhuang', ' Zhixuan Zhang', ' Yuheng Huang', ' Xiaoyi Zeng', ' Kai Shuang', ' Xiang Li']","{'Alibaba Group', 'Beijing University of Posts and Telecommunications'}",1,1,1,{'China'}
Limits on Testing Structural Changes in Ising Models,"Aditya Gangrade, Bobak Nazer, Venkatesh Saligrama",Limits on Testing Structural Changes in Ising Models,70431e77d378d760c3c5456519f06efe,https://proceedings.neurips.cc/paper/2020/file/70431e77d378d760c3c5456519f06efe-Paper.pdf,"Our work is theoretical. It primarily investigates the limits of finding changes in network structure in settings that are amenable to graphical models. Secondarily, it identifies regimes in which to focus algorithmic design of tests of network structure, and gaps in the characterisation of existing algorithmic approaches to the same. As such, the immediate impact it has is only on theoretical explorations.",Broader Impact,62,4,,,TRUE,TRUE,FALSE,Limits on Testing Structural Changes in Ising Models,Theory -> Information Theory,Probabilistic Methods -> Graphical Models; Theory -> High-Dimensional Inference,Theory (including computational and statistical analyses),"['Aditya Gangrade', ' Bobak Nazer', ' Venkatesh Saligrama']",{'Boston University'},1,0,0,{'USA'}
Field-wise Learning for Multi-field Categorical Data,"Zhibin Li, Jian Zhang, Yongshun Gong, Yazhou Yao, Qiang Wu",Field-wise Learning for Multi-field Categorical Data,7078971350bcefbc6ec2779c9b84a9bd,https://proceedings.neurips.cc/paper/2020/file/7078971350bcefbc6ec2779c9b84a9bd-Paper.pdf,A broader impact discussion is not applicable as it may depend on applications.,6 Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Field-wise Learning for Multi-field Categorical Data,Algorithms -> Classification,Theory -> Computational Learning Theory; Theory -> Data-driven Algorithm Design; Theory -> Models of Learning and Generalization ; Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Zhibin Li', ' Jian Zhang', ' Yongshun Gong', ' Yazhou Yao', ' Qiang Wu']","{'University of Technology Sydney', 'UTS', 'University of Technology Sydney ', 'Nanjing University of Science and Technology'}",1,0,0,"{'Australia', 'China'}"
Continual Learning in Low-rank Orthogonal Subspaces,"Arslan Chaudhry, Naeemullah Khan, Puneet Dokania, Philip Torr",Continual Learning in Low-rank Orthogonal Subspaces,70d85f35a1fdc0ab701ff78779306407,https://proceedings.neurips.cc/paper/2020/file/70d85f35a1fdc0ab701ff78779306407-Paper.pdf,"Continual learning methods like the one we propose allow machine learning models to efficiently learn on new data without requiring constant retraining on previous data. This type of learning can be useful when the model is expected to perform in multiple environments and a simultaneous retraining on all the environments is not feasible. However, one of the core assumptions in continual learning is  that model should have zero forgetting on previous data. In some scenarios, partially forgetting old data may be acceptable or even preferable, for example if older data was more biased (in any sense) than more recent data. A machine learning practitioner should be aware of this fact and use continual learning approaches only when suitable.",7 Broader Impact,118,5,,,FALSE,FALSE,FALSE,Continual Learning in Low-rank Orthogonal Subspaces,Algorithms -> Continual Learning,Algorithms -> Multitask and Transfer Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Arslan Chaudhry', ' Naeemullah Khan', ' Puneet Dokania', ' Philip Torr']",{'University of Oxford'},1,0,0,{'UK'}
Unsupervised Learning of Visual Features by Contrasting Cluster Assignments,"Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, Armand Joulin",Unsupervised Learning of Visual Features by Contrasting Cluster Assignments,70feb62b69f16e0238f741fab228fec2,https://proceedings.neurips.cc/paper/2020/file/70feb62b69f16e0238f741fab228fec2-Paper.pdf,"This work presents a self-supervised method for learning visual representations. Self-supervised or unsupervised learning allows training models with no annotations, nor metadata. Thus, this work increases the field of possible applications of image features to domains where annotations are hard to collect. For example, removing the need for annotations benefits applications where annotations require expert knowledge, like medical imaging, or are time consuming, like fine-grained classification. This work improves unsupervised feature learning and thus many potential downstream applications that use visual features can benefit from it. We are uncertain of all the possible new applications, but each application has its own merits and societal implications depending on the intentions of the individuals using the technology. Evaluating visual representations, whether they are supervised or self-supervised, is an open research question. Typically used benchmarks can suffer from dataset or concept bias, and thus may reinforce or guide future research in that direction. To mitigate this, we evaluate our work on multiple different benchmarks and hope that future researchers also take steps in this direction.",Broader Impact,172,9,,,TRUE,TRUE,FALSE,Unsupervised Learning of Visual Features by Contrasting Cluster Assignments,Algorithms -> Unsupervised Learning,Algorithms -> Clustering; Algorithms -> Large Scale Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Mathilde Caron', ' Ishan Misra', ' Julien Mairal', ' Priya Goyal', ' Piotr Bojanowski', ' Armand Joulin']","{'Facebook', 'Facebook AI Research ', 'Facebook AI Research', 'INRIA / FAIR', 'Facebook AI research', 'Inria'}",1,1,1,"{'France', 'USA'}"
"Sharpened Generalization Bounds based on Conditional Mutual Information and an Application to Noisy, Iterative Algorithms","Mahdi Haghifam, Jeffrey Negrea, Ashish Khisti, Daniel M. Roy, Gintare Karolina Dziugaite","Sharpened Generalization Bounds based on Conditional Mutual Information and an Application to Noisy, Iterative Algorithms",712a3c9878efeae8ff06d57432016ceb,https://proceedings.neurips.cc/paper/2020/file/712a3c9878efeae8ff06d57432016ceb-Paper.pdf,"This work builds upon the community’s understanding of generalization error for machine learning methods. This has a positive impact on the scientific advancement of the field, and may lead to further improvements in our understanding, methodologies and applications of machine learning and AI. While there are not obvious direct societal implications of the present work, the indirect and longer term impact on society may be positive, negative or both depending on how, where and for what machine learning method that will have benefited from our research are used in the future.",Broader Impact,91,3,,,TRUE,TRUE,FALSE,"Sharpened Generalization Bounds based on Conditional Mutual Information and an Application to Noisy, Iterative Algorithms",Theory -> Statistical Learning Theory,Theory -> Information Theory; Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Mahdi Haghifam', ' Jeffrey Negrea', ' Ashish Khisti', ' Daniel Roy', ' Gintare Karolina Dziugaite']","{'Element AI', 'University of Toronto'}",1,1,1,{'Canada'}
Learning Deformable Tetrahedral Meshes for 3D Reconstruction,"Jun Gao, Wenzheng Chen, Tommy Xiang, Alec Jacobson, Morgan McGuire, Sanja Fidler",Learning Deformable Tetrahedral Meshes for 3D Reconstruction,7137debd45ae4d0ab9aa953017286b20,https://proceedings.neurips.cc/paper/2020/file/7137debd45ae4d0ab9aa953017286b20-Paper.pdf,"In this work, we propose and investigate a method for tetrahedral meshing of shapes. The method can be used to mesh arbitrary objects both from point clouds and images. Robust tetrahedral meshing is a longstanding problem in graphics and we showed how a new representation which is amenable to learning can achieve significant advancement in this field. There are several tetrahedral meshing methods that exist in the literature that graphics people or artists use to convert regular meshes into tetrahedral meshes. We hope our work to set the new standard in this domain. Our work targets 3D reconstruction which is a widely studied task in computer vision, robotics and machine learning. Like other work in this domain, our approach can be employed in various applications such as VR/AR, simulation and robotics. We do not anticipate ethics issues with our work.",Broader Impact,140,8,,,FALSE,FALSE,FALSE,Learning Deformable Tetrahedral Meshes for 3D Reconstruction,Applications -> Computer Vision,,Vision,"['Jun Gao', ' Wenzheng Chen', ' Tommy Xiang', ' Alec Jacobson', ' Morgan McGuire', ' Sanja Fidler']","{'NVIDIA', 'University of Toronto'}",1,1,1,"{'Canada', 'USA'}"
Information theoretic limits of learning a sparse rule,"Clément Luneau, jean barbier, Nicolas Macris",Information theoretic limits of learning a sparse rule,713fd63d76c8a57b16fc433fb4ae718a,https://proceedings.neurips.cc/paper/2020/file/713fd63d76c8a57b16fc433fb4ae718a-Paper.pdf,"We believe that it is difficult to clearly foresee societal consequence of the present, purely theoretical, work. The results presented inscribe themselves in the larger theme of providing guidelines for better and parsimonious use of data when possible, for example when learning a sparse rule. On the long run, such guidelines must be taken into account for building engineering systems that are more efficient in terms of computational and energetic cost.",Broader Impact,71,3,,,FALSE,FALSE,FALSE,Information theoretic limits of learning a sparse rule,Theory -> Statistical Physics of Learning,Algorithms -> Sparsity and Compressed Sensing; Probabilistic Methods -> Bayesian Theory; Theory -> Information Theory,Theory (including computational and statistical analyses),"['Clément Luneau', ' jean barbier', ' Nicolas Macris']","{'École Polytechnique de Lausanne', 'EPFL'}",1,0,0,{'Switzerland'}
Self-supervised learning through the eyes of a child,"Emin Orhan, Vaibhav Gupta, Brenden M. Lake",Self-supervised learning through the eyes of a child,7183145a2a3e0ce2b68cd3735186b1d5,https://proceedings.neurips.cc/paper/2020/file/7183145a2a3e0ce2b68cd3735186b1d5-Paper.pdf,"This research addresses a basic scientific question: what kind of visual representations can be learned from developmentally realistic, natural video data, using state of the art self-supervised learning methods? As such, it does not have any significant foreseeable societal consequences and, to the best of our knowledge, the results of this study do not advantage or disadvantage any particular individual  or group of individuals. The use of the SAYCam dataset was approved by our Institutional Review Board (IRB) and we followed all applicable guidelines for the use of this dataset.",Broader Impact,90,3,TRUE,FALSE,FALSE,FALSE,FALSE,Self-supervised learning through the eyes of a child,Neuroscience and Cognitive Science -> Cognitive Science,Algorithms -> Representation Learning; Algorithms -> Unsupervised Learning; Applications -> Computer Vision; Applications -> Object Recognition; Deep Learning; Neuroscience and Cognitive Science; Neuroscience and Cognitive Science -> Human or Animal Learning; Neuroscience and Cognitive Science -> Visual Perception,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Emin Orhan', ' Vaibhav Gupta', ' Brenden Lake']",{'New York University'},1,0,0,{'USA'}
Unsupervised Semantic Aggregation and Deformable Template Matching for Semi-Supervised Learning,"Tao Han, Junyu Gao, Yuan Yuan, Qi Wang",Unsupervised Semantic Aggregation and Deformable Template Matching for Semi-Supervised Learning,71a58e8cb75904f24cde464161c3e766,https://proceedings.neurips.cc/paper/2020/file/71a58e8cb75904f24cde464161c3e766-Paper.pdf,"This work has the following potential positive impacts on the computer vision community. a) It contributes to the development of semi-supervised learning in combining the unsupervised and supervised learning. b) It can provide reference significances for various tasks related to image classification. Examples include but are not limited to medical image classification, scene classification, garbage classification, etc. c)This work may inspire other domains’ research in the future. This work will not raise ethical problems for the foreseeable time.",Broader Impact,78,6,FALSE,FALSE,FALSE,FALSE,FALSE,Unsupervised Semantic Aggregation and Deformable Template Matching for Semi-Supervised Learning,Algorithms,Algorithms -> Classification; Algorithms -> Semi-Supervised Learning; Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Qi Wang', ' Tao Han', ' Junyu Gao', ' Yuan Yuan']","{'Northwestern Polytechnical University, Center for OPTical IMagery Analysis and Learning', 'Northwestern Polytechnical University'}",1,0,0,{'China'}
A game-theoretic analysis of networked system control for common-pool resource management using multi-agent reinforcement learning,"Arnu Pretorius, Scott Cameron, Elan van Biljon, Thomas Makkink, Shahil Mawjee, Jeremy du Plessis, Jonathan Shock, Alexandre Laterre, Karim Beguir",A game-theoretic analysis of networked system control for common-pool resource management using multi-agent reinforcement learning,71c1806ca28b555c76650f52bb0d2810,https://proceedings.neurips.cc/paper/2020/file/71c1806ca28b555c76650f52bb0d2810-Paper.pdf,"It could be extremely costly should a critical multi-agent system completely fail. However, in this work, we have shown that even in a very simplified environment, a seemingly working system might convergence towards equilibriums that are still inefficient or unequal. These outcomes are also clearly undesirable, yet they do not provide a clear signal for system failure. Given the complexity of MARL system operation, failure modes related to inefficiencies at equilibrium are more subtle, and more difficult to detect. We consider our work a contribution towards better understanding networked multi-agent reinforcement learning systems for common-pool resource management. As mentioned in the main text, we envision these systems becoming more widespread in their use as effective control systems for managing critical life-supporting resources. However, a specific challenge facing future systems is to have them be highly adaptable. Multi-agent reinforcement learning offers this capability, but it also makes systems far more difficult to analyse and understand. Therefore, even though we consider our environment a considerable simplification over a real institutional level CPR management system, we nevertheless hope the broader impact of our work is to demonstrate EGTA as a viable approach to analysing practical multi-agent reinforcement learning systems.",Broader Impact,196,9,,,FALSE,FALSE,FALSE,A game-theoretic analysis of networked system control for common-pool resource management using multi-agent reinforcement learning,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> Game Theory and Computational Economics,Reinforcement learning and planning,"['Arnu Pretorius', ' Scott Cameron', ' Elan van Biljon', ' Thomas Makkink', ' Shahil Mawjee', ' Jeremy du Plessis', ' Jonathan Shock', ' Alexandre Laterre', ' Karim Beguir']","{'University of Cape Town', 'InstaDeep', 'Instadeep', 'Stellenbosch University'}",1,1,1,{'South Africa'}
"What shapes feature representations? Exploring datasets, architectures, and training","Katherine Hermann, Andrew Lampinen","What shapes feature representations? Exploring datasets, architectures, and training",71e9c6620d381d60196ebe694840aaaa,https://proceedings.neurips.cc/paper/2020/file/71e9c6620d381d60196ebe694840aaaa-Paper.pdf,"Understanding the representations that models use to make their decisions is an important part of ensuring the correctness and safety of these decisions, particularly in situations where models operate on inputs different in distribution from those on which they were trained. Furthermore, many ethical concerns about machine learning models hinge on their reliance on features that encourage bias on socially discriminatory features; understanding and being able to predict which features are used is an important step in solving this problem.",Broader Impact,80,2,,,FALSE,FALSE,FALSE,"What shapes feature representations? Exploring datasets, architectures, and training",Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Multitask and Transfer Learning; Neuroscience and Cognitive Science -> Cognitive Science,Theory (including computational and statistical analyses),"['Katherine Hermann', ' Andrew Lampinen']",{'Stanford University'},1,0,0,{'USA'}
Optimal Best-arm Identification in Linear Bandits,"Yassir Jedra, Alexandre Proutiere",Optimal Best-arm Identification in Linear Bandits,7212a6567c8a6c513f33b858d868ff80,https://proceedings.neurips.cc/paper/2020/file/7212a6567c8a6c513f33b858d868ff80-Paper.pdf,"This work is mostly theoretical. Our results may provide guidelines and insights towards an improved design of algorithms for linear bandits. Linear bandit algorithms are versatile, and in particular used in clinical trials and recommendation systems. Hence our results can benefit users and developers of such systems. In clinical trials, minimizing the sample complexity is crucial, and the use of our algorithm there can be really beneficial. Our algorithm has the additional advantage of being computationally efficient. Overall, we do not foresee any direct negative impact of our work. However, it worth noting that there is some concern about the potential use of recommender systems for opinion influence.",Broader impact,108,8,,,FALSE,FALSE,FALSE,Optimal Best-arm Identification in Linear Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Active Learning; Algorithms -> Adaptive Data Analysis; Algorithms -> Online Learning; Theory -> Statistical Learning Theory,Bandit Algorithms,"['Yassir Jedra', ' Alexandre Proutiere']",{'KTH'},1,0,0,{'Sweden'}
Data Diversification: A Simple Strategy For Neural Machine Translation,"Xuan-Phi Nguyen, Shafiq Joty, Kui Wu, Ai Ti Aw",Data Diversification: A Simple Strategy For Neural Machine Translation,7221e5c8ec6b08ef6d3f9ff3ce6eb1d1,https://proceedings.neurips.cc/paper/2020/file/7221e5c8ec6b08ef6d3f9ff3ce6eb1d1-Paper.pdf,"Our work has a potential positive impact on the application of machine translation in a variety of languages. It helps boost performance in both high- and low-resource languages. The method is simple to implement and applicable to virtually all existing machine translation systems. Future commercial and humanitarian translation services can benefit from our work and bring knowledge of one language to another, especially for uncommon language speakers such as Nepalese and Sri Lankan. On the other hand, our work needs to train multiple models, which requires more computational power or longer time to train the final model.",Broader Impact,97,5,,,FALSE,FALSE,FALSE,Data Diversification: A Simple Strategy For Neural Machine Translation,Applications -> Natural Language Processing,Deep Learning -> Supervised Deep Networks,Natural language processing,"['Phi Nguyen', ' Shafiq Joty', ' Kui Wu', ' Ai Ti Aw']","{'Nanyang Technological University', 'Institute for Infocomm Research', 'Institute for Infocomm Research, Singapore'}",1,0,0,"{'Singapore', 'China'}"
Interstellar: Searching Recurrent Architecture for  	Knowledge Graph Embedding,"Yongqi Zhang, Quanming Yao, Lei  Chen",Interstellar: Searching Recurrent Architecture for Knowledge Graph Embedding,722caafb4825ef5d8670710fa29087cf,https://proceedings.neurips.cc/paper/2020/file/722caafb4825ef5d8670710fa29087cf-Paper.pdf,"Most of the attention on KG embedding learning has been focused on the triplet-based models. In this work, we emphasis the benefits and importance of using relational paths to learn from KGs. And we propose the path-interstellar as a recurrent neural architecture search problem. This is the first work applying neural architecture search (NAS) methods on KG tasks. In order to search efficiently, we propose a novel hybrid-search algorithm. This algorithm addresses the limitations of stand-alone and one-shot search methods. More importantly, the hybrid-search algorithm is not specific to the problem here. It is also possible to be applied to the other domains with more complex search space [63, 47, 42]. One limitation of this work is that, the Interstellar is currently limited on the KG embedding tasks. Extending to reasoning tasks like DRUM [38] is an interesting direction.",Broader impact,139,10,,,FALSE,FALSE,FALSE,Interstellar: Searching Recurrent Architecture for  	Knowledge Graph Embedding,Algorithms -> AutoML,Algorithms -> Relational Learning; Deep Learning -> Embedding Approaches; Deep Learning -> Recurrent Networks,,"['Yongqi Zhang', ' Quanming Yao', ' Lei Chen']","{'Hong Kong University of Science and Technology', '4Paradigm Inc.', '4paradigm'}",1,1,1,{'China'}
CoSE: Compositional Stroke Embeddings,"Emre Aksan, Thomas Deselaers, Andrea Tagliasacchi, Otmar Hilliges",CoSE: Compositional Stroke Embeddings,723e8f97fde15f7a8d5ff8d558ea3f16,https://proceedings.neurips.cc/paper/2020/file/723e8f97fde15f7a8d5ff8d558ea3f16-Paper.pdf,"On the broader societal level, this work remains largely academic in nature, and does not pose foreseeable risks regarding defense, security, and other sensitive fields. One potential risk associated with all generative modelling work, is the danger of creating digital content that can be used for malicious purposes. In the context of stroke-based data the forgery of handwriting and signatures in particular is the most immediate concern. However, an attacker would require sufficient training data and extrapolation from such data would remain challenging. Furthermore, automating tasks that are commonly associated with creativity or craftsmanship holds some danger of rendering jobs or entire occupations redundant. However, we do believe that the positive impact of this work, which is to build technology that allows for better interaction between humans and computers by enabling for a more immediate and natural way to create structured drawings, will have a larger positive impact, such as improved creativity and better communication channels between humans.",Broader Impact,158,6,FALSE,FALSE,FALSE,FALSE,FALSE,CoSE: Compositional Stroke Embeddings,Deep Learning -> Generative Models,Algorithms -> Representation Learning; Applications -> Computer Vision; Deep Learning -> Deep Autoencoders; Deep Learning -> Embedding Approaches; Deep Learning -> Predictive Models,Deep learning,"['Emre Aksan', ' Thomas Deselaers', ' Andrea Tagliasacchi', ' Otmar Hilliges']","{'ETH Zurich', 'Apple', 'Google Research, Brain'}",1,1,1,"{'USA', 'Switzerland'}"
Learning Multi-Agent Coordination for Enhancing Target Coverage in Directional Sensor Networks,"Jing Xu, Fangwei Zhong, Yizhou Wang",Learning Multi-Agent Coordination for Enhancing Target Coverage in Directional Sensor Networks,7250eb93b3c18cc9daa29cf58af7a004,https://proceedings.neurips.cc/paper/2020/file/7250eb93b3c18cc9daa29cf58af7a004-Paper.pdf,"The target coverage problem is common in Directional Sensor Networks. This problem widely exists in a lot of real-world applications. For example, those who control the cameras to capture the sports match videos may benefit from our work, because our framework provides an automatic control solution to free them from heavy and redundancy labor. Surveillance camera networks may also benefit from this research. But there is also the risk of being misused in the military field, e.g., using directional radar to monitor missiles or aircraft. The framework may also inspire the RL community, for solving the target-oriented tasks, e.g. collaborative navigation, Predator-prey. If our method fails, the targets would be all out of views of sensors. So, maybe a rule-based alternate plan is needed for unexpected conditions. We reset the training environment randomly to leverage biases in the data for better generalization.",Broader Impact,142,9,,,FALSE,FALSE,FALSE,Learning Multi-Agent Coordination for Enhancing Target Coverage in Directional Sensor Networks,Applications,Reinforcement Learning and Planning -> Hierarchical RL; Reinforcement Learning and Planning -> Multi-Agent RL,"Other applications (e.g., robotics, biology, climate, finance)","['Jing Xu', ' Fangwei Zhong', ' Yizhou Wang']",{'Peking University'},1,0,0,{'China'}
Biological credit assignment through dynamic inversion of feedforward networks,"William Podlaski, Christian K. Machens",Biological Credit Assignment through Dynamic Inversion of Feedforward Networks,7261925973c9bf0a74d85ae968a57e5f,https://proceedings.neurips.cc/paper/2020/file/7261925973c9bf0a74d85ae968a57e5f-Paper.pdf,"The broader impacts of this work can be divided into two parts. First, there is the impact of the dynamic inversion algorithm on applications in machine learning and biological learning. Due to the costly nature of simulating such an inversion, we do not foresee its widespread use in training large- scale deep networks for applications. However, this study could have an impact on our understanding of learning in the brain at a very basic level, one day leading to implications for neurological disease, and also more neuroscience-related applications such as brain-machine interfaces. We foresee such results in the neuroscience and medical fields as primarily beneficial — any new insights into how the brain learns have the possibility to help those with disabilities or disorders. Second, there is the broader impact of dynamic inversion as a general algorithm for inverting computations. Due to the widespread use of inverse computations in many domains and applications, it may be the case that the insights provided in this paper have an effect. For example, the development of better inverse models in robots could lead to substantial improvement for robotic applications, which would have a tremendous effect on society, likely both for better and worse. Overall, however, the work presented here is at the “basic research” level, and very far removed from specific applications.",Broader Impact,219,9,,,FALSE,FALSE,FALSE,Biological credit assignment through dynamic inversion of feedforward networks,Neuroscience and Cognitive Science,Deep Learning -> Biologically Plausible Deep Networks; Deep Learning -> Optimization for Deep Networks; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Plasticity and Adaptation,Neuroscience and cognitive science,"['William Podlaski', ' Machens']",{'Champalimaud Research'},1,0,0,{'Portugal'}
Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching,"Di Hu, Rui Qian, Minyue Jiang, Xiao Tan, Shilei Wen, Errui Ding, Weiyao Lin, Dejing Dou",Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching,7288251b27c8f0e73f4d7f483b06a785,https://proceedings.neurips.cc/paper/2020/file/7288251b27c8f0e73f4d7f483b06a785-Paper.pdf,"Visually sound source localization is a kind of basic perception ability for human, while this work encourages the machine to be equipped with similar ability, especially when faced with multi-source scenarios. Hence, the impact mainly lies in the machine learning technique and application aspect. On the one hand, the proposed approach is fully based on self-supervised learning, but can reward considerable discrimination ability for the visual objects and correlation capabilities across audio and visual modalities. Predictably, without elaborately manual annotation, this approach could still facilitate the progress of unimodal and multimodal learning and parse/model complex scene. On the other hand, it steps forward to pursuing human-like multimodal perception ability, which could further contribute to our society in several aspects, e.g., audio-assistant scene understanding for the deaf people by figuring out which objects are making sound, facilitating exploration into how to solve the cocktail-party effect in realistic audiovisual scenes, i.e., to perceive different sounds and focus on the pertinent content from mixed auditory input.",Broader Impact,163,5,,,FALSE,FALSE,FALSE,Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching,Applications -> Visual Scene Analysis and Interpretation,Algorithms -> Multimodal Learning; Applications -> Activity and Event Recognition; Applications -> Computer Vision; Applications -> Video Analysis,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,"{'BAIDU', 'Shanghai Jiao Tong university', 'Renmin University of China', 'Baidu', 'Shanghai Jiao Tong University'}",1,1,1,{'China'}
Learning Multi-Agent Communication through Structured Attentive Reasoning,"Murtaza Rangwala, Ryan Williams",Learning Multi-Agent Communication through Structured Attentive Reasoning,72ab54f9b8c11fae5b923d7f854ef06a,https://proceedings.neurips.cc/paper/2020/file/72ab54f9b8c11fae5b923d7f854ef06a-Paper.pdf,"Multi-agent communication and cooperation is an active area of research that presents extreme challenges for agents to learn efficiently and in a scalable manner. Our work hopes to introduce a step towards learning sophisticated coordination strategies and behaviors in multi-agent learning and cooperation. Robotics has always been a natural application area for multi-agent learning. Communication in multi-agent research has varied applications, from the field of telecommunications, security and surveillance, to in fact bidding agents for Google Adwords [28]. Applications for deep reinforcement learning, especially in multi-robot systems, are still constrained due to the large sample complexity, and more importantly, coordination and cooperation are still left unsolved for larger tasks. Our work strives to achieve a robustness towards different learning mechanisms and tasks, while still learning to cooperate and communicate.",Broader Impact,129,6,,,FALSE,FALSE,FALSE,Learning Multi-Agent Communication through Structured Attentive Reasoning,Reinforcement Learning and Planning -> Multi-Agent RL,Applications -> Dialog- or Communication-Based Learning; Deep Learning -> Attention Models; Deep Learning -> Memory-Augmented Neural Networks; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Murtaza Rangwala', ' Ryan K Williams']",{'Virginia Tech'},1,0,0,{'USA'}
Private Identity Testing for High-Dimensional Distributions,"Clément L. Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman, Lydia Zakynthinou",Private Identity Testing for High-Dimensional Distributions,72b32a1f754ba1c09b3695e0cb6cde7f,https://proceedings.neurips.cc/paper/2020/file/72b32a1f754ba1c09b3695e0cb6cde7f-Paper.pdf,"This work focuses on privacy-preserving statistics: the task of performing statistical learning while maintaining the privacy of data participants. The right to privacy is a fundamental right, and works in this area allow for the facilitation of valuable social science and economic research, while preserving this fundamental right. There are many examples where releases of statistical data, even aggregate statistics, without formal privacy guarantees has resulted in blatant privacy violations. For example, Homer et al. [45] demonstrated that it is possible to identify individuals who participated in a GWAS study based on certain released test statistics.This can be especially harmful when resolving individuals who participated in trials pertaining to a socially stigmatized disease (e.g., HIV/AIDS). This finding was considered so significant that the NIH immediately revoked open access to a number of statistical results from medical trials, including χ 2 -statistics and p values. Hypothesis tests are applied to sensitive data in a myriad of studies, e.g. on voting behavior [44] or attitude toward abortion [34], highlighting urgent need for hypothesis tests which respect the privacy of participant data. Some specific applications of goodness-of-fit testing are [12, 39, 40]. The study of uniformity testing of product distributions is also equivalent to the well-motivated question of mean testing of categorical data, which has applications to high-dimensional statistical analysis. Further, uniformity testing is also deeply related to mean testing of high-dimensional normal distributions, as exemplified by our reduction from the latter to the former. Non-DP mean testing in high-dimensional settings itself has a long history in statistical hypothesis testing; see for example, [29]. Our objective is to initiate the study of high-dimensional hypothesis testing under privacy constraints. Although we do not close the chapter on identity testing, we believe our results to be an important, non-trivial, and natural first step, and a prerequisite to any further investigation (e.g., general identity testing for non-spherical Gaussians, graphical models, or sub-Gaussian distributions). Our work exposes and addresses a number of core challenges that arise in private high-dimensional data analysis. Indeed, the problems we study capture a challenge that is widespread in differential privacy: that solving high dimensional testing problems privately is difficult because the known non-private testers have high global sensitivity. We propose a novel way of dealing with this issue by reducing to the “typical sensitivity.” We demonstrate the effectiveness of this technique on identity testing, but we conjecture that it will find applications to other testing problems and beyond.",Broader Impact,406,16,,,FALSE,FALSE,FALSE,Private Identity Testing for High-Dimensional Distributions,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Theory -> Statistical Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Clement Canonne', ' Gautam Kamath', ' Audra McMillan', ' Jonathan Ullman', ' Lydia Zakynthinou']","{'University of Waterloo', 'Stanford', 'Northeastern University', 'Northeastern/Boston University'}",1,0,0,"{'Canada', 'USA'}"
On the Optimal Weighted ℓ2ℓ2 Regularization in Overparameterized Linear Regression,"Denny Wu, Ji Xu",On the Optimal Weighted 2 Regularization in Overparameterized Linear Regression,72e6d3238361fe70f22fb0ac624a7072,https://proceedings.neurips.cc/paper/2020/file/72e6d3238361fe70f22fb0ac624a7072-Paper.pdf,This work does not present any foreseeable direct societal consequence.,8 Broader Impact,10,1,TRUE,FALSE,FALSE,FALSE,FALSE,On the Optimal Weighted $\ell_2$ Regularization in Overparameterized Linear Regression,Algorithms -> Regression,Theory -> High-Dimensional Inference; Theory -> Regularization,Theory (including computational and statistical analyses),"['Denny Wu', ' Ji Xu']","{'Columbia University', 'University of Toronto & Vector Institute'}",1,0,0,"{'Canada', 'USA'}"
An Efficient Asynchronous Method for Integrating Evolutionary and Gradient-based Policy Search,"Kyunghyun Lee, Byeong-Uk Lee, Ukcheol Shin, In So Kweon",An Efficient Asynchronous Method for Integrating Evolutionary and Gradient-based Policy Search,731309c4bb223491a9f67eac5214fb2e,https://proceedings.neurips.cc/paper/2020/file/731309c4bb223491a9f67eac5214fb2e-Paper.pdf,"To apply RL in the real world problem, efficiency and stability are essential, because the cost of interacting with the environment is much higher than the simulation. Evolutionary Reinforcement Learning is an attempt to combine ES and RL for efficiency and stability. However, the previous works used synchronous evolutionary algorithms that cannot be scaled up. This paper focuses on the asynchronous combination method of RL and ES. We introduce several efficient update rules for applying asynchronism and analyze the performance. We confirm that the asynchronous methods are much more time efficient, and it also have more exploration property for searching effective policy. With the proposed algorithm, AES-RL, branch of stable and efficient policy search algorithms can be extended to numerous workers. We expect the policy search algorithms to be actively applied to real world problems.",Broader Impact,135,8,,,FALSE,FALSE,FALSE,An Efficient Asynchronous Method for Integrating Evolutionary and Gradient-based Policy Search,Optimization -> Evolutionary Computation,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Kyunghyun Lee', 'Uk Lee', ' Ukcheol Shin', ' In So Kweon']",{'KAIST'},1,0,0,{'South Korea'}
MetaSDF: Meta-Learning Signed Distance Functions,"Vincent Sitzmann, Eric Chan, Richard Tucker, Noah Snavely, Gordon Wetzstein",MetaSDF: Meta-learning Signed Distance Functions,731c83db8d2ff01bdc000083fd3c3740,https://proceedings.neurips.cc/paper/2020/file/731c83db8d2ff01bdc000083fd3c3740-Paper.pdf,"Emerging neural implicit representations are a powerful tool for representing signals, such as 3D shape and appearance. Generalizing across these neural implicit representations requires efficient approaches to learning distributions over functions. We have shown that gradient-based meta-learning approaches are one promising avenue to tackling this problem. As a result, the proposed approach may be part of the backbone of this emerging neural signal representation strategy. As a powerful representation of natural signals, such neural implicits may in the future be used for the generation and manipulation of signals, which may pose challenges similar to those posed by generative adversarial models today.",Broader Impact,101,5,,,FALSE,FALSE,FALSE,MetaSDF: Meta-Learning Signed Distance Functions,Applications -> Computer Vision,Algorithms -> Meta-Learning; Deep Learning,Deep learning,"['Vincent Sitzmann', ' Eric Chan', ' Richard Tucker', ' Noah Snavely', ' Gordon Wetzstein']","{'Google', 'Stanford University', 'Cornell University and Google AI'}",1,1,1,{'USA'}
Simple and Scalable Sparse k-means Clustering via Feature Ranking,"Zhiyue Zhang, Kenneth Lange, Jason Xu",Simple and Scalable Sparse k -means Clustering via Feature Ranking,735ddec196a9ca5745c05bec0eaa4bf9,https://proceedings.neurips.cc/paper/2020/file/735ddec196a9ca5745c05bec0eaa4bf9-Paper.pdf,"Our work contributes theoretically and computationally to unsupervised learning and feature selection. Because we simply provide a more scalable and transparent algorithm for addressing a classical task,  our work brings no immediate ethical or societal concerns. Since our work focuses on improving clustering accuracy and preserving the interpretability and identifiability of features during and after the clustering process, it can help to reduce spurious conclusions drawn from off-the-shelf methods that either lack interpretability or are more likely to produce poor solutions. Indeed, as many scientific problems with societal impacts such as discovering gene associations for rare diseases or risk factors in precision medicine can be partially addressed through the lens of unsupervised learning, our work can positively impact these areas with wide implications. While our method does not leverage any bias in data in any way, misinterpreting or having too much confidence in solutions produced by our method on highly noisy, biased, or imbalanced data can potentially yield to inaccurate interpretations. We advise all users to understand the assumptions behind our method and the limitations of unsupervised learning, especially in challenging high-dimensional settings, when basing decisions off of the results of any machine learning approach such as that we propose here.",Broader Impact,201,6,,,FALSE,FALSE,FALSE,Simple and Scalable Sparse k-means Clustering via Feature Ranking,Algorithms -> Clustering,Algorithms -> Missing Data; Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization,,,"{'UCLA', 'Duke University'}",1,0,0,{'USA'}
Model-based Adversarial Meta-Reinforcement Learning,"Zichuan Lin, Garrett Thomas, Guangwen Yang, Tengyu Ma",Model-based Adversarial Meta-Reinforcement Learning,73634c1dcbe056c1f7dcf5969da406c8,https://proceedings.neurips.cc/paper/2020/file/73634c1dcbe056c1f7dcf5969da406c8-Paper.pdf,"Meta-reinforcement learning has potential positive impact in real-life applications such as robotics. For example, in robotic assembly tasks, it is expensive and time-consuming to have engineers hand-produce controllers for each new configuration of parts; meta-RL allows for rapid development of controllers for new tasks, efficiently enabling greater variation and customizability in the manufacturing process. Our method makes meta-RL more practical in several ways: 1. By vastly improving the sample efficiency of meta-training compared to previous approaches, we lower the barrier to entry. 2. Directly optimizing worst-case performance reduces the chance of a catastrophic failure. 3. Zero-shot adaptation already produces a fairly strong policy, thereby improving safety in settings where an untrained policy is prone to cause damage. On the other hand, there are potential risks as well. Increased automation can reduce the demand for labor in certain industries, thereby impacting job availability.",Broader Impact,142,10,,,TRUE,TRUE,FALSE,Model-based Adversarial Meta-Reinforcement Learning,Reinforcement Learning and Planning,Algorithms -> Meta-Learning; Reinforcement Learning and Planning -> Model-Based RL,Reinforcement learning and planning,"['Zichuan Lin', ' Thomas', ' Guangwen Yang', ' Tengyu Ma']","{'Stanford University', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Graph Policy Network for Transferable Active Learning on Graphs,"Shengding Hu, Zheng Xiong, Meng Qu, Xingdi Yuan, Marc-Alexandre Côté, Zhiyuan Liu, Jian Tang",Graph Policy Network for Transferable Active Learning on Graphs,73740ea85c4ec25f00f9acbd859f861d,https://proceedings.neurips.cc/paper/2020/file/73740ea85c4ec25f00f9acbd859f861d-Paper.pdf,"Graph-structured data are ubiquitous in real world, covering a variety of domains and applications such as social science, biology, medicine, and political science. In many domains such as biology and medicine, annotating a large number of labeled data could be extremely expensive and time consuming. Therefore, the algorithm proposed in this paper could help significantly reduce the labeling efforts in these domains — we can train systems on domains where labeled data are available, then transfer to those lower-resource domains. We believe such systems can help accelerating some research and develop processes that usually take a long time, in domains such as drug development. It can potentially also lower the cost for such research by reducing the need of expert-annotations. However, we also acknowledge potential social and ethical issues related to our work. 1. Our proposed system can effectively reduce the need of human annotations. However, in a broader point of view, this can potentially lead to a reduction of employment opportunities which may cause layoff to data annotators. 2. GNNs are widely used in domains related to critical needs such as healthcare and drug development. The community needs to be extra cautious and rigorous since any mistake may cause harm to patients. 3. Training the policy network for active learning on multiple graphs is relatively time - and computational resource - consuming. This line of research may produce more carbon footprint compared to some other work. Therefore, how to accelerate the training process by developing more efficient algorithms requires further investigation. Nonetheless, we believe that the directions of active learning and transfer learning provide a hopeful path towards our ultimate goal of data efficiency and interpretable machine learning.",Broader Impact,279,17,,,TRUE,TRUE,FALSE,Graph Policy Network for Transferable Active Learning on Graphs,Applications -> Network Analysis,Algorithms -> Active Learning; Reinforcement Learning and Planning -> Markov Decision Processes,,"['Shengding Hu', ' Zheng Xiong', ' Meng Qu', ' Xingdi Yuan', 'Alexandre Côté', ' Zhiyuan Liu', ' Jian Tang']","{'Microsoft Research', 'Tsinghua University', 'University of Oxford', 'Mila'}",1,1,1,"{'Canada', 'UK', 'USA', 'China'}"
Towards a Better Global Loss Landscape of GANs,"Ruoyu Sun, Tiantian Fang, Alexander Schwing",Towards a Better Global Loss Landscape of GANs,738a6457be8432bab553e21b4235dd97,https://proceedings.neurips.cc/paper/2020/file/738a6457be8432bab553e21b4235dd97-Paper.pdf,"Generative adversarial nets (GANs) are an important tool for modeling of high-dimensional distri- butions. However, the theoretical understanding of GANs is still limited. While recent work has investigated GANs form a statistical and an optimization viewpoint, little is known about their global landscape. This paper is a first step to add theory about the global landscape of GANs. We think this research will have a societal impact as it enables practitioners to make a more informed decision about the type of loss function that should be optimized. For example, we show that RS-GAN has benefits: (1) fewer bad basins, permitting a more stable optimization; (2) better results for narrow deep net generators, permitting its use on smaller devices, and promoting the development of smart devices and smart home services; (3) better performance on high-resolution image generation, which can be helpful in the fashion, animation, film and television industries. Since we are focusing on the optimization of GANs, we do not think that this research has any ethical disadvantages beyond those of GANs. Illegal fake images or videos may be the main concern related to GAN. We hope that the research community finds these results interesting and that people will join our effort in uncovering more theory for GANs.",Broader Impact,208,9,,,FALSE,FALSE,FALSE,Towards a Better Global Loss Landscape of GANs,Optimization -> Non-Convex Optimization,Deep Learning -> Generative Models,Theory (including computational and statistical analyses),,"{'University of Illinois at Urbana-Champaign', 'University of Illinois Urbana-Champaign'}",1,0,0,{'USA'}
Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,"Tabish Rashid, Gregory Farquhar, Bei Peng, Shimon Whiteson",Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,73a427badebe0e32caa2e1fc7530b7f3,https://proceedings.neurips.cc/paper/2020/file/73a427badebe0e32caa2e1fc7530b7f3-Paper.pdf,"Due to the broad applicability of cooperative Multi-Agent Reinforcement Learning, we limit our discussion to the cooperative setting in which agents must act independently without communication. One such potential application is in self-driving cars, in which the agents should be able to make safe and sensible decisions even without access to a communication network. Due to the sample inefficiency of current RL methods, combined with their lack of safe exploration it is also necessary to first train agents in a simulated setting before even beginning to train in the real world. Hence, the class of algorithms we consider in this paper could be used to train agents in these scenarios and would likely be chosen over fully-decentralised options. It is important then to obtain a better understanding of the current approaches, in particular of their limitations. In this paper, we focus primarily on the limitations of QMIX due to its strong performance [26]. We also investigate the links between QTRAN and our algorithm and observe poor empirical performance for Actor-Critic style approaches. Investigating all of these further should improve the performance of all algorithms in this domain, and provide a better understanding of their relative strengths and weaknesses. One particular limitation of QMIX is that it can fail in environments in which an agent’s best action is dependent on the actions the other agents take, i.e., in environments in which agents must coordinate at the same timestep. However, in a Multi-Agent setting it is often crucial to coordinate with the other agents. Our approach lifts this restriction, and is theoretically able to learn the optimal policy in any environment which greatly increases its applicability. Extending the capabilities of cooperative MARL algorithms should further extend the applicability of these algorithms in a broader range of applications. However, our approach introduces extra complexity and can perform poorly in certain challenging domains. It is important then to consider whether the extra modelling capacity of our method is required to achieve good performance on a selected task.",Broader Impact,333,14,,,FALSE,FALSE,FALSE,Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,,{'University of Oxford'},1,0,0,{'UK'}
BanditPAM: Almost Linear Time k-Medoids Clustering via Multi-Armed Bandits,"Mo Tiwari, Martin J. Zhang, James Mayclin, Sebastian Thrun, Chris Piech, Ilan Shomorony",BanditPAM: Almost Linear Time k -Medoids Clustering via Multi-Armed Bandits,73b817090081cef1bca77232f4532c5d,https://proceedings.neurips.cc/paper/2020/file/73b817090081cef1bca77232f4532c5d-Paper.pdf,"BanditPAM accelerates finding solutions to the k -medoids problem while producing comparable – and usually equivalent – final cluster assignments. Our work enables the discovery of high-quality medoid assignments in very large datasets, including some on which prior algorithms were prohibitively expensive. A potential negative consequence of this is that practitioners may be incentivized to gather and store larger amounts of data now that it can be meaningfully processed, in a phenomenon more generally described as induced demand [14]. This incentive realignment could potentially result in negative externalities such as an increase in energy consumption and carbon footprints. Our application to the HOC4 dataset suggests a method for scaling personalized feedback to individual students in online courses. If limited resources are available, instructors can choose to provide feedback on just the medoids of submitted solutions instead of exhaustively providing feedback on every unique solution, of which there may be several thousand. Instructors can then refer individual students to the feedback provided for their closest medoid. We anticipate that this approach can be applied generally for students of Massive Open Online Courses (MOOCs), thereby enabling more equitable access to education and personalized feedback for students. We also anticipate, however, that BanditPAM will enable several beneficial applications in other fields such as biomedicine and and fairness. For example, the evolutionary pathways of infectious diseases could possibly be constructed from the medoids of genetic sequences available at a given point in time, if prior temporal information about these sequences’ histories is not available. Similarly, the medoids of patients infected in a disease outbreak may elucidate the origins of outbreaks, as did prior analyses of cholera outbreaks using Voronoi Iteration [8]. As discussed in Section 6, our application to the HOC4 data also demonstrates the utility of BanditPAM in online education. In particular, especially with recent interest in online learning, we hope that our work will improve the quality of online learning for students worldwide.",Broader Impact,321,13,,,FALSE,FALSE,FALSE,BanditPAM: Almost Linear Time k-Medoids Clustering via Multi-Armed Bandits,Algorithms -> Clustering,Algorithms -> Bandit Algorithms; Algorithms -> Unsupervised Learning; Applications -> Computational Biology and Bioinformatics,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Mo Tiwari', ' Martin Zhang', ' James J Mayclin', ' Sebastian Thrun', ' Chris Piech', ' Ilan Shomorony']","{'Stanford', 'University of Illinois at Urbana Champaign', 'Stanford University', 'Harvard University'}",1,0,0,{'USA'}
"UDH: Universal Deep Hiding for Steganography, Watermarking, and Light Field Messaging","Chaoning Zhang, Philipp Benz, Adil Karjauv, Geng Sun, In Kweon","UDH: Universal Deep Hiding for Steganography, Watermarking, and Light Field Messaging",73d02e4344f71a0b0d51a925246990e7,https://proceedings.neurips.cc/paper/2020/file/73d02e4344f71a0b0d51a925246990e7-Paper.pdf,"Information hiding is commonly used in an nefarious context, such as criminals secretly coordinating plans through messages hidden in images on public websites. However, we investigate the potential of deep hiding for beneficial applications. By comparing the existing DDH and the proposed UDH on various aspects, we provide an intuition behind the mechanisms of DNN-based deep hiding. With this understanding, we further push the simple use case of hiding one image in another to a more general case of hiding M in N images. Meanwhile, we demonstrate the possibility that different recipients can retrieve different secret images through the same container image, which can be used to provide different content to different users based on their practical needs. Intellectual property has become a major concern with the exponentially increasing number of images and videos. The proposed UDH constitutes a timely solution for addressing this issue with the concept of “universal watermarking”. Finally, we show that UDH can be used for light field messaging. Different from prior works that only hide simple binary information, our work demonstrates the possibility of hiding a full image, which can greatly expand its use cases. For example, museums and exhibitions, can adopt light field messaging to provide a more informative and vivid experience for visitors.",7 Broader impact,210,10,,,FALSE,FALSE,FALSE,"UDH: Universal Deep Hiding for Steganography, Watermarking, and Light Field Messaging","Deep Learning -> Visualization, Interpretability, and Explainability",,Deep learning,,{'KAIST'},1,0,0,{'South Korea'}
Evidential Sparsification of Multimodal Latent Spaces in Conditional Variational Autoencoders,"Masha Itkina, Boris Ivanovic, Ransalu Senanayake, Mykel J. Kochenderfer, Marco Pavone",Evidential Sparsification of Multimodal Latent Spaces in Conditional Variational Autoencoders,73f95ee473881dea4afd89c06165fa66,https://proceedings.neurips.cc/paper/2020/file/73f95ee473881dea4afd89c06165fa66-Paper.pdf,"Our work focuses on sparsifying the latent space of a conditional variational autoencoder (CVAE). We consider the tasks of image generation and pedestrian trajectory prediction for empirical evaluation. We intend our work to be applicable in the domain of robotics. For instance, our method has the potential to improve tractability of motion planning in a latent representation of the robot’s dynamics and to decrease the amount of information required to be transmitted between coordinating robots. However, our work is also more broadly applicable to any domain that would benefit from sparsifying the discrete latent distribution of a pre-trained CVAE. As such, in the process of sparsification, any inherent bias in the pre-trained network may be amplified, causing potential ethical concerns. Also, although we extensively validate our work empirically, we do not provide theoretical safety guarantees for the removed latent classes, requiring sufficient safety testing for any downstream task. We hope that our contribution will enable future positive research outcomes within the fields of robotics, generative modeling, and evidential theory.",Broader Impact,169,8,,,FALSE,FALSE,FALSE,Evidential Sparsification of Multimodal Latent Spaces in Conditional Variational Autoencoders,Probabilistic Methods -> Latent Variable Models,Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models,Vision,"['Masha Itkina', ' Boris Ivanovic', ' Ransalu Senanayake', ' Mykel J Kochenderfer', ' Marco Pavone']",{'Stanford University'},1,0,0,{'USA'}
An Unbiased Risk Estimator for Learning with Augmented Classes,"Yu-Jie Zhang, Peng Zhao, Lanjihong Ma, Zhi-Hua Zhou",An Unbiased Risk Estimator for Learning with Augmented Classes,747c1bcceb6109a4ef936bc70cfe67de,https://proceedings.neurips.cc/paper/2020/file/747c1bcceb6109a4ef936bc70cfe67de-Paper.pdf,"In this paper, we develop the E ULAC , an approach exploiting unlabeled data for learning with augmented classes. The augmented classes appear in many applications, such as unobserved animals appear in species recognition task [1] and unexpected background images exist in object detection [12]. Our approach offers a way to improve the robustness of the learning system for these applications by identifying the unseen augmented classes more accurately. Nevertheless, we also admit it would raise concerns when applying these techniques to some malicious applications. For example, one could employ ML systems to detect rare animals, resulting in an increased probability of rare animals being hunted and thus making the animals even more dangerous. Therefore, we should call for laws and regulations to limits the use of ML techniques in such applications. On the other hand, it is also crucial to facilitate learning systems with the capability of tackling the augmented classes. Many applications require such robustness and will benefit from our techniques, and the potential risk is believed to be manageable with more sound human regulations.",Broader Impact,177,8,,,FALSE,FALSE,FALSE,An Unbiased Risk Estimator for Learning with Augmented Classes,Algorithms -> Classification,Algorithms -> Semi-Supervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jie Zhang', ' Peng Zhao', ' Lanjihong Ma', 'Hua Zhou']",{'Nanjing University'},1,0,0,{'China'}
AutoBSS: An Efficient Algorithm for Block Stacking Style Search,"yikang zhang, Jian Zhang, Zhao Zhong",AutoBSS: An Efficient Algorithm for Block Stacking Style Search,747d3443e319a22747fbb873e8b2f9f2,https://proceedings.neurips.cc/paper/2020/file/747d3443e319a22747fbb873e8b2f9f2-Paper.pdf,"The main goal of this work is to investigate the impact of Block Stacking Style (BSS) and design an efficient algorithm to search it automatically. As shown in our experiments, the BSS configuration of current popular networks is not the optimal solution. Our methods can give a better understanding of the neural network design and exploit their capabilities. For the community, one potential positive impact of our work would be that we should not only focus on new convolutional operator or topological structure but also BSS of the Network. In addition, our work indicates that AutoML algorithm with unbiased evaluation has a strong potential for future research. For the negative aspects, our experiments on model compression may suggest that pruning based methods have less potential than tuning the BSS of a network.",Broader Impact,132,6,,,FALSE,FALSE,FALSE,AutoBSS: An Efficient Algorithm for Block Stacking Style Search,Algorithms -> AutoML,Applications -> Computer Vision; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> CNN Architectures,AutoML,"['yikang zhang', ' Jian Zhang', ' Zhao Zhong']",{'HUAWEI'},0,1,0,{'China'}
Pushing the Limits of Narrow Precision Inferencing at Cloud Scale with Microsoft Floating Point,"Bita Darvish Rouhani, Daniel Lo, Ritchie Zhao, Ming Liu, Jeremy Fowers, Kalin Ovtcharov , Anna Vinogradsky, Sarah Massengill , Lita Yang, Ray Bittner, Alessandro Forin, Haishan Zhu, Taesik Na, Prerak Patel, Shuai Che, Lok Chand Koppaka , XIA SONG, Subhojit  Som, Kaustav  Das, Saurabh T, Steve Reinhardt , Sitaram Lanka, Eric Chung, Doug Burger",Pushing the Limits of Narrow Precision Inferencing at Cloud Scale with Microsoft Floating Point,747e32ab0fea7fbd2ad9ec03daa3f840,https://proceedings.neurips.cc/paper/2020/file/747e32ab0fea7fbd2ad9ec03daa3f840-Paper.pdf,"This paper opens a new axis for the growing research in quantized DNN inference. It challenges the current practice in the field regarding the choice of numerical format and sheds light on the importance of a holistic co-design of hardware architecture and algorithms. This paper further highlights the importance of generalization in designing next generation standard quantization techniques to minimize the non-recurring engineering cost and ensure ease-of-use across various classes of models. Large-scale cost-efficient inference over DNNs enables an ever-increasing number of AI applications in consumer and enterprise products. MSFP enables inferencing on larger and more powerful DNN models in scenarios that require very high rates of inference such as web search, enterprise search, and email search. Other scenarios such as real-time recommendations, AI-powered text auto-completion (e.g. auto-suggestion, smart compose), and conversational interfaces also require high inference rates and benefit from inferencing with MSFP format.",7 Broader impact,145,6,,,FALSE,FALSE,FALSE,Pushing the Limits of Narrow Precision Inferencing at Cloud Scale with Microsoft Floating Point,Deep Learning -> Efficient Inference Methods,Deep Learning -> Analysis and Understanding of Deep Networks,Hardware acceleration for DNNs,"['Bita Darvish Rouhani', ' Daniel Lo', ' Ritchie Zhao', ' Ming Liu', ' Jeremy Fowers', ' Kalin Ovtcharov', ' Anna Vinogradsky', ' Sarah Massengill', ' Lita Yang', ' Ray Bittner', ' Alessandro Forin', ' Haishan Zhu', ' Taesik Na', ' Prerak Patel', ' Shuai Che', ' Lok Chand Koppaka', ' Steve Reinhardt', ' Sitaram Lanka', ' XIA SONG', ' Subhojit Som', ' Kaustav Das', ' Saurabh K T', ' Eric Chung', ' Doug Burger']","{'Caltech', 'Microsoft', 'Microsoft Research', 'Microsoft Corporation'}",1,1,1,{'USA'}
Stochastic Optimization with Laggard Data Pipelines,"Naman Agarwal, Rohan Anil, Tomer Koren, Kunal Talwar, Cyril Zhang",Stochastic Optimization with Laggard Data Pipelines,74dbd1111727a31a2b825d615d80b2e7,https://proceedings.neurips.cc/paper/2020/file/74dbd1111727a31a2b825d615d80b2e7-Paper.pdf,"This work is theoretical in nature, and is concerned with the very general framework of stochastic optimization. As such, there are no foreseen ethical or societal consequences for the research presented herein. We hope that by providing theoretical groundwork and algorithmic techniques for e cient large-scale optimization in settings informed by modern developments in optimization, works like this one will contribute to alleviating the steep resource and energy costs of large-scale machine learning.",Broader Impact,73,3,,,FALSE,FALSE,FALSE,Stochastic Optimization with Laggard Data Pipelines,Optimization,Optimization -> Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Naman Agarwal', ' Rohan Anil', ' Tomer Koren', ' Kunal Talwar', ' Cyril Zhang']","{'Google', 'Princeton University'}",1,1,1,{'USA'}
Self-supervised Auxiliary Learning with Meta-paths for Heterogeneous Graphs,"Dasol Hwang, Jinyoung Park, Sunyoung Kwon, KyungMin Kim, Jung-Woo Ha, Hyunwoo J. Kim",Self-supervised Auxiliary Learning with Meta-paths for Heterogeneous Graphs,74de5f915765ea59816e770a8e686f38,https://proceedings.neurips.cc/paper/2020/file/74de5f915765ea59816e770a8e686f38-Paper.pdf,"We thank NeurIPS2020 for this opportunity to revisit the broader impact of our work and the potential societal consequence of machine learning researches. Our work is a general learning method to benefit from auxiliary tasks. One interesting finding is that meta-path prediction can be an effective self-supervised task to learn more power representation of heterogeneous graphs. Nowadays, people use social media (e.g., Facebook, Twitter, etc.) on a daily basis. Also, people watch movies and TV-shows online and purchase products on Amazon. All this information can be represented as heterogeneous graphs. We believe that our meta-path auxiliary tasks will benefit the customers with improved services. For instance, more accurate recommender systems will save customers’ time and provide more relevant contents and products. We believe that there is no direct negative consequence of this research. We proposed how to train models with auxiliary tasks. We did not make any algorithms for specific applications. So, no one will be put at a disadvantage from our work. No direct negative consequence of a failure of the system is expected. We used four datasets Last-FM, Book-Crossing, ACM, and IMDB. They may not represent all the population on the earth but our experiments did not leverage any biases in the datasets. We believe that our method will be as effective as we reported in the paper on different datasets from different populations.",Broader Impact,226,17,,,FALSE,FALSE,FALSE,Self-supervised Auxiliary Learning with Meta-paths for Heterogeneous Graphs,Algorithms -> Representation Learning,Algorithms -> Meta-Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Dasol Hwang', ' Jinyoung Park', ' Sunyoung Kwon', ' KyungMin Kim', 'Woo Ha', ' Hyunwoo Kim']","{'Pusan National University', 'Seoul National University', 'Korea University'}",1,0,0,{'South Korea'}
GPS-Net: Graph-based Photometric Stereo Network,"Zhuokun Yao, Kun Li, Ying Fu, Haofeng Hu, Boxin Shi",GPS-Net: Graph-based Photometric Stereo Network,7503cfacd12053d309b6bed5c89de212,https://proceedings.neurips.cc/paper/2020/file/7503cfacd12053d309b6bed5c89de212-Paper.pdf,"The proposed framework will promote the development of photometric stereo technology, which can be useful for applications requiring 3D models with fine details (such as movie, game and other entertainment industries or industrial inspection). With the advancement of this technology, people may conveniently recover high-resolution and high-accuracy 3D information from images through specialist devices and efficient algorithms. However, the efficient acquisition of high-quality 3D models (such as faces) may cause severer privacy violation problems than 2D images. We suggest that policymakers should establish an efficient monitoring platform to regulate the illegal spread of 3D models with private information that may cause ethical problems.",Broader Impact,103,4,,,FALSE,FALSE,FALSE,GPS-Net: Graph-based Photometric Stereo Network,Applications -> Computational Photography,Applications -> Computer Vision,Vision,"['Zhuokun Yao', ' Kun Li', ' Ying Fu', ' Haofeng Hu', ' Boxin Shi']","{'Peking University', 'Tianjin University', 'Beijing Institute of Technology'}",1,0,0,{'China'}
Consistent Structural Relation Learning for Zero-Shot Segmentation,"Peike Li, Yunchao Wei, Yi Yang",Consistent Structural Relation Learning for Generalized Zero-Shot Segmentation,7504adad8bb96320eb3afdd4df6e1f60,https://proceedings.neurips.cc/paper/2020/file/7504adad8bb96320eb3afdd4df6e1f60-Paper.pdf,"Our research advances the zero-shot learning segmentation task, which alleviates the need for expensive human annotations when learning the unseen categories. Moreover, our research needs less computational cost which only needs to re-train the classification head rather than the whole network. Thus our research is more financially-friendly and environmental-friendly compared to the traditional fully-supervised learning paradigm. By utilizing the large amount of word embedding vectors, the network can be built with stronger scalability to potential unseen categories.",Broader Impact,77,4,,,FALSE,FALSE,FALSE,Consistent Structural Relation Learning for Zero-Shot Segmentation,Applications,Algorithms -> Multimodal Learning; Applications -> Computer Vision; Applications -> Object Recognition; Applications -> Visual Scene Analysis and Interpretation,Vision,"['Peike Li', ' Yunchao Wei', ' Yi Yang']","{'UTS', 'University of Technology Sydney', 'UIUC'}",1,0,0,"{'Australia', 'USA'}"
Model Selection in Contextual Stochastic Bandit Problems,"Aldo Pacchiano, My Phan, Yasin Abbasi Yadkori, Anup Rao, Julian Zimmert, Tor Lattimore, Csaba Szepesvari",Model Selection in Contextual Stochastic Bandit Problems,751d51528afe5e6f7fe95dece4ed32ba,https://proceedings.neurips.cc/paper/2020/file/751d51528afe5e6f7fe95dece4ed32ba-Paper.pdf,The work does not present any foreseeable societal consequence.,Broader impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Model Selection in Contextual Stochastic Bandit Problems,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning,Reinforcement learning and planning,"['Aldo Pacchiano', ' My Phan', ' Yasin Abbasi Yadkori', ' Anup Rao', ' Julian Zimmert', ' Tor Lattimore', ' Csaba Szepesvari']","{'School of Computer Science, Georgia Tech', 'University of Massachusetts Amherst', 'DeepMind', 'UC Berkeley', 'Google', 'DeepMind / University of Alberta'}",1,1,1,"{'Canada', 'UK', 'USA'}"
Truncated Linear Regression in High Dimensions,"Constantinos Daskalakis, Dhruv Rohatgi, Emmanouil Zampetakis",Truncated Linear Regression in High Dimensions,751f6b6b02bf39c41025f3bcfd9948ad,https://proceedings.neurips.cc/paper/2020/file/751f6b6b02bf39c41025f3bcfd9948ad-Paper.pdf,"Our contribution is mathematical and computational in nature. We show that truncated linear regression is computationally and statistically efficiently solvable even in the sparse, high-dimensional setting. Our advances in statistical inference with truncation present opportunities in decreasing the bias of models that are trained on biased data. Biased data is a real and significant problem in applications of Machine Learning, as well as broader data science applications and scientific reasoning. There are many types of bias and their source and type might be known or unknown. In this paper, we focus on bias coming from systematic data truncation, which is an important type of bias as discussed in the introduction. In extending prior work on this topic to high dimensions we address another growing challenge—namely, the dimensionality of the data which must now be processed. As usual, in interpreting our methodological advancements and using our algorithms in practice, we must recognize that the theory is only as good as the model: we make several assumptions (e.g. Gaussian measurements and noise), and the practitioner must judge whether these assumptions are justified in their application.",Broader impact,183,8,,,FALSE,FALSE,FALSE,Truncated Linear Regression in High Dimensions,Algorithms -> Sparsity and Compressed Sensing,Algorithms -> Regression; Theory -> Computational Learning Theory; Theory -> High-Dimensional Inference; Theory -> Large Deviations and Asymptotic Analysis; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Constantinos Daskalakis', ' Dhruv Rohatgi', ' Emmanouil Zampetakis']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Incorporating Pragmatic Reasoning Communication into Emergent Language,"Yipeng Kang, Tonghan Wang, Gerard  de Melo",Incorporating Pragmatic Reasoning Communication into Emergent Language,7520fa31d14f45add6d61e52df5a03ff,https://proceedings.neurips.cc/paper/2020/file/7520fa31d14f45add6d61e52df5a03ff-Paper.pdf,"This paper studies fundamental principles of communication, attempting to shed light on conditions under which pragmatic reasoning can enable agents to communicate more efficiently in challenging circumstances. Our interdisciplinary work draws novel connections between several distinct branches of linguistics, as well as multi-agent reinforcement learning and game theory. We believe it is important to develop models of agents endowed with communicative abilities that not only allow for the long-term emergence of linguistic patterns but also incorporate interlocutor awareness (theory of mind) and game theory. Recent work using language to achieve common objectives and cognitive studies show that feedback is paramount for language learning (Zaïem and Bennequin, 2019). Thus, 3 https://fringsoo.github.io/pragmatic_in2_emergent_papersite/  these sorts of models could be important for studying how to go beyond regular data-driven training of (neural) language models. In the long run, this sort of research has the potential to enable chatbots or other forms of virtual personal assistants endowed with more empathy and better awareness of the state of mind of the person they are interacting with. This might also allow them to better adapt to the needs of underrepresented social groups and different personalities.",Broader Impact,188,7,,,FALSE,FALSE,FALSE,Incorporating Pragmatic Reasoning Communication into Emergent Language,Applications -> Natural Language Processing,Applications -> Dialog- or Communication-Based Learning,Natural language processing,"['Yipeng Kang', ' Tonghan Wang', ' Gerard de Melo']","{'Tsinghua University', 'Hasso Plattner Institute'}",1,0,0,"{'China', 'Germany'}"
Deep Subspace Clustering with Data Augmentation,"Mahdi Abavisani, Alireza Naghizadeh, Dimitris Metaxas, Vishal Patel",Deep Subspace Clustering with Data Augmentation,753a043674f0193523abc1bbce678686,https://proceedings.neurips.cc/paper/2020/file/753a043674f0193523abc1bbce678686-Paper.pdf,"Since our method improves subspace clustering, it advances learning from unannotated data. Im- proving the learning process and providing more accurate similarity matrices for unannotated data can positively impact accountability, transparency and explainability of AI methods. However, if not controlled, providing the opportunity to learn from big unannotated datasets could increase the concerns about violating the privacy of individuals.",7 Broader Impact,59,3,FALSE,FALSE,FALSE,FALSE,FALSE,Deep Subspace Clustering with Data Augmentation,Applications -> Computer Vision,Algorithms -> Clustering; Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Algorithms -> Representation Learning; Algorithms -> Sparse Coding and Dimensionality Expansion; Algorithms -> Sparsity and Compressed Sensing; Algorithms -> Unsupervised Learning; Deep Learning -> Deep Autoencoders,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Mahdi Abavisani', ' Alireza Naghizadeh', ' Dimitris Metaxas', ' Vishal Patel']","{'Rutgers, The State University of New Jersey', 'Johns Hopkins University', 'Rutgers University'}",1,0,0,{'USA'}
An Empirical Process Approach to the Union Bound: Practical Algorithms for Combinatorial and Linear Bandits,"Julian Katz-Samuels, Lalit Jain, zohar karnin, Kevin G. Jamieson",An Empirical Process Approach to the Union Bound: Practical Algorithms for Combinatorial and Linear Bandits,75800f73fa80f935216b8cfbedf77bfa,https://proceedings.neurips.cc/paper/2020/file/75800f73fa80f935216b8cfbedf77bfa-Paper.pdf,"In this paper, we developed adaptive learning algorithms for linear and combinatorial settings. These algorithms hold the promise of decreasing the amount of data that is required to make discoveries. Given the generic nature of these algorithms, it is possible that practitioners will apply these algorithms towards goals that are ultimately harmful for society. However, we believe that our algorithms also hold significant promise to benefit society. By making the learning process more data-efficient, we are optimistic that our algorithms can be applied to accelerate drug discovery, as well as the rate of scientific discovery in a wide range of fields ranging from biology to the social sciences. Our belief is that the potential benefits outweigh the potential negative consequences.",Broader Impact,120,6,,,FALSE,FALSE,FALSE,An Empirical Process Approach to the Union Bound: Practical Algorithms for Combinatorial and Linear Bandits,Algorithms -> Bandit Algorithms,,,"['Samuels', ' Lalit Jain', ' zohar karnin', ' Kevin Jamieson']","{'Amazon', 'University of Washington', 'U Washington'}",1,1,1,{'USA'}
Can Graph Neural Networks Count Substructures?,"Zhengdao Chen, Lei Chen, Soledad Villar, Joan Bruna",Can Graph Neural Networks Count Substructures?,75877cb75154206c4e65e76b88a12712,https://proceedings.neurips.cc/paper/2020/file/75877cb75154206c4e65e76b88a12712-Paper.pdf,"In this work we propose to understand the power of GNN architectures via the substructures that they can and cannot count. Our work is motivated by the relevance of detecting and counting graph substructures in applications, and the current trend on using deep learning – in particular, graph neural networks – in such scientific fields. The ability of different GNN architectures to count graph substructures not only serves as an intuitive theoretical measure of their expressive power but also is highly relevant to real-world scenarios. Our results show that some widely used GNN architectures are not able to count substructures. Such knowledge may indicate that some widely-used graph neural network architectures are actually not the right tool for certain scientific problems. On the other hand, we propose a GNN model that not only has the ability to count substructures but also can learn from data what the relevant substructures are.",Broader impact,150,6,,,FALSE,FALSE,FALSE,Can Graph Neural Networks Count Substructures?,Algorithms -> Relational Learning,Theory,Relational learning; Graph Neural Networks,"['Zhengdao Chen', ' Lei Chen', ' Soledad Villar', ' Joan Bruna']","{'New York University', 'NYU'}",1,0,0,{'USA'}
A Bayesian Perspective on Training Speed and Model Selection,"Clare Lyle, Lisa Schut, Robin Ru, Yarin Gal, Mark van der Wilk",A Bayesian Perspective on Training Speed and Model Selection,75a7c30fc0063c4952d7eb044a3c0897,https://proceedings.neurips.cc/paper/2020/file/75a7c30fc0063c4952d7eb044a3c0897-Paper.pdf,"Due to the theoretical nature of this paper, we do not foresee any immediate applications (positive or negative) that may arise from our work. However, improvement in our understanding of generalization in deep learning may lead to a host of downstream impacts which we outline briefly here for completeness, noting that the marginal effect of this paper on such broad societal and environmental impacts is likely to be very small. 1. Safety and robustness. Developing a stronger theoretical understanding of generalization will plausibly lead to training procedures which improve the test-set performance of deep neural networks. Improving generalization performance is crucial to ensuring that deep learning systems applied in practice behave as expected based on their training performance. 2. Training efficiency and environmental impacts. In principle, obtaining better estimates of model and sub-model performance could lead to more efficient training schemes, thus potentially reducing the carbon footprint of machine learning research. 3. Bias and Fairness. The setting of our paper, like much of the related work on generalization, does not consider out-of-distribution inputs or training under constraints. If the training dataset is biased, then a method which improves the generalization performance of the model under the i.i.d. assumption will be prone to perpetuating this bias.",6 Broader Impact,205,14,,,FALSE,FALSE,FALSE,A Bayesian Perspective on Training Speed and Model Selection,Deep Learning -> Analysis and Understanding of Deep Networks,Probabilistic Methods -> Bayesian Theory,Probabilistic methods and inference,"['Clare Lyle', ' Lisa Schut', ' Robin Ru', ' Yarin Gal', ' Mark van der Wilk']","{'Imperial College', 'Oxford University', 'University of Oxford'}",1,0,0,{'UK'}
On the Modularity of Hypernetworks,"Tomer Galanti, Lior Wolf",On the Modularity of Hypernetworks,75c58d36157505a600e0695ed0b3a22d,https://proceedings.neurips.cc/paper/2020/file/75c58d36157505a600e0695ed0b3a22d-Paper.pdf,"Understanding modular models, in which learning is replaced by meta-learning, can lead to an ease in which models are designed and combined at an abstract level. This way, deep learning technology can be made more accessible. Beyond that, this work falls under the category of basic research and does not seem to have particular societal or ethical implications.",Broader Impact,58,3,FALSE,TRUE,FALSE,FALSE,FALSE,On the Modularity of Hypernetworks,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Meta-Learning,Theory (including computational and statistical analyses),"['Tomer Galanti', ' Lior Wolf']","{'Facebook AI Research', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
Doubly Robust Off-Policy Value and Gradient Estimation for Deterministic Policies,"Nathan Kallus, Masatoshi Uehara",Doubly Robust Off-Policy Value and Gradient Estimation for Deterministic Policies,75df63609809c7a2052fdffe5c00a84e,https://proceedings.neurips.cc/paper/2020/file/75df63609809c7a2052fdffe5c00a84e-Paper.pdf,"As a contribution to offline RL, our work is of particular importance for RL in the context of social and medical sciences, where experimentation is limited and observational data must be used. Deterministic policies are particularly important for real applications of offline RL because optimal policies are deterministic (up to ties). There exist various examples of the use of deterministic policies in epidemiology (Wu et al., 2018), political science (Imai and van Dyk, 2004), and economics (Colangelo and Lee, 2019). We provide some of the first theoretical results on convergence rates in sequential RL settings. Our work contributes both to the theoretical understanding of deterministic policies in RL and to practical methods for evaluating and learning these. That said, it is well understood that there is generally a gap between theory and practice in RL as it is applied to very complex and large-scale systems, and valid convergence rate guarantees need not directly translate by themselves into practical success in real, large-scale settings. It is therefore important to keep in mind practical heuristics, stopgaps, and approximations from applied RL when translating this work into practice. The systematic investigation of the use of these in the context of deterministic-policy offline RL may require additional future work. There are also several potential dangers to be cognizant of when applying offline RL tools in general. First, the presence of large unobserved confounding in the data (in our setting this would manifest as large violations of the MDP model) can bias evaluation and, unchecked, may potentially hide harms done by the policy being evaluated or the policy learned by off-policy optimization. Second, if the observational data is not representative of the population, that is, there is a covariate shift in the initial state distribution, then the evaluation both of value and of gradient will reflect these biases and correspondingly be unrepresentative, under-emphasizing value to some parts of the population and over-emphasizing value to others, leading to learned policies that possibly benefit over-represented subpopulations more than others. More generally, even without covariate shift, here we focused on evaluation and optimization of average welfare, which may average the harms to some and the benefits to others; it may therefore be important in some applications to also conduct auxiliary evaluations on certain protected subgroups to ensure equal impact, which can be done by segmenting the data.",Broader Impact,389,12,,,FALSE,FALSE,FALSE,Doubly Robust Off-Policy Value and Gradient Estimation for Deterministic Policies,Reinforcement Learning and Planning -> Reinforcement Learning,Probabilistic Methods -> Causal Inference,Reinforcement learning and planning,"['Nathan Kallus', ' Masatoshi Uehara']",{'Cornell University'},1,0,0,{'USA'}
Provably Efficient Neural GTD for Off-Policy Learning,"Hoi-To Wai, Zhuoran Yang, Zhaoran Wang, Mingyi Hong",Provably Efficient Neural GTD Algorithm for Off-policy Learning,75ebb02f92fc30a8040bbd625af999f1,https://proceedings.neurips.cc/paper/2020/file/75ebb02f92fc30a8040bbd625af999f1-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,TRUE,TRUE,FALSE,Provably Efficient Neural GTD for Off-Policy Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Reinforcement learning and planning,"['To Wai', ' Zhuoran Yang', ' Zhaoran Wang', ' Mingyi Hong']","{'Princeton', 'The Chinese University of Hong Kong', 'University of Minnesota', 'Northwestern University'}",1,0,0,"{'USA', 'China'}"
Learning Discrete Energy-based Models via Auxiliary-variable Local Exploration,"Hanjun Dai, Rishabh Singh, Bo Dai, Charles Sutton, Dale Schuurmans",Learning Discrete Energy-based Models via Auxiliary-variable Local Exploration,7612936dcc85282c6fa4dd9d4ffe57f1,https://proceedings.neurips.cc/paper/2020/file/7612936dcc85282c6fa4dd9d4ffe57f1-Paper.pdf,"We hope our new algorithm ALOE for learning discrete EBMs can be useful for different domains with discrete structures, and it furthers the general research efforts in this direction of generative models of discrete structures. In this paper, we present its application to program synthesis and software fuzzing. A positive outcome of improved performance in program synthesis would be that it can help democratize the task of programming by allowing people to express their desired intent using input-output examples without the need of learning complex programming languages. Similarly, a positive outcome of improvements in software fuzzing could allow software developers to identify bugs and vulnerabilities quicker and in turn improve software reliability and robustness. A possible negative outcome could be that malicious attackers might also use such technology to discover software vulnerabilities and use it for undesirable purposes [66]. However, this outcome is not specific to our technique but more generally applicable to the large research field of software fuzzing, and there is a large amount of work in the fuzzing field for accounting ethical considera- tions. For example, the vulnerabilities typically found by fuzzers is first responsibly disclosed to corresponding software teams [67] that gives them enough time to patch the vulnerabilities before the bugs and vulnerabilities are released publicly.",Broader Impact,211,7,,,FALSE,FALSE,FALSE,Learning Discrete Energy-based Models via Auxiliary-variable Local Exploration,Deep Learning -> Generative Models,Algorithms -> Structured Prediction; Applications -> Program Understanding and Generation,Probabilistic methods and inference,"['Hanjun Dai', ' Rishabh Singh', ' Bo Dai', ' Charles Sutton', ' Dale Schuurmans']","{'Google Brain', 'Google'}",0,1,0,{'USA'}
Stable and expressive recurrent vision models,"Drew Linsley, Alekh Karkada Ashok, Lakshmi Narasimhan Govindarajan, Rex Liu, Thomas Serre",Stable and expressive recurrent vision models,766d856ef1a6b02f93d894415e6bfa0e,https://proceedings.neurips.cc/paper/2020/file/766d856ef1a6b02f93d894415e6bfa0e-Paper.pdf,"The development of artificial vision systems that can rival the accuracy and robustness of biological vision is a broadly useful endeavor for scientific research. Any such advances in artificial vision inevitably can lead to unethical applications. Because our methods and code are open sourced, our work is similarly exposed. However, we anticipate that our contributions to brain science make this risk worthwhile, and that our work will have a net positive impact on the broader scientific community.",Broader Impact,77,4,,,FALSE,FALSE,FALSE,Stable and expressive recurrent vision models,Neuroscience and Cognitive Science,Applications -> Computer Vision; Applications -> Image Segmentation; Deep Learning -> Optimization for Deep Networks; Deep Learning -> Recurrent Networks; Neuroscience and Cognitive Science -> Cognitive Science; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Perception; Neuroscience and Cognitive Science -> Visual Perception,Neuroscience and cognitive science,"['Drew Linsley', ' Alekh K A', ' Lakshmi Narasimhan Govindarajan', ' Rex Liu', ' Thomas Serre']","{'R V College of Engineering', 'Brown University'}",1,0,0,{'USA'}
Entropic Optimal Transport between Unbalanced Gaussian Measures has a Closed Form,"Hicham Janati, Boris Muzellec, Gabriel Peyré, Marco Cuturi",Entropic Optimal Transport between Unbalanced Gaussian Measures has a Closed Form,766e428d1e232bbdd58664b41346196c,https://proceedings.neurips.cc/paper/2020/file/766e428d1e232bbdd58664b41346196c-Paper.pdf,"We expect this work to benefit research on sample complexity issues in regularized optimal transport, such as [24] for balanced regularized OT, and future work on unbalanced regularized OT. By providing the first continuous test-case, we hope that researchers will be able to better test their theoretical bounds and benchmark their methods.",Broader Impact,52,2,FALSE,FALSE,FALSE,FALSE,FALSE,Entropic Optimal Transport between Unbalanced Gaussian Measures has a Closed Form,Optimization,Theory,Optimal transport,,"{'ENSAE, Institut Polytechnique de Paris', 'Inria / ENSAE', 'CNRS and ENS'}",1,0,0,{'France'}
BRP-NAS: Prediction-based NAS using GCNs,"Lukasz Dudziak, Thomas Chau, Mohamed Abdelfattah, Royson Lee, Hyeji Kim, Nicholas Lane",BRP-NAS: Prediction-based NAS using GCNs,768e78024aa8fdb9b8fe87be86f64745,https://proceedings.neurips.cc/paper/2020/file/768e78024aa8fdb9b8fe87be86f64745-Paper.pdf,"This research can democratize on-device deployment with cost-efficient NAS methodology for model optimization within device latency constraints. Additionally, carbon footprint of traditionally expensive NAS methods is vastly reduced. On the other hand, measurement and benchmarking data can be used both to create new NAS methodologies, and to gain further insights about the device performance. This can bridge the machine learning and device research communities together.",Broader Impact,65,4,,,FALSE,FALSE,FALSE,BRP-NAS: Prediction-based NAS using GCNs,Algorithms -> AutoML,"Algorithms -> Few-Shot Learning; Algorithms -> Multitask and Transfer Learning; Applications -> Hardware and Systems; Data, Challenges, Implementations, and Software -> Benchmarks; Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories; Deep Learning -> CNN Architectures; Deep Learning -> Predictive Models",AutoML,"['Thomas Chau', ' Lukasz Dudziak', ' Mohamed Abdelfattah', ' Royson Lee', ' Hyeji Kim', ' Nicholas Lane']","{'Samsung AI Center Cambridge', 'Samsung AI Centre Cambridge'}",0,1,0,{'UK'}
Deep Shells: Unsupervised Shape Correspondence with Optimal Transport,"Marvin Eisenberger, Aysim Toker, Laura Leal-Taixé, Daniel Cremers",Deep Shells: Unsupervised Shape Correspondence with Optimal Transport,769c3bce651ce5feaa01ce3b75986420,https://proceedings.neurips.cc/paper/2020/file/769c3bce651ce5feaa01ce3b75986420-Paper.pdf,"With the ever increasing number of surface acquisition devices and techniques, the demand for algorithms that can process 3D data directly nowadays is higher than ever. The overarching goal is to perform recognition tasks directly on 3D sensory inputs, similarly to the way that we as humans make sense of our environment. In comparison to 2D images, which are a mere projection of the world surrounding us, geometric data is more robust to secondary effects like lighting conditions and general appearances of 3D objects. It is therefore imperative for the vision community to focus its efforts on both 2D and 3D understanding. Regarding ethical aspects, in the context of computer vision algorithms there is always the distinct possibility of dual use, e.g. for military aims. However, we believe that there is not an immediate risk of misuse associated with our algorithm.",Broader Impact,141,6,,,FALSE,FALSE,FALSE,Deep Shells: Unsupervised Shape Correspondence with Optimal Transport,Applications -> Computer Vision,Algorithms -> Unsupervised Learning,Vision,"['Marvin Eisenberger', ' Aysim Toker', 'Taixé', ' Daniel Cremers']","{'TUM', 'Technical University of Munich'}",1,0,0,{'Germany'}
ISTA-NAS: Efficient and Consistent Neural Architecture Search by Sparse Coding,"Yibo Yang, Hongyang Li, Shan You, Fei Wang, Chen Qian, Zhouchen Lin",ISTA-NAS: Efficient and Consistent Neural Architecture Search by Sparse Coding,76cf99d3614e23eabab16fb27e944bf9,https://proceedings.neurips.cc/paper/2020/file/76cf99d3614e23eabab16fb27e944bf9-Paper.pdf,"Our work proposes a new perspective to formulate the NAS problem and develops two algorithms that have better efficiency and correlation. The positive impacts are obvious. First, better architectures may be searched for some problems, so the practical application of neural network to the corresponding area can be fostered. It benefits industry because the products or services with more satisfactory performance can be employed. Second, NAS has been a resource demanding task. Our method saves much memory and time cost, which is friendly to environment and easy to use for practitioners. Finally, automation is believed as a complementary tool to human experts. We think that a good NAS method could bring researchers expertise in understanding neural architectures.",Broader Impact,117,8,,,FALSE,FALSE,FALSE,ISTA-NAS: Efficient and Consistent Neural Architecture Search by Sparse Coding,Algorithms -> AutoML,Deep Learning -> CNN Architectures,AutoML,"['Yibo Yang', ' Hongyang Li', ' Shan You', ' Fei Wang', ' Chen Qian', ' Zhouchen Lin']","{'SenseTime', 'Peking University'}",1,1,1,"{'Hong Kong', 'China'}"
Rel3D: A Minimally Contrastive Benchmark for Grounding Spatial Relations in 3D,"Ankit Goyal, Kaiyu Yang, Dawei Yang, Jia Deng",Rel3D: A Minimally Contrastive Benchmark for Grounding Spatial Relations in 3D,76dc611d6ebaafc66cc0879c71b5db5c,https://proceedings.neurips.cc/paper/2020/file/76dc611d6ebaafc66cc0879c71b5db5c-Paper.pdf,"This work contributes to improve the understanding of spatial relations, which in turn is a critical piece of the giant puzzle on language understanding. Our work could potentially lead to better language understanding and scene comprehension for intelligent systems like robots. This can eventually help the intelligent systems to communicate better with humans. Depending on how these intelligent systems are used, the society could gain positively as well as negatively from the existence of such systems.",7 Broader Impact,76,4,,,TRUE,TRUE,FALSE,Rel3D: A Minimally Contrastive Benchmark for Grounding Spatial Relations in 3D,"Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories",Applications -> Computer Vision,Vision,,"{'Princeton University', 'University of Michigan'}",1,0,0,{'USA'}
Regularizing Black-box Models for Improved Interpretability,"Gregory Plumb, Maruan Al-Shedivat, Ángel Alexander Cabrera, Adam Perer, Eric Xing, Ameet Talwalkar",Regularizing Black-box Models for Improved Interpretability,770f8e448d07586afbf77bb59f698587,https://proceedings.neurips.cc/paper/2020/file/770f8e448d07586afbf77bb59f698587-Paper.pdf,"Our user study plan has been approved by the IRB to minimize any potential risk to the participants, and the datasets used in this work are unlikely to contain sensitive information because they are public and well-studied. Within the Machine Learning community, we hope that E XP O will help encourage Interpretable Machine Learning research to adopt a more quantitative approach, both in the form of proxy evaluations and user studies. For broader societal impact, the increased interpretability of models trained with E XP O should be a significant benefit. However, E XP O does not address some issues with local explanations such as their susceptibility to adversarial attack or their potential to artificially inflate people’s trust in the model.",7 Broader Impact,120,4,,,FALSE,FALSE,FALSE,Regularizing Black-box Models for Improved Interpretability,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Gregory Plumb', 'Shedivat', ' Ángel Alexander Cabrera', ' Adam Perer', ' Eric Xing', ' Ameet Talwalkar']","{'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Trust the Model When It Is Confident: Masked Model-based Actor-Critic,"Feiyang Pan, Jia He, Dandan Tu, Qing He",Trust the Model When It Is Confident: Masked Model-based Actor-Critic,77133be2e96a577bd4794928976d2ae2,https://proceedings.neurips.cc/paper/2020/file/77133be2e96a577bd4794928976d2ae2-Paper.pdf,"This paper aims to make reinforcement learning more reliable in practical use. We point out that previous methods that work well under ideal conditions can have a poor performance in a more realistic setting (e.g., in a noisy environment) and are not robust to some hyper-parameters (e.g., the model rollout length). We suggest that these factors should be taken into account for future work. We improve the robustness and generalization ability by restricting model use with a notion of uncertainty. Such an insight can be universal in all areas for building reliable Artificial Intelligence systems.",Broader impact,95,5,,,FALSE,FALSE,FALSE,Trust the Model When It Is Confident: Masked Model-based Actor-Critic,Reinforcement Learning and Planning -> Model-Based RL,Algorithms -> Uncertainty Estimation; Reinforcement Learning and Planning,,"['Feiyang Pan', ' Jia He', ' Dandan Tu', ' Qing He']","{'Huawei', 'Institute of Computing Technology, Chinese Academy of Sciences'}",1,1,1,{'China'}
Semi-Supervised Neural Architecture Search,"Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Enhong Chen, Tie-Yan Liu",Semi-Supervised Neural Architecture Search,77305c2f862ad1d353f55bf38e5a5183,https://proceedings.neurips.cc/paper/2020/file/77305c2f862ad1d353f55bf38e5a5183-Paper.pdf,"This work focuses on neural architecture search. It has the following potential positive impact in the society: 1) Improve the performance of neural networks for better applications. 2) Reduce the human efforts in designing neural architectures. At the same time, it may have some negative consequences because architecture search may cost many resources.",Broader Impact,53,4,FALSE,FALSE,FALSE,FALSE,FALSE,Semi-Supervised Neural Architecture Search,Algorithms -> AutoML,Deep Learning,AutoML,"['Renqian Luo', ' Xu Tan', ' Rui Wang', ' Tao Qin', ' Enhong Chen', 'Yan Liu']","{'University of Science and Technology of China', 'Microsoft Research Asia', 'Microsoft Research'}",1,1,1,"{'USA', 'China'}"
Consistency Regularization for Certified Robustness of Smoothed Classifiers,"Jongheon Jeong, Jinwoo Shin",Consistency Regularization for Certified Robustness of Smoothed Classifiers,77330e1330ae2b086e5bfcae50d9ffae,https://proceedings.neurips.cc/paper/2020/file/77330e1330ae2b086e5bfcae50d9ffae-Paper.pdf,"The potential risk of adversarial attacks has left many practitioners hesitant to apply the latest developments in deep learning into their systems. Adversarial robustness of deep neural networks is one of the most important research problems toward AI safety [1], with much impact on various applications especially for security-concerned systems: e.g., medical diagnosis [9], speech recognition [29], and autonomous driving [43]. Our research could be beneficial for those who design such systems, thanks to the certifiable guarantees on adversarial robustness that randomized smoothing can provide. Especially, we expect the simplicity of our method would encourage many practitioners to incorporate randomized smoothing into their systems along with our work. A practical success of systems equipped with a sufficient amount of certified robustness would be fatal for those who maliciously attempt to break down the system via adversarial attacks. This statement, however, presumes that many of the practical issues on the current randomized smoothing technique would be resolved in future research. For example, (a) randomized smoothing requires exponentially many inferences for a single reliable inference, and (b) there is still a gap between theoretical guarantee [13, 42] and practice [40, 4] on robustness that randomized smoothing currently gives: consequently, current randomized smoothing can be easily misused in practical systems, and a failure of such systems may implicitly lead practitioners to have a biased, false sense of security. We believe our research is a step toward reducing this practical gap to deploy randomized smoothing into the real-world.",Broader Impact,244,8,,,FALSE,FALSE,FALSE,Consistency Regularization for Certified Robustness of Smoothed Classifiers,Deep Learning,Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Jongheon Jeong', ' Jinwoo Shin']",{'KAIST'},1,0,0,{'South Korea'}
Robust Multi-Agent Reinforcement Learning with Model Uncertainty,"Kaiqing Zhang, TAO SUN, Yunzhe Tao, Sahika Genc, Sunil Mallya, Tamer Basar",Robust Multi-Agent Reinforcement Learning with Model Uncertainty,774412967f19ea61d448977ad9749078,https://proceedings.neurips.cc/paper/2020/file/774412967f19ea61d448977ad9749078-Paper.pdf,"We believe that researchers of multi-agent reinforcement learning (MARL) and robust RL would benefit from this work, as we have explored one possibility to systematically handle model-uncertainty in MARL. In particular, prior to this work, though a common issue in practice, it is unknown yet how to deal with the uncertainties of the model in MARL, to address the sim-to-real gap in MARL. We have made an initial attempt to address this issue, under a theoretical framework of robust Markov games. In light of the ubiquity of RL on multi-agent systems, especially those safety-critical ones, e.g., autonomous-driving cars, robots, unmanned aerial vehicles, safe MARL , the broader topic that our work belongs to, would be of paramount importance, and would eventually push forward the application of MARL on practical systems. Our work will hopefully bring the topic of safe MARL into researchers’ attention, and open up several interesting and challenging future research directions along the line. We do not believe that our research will cause any ethical issue, or put anyone at any disadvantage.",Broader Impact,174,6,,,FALSE,FALSE,FALSE,Robust Multi-Agent Reinforcement Learning with Model Uncertainty,Reinforcement Learning and Planning -> Multi-Agent RL,"Social Aspects of Machine Learning -> AI Safety; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security; Theory -> Game Theory and Computational Economics",Reinforcement learning and planning,"['Kaiqing Zhang', 'Champaign', ' TAO SUN', ' Yunzhe Tao', ' Sahika Genc', ' Sunil Mallya', ' Tamer Basar']","{'Amazon AWS', 'University of Illinois at Urbana-Champaign', 'Amazon Artificial Intelligence', 'UIUC'}",1,1,1,{'USA'}
SIRI: Spatial Relation Induced Network For Spatial Description Resolution,"peiyao wang, Weixin Luo, Yanyu Xu, Haojie  Li, Shugong Xu, Jianyu Yang, Shenghua Gao",SIRI: Spatial Relation Induced Network For Spatial Description Resolution,778609db5dc7e1a8315717a9cdd8fd6f,https://proceedings.neurips.cc/paper/2020/file/778609db5dc7e1a8315717a9cdd8fd6f-Paper.pdf,"We would like to claim that our proposed method tackles the spatial description resolution task, under strict privacy preservation by using features rather than raw images. Our work provides novel horizons to the academic community, but it also pushes this task towards real-world application. We also acknowledge that ethical concerns may be caused by the unsatisfactory target localization in some challenging cases, as whis may mislead users. Nonetheless, safety and reliability will be our top priorities when we deploy this system in real-world applications.",Broader Impact,84,4,,,FALSE,FALSE,FALSE,SIRI: Spatial Relation Induced Network For Spatial Description Resolution,Applications -> Visual Question Answering,Applications -> Visual Scene Analysis and Interpretation,Vision,"['peiyao wang', ' Weixin Luo', ' Yanyu Xu', ' Haojie Li', ' Shugong Xu', ' Jianyu Yang', ' Shenghua Gao']","{'Shanghaitech University', 'ShanghaiTech University', 'Soochow University', 'Shanghai University', 'Dalian University of Technology'}",1,0,0,{'China'}
Adaptive Shrinkage Estimation for Streaming Graphs,"Nesreen Ahmed, Nick Duffield",Adaptive Shrinkage Estimation for Streaming Graphs,780261c4b9a55cd803080619d0cc3e11,https://proceedings.neurips.cc/paper/2020/file/780261c4b9a55cd803080619d0cc3e11-Paper.pdf,"There is a burgeoning recent literature of statistical estimation and adaptive data analysis of the higher-order structural properties of graphs in both the streaming and non streaming context that reflect the importance and interest of this topic for the graph algorithms and relational learning research community. On the other hand, shrinkage estimators are an established technique from more general statistics. This paper is the first to apply shrinkage based methods in the context of graph approximation. The expected broader impact is as a proof of concept that shows the way for other researchers in this area to improve estimation quality. Moreover, this work fits under statistical inference for temporal relational/network data, which would enable statistical analysis and learning for network data that appear in streaming settings, in particular when exact solutions are not feasible (similar to the important literature on randomization algorithms for data matrices [1]). Furthermore, there are many applications where the data has a pronounced temporal, relational, and spatial structure (e.g., relational data). Examples of Non-IID streams include (i) non-independence due to temporal clustering in communication graphs on internet, online social networks, physical contact networks, and social media such as flash crowds and coordinated botnet activity; (ii) non- identical distributions in activity on these networks due to diurnal and other seasonal variations, synchronization of user network activity e.g., searches stimulated by hourly news reports. The proposed framework is suitable for these applications, because it makes no statistical assumptions concerning the arrival stream and the order of the arriving edges.",Broader Impact,251,8,,,FALSE,FALSE,FALSE,Adaptive Shrinkage Estimation for Streaming Graphs,Algorithms -> Adaptive Data Analysis,Applications -> Network Analysis,Theory (including computational and statistical analyses),"['Nesreen Ahmed', ' Nick Duffield']",{'Intel Labs'},0,1,0,{'USA'}
Make One-Shot Video Object Segmentation Efficient Again,"Tim Meinhardt, Laura Leal-Taixé",Make One-Shot Video Object Segmentation Efficient Again,781397bc0630d47ab531ea850bddcf63,https://proceedings.neurips.cc/paper/2020/file/781397bc0630d47ab531ea850bddcf63-Paper.pdf,"Authors are asked to include a section in their submissions discussing the broader impact of their work, including possible societal consequences, both, positive and negative. Many methods for video object segmentation or multiple object tracking rely on appearance models of objects. In this work, we have shown that one can rely on the simple but elegant solution of fine-tuning of a model as a way to build appearance models. Semi-supervised video object segmentation is often used to automatize video editing, e.g., to remove one object from a video. While it is clear that more automatic methods would have a positive impact in reducing the manual work needed to perform such video edits, there is also potential to misuse such technology. One could imagine the creation of fake videos, where objects are taken out or put on the scene to create out-of-context content that might lead viewers to misinterpret the situation. Nonetheless, we believe the technology is still in early stages and far from being able to create fake content without substantial knowledge and manual work. Therefore, we believe that, for this particular task, the benefits outweigh the potential misuses of the technology. Appearance models are also key towards tackling multi-object tracking and segmentation, important for applications such as robotics. For example, social robots are often tasked with following one specific person, hence the robot has to learn fast an on the fly the appearance of the specific person that it has to follow. This can be extended to multiple people tracking, where each model would be fine-tuned to a specific person on the scene. Segmentation of an object of interest becomes also key for robotic tasks such as grasping or any object-robot interaction. But multi-object tracking and video object segmentation also have a dark side, with applications such as illegal surveillance. We want to note, that our method does not make use of any kind of identifying characteristic of a person (if the person would be our object to follow and segment). Therefore, we believe our technology does not directly contribute nor promote these kinds of misuses. We believe that the simple concept of fine-tuning a model to a specific object is incredibly powerful. With our work, we hope to inspire researchers to continue with that paradigm, now that we can properly train it to achieve state-of-the-art results. Looking at the impact that these tools can have for society, one can see extremely positive things such as the realization of social robots that could help the elderly in their daily chores.",Acknowledgements Broader Impact,421,18,,,FALSE,FALSE,FALSE,Make One-Shot Video Object Segmentation Efficient Again,Applications -> Video Analysis,,Vision,"['Tim Meinhardt', 'Taixé']",{'TUM'},1,0,0,{'Germany'}
Depth Uncertainty in Neural Networks,"Javier Antoran, James Allingham, José Miguel Hernández-Lobato",Depth Uncertainty in Neural Networks,781877bda0783aac5f1cf765c128b437,https://proceedings.neurips.cc/paper/2020/file/781877bda0783aac5f1cf765c128b437-Paper.pdf,"We have introduced a general method for training neural networks to capture model uncertainty. These models are fairly flexible and can be applied to a large number of applications, including potentially malicious ones. Perhaps, our method could have the largest impact on critical decision making applications, where reliable uncertainty estimates are as important as the predictions themselves. Financial default prediction and medical diagnosis would be examples of these. We hope that this work will contribute to increased usage of uncertainty aware deep learning methods in production. DUNs are trained with default hyperparameters and easy to make converge to reasonable solutions. The computational cost of inference in DUNs is similar to that of vanilla NNs. This makes DUNs especially well suited for applications with real-time requirements or low computational resources, such as self driving cars or sensor fusion on embedded devices. More generally, DUNs make leveraging uncertainty estimates in deep learning more accessible for researchers or practitioners who lack extravagant computational resources.  Despite the above, a hypothetical failure of our method, e.g. providing miscalibrated uncertainty estimates, could have large negative consequences. This is particularly the case for critical decision making applications, such as medical diagnosis.",Broader Impact,194,11,,,FALSE,FALSE,FALSE,Depth Uncertainty in Neural Networks,Algorithms -> Uncertainty Estimation,Algorithms -> Model Selection and Structure Learning; Deep Learning; Probabilistic Methods,Probabilistic methods and inference,"['Javier Antoran', ' James Allingham', 'Lobato']",{'University of Cambridge'},1,0,0,{'UK'}
Non-Euclidean Universal Approximation,"Anastasis Kratsios, Ievgen Bilokopytov",Non-Euclidean Universal Approximation,786ab8c4d7ee758f80d57e65582e609d,https://proceedings.neurips.cc/paper/2020/file/786ab8c4d7ee758f80d57e65582e609d-Paper.pdf,"A large portion of available data is non-Euclidean, either in the form of social network data to imaging data relevant in health applications of deep learning. The tools in this paper open up a generic means of translating the currently available deep learning technology to those milieus. The automation of tools in the medical sciences is important to helping reducing waiting times in hospitals and help make healthcare more accessible to all, so in that way, any automatizing of health science tools helps move society in that direction. Therefore, we hope that the methods presented in paper form a small step towards a greater positive advancement of the social and natural sciences.",Broader Impact,112,4,,,FALSE,FALSE,FALSE,Non-Euclidean Universal Approximation,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning,Algorithms -> Classification; Applications -> Computer Vision; Deep Learning -> Embedding Approaches; Theory -> Hardness of Learning and Approximations; Theory -> Spaces of Functions and Kernels,Theory (including computational and statistical analyses),"['Anastasis Kratsios', ' Ievgen Bilokopytov']","{'University of Manitoba', 'ETH Zürich'}",1,0,0,"{'Canada', 'Switzerland'}"
Constraining Variational Inference with Geometric Jensen-Shannon Divergence,"Jacob Deasy, Nikola Simidjievski, Pietro Lió",Constraining Variational Inference with Geometric Jensen-Shannon Divergence,78719f11fa2df9917de3110133506521,https://proceedings.neurips.cc/paper/2020/file/78719f11fa2df9917de3110133506521-Paper.pdf,"For the statistics community, our introduction of the alternative JS G α and JS ∗ G α , rather than the ""original"" JS G α and JS ∗ G α , immediately presents a benefit as a more intuitive interpolation through divergence and distribution space. As we have shown the benefits of such an interpolation on the task of image reconstruction, the first impact of our model lies in better image compression and generation from latent samples. However, in a more general setting, VAEs present multiple impactful opportunities. Applications include compression (of any data type), generation of new samples in fields with data paucity, as well as extraction of underlying relationships. As our exploration of the JS G α family of VAEs has improved performance, after translation to data types with other structures, our VAE could be used for all of these applications. Our experiments also indicate strong regions for the skew parameter α which could be used as a standard regularisation mechanism across variational learning. In settings with sensitive data, all of these applications bear some risks. As VAEs provide a form of lossy compression, in healthcare and social settings there is the risk of misrepresenting personal information in latent space. In areas of data paucity, without additional constraints, VAEs may generate samples which are unrealistic and severely bias any downstream training. Finally, when using VAEs in science, to extract underlying associations, it remains important to analyse the true meaning of any independent components extracted, rather than taking these rules at face value.",Broader Impact,254,10,,,FALSE,FALSE,FALSE,Constraining Variational Inference with Geometric Jensen-Shannon Divergence,Probabilistic Methods -> Variational Inference,Deep Learning -> Deep Autoencoders; Theory -> Regularization,Deep learning,"['Jacob Deasy', ' Nikola Simidjievski', ' Pietro Lió']",{'University of Cambridge'},1,0,0,{'UK'}
Gibbs Sampling with People,"Peter Harrison, Raja Marjieh, Federico Adolfi, Pol van Rijn, Manuel Anglada-Tort, Ofer Tchernichovski, Pauline Larrouy-Maestri, Nori Jacoby",Gibbs Sampling with People,7880d7226e872b776d8b9f23975e2a3d,https://proceedings.neurips.cc/paper/2020/file/7880d7226e872b776d8b9f23975e2a3d-Paper.pdf,"This research extends the methods available to cognitive scientists who seek to characterize semantic representations in human participants. In particular, the proposed method facilitates studying much richer perceptual spaces (both in terms of dimensionality and in terms of granularity) than can be explored effectively with conventional methods. Our research group is particularly interested in using GSP to study cross-cultural differences in perception [24, 47, 55]. In this context, exploratory techniques such as GSP are particularly useful, because they can generate valuable cognitive insights without specifying a constrained hypothesis space a priori . Previous work using slider interfaces with cross-cultural populations makes us relatively confident that GSP could be applied cross-culturally [56], as long as sufficient care is taken to ensure that the task is understood properly by the participants. Addressing cross-cultural populations in this way can help to ameliorate cognitive science’s longstanding bias towards participants from WEIRD (Western, Educated, Industrial, Rich and Democratic) backgrounds [57]. It is important to identify potential pitfalls in applying GSP, especially when such activities have adverse ethical implications. We give three recommendations below for avoiding such mistakes. Do not conflate subjective judgments with objective truth. GSP is a tool for understanding participants’ subjective notions of particular semantic concepts. It does not necessarily reveal any objective truth about these concepts. This is particularly relevant in examples like our face study, where GSP is used to characterize perceived intelligence and trustworthiness. For example, GSP may suggest that participants associate glasses-wearing with intelligence: this does not mean that wearing glasses makes someone intelligent, or even that glasses wearing is necessarily associated with intelligence in the real world. Mistakes of this kind have the potential to perpetuate or amplify dangerous stereotypes in society, especially when the inferences concern race/ethnicity and gender; such an approach has a regrettable history in the now-discredited field of physiognomy. Researchers using our method and related psychological methods should be aware of this negative history, and hold their own work to a higher ethical standard to avoid causing similar harm. Consequently, GSP should not be used as tool for generating training datasets for machine-learning algorithms, or for fine-tuning the parameters or hyperparameters of such algorithms, unless the researcher makes it absolutely clear that the algorithm is being used to study human stereotypes rather than objective truths. Analyze, report, and ideally avoid potential biases. Cognitive scientists must always be sensitive to potential biases in designing their stimuli and recruiting their participants. GSP is no exception to this principle. Our studies include examples of relatively simple and unbiased stimulus spaces (HSL colors; musical triads) as well as examples of relatively complex but potentially biased stimulus spaces (recordings of spoken sentences; images generated by the StyleGAN model). For practical reasons, our studies all used participants recruited from AMT; while this platform provides a relatively diverse participant group compared to the common practice of recruiting psychology students, it clearly does not represent the full diversity of the global population [58], and our results are likely to reflect culturally dependent stereotypes as a result (e.g., the Western preference for musical chords with high harmonicity, [49]). It is imperative that cognitive scientists remain vigilant concerning the potential harms of using non-diverse participant groups, both as regards making incorrect scientific conclusions and as regards perpetuating the under-representation of already marginalized parts of society [57]. We discuss these issues on a case-by-case basis above, but future cognitive work using these methods should examine these issues in greater detail. For example, we did not gather detailed personal information about our participants on variables such as race/ethnicity due to privacy reasons, but it is important that future work studying facial stereotypes takes such variables into account. Validate findings with rigorous hypothesis-driven experiments. The power of combining GSP with deep generative models (e.g., StyleGAN) is that it enables the researcher to ask exploratory questions about complex naturalistic stimuli, such as ‘what do people think a serious face looks like?’ However, the downside of this approach is that the technique is susceptible to inheriting hidden biases from the generative model [59]. It is therefore essential that cognitive research combining GSP with deep generative models should treat the results as exploratory, and ideally validate the results with well-controlled experiments that do not rely on the generative model.",Broader Impact,709,27,,,FALSE,TRUE,FALSE,Gibbs Sampling with People,Neuroscience and Cognitive Science -> Cognitive Science,Applications -> Audio and Speech Processing; Applications -> Music Modeling and Analysis; Deep Learning; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Generative Models; Neuroscience and Cognitive Science; Neuroscience and Cognitive Science -> Auditory Perception; Neuroscience and Cognitive Science -> Perception; Neuroscience and Cognitive Science -> Visual Perception; Theory,Neuroscience and cognitive science,"['Peter Harrison', ' Raga Marjieh', ' Federico G Adolfi', ' Pol van Rijn', 'Tort', ' Ofer Tchernichovski', 'Maestri', ' Nori Jacoby']","{'Max-Planck-Institute of Empircal Aesthetics', 'Max Planck Institute for Empirical Aesthetics', 'Hunter College, CUNY', 'Max-Planck Institute AE, Frankfurt, Germany'}",1,0,0,"{'USA', 'Germany'}"
HM-ANN: Efficient Billion-Point Nearest Neighbor Search on Heterogeneous Memory,"Jie Ren, Minjia Zhang, Dong Li",HM-ANN: Efficient Billion-Point Nearest Neighbor Search on Heterogeneous Memory,788d986905533aba051261497ecffcbb,https://proceedings.neurips.cc/paper/2020/file/788d986905533aba051261497ecffcbb-Paper.pdf,"In this paper, we introduce HM-ANN, a hierarchical graph-based similarity search algorithm to leverage emerging heterogeneous memory, aiming to serve extremely large-scale data points on a single node with high accuracy and ultra fast response time. The similarity search algorithm has been applied to a wide range of applications, including large-scale image/text search, web question and answer, and recommendation systems. Our research could be used to improve quality of services for those applications, increasing system scales without adding too much production cost, and efficiently handling large data sets with increasing volumes in data centers. Furthermore, HM is an emerging architecture providing extremely large memory capacity for data intensive applications. Our research reveals a new field that could benefit from this architecture and shows great potential of using HM to establish the new state-of-the-art for indexing and searching large-scale datasets. Other algorithms that have the similar workload characteristics as ANN (such as the hierarchical design in ANN) can benefit from our research. Although there are many benefits of using HM-ANN, we must pay attention to the potential risks of HM-ANN. HM-ANN uses a highly-structured approach to build the graph and removes randomness during node promotion. Although this approach is necessary to improve search quality and manage memory accesses in slow memory, it raises a risk of explicitly exposing critical information (such as nodes with high degrees) into specific memory regions, allowing the hacker to steal the information from the structured graph. Furthermore, Optane-based HM, which is one of the most common HM, raises security issues because of using non-volatile memory (i.e., Optane) [48, 5, 39]. Those security issues could happen in ANN search based on the Optane-based HM. To mitigate the risks associated with using HM for ANN, we encourage research to understand the impacts of using HM-ANN in real-world scenarios and consider how the system (especially the address mapping scheme and memory organization) should be evolved to introduce randomness to mitigate security risk. More fundamentally, how to strike a good balance between high performance using a structured approach and potential security issues should be considered more broadly.",Broader Impact,347,13,,,FALSE,FALSE,FALSE,HM-ANN: Efficient Billion-Point Nearest Neighbor Search on Heterogeneous Memory,Applications -> Information Retrieval,Algorithms -> Similarity and Distance Learning; Applications -> Hardware and Systems,"Datasets, challenges, software","['Jie Ren', ' Minjia Zhang', ' Dong Li']","{'Microsoft', 'University of California, Merced'}",1,1,1,{'USA'}
FrugalML: How to use ML Prediction APIs more accurately and cheaply,"Lingjiao Chen, Matei Zaharia, James Y. Zou",FrugalML: How to Use ML Prediction APIs More Accurately and Cheaply,789ba2ae4d335e8a2ad283a3f7effced,https://proceedings.neurips.cc/paper/2020/file/789ba2ae4d335e8a2ad283a3f7effced-Paper.pdf,"ML as a service is a growing industry with substantial economic and societal impact. In this paper, we identify the cost and performance heterogeneity across popular ML APIs, which contributes to the broader understanding of this important but under-explored industry. We proposed a method to automatically reduce user cost while improving accuracy. FrugalML can broadly contribute to the applied ML ecosystem by reducing the expense and complexity of using prediction APIs. This can be a positive impact by increasing accessibility to ML APIs for less well-resourced groups. A potential concern about the ML APIs in general is that they may be trained on biased data and produce biased predictions that could disadvantage certain sub-groups. To tackle this challenge, we are releasing our dataset of over 600k images, text, and utterances that we annotated using commercial APIs. This is a resource for the broad community to use to better understand the biases in existing APIs.",Potential Broader Impact,154,8,,,FALSE,FALSE,FALSE,FrugalML: How to use ML Prediction APIs more accurately and cheaply,Algorithms,Algorithms -> Boosting and Ensemble Methods; Algorithms -> Classification; Applications,Resource aware machine learning,"['Lingjiao Chen', ' Matei Zaharia', ' James Zou']","{'Stanford University', 'Stanford and Databricks', 'University of Wisconsin-Madison'}",1,1,1,{'USA'}
Sharp Representation Theorems for ReLU Networks with Precise Dependence on Depth,"Guy Bresler, Dheeraj Nagaraj",Sharp Representation Theorems for ReLU Networks with Precise Dependence on Depth,78f7d96ea21ccae89a7b581295f34135,https://proceedings.neurips.cc/paper/2020/file/78f7d96ea21ccae89a7b581295f34135-Paper.pdf,This section is not applicable to this work.,Broader Impact,8,1,TRUE,FALSE,FALSE,FALSE,FALSE,Sharp Representation Theorems for ReLU Networks with Precise Dependence on Depth,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Statistical Learning Theory,Deep learning,"['Guy Bresler', ' Dheeraj Nagaraj']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning,"Filippos Christianos, Lukas Schäfer, Stefano Albrecht",Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning,7967cc8e3ab559e68cc944c44b1cf3e8,https://proceedings.neurips.cc/paper/2020/file/7967cc8e3ab559e68cc944c44b1cf3e8-Paper.pdf,"Multi-agent deep reinforcement learning has potential applications in areas such as autonomous vehicles, robotic warehouses, internet of things, smart grids, and more. Our research could be used to improve reinforcement learning models in such applications. However, it must be noted that real-world application of MARL algorithms is currently not viable due to open problems in AI explainability, robustness to failure cases, legal and ethical aspects, and other issues, which are outside the scope of our work. That being said, improvements in MARL could lead to undue trust in RL models; having models that work well does not translate to models that are safe or which can be broadly used. Agents trained with these methods need to be thoroughly studied before being used in production. However, if these technologies are indeed used responsibly, they can improve several aspects of modern society such as making transportation safer, or performing jobs that might pose risks to humans.",Broader Impact,154,6,,,FALSE,FALSE,FALSE,Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning -> Exploration,Reinforcement learning and planning,"['Filippos Christianos', ' Lukas Schäfer', ' Stefano Albrecht']",{'University of Edinburgh'},1,0,0,{'UK'}
Monotone operator equilibrium networks,"Ezra Winston, J. Zico Kolter",Monotone operator equilibrium networks,798d1c2813cbdf8bcdb388db0e32d496,https://proceedings.neurips.cc/paper/2020/file/798d1c2813cbdf8bcdb388db0e32d496-Paper.pdf,"While the main thrust of our work is foundational in nature, we do demonstrate the potential for implicit models to become practical alternatives to traditional deep networks. Owing to their improved memory efficiency, these networks have the potential to further applications of AI methods on edge devices, where they are currently largely impractical. However, the work is still largely algorithmic in nature, and thus it is much less clear the immediate societal-level benefits (or harms) that could result from the specific tehniques we propose and demonstrate in this paper.",Broader impact statement,89,3,,,FALSE,FALSE,FALSE,Monotone operator equilibrium networks,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Optimization for Deep Networks; Optimization -> Convex Optimization,Deep learning,"['Ezra Winston', ' Zico Kolter']","{'Carnegie Mellon University', 'Carnegie Mellon University / Bosch Center for AI'}",1,1,1,"{'USA', 'Germany'}"
When and How to Lift the Lockdown? Global COVID-19 Scenario Analysis and Policy Assessment using Compartmental Gaussian Processes,"Zhaozhi Qian, Ahmed M. Alaa, Mihaela van der Schaar",When and How to Lift the Lockdown? Global COVID-19 Scenario Analysis and Policy Assessment using Compartmental Gaussian Processes,79a3308b13cd31f096d8a4a34f96b66b,https://proceedings.neurips.cc/paper/2020/file/79a3308b13cd31f096d8a4a34f96b66b-Paper.pdf,"This paper addresses a timely decision-making problem that faces governments and authorities around the world during these exceptional times. Decisions informed by our model may affect the daily lives of millions of people around the world during the upcoming months. We believe that now is the time for research on machine learning for clinical and public health applications to contribute to the efforts humanity exerts to handle the current crisis — we hope that our model plays a role in informing the public and governments on the consequences of policies and social behavior on public health. We are currently in the phase of communicating the projections of our model with official public health services in multiple countries, including developing countries.",Broader Impact,120,4,,,FALSE,FALSE,FALSE,When and How to Lift the Lockdown? Global COVID-19 Scenario Analysis and Policy Assessment using Compartmental Gaussian Processes,Applications,Applications -> Health,Healthcare,"['Zhaozhi Qian', ' Ahmed Alaa', ' Mihaela van der Schaar']","{'University of Cambridge', 'UCLA'}",1,0,0,"{'UK', 'USA'}"
Unsupervised Learning of Lagrangian Dynamics from Images for Prediction and Control,"Yaofeng Desmond Zhong, Naomi  Leonard",Unsupervised Learning of Lagrangian Dynamics from Images for Prediction and Control,79f56e5e3e0e999b3c139f225838d41f,https://proceedings.neurips.cc/paper/2020/file/79f56e5e3e0e999b3c139f225838d41f-Paper.pdf,"We focus on the impact of using our model to provide explanations for physical system modelling. Our model could be used to provide explanations regarding the underlying symmetries, i.e., conservation laws, of physical systems. Further, the incorporation of the physics prior of Lagrangian dynamics improves robustness and generalizability for both prediction and control applications. We see opportunities for research applying our model to improve transparency and explanability in reinforcement learning, which is typically solved with low-dimensional observation data instead of image data. Our work also enables future research on vision-based controllers. The limitations of our work will also motivate research on unsupervised segmentation of images of physical systems.",Broader Impact,108,6,,,FALSE,FALSE,FALSE,Unsupervised Learning of Lagrangian Dynamics from Images for Prediction and Control,Algorithms -> Dynamical Systems,Probabilistic Methods -> Variational Inference; Reinforcement Learning and Planning -> Decision and Control,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yaofeng Zhong', ' Naomi Leonard']",{'Princeton University'},1,0,0,{'USA'}
High-Dimensional Sparse Linear Bandits,"Botao Hao, Tor Lattimore, Mengdi Wang",High-Dimensional Sparse Linear Bandits,7a006957be65e608e863301eb98e1808,https://proceedings.neurips.cc/paper/2020/file/7a006957be65e608e863301eb98e1808-Paper.pdf,We believe that presented research should be categorized as basic research and we are not targeting any specific application area. Theorems may inspire new algorithms and theoretical investigation. The algorithms presented here can be used for many different applications and a particular use may have both positive or negative impacts. We are not aware of any immediate short term negative implications of this research and we believe that a broader impact statement is not required for this paper.,Broader Impact,78,4,,,TRUE,TRUE,FALSE,High-Dimensional Sparse Linear Bandits,Algorithms -> Bandit Algorithms,Theory -> Statistical Learning Theory,Bandits,"['Botao Hao', ' Tor Lattimore', ' Mengdi Wang']","{'Princeton University', 'DeepMind', 'Purdue University'}",1,1,1,"{'UK', 'USA'}"
Non-Stochastic Control with Bandit Feedback,"Paula Gradu, John Hallman, Elad Hazan",Non-Stochastic Control with Bandit Feedback,7a1d9028a78f418cb8f01909a348d9b2,https://proceedings.neurips.cc/paper/2020/file/7a1d9028a78f418cb8f01909a348d9b2-Paper.pdf,The purpose of this work is to contribute to scientific progress in control theory. We do not expect any unethical use of this work.,Broader Impact,24,2,TRUE,FALSE,FALSE,FALSE,FALSE,Non-Stochastic Control with Bandit Feedback,Theory -> Control Theory,Algorithms -> Bandit Algorithms; Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Paula Gradu', ' John Hallman', ' Elad Hazan']","{'Princeton University', 'Princeton University, Google AI Princeton'}",1,1,1,{'USA'}
Generalized Leverage Score Sampling for Neural Networks,"Jason D. Lee, Ruoqi Shen, Zhao Song, Mengdi Wang, zheng Yu",Generalized Leverage Score Sampling for Neural Networks ∗,7a22c0c0a4515485e31f95fd372050c9,https://proceedings.neurips.cc/paper/2020/file/7a22c0c0a4515485e31f95fd372050c9-Paper.pdf,"The focus of this paper is purely theoretical, and thus a broader impact discussion is not applicable.",Broader Impact,17,1,TRUE,FALSE,FALSE,FALSE,FALSE,Generalized Leverage Score Sampling for Neural Networks,Algorithms -> Kernel Methods,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Algorithms -> Regression; Deep Learning; Optimization; Theory,Deep learning,"['zheng Yu', ' Ruoqi Shen', ' Zhao Song', ' Jason Lee', ' Mengdi Wang']","{'Princeton University', 'University of Washington', 'IAS/Princeton'}",1,1,1,{'USA'}
An Optimal Elimination Algorithm for Learning a Best Arm,"Avinatan Hassidim, Ron Kupfer, Yaron Singer",An Optimal Elimination Algorithm for Learning a Best Arm,7a43ed4e82d06a1e6b2e88518fb8c2b0,https://proceedings.neurips.cc/paper/2020/file/7a43ed4e82d06a1e6b2e88518fb8c2b0-Paper.pdf,"Learning a best arm is a fundamental, well-studied, problem largely because it captures the most basic experimental question: given n treatments, each with a stochastic outcome, which one is best? Cancer treatment, drug discovery, gene detection, manufacturing quality assurance, financial fraud detection, spam detection, software testing, are all examples of direct applications of learning a best arm. Providing dramatically faster algorithms for these applications without compromising on guarantees will impact areas well outside machine learning. Specifically, this work provides an algorithm that is 6000 times faster than the state-of-the-art. In addition to asymptotic bounds that converge as the number of arms grows to what we conjecture is the optimal sample complexity, we provide dramatic speedups for any number of arms. The result is an extremely efficient simple algorithm for learning a best arm with strong theoretical guarantees that can be used across all applications of learning a best arm. The simplicity and speed of the algorithms presented here are such that any practitioner can implement them and accelerate their experimental setup immediately. We trust that we will see immediate action across a broad set of application domains.",Broader Impact,187,8,,,TRUE,TRUE,FALSE,An Optimal Elimination Algorithm for Learning a Best Arm,Algorithms -> Bandit Algorithms,Algorithms,Theory (including computational and statistical analyses),"['Avinatan Hassidim', ' Ron Kupfer', ' Yaron Singer']","{'Google', 'Harvard University', 'The Hebrew University of Jerusalem'}",1,1,1,"{'USA', 'Israel'}"
Efficient Projection-free Algorithms for Saddle Point Problems,"Cheng Chen, Luo Luo, Weinan Zhang, Yong Yu",Efficient Projection-Free Algorithms for Saddle Point Problems,7a53928fa4dd31e82c6ef826f341daec,https://proceedings.neurips.cc/paper/2020/file/7a53928fa4dd31e82c6ef826f341daec-Paper.pdf,"This paper studies projection-free algorithms for convex-strongly-concave saddle point problems. From a theoretical viewpoint, our method propose the first stochastic projection-free algorithm for saddle point problems without special conditions on the problem. From a practical viewpoint, our method can be applied to many machine learning applications which solve minimax problem with complicated constraints, e.g. robust optimization, matrix completion, two-player games and much more.",Broader Impact,63,3,,,FALSE,FALSE,FALSE,Efficient Projection-free Algorithms for Saddle Point Problems,Optimization -> Non-Convex Optimization,,Optimization Methods (continuous or discrete),"['Cheng Chen', ' Luo Luo', ' Weinan Zhang', ' Yong Yu']","{'Shanghai Jiao Tong Unviersity', 'Shanghai Jiao Tong University', 'The Hong Kong University of Science and Technology'}",1,0,0,{'China'}
A mathematical model for automatic differentiation in machine learning,"Jérôme Bolte, Edouard Pauwels",A mathematical model for automatic differentiation in machine learning,7a674153c63cff1ad7f0e261c369ab2c,https://proceedings.neurips.cc/paper/2020/file/7a674153c63cff1ad7f0e261c369ab2c-Paper.pdf,"One of the goals of the paper is to raise awareness about an important issue of in the training of ML methods: the spuriousness of AD. To address adequately this issue, we think it is necessary to include algorithmic differentiation explicitly in the study of optimization algorithms, a point of view which is largely ignored by today’s machine learning community.",Broader impact,60,2,FALSE,FALSE,FALSE,FALSE,FALSE,A mathematical model for automatic differentiation in machine learning,Optimization,Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Optimization for Deep Networks; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Theory (including computational and statistical analyses),"['Jérôme Bolte', ' Edouard Pauwels']","{'Université Toulouse 1', 'IRIT'}",1,0,0,{'France'}
Unsupervised Text Generation by Learning from Search,"Jingjing Li, Zichao Li, Lili Mou, Xin Jiang, Michael Lyu, Irwin King",Unsupervised Text Generation by Learning from Search,7a677bb4477ae2dd371add568dd19e23,https://proceedings.neurips.cc/paper/2020/file/7a677bb4477ae2dd371add568dd19e23-Paper.pdf,"Our TGLS is a new framework of search and learning for natural language processing (NLP) applications. Typically, an NLP application is different from an agent-based reinforcement learning (RL) setting, as our “environment” is fixed. Previous work in NLP usually uses the REINFORCE algorithm, which introduces much noise and is inefficient because actions are sampled from its policy. Imitation learning (IL), another framework for search and learning, is successful in various NLP structured prediction tasks, but requires expert demonstrations (i.e., groundtruth). Our work alleviates the drawbacks of RL and IL by injecting a strong search algorithm in the search-and-learning loop. With the success in paraphrasing and text formalization in our paper, we expect TGLS would be potentially applicable to other NLP tasks. For social aspects, the unsupervised nature of TGLS would have the following potential impact. • Reducing human annotation labors. Most text generation approaches need parallel data for supervised training, which oftentimes in turn requires human annotation. Our TGLS does not rely on annotated parallel data. Experiments show that TGLS largely reduces the performance gap between supervised and unsupervised text generation, sometimes even comparable to recent supervised models. This reduces the need of human annotation in the research and application of text generation. • Helping low-resource language processing. Previous text generation studies hardly tackle low-resource language, due to the lack of parallel corpora. Our unsupervised TGLS is easily applicable to low-resource language, thus benefiting people from different cultures speaking different languages. • Supporting small businesses and new applications. Small businesses, different from a large company, may not have enough human and financial resources to annotate large-scale corpora. They may apply our unsupervised TGLS as a starting point for a new project, or even a new application.",6 Broader Impact,286,18,,,TRUE,TRUE,FALSE,Unsupervised Text Generation by Learning from Search,Applications -> Natural Language Processing,,Natural language processing,,"{'The Chinese University of Hong Kong', 'University of Alberta', 'CUHK', 'Chinese University of Hong Kong'}",1,0,0,"{'Canada', 'China'}"
Learning Compositional Rules via Neural Program Synthesis,"Maxwell Nye, Armando Solar-Lezama, Josh Tenenbaum, Brenden M. Lake",Learning Compositional Rules via Neural Program Synthesis,7a685d9edd95508471a9d3d6fcace432,https://proceedings.neurips.cc/paper/2020/file/7a685d9edd95508471a9d3d6fcace432-Paper.pdf,"Our approach involves using program synthesis to learn explicit rule systems from just a few examples. Compared to pure neural approaches, we expect that our approach has two main advantages: robustness and interpretability. Because our approach combines a neural ""proposer"" and a symbolic ""checker"", when neural inference fails, the symbolic checker can determine if the proposed program satisfies the given examples. Because the representation produced by our model is a symbolic program, it is also more interpretable than pure neural approaches; when mistakes are made, the incorrect program can be analyzed in order to understand the error. We conjecture that, if systems such as these are used in industrial or consumer settings, these interpretability and robustness features could lead to better safety and security. We hesitate to speculate on the long-term effects of such a research program, but we do not foresee certain groups of people being selectively advantaged.",Broader Impact,149,6,,,FALSE,FALSE,FALSE,Learning Compositional Rules via Neural Program Synthesis,Neuroscience and Cognitive Science -> Cognitive Science,Algorithms -> Program Induction; Applications -> Program Understanding and Generation; Neuroscience and Cognitive Science -> Language for Cognitive Science; Neuroscience and Cognitive Science -> Reasoning,Neuroscience and cognitive science,"['Maxwell Nye', 'Lezama', ' Josh Tenenbaum', ' Brenden Lake']","{'MIT', 'New York University'}",1,0,0,{'USA'}
Incorporating BERT into Parallel Sequence Decoding with Adapters,"Junliang Guo, Zhirui Zhang, Linli Xu, Hao-Ran Wei, Boxing Chen, Enhong Chen",Incorporating BERT into Parallel Sequence Decoding with Adapters,7a6a74cbe87bc60030a4bd041dd47b78,https://proceedings.neurips.cc/paper/2020/file/7a6a74cbe87bc60030a4bd041dd47b78-Paper.pdf,"The proposed framework can be seen as a new and general paradigm of designing sequence-to- sequence models by leveraging pre-trained models, which has a wide range of applications not limited to the text generation tasks discussed in the paper, e.g., end-to-end speech/image translation. If proper pre-trained models for the specific task are provided (such as BERT for text or ResNet for images), our framework can then provide a cost-effective solution to leverage them without tuning their massive parameters or re-training them from scratch, which will save lots of resources for researchers who are individual or affiliated with academic institutions. In addition, different from most pre-training approaches which particularly focus on English, our framework works well when dealing with various low-resource languages as shown in the paper, therefore we may help improve the performance of existing low-resource machine translation systems. On the other hand, although we only need to tune the adapters while training, we have to load the whole framework into GPUs, which limits the choices of hyper-parameters because large-scale BERT models will occupy more memory than traditional Transformer models. As a consequence, our framework may not perform as its best on GPUs with limited memory. From a broader perspective, the proposed framework is not free from the risks of automation methods. For example, the model may inherit the biases contained in data. And in our framework, both pre-training and fine-tuning datasets may have biases. Therefore we encourage future works to study how to detect and mitigate similar risks that may arise in our framework.",Broader Impact,255,9,,,FALSE,FALSE,FALSE,Incorporating BERT into Parallel Sequence Decoding with Adapters,Applications -> Natural Language Processing,Algorithms -> Multitask and Transfer Learning; Deep Learning -> Attention Models,Natural language processing,"['Junliang Guo', ' Zhirui Zhang', ' Linli Xu', 'Ran Wei', ' Boxing Chen', ' Enhong Chen']","{'University of Science and Technology of China', 'University of Science and Technology China', 'Alibaba DAMO Academy', 'Alibaba Group'}",1,1,1,{'China'}
Estimating Fluctuations in Neural Representations of Uncertain Environments,"Sahand Farhoodi, Mark Plitt, Lisa Giocomo, Uri Eden",Estimating Fluctuations in Neural Representations of Uncertain Environments,7a8b8402b2f0fc78cf726ee484a0a2b7,https://proceedings.neurips.cc/paper/2020/file/7a8b8402b2f0fc78cf726ee484a0a2b7-Paper.pdf,"Most classical neural coding analyses heavily depend on the simplifying assumptions that neurons respond uniquely and consistently to particular stimuli. Such assumptions may be valid for simple stimuli that are clearly distinguishable, leading to population codes where each neuron provides consistent information about each stimulus across multiple presentations. In such scenarios, we might expect downstream brain regions to decode the represented stimuli in such tasks by averaging the information over a large set of upstream neurons. However, as the class of neuroscience experiments becomes more complicated, and we encounter a higher level of uncertainty in the population code, where subsets of neurons code intermittently for a stimulus based on other uncontrolled factors, new methods that account for moment-by-moment temporal dynamics and the multiple ways in which neural populations can represent information across different stimulus become increasingly important. The resulting analyses may then provide added insight into the ways in which the brain resolves  ambiguous stimuli, or represents specific signals in the face of changing situations and distractions. As neuroscience experiments begin to explore more naturalistic tasks and stimuli, and reflect more ambiguity in neural representations, neural data analysis methods, such as the one presented in this paper, must adapt to reflect these features.",Broader Impact,203,6,,,FALSE,FALSE,FALSE,Estimating Fluctuations in Neural Representations of Uncertain Environments,Neuroscience and Cognitive Science,Neuroscience and Cognitive Science -> Memory; Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Plasticity and Adaptation; Neuroscience and Cognitive Science -> Visual Perception; Probabilistic Methods -> Latent Variable Models,Neuroscience and cognitive science,"['Sahand Farhoodi', ' Mark Plitt', ' Lisa Giocomo', ' Uri Eden']","{'Stanford University', 'Boston University'}",1,0,0,{'USA'}
"Discover, Hallucinate, and Adapt: Open Compound Domain Adaptation for Semantic Segmentation","KwanYong Park, Sanghyun Woo, Inkyu Shin, In So Kweon","Discover, Hallucinate, and Adapt: Open Compound Domain Adaptation for Semantic Segmentation",7a9a322cbe0d06a98667fdc5160dc6f8,https://proceedings.neurips.cc/paper/2020/file/7a9a322cbe0d06a98667fdc5160dc6f8-Paper.pdf,"We investigate the newly presented problem called open compound domain adaptation (OCDA). The problem well reflects the nature of real-world that the target domain often include mixed and novel situations at the same time. The prior work on this OCDA setting mainly focuses on the classification task. Though, we note that extending the classification model to the structured prediction task is non-trivial and requires significant domain-knowledge. In this work, we identify the challenges of OCDA in semantic segmentation and carefully design a new strong baseline model. Specifically, we present three core design principles: Discover, Hallucinate, and Adapt. We empirically show that our proposals are complementary to each other in constructing a strong OCDA model. We provide both the quantitative and qualitative results to show the efficacy of our final model. We hope the proposed new algorithm and its results will drive the research directions to step forward towards generalization in the real-world.",Broader Impact,152,9,,,FALSE,FALSE,FALSE,"Discover, Hallucinate, and Adapt: Open Compound Domain Adaptation for Semantic Segmentation",Algorithms -> Unsupervised Learning,Applications -> Computer Vision; Deep Learning -> Adversarial Networks; Deep Learning -> Generative Models,Vision,"['KwanYong Park', ' Sanghyun Woo', ' Inkyu Shin', ' In So Kweon']","{'Korea Advanced Institute of Science and Technology', 'KAIST'}",1,0,0,{'South Korea'}
"SURF: A Simple, Universal, Robust, Fast Distribution Learning Algorithm","Yi Hao, Ayush Jain, Alon Orlitsky, Vaishakh Ravindrakumar","SURF: A Simple, Universal, Robust, Fast Distribution Learning Algorithm",7ac52e3f2729d1b3f6d2b7e8f6467226,https://proceedings.neurips.cc/paper/2020/file/7ac52e3f2729d1b3f6d2b7e8f6467226-Paper.pdf,"SURF is a simple, universal, robust, and fast algorithm for the important problem of estimating distributions by piecewise polynomials. Real-life applications are likely to be approximated by relatively low-degree polynomials and require fast algorithms. SURF is particularly well-suited for these regimes.",Broader Impact,41,3,FALSE,FALSE,FALSE,FALSE,FALSE,"SURF: A Simple, Universal, Robust, Fast Distribution Learning Algorithm",Theory -> Statistical Learning Theory,Theory -> Computational Learning Theory; Theory -> Information Theory,Theory (including computational and statistical analyses),"['Yi Hao', ' Ayush Jain', ' Alon Orlitsky', ' Vaishakh Ravindrakumar']","{'UC San Diego', 'University of California, San Diego'}",1,0,0,{'USA'}
Understanding Approximate Fisher Information for Fast Convergence of Natural Gradient Descent in Wide Neural Networks,"Ryo Karakida, Kazuki Osawa",Understanding Approximate Fisher Information for Fast Convergence of Natural Gradient Descent in Wide Neural Networks,7b41bfa5085806dfa24b8c9de0ce567f,https://proceedings.neurips.cc/paper/2020/file/7b41bfa5085806dfa24b8c9de0ce567f-Paper.pdf,We believe that this section is not applicable to this paper.,Broader Impact,11,1,TRUE,FALSE,FALSE,FALSE,FALSE,Understanding Approximate Fisher Information for Fast Convergence of Natural Gradient Descent in Wide Neural Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Models of Learning and Generalization ; Theory -> Statistical Physics of Learning,,"['Ryo Karakida', ' Kazuki Osawa']","{'National Institute of Advanced Industrial Science and Technology', 'Tokyo Institute of Technology'}",1,0,0,{'Japan'}
General Transportability of Soft Interventions: Completeness Results,"Juan Correa, Elias Bareinboim",General Transportability of Soft Interventions: Completeness Results,7b497aa1b2a83ec63d1777a88676b0c2,https://proceedings.neurips.cc/paper/2020/file/7b497aa1b2a83ec63d1777a88676b0c2-Paper.pdf,"Our work investigates the formal conditions under which knowledge acquired in one domain (e.g., setting, population, environment) can be generalized to a different one that may be related, but is unlikely to be the same. This is known in the causal inference literature as the problem of ""transportability."" As alluded to in the introduction, issues of transportability are pervasive throughout the empirical sciences as well as AI and ML. We believe that having a more foundational tool that allows the empirical investigator to determine whether (and how) her/his understanding of the underlying system is sufficient to support the generalization of an empirical claim is a critical addition to the scientific toolbox. Not having such a tool, on the other hand, may lead researchers to operate on a more heuristical basis, which may lead to a lack of understanding of when things can go wrong and how to fix them. For instance, public policies that will fail or have unintended consequences, potentially harming people, or spending unnecessary societal resources. In the context of automated decision-making in AI, we could have systems following policies that harm the users, can act unfairly, or discriminate against certain groups (e.g., the policy was trained in Scandinavia and moved to the US). By and large, we believe this research on the theory of generalization of policies based on soft interventions can benefit a large group of individuals, including empirical scientists, policy-makers, AI researchers, and society in general.",Broader Impact,241,8,,,FALSE,FALSE,FALSE,General Transportability of Soft Interventions: Completeness Results,Probabilistic Methods -> Causal Inference,Probabilistic Methods -> Graphical Models,Causality,"['Juan Correa', ' Elias Bareinboim']",{'Columbia University'},1,0,0,{'USA'}
GAIT-prop: A biologically plausible learning rule derived from backpropagation of error,"Nasir Ahmad, Marcel A. J. van Gerven, Luca Ambrogioni",GAIT-prop: A biologically plausible learning rule derived from backpropagation of error,7ba0691b7777b6581397456412a41390,https://proceedings.neurips.cc/paper/2020/file/7ba0691b7777b6581397456412a41390-Paper.pdf,"This research positively impacts discourse and research into relevant scientific sub-disciplines (in- cluding machine learning, computational neuroscience, and neuromorphic computing). Its continued development could lead to algorithms for learning in neuromorphic computing devices, and insights into the nature of credit assignment in biological neural systems. Beyond research and development, this work alone has no broader societal or ethical impact.",Broader impact,59,3,FALSE,TRUE,FALSE,FALSE,FALSE,GAIT-prop: A biologically plausible learning rule derived from backpropagation of error,Deep Learning,Deep Learning -> Biologically Plausible Deep Networks,Neuroscience and cognitive science,"['Nasir Ahmad', ' van Gerven', ' Luca Ambrogioni']","{'Radboud Universiteit', 'Donders Institute for Brain, Cognition and Behaviour, Radboud University', 'Radboud University'}",1,0,0,{'Netherlands'}
Lipschitz Bounds and Provably Robust Training by Laplacian Smoothing,"Vishaal Krishnan, Abed AlRahman Al Makdah, Fabio Pasqualetti",Lipschitz Bounds and Provably Robust Training by Laplacian Smoothing,7bab7650be60b0738e22c3b8745f937d,https://proceedings.neurips.cc/paper/2020/file/7bab7650be60b0738e22c3b8745f937d-Paper.pdf,"This paper is primarily of a theoretical nature. We expect our findings to impact the development of a formal theory of adversarially robust learning. Furthermore, we expect the proposed robust training schemes to contribute to efforts in adversarially robust graph-based learning. However, we do not envision any immediate application of our results to a societally relevant problem.",6 Broader impact,57,4,TRUE,FALSE,FALSE,FALSE,FALSE,Lipschitz Bounds and Provably Robust Training by Laplacian Smoothing,Algorithms -> Adversarial Learning,Optimization -> Convex Optimization; Theory -> Models of Learning and Generalization ; Theory -> Regularization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Vishaal Krishnan', ' Abed AlRahman Al Makdah', ' Fabio Pasqualetti']","{'University of California, Riverside'}",1,0,0,{'USA'}
SCOP: Scientific Control for Reliable Neural Network Pruning,"Yehui Tang, Yunhe Wang, Yixing Xu, Dacheng Tao, Chunjing XU, Chao Xu, Chang Xu",SCOP: Scientific Control for Reliable Neural Network Pruning,7bcdf75ad237b8e02e301f4091fb6bc8,https://proceedings.neurips.cc/paper/2020/file/7bcdf75ad237b8e02e301f4091fb6bc8-Paper.pdf,"Network pruning is an effective model compression strategy to accelerate the inference of deep neural networks and reduce their memory requirement. It greatly promotes the deployment of deep neural networks on the massive edge devices such as mobile phones and wearable gadgets [24]. Even on a cheap device with limited computer capability, powerful models can still work well with the proposed pruning method. It lowers the barrier of the application of artificial intelligence and provides convenience to our works and lives.",Broader Impact,81,4,,,FALSE,FALSE,FALSE,SCOP: Scientific Control for Reliable Neural Network Pruning,Deep Learning,Algorithms -> Classification; Deep Learning -> CNN Architectures; Deep Learning -> Efficient Inference Methods; Deep Learning -> Optimization for Deep Networks,Deep learning,,"{'Huawei Technologies', 'University of Sydney', 'Peking University'}",1,1,1,"{'Australia', 'China'}"
Provably Consistent Partial-Label Learning,"Lei Feng, Jiaqi Lv, Bo Han, Miao Xu, Gang Niu, Xin Geng, Bo An, Masashi Sugiyama",Provably Consistent Partial-Label Learning,7bd28f15a49d5e5848d6ec70e584e625,https://proceedings.neurips.cc/paper/2020/file/7bd28f15a49d5e5848d6ec70e584e625-Paper.pdf,"A potential application of our proposed partial-label learning methods would be data privacy. For example, when we collect some survey data, we may ask respondents to answer some extremely private questions. It would be difficult for us to directly obtain the ground-truth answer (label) to the question. However, it would be easier for us to obtain a set of candidate labels that contains the true label, since it is mentally less demanding for respondents to remove several obviously wrong labels. In this case, our proposed partial-label learning methods can be used. There may also exist some negative impacts of our proposed methods. For example, an adversary might deliberately ask a person to give some candidate choices or remove some improper choices to specially designed questions, so that high-quality partially labeled data could be collected. The adversary may apply the proposed partial-label learning methods to learn from the collected partially labeled data. As a consequence, some extremely private data of the person would be divulged or leveraged by the adversary. In addition, if partial-label learning methods are very effective and prevalent, the need for accurately annotated data would be significantly reduced. As a result, the rate of unemployment for data annotation specialists might be increased.",Broader Impact,204,11,,,FALSE,FALSE,FALSE,Provably Consistent Partial-Label Learning,Algorithms -> Semi-Supervised Learning,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Lei Feng', ' Jiaqi Lv', ' Bo Han', ' Miao Xu', ' Gang Niu', ' Xin Geng', ' Bo An', ' Masashi Sugiyama']","{'RIKEN / University of Tokyo', 'RIKEN', 'Nanyang Technological University', 'HKBU / RIKEN', 'RIKEN AIP', 'Southeast University'}",1,0,0,"{'Japan', 'Singapore', 'China'}"
"Robust, Accurate Stochastic Optimization for Variational Inference","Akash Kumar Dhaka, Alejandro Catalina, Michael R. Andersen, Måns Magnusson, Jonathan Huggins, Aki Vehtari","Robust, Accurate Stochastic Optimization for Variational Inference",7cac11e2f46ed46c339ec3d569853759,https://proceedings.neurips.cc/paper/2020/file/7cac11e2f46ed46c339ec3d569853759-Paper.pdf,"There are sometimes misconceptions about how fast or accurate variational inference can be for Bayesian inference. In this paper, we show potential pitfalls of current practices that may lead to incorrect conclusions, especially when the interest of the user is more focused on inference than prediction. More robust and reliable inference makes data analysis for decision-making by scientists and organizations (e.g., corporations, governments, and foundations) more reliable and reproducible.  Whether such improvements in decision-making quality lead to better outcomes for society will depend upon the goals of the organization or person. On net, however, we expect more reliable data analysis to be for the good.",Broader impact,105,5,,,FALSE,FALSE,FALSE,"Robust, Accurate Stochastic Optimization for Variational Inference",Probabilistic Methods -> Variational Inference,Probabilistic Methods -> Hierarchical Models; Probabilistic Methods -> Probabilistic Programming,Probabilistic methods and inference,"['Akash Kumar Dhaka', ' Alejandro Catalina', ' Michael Andersen', ' Måns Magnusson', ' Jonathan Huggins', ' Aki Vehtari']","{'Aalto University', 'Boston University'}",1,0,0,"{'Finland', 'USA'}"
Discovering conflicting groups in signed networks,"Ruo-Chun Tzeng, Bruno Ordozgoiti, Aristides Gionis",Discovering conflicting groups in signed networks,7cc538b1337957dae283c30ad46def38,https://proceedings.neurips.cc/paper/2020/file/7cc538b1337957dae283c30ad46def38-Paper.pdf,"As the task we tackle in this paper belongs to the broad category of data mining, and as our study is mainly of theoretical nature, the impact of our work to the society is indirect. With respect to positive consequences, we name two possible applications that could impact the modern society. First, the rise of polarization and fake news is related to the existence of conflicting groups. Thus, having an efficient characterization tool is the first step to mitigate the situation. Second, both collaboration and competition exist in a diverse environment and detecting conflicting groups helps to understand the interplay of the two. With respect to negative consequences, we do not foresee specific issues when applying our method.",Broader Impact,118,6,,,FALSE,FALSE,FALSE,Discovering conflicting groups in signed networks,Algorithms -> Spectral Methods,Algorithms -> Unsupervised Learning; Applications -> Network Analysis,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Chun Tzeng', ' Bruno Ordozgoiti', ' Aristides Gionis']","{'Aalto University', 'KTH', 'KTH Royal Institute of Technology'}",1,0,0,"{'Finland', 'Sweden'}"
Learning Some Popular Gaussian Graphical Models without Condition Number Bounds,"Jonathan Kelner, Frederic Koehler, Raghu Meka, Ankur Moitra",Learning Some Popular Gaussian Graphical Models without Condition Number Bounds,7cc980b0f894bd0cf05c37c246f215f3,https://proceedings.neurips.cc/paper/2020/file/7cc980b0f894bd0cf05c37c246f215f3-Paper.pdf,"We expect our work will be most useful to theorists and practitioners interested in learning graphical models from data and related problems; for example, we hope it will raise awareness that the output of GGM learning algorithms commonly used in practice can be misleading when the data is poorly conditioned. As we established in our paper, our methods provably succeed for a subset of ill- conditioned GGMs but there remain other situations where even these methods (as well as all other popular approaches) fail. As with other linear models and machine learning tools, the algorithm can fit biases in the data. For this reason it remains necessary for practitioners to apply due diligence when interpreting the results of this, or any other, GGM learning algorithm.",Broader Impact,125,4,,,FALSE,FALSE,FALSE,Learning Some Popular Gaussian Graphical Models without Condition Number Bounds,Theory -> Computational Learning Theory,Algorithms -> Unsupervised Learning; Probabilistic Methods -> Graphical Models,,"['Jonathan Kelner', ' Frederic Koehler', ' Raghu Meka', ' Ankur Moitra']","{'UCLA', 'MIT'}",1,0,0,{'USA'}
Sense and Sensitivity Analysis: Simple Post-Hoc Analysis of Bias Due to Unobserved Confounding,"Victor Veitch, Anisha Zaveri",Sense and Sensitivity Analysis: Simple Post-Hoc Analysis of Bias Due to Unobserved Confounding,7d265aa7147bd3913fb84c7963a209d1,https://proceedings.neurips.cc/paper/2020/file/7d265aa7147bd3913fb84c7963a209d1-Paper.pdf,"This paper addressed sensitivity analysis for causal inference. We have extended Imbens’ approach to allow the use of arbitrary machine-learning methods for the data modeling. Austen plots provide an entirely post-hoc and blackbox manner of conducting sensitivity analysis. In particular, they make it substantially simpler to perform sensitivity analysis. This is because the initial analysis can be performed without have a sensitivty analysis already in mind, and because producing the sensitivity plots only requires predictions from models that the practitioner has fit anyways. The ideal positive consequence is that routine use of Austen plots will improve the credibility of machine-learning based causal inferences from observational data. Austen plots allow us to both use state-of-the-art models for the observed part of the data, and to reason coherently about the causal effects of potential unobserved confounders. The availability of such a tool may speed the adoption of machine-learning based causal inference for important real-world applications (where, so far, adoption has been slow). On the negative side, an accelerated adoption of machine-learning methods into causal practice may be undesirable. This is simply because the standards of evidence and evaluation used in common machine-learning practice do not fully reflect the needs of causal practice. Austen plots partially bridge this gap, but they just one of the elements required to establish credibility.",Societal Consequences ,217,11,,,TRUE,TRUE,FALSE,Sense and Sensitivity Analysis: Simple Post-Hoc Analysis of Bias Due to Unobserved Confounding,Probabilistic Methods -> Causal Inference,,Causality,"['Victor Veitch', ' Anisha Zaveri']","{'Columbia University', 'Weill Cornell Medicine'}",1,0,0,{'USA'}
Mix and Match: An Optimistic Tree-Search Approach for Learning Models from Mixture Distributions,"Matthew Faw, Rajat Sen, Karthikeyan Shanmugam, Constantine Caramanis, Sanjay Shakkottai",Mix and Match: An Optimistic Tree-Search Approach for Learning Models from Mixture Distributions,7d3d5bcad324d3edc08e40738e663554,https://proceedings.neurips.cc/paper/2020/file/7d3d5bcad324d3edc08e40738e663554-Paper.pdf,"This work addresses the problem of using abundant training data from several domains, along with a limited amount of data from a new, related domain, to train effective models for this new domain. As we discussed in the introduction, a natural motivation for this setup is that a company wants to make predictions on a new population, but most data available at training time is not drawn from this target distribution. Our focus in this work is primarily theoretical – we design an algorithm that can provably succeed at training a good model for the target distribution. As such, one should be cautious when using the ideas from this paper in settings where humans are impacted and our assumptions cannot be verified. Indeed, biases present in training data could lead to unwanted biases in the resulting model, and our results do not have known provable guarantees when training complex neural networks as is often done in practice. However, we hope the ideas presented in this paper, and in particular, the ideas of model reuse for efficient mixture search, serve as useful starting points for deploying such models in real-world settings.",Broader Impact,190,6,,,FALSE,FALSE,FALSE,Mix and Match: An Optimistic Tree-Search Approach for Learning Models from Mixture Distributions,Algorithms -> Bandit Algorithms,Optimization -> Convex Optimization,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Matthew Faw', ' Rajat Sen', ' Karthikeyan Shanmugam', ' Constantine Caramanis', ' Sanjay Shakkottai']","{'UT Austin', 'IBM Research, NY', 'Amazon', 'University of Texas at Austin'}",1,1,1,{'USA'}
Understanding Double Descent Requires A Fine-Grained Bias-Variance Decomposition,"Ben Adlam, Jeffrey Pennington",Understanding Double Descent Requires a Fine-Grained Bias-Variance Decomposition,7d420e2b2939762031eed0447a9be19f,https://proceedings.neurips.cc/paper/2020/file/7d420e2b2939762031eed0447a9be19f-Paper.pdf,"While it is hard to envision all future applications of this research, the authors do not believe this theoretical work will raise any ethical concerns or will generate any adverse future societal consequences.",Broader Impact,33,1,TRUE,FALSE,FALSE,FALSE,FALSE,Understanding Double Descent Requires A Fine-Grained Bias-Variance Decomposition,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Kernel Methods; Theory -> Large Deviations and Asymptotic Analysis; Theory -> Statistical Physics of Learning,Theory (including computational and statistical analyses),"['Ben Adlam', ' Jeffrey Pennington']","{'Google', 'Google Brain'}",0,1,0,{'USA'}
VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,"Jinsung Yoon, Yao Zhang, James Jordon, Mihaela van der Schaar",VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,7d97667a3e056acab9aaf653807b4a03,https://proceedings.neurips.cc/paper/2020/file/7d97667a3e056acab9aaf653807b4a03-Paper.pdf,"Tabular data is the most common data type in the real-world. Most databases include tabular data such as demographic information in medical and finance datasets and SNPs in genomic datasets. However, the tremendous successes in deep learning (especially in image and language domains) has not yet been fully extended to the tabular domain. Still, in the tabular domain, ensembles of decision trees achieve the state-of-the-art performance. If we can efficiently extend the successful deep learning methodologies from images and language to tabular data, the application of machine learning in the real-world can be greatly extended. This paper takes a step in this direction for self- and semi-supervised learning frameworks which recently have achieved significant successes in images and language. In addition, the proposed tabular data augmentation and representation learning methodologies can be utilized in various fields such as tabular data encoding, balancing the labels of tabular data, and missing data imputation.",Broader Impact,151,7,,,FALSE,FALSE,FALSE,VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain,Algorithms -> Unsupervised Learning,Algorithms -> Semi-Supervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jinsung Yoon', ' Yao Zhang', ' James Jordon', ' Mihaela van der Schaar']","{'University of Cambridge', 'University of California, Los Angeles', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
The Smoothed Possibility of Social Choice,Lirong Xia,The Smoothed Possibility of Social Choice,7e05d6f828574fbc975a896b25bb011e,https://proceedings.neurips.cc/paper/2020/file/7e05d6f828574fbc975a896b25bb011e-Paper.pdf,"In this paper we aim to provide smoothed possibilities of social choice, which is an important prob- lem in the society. Therefore, success of the research will benefit general public beyond the CS research community because better solutions are now available for a wide range of group decision- making scenarios.",Broader Impact,50,2,FALSE,FALSE,FALSE,FALSE,FALSE,The Smoothed Possibility of Social Choice,Theory -> Game Theory and Computational Economics,,Theory (including computational and statistical analyses),['Lirong Xia'],{'RPI'},1,0,0,{'USA'}
A Decentralized Parallel Algorithm for Training Generative Adversarial Nets,"Mingrui Liu, Wei Zhang, Youssef Mroueh, Xiaodong Cui, Jarret Ross, Tianbao Yang, Payel Das",A Decentralized Parallel Algorithm for Training Generative Adversarial Nets,7e0a0209b929d097bd3e8ef30567a5c1,https://proceedings.neurips.cc/paper/2020/file/7e0a0209b929d097bd3e8ef30567a5c1-Paper.pdf,"In this paper, researchers introduce a decentralized parallel algorithm for training Generative Adver- sarial Nets (GANs). The proposed scheme can be proved to have a non-asymptotic convergence to first-order stationary points in theory, and outperforms centralized counterpart in practice. Our proposed decentralized algorithm is a class of foundational research, since the algorithm design and analysis are proposed for a general class of nonconvex-nonconcave min-max problems and not necessarily restricted for training GANs. Both the algorithm design and the proof techniques are novel, and it may inspire future research along this direction. Our decentralized algorithm has broader impacts in a variety of machine learning tasks beyond GAN training. For example, our algorithm is promising in other machine learning problems whose objective function has a min-max structure, such as adversarial training [92], robust machine learning [93], etc. Our decentralized algorithm can be applied in several real-world applications such as image-to-image generation [94], text-to-image generation [95], face aging [96], photo inpainting [97], dialogue systems [98], etc. In all these applications, GAN training is an indispensable backbone. Training GANs in these applications usually requires to leverage centralized large batch distributed training which could suffer from inefficiency in terms of run-time, and our algorithm is able to address this issue by drastically reducing the running time in the whole training process. These real-world applications have a broad societal implications. First, it can greatly help people’s daily life. For example, many companies provide online service, where an AI chatbot is usually utilized to answer customer’s questions. However, the existing chatbot may not be able to fully understand customer’s question and its response is usually not good enough. One can adopt our decentralized algorithms to efficiently train a generative adversarial network based on the human-to- human chatting history, and the learned model is expected to answer customer’s questions in a better manner. This system can help customers and significantly enhance users’ satisfaction. Second, it can help protect users’ privacy. One benefit of decentralized algorithms is that it does not need the central node to collect all users’ information and every node only communicates with its trusted neighbors. In this case, our proposed decentralized algorithms naturally preserve users’ privacy. We encourage researchers to further investigate the merits and shortcomings of our proposed approach. In particular, we recommend researchers to design new algorithms for training GANs with faster convergence guarantees.",Broader Impact,391,20,,,FALSE,FALSE,FALSE,A Decentralized Parallel Algorithm for Training Generative Adversarial Nets,Optimization,Deep Learning; Deep Learning -> Generative Models; Deep Learning -> Optimization for Deep Networks; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Mingrui Liu', ' Wei Zhang', ' Youssef Mroueh', ' Xiaodong Cui', ' Jarret Ross', ' Tianbao Yang', ' Payel Das']","{'The University of Iowa', 'IBM Research', 'Boston University', 'IBM'}",1,1,1,{'USA'}
Phase retrieval in high dimensions: Statistical and computational phase transitions,"Antoine Maillard, Bruno Loureiro, Florent Krzakala, Lenka Zdeborová",Phase retrieval in high dimensions: Statistical and computational phase transitions,7ec0dbeee45813422897e04ad8424a5e,https://proceedings.neurips.cc/paper/2020/file/7ec0dbeee45813422897e04ad8424a5e-Paper.pdf,"Our work is theoretical in nature, and as such its potential societal consequences are difficult to foresee. We however anticipate that deeper theoretical understanding of the functioning of machine learning systems will lead to better anticipation of such societal consequences in the long term.",Broader Impact,44,2,TRUE,TRUE,FALSE,FALSE,FALSE,Phase retrieval in high dimensions: Statistical and computational phase transitions,Theory -> High-Dimensional Inference,Theory -> Hardness of Learning and Approximations; Theory -> Information Theory; Theory -> Large Deviations and Asymptotic Analysis; Theory -> Statistical Learning Theory; Theory -> Statistical Physics of Learning,Theory (including computational and statistical analyses),"['Antoine Maillard', ' Bruno Loureiro', ' Florent Krzakala', ' Lenka Zdeborová']","{'Ecole Normale Supérieure', 'CEA Saclay', 'IPhT Saclay'}",1,0,0,{'France'}
Fair Performance Metric Elicitation,"Gaurush Hiranandani, Harikrishna Narasimhan, Oluwasanmi O. Koyejo",Fair Performance Metric Elicitation,7ec2442aa04c157590b2fa1a7d093a33,https://proceedings.neurips.cc/paper/2020/file/7ec2442aa04c157590b2fa1a7d093a33-Paper.pdf,"Machine Learning community has constructed many methods that create bias-free classifiers; however, it has been long accepted that fairness is not only an algorithmic concept but a societal one [53, 10]. So machine learning systems cannot presume how policymakers would like to handle fairness but have to elicit fairness criteria from them. Thus our primary contribution is a framework for selecting metrics that can be tuned to expert panel preferences and are designed to measure intrinsic fairness tradeoffs. We hope that by eliciting metrics, algorithmic fairness can be better tuned to the tradeoffs of stakeholders, or be used to compare preferences of different possible stakeholders. This paper seeks to truly democratize and personalize fair machine learning. Besides, the significance of fair performance metric elicitation lies in how it empowers the practitioner to tune the design of machine learning models to the needs of the target fairness task. The ‘transportability’ aspect of the proposed procedure is crucial here since it allows practitioners to elicit metrics using any estimated distribution, perhaps from simple model class, and then use the elicited fair metric for optimizing complex models or evaluating models in test time for the target fairness task. At the same time, this work may have drawbacks because it leaves open the key question of who should be the stakeholders to be queried. This work also assumes a parametric form for the oracle metric, which may not be an exact match to practice. Furthermore, we should be cautious of the result of the failure of the system which could cause disparate impact among sensitive groups when the elicited metric is incorrect, e.g., when applied to settings where the stated assumptions are not met.",Broader Impact,280,10,,,FALSE,TRUE,FALSE,Fair Performance Metric Elicitation,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Active Learning; Algorithms -> Classification; Algorithms -> Ranking and Preference Learning; Theory -> Statistical Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Gaurush Hiranandani', ' Harikrishna Narasimhan', ' Oluwasanmi Koyejo']","{'UIUC', 'University of Illinois at Urbana-Champaign', 'Google Research'}",1,1,1,{'USA'}
Hybrid Variance-Reduced SGD Algorithms For Minimax Problems with Nonconvex-Linear Function,"Quoc Tran Dinh, Deyi Liu, Lam Nguyen",Hybrid Variance-Reduced SGD Algorithms For Minimax Problems with Nonconvex-Linear Function,7f141cf8e7136ce8701dc6636c2a6fe4,https://proceedings.neurips.cc/paper/2020/file/7f141cf8e7136ce8701dc6636c2a6fe4-Paper.pdf,"This work could potentially have positive impact in different fields where nonconvex-concave minimax and nonconvex compositional optimization models as (1) and (2) are used. For instance, robust learning, distributionally robust optimization, zero-sum game, and generative adversarial nets (GANs) applications are concrete examples under certain settings. We emphasize that the nonconvex-concave minimax problem (1) studied in this paper remains challenging to solve for global solutions. Existing methods can only find an approximate KKT (Karush-Kuhn-Tucker) point in general. This paper proposed new algorithms to tackle a class of nonconvex-concave minimax problems, but they can only guarantee to find an approximate KKT point, which may not be an approximate global solution of the model. This could lead to a negative impact if one expects to find an approximate global solution instead of an approximate KKT point without further investigation. Apart from the above impact, since this paper is a theoretical work, it does not present any other foreseeable societal consequence.",6 Broader Impact,157,7,FALSE,FALSE,FALSE,FALSE,FALSE,Hybrid Variance-Reduced SGD Algorithms For Minimax Problems with Nonconvex-Linear Function,Optimization -> Non-Convex Optimization,Optimization -> Stochastic Optimization; Theory -> Game Theory and Computational Economics,,"['Quoc Tran Dinh', ' Deyi Liu', ' Lam Nguyen']","{'Department of Statistics and Operations Research, University of North Carolina at Chapel Hill, North Carolina', 'IBM Research, Thomas J. Watson Research Center', 'University of North Carolina'}",1,1,1,{'USA'}
Belief-Dependent Macro-Action Discovery in POMDPs using the Value of Information,"Genevieve Flaspohler, Nicholas A. Roy, John W. Fisher III",Belief-Dependent Macro-Action Discovery in POMDPs using the Value of Information,7f2be1b45d278ac18804b79207a24c53,https://proceedings.neurips.cc/paper/2020/file/7f2be1b45d278ac18804b79207a24c53-Paper.pdf,"Decision-making problems are ubiquitous, arising in applications such as tracking an oil spill using a marine robot, selecting an effective drug schedule in personalized medicine, or allocating irrigation resources based on seasonal weather forecasts. In each of these important application areas, system dynamics are represented by complex and potentially learned models and the decision-making agent can only observe the state through limited sensors. Many current planning and reinforcement learning algorithms focus on fully-observable domains and generate learned policies without performance guarantees. However, uncertainty and formal guarantees must play a role in robust decision-making for high-stakes domains. VoI macro-action generation contributes to fundamental research in robust and efficient model-based planning under uncertainty. As with all formal results, however, the bounds we derive only hold under the assumptions that we describe in the text. When performing decision-making in high-stakes applications, understanding these conditions, the extent to which they hold, and how algorithm performance degrades as assumptions are violated is critical.",Broader Impact,158,7,,,FALSE,FALSE,FALSE,Belief-Dependent Macro-Action Discovery in POMDPs using the Value of Information,Reinforcement Learning and Planning -> Planning,Applications -> Robotics; Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Markov Decision Processes,,"['Genevieve E Flaspohler', ' Nicholas Roy', ' John W Fisher III']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Soft Contrastive Learning for Visual Localization,"Janine Thoma, Danda Pani Paudel, Luc V. Gool",Soft Contrastive Learning for Visual Localization,7f2cba89a7116c7c6b0a769572d5fad9,https://proceedings.neurips.cc/paper/2020/file/7f2cba89a7116c7c6b0a769572d5fad9-Paper.pdf,"This paper addresses the topic of retrieval-based visual localization. We present a formal problem statement and derive improved loss function variations for feature learning. While we are making our source code and data publicly available, we do not consider them to be a finished product. Any potential benefits and disadvantages depend on how people choose to use our method and on how they are handling failure cases. E.g. one obvious application of retrieval-based visual localization— pedestrian navigation—clearly benefits its users: they find their destination more easily. A negligently or maliciously implemented navigation solution, however, could also lead people astray. Similarly, if our method is used in conjunction with a structure-based method for autonomous driving or robot navigation, it mostly leads to positive outcomes (e.g. increased safety and efficiency) as long as failure cases are handled properly and robots are not used for unethical tasks. To summarize, our method by itself does not have any direct negative ethical or social consequences. If it is integrated into a product, it is the quality and intention of the product that determines the broader impact.  The images used for training our networks were taken in Oxford. It is therefore to be expected that—if someone chooses to use our pre-trained models—they will work best in Oxford or similar places. The underling theoretical formulation and loss functions, however, are entirely location-agnostic.",Broader Impact,225,13,,,FALSE,FALSE,FALSE,Soft Contrastive Learning for Visual Localization,Algorithms -> Metric Learning,Algorithms -> Similarity and Distance Learning; Applications -> Computer Vision; Deep Learning -> Embedding Approaches,Vision,"['Janine Thoma', ' Danda Pani Paudel', ' Luc V Gool']","{'ETH Zurich', 'ETH Zürich', 'Computer Vision Lab, ETH Zurich'}",1,0,0,{'Switzerland'}
Fine-Grained Dynamic Head for Object Detection,"Lin Song, Yanwei Li, Zhengkai Jiang, Zeming Li, Hongbin Sun, Jian Sun, Nanning Zheng",Fine-Grained Dynamic Head for Object Detection,7f6caf1f0ba788cd7953d817724c2b6e,https://proceedings.neurips.cc/paper/2020/file/7f6caf1f0ba788cd7953d817724c2b6e-Paper.pdf,"Object detection is a fundamental task in the computer vision domain, which has already been applied to a wide range of practical applications. For instance, face recognition, robotics and autonomous driving heavily rely on object detection. Our method provides a new dimension for object detection by utilizing the fine-grained dynamic routing mechanism to improve performance and maintain low computational cost. Compared with hand-crafted or searched methods, ours does not need much time for manual design or machine search. Besides, the design philosophy of our fine-grained dynamic head could be further extended to many other computer vision tasks, e.g. , segmentation and video analysis.",Broader Impact,103,5,,,FALSE,FALSE,FALSE,Fine-Grained Dynamic Head for Object Detection,Applications -> Object Detection,,Vision,"['Lin Song', ' Yanwei Li', ' Zhengkai Jiang', ' Zeming Li', ' Hongbin Sun', ' Jian Sun', ' Nanning Zheng']",{'The Chinese University of Hong Kong'},1,0,0,{'China'}
LoCo: Local Contrastive Representation Learning,"Yuwen Xiong, Mengye Ren, Raquel Urtasun",LoCo: Local Contrastive Representation Learning,7fa215c9efebb3811a7ef58409907899,https://proceedings.neurips.cc/paper/2020/file/7fa215c9efebb3811a7ef58409907899-Paper.pdf,"Our work aims to make deep unsupervised representation learning more biologically plausible by removing the reliance on end-to-end backpropagation, a step towards a better understanding of the learning in our brain. This can potentially lead to solutions towards mental and psychological illness. Our algorithm also lowers the GPU memory requirements and can be deployed with model parallel configurations. This can potentially allow deep learning training to run on cheaper and more energy efficient hardware, which would make a positive impact to combat climate change. We acknowledge unknown risks can be brought by the development of AI technology; however, the contribution of this paper has no greater risk than any other generic deep learning paper that studies standard datasets such as ImageNet.",Broader Impact,121,5,,,FALSE,FALSE,FALSE,LoCo: Local Contrastive Representation Learning,Algorithms -> Unsupervised Learning,Algorithms -> Communication- or Memory-Bounded Learning; Algorithms -> Representation Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yuwen Xiong', ' Mengye Ren', ' Raquel Urtasun']","{'University of Toronto / Uber ATG', 'Uber ATG', 'Uber ATG / University of Toronto'}",1,1,1,"{'Canada', 'USA'}"
Modeling and Optimization Trade-off in Meta-learning,"Katelyn Gao, Ozan Sener",Modeling and Optimization Trade-off in Meta-learning,7fc63ff01769c4fa7d9279e97e307829,https://proceedings.neurips.cc/paper/2020/file/7fc63ff01769c4fa7d9279e97e307829-Paper.pdf,"The massive progress made by machine learning in artificial intelligence has been partly driven by massive amounts of data and compute [1]. By sharing inductive biases across tasks, meta-learning aims to speed up learning on novel tasks, thereby reducing their data and computational burden. In this paper, we have argued that the data and computational cost of the meta-training procedure matters in addition to that of the meta-test procedure. We have shown that domain randomized search, a computationally cheaper approach compared to classic meta-learning methods such as MAML, solves the meta-learning problem and is competitive with MAML when the budget of meta-training data/compute is small. Thus, it can be an effective meta-learning approach in practice when obtaining data is expensive and/or one would like to reduce the carbon footprint of meta-training, with some cost in performance at meta-test.",Broader Impact,138,5,,,FALSE,FALSE,FALSE,Modeling and Optimization Trade-off in Meta-learning,Algorithms -> Meta-Learning,Algorithms -> Multitask and Transfer Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Katelyn Gao', ' Ozan Sener']",{'Intel Labs'},0,1,0,{'USA'}
SnapBoost: A Heterogeneous Boosting Machine,"Thomas Parnell, Andreea Anghel, Małgorzata Łazuka, Nikolas Ioannou, Sebastian Kurella, Peshal Agarwal, Nikolaos Papandreou, Haralampos Pozidis",SnapBoost: A Heterogeneous Boosting Machine,7fd3b80fb1884e2927df46a7139bb8bf,https://proceedings.neurips.cc/paper/2020/file/7fd3b80fb1884e2927df46a7139bb8bf-Paper.pdf,"Boosting machines are generally considered most effective in application domains involving large amounts of tabular data. We have directly encountered use-cases in the retail, financial and insurance industries, and there are likely to be many others. Such examples include: credit scoring, residential mortgage appraisal, fraud detection and client risk profiling. 4 https://github.com/catboost/catboost/issues/505  The tables used to train these models may contain sensitive personal information such as gender, ethnicity, health, religion or financial status. It is therefore critical that the algorithms used do not leak such information. In particular, an adversary should not be able to exploit a trained model to discover sensitive information about an individual or group. While we do not address these concerns in this paper, efforts are ongoing in the research community to develop privacy-preserving boosting machines [34]. Given the application domains where boosting machines are currently deployed, another important issue is fairness. Formally, we would like that certain statistics regarding the decisions produced by the trained model are consistent across individuals or groups of individuals. This definition imposes new constraints, which our training algorithms must be modified to satisfy. While this problem has received a significant amount of attention from the community in general, only a few works have looked at designing boosting machines that satisfy fairness constraints [20, 25]. Given the widespread use of boosting machines in production systems, this is a topic worthy of future investigation.",Broader Impact,232,12,,,FALSE,FALSE,FALSE,SnapBoost: A Heterogeneous Boosting Machine,Algorithms -> Boosting and Ensemble Methods,Algorithms -> Classification; Algorithms -> Kernel Methods; Algorithms -> Regression; Algorithms -> Stochastic Methods,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Thomas Parnell', ' Andreea Anghel', ' Małgorzata Łazuka', ' Nikolas Ioannou', ' Sebastian Kurella', ' Peshal Agarwal', ' Nikolaos Papandreou', ' Haralampos Pozidis']","{'IBM Research', 'ETH Zürich', 'IBM Research Zurich'}",1,1,1,"{'USA', 'Switzerland'}"
On Adaptive Distance Estimation,"Yeshwanth Cherapanamjeri, Jelani Nelson",On Adaptive Distance Estimation,803ef56843860e4a48fc4cdb3065e8ce,https://proceedings.neurips.cc/paper/2020/file/803ef56843860e4a48fc4cdb3065e8ce-Paper.pdf,"As a theoretical contribution, we do not see our work as having any foreseeable societal implications. While we do provide theoretical insights towards designing more resilient machine learning algo- rithms, it is difficult to gauge the downstream effects of incorporating such insights into practical algorithms and these effects may heavily rely on context.",7 Broader Impact,53,2,TRUE,FALSE,FALSE,FALSE,FALSE,On Adaptive Distance Estimation,Algorithms,Algorithms -> Adaptive Data Analysis,Theory (including computational and statistical analyses),"['Yeshwanth Cherapanamjeri', ' Jelani Nelson']",{'UC Berkeley'},1,0,0,{'USA'}
Stage-wise Conservative Linear Bandits,"Ahmadreza Moradipari, Christos Thrampoulidis, Mahnoosh Alizadeh",Stage-wise Conservative Linear Bandits,804741413d7fe0e515b19a7ffc7b3027,https://proceedings.neurips.cc/paper/2020/file/804741413d7fe0e515b19a7ffc7b3027-Paper.pdf,"The main goal of this paper is to design and study novel “safe” learning algorithms for safety-critical systems with provable performance guarantees. An example arises in clinical trials where the effect of different therapies on patient’s health is not known in advance. We select the baseline actions to be the therapies that have been historically chosen by medical practitioners, and the reward captures the effectiveness of the chosen therapy. The stage-wise conservative constraint modeled in this paper ensures that at each round the learner should choose a therapy which results in an expected reward if not better, must be close to the baseline policy. Another example arises in societal-scale infrastructure networks such as communication/power/transportation/data network infrastructure. We focus on the case where the reliability requirements of network operation at each round depends on the reward of the selected action and certain baseline actions are known to not violate system constraints and achieve certain levels of operational efficiency as they have been used widely in the past. In this case, the stage-wise conservative constraint modeled in this paper ensures that at each round, the reward of action employed by learning algorithm if not better, should be close to that of baseline policy in terms of network efficiency, and the reliability requirement for network operation must not be violated by the learner. Another example is in recommender systems that at each round, we wish to avoid recommendations that are extremely disliked by the users. Our proposed stage-wise conservative constrains ensures that at no round would the recommendation system cause severe dissatisfaction for the users (consider perhaps how a really bad personal movie recommendation from a streaming platform would severely affect your view of the said platform).",8 Broader Impact,284,9,,,FALSE,FALSE,FALSE,Stage-wise Conservative Linear Bandits,Algorithms -> Bandit Algorithms,,Theory (including computational and statistical analyses),"['Ahmadreza Moradipari', ' Christos Thrampoulidis', ' Mahnoosh Alizadeh']","{'UCSB', 'University of California Santa Barbara', 'University of California, Santa Barbara'}",1,0,0,{'USA'}
RELATE: Physically Plausible Multi-Object Scene Synthesis Using Structured Latent Spaces,"Sebastien Ehrhardt, Oliver Groth, Aron Monszpart, Martin Engelcke, Ingmar Posner, Niloy Mitra, Andrea Vedaldi",RELATE: Physically Plausible Multi-Object Scene Synthesis Using Structured Latent Spaces,806beafe154032a5b818e97b4420ad98,https://proceedings.neurips.cc/paper/2020/file/806beafe154032a5b818e97b4420ad98-Paper.pdf,"Our method advances the ability of computers to learn to understand environments in images in an object-centric way. It also enhances the capabilities of generative models to generate realistic images of “invented” environment configurations. Overall, we believe our research to be at low to no risk of direct misuse. At present, our generation results are insufficient to fool a human observer. However, it has to be noted that the sampling process is, as in many other deep generative models, capable of revealing patterns observed in the training data, e.g. , specific textures or object geometries. Such data privacy concerns are not applicable in the street traffic data used in our research, since the resolution of the videos is far too low to identify individual drivers or recognize cars’ license plates. However, ‘training data leakage’ should be taken into consideration when the model is trained on more sensitive datasets. In a positive prospect, we believe that our model contributes to further the development of less opaque machine learning models. The explicit object-centric modelling of image components and their geometric relationships is in many of its aspects intelligble to a human user. This facilitates debugging and interpreting the model’s behaviour and can help to establish trust towards the model when employed in larger application pipelines. However, the key value of our paper is in the methodological advances. It is conceivable that, like any advance in machine learning, our contributions could ultimately lead to methods that in turn can and are misused. However, there is nothing to indicate that our contributions facilitate misuse in any direct way; in particular, they seem extremely unlikely to be misused directly.",Broader Impact,274,13,FALSE,FALSE,FALSE,FALSE,FALSE,RELATE: Physically Plausible Multi-Object Scene Synthesis Using Structured Latent Spaces,Deep Learning,Deep Learning -> Generative Models,Vision,"['Sebastien Ehrhardt', ' Oliver Groth', ' Aron Monszpart', ' Martin Engelcke', ' Ingmar Posner', ' Niloy Mitra', ' Andrea Vedaldi']","{'Oxford Robotics Institute', 'UCL/Adobe', 'Niantic', 'Facebook AI Research and University of Oxford', 'Oxford University', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
Metric-Free Individual Fairness in Online Learning,"Yahav Bechavod, Christopher Jung, Steven Z. Wu",Metric-Free Individual Fairness in Online Learning,80b618ebcac7aa97a6dac2ba65cb7e36,https://proceedings.neurips.cc/paper/2020/file/80b618ebcac7aa97a6dac2ba65cb7e36-Paper.pdf,"As the authors of this work believe that bridging the gap between theoretical research in algorithmic fairness and practical use is of the essence, one of the main focuses of this work has been removing  the rather stringent assumptions made in previous research in individual fairness, and replacing these with more realistic ones (if any). As such, the contributions offered in the paper allow taking a step closer to incorporating the long sought-after notion of individual fairness into real life systems. The introduction of a fairness auditor gives a simple, elegant solution to the hurdle posed by the classic similarity metric assumption. The notion of individual fairness pursued in this work offers a strong guarantee on the individual’s level (which is not given, for example, by the various more popular yet weaker notions of group fairness). We believe this combination between practicality of use and a strong fairness guarantee has the power to significantly impact our ability to ensure fairness and non-discrimination in machine learning based algorithms.",Broader Impact,167,5,,,FALSE,FALSE,FALSE,Metric-Free Individual Fairness in Online Learning,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Online Learning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yahav Bechavod', ' Christopher Jung', ' Steven Wu']","{'University of Pennsylvania', 'Hebrew University of Jerusalem', 'Carnegie Mellon University'}",1,0,0,"{'USA', 'Israel'}"
GreedyFool: Distortion-Aware Sparse Adversarial Attack,"Xiaoyi Dong, Dongdong Chen, Jianmin Bao, Chuan Qin, Lu Yuan, Weiming Zhang, Nenghai Yu, Dong Chen",GreedyFool: Distortion-Aware Sparse Adversarial Attack,8169e05e2a0debcb15458f2cc1eff0ea,https://proceedings.neurips.cc/paper/2020/file/8169e05e2a0debcb15458f2cc1eff0ea-Paper.pdf,"Technically, the newly proposed method boosts existing sparse adversarial attacks with much better sparsity and invisibility, which is indeed big progress. For a broad deep learning community, it will help them understand the fragility of CNN more thoroughly and design more robust network structures.",Broader Impact.,44,2,FALSE,FALSE,FALSE,FALSE,FALSE,GreedyFool: Distortion-Aware Sparse Adversarial Attack,Deep Learning,Applications -> Computer Vision,Adversarial attack,"['Xiaoyi Dong', ' Dongdong Chen', ' Jianmin Bao', ' Chuan Qin', ' Lu Yuan', ' Weiming Zhang', ' Nenghai Yu', ' Dong Chen']","{'Microsoft Research', 'Microsoft', 'University of Science and Technology of China', 'Microsoft Research Asia', 'Microsoft Cloud AI'}",1,1,1,"{'USA', 'China'}"
VAEM: a Deep Generative Model for Heterogeneous Mixed Type Data,"Chao Ma, Sebastian Tschiatschek, Richard Turner, José Miguel Hernández-Lobato, Cheng Zhang",VAEM: a Deep Generative Model for Heterogeneous Mixed Type Data,8171ac2c5544a5cb54ac0f38bf477af4,https://proceedings.neurips.cc/paper/2020/file/8171ac2c5544a5cb54ac0f38bf477af4-Paper.pdf,"Our paper provides a simple solution for handling heterogeneous mixed-type data with deep generative models. This is an under explored topic in the literature, which to a certain extend, limits the application of deep generative models to real-life tasks. Our research opens-up new possibilities to VAEs, and broadens the range of real-world applications where deep generative models can be successfully deployed. As a model, we foresee that our research is a useful addition to the deep generative modeling toolbox. It is of particular interest to ML researchers and practitioners, whenever a good probabilistic model for mixed-type data is needed. Our SAIA algorithm and data imputation algorithm with VAEM is also valuable for ML practitioners who is looking for immediate solutions for their specific scenarios at hand.",Broader Impact,126,6,,,FALSE,FALSE,FALSE,VAEM: a Deep Generative Model for Heterogeneous Mixed Type Data,Deep Learning -> Generative Models,,Probabilistic methods and inference,"['Chao Ma', ' Sebastian Tschiatschek', ' Richard E Turner', 'Lobato', ' Cheng Zhang']","{'University of Cambridge', 'Microsoft Research', 'Microsoft Research, Cambridge, UK'}",1,1,1,"{'UK', 'USA'}"
RetroXpert: Decompose Retrosynthesis Prediction Like A Chemist,"Chaochao Yan, Qianggang Ding, Peilin Zhao, Shuangjia Zheng, JINYU YANG, Yang Yu, Junzhou Huang",RetroXpert: Decompose Retrosynthesis Prediction Like A Chemist,819f46e52c25763a55cc642422644317,https://proceedings.neurips.cc/paper/2020/file/819f46e52c25763a55cc642422644317-Paper.pdf,"Our proposed new retrosynthesis method RetroXpert solves the retrosynthesis prediction in two steps like chemists do, and it achieves impressive performance. It is template-free and is very scalable to the large real-world dataset. We believe that our work will greatly inspire and advance related research, such as forward reaction prediction and drug discovery. The researchers and industry experts in drug discovery will benefit most from this research since the retrosynthesis prediction is an important part of drug discovery. We are not aware anyone may be put at disadvantage from this research. Our method does not take advantage of the data bias, it is general and scalable.",Broader Impact,106,6,,,FALSE,FALSE,FALSE,RetroXpert: Decompose Retrosynthesis Prediction Like A Chemist,Applications -> Computational Biology and Bioinformatics,Deep Learning -> Attention Models; Probabilistic Methods -> Graphical Models,"Other applications (e.g., robotics, biology, climate, finance)","['Chaochao Yan', ' Qianggang Ding', ' Peilin Zhao', ' Shuangjia Zheng', ' JINYU YANG', ' Yang Yu', ' Junzhou Huang']","{'University of Texas at Arlington / Tencent AI Lab', 'The University of Texas at Arlington', 'SUN YAT-SEN UNIVERSITY', 'Tsinghua University', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
Sample-Efficient Optimization in the Latent Space of Deep Generative Models via Weighted Retraining,"Austin Tripp, Erik Daxberger, José Miguel Hernández-Lobato",Sample-Efficient Optimization in the Latent Space of Deep Generative Models via Weighted Retraining,81e3225c6ad49623167a4309eb4b2e75,https://proceedings.neurips.cc/paper/2020/file/81e3225c6ad49623167a4309eb4b2e75-Paper.pdf,"Ultimately, this work is preliminary, despite the promise of latent space optimization, there may still be significant obstacles to applying it more widely in the real world. That aside, we believe that the primary effect of this line of research will be to enable faster discoveries of novel entities, such as new medicines, new energy materials, or new device designs. The worldwide effort to develop vaccines and treatments for the COVID-19 pandemic has highlighted the importance of techniques for fast, targeted discovery using only small amounts of data: we have seen that even if the whole world is devoted to performing experiments with a single goal, the sheer size of the search space means that sample efficiency is still important. As much as this technology could be used to discover good things, it could also be used to discover bad things (e.g. chemical/biological weapons). However, as substantial resources and infrastructure are required to produce these, we do not expect that this line of work will enable new parties to begin their development. Rather, at worse, it may allow people who are already involved in their development to do it slightly more effectively. Finally, we believe that this line of work has the potential to influence other problem areas in machine learning, such as conditional image generation and conditional text generation, because these tasks can also be viewed as optimization, whose objective function is a human judgement, which is generally expensive to obtain.",Broader Impact,242,7,,,FALSE,FALSE,FALSE,Sample-Efficient Optimization in the Latent Space of Deep Generative Models via Weighted Retraining,Deep Learning -> Generative Models,Algorithms; Algorithms -> Active Learning; Algorithms -> Representation Learning; Applications,Deep learning,"['Austin Tripp', ' Erik Daxberger', 'Lobato']",{'University of Cambridge'},1,0,0,{'UK'}
Improved Sample Complexity for Incremental Autonomous Exploration in MDPs,"Jean Tarbouriech, Matteo Pirotta, Michal Valko, Alessandro Lazaric",Improved Sample Complexity for Incremental Autonomous Exploration in MDPs,81e793dc8317a3dbc3534ed3f242c418,https://proceedings.neurips.cc/paper/2020/file/81e793dc8317a3dbc3534ed3f242c418-Paper.pdf,"This paper makes contributions to the fundamentals of online learning (RL) and due to its theoretical nature, we see no ethical or immediate societal consequence of our work.",Broader Impact,28,1,TRUE,FALSE,FALSE,FALSE,FALSE,Improved Sample Complexity for Incremental Autonomous Exploration in MDPs,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Jean Tarbouriech', ' Matteo Pirotta', ' Michal Valko', ' Alessandro Lazaric']","{'Facebook Artificial Intelligence Research', 'Facebook AI Research', 'DeepMind Paris and Inria Lille - Nord Europe'}",1,1,1,"{'France', 'USA'}"
"TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning","Han Cai, Chuang Gan, Ligeng Zhu, Song Han","TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning",81f7acabd411274fcf65ce2070ed568a,https://proceedings.neurips.cc/paper/2020/file/81f7acabd411274fcf65ce2070ed568a-Paper.pdf,"The proposed efficient on-device learning technique greatly reduces the training memory footprint of deep neural networks, enabling adapting pre-trained models to new data locally on edge devices without leaking them to the cloud. It can democratize AI to people in the rural areas where the Internet is unavailable or the network condition is poor. They can not only inference but also fine-tune AI models on their local devices without connections to the cloud servers. This can also benefit privacy-sensitive AI applications, such as health care, smart home, and so on.",Broader Impact,90,4,,,FALSE,FALSE,FALSE,"TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning",Deep Learning -> Efficient Training Methods,,Resource aware machine learning,,"{'Massachusetts Institute of Technology', 'MIT', 'MIT-IBM Watson AI Lab'}",1,1,1,{'USA'}
RD22: Reward Decomposition with Representation Decomposition,"Zichuan Lin, Derek Yang, Li Zhao, Tao Qin, Guangwen Yang, Tie-Yan Liu",RD 2 : Reward Decomposition with Representation Disentanglement,82039d16dce0aab3913b6a7ac73deff7,https://proceedings.neurips.cc/paper/2020/file/82039d16dce0aab3913b6a7ac73deff7-Paper.pdf,"Reinforcement learning has a wide range of applications in real life. In board games [Schrittwieser et al., 2019], RL has shown that it has the potential to beat human and therefore provide valuable insights. In optimal control, RL has also been widely used as a search policy that guarantees convergence. In general planning problems such as traffic control or recommendation system, introducing RL is also an active line of research. Reward decomposition has a lot of potential impacts, especially in multi-agent setting, where each agent should obtain a portion of the total reward, and in interpretation-required problems such as recommendation system. RD 2 is capable of both decomposing rewards into sub-rewards, and on top of that provide meaningful interpretation due to disentangled representation. Integrating RD 2 with those settings would provide benefits to both training aspects and interpretability aspects. However, the rise of autonomous analytic algorithms will inevitably decrease the demand for human data analysts.",Broader Impact,155,8,,,FALSE,FALSE,FALSE,RD$^2$: Reward Decomposition with Representation Decomposition,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Zichuan Lin', ' Derek Yang', ' Li Zhao', ' Tao Qin', ' Guangwen Yang', 'Yan Liu']","{'Tsinghua University', 'Microsoft Research Asia', 'UC San Diego', 'Microsoft Research'}",1,1,1,"{'USA', 'China'}"
Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID,"Yixiao Ge, Feng Zhu, Dapeng Chen, Rui Zhao, hongsheng Li",Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID,821fa74b50ba3f7cba1e6c53e8fa6845,https://proceedings.neurips.cc/paper/2020/file/821fa74b50ba3f7cba1e6c53e8fa6845-Paper.pdf,"Our method can help to identify and track different types of objects ( e . g ., vehicles, cyclists, pedestrians, etc . ) across different cameras (domains), thus boosting the development of smart retail, smart transportation, and smart security systems in the future metropolises. In addition, our proposed self-paced contrastive learning is quite general and not limited to the specific research field of object re-ID. It can be well extended to broader research areas, including unsupervised and semi-supervised representation learning. However, object re-ID systems, when applied to identify pedestrians and vehicles in surveillance systems, might give rise to the infringement of people’s privacy, since such re-ID systems often rely on non-consensual surveillance data for training, i . e ., it is unlikely that all human subjects even knew they were being recorded. Therefore, governments and officials need to carefully establish strict regulations and laws to control the usage of re-ID technologies. Otherwise, re-ID technologies can potentially equip malicious actors with the ability to surveil pedestrians or vehicles through multiple CCTV cameras without their consent. The research committee should also avoid using the datasets with ethics issues, e . g ., DukeMTMC [37], which has been taken down due to the violation of data collection terms, should no longer be used. We would not evaluate our method on DukeMTMC related benchmarks as well. Furthermore, we should be cautious of the misidentification of the re-ID systems to avoid possible disturbance. Also, note that the demographic makeup of the datasets used is not representative of the broader population.",Broader Impact,255,14,,,FALSE,FALSE,FALSE,Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID,Algorithms -> Unsupervised Learning,Algorithms -> Representation Learning; Algorithms -> Semi-Supervised Learning; Applications -> Computer Vision; Applications -> Object Recognition,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yixiao Ge', ' Dapeng Chen', ' Feng Zhu', ' Rui Zhao', ' hongsheng Li']","{'SenseTime Research', 'The Chinese University of Hong Kong', 'cuhk'}",1,1,1,"{'Hong Kong', 'China'}"
Fairness constraints can help exact inference in structured prediction,"Kevin Bello, Jean Honorio",Fairness constraints can help exact inference in structured prediction,8248a99e81e752cb9b41da3fc43fbe7f,https://proceedings.neurips.cc/paper/2020/file/8248a99e81e752cb9b41da3fc43fbe7f-Paper.pdf,This theoretical work does not present any foreseeable societal consequence. We believe the research community interested in the foundations of machine learning might benefit from the results of this work.,Broader Impact,30,2,TRUE,FALSE,FALSE,FALSE,FALSE,Fairness constraints can help exact inference in structured prediction,Theory -> Statistical Learning Theory,,Theory (including computational and statistical analyses),"['Kevin Bello', ' Jean Honorio']",{'Purdue University'},1,0,0,{'USA'}
Instance-based Generalization in Reinforcement Learning,"Martin Bertran, Natalia Martinez, Mariano Phielipp, Guillermo Sapiro",Instance-based Generalization in Reinforcement Learning,82674fc29bc0d9895cee346548c2cb5c,https://proceedings.neurips.cc/paper/2020/file/82674fc29bc0d9895cee346548c2cb5c-Paper.pdf,"Understanding generalization properties in reinforcement learning (RL) is one of the most critical open questions in modern machine learning, with implications ranging from basic science to sociallyimpactful applications. Towards this goal, we formally analyze the training dynamics of RL agents when environments are reused. We prove that this standard RL training methodology introduces undesired changes in the environment dynamics, something to be aware of since it directly impacts the learned policies and generalization capabilities. We then introduce a simple computational methodology to address this problem, and provide experimental validation of the theory presented. Beyond the scope of this paper, deep reinforcement learning has multiple human-facing applications, but is notoriously data inefficient and more generalization understanding is needed. Addressing these fundamental problems and providing a foundational understanding is critical to increase its real-world applicability in fields such as robotics, chemistry, and healthcare. This work is a step in this direction, with building blocks that will encourage and facilitate future critical developments.",Broader impact,160,7,,,TRUE,TRUE,TRUE,Instance-based Generalization in Reinforcement Learning,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement learning and planning,"['Martin Bertran', ' Natalia L Martinez', ' Mariano Phielipp', ' Guillermo Sapiro']","{'Intel AI Labs', 'Duke University'}",1,1,1,{'USA'}
Smooth And Consistent Probabilistic Regression Trees,"Sami Alkhoury, Emilie Devijver, Marianne Clausel, Myriam Tami, Eric Gaussier, georges Oppenheim",Smooth And Consistent Probabilistic Regression Trees,8289889263db4a40463e3f358bb7c7a1,https://proceedings.neurips.cc/paper/2020/file/8289889263db4a40463e3f358bb7c7a1-Paper.pdf,"This work is mainly theoretical, with standard regression applications.",Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Smooth And Consistent Probabilistic Regression Trees,Algorithms -> Regression,Algorithms -> Boosting and Ensemble Methods,Probabilistic methods and inference,"['Sami Alkhoury', ' Emilie Devijver', ' Marianne Clausel', ' Myriam Tami', ' Eric Gaussier', ' georges Oppenheim']","{'University Grenoble Alpes', 'Université Joseph Fourier, Grenoble', 'CNRS - UGA', 'IECL', 'Université Paris-Saclay', 'Private'}",1,0,0,{'France'}
Computing Valid p-value for Optimal Changepoint by Selective Inference using Dynamic Programming,"Vo Nguyen Le Duy, Hiroki Toda, Ryota Sugiyama, Ichiro Takeuchi",Computing Valid p -value for Optimal Changepoint by Selective Inference using Dynamic Programming,82b04cd5aa016d979fe048f3ddf0e8d3,https://proceedings.neurips.cc/paper/2020/file/82b04cd5aa016d979fe048f3ddf0e8d3-Paper.pdf,"Reliable machine learning (ML), which is the problem of assessing the reliability of data-driven knowledge obtained by ML algorithms, is one of the most important issues in the ML community. Changepoint (CP) detection is an important unsupervised learning task, and has been studied in many areas. Unfortunately, less attention has been paid to the statistical reliability of the detected CPs. Without statistical reliability, the results may contain many false detections . These falsely detected CPs are harmful when they are used for high-stake decision making. The main idea of this paper is to employ a selective inference — a new promising approach for assessing the statistical reliability of data-driven hypotheses selected by complex data analysis algorithms — to quantify the reliability of the detected CPs. By mainly focusing on the reliability, this paper can have potential impact on reducing the risky as well as improving the quality of several CP detection-based data analysis tasks such as bioinformatics [14, 35], financial analysis [15], climatology [22], signal processing [19]. Especially for applications in healthcare domain, since the p -value that we introduced in the paper is valid and it is guaranteed that the probability of making false decisions is properly controlled, valid p -values can be used as one of many other possible criteria for making medical decisions.",Broader Impact,216,8,,,FALSE,FALSE,FALSE,Computing Valid p-value for Optimal Changepoint by Selective Inference using Dynamic Programming,Algorithms -> Unsupervised Learning,Algorithms -> Adaptive Data Analysis; Applications -> Computational Biology and Bioinformatics; Social Aspects of Machine Learning -> AI Safety,Probabilistic methods and inference,"['Duy Vo', ' Hiroki Toda', ' Ryota Sugiyama', ' Ichiro Takeuchi']",{'Nagoya Institute of Technology'},1,0,0,{'Japan'}
Factorized Neural Processes for Neural Processes: K-Shot Prediction of Neural Responses,"Ronald (James) Cotton, Fabian Sinz, Andreas Tolias",Factorized Neural Processes for Neural Processes: K -Shot Prediction of Neural Responses,82e9e7a12665240d13d0b928be28f230,https://proceedings.neurips.cc/paper/2020/file/82e9e7a12665240d13d0b928be28f230-Paper.pdf,"We hope this approach will be useful to the Neuroscience community and that Factorized Neural Processes may have even broader applications for modeling functions. The ability to perform real- time, closed-loop experiments and to performances inferences with less data may reduce the amount of time to record from animals or the number of experimental sessions. We do not believe this methodology or the demonstrated application will disadvantage anyone.",Broader Impact,68,3,,,FALSE,FALSE,FALSE,Factorized Neural Processes for Neural Processes: K-Shot Prediction of Neural Responses,Neuroscience and Cognitive Science,Algorithms -> Few-Shot Learning; Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Visual Perception,Neuroscience and cognitive science,"['Ronald Cotton', ' Fabian Sinz', ' Andreas Tolias']","{'University Tübingen', 'Baylor College of Medicine', 'Shirley Ryan AbilityLab'}",1,0,0,"{'USA', 'Germany'}"
Winning the Lottery with Continuous Sparsification,"Pedro Savarese, Hugo Silva, Michael Maire",Winning the Lottery with Continuous Sparsification,83004190b1793d7aa15f8d0d49a13eba,https://proceedings.neurips.cc/paper/2020/file/83004190b1793d7aa15f8d0d49a13eba-Paper.pdf,"Training deep neural networks usually requires significant computational resources. Additional efforts are often needed to prune trained networks to enable efficient inference – for example, in mobile applications which may be both power and compute constrained. Our work presents a new technique via which to sparsify networks, and contributes to the analysis of the recently discovered scientific phenomenon of re-trainable subnetworks (tickets). These contributions might open new pathways towards reducing the computational resources required for deep learning, thereby having a potentially wide-ranging practical impact across the field.",Broader Impact,87,4,,,FALSE,FALSE,FALSE,Winning the Lottery with Continuous Sparsification,Deep Learning -> Efficient Training Methods,Deep Learning -> CNN Architectures; Deep Learning -> Supervised Deep Networks,Deep learning,"['Pedro Savarese', ' Hugo Silva', ' Michael Maire']","{'Independent Researcher', 'TTIC', 'University of Chicago'}",1,0,0,"{'USA', 'Independent'}"
Adversarial robustness via robust low rank representations,"Pranjal Awasthi, Himanshu Jain, Ankit Singh Rawat, Aravindan Vijayaraghavan",Adversarial robustness via robust low rank representations,837a7924b8c0aa866e41b2721f66135c,https://proceedings.neurips.cc/paper/2020/file/837a7924b8c0aa866e41b2721f66135c-Paper.pdf,"Our work provides efficient algorithms for training neural networks with certified robustness guarantees. This can have significant positive societal impact considering the importance of protecting AI systems against malicious adversaries. A classifier with certified robustness guarantees can give a sense of security to the end user. On the other hand, our methods achieve robustness at the expense of a small loss in natural test accuracy as compared to non- adversarial training. It is unclear how this loss in accuracy is distributed across the population. This could have a negative societal impact if the loss in accuracy is disproportionately on data points/individuals belonging to a specific demographic group based on say race or gender. That said, robustness to perturbations also corresponds to a natural notion of individual fairness since data points with similar features need to be treated similarly by a robust classifier. Hence, a careful study must be done to understand these effects before a large scale practical deployment of systems based on our work.",Broader Impact,165,8,,,FALSE,FALSE,FALSE,Adversarial robustness via robust low rank representations,Algorithms -> Adversarial Learning,Theory -> Computational Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Pranjal Awasthi', ' Himanshu Jain', ' Ankit Singh Rawat', ' Aravindan Vijayaraghavan']","{'Google', 'Rutgers University/Google', 'Google Research', 'Northwestern University'}",1,1,1,{'USA'}
Joints in Random Forests,"Alvaro Correia, Robert Peharz, Cassio P. de Campos",Joints in Random Forests,8396b14c5dff55d13eea57487bf8ed26,https://proceedings.neurips.cc/paper/2020/file/8396b14c5dff55d13eea57487bf8ed26-Paper.pdf,"This work establishes a connection between two sub-fields in machine learning, namely decision trees/random forests and probabilistic circuits. Since there was very restricted communication between these two research communities, a fruitful cross-fertilisation of ideas, theory and algorithms between these research domains can be expected. This represents a highly positive impact on fundamental machine learning and artificial intelligence research. Decision trees and random forests are a de facto standard classification and regression tools in daily applied machine learning and data science. Being—so far—purely discriminative models, they struggle with two problems which are key concerns in this work: missing data and outlier detection. Since the improvements suggested in this paper can be incorporated in existing decision tree algorithms with very minor changes, our results have a potentially dramatic and immediate impact on a central and widely used machine learning and data science tool. Since our work is elementary machine learning research, its ethical consequences are hard to assess. However, the main ethical and societal impact of our work is the extension of a standard prediction tool, increasing its application domain and pertinence, and thus amplifying existing ethical considerations of data-driven and automatic prediction.",Broader Impact,191,8,,,FALSE,FALSE,FALSE,Joints in Random Forests,Probabilistic Methods -> Graphical Models,Algorithms -> Boosting and Ensemble Methods; Algorithms -> Classification,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Alvaro Correia', ' Robert Peharz', ' Cassio de Campos']","{'University of Cambridge', 'Eindhoven University of Technology'}",1,0,0,"{'UK', 'Netherlands'}"
Compositional Generalization by Learning Analytical Expressions,"Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao, Bin Zhou, Nanning Zheng, Dongmei Zhang",Compositional Generalization by Learning Analytical Expressions,83adc9225e4deb67d7ce42d58fe5157c,https://proceedings.neurips.cc/paper/2020/file/83adc9225e4deb67d7ce42d58fe5157c-Paper.pdf,"This work explores the topic of compositional generalization capacities in neural networks, which is a fundamental problem in artificial intelligence but not involved in real applications at now. Therefore, there will be no foreseeable societal consequences nor ethical aspects.",Broader Impact,39,2,TRUE,FALSE,FALSE,FALSE,FALSE,Compositional Generalization by Learning Analytical Expressions,Neuroscience and Cognitive Science -> Cognitive Science,Applications -> Natural Language Processing; Neuroscience and Cognitive Science -> Language for Cognitive Science,Natural language processing,"['Qian Liu', ' Shengnan An', 'Guang Lou', ' Bei Chen', ' Zeqi Lin', ' Yan Gao', ' Bin Zhou', ' Nanning Zheng', ' Dongmei Zhang']","{'Microsoft Research', 'Microsoft Research Asia, Beijing, China', 'Beihang University', 'State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering,Beihang University', 'Microsoft', 'Microsoft Research Asia'}",1,1,1,"{'USA', 'China'}"
JAX MD: A Framework for Differentiable Physics,"Samuel Schoenholz, Ekin Dogus Cubuk","JAX, M.D. A Framework for Differentiable Physics",83d3d4b6c9579515e1679aca8cbc8033,https://proceedings.neurips.cc/paper/2020/file/83d3d4b6c9579515e1679aca8cbc8033-Paper.pdf,"We believe there is significant potential when deep learning, automatic differentiation, and simulation meet. We are excited about the possibilities of larger and more accurate simulations of quantum mechanical systems. If we can reliably simulate and optimize these systems at scale it has the potential to revolutionize many problems that are currently hard: from material design to drug discovery. Of course, if this program is successful enough to provide actual benefits to benevolent technologies it surely has the potential to be used in an ethically questionable manner to e.g. design weapons. We are also excited about the potential of marrying the extreme expressivity of machine learning models with the excellent generalization capabilities of physical laws to improve our ability to do science.",Broader Impact,122,5,,,TRUE,TRUE,FALSE,JAX MD: A Framework for Differentiable Physics,"Data, Challenges, Implementations, and Software -> Software Toolkits",Applications,"Other applications (e.g., robotics, biology, climate, finance)","['Samuel Schoenholz', ' Ekin Dogus Cubuk']",{'Google Brain'},0,1,0,{'USA'}
An implicit function learning approach for parametric modal regression,"Yangchen Pan, Ehsan Imani, Amir-massoud Farahmand, Martha White",An implicit function learning approach for parametric modal regression,83eaa6722798a773dd55e8fc7443aa09,https://proceedings.neurips.cc/paper/2020/file/83eaa6722798a773dd55e8fc7443aa09-Paper.pdf,"This work is about parametric methods of modal regression. Non-parametric modal regression methods are typically studied in the statistics community; and there is yet little parametric modal regression algorithm suitable in deep learning setting. Hence, our work should be generally beneficial to the machine learning and statistics research community. Potential impact of this work in real world is likely to be further improvement of applicability of modal regression methods, which provide more information to decision makers than popular regression methods which attempt to learn conditional mean. The proposed objective may be also of high interest to the community studying energy-based models. We do not consider any specific application scenario as the goal of this work.",7 Broader Impact Discussion,115,6,,,FALSE,FALSE,FALSE,An implicit function learning approach for parametric modal regression,Theory -> Computational Learning Theory,Algorithms -> Regression; Theory -> Data-driven Algorithm Design; Theory -> Regularization; Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yangchen Pan', ' Ehsan Imani', ' Martha White', 'massoud Farahmand']","{'Vector Institute and University of Toronto', 'University of Alberta'}",1,0,0,{'Canada'}
SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static Images,"Chen-Hsuan Lin, Chaoyang Wang, Simon Lucey",SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static Images,83fa5a432ae55c253d0e60dbfa716723,https://proceedings.neurips.cc/paper/2020/file/83fa5a432ae55c253d0e60dbfa716723-Paper.pdf,"Our proposed framework, SDF-SRN, allows for learning dense 3D geometry of object categories from real-world images using annotations ( i.e . 2D silhouettes) that can be feasibly obtained at a large scale. Computer vision increasingly needs to perform 3D geometric reasoning from images, such as when an autonomous vehicle encounters a vehicle in the streets. To avoid catastrophe, the car must not only detect the existence of the vehicle but also exactly determine its spatial extent in the 3D world. Similarly, robots and drones are increasingly deployed in unconstrained environments where they must safely manipulate and avoid 3D objects. Health professionals are increasingly using computer vision to interpret 2D scans/imagery in 3D. Breakthroughs in dense geometric reasoning could allow these researchers to extract unprecedented detail from visual data. This work also offers up exciting new opportunities in the area of computer graphics for 3D content creation, where the laborious process of creating 3D models and animations could be significantly simplified. This could reduce the time and money costs required for many industrial applications ( e.g . involving virtual reality). We should note that all new technologies have the potential for misuse, and our framework SDF-SRN is no different in this regard. However, we strongly believe the myriad of possible societal and economic benefits of our work vastly outweigh such risks.",Broader Impact,220,12,,,FALSE,FALSE,FALSE,SDF-SRN: Learning Signed Distance 3D Object Reconstruction from Static Images,Applications -> Computer Vision,,Vision,"['Hsuan Lin', ' Chaoyang Wang', ' Simon Lucey']","{'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Coresets for Robust Training of Deep Neural Networks against Noisy Labels,"Baharan Mirzasoleiman, Kaidi Cao, Jure Leskovec",Coresets for Robust Training of Neural Networks against Noisy Labels,8493eeaccb772c0878f99d60a0bd2bb3,https://proceedings.neurips.cc/paper/2020/file/8493eeaccb772c0878f99d60a0bd2bb3-Paper.pdf,"Deep neural networks achieve impressive results in a wide variety of domains, including vision and speech recognition. The quality of the trained deep models on such datasets increases logarithmically with the size of the data [ 38]. This improvement, however, is contingent on the availability of reliable and accurate labels. In practice, collecting large high quality datasets is often very expensive and time-consuming. For example, labeling of medical images depends on domain experts and hence is very resource-intensive. In some applications, it necessitate obtaining consensus labels or labels from multiple experts and methods for aggregating those annotations to get the ground truth labels [18]. In some domains, crowd-sourcing methods are used to obtain labels from non-experts. An alternative solution is automated mining of data, e.g., from the Internet by using different image-level tags that can be regarded as labels. These solutions are cheaper and more time-efficient than human annotations, but label noise in such datasets is expected to be higher than in expert-labeled datasets. Noisy labels have a drastic effect on the generalization performance of deep neural networks. This prevents deep networks from being employed in real-world noisy scenarios, in particular in safety critical applications such as aircraft, autonomous cars, and medical devices. State-of-the art methods for training deep networks with noisy labels are mostly heuristics and cannot provide theoretical guarantees for the robustness of the trained model in presence of noisy labels. Failure of such systems can have a drastic effect in sensitive and safety critical applications. Our research provides a principled method for training deep networks on real-world datasets with noisy labels. Our proposed method, C RUST , is based on the recent advances in theoretical understanding of neural networks, and provides theoretical guarantee for the performance of the deep networks trained with noisy labels. We expect our method to have a far-reaching impact in deployment of deep neural networks in real-world systems. We believe our research will be beneficial for deep learning in variety of domains, and do not have any societal or ethical disadvantages.",Broader Impact,338,17,,,FALSE,FALSE,FALSE,Coresets for Robust Training of Deep Neural Networks against Noisy Labels,Deep Learning -> Supervised Deep Networks,Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Efficient Training Methods,,"['Baharan Mirzasoleiman', ' Kaidi Cao', ' Jure Leskovec']","{'Stanford University', 'Stanford University and Pinterest'}",1,0,0,{'USA'}
Adapting to Misspecification in Contextual Bandits,"Dylan J. Foster, Claudio Gentile, Mehryar Mohri, Julian Zimmert",Adapting to Misspecification in Contextual Bandits,84c230a5b1bc3495046ef916957c7238,https://proceedings.neurips.cc/paper/2020/file/84c230a5b1bc3495046ef916957c7238-Paper.pdf,"This paper concerns contextual bandit algorithms that adapt to unknown model misspecification. Because of their efficiency and ability to adapt to the amount of misspecification contained with no prior knowledge, our algorithms are robust, and may be suitable for large-scale practical deployment. On the other hand, our work is at the level of foundational research, and hence its impact on society is shaped by the applications that stem from it. We will focus our brief discussion on the applications mentioned in the introduction. Health services [43] offer an opportunity for potential positive impact. Contextual bandits can be used to propose medical interventions that lead to a better health outcomes. However, care must be taken to ethically implement the explore-exploit tradeoff in this sensitive setting, and more research is required. Online advertisements [4, 35] and recommendation systems [8] are another well-known application. While improved, robust algorithms can lead to increased profits here, it is important to recognize that this may positively impact society as a whole. Lastly, we mention that predictive algorithms like contextual bandits become more and more powerful as more information is gathered about users. This provides a clear incentive toward collecting as much information as possible. We believe that the net benefit of research on contextual bandit outweighs the harm, but we welcome regulatory efforts to produce a legal framework that steers the usage of machine learning algorithms, including in contextual bandits, in a direction which is respects of the privacy rights of users.",Broader Impact,246,12,,,FALSE,FALSE,FALSE,Adapting to Misspecification in Contextual Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning; Algorithms -> Regression,Reinforcement learning and planning,"['Dylan Foster', ' Claudio Gentile', ' Mehryar Mohri', ' Julian Zimmert']","{'Courant Inst. of Math. Sciences & Google Research', 'MIT', 'Google Research', 'Google'}",1,1,1,{'USA'}
Convergence of Meta-Learning with Task-Specific Adaptation over Partial Parameters,"Kaiyi Ji, Jason D. Lee, Yingbin Liang, H. Vincent Poor",Convergence of Meta-Learning with Task-Specific Adaptation over Partial Parameters,84c578f202616448a2f80e6f56d5f16d,https://proceedings.neurips.cc/paper/2020/file/84c578f202616448a2f80e6f56d5f16d-Paper.pdf,"Meta-learning has been successfully used in a wide range of applications including reinforcement learning, robotics, federated learning, imitation learning, etc, which will be highly influential to technologize our life. This work focuses on understanding the computational efficiency of the optimization-based meta learning algorithms, particularly MAML and ANIL type algorithms. We characterize the convergence guarantee on these algorithms. Furthermore, our theory provides useful guidelines on the selections of hyperparameters for these algorithms, in order for them to be efficiently implemented in large-scale applications. We also anticipate the theory that we develop will be useful in other academic fields in addition to machine learning, including optimization theory, signal processing, and statistics.",Broader Impact,109,5,,,FALSE,FALSE,FALSE,Convergence of Meta-Learning with Task-Specific Adaptation over Partial Parameters,Optimization -> Non-Convex Optimization,,,"['Kaiyi Ji', ' Jason Lee', ' Yingbin Liang', ' Vincent Poor']","{'The Ohio State University', 'Princeton University'}",1,0,0,{'USA'}
MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and Architectures,"Jeong Un Ryu, JaeWoong Shin, Hae Beom Lee, Sung Ju Hwang",MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and Architectures,84ddfb34126fc3a48ee38d7044e87276,https://proceedings.neurips.cc/paper/2020/file/84ddfb34126fc3a48ee38d7044e87276-Paper.pdf,"Our MetaPerturb regularizer effectively eliminates the need for retraining of the source task because it can generalize to any convolutional neural architectures and to any image datasets. This versatility is extremely helpful for lowering the energy consumption and training time required in transfer learning, because in real world there exists extremely diverse learning scenarios that we have to deal with. Previous transfer learning or meta-learning methods have not been flexible and versatile enough to solve those diverse large-scale problems simultaneously, but our model can efficiently improve the performance with a single meta-learned regularizer. Also, MetaPerturb efficiently extends the previous meta-learning to standard learning frameworks by avoiding the expensive bilevel optimization, which reduces the computational cost of meta-training, which will result in further reduction in the energy consumption and training time.",Broader Impact,130,4,,,TRUE,TRUE,FALSE,MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and Architectures,Algorithms -> Meta-Learning,Algorithms -> Multitask and Transfer Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jeong Un Ryu', ' JaeWoong Shin', ' Hae Beom Lee', ' Sung Ju Hwang']","{'KAIST, AITRICS', 'KAIST'}",1,1,1,{'South Korea'}
Learning to solve TV regularised problems with unrolled algorithms,"Hamza Cherkaoui, Jeremias Sulam, Thomas Moreau",Learning to solve TV regularised problems with unrolled algorithms,84fec9a8e45846340fdf5c7c9f7ed66c,https://proceedings.neurips.cc/paper/2020/file/84fec9a8e45846340fdf5c7c9f7ed66c-Paper.pdf,"This work attempts to shed some understanding into empirical phenomena in signal processing – in our case, piecewise constant approximations. As such, it is our hope that this work encourages fellow researchers to invest in the study and development of principled machine learning tools. Besides these, we do not foresee any other immediate societal consequences.",Broader Impact,55,3,FALSE,TRUE,FALSE,FALSE,FALSE,Learning to solve TV regularised problems with unrolled algorithms,Optimization -> Convex Optimization,Algorithms -> Sparsity and Compressed Sensing; Applications -> Signal Processing,Optimization Methods (continuous or discrete),"['Hamza Cherkaoui', ' Jeremias Sulam', ' Thomas Moreau']","{'Johns Hopkins University', 'CEA', 'Inria'}",1,0,0,"{'France', 'USA'}"
Object-Centric Learning with Slot Attention,"Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran, Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, Thomas Kipf",Object-Centric Learning with Slot Attention,8511df98c02ab60aea1b2356c013bc0f,https://proceedings.neurips.cc/paper/2020/file/8511df98c02ab60aea1b2356c013bc0f-Paper.pdf,"The Slot Attention module allows to learn object-centric representations from perceptual input. As such, it is a general module that can be used in a wide range of domains and applications. In our paper, we only consider artificially generated datasets under well-controlled settings where slots are expected to specialize to objects. However, the specialization of our model is implicit and fully driven by the downstream task. We remark that as a concrete measure to assess whether the module specialized in unwanted ways, one can visualize the attention masks to understand how the input features are distributed across the slots (see Figure 6). While more work is required to properly address the usefulness of the attention coefficients in explaining the overall predictions of the network (especially if the input features are not human interpretable), we argue that they may serve as a step towards more transparent and interpretable predictions.",Broader Impact,148,6,,,FALSE,FALSE,FALSE,Object-Centric Learning with Slot Attention,Algorithms -> Representation Learning,Deep Learning -> Attention Models,Deep learning,"['Francesco Locatello', ' Dirk Weissenborn', ' Thomas Unterthiner', ' Aravindh Mahendran', ' Georg Heigold', ' Jakob Uszkoreit', ' Alexey Dosovitskiy', ' Thomas Kipf']","{'Google', 'Google Research', 'ETH Zürich - MPI Tübingen', 'Google Research, Brain Team'}",1,1,1,"{'USA', 'Switzerland'}"
Improving robustness against common corruptions by covariate shift adaptation,"Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, Matthias Bethge",Improving robustness against common corruptions by covariate shift adaptation,85690f81aadc1749175c187784afc9ee,https://proceedings.neurips.cc/paper/2020/file/85690f81aadc1749175c187784afc9ee-Paper.pdf,"The primary goal of this paper is to increase the robustness of machine vision models against common corruptions and to spur further progress in this area. Increasing the robustness of machine vision  systems can enhance their reliability and safety, which can potentially contribute to a large range of use cases including autonomous driving, manufacturing automation, surveillance systems, health care and others. Each of these uses may have a broad range of societal implications: autonomous driving can increase mobility of the elderly and enhance safety, but could also enable more autonomous weapon systems. Manufacturing automation can increase resource efficiency and reduce costs for goods, but may also increase societal tension through job losses or increase consumption and thus waste. Of particular concern (besides surveillance) is the use of generative vision models for spreading misinformation or for creating an information environment of uncertainty and mistrust. We encourage further work to understand the limitations of machine vision models in out-of- distribution generalization settings. More robust models carry the potential risk of automation bias, i.e., an undue trust in vision models. However, even if models are robust to common corruptions, they might still quickly fail on slightly different perturbations like surface reflections. Understanding under what conditions model decisions can be deemed reliable or not is still an open research question that deserves further attention.",Broader Impact,220,9,,,FALSE,FALSE,FALSE,Improving robustness against common corruptions by covariate shift adaptation,Algorithms -> Multitask and Transfer Learning,"Applications -> Computer Vision; Applications -> Object Recognition; Data, Challenges, Implementations, and Software -> Benchmarks; Deep Learning; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> CNN Architectures; Deep Learning -> Supervised Deep Networks",Deep learning,"['Steffen Schneider', ' Evgenia Rusak', ' Luisa Eck', ' Oliver Bringmann', ' Wieland Brendel', ' Matthias Bethge']","{'University of Tübingen', 'LMU Munich', 'University of Tuebingen', 'AG Bethge, University of Tübingen'}",1,0,0,{'Germany'}
Deep Smoothing of the Implied Volatility Surface,"Damien Ackerer, Natasa Tagasovska, Thibault Vatter",Deep Smoothing of the Implied Volatility Surface,858e47701162578e5e627cd93ab0938a,https://proceedings.neurips.cc/paper/2020/file/858e47701162578e5e627cd93ab0938a-Paper.pdf,"Financial markets play a central role in our economy, and our work could be used to generalize in a robust way the information available to participants. Options are actively traded securities that can be used for multiple reasons such as protecting pension portfolios against future losses, hedging against future fluctuations in crop prices for agricultural farmers, or speculation for hedge funds. Options are also used by economist and financial expert to extract market implied sentiment measures such as the VIX “fear” index. The financial risk created by options is often held by financial intermediaries, such as banks or brokers, which need appropriate tools to monitor and control their financial risk.",Broader Impact,110,4,,,FALSE,FALSE,FALSE,Deep Smoothing of the Implied Volatility Surface,Applications -> Quantitative Finance and Econometrics,Algorithms -> Regression,"Other applications (e.g., robotics, biology, climate, finance)","['Damien Ackerer', ' Natasa Tagasovska', ' Thibault Vatter']","{'Columbia University', 'Swissquote', 'EPFL'}",1,1,1,"{'USA', 'Switzerland'}"
Probabilistic Inference with Algebraic Constraints: Theoretical Limits and Practical Approximations,"Zhe Zeng, Paolo Morettin, Fanqi Yan, Antonio Vergari, Guy Van den Broeck",Probabilistic Inference with Algebraic Constraints: Theoretical Limits and Practical Approximations,85934679f30131d812a8c7475a7d0f74,https://proceedings.neurips.cc/paper/2020/file/85934679f30131d812a8c7475a7d0f74-Paper.pdf,"Our contributions in this work can be filed under the label of basic research in probabilistic inference. As a work of basic research it might have a very broad impact. Therefore it is hard to imagine specific negative outcomes at this stage. Concerning benefits, on the other hand, our complexity results will help the community working on probabilistic inference on hybrid domain at large as they lay the foundation for more theoretical research. On the other hand, our general-purpose approximate WMI inference scheme could be particularized by other researchers to fit specific application scenarios. It is hard to foresee or restrict the range of these possible applications. We note that WMI and SMT technologies have been previously used in probabilistic programming and program verification, two very vast fields on their own. Lastly, we are focusing on and advancing inference per se, therefore there is no specific learning phase, or data involved. Our solver is going to perform inference over the distribution induced over an arbitrary SMT theory given as input, if such a theory encodes bias in some form, this bias will clearly be reflected in the probabilistic queries the users are going to ask.",Broader Impact,195,9,,,FALSE,FALSE,FALSE,Probabilistic Inference with Algebraic Constraints: Theoretical Limits and Practical Approximations,Deep Learning -> Efficient Inference Methods,Probabilistic Methods -> Belief Propagation; Probabilistic Methods -> Variational Inference; Theory -> Hardness of Learning and Approximations,Probabilistic methods and inference,"['Zhe Zeng', ' Paolo Morettin', ' Fanqi Yan', ' Antonio Vergari', ' Guy Van den Broeck']","{'UCLA', 'University of California, Los Angeles', 'University of Trento'}",1,1,1,"{'Italy', 'USA'}"
Provable Online CP/PARAFAC Decomposition of a Structured Tensor via Dictionary Learning,"Sirisha Rambhatla, Xingguo Li, Jarvis Haupt",Provable Online CP/PARAFAC Decomposition of a Structured Tensor via Dictionary Learning,85b42dd8aae56e01379be5736db5b496,https://proceedings.neurips.cc/paper/2020/file/85b42dd8aae56e01379be5736db5b496-Paper.pdf,"This work explores the theoretical foundations behind the success of popular alternating minimization-based techniques for tensor factorization. Specifically, we propose an algorithm for accurate model recovery for a tensor factorization task which has applications in clustering and pattern recovery. Since clustering-based algorithms are used for identification of users for targeted advertising campaigns on social network platforms, potential use cases may target users based on their activity patterns. Nevertheless, understanding the theoretical aspects of machine learning algorithms is crucial for ensuring safety and trustworthiness in critical applications, and can in fact be used to mitigate effects of the very biases that these algorithms are prone to exacerbate.",Broader Impact,106,4,,,FALSE,FALSE,FALSE,Provable Online CP/PARAFAC Decomposition of a Structured Tensor via Dictionary Learning,Applications -> Matrix and Tensor Factorization,Algorithms -> Sparse Coding and Dimensionality Expansion,Theory (including computational and statistical analyses),"['Sirisha Rambhatla', ' Xingguo Li', ' Jarvis Haupt']","{'University of Minnesota', 'University of Southern California', 'Princeton University'}",1,0,0,{'USA'}
Look-ahead Meta Learning for Continual Learning,"Gunshi Gupta, Karmesh Yadav, Liam Paull",La-MAML: Look-ahead Meta Learning for Continual Learning,85b9a5ac91cd629bd3afe396ec07270a,https://proceedings.neurips.cc/paper/2020/file/85b9a5ac91cd629bd3afe396ec07270a-Paper.pdf,"This work takes a step towards enabling deployed models to operate while learning online . This would be very relevant for online, interactive services like recommender systems or home robotics, among others. By tackling the problem of catastrophic forgetting, the proposed approach goes some way in allowing models to add knowledge incrementally without needing to be re-trained from scratch. Training from scratch is a compute intensive process, and even requires access to data that might not be available anymore. This might entail having to navigate a privacy-performance trade-off since many techniques like federated learning actually rely on not having to share data across servers, in order to protect user-privacy. The proposed algorithm stores and replays random samples of prior data, and even with the higher alignment of the samples within a task under the proposed approach, there will eventually be some concept drift. While the proposed algorithm itself does not rely on or introduce any biases, any bias in the sampling strategy itself might influence the distribution of data that the algorithm remembers and performs well on.",Broader Impact,177,7,,,TRUE,TRUE,FALSE,Look-ahead Meta Learning for Continual Learning,Algorithms -> Continual Learning,Algorithms -> Meta-Learning; Algorithms -> Online Learning; Neuroscience and Cognitive Science -> Plasticity and Adaptation,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Gunshi Gupta', ' Karmesh Yadav', ' Liam Paull']","{'University of montreal', 'Université de Montréal', 'Carnegie'}",1,0,0,"{'Canada', 'USA'}"
A polynomial-time algorithm for learning nonparametric causal graphs,"Ming Gao, Yi Ding, Bryon Aragam",A polynomial-time algorithm for learning nonparametric causal graphs,85c9f9efab89cee90a95cb98f15feacd,https://proceedings.neurips.cc/paper/2020/file/85c9f9efab89cee90a95cb98f15feacd-Paper.pdf,"Causality and interpretability are crucial aspects of modern machine learning systems. Graphical models in particular are a promising tool at the intersection of causality and interpretability, and our work provides an intuitive approach to balance these issues against modeling flexibility with nonparametric models. That being said, as this work is primarily theoretical, the broader impacts and ethical implications of our work are most likely to be felt downstream in applications. For example, while DAGs can provide causal insights under certain assumptions, these models can potentially be used to provide a false sense of security when they are not applied and deployed carefully. Along these lines, our work attempts to provide a rigourous sense of when flexible nonparametric causal models can be learned from data, by developing both theory and algorithms to justify these models from both mathematical and empirical perspectives.",Broader Impact,140,5,,,FALSE,FALSE,FALSE,A polynomial-time algorithm for learning nonparametric causal graphs,Theory -> Statistical Learning Theory,Algorithms -> Model Selection and Structure Learning; Probabilistic Methods -> Graphical Models,Causality,"['Ming Gao', ' Yi Ding', ' Bryon Aragam']","{'University of Chicago', 'the University of Chicago'}",1,0,0,{'USA'}
Sparse Learning with CART,Jason Klusowski,Sparse Learning with CART,85fc37b18c57097425b52fc7afbb6969,https://proceedings.neurips.cc/paper/2020/file/85fc37b18c57097425b52fc7afbb6969-Paper.pdf,"Who may benefit from this research. There are at least two groups of people who will bene- fit—either directly or indirectly—from this research. 1. Decision makers across a variety of domains, especially those with limited training in statistics. CART has enabled data-driven decision making in multiple high-stakes domains (e.g., business, medicine, and policy) over the past three decades. In particular, those who do not have a formal quantitative background will benefit from the intuitive and interpretable nature of CART and its quick and easy implementation. 2. Members of the society who may be have faced ethical/fairness concerns associated with their data and its use. As this paper has demonstrated, CART forms predictions by emphasizing variables that are more relevant to the output. In a social science context, this suggests that CART may focus more on key diagnostic information (e.g., education, income) without being influenced by potentially non-diagnostic variables that other methods may have falsely deemed relevant (e.g., gender, race). Who may be put at a disadvantage from this research. There is no foreseeable population who may be put at a disadvantage from this research. What are the consequences of failure of the system. Overreliance on any prediction method can have obvious, negative real-world consequences, particularly when the prediction method is prone to failure. CART suffers from a couple of pitfalls: instability (i.e., small perturbations in the training samples may significantly change the structure of an optimal tree and consequent predictions) and difficulty in accurately approximating certain simple models, such as linear or, more generally, additive, if given insufficient or low quality data. Whether the task/method leverages biases in the data. While CART is not impervious to all pre-existing biases in the data (e.g., those arising from systematic measurement errors at the data collection stage), as we have shown, it is less susceptible to the presence of additional, non-diagnostic variables in the data. Consequently, CART has the potential to mitigate the negative consequences of biasing information that is inevitable with most datasets.",Broader Impact,331,18,FALSE,FALSE,FALSE,FALSE,FALSE,Sparse Learning with CART,Algorithms -> Regression,Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,{'Princeton University'},1,0,0,{'USA'}
Proximal Mapping for Deep Regularization,"Mao Li, Yingyi Ma, Xinhua Zhang",Proximal Mapping for Deep Regularization,8606bdb6f1fa707fc6ca309943eea443,https://proceedings.neurips.cc/paper/2020/file/8606bdb6f1fa707fc6ca309943eea443-Paper.pdf,"Information can be presented in multiple sensory modalities like vision, sound, and touch. However, many machine/deep learning algorithms are still trained on single-modality data instead of taking full advantage of multiple modalities. Recent works have shown that these applications learning from single-modality data might imperil the model by producing biased and/or even unfair results. For instance, a model trained on image data, which has little or no effect on the acoustic and tactile properties of the imaged scene, might has a different or opposite understand of its semantics which results in a wrong prediction [59]. Our work aims to mitigate this problem by learning representations that capture information shared between two views. Thanks to its flexibility and efficiency of ProxNet, this technique can also be extended to many other applications that may affect our daily life. Temporal multiview learning for brain network analysis and mortality forecasting. In neuro- logical disorder analysis, fMRI and diffusion tensor imaging provide different views of the same brain, and each of them represents a graph of brain regions, evolving over the duration of scanning. This evolution can be modeled as dynamic graphs. Naturally, we can apply the multiview ProxNet to graph convolutional networks to discover salient representations that provide insightful interpretations for medical practitioners. Similar techniques also can be used to understand mortality rates from multiple populations (views) with a time-series structure. Adversarial recurrent networks for sentiment analysis on reviews. In sentiment analysis of reviews, a writer can outwit the auto-rater by changing the style, such as inserting common words and avoiding specific keywords consistently over time. Interestingly, invariance to such perturbations in a sequential model of text can be effectively modeled by inserting a proximal layer at each step to build adversarial ProxNet based on LSTMs.",Broader Impact,292,14,,,FALSE,FALSE,FALSE,Proximal Mapping for Deep Regularization,Deep Learning -> Supervised Deep Networks,Algorithms -> Classification,Deep learning,"['mao li', ' Yingyi Ma', ' Xinhua Zhang']","{'University of Illinois at Chicago', 'UIC'}",1,0,0,"{'USA', 'Thailand'}"
Identifying Causal-Effect Inference Failure with Uncertainty-Aware Models,"Andrew Jesson, Sören Mindermann, Uri Shalit, Yarin Gal",Identifying Causal-Effect Inference Failure with Uncertainty-Aware Models,860b37e28ec7ba614f00f9246949561d,https://proceedings.neurips.cc/paper/2020/file/860b37e28ec7ba614f00f9246949561d-Paper.pdf,"Here, we highlight a set of beneficial and potentially alarming application scenarios. We are excited about our methods to contribute to ongoing efforts to create neural treatment recommendation systems that can be safely used in medical settings. Safety, along with performance, is a major roadblock for this application. In regions where medical care is scarce, it may be especially likely that systems will be deployed despite limited safety, leading to potentially harmful recommendations. In regions with more universal medical care, individual-based recommendations could improve health outcomes, but systems are unlikely to be deployed when they are not deemed safe. Massive observational datasets are available to consumer-facing online businesses such as social networks, and to some governments. For example, standard inference approaches are limited for recommendation systems on social media sites because a user’s decision to follow a recommendation (the treatment) is confounded by the user’s attributes (and even the user-base itself can be biased by the recommendation algorithm’s choices) [46]. Causal approaches are therefore advantageous. Observational datasets are typically high-dimensional, and therefore likely to suffer from severe overlap violations, making the data unusable for causal inference, or implying the need for cumbersome preprocessing. As our methods enable working directly with such data, they might enable the owners of these datasets to construct causal models of individual human behavior, and use these to manipulate attitudes and behavior. Examples of such manipulation include affecting voting and purchasing choices.",8 Broader impact,236,11,,,FALSE,FALSE,FALSE,Identifying Causal-Effect Inference Failure with Uncertainty-Aware Models,Probabilistic Methods -> Causal Inference,Algorithms -> Uncertainty Estimation; Probabilistic Methods; Probabilistic Methods -> Variational Inference,Causality,"['Andrew Jesson', ' Sören Mindermann', ' Uri Shalit', ' Yarin Gal']","{'Technion', 'University of Oxford'}",1,1,1,"{'UK', 'Israel'}"
Hierarchical Granularity Transfer Learning,"Shaobo Min, Hongtao Xie, Hantao Yao, Xuran Deng, Zheng-Jun Zha, Yongdong Zhang",Hierarchical Granularity Transfer Learning,861637a425ef06e6d539aaaff113d1d5,https://proceedings.neurips.cc/paper/2020/file/861637a425ef06e6d539aaaff113d1d5-Paper.pdf,"This paper proposes a new visual recognition task, which is general to various recognition scenarios. The positive impacts of this paper contain that: a) the proposed methods enable the data annotators to only label the basic-level images, instead of fine-grained labels, which significantly reduce the annotation difficulty and cost; and b) the proposed model is light and can be easily extended to most existing backbones, which costs little extra computing resource. The negative impacts contain that: a) the proposed HGTL requires abundant semantic annotations for the hierarchical categories, which may be not easy to obtain; and b) the subordinate recognition performance is not so good yet, which should be further improved to apply to practice scenarios.",6 Broader Impact,116,3,,,FALSE,TRUE,FALSE,Hierarchical Granularity Transfer Learning,Applications -> Object Recognition,Algorithms -> Multitask and Transfer Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Shaobo Min', ' Hongtao Xie', ' Hantao Yao', ' Xuran Deng', 'Jun Zha', ' Yongdong Zhang']","{' Institute of Automation, Chinese Academy of Sciences', 'University of Science and Technology of China', 'USTC'}",1,0,0,{'China'}
Deep active inference agents using Monte-Carlo methods,"Zafeirios Fountas, Noor Sajid, Pedro Mediano, Karl Friston",Deep active inference agents using Monte-Carlo methods,865dfbde8a344b44095495f3591f7407,https://proceedings.neurips.cc/paper/2020/file/865dfbde8a344b44095495f3591f7407-Paper.pdf,"Our deep active inference agent – equipped with MC methods – provides a flexible framework that may help gain new insights into the brain by simulating realistic, biologically-inspired intelligent agents. General contributions of this framework include helping bridge the gap between cognitive science and deep learning and providing an architecture that would allow psychologists to run more realistic experiments probing human behavior. Specifically, we hope that simulating this agent will allow us use the neural network gradients to make predictions about the underlying physiology associated with behaviors of interest and formulate appropriate hypothesis. We believe this architecture may also help elucidate complex structure-function relationships in cognitive systems through manipulation of priors (under the complete class theorem). This would make it a viable (scaled-up) framework for understanding how brain damage (introduced in the generative model by changing the priors) can affect cognitive function, previously explored in discrete-state formulations of active inference [67, 70]. A potential (future) drawback is that this model could be used to exploit people’s inherent cognitive biases, and as such could potentially be used by bad actors trying to model (and then profit from) human behavior.",6 Broader impact,188,6,,,FALSE,FALSE,FALSE,Deep active inference agents using Monte-Carlo methods,Neuroscience and Cognitive Science -> Cognitive Science,Deep Learning -> Biologically Plausible Deep Networks; Deep Learning -> Deep Autoencoders; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Perception; Probabilistic Methods -> Variational Inference,Neuroscience and cognitive science,"['Zafeirios Fountas', ' Noor Sajid', ' Pedro Mediano', ' Karl Friston']","{'University of Cambridge ', 'University College London'}",1,0,0,{'UK'}
Consistent Estimation of Identifiable Nonparametric Mixture Models from Grouped Observations,"Alexander Ritchie, Robert A. Vandermeulen, Clayton Scott",Consistent Estimation of Identifiable Nonparametric Mixture Models from Grouped Observations,866d90e0921ac7b024b47d672445a086,https://proceedings.neurips.cc/paper/2020/file/866d90e0921ac7b024b47d672445a086-Paper.pdf,"Our work could be applied to many problems for which labeling data is prohibitive, but groups of similar data points can be collected easily. We have explored two such applications: nuclear source detection and topic modeling. These applications, as we have interpreted them, have potential for positive societal impact. Since our work is mostly theoretical and centered around a relatively unexplored sampling scheme, there are likely applications we have not anticipated. We note that topic modeling, in general, has potential surveillance applications, but this is not unique to the proposed method.",Broader Impact,91,5,,,TRUE,TRUE,FALSE,Consistent Estimation of Identifiable Nonparametric Mixture Models from Grouped Observations,Theory -> Statistical Learning Theory,Algorithms -> Clustering; Algorithms -> Density Estimation,Theory (including computational and statistical analyses),"['Alexander Ritchie', ' Robert Vandermeulen', ' Clayton Scott']","{'Technische Universität Berlin', 'University of Michigan'}",1,0,0,"{'USA', 'Germany'}"
Manifold structure in graph embeddings,Patrick Rubin-Delanchy,Manifold structure in graph embeddings,8682cc30db9c025ecd3fee433f8ab54c,https://proceedings.neurips.cc/paper/2020/file/8682cc30db9c025ecd3fee433f8ab54c-Paper.pdf,"Beneficiaries. This work gives a new perspective on graph embedding, which will first benefit network science research, in providing a new paradigm in which to explore, compare and test different latent position network models. The work will also benefit applied data science in demystifying the presence of ‘manifold-like’ features appearing in embeddings, the practice of non-linear dimension reduction after spectral embedding (examples in Section 5.3), and in general suggesting the incorporation of manifold learning in supervised and unsupervised inference problems based on graphs. Finally, researchers in manifold learning may enjoy this new application domain. Who may be put at a disadvantage. The growth of network science is fuelled by the internet [48] and the chief ethical concern with research in this area is privacy. All data used here are in the public domain, and those from Los Alamos National Laboratory are anonymised and approved by the organisations’ Human Subject review board. Consequence of failure of system. Not applicable. Leveraging biases in the data. Of a plethora of graph embedding techniques, spectral embedding has arguably benefitted from the most rigorous statistical examination [57, 41, 63, 60, 64, 4, 43, 13, 14]. Nevertheless, mathematical bias is known to persist, and there is no question that bias in the usual sense will too. This should be noted, for example, when implementing spectral embedding for prediction. There are in general worrying implications in making decisions affecting humans based on network data but, as the current pandemic shows, such decisions are no less necessary and should be informed by best practice.",Broader Impact,256,14,,,TRUE,TRUE,FALSE,Manifold structure in graph embeddings,Applications -> Network Analysis,Algorithms -> Clustering; Algorithms -> Density Estimation; Algorithms -> Kernel Methods; Algorithms -> Spectral Methods; Applications -> Matrix and Tensor Factorization; Probabilistic Methods -> Latent Variable Models; Theory -> High-Dimensional Inference; Theory -> Spaces of Functions and Kernels,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",['Delanchy'],{'University of Bristol'},1,0,0,{'UK'}
Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web,"Zhenwei Dai, Anshumali Shrivastava",Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web,86b94dae7c6517ec1ac767fd2c136580,https://proceedings.neurips.cc/paper/2020/file/86b94dae7c6517ec1ac767fd2c136580-Paper.pdf,"In this work, we developed two algorithms, Ada-BF and disjoint Ada-BF to extend the learned Bloom filter. We make full use of a common observation of the binary classification model that the distribution of prediction score show different trends for the two classes, which is ignored by the previous learned Bloom filters. We demonstrate the significant performance boost compared to the state-of-art methods theoretically and empirically in terms of memory cost and FPR control. Since we did not pose extra assumptions compared to the previous learned Bloom filters, the extra memory savings achieved by our algorithms are almost price free. Considering the generality of our assumptions and simplicity of our algorithm structure, we expect Ada-BF and disjoint Ada-BF have a great potential as an alternative to current learned Bloom filters. Bloom filters is a widely used probabilistic data structure to solve set membership and related problems in many areas including, but not limited to, web and computational biology. Any improvement to Bloom filter false positive rates impacts the efficiency and performance of the entire internet. This affects productivity and user experience of all the end users of internet. In the nature paper “Ultrafast search of all deposited bacterial and viral genomic data”, the primary goal was to compress terabytes of DNA sequences using Bloom filters. Thus, if Ada-BF can get 50% extra memory saving as indicated by our experiment, it is a significant advantage. A more important recent example is using Bloom filter for Covid-19 test [CTV20]. Since Ada-BF is way more accurate than standard Bloom filter under the same memory budget, we envision it can contribute to large scale Covid-19 test.",8 Broader Impact,272,12,,,FALSE,FALSE,FALSE,Adaptive Learned Bloom Filter (Ada-BF): Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web,Applications -> Web Applications and Internet Data,Algorithms -> Data Compression; Applications -> Hardware and Systems,Probabilistic methods and inference,,{'Rice University'},1,0,0,{'USA'}
MCUNet: Tiny Deep Learning on IoT Devices,"Ji Lin, Wei-Ming Chen, Yujun Lin, john cohn, Chuang Gan, Song Han",MCUNet: Tiny Deep Learning on IoT Devices,86c51678350f656dcc7f490a43946ee5,https://proceedings.neurips.cc/paper/2020/file/86c51678350f656dcc7f490a43946ee5-Paper.pdf,"Our work is expected to enable tiny-scale deep learning on microcontrollers and further democratize deep learning applications. Over the years, people have brought down the cost of deep learning inference from $5,000 workstation GPU to $500 mobile phones. We now bring deep learning to microcontrollers costing $5 or even less, which greatly expands the scope of AI applications, making AI much more accessible. Thanks to the low cost and large quantity (250B) of commercial microcontrollers, we can bring AI applications to every aspect of our daily life, including personalized healthcare, smart retail, precision agriculture, smart factory, etc. People from rural and under-developed areas without Internet or high-end hardware can also enjoy the benefits of AI. Our method also helps combat COVID-19 by providing affordable deep learning solutions detecting face masks and people gathering on edge devices without sacrificing privacy. With these always-on low-power microcontrollers, we can process raw sensor data right at the source. It helps to protect privacy since data no longer has to be transmitted to the cloud but processed locally.",Statement of Broader Impacts,173,8,,,TRUE,TRUE,FALSE,MCUNet: Tiny Deep Learning on IoT Devices,Deep Learning -> Efficient Inference Methods,,Resource aware machine learning,"['Ji Lin', 'Ming Chen', ' Yujun Lin', ' john cohn', ' Chuang Gan', ' Song Han']","{'MIT', 'IBM Corp', 'National Taiwan University', 'MIT-IBM Watson AI Lab'}",1,1,1,"{'USA', 'Taiwan'}"
In search of robust measures of generalization,"Gintare Karolina Dziugaite, Alexandre Drouin, Brady Neal, Nitarshan Rajkumar, Ethan Caballero, Linbo Wang, Ioannis Mitliagkas, Daniel M. Roy",In Search of Robust Measures of Generalization,86d7c8a08b4aaa1bc7c599473f5dddda,https://proceedings.neurips.cc/paper/2020/file/86d7c8a08b4aaa1bc7c599473f5dddda-Paper.pdf,"Our work aims to sharpen our understanding of generalization by improving the way that we evaluate theories of generalization empirically. The proposed methodology is expected to aid in the quest to understand generalization in deep neural networks. Ultimately, this could lead to more accurate and reliable models and strengthen the impact of machine learning in critical applications where accuracy must be predictable. We believe that this work has no direct ethical implications. However, as with all advances to machine learning, long-term societal impacts depend heavily on how machine learning is used.",Broader Impact,91,5,,,FALSE,FALSE,FALSE,In search of robust measures of generalization,Theory -> Models of Learning and Generalization,Deep Learning -> Analysis and Understanding of Deep Networks; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Gintare Karolina Dziugaite', ' Alexandre Drouin', ' Brady Neal', ' Nitarshan Rajkumar', ' Ethan Caballero', ' Linbo Wang', ' Ioannis Mitliagkas', ' Daniel Roy']","{'Element AI', 'Mila, Université de Montréal', 'University of Toronto', 'Mila'}",1,1,1,{'Canada'}
Task-agnostic Exploration in Reinforcement Learning,"Xuezhou Zhang, Yuzhe Ma, Adish Singla",Task-agnostic Exploration in Reinforcement Learning,8763d72bba4a7ade23f9ae1f09f4efc7,https://proceedings.neurips.cc/paper/2020/file/8763d72bba4a7ade23f9ae1f09f4efc7-Paper.pdf,Our work provides theoretical foundation for empirical studies of multi-task reinforcement learning and unsupervised reinforcement learning.,Broader Impact,16,1,TRUE,TRUE,FALSE,FALSE,FALSE,Task-agnostic Exploration in Reinforcement Learning,Reinforcement Learning and Planning -> Exploration,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Xuezhou Zhang', ' Yuzhe Ma', ' Adish Singla']","{'UW-Madison', 'MPI-SWS', 'University of Wisconsin-Madison'}",1,0,0,"{'USA', 'Germany'}"
Multi-task Additive Models for Robust Estimation and Automatic Structure Discovery,"Yingjie Wang, Hong Chen, Feng Zheng, Chen Xu, Tieliang Gong, Yanhong Chen",Multi-task Additive Models for Robust Estimation and Automatic Structure Discovery,8767bccb1ff4231a9962e3914f4f1f8f,https://proceedings.neurips.cc/paper/2020/file/8767bccb1ff4231a9962e3914f4f1f8f-Paper.pdf,"The positive impacts of this work are two-fold: 1) Our algorithmic framework paves a new way for mining the intrinsic feature structure among high-dimensional variables, and may be the stepping stone to further explore data-driven structure discovery with overlapping groups. 2) Our MAM can be applied to other fields, e.g, gene expression analysis and drug discovery. However, there is also a risk of resulting an unstable estimation when facing ultra high-dimensional data.",Broader Impact,72,3,,,FALSE,FALSE,FALSE,Multi-task Additive Models for Robust Estimation and Automatic Structure Discovery,Algorithms -> Structured Prediction,Algorithms -> Regression,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yingjie Wang', ' Hong Chen', ' Feng Zheng', ' Chen Xu', ' Tieliang Gong', ' Yanhong Chen']","{' Chinese Academy of Sciences', 'Huazhong Agricultural University', 'University of Texas at Arlington', 'University of Ottawa', 'SUSTech'}",1,0,0,"{'Canada', 'USA', 'China'}"
Provably Efficient Reward-Agnostic Navigation with Linear Value Iteration,"Andrea Zanette, Alessandro Lazaric, Mykel J. Kochenderfer, Emma Brunskill",Provably Efficient Reward-Agnostic Navigation with Linear Value Iteration,87736972ed2fb48230f1052699dedbe7,https://proceedings.neurips.cc/paper/2020/file/87736972ed2fb48230f1052699dedbe7-Paper.pdf,This work is of theoretical nature and aims at improving our core understanding of reinforcement learning; no immediate societal consequences are anticipated as a result of this study.,7 Broader Impact,28,1,TRUE,FALSE,FALSE,FALSE,FALSE,Provably Efficient Reward-Agnostic Navigation with Linear Value Iteration,Reinforcement Learning and Planning -> Exploration,,Reinforcement learning and planning,"['Andrea Zanette', ' Alessandro Lazaric', ' Mykel J Kochenderfer', ' Emma Brunskill']","{'Stanford University', 'Facebook Artificial Intelligence Research'}",1,1,1,{'USA'}
Softmax Deep Double Deterministic Policy Gradients,"Ling Pan, Qingpeng Cai, Longbo Huang",Softmax Deep Double Deterministic Policy Gradients,884d247c6f65a96a7da4d1105d584ddd,https://proceedings.neurips.cc/paper/2020/file/884d247c6f65a96a7da4d1105d584ddd-Paper.pdf,"Recent years have witnessed unprecedented advances of deep reinforcement learning in real-world tasks involving high-dimensional state and action spaces that leverages the power of deep neural networks including robotics, transportation, recommender systems, etc. Our work investigates the Boltzmann softmax operator in updating value functions in reinforcement learning for continuous control, and provides new insights and further understanding of the operator. We show that the error bound of the value function under the softmax operator and the optimal can be bounded and it is promising to use the softmax operator in continuous control. We demonstrate the smoothing effect of the softmax operator on the optimization landscape, and shows that it can provide better value estimations. Experimental results show the potential of our proposed algorithm to improve final performance and sample efficiency. It will be interesting to apply our algorithm in practical applications.",Broader Impact,141,6,,,FALSE,FALSE,FALSE,Softmax Deep Double Deterministic Policy Gradients,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Ling Pan', ' Qingpeng Cai', ' Longbo Huang']","{'IIIS, Tsinghua Univeristy', 'Alibaba Group', 'Tsinghua University'}",1,1,1,{'China'}
Online Decision Based Visual Tracking via Reinforcement Learning,"ke Song, Wei Zhang, Ran Song, Yibin Li",Online Decision Based Visual Tracking via Reinforcement Learning,885b2c7a6deb4fea10f319c4ce993e02,https://proceedings.neurips.cc/paper/2020/file/885b2c7a6deb4fea10f319c4ce993e02-Paper.pdf,"In this paper, the authors introduce DTNet which learns an online decision for switching to a proper tracker to conduct visual tracking in the current video frame. Although this paper only validates the efficacy of the decision learning framework in the specific scenario of visual tracking, it can actually be extended to other video-based computer vision tasks such as person re-identification, motion caption and action recognition, etc. It can be applied by defining a reward concerning the specific task and replacing the two trackers used in this paper with some other algorithms. To this end, the proposed DTNet could be of broad interest in different fields such as transportation industry, film industry, sport industry, etc. As a method for visual tracking, the DTNet can inevitably be used for monitoring and security purpose. As a learning-based method, what the DTNet can track, a person or a pet, essentially depends on the training data. Therefore, the risk of applying our method to some tasks that could raise ethical issues can be mitigated by imposing a strict and secure data protection regulation such as the GDPR. Without a sufficiently large amount of data of high quality that contain the particular target, the DTNet cannot deliver a good tracking in the particular task.",Broader Impact,209,8,,,FALSE,FALSE,FALSE,Online Decision Based Visual Tracking via Reinforcement Learning,Applications -> Tracking and Motion in Video,Reinforcement Learning and Planning -> Reinforcement Learning,Tracking and Motion in Video,"['ke Song', ' Wei Zhang', ' Ran Song', ' Yibin Li']","{'School of Control Science and Engineering, Shandong University', 'Shandong university', 'Shandong University'}",1,0,0,{'China'}
Efficient Marginalization of Discrete and Structured Latent Variables via Sparsity,"Gonçalo Correia, Vlad Niculae, Wilker Aziz, André Martins",Efficient Marginalization of Discrete and Structured Latent Variables via Sparsity,887caadc3642e304ede659b734f79b00,https://proceedings.neurips.cc/paper/2020/file/887caadc3642e304ede659b734f79b00-Paper.pdf,"We discuss here the broader impact of our work. Discussion in this section is predominantly speculative, as the methods described in this work are not yet tested in broader applications. However, we do think that the methods described here can be applied to many applications — as this work is applicable to any model that contains discrete latent variables, even of combinatorial type. Currently, the solutions available to train discrete latent variable models (LVMs) greatly rely on MC sampling, which can have high variance. Methods that aim to decrease this variance are often not trivial to train and to implement and may disincentivize practitioners from using this class of models. However, we believe that discrete LVMs have, in many cases, more interpretable and intuitive latent representations. Our methods offer: a simple approach in implementation to train these models; no addition in the number of parameters; low increase in computational overhead (especially when compared to more sophisticated methods of variance reduction [22]); and improved performance. Our code has been open-sourced as to ensure it’s scrutinizable by anyone and to boost any related future work that other researchers might want to pursue. As we have already pointed out, oftentimes LVMs have superior explanatory power and so can aid in understanding cases in which the model failed the downstream task. Interpretability of deep neural models can be essential to better discover any ethically harmful biases that exist in the data or in the model itself. On the other hand, the generative models discussed in this work may also pave the way for malicious use cases, such as is the case with Deepfakes , fake human avatars used by malevolent Twitter users, and automatically generated fraudulent news. Generative models are remarkable at sampling new instances of fake data and, with the power of latent variables, the interpretability discussed before can be used maliciously to further push harmful biases instead of removing them. Furthermore, our work is promising in improving the performance of LVMs with several discrete variables, that can be trained as attributes to control the sample generation. Attributes that can be activated or deactivated at will to generate fake data can both help beneficial and malignant users to finely control the generated sample. Our work may be currently agnostic to this, but we recognize the dangers and dedicate effort to combating any malicious applications. Energy-wise, LVMs often require less data and computation than other models that rely on a massive amount of data and infrastructure. This makes LVMs ideal for situations where data is scarce, or where there are few computational resources to train large models. We believe that better latent variable modeling is a step forward in the direction of alleviating environmental concerns of deep learning research [58]. However, the models proposed in this work tend to use more resources earlier on in training than standard methods, and even though in the applications shown they consume much less as training progresses, it’s not clear if that trend is still observed in all potential applications. In data science, LVMs, such as mixed-membership models [59], can be used to uncover correlations in large amounts of data, for example, by clustering observations. Training these models requires various degrees of approximations which are not without consequence, they may impact the quality of our conclusions and their fealty to the data. For example, variational inference tends to under-estimate uncertainty and give very little support to certain less-represented groups of variables. Where such a model informs decision-makers on matters that affect lives, these decisions may be based on an incomplete view of the correlations in the data and/or these correlations may be exaggerated in harmful ways. On the one hand, our work contributes to more stable training of LVMs, and thus it is a step towards addressing some of the many approximations that can blur the picture. On the other hand, sparsity may exhibit a larger risk of disregarding certain correlations or groups of observations, and thus contribute to misinforming the data scientist. At this point it is unclear to which extent the latter happens and, if it does, whether it is consistent across LVMs and their various uses. We aim to study this issue further and work with practitioners to identify failure cases.",Broader Impact,706,27,,,FALSE,TRUE,FALSE,Efficient Marginalization of Discrete and Structured Latent Variables via Sparsity,Probabilistic Methods -> Latent Variable Models,Deep Learning -> Generative Models; Probabilistic Methods -> Variational Inference,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Gonçalo Correia', ' Vlad Niculae', ' Wilker Aziz', ' André Martins']","{'University of Amsterdam', 'Instituto de Telecomunicações', 'Instituto de Telecomunicações, LUMIS Instituto Superior Técnico, Unbabel'}",1,1,1,"{'Portugal', 'Netherlands'}"
DeepI2I: Enabling Deep Hierarchical Image-to-Image Translation by Transferring from GANs,"yaxing wang, Lu Yu, Joost van de Weijer",DeepI2I: Enabling Deep Hierarchical Image-to-Image Translation by Transferring from GANs,88855547570f7ff053fff7c54e5148cc,https://proceedings.neurips.cc/paper/2020/file/88855547570f7ff053fff7c54e5148cc-Paper.pdf,"Computer Graphics (CG) plays a key role in the creative industries, especially for the movie industry. CG is the application of computer graphics to use the computer generated graphics and animation mostly for motion pictures, television commercials, videos, printed media and video games. Our application is in the field of machine learning applied to computer graphics. More specifically, our approach can be applied for the automatic translation of faces and/or objects. Traditionally, this technique is labour intensive. Potential danger of these techniques is that they can be applied for deepfakes which can be used to create fake events. The I2I algorithms reflect the biases present in the dataset. Therefore special attention should be taken when applying this technique to applications where possible biases in the dataset might result in biased outcomes towards minority and/or under- represented groups in the data.",Broader Impact,140,8,,,FALSE,FALSE,FALSE,DeepI2I: Enabling Deep Hierarchical Image-to-Image Translation by Transferring from GANs,Applications -> Computer Vision,,Deep learning,"['yaxing wang', 'Centre de Visió per Computador', ' Lu Yu', ' Joost van de Weijer']","{'CVC', 'computer vision center, UAB', 'Computer Vision Center Barcelona'}",1,1,1,{'Spain'}
Distributional Robustness with IPMs and links to Regularization and GANs,Hisham Husain,Distributional Robustness with IPMs and links to Regularization and GANs,8929c70f8d710e412d38da624b21c3c8,https://proceedings.neurips.cc/paper/2020/file/8929c70f8d710e412d38da624b21c3c8-Paper.pdf,"From the perspective of impact, the main contribution of our work is understanding how regularization, a commonly used technique in machine training, gives benefits for robustness. We show this for different areas of machine learning, such as supervised learning and generative adversarial networks. The ultimate goal of such work is to develop further our understanding of these methods and how their performances can be improved. Our work does not have a focused application use-case under which we can discuss specific ethical considerations since it contributes more generally to the advancements of performance. In this sense, ethical considerations are subject to the application of these methods.",Broader Impact,105,5,,,FALSE,FALSE,FALSE,Distributional Robustness with IPMs and links to Regularization and GANs,Theory -> Regularization,Deep Learning -> Adversarial Networks; Deep Learning -> Generative Models,Theory (including computational and statistical analyses),['Hisham Husain'],{'The Australian National University & Data61'},1,1,1,{'Australia'}
A shooting formulation of deep learning,"François-Xavier Vialard, Roland Kwitt, Susan Wei, Marc Niethammer",A shooting formulation of deep learning,89562dccfeb1d0394b9ae7e09544dc70,https://proceedings.neurips.cc/paper/2020/file/89562dccfeb1d0394b9ae7e09544dc70-Paper.pdf,"One goal of this work is to enrich the understanding of continuous depth neural networks and to open a different (or alternative) perspective on its parameterization. Specifically, we shift the parameterization of deep neural networks from a layer-by-layer perspective to an initial-value perspective and Hamiltonian dynamics. At this point, our work is conceptual and theoretical in nature; broader impact emerges most likely as a consequence of better understanding the role of neural network parameterizations.",Broader Impact,74,3,,,FALSE,FALSE,FALSE,A shooting formulation of deep learning,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks; Theory -> Models of Learning and Generalization,Deep learning,"['Xavier Vialard', ' Roland Kwitt', ' Susan Wei', ' Marc Niethammer']","{'UNC Chapel Hill', 'University of Salzburg', 'University of Melbourne', 'University Gustave Eiffel'}",1,0,0,"{'France', 'Austria', 'USA', 'Australia'}"
CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances,"Jihoon Tack, Sangwoo Mo, Jongheon Jeong, Jinwoo Shin",CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances,8965f76632d7672e7d3cf29c87ecaa0c,https://proceedings.neurips.cc/paper/2020/file/8965f76632d7672e7d3cf29c87ecaa0c-Paper.pdf,"This paper is focused on the subject of out-of-distribution (OOD) (or novelty, anomaly) detection, which is an essential ingredient for building safe and reliable intelligent systems [1]. We expect our results to have two consequences for academia and broader society. Rethinking representation for OOD detection. In this paper, we demonstrate that the representation for classification (or other related tasks, measured by linear evaluation [32]) can be different from the representation for OOD detection. In particular, we verify that the “hard” augmentations, thought to be harmful for contrastive representation learning [5], can be helpful for OOD detection. Our observation raises new questions for both representation learning and OOD detection: (a) representation learning researches should also report the OOD detection results as an evaluation metric, (b) OOD detection researches should more investigate the specialized representation. Towards reliable intelligent system. The intelligent system should be robust to the potential dangers of uncertain environments ( e . g ., financial crisis [65]) or malicious adversaries ( e . g ., cybersecurity [34]). Detecting outliers is also related to human safety ( e . g ., medical diagnosis [4] or autonomous driving [12]), and has a broad range of industrial applications ( e . g ., manufacturing inspection [42]). However, the system can be stuck into confirmation bias , i . e ., ignore new information with a myopic perspective. We hope the system to balance the exploration and exploitation of the knowledge.",Broader Impact,238,16,,,FALSE,FALSE,FALSE,CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances,Deep Learning,Algorithms -> Representation Learning; Algorithms -> Uncertainty Estimation,Deep learning,"['Jihoon Tack', ' Sangwoo Mo', ' Jongheon Jeong', ' Jinwoo Shin']",{'KAIST'},1,0,0,{'South Korea'}
Learning Implicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning,"Meng Zhou, Ziyu Liu, Pengwei Sui, Yixuan Li, Yuk Ying Chung",Learning Implicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning,8977ecbb8cb82d77fb091c7a7f186163,https://proceedings.neurips.cc/paper/2020/file/8977ecbb8cb82d77fb091c7a7f186163-Paper.pdf,"As many complex real-world problems can be formulated as cooperative multi-agent games, this work provides an effective approach to these problems. For example, decentralized agents can be applied to network routing optimization to speed up transmission, traffic management with autonomous vehicles to maximize traffic flow, and efficient package delivery with swarms of drones to reduce delivery costs. However, since our method relies on deep neural networks to implicitly attribute shared outcomes of the agent group to the individual agents, it faces the “black box problem” where behaviors of the individual agents may not be rational or interpretable from the human perspective. Furthermore, when maximizing a shared reward in multi-agent cooperative settings without considering the status of the individual agents, ethical issues may arise when the optimal joint actions require sacrificing certain agents. Using the task of traffic management with autonomous vehicles as an example, maximizing the total traffic volume could lead to indefinite delays for a subset of the vehicles.",Broader Impact,160,5,,,FALSE,FALSE,FALSE,Learning Implicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning,Reinforcement Learning and Planning -> Multi-Agent RL,,Reinforcement learning and planning,"['Meng Zhou', ' Ziyu Liu', ' Pengwei Sui', ' Yixuan Li', ' Yuk Ying Chung']","{'University of Sydney', 'The University of Sydney'}",1,0,0,{'Australia'}
MATE: Plugging in Model Awareness to Task Embedding for Meta Learning,"Xiaohan Chen, Zhangyang Wang, Siyu Tang, Krikamol Muandet",MATE: Plugging in Model Awareness to Task Embedding for Meta Learning,8989e07fc124e7a9bcbdebcc8ace2bc0,https://proceedings.neurips.cc/paper/2020/file/8989e07fc124e7a9bcbdebcc8ace2bc0-Paper.pdf,"Nowadays machine learning models requires training with a large number of samples. Humans, in contrast, learn new concepts and skills much faster and more efficiently. Even a kid who has seen cats and birds only a few times can quickly tell them apart. Inspired by that, meat learning aims to design a machine learning model with similar properties — learning a new task fast over a few training examples, via experiencing and summarizing generalizable rules from a family of similar tasks. Meta learning is significant in at least two-folds: 1) to reduce the labeled samples needed by training models to resolve certain task(s); and (2) to achieve open-end lifelong learning for a stream of tasks by transferring the acquired knowledge. Our MATE framework leverages a Hilbert space embedding framework and inject model awareness to (in principle) any meta learning algorithm. It shows to help the learning agent to adapt faster and better to new tasks, thanks to this new model-based inductive prior.",Broader Impact,162,7,,,FALSE,FALSE,FALSE,MATE: Plugging in Model Awareness to Task Embedding for Meta Learning,Algorithms -> Meta-Learning,Algorithms -> Kernel Methods,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Xiaohan Chen', ' Zhangyang Wang', ' Siyu Tang', ' Krikamol Muandet']","{'ETH Zurich', 'University of Texas at Austin', 'Max Planck Institute for Intelligent Systems'}",1,0,0,"{'USA', 'Switzerland', 'Germany'}"
"Restless-UCB, an Efficient and Low-complexity Algorithm for Online Restless Bandits","Siwei Wang, Longbo Huang, John C. S. Lui","Restless-UCB, an Efficient and Low-complexity Algorithm for Online Restless Bandits",89ae0fe22c47d374bc9350ef99e01685,https://proceedings.neurips.cc/paper/2020/file/89ae0fe22c47d374bc9350ef99e01685-Paper.pdf,"Online restless bandit model has found applications in many important areas such as wireless communications [3, 2], recommendation systems [30] and queueing systems [4]. Existing results face challenges including exponential implementation-complexity and regret bounds that are exponential in the size of the game [33, 22, 23]. Our Restless-UCB algorithm offers a novel approach that enjoys O ( N ) time-complexity to implement, which greatly reduces the running time in real applications.  Moreover, our analysis reduces the exponential factor in the regret upper bound to a polynomial one. Our work contributes to designing low-complexity and efficient learning policies for online restless bandit problem and can likely find applications in a wide range of areas.",Broader Impact,113,5,,,FALSE,FALSE,FALSE,"Restless-UCB, an Efficient and Low-complexity Algorithm for Online Restless Bandits",Algorithms -> Bandit Algorithms,Reinforcement Learning and Planning -> Reinforcement Learning,Online Learning and bandits model,"['Siwei Wang', ' Longbo Huang', ' Lui']","{'IIIS, Tsinghua Univeristy', 'IIIS, Tsinghua University', 'The Chinese University of Hong Kong'}",1,0,0,{'China'}
Predictive Information Accelerates Learning in RL,"Kuang-Huei Lee, Ian Fischer, Anthony Liu, Yijie Guo, Honglak Lee, John Canny, Sergio Guadarrama",Predictive Information Accelerates Learning in RL,89b9e0a6f6d1505fe13dea0f18a2dcfa,https://proceedings.neurips.cc/paper/2020/file/89b9e0a6f6d1505fe13dea0f18a2dcfa-Paper.pdf,"This work attempts to expand the applicability of RL to visual inputs and expand the range of RL applications, especially in Robotics. In its current form this work is applied to simulated environments, but thanks to the improvements in sample efficiency and generalization it increases the possibility of training directly on real-world robots. However, advancements in robotic automation likely have complex societal impacts. One potential risk is creating shifts in skill demand and thus structural unemployment. Improving RL autonomous agents’ applicability to visual inputs is a potential threat to a range of employment types, for example,  in the manufacturing industry. Public policy and regulation support will be necessary to reduce societal and economic friction as techniques like these are deployed in the physical world. On the other hand, potential positive outcomes from continued RL improvements include replacement of human workers at high-risk workspace, reduction of repetitive operations, and productivity increases. We see opportunities that researchers and engineers would benefit from adding CEB and the Predictive Information to the list of tools in RL. We would like to note that designing RL tasks and reward functions can have potential biases if applied to real systems that interact with users. Therefore we encourage further research to understand the impacts, implications, and limitations of using this work in real-world scenarios.",Broader Impact,217,10,,,FALSE,FALSE,FALSE,Predictive Information Accelerates Learning in RL,Reinforcement Learning and Planning -> Reinforcement Learning,Theory -> Information Theory,Reinforcement learning and planning,"['Huei Lee', ' Ian Fischer', ' Anthony Z Liu', ' Yijie Guo', ' Honglak Lee', ' John Canny', ' Sergio Guadarrama']","{'Google Brain', 'Google Research', 'University of Michigan', 'Google', 'UC Berkeley'}",1,1,1,{'USA'}
"Robust and Heavy-Tailed Mean Estimation Made Simple, via Regret Minimization","Sam Hopkins, Jerry Li, Fred Zhang","Robust and Heavy-Tailed Mean Estimation Made Simple, via Regret Minimization",8a1276c25f5efe85f0fc4020fbf5b4f8,https://proceedings.neurips.cc/paper/2020/file/8a1276c25f5efe85f0fc4020fbf5b4f8-Paper.pdf,"We believe that our work is an important step on the design and analysis of efficient methods in algo- rithmic high-dimensional robust statistics. In particular, our unified perspective may be applicable to to other tasks in this field, so we expect it will continue to generate academic impact. Moreover, the area should be viewed as the theoretical foundation of robust and trust-worthy machine learning. Hence, we hope that our contributions will eventually have positive downstream implications for learning in sefety-critical settings.",5 Broader Impact Statement,81,4,,,FALSE,FALSE,FALSE,"Robust and Heavy-Tailed Mean Estimation Made Simple, via Regret Minimization",Theory -> High-Dimensional Inference,Algorithms -> Spectral Methods,Theory (including computational and statistical analyses),"['Sam Hopkins', ' Jerry Li', ' Fred Zhang']","{'UC Berkeley', 'Microsoft'}",1,1,1,{'USA'}
High-Fidelity Generative Image Compression,"Fabian Mentzer, George D. Toderici, Michael Tschannen, Eirikur Agustsson",High-Fidelity Generative Image Compression,8a50bae297807da9e97722a0b3fd8f27,https://proceedings.neurips.cc/paper/2020/file/8a50bae297807da9e97722a0b3fd8f27-Paper.pdf,"Users of our compression method can benefit from better reconstructions at lower bitrates, reducing the amount of storage needed to save pictures and the bandwidth required to transmit pictures. The latter is important as wireless technology typically lags behind user trends which have been continuously requiring higher bandwidths over the past decades, and there is no end in sight with emerging applications such as virtual reality. Furthermore, better compression technology improves accessibility in developing areas of the world where the wireless infrastructure is less performant and robust than in developed countries. It is important to keep in mind that we employ a generator G that in theory can produce images that are very different from the input. While this is the case for any lossy image compression algorithm, this has a bigger impact here as we specifically train G for realistic reconstructions. Therefore, we emphasize that our method is not suitable for sensitive image contents, such as, e.g. , storing medical images, or important documents.",Broader Impact,165,6,,,FALSE,FALSE,FALSE,High-Fidelity Generative Image Compression,Algorithms -> Data Compression,Deep Learning -> Generative Models,Deep learning,"['Fabian Mentzer', ' George D Toderici', ' Michael Tschannen', ' Eirikur Agustsson']","{'Google', 'ETH Zurich', 'Google Brain'}",1,1,1,"{'USA', 'Switzerland'}"
A Statistical Mechanics Framework for Task-Agnostic Sample Design in Machine Learning,"Bhavya Kailkhura, Jayaraman J. Thiagarajan, Qunwei Li, Jize Zhang, Yi Zhou, Timo Bremer",A Statistical Mechanics Framework for Task-Agnostic Sample Design in Machine Learning,8a7129b8f3edd95b7d969dfc2c8e9d9d,https://proceedings.neurips.cc/paper/2020/file/8a7129b8f3edd95b7d969dfc2c8e9d9d-Paper.pdf,"In this paper, we introduce a statistical mechanics framework to understand the effect of sample design on the generalization gap of ML algorithms. Our framework could be applied to a wide range of applications, including scientific ML, design and optimization in engineering, agricultural experiments, and many more. It can also play an important building block for several ML problems, such as, supervised ML, neural network training, image reconstruction, reinforcement learning, etc. We expect that our framework will significantly improve the quality of inference and our current understanding in several science and engineering applications where ML is applied. Our focus on this paper has been understanding the effect of sample design on the generalization gap, however, in several applications we may additionally want to understand implication of a sample design on fairness, robustness, privacy, etc. This is an unexplored area in sample design and we encourage researchers to understand and mitigate the risks arising from task-agnostic designs in these contexts.",Broader Impact,159,6,,,FALSE,FALSE,FALSE,A Statistical Mechanics Framework for Task-Agnostic Sample Design in Machine Learning,Algorithms -> Spectral Methods,Theory -> Models of Learning and Generalization,,"['Bhavya Kailkhura', ' Thiagarajan', ' Qunwei Li', ' Jize Zhang', ' Yi Zhou', ' Timo Bremer']","{'University of Utah', 'Lawrence Livermore National Laboratory', 'Ant Financial', 'Lawrence Livermore National Lab', 'Lawrence Livermore National Labs'}",1,1,1,{'USA'}
Counterexample-Guided Learning of Monotonic Neural Networks,"Aishwarya Sivaraman, Golnoosh Farnadi, Todd Millstein, Guy Van den Broeck",Counterexample-Guided Learning of Monotonic Neural Networks,8ab70731b1553f17c11a3bbc87e0b605,https://proceedings.neurips.cc/paper/2020/file/8ab70731b1553f17c11a3bbc87e0b605-Paper.pdf,"In scenarios where monotonicity is a natural and fair requirement on the learned function, it is clear that eliminating errors or noise coming from monotonicity violations can increase the fairness of the predictions, and eliminate some frustration with receiving arbitrary outcomes. At the same time, one can imagine someone requiring monotonicity of certain features that should not be monotonic, and the work in this paper can enable such undesirable behavior. By incorporating correct and ethical domain knowledge using our algorithms, we make the learned model more robust. We acknowledge that the counterexamples generated based on data can be used in ways other than the ways mentioned in this paper. Although our approach can produce monotonic predictions, it is still based on a model produced by a machine learning algorithm. Therefore, it becomes essential to understand that the monotonic model could also suffer from the same disadvantages as the original model, and reinforce the same biases. Hence, the user must be aware of such a system’s limitations, especially when using these models to replace people in decision making.",Broader Impact,177,7,,,TRUE,TRUE,FALSE,Counterexample-Guided Learning of Monotonic Neural Networks,Deep Learning -> Supervised Deep Networks,Applications -> Automated Reasoning and Formal Methods; Social Aspects of Machine Learning -> AI Safety,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Aishwarya Sivaraman', ' Golnoosh Farnadi', ' Todd Millstein', ' Guy Van den Broeck']","{'UCLA', 'Mila'}",1,0,0,"{'Canada', 'USA'}"
A Novel Approach for Constrained Optimization in Graphical Models,"Sara Rouhani, Tahrima Rahman, Vibhav Gogate",A Novel Approach for Constrained Optimization in Graphical Models,8ab9bb97ce35080338be74dc6375e0ed,https://proceedings.neurips.cc/paper/2020/file/8ab9bb97ce35080338be74dc6375e0ed-Paper.pdf,"Our work has mostly theoretical value and will require substantial effort and human-power in order to be used for commercial, government or defense purposes. The presented CMPE problem has potential applications in many sub-fields of AI and machine learning (ML) including computer vision, robotics, economics, operations research, NLP, and computational Biology where graphical models are used to represent and reason about structural features and uncertainty. The algorithm developed in this paper can be immediately leveraged to solve hard reasoning problems in these domains. Apart from these obvious advantages that any optimization algorithm can bring to bear, as scientific research evolves, our work and technology can be misused deliberately or unknowingly. For example, finding the most likely assignment to all unobserved variables given evidence such that the model makes a specific decision is an application of our research. While it benefits the society via its superior prediction ability and potentially improving users’ trust in the system, it can be misused by making a model make decisions in favor of a special group of people and harm the vulnerable ones (by appropriately modifying the constraints in CMPE), specifically in financial organizations. Our research can potentially lead to a practical tool which helps physicians diagnose diseases in a robust manner and fill up appropriate prescriptions by resolving conflicts. However, if the prior knowledge expressed in the graphical model is wrong or the relationships are learned inaccurately or the approximation error of our proposed algorithm is large (e.g., the problem belongs to one of the hard cases described in the experiments section), it may lead physicians to make a wrong decision/diagnosis. The negative consequences of this can be quite dire. Today, a wide variety of tasks which are special cases of CMPE are solved by hand. In particular, several local experts who understand problem structure and who use implicit heuristic algorithms for solving special cases of CMPE are employed by various small businesses such as mom-and-pop moving companies, florists and local food delivery companies (not Grubhub). An advanced, easy to use tool for CMPE will obviate the need for local experts and may lead to significant job losses. Although the regulation and legal systems supported by governments along with developing profound knowledge about application fields can significantly manage potential harmful effects of such job losses (e.g., universal basic income), some damages are naturally inevitable.",7 Broader Impact,390,13,,,FALSE,FALSE,FALSE,A Novel Approach for Constrained Optimization in Graphical Models,Probabilistic Methods -> Graphical Models,Optimization -> Discrete Optimization,Probabilistic methods and inference,"['Sara Rouhani', ' Tahrima Rahman', ' Vibhav Gogate']","{'UT Dallas', 'University of Texas at Dallas'}",1,0,0,{'USA'}
Global Convergence of Deep Networks with One Wide Layer Followed by Pyramidal Topology,"Quynh N. Nguyen, Marco Mondelli",Global Convergence of Deep Networks with One Wide Layer Followed by Pyramidal Topology,8abfe8ac9ec214d68541fcb888c0b4c3,https://proceedings.neurips.cc/paper/2020/file/8abfe8ac9ec214d68541fcb888c0b4c3-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Global Convergence of Deep Networks with One Wide Layer Followed by Pyramidal Topology,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Quynh N Nguyen', ' Marco Mondelli']","{'IST Austria', 'Saarland University'}",1,0,0,"{'Austria', 'Germany'}"
On the Trade-off between Adversarial and Backdoor Robustness,"Cheng-Hsin Weng, Yan-Ting Lee, Shan-Hung (Brandon) Wu",On the Trade-off between Adversarial and Backdoor Robustness,8b4066554730ddfaa0266346bdc1b202,https://proceedings.neurips.cc/paper/2020/file/8b4066554730ddfaa0266346bdc1b202-Paper.pdf,"Currently, the adversarial learning communities are aware of the adversarial attacks, backdoor attacks, and their respective defenses. However, the interactions between the vulnerabilities of a network to both types of attacks have not been carefully investigated yet. Our findings in this paper have implications for both existing systems and future research in adversarial learning. The Bad. The trade-off between the adversarial and backdoor robustness could be exploited by an adversary to create stronger and/or sneak attacks against existing security-critical machine learning systems and applications. Future research on defense should take both adversarial and backdoor attacks into account when designing algorithms or robustness measures to avoid pitfalls and a false sense of security. The Good. On the other hand, our findings give a guide on the selection of existing adversarial and backdoor defenses to achieve simultaneous adversarial and backdoor robustness. In addition, our finding that the trade-off improves the post-training backdoor defenses based on neural cleansing [39] also opens a door for joint adversarial and backdoor defense in the future. In particular, the “adversarial complement” of the work [30] on reverse-engineering triggers via generative distribution modeling seems to be a promising direction.",Broader Impact,191,10,,,FALSE,FALSE,FALSE,On the Trade-off between Adversarial and Backdoor Robustness,Algorithms -> Adversarial Learning,Deep Learning,,"['Hsin Weng', 'Ting Lee', 'Hung', ' Wu']","{'National Tsing Hua University', 'Brandon'}",1,0,0,"{'China', 'Taiwan'}"
Implicit Graph Neural Networks,"Fangda Gu, Heng Chang, Wenwu Zhu, Somayeh Sojoudi, Laurent El Ghaoui",Implicit Graph Neural Networks,8b5c8441a8ff8e151b191c53c1842a38,https://proceedings.neurips.cc/paper/2020/file/8b5c8441a8ff8e151b191c53c1842a38-Paper.pdf,"GNN models are widely used on applications involving graph-structured data, including computer vision, recommender systems, and biochemical strucature discovery. Backed by more rigorous mathematical arguments, our research improves the capability GNNs of capturing the long-range dependency and therefore boosts the performance on these applications. The improvements of performance in the applications will give rise to a better user experience of products and new discoveries in other research fields. But like any other deep learning models, GNNs runs into the problem of interpretability. The trade-off between performance and interpretability has been a topic of discussion. On one hand, the performance from GNNs benefits the tasks. On the other hand, the lack of interpretability might make it hard to recognize underlying bias when applying such algorithm to a new data set. Recent works (Hardt et al., 2016) propose to address the fairness issue by enforcing the fairness constraints. While our research focuses on performance by capturing the long-range dependency, like many other GNNs, it does not directly tackle the fairness and interpretability aspect. We would encourage further work on fairness and interpretability on GNNs. Another contribution of our research is on the analysis of heterogeneous networks, where the fairness on treatment of different relationships remains unexplored. The risk of discrimination in particular real-world context might require cautious handling when researchers develop models.",Broader Impact,220,12,,,FALSE,FALSE,FALSE,Implicit Graph Neural Networks,Algorithms -> Representation Learning,Deep Learning -> Optimization for Deep Networks; Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization,Deep learning,"['Fangda Gu', ' Heng Chang', ' Wenwu Zhu', ' Somayeh Sojoudi', ' Laurent El Ghaoui']","{'UC Berkeley', 'University of California, Berkeley', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Rethinking Importance Weighting for Deep Learning under Distribution Shift,"Tongtong Fang, Nan Lu, Gang Niu, Masashi Sugiyama",Rethinking Importance Weighting for Deep Learning under Distribution Shift,8b9e7ab295e87570551db122a04c6f7c,https://proceedings.neurips.cc/paper/2020/file/8b9e7ab295e87570551db122a04c6f7c-Paper.pdf,"Distribution shift exists almost everywhere in the wild for reasons ranging from the subjective bias in data collection to the non-stationary environment. The shift poses threats for various applications of machine learning. For example, in the context of autonomous driving, the biased-to-training-data model may pose safety threats when applied in practice; and in a broader social science perspective, the selection bias in data preparation process may lead to fairness issues on gender, race or nation.  In this work, we aim to mitigate the distribution shift. We rethink the traditional importance weighting method in non-deep learning and propose a novel dynamic importance weighting framework that can leverage more expressive power of deep learning. We study it theoretically and algorithmically. As shown in the experiments, our proposed method can successfully learn robust classifiers under different forms of distribution shift. In ablation study, we also provide practical advices on algorithm design for practitioners.",7 Broader impact,150,8,,,FALSE,FALSE,FALSE,Rethinking Importance Weighting for Deep Learning under Distribution Shift,Algorithms -> Classification,Algorithms -> Representation Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Tongtong Fang', ' Nan Lu', ' Gang Niu', ' Masashi Sugiyama']","{'RIKEN / University of Tokyo', 'RIKEN', 'KTH Royal Institute of Technology', 'University of Tokyo/ RIKEN-AIP'}",1,0,0,"{'Japan', 'Sweden'}"
Guiding Deep Molecular Optimization with Genetic Exploration,"Sung-Soo Ahn, Junsu Kim, Hankook Lee, Jinwoo Shin",Guiding Deep Molecular Optimization with Genetic Exploration,8ba6c657b03fc7c8dd4dff8e45defcd2,https://proceedings.neurips.cc/paper/2020/file/8ba6c657b03fc7c8dd4dff8e45defcd2-Paper.pdf,"De novo molecular design. Our framework is likely to advance the field of de novo molecular design. In this field, successful algorithms significantly impact real-world, since the discovery of a new molecule has been the key challenge of many applications. Domain of such applications includes, but are not limited to, drug molecules [67], organic light emitting diodes [68], organic solar cells [69], energetic materials [70], and electrochromic devices [71]. Improvements in these applications are beneficial to human kind in general, as they often improve the quality of human life and may broaden our knowledge of chemistry. Combinatorial optimization with deep reinforcement learning. In a broader sense, our framework offers a new paradigm to search over a intractably large space of combinatorial objects with DNN. In particular, our algorithm is expected to perform well for domains where genetic algorithms are powerful; this includes domains of biological sequence design [64], program synthesis [65], and vehicle routing problems [66]. Hence, at a high-level, our work also shares the domain of applications impacted from such works.",Broader Impact,172,9,,,FALSE,FALSE,FALSE,Guiding Deep Molecular Optimization with Genetic Exploration,Deep Learning,Applications -> Computational Biology and Bioinformatics; Reinforcement Learning and Planning,"Other applications (e.g., robotics, biology, climate, finance)","['Soo Ahn', ' Junsu Kim', ' Hankook Lee', ' Jinwoo Shin']","{'Korea Advanced Institute of Science and Technology', 'KAIST'}",1,0,0,{'South Korea'}
Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks,"Wenrui Zhang, Peng Li",Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks,8bdb5058376143fa358981954e7626b8,https://proceedings.neurips.cc/paper/2020/file/8bdb5058376143fa358981954e7626b8-Paper.pdf,"Our proposed Temporal Spike Sequence Learning Backpropagation (TSSL-BP) method is able to train deep SNNs while achieving the state-of-the-art efficiency and accuracy. TSSL-BP breaks down error backpropagation across two types of inter-neuron and intra-neuron dependencies and leads to improved temporal learning precision. It captures inter-neuron dependencies through presynaptic firing times by considering the all-or-none characteristics of firing activities, and captures intra-neuron dependencies by handling the internal evolution of each neuronal state in time. Spiking neural networks offer a very appealing biologically plausible model of computation and may give rise to ultra-low power inference and training on recently emerged large-scale neuromorphic computing hardware. Due to the difficulties in dealing with the all-or-one characteristics of spiking neurons, however, training of SNNs is a major present challenge and has limited wide adoption of SNNs models. The potential impacts of this work are several-fold: 1) Precision : TSSL-BP offers superior precision in learning arbitrarily specified target temporal sequences, outperforming all recently developed the-state-of-the-art SNN BP methods. 2) Low latency : TSSL-BP delivers high-precision training over a very short temporal window of a few time steps. This is contrast with many BP methods that require hundreds of time steps for maintaining a decent accuracy. Low latency computation immediately corresponds to fast decision making. 3) Scalability and energy efficiency : The training of SNNs is signficantly more costly than that of the conventional neural networks. The training cost is one major bottleneck to training large/deep SNNs in order to achieve competitive performance. The low latency training capability of TSSL- BP reduces the training cost by more than one order of magnitude and also cuts down the energy dissipation of the training and inference on the deployed computing hardware. 4) Community impact : TSSL-BP has been prototyped based on the widely adopted Pytorch frame- work and will be made available to the public. We believe our TSSL-BP code will benefit the brain-inspired computing community from both an algorithmic and neuromorphic computing hardware development perspective.",Broader Impact,327,14,,,FALSE,FALSE,FALSE,Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks,Deep Learning -> Biologically Plausible Deep Networks,Deep Learning -> Supervised Deep Networks,Deep learning,"['Wenrui Zhang', ' Peng Li']","{'University of California, Santa Barbara'}",1,0,0,{'USA'}
TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation,"DONGXU LI, Chenchen Xu, Xin Yu, Kaihao Zhang, Benjamin Swift, Hanna Suominen, Hongdong Li",TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation,8c00dee24c9878fea090ed070b44f1ab,https://proceedings.neurips.cc/paper/2020/file/8c00dee24c9878fea090ed070b44f1ab-Paper.pdf,"As of the year 2020, 466 million people worldwide, one in every ten people, has disabling hearing loss. And by the year of 2050, it is estimated that this number will grow to over 900 million [ 42]. Assisting deaf and hard-of-hearing people to participate fully and feel entirely included in our society is critical and can be facilitated by maximizing their ability to communicate with others in sign languages, thereby minimizing the impact of disability and disadvantage on performance. Communication difficulties experienced by deaf and hard-of-hearing people may lead to unwelcome feelings of isolation, frustration and other mental health issues. Their global cost, including the loss of productivity and deaf service support packages, is US$ 750 billion per annum in the healthcare expenditure alone [42]. The technique developed in this work contributes to the design of automated sign language interpretation systems. Successful applications of such communication technologies would facilitate access and inclusion of all community members. Our work also promotes the public awareness of people living with hearing or other disabilities, who are commonly under-representative in social activities. With more research works on automated sign language interpretation, our ultimate goal is to encourage equitable distribution of health, education, and economic resources in the society. Failure in translation leads to potential miscommunication. However, achieving highly-accurate automated translation systems that are trustworthy even in life-critical emergency and health care situations requires further studies and regulation. In scenarios of this kind, automated sign language translators are recommended to serve as auxiliary communication tools, rather an alternative to human interpreters. Moreover, RPWT dataset was sourced from TV weather forecasting, consequently, is biased towards this genre. Hence, its applicability to real-life use may be limited. Despite this linguistic limitation, RPWT remains the only existing large-scale dataset for sign language translation; this under-resourced area deserves more attention. Both datasets and models ought to be developed.",Broader Impact,310,16,,,FALSE,FALSE,FALSE,TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation,"Applications -> Body Pose, Face, and Gesture Analysis",Applications -> Computer Vision,Vision,"['DONGXU LI', ' Chenchen Xu', ' Xin Yu', ' Kaihao Zhang', ' Benjamin Swift', ' Hanna Suominen', ' Hongdong Li']","{'The Australian National University', 'Australian National University', 'The Australian National University and Data61/CSIRO', 'University of Technology Sydney', 'THE AUSTRALIAN NATIONAL UNIVERSITY'}",1,0,0,{'Australia'}
Neural Topographic Factor Analysis for fMRI Data,"Eli Sennesh, Zulqarnain Khan, Yiyu Wang, J Benjamin Hutchinson, Ajay Satpute, Jennifer Dy, Jan-Willem van de Meent",Neural Topographic Factor Analysis for fMRI Data,8c3c27ac7d298331a1bdfd0a5e8703d3,https://proceedings.neurips.cc/paper/2020/file/8c3c27ac7d298331a1bdfd0a5e8703d3-Paper.pdf,"While this paper reports on NTFA in terms of its characteristics as a general-purpose machine learning method for the analysis of neuroimaging data, we envision downstream impacts in the context of specific neuroscientific research questions. There is a need in neuroscience research to develop formal computational approaches that capture individual differences in neural function. The embedding space yields a simple, visualizable model to inspect individual differences that has the potential to, at least in a qualitative manner, provide insights into fundamental questions in cognitive neuroscience. One such question is whether neural responses to stimuli are shared across individuals, vary by pre-defined participants groups (e.g. depressed vs. non-depressed participants), or are unique to participants or subgroups (e.g. as suggested by calls for “precision medicine” approaches). Going forward, we will use our pilot data to address whether the neural basis of fear, for example, is shared across individuals and situations (i.e. there is a single “biomarker” or “neural signature” for fear), or as we expect, whether it varies by person or situation (suggesting that biomarkers for fear are idiographic) [Satpute and Lindquist, 2019]. With further developments, we plan to perform more extensive neuroimaging experiments that probe individual variation in additional fMRI datasets including in house datasets and publicly available datasets. Our hope is that the work presented in this paper will form a basis for developing probabilistic factor-analysis models with structured priors that will allow testing and development of specific neuroscientific hypotheses regarding individual variation in the functional neural organization of psychological processes.",Broader Impact,251,7,,,FALSE,FALSE,FALSE,Neural Topographic Factor Analysis for fMRI Data,Neuroscience and Cognitive Science -> Brain Imaging,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Algorithms -> Representation Learning; Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models; Probabilistic Methods -> Hierarchical Models; Probabilistic Methods -> Latent Variable Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Eli Sennesh', ' Zulqarnain Khan', ' Yiyu Wang', ' J Benjamin Hutchinson', ' Ajay Satpute', ' Jennifer Dy', 'Willem van de Meent']","{'University of Oregon', 'Northeastern University', 'Northeastern'}",1,0,0,{'USA'}
Neural Architecture Generator Optimization,"Robin Ru, Pedro Esperança, Fabio Maria Carlucci",Neural Architecture Generator Optimization,8c53d30ad023ce50140181f713059ddf,https://proceedings.neurips.cc/paper/2020/file/8c53d30ad023ce50140181f713059ddf-Paper.pdf,"As highlighted in [7], NAS literature has focused for a long time on achieving higher accuracies, no matter the source of improvement. This has lead to the widespread use of narrowly engineered search spaces, in which all considered architectures share the same human defined macro-structure. While this does lead to higher accuracies, it prevents those methods from ever finding truly novel architecture. This is detrimental both for the community, which has focused many works on marginally improving performance in a shallow pond, but also for the environment [61]. As NAS is undoubtedly computationally intensive, researchers have the moral obligation to make sure these resources are invested in meaningful pursuits: our flexible search space, based on hierarchical graphs, has the potential to find truly novel network paradigms, leading to significant changes in the way we design networks. It is worth mentioning that, as our search space if fundamentally different from previous ones, it is not trivial to use the well-optimised training techniques (e.g. DropPath, Auxiliary Towers, etc.) which are commonly used in the field. While transferring those techniques is viable, we do believe that our new search space will open up the development of novel training techniques. We do however acknowledge that the computational costs of using our NAS approach are still relatively high - this may not be attractive to the industrial or academic user with limited resources. On the other hand, by converting NAS to a low-dimensional hyperparameter optimisation problem, we have significantly reduced the optimisation difficulty and opened up the chance of applying more optimisation techniques to NAS. Although only demonstrated with BOHB and MOBO in this work, we believe more query-efficient methods, such as BO works based on transfer learning [62, 63, 64, 65, 66, 67] can be deployed directly on our search space to further reduce the computation costs.",6 Broader Impact,303,11,,,FALSE,FALSE,FALSE,Neural Architecture Generator Optimization,Algorithms -> AutoML,Deep Learning -> CNN Architectures,AutoML,"['Robin Ru', ' Pedro M Esperança', ' Fabio Maria Carlucci']","{'Huawei', 'Sapienza University of Rome', 'Oxford University'}",1,1,1,"{'UK', 'Italy', 'China'}"
A Bandit Learning Algorithm and Applications to Auction Design,Kim Thang Nguyen,A Bandit Learning Algorithm and Applications to Auction Design,8ccf1fb8b09a8212bafea305cf5d5e9f,https://proceedings.neurips.cc/paper/2020/file/8ccf1fb8b09a8212bafea305cf5d5e9f-Paper.pdf,"As for the ethical and future societal direct consequences, this is not relevant in the context of this paper.",Broader Impact,19,1,TRUE,FALSE,FALSE,FALSE,FALSE,A Bandit Learning Algorithm and Applications to Auction Design,Theory -> Game Theory and Computational Economics,Algorithms -> Online Learning,Theory (including computational and statistical analyses),['Kim Thang Nguyen'],"{'IBISC, University Paris-Saclay'}",1,0,0,{'France'}
MetaPoison: Practical General-purpose Clean-label Data Poisoning,"W. Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, Tom Goldstein",MetaPoison: Practical General-purpose Clean-label Data Poisoning,8ce6fc704072e351679ac97d4a985574,https://proceedings.neurips.cc/paper/2020/file/8ce6fc704072e351679ac97d4a985574-Paper.pdf,"Data lies at the heart of modern machine learning systems. The ability of MetaPoison to attack real-world systems is should raise awareness of its broader implications on computer security and data/model governance. While a full discussion should involve all stakeholders, we provide here some initial comments. First, data and model governance is of utmost importance when it comes to, among other things, mitigating data poisoning. Bursztein [2018] provides some common-sense steps to take when curating a training set. For example, one should ensure that no single source of data accounts for a large fraction of the training set or even of a single class, so as to keep the poison budget low for a malicious data contributor. Second, it is easier to defend against wholesale model skewing attacks which aim to reduce overall model performance or to bias it toward some direction. Targeted attacks such as ours, on the other hand, are far more difficult to mitigate, since the overall model behavior is unchanged and the target input on which the model’s behavior is changed is not known to the victim. Systems should rely on additional auxiliary measures, such as interpretability techniques [Kim et al., 2017], to make security-critical decisions. Third, at the moment, the computational power required to craft MetaPoison examples exceeds that of evasion attacks by a large margin. This provides researchers time to design mitigation strategies before it becomes a dominant threat to real-world systems, as well as study robust learning techniques that leverage, e.g., computational hardness [Mahloujifar and Mahmoody, 2019]. As a final note, data poisoning techniques are not limited to nefarious uses. For example, it can be used for copyright enforcement as discussed in §1 and similar to the concept of “radioactive data” [Sablayrolles et al., 2020]. Another non-nefarious use case is privacy protection [Shan et al., 2020].",Broader Implications,303,14,,,TRUE,TRUE,FALSE,MetaPoison: Practical General-purpose Clean-label Data Poisoning,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Adversarial Learning; Algorithms -> Meta-Learning; Deep Learning -> Adversarial Networks; Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","[' Ronny Huang', ' Jonas Geiping', ' Liam Fowl', ' Gavin Taylor', ' Tom Goldstein']","{'EY', 'US Naval Academy', 'University of Maryland', 'University of Siegen'}",1,0,0,"{'USA', 'Germany'}"
Sample Efficient Reinforcement Learning via Low-Rank Matrix Estimation,"Devavrat Shah, Dogyoon Song, Zhi Xu, Yuzhe Yang",Sample Efficient Reinforcement Learning via Low-Rank Matrix Estimation,8d2355364e9a2ba1f82f975414937b43,https://proceedings.neurips.cc/paper/2020/file/8d2355364e9a2ba1f82f975414937b43-Paper.pdf,"As reinforcement learning becomes increasingly popular in practice and the problem dimension grows, there is a soaring demand for data-efficient learning algorithms. Through the lens of low-rank representation of so-called Q -function, this work proposes a theoretical framework to devise efficient RL algorithms. The resulting “low-rank” algorithm, which utilizes a novel matrix estimation method, offers both strong theoretical guarantees and appealing empirical performance. In particular, the novel “low-rank” perspective about RL provides an effective tool to tackle RL problems with both state and action spaces continuous, which have received much less attention despite their practical significance. We believe that this work serves as an important step towards provable efficient RL for continuous problems. The theoretical insights in this work can motivate further research in both efficient RL and ME, while the empirical results should be beneficial more broadly for practitioners working in continuous controls.",Broader Impact,144,6,,,FALSE,FALSE,FALSE,Sample Efficient Reinforcement Learning via Low-Rank Matrix Estimation,Reinforcement Learning and Planning,Theory,Reinforcement learning and planning,"['Devavrat Shah', ' Dogyoon Song', ' Zhi Xu', ' Yuzhe Yang']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Training Generative Adversarial Networks with Limited Data,"Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, Timo Aila",Training Generative Adversarial Networks with Limited Data,8d30aa96e72440759f74bd2306c1fa3d,https://proceedings.neurips.cc/paper/2020/file/8d30aa96e72440759f74bd2306c1fa3d-Paper.pdf,"Data-driven generative modeling means learning a computational recipe for generating complicated data based purely on examples. This is a foundational problem in machine learning. In addition to their fundamental nature, generative models have several uses within applied machine learning research as priors, regularizers, and so on. In those roles, they advance the capabilities of computer vision and graphics algorithms for analyzing and synthesizing realistic imagery. The methods presented in this work enable high-quality generative image models to be trained using significantly less data than required by existing approaches. It thereby primarily contributes to the deep technical question of how much data is enough for generative models to succeed in picking up the necessary commonalities and relationships in the data. From an applied point of view, this work contributes to efficiency; it does not introduce fundamental new capabilities. Therefore, it seems likely that the advances here will not substantially affect the overall themes— surveillance, authenticity, privacy, etc.— in the active discussion on the broader impacts of computer vision and graphics. Specifically, generative models’ implications on image and video authenticity is a topic of active discussion. Most attention revolves around conditional models that allow semantic control and sometimes manipulation of existing images. Our algorithm does not offer direct controls for highlevel attributes (e.g., identity, pose, expression of people) in the generated images, nor does it enable direct modification of existing images. However, over time and through the work of other researchers, our advances will likely lead to improvements in these types of models as well. The contributions in this work make it easier to train high-quality generative models with custom sets of images. By this, we eliminate, or at least significantly lower, the barrier for applying GAN-type models in many applied fields of research. We hope and believe that this will accelerate progress in several such fields. For instance, modeling the space of possible appearance of biological specimens (tissues, tumors, etc.) is a growing field of research that appears to chronically suffer from limited high-quality data. Overall, generative models hold promise for increased understanding of the complex and hard-to-pinpoint relationships in many real-world phenomena; our work hopefully increases the breadth of phenomena that can be studied.",Broader impact,364,18,,,TRUE,TRUE,FALSE,Training Generative Adversarial Networks with Limited Data,Deep Learning -> Generative Models,Algorithms -> Unsupervised Learning; Deep Learning -> Adversarial Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Tero Karras', ' Miika Aittala', ' Janne Hellsten', ' Samuli Laine', ' Jaakko Lehtinen', ' Timo Aila']","{'MIT CSAIL / NVIDIA', 'NVIDIA'}",1,1,1,{'USA'}
Deeply Learned Spectral Total Variation Decomposition,"Tamara G. Grossmann, Yury Korolev, Guy Gilboa, Carola Schoenlieb",Deeply Learned Spectral Total Variation Decomposition,8d3215ae97598264ad6529613774a038,https://proceedings.neurips.cc/paper/2020/file/8d3215ae97598264ad6529613774a038-Paper.pdf,"This statement does not apply to this paper. We are concerned with computing a decomposition modelled by a PDE that can already be solved by model-driven methods, however we considerably reduce the computational cost in our approach. Therefore, we do not expect it to have immediate broader impact on society.",Broader Impacts,50,3,TRUE,TRUE,FALSE,FALSE,FALSE,Deeply Learned Spectral Total Variation Decomposition,Applications -> Computer Vision,Applications -> Denoising; Applications -> Signal Processing; Deep Learning -> CNN Architectures; Deep Learning -> Supervised Deep Networks,Deep learning,"['Tamara Grossmann', ' Yury Korolev', ' Guy Gilboa', ' Carola Schoenlieb']","{'University of Cambridge', 'Cambridge University', 'Technion'}",1,1,1,"{'UK', 'Israel'}"
FracTrain: Fractionally Squeezing Bit Savings Both Temporally and Spatially for Efficient DNN Training,"Yonggan Fu, Haoran You, Yang Zhao, Yue Wang, Chaojian Li, Kailash Gopalakrishnan, Zhangyang Wang, Yingyan Lin",FracTrain: Fractionally Squeezing Bit Savings Both Temporally and Spatially for Efficient DNN Training,8dc5983b8c4ef1d8fcd5f325f9a65511,https://proceedings.neurips.cc/paper/2020/file/8dc5983b8c4ef1d8fcd5f325f9a65511-Paper.pdf,"Our FracTrain framework will potentially have a deep social impact due to its impressive efforts on efficient DNN training, which will greatly contribute to the popularization of Artificial Intelligence in daily life. Efficient DNN training techniques are necessary from two aspects. For one thing, recent breakthroughs in deep neural networks (DNNs) have motivated an explosive demand for intelligent edge devices. Many of them, such as autonomous vehicles and healthcare wearables, require real-time and on-site learning to enable them to proactively learn from new data and adapt to dynamic environments. The challenge for such on-site learning is that the massive and growing cost of state-of-the-art (SOTA) DNNs stands at odds with the limited resources available at the edge devices. With the development of efficient training techniques, on-site learning becomes more efficient and economical, enabling pervasive intelligent computing systems like smart phones or smart watches in our daily life which deeply influences the life style of the whole society. From another, despite the substantially growing need of on-device learning, current practices mostly train DNN models in a cloud server, and then deploy the pre-trained models into the devices for inference, due to the large gap between the devices’ constrained resource and the highly complex training process. However, based on a recent survey training a DNN will generate five cars’ life time carbon dioxide emission which is extremely environmental unfriendly. Efficient training techniques will notably help mitigate the negative ecological influence when training DNNs at data centers during the evolution of the AI field, which further boosts the high-speed development of AI and deepens its influences on the society. Therefore, as the proposed FracTrain framework has been verified to be effective on various applications, its contribution to the efficient training field will directly bring positive impacts to the society. However, due to more pervasive applications driven by AI enabled by efficient training techniques, personal data privacy can be a potential problem which needs the help of other privacy-protecting techniques or regulations.",Broader impact,328,11,,,FALSE,FALSE,FALSE,FracTrain: Fractionally Squeezing Bit Savings Both Temporally and Spatially for Efficient DNN Training,Deep Learning -> Efficient Training Methods,Deep Learning -> Efficient Inference Methods,Resource aware machine learning,"['Yonggan Fu', ' Haoran You', ' Yang Zhao', ' Yue Wang', ' Chaojian Li', ' Kailash Gopalakrishnan', ' Zhangyang Wang', ' Yingyan Lin']","{'University of Texas at Austin', 'IBM Research', 'Rice University'}",1,1,1,{'USA'}
Improving Neural Network Training in Low Dimensional Random Bases,"Frithjof Gressmann, Zach Eaton-Rosen, Carlo Luschi",Improving Neural Network Training in Low Dimensional Random Bases,8dcf2420e78a64333a59674678fb283b,https://proceedings.neurips.cc/paper/2020/file/8dcf2420e78a64333a59674678fb283b-Paper.pdf,"The reduced communication costs of the proposed method may lead to more energy-efficient ways to distribute computation, which are needed to address growing environmental impacts of deep learning [35, 12]. For language modelling in particular, we still seem to be in the regime where bigger models perform better [6]. New optimization approaches could help reducing the energy consumption of training ever larger models. However, Jevon’s Paradox suggests that increased efficiency may, counterintuitively, lead to increased total energy usage.",Broader Impact,78,4,,,FALSE,FALSE,FALSE,Improving Neural Network Training in Low Dimensional Random Bases,Deep Learning -> Efficient Training Methods,Optimization -> Evolutionary Computation ; Optimization -> Stochastic Optimization,Deep learning,"['Frithjof Gressmann', 'Rosen', ' Carlo Luschi']",{'Graphcore'},0,1,0,{'UK'}
Safe Reinforcement Learning via Curriculum Induction,"Matteo Turchetta, Andrey Kolobov, Shital Shah, Andreas Krause, Alekh Agarwal",Safe Reinforcement Learning via Curriculum Induction,8df6a65941e4c9da40a4fb899de65c55,https://proceedings.neurips.cc/paper/2020/file/8df6a65941e4c9da40a4fb899de65c55-Paper.pdf,"Our paper introduces conceptual formulations and algorithms for the safe training of RL agents. RL has the potential to bring significant benefits for society, beyond the existing use cases. However, in many domains it is of paramount importance to develop RL approaches that avoid harmful side-effects during learning and deployment. We believe that our work contributes to this quest, potentially bringing RL closer to high-stakes real-world applications. Of course, any technology – especially one as general as RL – has the potential of misuse, and we refrain from speculating further.",Broader Impact Statement,90,5,,,FALSE,FALSE,FALSE,Safe Reinforcement Learning via Curriculum Induction,Social Aspects of Machine Learning -> AI Safety,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Matteo Turchetta', ' Andrey Kolobov', ' Shital Shah', ' Andreas Krause', ' Alekh Agarwal']","{'ETH Zurich', 'Microsoft', 'Microsoft Research'}",1,1,1,"{'USA', 'Switzerland'}"
Leverage the Average: an Analysis of KL Regularization in Reinforcement Learning,"Nino Vieillard, Tadashi Kozuno, Bruno Scherrer, Olivier Pietquin, Remi Munos, Matthieu Geist",Leverage the Average: an Analysis of KL Regularization in Reinforcement Learning,8e2c381d4dd04f1c55093f22c59c3a08,https://proceedings.neurips.cc/paper/2020/file/8e2c381d4dd04f1c55093f22c59c3a08-Paper.pdf,"Our core contribution is theoretical. We unify a large body of the literature under KL-regularized reinforcement learning, and provide strong performance bounds, among them the first one ever to combine a linear dependency to the horizon and an averaging of the errors. We complement these results with an empirical study. It shows that the insights provided by the theory can still be used in a deep learning context, when some of the assumptions are not satisfied. As such, we think the broader impact of our contribution to be the same as the one of reinforcement learning.",Broader impact,96,5,,,TRUE,TRUE,FALSE,Leverage the Average: an Analysis of KL Regularization in Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement learning and planning,"['Nino Vieillard', ' Tadashi Kozuno', ' Bruno Scherrer', ' Olivier Pietquin', ' Remi Munos', ' Matthieu Geist']","{'Google Brain', 'INRIA', 'DeepMind', 'Okinawa Institute of Science and Technology', 'Google Research Brain Team'}",1,1,1,"{'Japan', 'France', 'UK', 'USA'}"
How Robust are the Estimated Effects of Nonpharmaceutical Interventions against COVID-19?,"Mrinank Sharma, Sören Mindermann, Jan Brauner, Gavin Leech, Anna Stephenson, Tomáš Gavenčiak, Jan Kulveit, Yee Whye Teh, Leonid Chindelevitch, Yarin Gal",How Robust are the Estimated Effects of Nonpharmaceutical Interventions against COVID-19?,8e3308c853e47411c761429193511819,https://proceedings.neurips.cc/paper/2020/file/8e3308c853e47411c761429193511819-Paper.pdf,"The rapid pace of the COVID-19 research cycle has led to an increased number of erroneous and misreported findings reaching popular attention [21]. It is critical that such errors are caught before publication; the sensitivity analyses developed in this work can uncover faulty assumptions, and so prevent overconfidence or misinformation. We intend for our findings to aid other modelling teams in producing highly reliable, policy-guiding estimates of NPI effects; to this end we release our sensitivity analysis suite and model implementations. This work is written as many governments are selecting the time and order in which to reintroduce NPIs, and attempting to control second wave epidemics. It offers vital validation of the evidence, to help minimise harm to the world population. One potential risk stems from miscommunication: we must not mistake high robustness for excessive certainty.We expect results and conclusions of NPI effectiveness models to change as best practice evolves. In addition, the subtle issues of interpretation raised in Section 3 are difficult to convey to non-technical audiences, and could easily be misread as unconditional effects, or extrapolated incorrectly.",Broader Impact,179,7,,,FALSE,FALSE,FALSE,How Robust are the Estimated Effects of Nonpharmaceutical Interventions against COVID-19?,Applications -> Health,Applications -> Computational Biology and Bioinformatics,Healthcare,"['Mrinank Sharma', ' Sören Mindermann', ' Jan Brauner', ' Gavin Leech', ' Anna Stephenson', ' Tomáš Gavenčiak', ' Jan Kulveit', ' Yee Whye Teh', ' Leonid Chindelevitch', ' Yarin Gal']","{'University of Oxford', 'Simon Fraser University', 'University of Bristol', 'Harvard University', 'Independent researcher', 'University of Oxford, DeepMind'}",1,1,1,"{'Canada', 'UK', 'USA', 'Independent'}"
Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses,"Kaivalya Rawal, Himabindu Lakkaraju",Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses,8ee7730e97c67473a424ccfeff49ab20,https://proceedings.neurips.cc/paper/2020/file/8ee7730e97c67473a424ccfeff49ab20-Paper.pdf,"Our framework, AReS, can be used by decision makers that wish to analyse machine learning systems for biases in recourse before deploying them in the real world. It can be applicable to a variety of domains where algorithms are making decisions and recourses are necessary–e.g., healthcare, education, insurance, credit-scoring, recruitment, and criminal justice. AReS enables the auditing of systems for fairness, and its customizable nature allows decision makers to specifically test and understand their models in a context dependent manner. It is important to be cognizant of the fact that just like any other recourse generation algorithm, AReS may also be prone to errors. For instance, spurious recourses may be reported either due to particular configurations of hyperparameters (e.g., valuing coverage or interpretability way more than correctness) or due to the approximation algorithms we use for optimization. Such errors may translate into masking existing biases of a classifier, especially on subgroups that are particularly underrepresented in the data. It may also lead to AReS reporting nonexistent biases. It is thus important to be cognizant of the fact that AReS is finally an explainable algorithm (as opposed to being a fairness technique) that is meant to guide decision makers. It can be used to gauge the need for deeper analysis, and test for specific, known red-flags, rather than to provide concrete evidence of violations of fairness criteria. Good use of AReS requires decision makers to be cognizant of these strengths and weaknesses. For a more complete understanding of a black box classifier before deployment, we recommend that AReS be run multiple times, with different hyperparameters and candidate sets RL and SD . Furthermore, evaluating the interpretability-recourse accuracy tradeoffs ( Figure 2) can help detect any undesirable scenarios which might result in spurious recourses. Possible violations of fairness criteria discovered by AReS should be investigated further before any action is taken. Finally, we propose that when showing summaries output by AReS, the recourse accuracies of each of the recourse rules should also be included so that decision makers can make informed choices.",5 Broader Impact,340,14,,,FALSE,FALSE,FALSE,Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Social Aspects of Machine Learning,,,"{'Harvard University', 'Harvard'}",1,0,0,{'USA'}
Generalization error in high-dimensional perceptrons: Approaching Bayes error with convex optimization,"Benjamin Aubin, Florent Krzakala, Yue Lu, Lenka Zdeborová",Generalization error in high-dimensional perceptrons: Approaching Bayes error with convex optimization,8f4576ad85410442a74ee3a7683757b3,https://proceedings.neurips.cc/paper/2020/file/8f4576ad85410442a74ee3a7683757b3-Paper.pdf,"Our work is theoretical in nature, and as such the potential societal consequence are difficult to foresee. We anticipate that deeper theoretical understanding of the functioning of machine learning systems will lead to their improvement in the long term.",Broader Impact,39,2,TRUE,FALSE,FALSE,FALSE,FALSE,Generalization error in high-dimensional perceptrons: Approaching Bayes error with convex optimization,Theory -> Statistical Physics of Learning,Algorithms -> Classification; Theory -> High-Dimensional Inference; Theory -> Models of Learning and Generalization ; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Benjamin Aubin', ' Florent Krzakala', ' Yue Lu', ' Lenka Zdeborová']","{'Harvard University', 'Ipht Saclay', 'CEA Saclay'}",1,0,0,"{'France', 'USA'}"
Projection Efficient Subgradient Method and Optimal Nonsmooth Frank-Wolfe Method,"Kiran K. Thekumparampil, Prateek Jain, Praneeth Netrapalli, Sewoong Oh",Projection Efficient Subgradient Method and Optimal Nonsmooth Frank-Wolfe Method,8f468c873a32bb0619eaeb2050ba45d1,https://proceedings.neurips.cc/paper/2020/file/8f468c873a32bb0619eaeb2050ba45d1-Paper.pdf,"As this is foundational research that is theoretical in nature, it is hard to predict any foreseeable societal consequence.",Broader Impact,19,1,TRUE,FALSE,FALSE,FALSE,FALSE,Projection Efficient Subgradient Method and Optimal Nonsmooth Frank-Wolfe Method,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization,Theory (including computational and statistical analyses),"['Kiran Thekumparampil', ' Prateek Jain', ' Praneeth Netrapalli', ' Sewoong Oh']","{'Univ. of Illinois at Urbana-Champaign', 'University of Washington', 'Microsoft Research'}",1,1,1,{'USA'}
PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks,"Minh Vu, My T. Thai",PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks,8fb134f258b1f7865a6ab2d935a897c9,https://papers.nips.cc/paper/2020/file/8fb134f258b1f7865a6ab2d935a897c9-Paper.pdf,"This paper proposed PGM-Explainer, which explains decisions of any GNN model in an interpretable manner, covering the non-linear dependency between features, a key aspect of graph data. Thus the contribution of this paper is fundamental and will have a broader impact on a vast number of applications, especially when many complex GNNs have been recently proposed and deployed in various domain fields. This paper will benefit a variety of high-impact GNNs based applications in terms of their interpretability, transparency, and fairness, including social network analysis, neural science, team science management, intelligent transportation systems, and critical infrastructures, to name a few.",Broader Impact,100,3,,,TRUE,TRUE,TRUE,PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks,"Deep Learning -> Visualization, Interpretability, and Explainability",Probabilistic Methods -> Graphical Models,Interpretable Machine Learning,"['Minh N Vu', ' Thai']",{'University of Florida'},1,0,0,{'USA'}
Few-Cost Salient Object Detection with Adversarial-Paced Learning,"Dingwen Zhang, HaiBin Tian, Jungong Han",Few-Cost Salient Object Detection with Adversarial-Paced Learning,8fc687aa152e8199fe9e73304d407bca,https://proceedings.neurips.cc/paper/2020/file/8fc687aa152e8199fe9e73304d407bca-Paper.pdf,"To our best knowledge, this research would provide intelligent visual perception to assistive robotics, which might offer supports in allowing people to live healthier and independent lives for longer. It is believed that advances in automatic saliency detection are net positive for society, despite the potential for misuse. The consequences of the failure of the system would lead to a false understanding of the image content. The task and method do not leverage biases in the data.",Broader Impact,77,4,,,FALSE,FALSE,FALSE,Few-Cost Salient Object Detection with Adversarial-Paced Learning,Applications -> Computer Vision,Algorithms -> Adversarial Learning,Vision,"['Dingwen Zhang', ' HaiBin Tian', ' Jungong Han']","{'University of Warwick', 'Xidian University'}",1,0,0,"{'UK', 'China'}"
Minimax Estimation of Conditional Moment Models,"Nishanth Dikkala, Greg Lewis, Lester Mackey, Vasilis Syrgkanis",Minimax Estimation of Conditional Moment Models,8fcd9e5482a62a5fa130468f4cf641ef,https://proceedings.neurips.cc/paper/2020/file/8fcd9e5482a62a5fa130468f4cf641ef-Paper.pdf,"Our work presents a unifying framework for the classical problem of generalized method of moments (GMM). Our framework can be easily applied in a diverse range of scenarios and is efficient at yielding accurate results even in high-dimensional scenarios. Moreover, we provide a strong theoretical foundation for our framework which shows how to use regularization or constrained optimization to obtain a theoretical bound on the performance of the underlying estimator. In providing the theoretical upper bounds on the generalization error of the GMM estimator, we bring in a statistical learning view, which is novel and has many related directions to explore in future. A  number of recent works (Bennett et al. [2019], Hartford et al. [2017]) try to tackle the GMM problem using neural networks. We build on this direction and present many novel ways in which one can use kernel ideas combined with neural networks to produce different estimators. We believe this flexibility offered by our framework speaks for its generality and potential for future impact. On a more broader front, within the econometrics literature, the GMM problem arises in many scenarios where a policy decision which impacts humans is to be made. A better and theoretically sound estimation procedure would result in better decisions made. Moreover, given instances of the problem where the decisions downstream impact humans, quantities such as privacy and fairness could also be incorporated into our framework for GMM estimation. A better and theoretically sound estimation procedure would result in better decisions made. Moreover, given instances of the problem where the decisions downstream impact humans, quantities such as privacy and fairness could also be incorporated into our framework for GMM estimation.",Broader Impact,276,14,,,FALSE,FALSE,FALSE,Minimax Estimation of Conditional Moment Models,Probabilistic Methods -> Causal Inference,Algorithms -> Adversarial Learning; Theory -> High-Dimensional Inference; Theory -> Models of Learning and Generalization ; Theory -> Spaces of Functions and Kernels; Theory -> Statistical Learning Theory,Causality,"['Nishanth Dikkala', ' Greg Lewis', ' Lester Mackey', ' Vasilis Syrgkanis']","{'MIT', 'Microsoft Research'}",1,1,1,{'USA'}
Causal Imitation Learning With Unobserved Confounders,"Junzhe Zhang, Daniel Kumor, Elias Bareinboim",Causal Imitation Learning with Unobserved Confounders,8fdd149fcaa7058caccc9c4ad5b0d89a,https://proceedings.neurips.cc/paper/2020/file/8fdd149fcaa7058caccc9c4ad5b0d89a-Paper.pdf,"This paper investigates the theoretical framework of learning a policy that imitates the distribution over a primary outcome from natural trajectories of an expert demonstrator, even when the primary outcome itself is unobserved and input covariates used by the expert determining original values of the action are unknown. Since in practice, the actual reward is often unspecified and the learner and the demonstrator rarely observe the environment in the same fashion, our methods are likely to increase the progress of automated decision systems. Such systems may be applicable to various fields, including the development of autonomous vehicle, industrial automation and the management of chronic disease. These applications may have a broad spectrum of societal implications. The adoption of autonomous driving and industrial automation systems could save cost and reduce risks such as occupational injuries; while it could also create unemployment. Treatment recommendation in the clinical decision support system could certainly alleviate the stress on the healthcare workers. However, this also raise questions concerning with the accountability in case of medical malpractice; collection of private personal information could also make the hospital database valuable targets for malicious hackers. Overall, we would encourage research to understand the risks arising from automated decision systems and mitigations for its negative impact. Recently, there is a growing amount of dataset of natural vehicle trajectories like highD [ 18] being licensed for commercial use. An immediate positive impact of this work is that we discuss potential risk of training decision-making policy from the observational data due to the presence of unobserved confounding, as shown in Sec. 1 and 4. More broadly, since our method is based on the semantics of structural causal models [29, Ch. 7], its adoption could cultivate machine learning practitioners with proper training in causal reasoning. A favorable characteristic of causal inference methods is that they are inherently robust: for example, the definition of imitability Def. 3 requires the imitating policy to perfectly mimics the expert performance in any model compatible to the causal diagram. Automated decision systems using the causal inference methods prioritize the safety and robustness in decision-making, which is increasingly essential since the use of black-box AI systems is prevalent and our understandings of their potential implications are still limited.",Broader Impact,370,16,,,FALSE,FALSE,FALSE,Causal Imitation Learning With Unobserved Confounders,Probabilistic Methods -> Causal Inference,Probabilistic Methods -> Graphical Models,Causality,"['Junzhe Zhang', ' Daniel Kumor', ' Elias Bareinboim']","{'Columbia University', 'Purdue University'}",1,0,0,{'USA'}
Your GAN is Secretly an Energy-based Model and You Should Use Discriminator Driven Latent Sampling,"Tong Che, Ruixiang ZHANG, Jascha Sohl-Dickstein, Hugo Larochelle, Liam Paull, Yuan Cao, Yoshua Bengio",Your GAN is Secretly an Energy-based Model and You Should Use Discriminator Driven Latent Sampling,90525e70b7842930586545c6f1c9310c,https://proceedings.neurips.cc/paper/2020/file/90525e70b7842930586545c6f1c9310c-Paper.pdf,"The development of powerful generative models which can generate fake images, audio, and video which appears realistic is a source of acute concern [53], and can enable fake news or propaganda. On the other hand these same technologies also enable assistive technologies like text to speech [54], new art forms [55, 56], and new design technologies [57]. Our work enables the creation of more powerful generative models. As such it is multi-use, and may result in both positive and negative societal consequences. However, we believe that improving scientific understanding tends also to improve the human condition [58] – so in the absence of a reason to expect specific harm, we believe that in expectation our work will have a positive impact on the world. One potential benefit of our work is that it leads to better calibrated GANs, which are less likely to simply drop under-represented sample classes from their generated output. The tendency of machine learning models to produce worse outcomes for groups which are underrepresented in their training data (in terms of race, gender, or otherwise) is well documented [59]. The use of our technique should produce generative models which are slightly less prone to this type of bias.",7 Broader Impact,201,8,,,FALSE,FALSE,FALSE,Your GAN is Secretly an Energy-based Model and You Should Use Discriminator Driven Latent Sampling,Deep Learning -> Generative Models,Deep Learning -> Adversarial Networks; Probabilistic Methods -> MCMC,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Tong Che', ' Ruixiang ZHANG', 'Dickstein', ' Hugo Larochelle', ' Liam Paull', ' Yuan Cao', ' Yoshua Bengio']","{'MILA', 'Mila/UdeM', 'Google Brain', 'Université de Montréal'}",1,1,1,"{'Canada', 'USA'}"
Learning Black-Box Attackers with Transferable Priors and Query Feedback,"Jiancheng YANG, Yangzhou Jiang, Xiaoyang Huang, Bingbing Ni, Chenglong Zhao",Learning Black-Box Attackers with Transferable Priors and Query Feedback,90599c8fdd2f6e7a03ad173e2f535751,https://proceedings.neurips.cc/paper/2020/file/90599c8fdd2f6e7a03ad173e2f535751-Paper.pdf,"In this paper, by combining transferability-based and query-based adversarial attack, we propose a strong black-box adversarial attack named LeBA, which significantly reduces query numbers against strong victim models while keep high success rates close to 100%. Specifically, it significantly  reduces queries compared to previous state-of-the-art query-based black-box attack. For instance, it requires average query numbers of only 243.8, 178.7 and 145.5 to attack Inception-V3, ResNet-50 and VGG-16, respectively. We introduce two ideas to black-box attack: 1) alternating transferability-based and query-based adversarial attack is surprisingly simple yet effective; 2) learning surrogate model with limited query feedback is feasible. We believe these ideas could benefit the further research in adversarial security of deep vision models. On the other hand, this study poses new challenges to the adversarial robustness in a black-box setting. More research effort should be paid to block the query-based adversarial attackers in real world scenarios.",Broader Impact,146,7,,,FALSE,TRUE,FALSE,Learning Black-Box Attackers with Transferable Priors and Query Feedback,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Adversarial Learning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Jiancheng YANG', ' Yangzhou Jiang', ' Xiaoyang Huang', ' Bingbing Ni', ' Chenglong Zhao']","{'Shanghai Jiaotong University', 'Shanghai Jiao Tong University'}",1,0,0,{'China'}
Locally Differentially Private (Contextual) Bandits Learning,"Kai Zheng, Tianle Cai, Weiran Huang, Zhenguo Li, Liwei Wang",Locally Differentially Private (Contextual) Bandits Learning,908c9a564a86426585b29f5335b619bc,https://proceedings.neurips.cc/paper/2020/file/908c9a564a86426585b29f5335b619bc-Paper.pdf,"This work is mostly theoretical, with no negative outcomes. (Contextual) bandits learning has been widely used in real applications, which heavily relies on user’s data that may contain personal private information. To protect user’s privacy, we adopt the appealing solid notion of privacy – Local Differential Privacy (LDP) that can protect each user’s data before collection, and design (contextual) bandit algorithms under the guarantee of LDP. Our algorithms can be easily used in real applications, such as recommendation, advertising, to protect data privacy and ensure the utility of private algorithms simultaneously, which will befit everyone in the world.",Broader Impact,98,4,,,TRUE,TRUE,FALSE,Locally Differentially Private (Contextual) Bandits Learning,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Bandit Algorithms,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Kai Zheng', ' Tianle Cai', ' Weiran Huang', ' Zhenguo Li', ' Liwei Wang']","{'Kuaishou', 'Peking University'}",1,1,1,{'China'}
Invertible Gaussian Reparameterization: Revisiting the Gumbel-Softmax,"Andres Potapczynski, Gabriel Loaiza-Ganem, John P. Cunningham",Invertible Gaussian Reparameterization: Revisiting the Gumbel-Softmax,90c34175923a36ab7a5de4b981c1972f,https://proceedings.neurips.cc/paper/2020/file/90c34175923a36ab7a5de4b981c1972f-Paper.pdf,We do not foresee our work having any negative ethical implications or societal consequences.,Broader Impact,14,1,TRUE,FALSE,FALSE,FALSE,FALSE,Invertible Gaussian Reparameterization: Revisiting the Gumbel-Softmax,Deep Learning -> Generative Models,Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Andres Potapczynski', 'Ganem', ' John Cunningham']","{'Layer 6 AI', 'University of Columbia', 'Columbia University'}",1,1,1,"{'Canada', 'USA'}"
Kernel Based Progressive Distillation for Adder Neural Networks,"Yixing Xu, Chang Xu, Xinghao Chen, Wei Zhang, Chunjing XU, Yunhe Wang",Kernel Based Progressive Distillation for Adder Neural Networks,912d2b1c7b2826caf99687388d2e8f7c,https://proceedings.neurips.cc/paper/2020/file/912d2b1c7b2826caf99687388d2e8f7c-Paper.pdf,"Adder Neural Network (ANN) is a new way of generating neural networks without using multiplication operations. It will largely reduce the energy cost and the area usage of the chips. This paper makes the performance of ANN exceeded that of homogeneous CNN, which means that we can use less energy to achieve a better performance. This is beneficial to the application of smart phones, the Internet of things, etc.",Broader Impact,69,4,,,FALSE,FALSE,FALSE,Kernel Based Progressive Distillation for Adder Neural Networks,Deep Learning,Algorithms -> Classification; Applications -> Computer Vision; Deep Learning -> CNN Architectures; Deep Learning -> Efficient Inference Methods,Deep learning,"['Yixing Xu', ' Yunhe Wang', ' Xinghao Chen', ' Wei Zhang', ' Chunjing XU', ' Chang Xu']","{'University of Sydney', 'Huawei Technologies'}",1,1,1,"{'Australia', 'China'}"
Adversarial Soft Advantage Fitting: Imitation Learning without Policy Optimization,"Paul Barde, Julien Roy, Wonseok Jeon, Joelle Pineau, Chris Pal, Derek Nowrouzezahrai",Adversarial Soft Advantage Fitting: Imitation Learning without Policy Optimization,9161ab7a1b61012c4c303f10b4c16b2c,https://proceedings.neurips.cc/paper/2020/file/9161ab7a1b61012c4c303f10b4c16b2c-Paper.pdf,"Our contributions are mainly theoretical and aim at simplifying current Imitation Learning methods. We do not propose new applications nor use sensitive data or simulator. Yet our method can ease and promote the use, design and development of Imitation Learning algorithms and may eventually lead to applications outside of simple and controlled simulators. We do not pretend to discuss the ethical implications of the general use of autonomous agents but we rather try to investigate what are some of the differences in using Imitation Learning rather than reward oriented methods in the design of such agents. Using only a scalar reward function to specify the desired behavior of an autonomous agent is a challenging task as one must weight different desiderata and account for unsuspected behaviors and situations. Indeed, it is well known in practice that Reinforcement Learning agents tend to find bizarre ways of exploiting the reward signal without solving the desired task. The fact that it is difficult to specify and control the behavior or an RL agents is a major flaw that prevent current methods to be applied to risk sensitive situations. On the other hand, Imitation Learning proposes a more natural way of specifying nuanced preferences by demonstrating desirable ways of solving a task. Yet, IL also has its drawbacks. First of all one needs to be able to demonstrate the desired behavior and current methods tend to be only as good as the demonstrator. Second, it is a challenging problem to ensure that the agent will be able to adapt to new situations that do not resemble the demonstrations. For these reasons, it is clear for us that additional safeguards are required in order to apply Imitation Learning (and Reinforcement Learning) methods to any application that could effectively have a real world impact.",Broader Impact,298,12,,,FALSE,FALSE,FALSE,Adversarial Soft Advantage Fitting: Imitation Learning without Policy Optimization,Reinforcement Learning and Planning,Deep Learning -> Adversarial Networks,Reinforcement learning and planning,"['Paul Barde', ' Julien Roy', ' Wonseok Jeon', ' Joelle Pineau', ' Chris Pal', ' Derek Nowrouzezahrai']","{'Quebec AI institute - Ubisoft La Forge', 'MILA, Polytechnique Montréal, Element AI', 'MILA, McGill University', 'McGill University', 'Mila'}",1,1,1,{'Canada'}
Agree to Disagree: Adaptive Ensemble Knowledge Distillation in Gradient Space,"Shangchen Du, Shan You, Xiaojie Li, Jianlong Wu, Fei Wang, Chen Qian, Changshui Zhang",Agree to Disagree: Adaptive Ensemble Knowledge Distillation in Gradient Space,91c77393975889bd08f301c9e13a44b7,https://proceedings.neurips.cc/paper/2020/file/91c77393975889bd08f301c9e13a44b7-Paper.pdf,"Knowledge distillation (KD) serves as a general technique for boosting training neural networks. And it is more highlighted in the training of smaller networks, which enjoys the prospects to be deployed in various edge devices, such as smartphones, wearable watches and AR glasses. KD enables us to take the full advantage of deep learning power, and introduce it on the edge computation. It is thus promising to realize a truly-intelligent society.",Broader Impact,71,4,,,FALSE,FALSE,FALSE,Agree to Disagree: Adaptive Ensemble Knowledge Distillation in Gradient Space,Deep Learning -> Efficient Training Methods,,Deep learning,"['Shangchen Du', ' Shan You', ' Xiaojie Li', ' Jianlong Wu', ' Fei Wang', ' Chen Qian', ' Changshui Zhang']","{'SenseTime', 'Tsinghua University', 'Shandong University', 'sensetime'}",1,1,1,"{'Hong Kong', 'China'}"
The Wasserstein Proximal Gradient Algorithm,"Adil SALIM, Anna Korba, Giulia Luise",The Wasserstein Proximal Gradient Algorithm,91cff01af640a24e7f9f7a5ab407889f,https://proceedings.neurips.cc/paper/2020/file/91cff01af640a24e7f9f7a5ab407889f-Paper.pdf,"The results that we showed, together with efficient implementations of some specific JKOs could be very impactful for many machine learning tasks.",8 Broader impact,22,1,FALSE,FALSE,FALSE,FALSE,FALSE,The Wasserstein Proximal Gradient Algorithm,Algorithms -> Dynamical Systems,,"algorithms, dynamical systems, optimal transport","['Adil SALIM', ' Anna Korba', ' Giulia Luise']","{'Gatsby Unit - UCL', 'University College London', 'KAUST'}",1,0,0,"{'UK', 'Saudi Arabia'}"
Universally Quantized Neural Compression,"Eirikur Agustsson, Lucas Theis",Universally Quantized Neural Compression,92049debbe566ca5782a3045cf300a3c,https://proceedings.neurips.cc/paper/2020/file/92049debbe566ca5782a3045cf300a3c-Paper.pdf,"Poor internet connectivity and high traffic costs are still a reality in many developing countries [3]. But also in developed countries internet connections are often poor due to congestion in crowded areas or insufficient mobile network coverage. By improving compression rates, neural compression has the potential to make information more broadly available. About 79% of global IP traffic is currently made up of videos [17]. This means that work on image and video compression in particular has the potential to impact a lot of people. Assigning fewer bits to one image is only possible by simultaneously assigning more bits to other images. Care needs to be taken to make sure that training sets are representative. Generative compression in particular bears the risk of misrepresenting content but is outside the scope of this paper.",Broader Impact,133,8,,,FALSE,FALSE,FALSE,Universally Quantized Neural Compression,Algorithms -> Data Compression,Applications -> Computer Vision; Deep Learning -> Deep Autoencoders,,"['Eirikur Agustsson', ' Lucas Theis']","{'Google', 'Twitter'}",0,1,0,{'USA'}
Temporal Variability in Implicit Online Learning,"Nicolò Campolongo, Francesco Orabona",Temporal Variability in Implicit Online Learning,9239be5f9dc4058ec647f14fd04b1290,https://proceedings.neurips.cc/paper/2020/file/9239be5f9dc4058ec647f14fd04b1290-Paper.pdf,"We believe our investigation will foster further studies promoting the adoption of adaptive learning rates in online learning and beyond. Indeed, in recent years adaptive methods in optimization proved to be one of the preferred methods for training deep neural networks. On the other hand, this work confirm the robustness of implicit updates and opens up to new possibilities in this field. From a societal aspect, this work in mainly theoretical and does not present any foreseeable consequence.",Broader Impact,78,4,FALSE,FALSE,FALSE,FALSE,FALSE,Temporal Variability in Implicit Online Learning,Algorithms -> Online Learning,,Theory (including computational and statistical analyses),"['Nicolò Campolongo', ' Francesco Orabona']","{'Università degli Studi di Milano', 'Boston University'}",1,0,0,"{'Italy', 'USA'}"
Investigating Gender Bias in Language Models Using Causal Mediation Analysis,"Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Yaron Singer, Stuart Shieber",Investigating Gender Bias in Language Models Using Causal Mediation Analysis,92650b2e92217715fe312e6fa7b90d82,https://proceedings.neurips.cc/paper/2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf,"This work focuses on the identification and analysis of biases that large language models acquire during training. Following the reasoning of Rawls (1958) among others, it is impermissible to use models that treat persons, groups, or institutions differently based on their attributes. Yet, language models are widely applied in real world settings. To remedy the effect of the implicit discrimination that this may cause, it is imperative to develop unbiased models. Understanding the causal mechanisms within neural networks is critical to developing trustworthy and provably fair models. Our method presents a first step toward the active debiasing of such models, as discussed in Section 6. Moreover, since model biases mirror societal biases, as shown by Caliskan et al. (2017) and confirmed in Section 4.1, our method may be of interest to those studying these biases in large corpora. However, while our case study presents a best effort to cover different cases and linguistic phenomena, it is not possible to fully cover all cases of gender bias within a language using only a limited set of constructed templates. Importantly, the main focus of our study uses a limited binary setup, which does not easily lend itself to applications on grammatical gender. We tried to avoid implicit discrimination of individuals who do not identify as either male or female by conducting experiments on a gender-neutral pronoun, but more work needs to be done on generating inclusive referring expressions that cover all possible pronouns. Moreover, since the model confuses the singular for the plural they , it will require additional disambiguation efforts to apply our methodology in this case. Finally, this study focuses only on the English language. The conclusions drawn from our results may not generalize to other languages or linguistic phenomena. In this case, our findings may lead researchers down the wrong path.",Broader Impact,302,15,,,FALSE,FALSE,FALSE,Investigating Gender Bias in Language Models Using Causal Mediation Analysis,Applications -> Natural Language Processing,"Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Visualization, Interpretability, and Explainability; Probabilistic Methods -> Causal Inference",Natural language processing,"['Jesse Vig', ' Sebastian Gehrmann', ' Yonatan Belinkov', ' Sharon Qian', ' Daniel Nevo', ' Yaron Singer', ' Stuart Shieber']","{'Salesforce', 'Technion', 'Harvard', 'Tel Aviv University', 'Harvard University'}",1,1,1,"{'USA', 'Israel'}"
Off-Policy Imitation Learning from Observations,"Zhuangdi Zhu, Kaixiang Lin, Bo Dai, Jiayu Zhou",Off-Policy Imitation Learning from Observations,92977ae4d2ba21425a59afb269c2a14e,https://proceedings.neurips.cc/paper/2020/file/92977ae4d2ba21425a59afb269c2a14e-Paper.pdf,"The success of Imitation Learning (IL) is crucial for realizing robotic intelligence. Serving as an effective solution to a practical IL setting, OPOLO has a promising future in various applications, including robotics control [43], game-playing [6], autonomous driving [14], algorithmic trading [44], to name just a few. On one hand, OPOLO provides an working evidence of sample-efficient IL. OPOLO costs less environment interactions compared with conventional IL approaches. For tasks where taking real actions can be expensive (high-frequency trading) or dangerous (autonomous driving), using less interactions for imitation learning is a crucial requirement for successful applications. On the other hand, OPOLO validates the feasibility of learning from incomplete guidance, and can enable IL in applications where expert demonstrations are costly to access. Moreover, OPOLO is more resemblant to human intelligence, as it can recover expertise simply by learning from expert observations. In general, OPOLO has a strong impact on the advancement of IL, from the perspective of both theoretical and empirical studies.",8 Broader Impact,162,8,,,FALSE,FALSE,FALSE,Off-Policy Imitation Learning from Observations,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Zhuangdi Zhu', ' Kaixiang Lin', ' Bo Dai', ' Jiayu Zhou']","{'Michigan State University', 'Google Brain'}",1,1,1,{'USA'}
Escaping Saddle-Point Faster under Interpolation-like Conditions,"Abhishek Roy, Krishnakumar Balasubramanian, Saeed Ghadimi, Prasant Mohapatra",Escaping Saddle-Point Faster under Interpolation-like Conditions,92a08bf918f44ccd961477be30023da1,https://proceedings.neurips.cc/paper/2020/file/92a08bf918f44ccd961477be30023da1-Paper.pdf,"We focus in this work on establishing theoretical justification for a practically observed phenomenon: Stochastic gradient method and its relatives perform well for training deep neural networks with complicated nonconvex landscape. The result presented will benefit researchers and practitioners who are interested in understanding the theoretical underpinnings of stochastic optimization for deep learning. Although our work in this draft is theoretical, it might have a positive impact for various practical applications of neural networks.",Broader Impact,74,3,,,FALSE,FALSE,FALSE,Escaping Saddle-Point Faster under Interpolation-like Conditions,Optimization -> Non-Convex Optimization,Deep Learning -> Optimization for Deep Networks; Optimization; Optimization -> Evolutionary Computation ; Optimization -> Stochastic Optimization,Deep learning,"['Abhishek Roy', ' Krishnakumar Balasubramanian', ' Saeed Ghadimi', ' Prasant Mohapatra']","{'Princeton University', 'University of California, Davis'}",1,0,0,{'USA'}
Matérn Gaussian Processes on Riemannian Manifolds,"Viacheslav Borovitskiy, Alexander Terenin, Peter Mostowsky, Marc Deisenroth",Matérn Gaussian processes on Riemannian manifolds,92bf5e6240737e0326ea59846a83e076,https://proceedings.neurips.cc/paper/2020/file/92bf5e6240737e0326ea59846a83e076-Paper.pdf,"This is a purely theoretical paper. We develop technical tools that make Matérn Gaussian processes easier to work with in the Riemannian setting. This enables practitioners who are not experts in stochastic partial differential equations to model data that lives on spaces such as spheres and tori. We envision the impact of this work to be concentrated in the physical sciences, where spaces of this type occur naturally. Since the state spaces of most robotic arms are Riemannian manifolds, we expect these ideas to improve performance of model-based reinforcement learning by making it easier to incorporate geometric prior information into models. Since climate science is concerned with studying the globe, we also expect that our ideas can be used to model environmental phenomena, such as sea surface temperatures. By employing Gaussian processes for data assimilation and building them into larger frameworks, this could facilitate more accurate climate models compared to current methods. These impacts carry forward to potential generalizations of our work. We encourage practitioners to consider impacts on their respective disciplines that arise from incorporating geometry into models.",Broader Impact,179,9,,,FALSE,FALSE,FALSE,Matérn Gaussian Processes on Riemannian Manifolds,Probabilistic Methods -> Gaussian Processes,,Probabilistic methods and inference,"['Viacheslav Borovitskiy', ' Petersburg Department of Steklov Mathematical Institute of Russian Academy of Sciences', ' Alexander Terenin', ' Peter Mostowsky', ' Marc Deisenroth']","{'Petuum, Inc. and Imperial College London', 'University College London', 'St. Petersburg State University', 'PDMI RAS'}",1,1,1,"{'UK', 'USA', 'Russia'}"
Improved Techniques for Training Score-Based Generative Models,"Yang Song, Stefano Ermon",Improved Techniques for Training Score-Based Generative Models,92c3b916311a5517d9290576e3ea37ad,https://proceedings.neurips.cc/paper/2020/file/92c3b916311a5517d9290576e3ea37ad-Paper.pdf,"Our work represents another step towards more powerful generative models. While we focused on images, it is quite likely that similar techniques could be applicable to other data modalities such as speech or behavioral data (in the context of imitation learning). Like other generative models that have been previously proposed, such as GANs and WaveNets, score models have a multitude of applications. Among many other applications, they could be used to synthesize new data automatically, detect anomalies and adversarial examples, and also improve results in key tasks such as semi-supervised learning and reinforcement learning. In turn, these techniques can have both positive and negative impacts on society, depending on the application. In particular, the models we trained on image datasets can be used to synthesize new images that are hard to distinguish from real ones by humans. Synthetic images from generative models have already been used to deceive humans in malicious ways. There are also positive uses of these technologies, for example in the arts and as a tool to aid design in engineering. We also note that our models have been trained on datasets that have biases ( e.g ., CelebA is not gender-balanced), and the learned distribution is likely to have inherited them, in addition to others that are caused by the so-called inductive bias of models.",Broader Impact,219,9,,,FALSE,FALSE,FALSE,Improved Techniques for Training Score-Based Generative Models,Deep Learning -> Generative Models,,Deep learning,"['Yang Song', ' Stefano Ermon']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,"Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, Michael Auli",wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,92d1e1eb1cd6f9fba3227870bb6d7f07,https://proceedings.neurips.cc/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf,"There are around 7,000 languages in the world and many more dialects. However, for most of them no speech recognition technology exists since current systems require hundreds or thousands of hours of labeled data which is hard to collect for most languages. We have shown that speech recognition models can be built with very small amounts of annotated data at very good accuracy. We hope our work will make speech recognition technology more broadly available to many more languages and dialects.",Broader Impact,81,4,,,FALSE,FALSE,FALSE,wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,Applications -> Speech Recognition,Algorithms -> Representation Learning; Algorithms -> Unsupervised Learning; Applications -> Audio and Speech Processing,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Alexei Baevski', ' Yuhao Zhou', 'rahman Mohamed', 'Facebook AI Research', ' Michael Auli']","{'FAIR', 'Facebook AI Research', 'University of Toronto'}",1,1,1,"{'Canada', 'USA'}"
A Maximum-Entropy Approach to Off-Policy Evaluation in Average-Reward MDPs,"Nevena Lazic, Dong Yin, Mehrdad Farajtabar, Nir Levine, Dilan Gorur, Chris Harris, Dale Schuurmans",A Maximum-Entropy Approach to Off-Policy Evaluation in Average-Reward MDPs,9308b0d6e5898366a4a986bc33f3d3e7,https://proceedings.neurips.cc/paper/2020/file/9308b0d6e5898366a4a986bc33f3d3e7-Paper.pdf,"In general, when learning from a batch of data produced by a fixed behavior policy, we may inherit the biases of that policy, and our models may not generalize beyond the support of the data distribution. In our paper, we circumvent this issue by assuming that the information sufficient for evaluating and optimizing policies is contained in some known features, and that the behavior policy is exploratory enough in the sense that it spans those features. These assumptions may not always hold when applying the method in practice.",Broader impact,88,3,,,FALSE,FALSE,FALSE,A Maximum-Entropy Approach to Off-Policy Evaluation in Average-Reward MDPs,Reinforcement Learning and Planning,,Reinforcement learning and planning,"['Nevena Lazic', ' Dong Yin', ' Mehrdad Farajtabar', ' Nir Levine', ' Dilan Gorur', ' Chris Harris', ' Dale Schuurmans']","{'DeepMind', 'Google'}",0,1,0,"{'UK', 'USA'}"
"Instead of Rewriting Foreign Code for Machine Learning, Automatically Synthesize Fast Gradients","William Moses, Valentin Churavy","Instead of Rewriting Foreign Code for Machine Learning, Automatically Synthesize Fast Gradients",9332c513ef44b682e9347822c2e457ac,https://proceedings.neurips.cc/paper/2020/file/9332c513ef44b682e9347822c2e457ac-Paper.pdf,"Enzyme reduces the amount of work necessary to apply ML to new domains. This has a generally positive impact as it reduces the workload necessary by researchers to use ML. It could be negative, however, for those whose job manually rewrites existing code for ML frameworks. Similarly, this added accessibility advances various scientific problem domains with all the positives and negatives that come with it. Enzyme also provides generally positive impact by helping bridge the gap between the ML and the scientific computing communities through allowing them to share tools and more easily interoperate. As an example, Enzyme may allow for improved policy design for climate change via projected-gradient-descent on a climate simulator.",Broader Impact,113,6,,,FALSE,FALSE,FALSE,"Instead of Rewriting Foreign Code for Machine Learning, Automatically Synthesize Fast Gradients","Data, Challenges, Implementations, and Software -> Software Toolkits","Data, Challenges, Implementations, and Software -> Benchmarks; Deep Learning -> Efficient Training Methods","Datasets, challenges, software","['William Moses', ' Valentin Churavy']","{'MIT', 'Massachussets Institute of Technology'}",1,0,0,{'USA'}
Does Unsupervised Architecture Representation Learning Help Neural Architecture Search?,"Shen Yan, Yu Zheng, Wei Ao, Xiao Zeng, Mi Zhang",Does Unsupervised Architecture Representation Learning Help Neural Architecture Search?,937936029af671cf479fa893db91cbdd,https://proceedings.neurips.cc/paper/2020/file/937936029af671cf479fa893db91cbdd-Paper.pdf,"In this paper, we challenge the common practice in neural architecture search and ask the question: does unsupervised architecture representation learning help neural architecture search? We approach this question through two sets of experiments: 1) the predictive performance comparison and 2) the neural architecture search efficiency and robustness comparison of the learned architecture representations using supervised and unsupervised learning. In both experiments, we found unsupervised architecture representation learning performs reasonably well. Current NAS methods are typically restricted to some small search blocks such as Inception cell or ResNet block, and most of them perform equally well with enough human expertise under this setup. With the drastically increased computational power, the design of the search space will be more complex [70] and therefore hugely increases the search complexity. In such case, unsupervised architecture representation learning may benefit many downstream applications where the search space contains billions of network architectures, with only a few of them trained with annotated data to obtain the accuracy. Supervised optimization in such large search spaces might be less effective . In the future, we suggest more work to be done to investigate unsupervised neural architecture search with different meaningful pretext tasks on larger search spaces. A better pre-training strategy for neural architectures leveraging graph neural networks seems to be a promising direction, as the unsupervised learning method introduced in our paper has already shown its simplicity and effectiveness.",Broader Impact,232,9,,,FALSE,FALSE,FALSE,Does Unsupervised Architecture Representation Learning Help Neural Architecture Search?,Algorithms -> AutoML,"Algorithms -> Representation Learning; Algorithms -> Unsupervised Learning; Deep Learning -> Visualization, Interpretability, and Explainability",AutoML,"['Shen Yan', ' Yu Zheng', ' Wei Ao', ' Xiao Zeng', ' Mi Zhang']",{'Michigan State University'},1,0,0,{'USA'}
Value-driven Hindsight Modelling,"Arthur Guez, Fabio Viola, Theophane Weber, Lars Buesing, Steven Kapturowski, Doina Precup, David Silver, Nicolas Heess",Value-driven Hindsight Modelling,9381fc93ad66f9ec4b2eef71147a6665,https://proceedings.neurips.cc/paper/2020/file/9381fc93ad66f9ec4b2eef71147a6665-Paper.pdf,"This work carries fundamental research in reinforcement learning (RL) using simulated data, with the immediate goal to improve RL techniques. While we are not directly targeting any application domain in this paper, the future impact of this research will be dependent on the context in which such techniques are deployed.",Broader Impact,50,2,FALSE,FALSE,FALSE,FALSE,FALSE,Value-driven Hindsight Modelling,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Arthur Guez', ' Fabio Viola', ' Theophane Weber', ' Lars Buesing', ' Steven Kapturowski', ' Doina Precup', ' David Silver', ' Nicolas Heess']","{'Google DeepMind', 'DeepMind', 'Deepmind'}",0,1,0,{'UK'}
Dynamic Regret of Convex and Smooth Functions,"Peng Zhao, Yu-Jie Zhang, Lijun Zhang, Zhi-Hua Zhou",Dynamic Regret of Convex and Smooth Functions,939314105ce8701e67489642ef4d49e8,https://proceedings.neurips.cc/paper/2020/file/939314105ce8701e67489642ef4d49e8-Paper.pdf,The work is mostly theoretical and the broader impact discussion is not applicable.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Dynamic Regret of Convex and Smooth Functions,Algorithms -> Online Learning,,Theory (including computational and statistical analyses),"['Peng Zhao', 'Jie Zhang', ' Lijun Zhang', 'Nanjing University', 'Hua Zhou']","{'Nanjing University', 'NJU'}",1,0,0,{'China'}
On Convergence of Nearest Neighbor Classifiers over Feature Transformations,"Luka Rimanic, Cedric Renggli, Bo Li, Ce Zhang",On Convergence of Nearest Neighbor Classifiers over Feature Transformations,93d9033636450402d67cd55e60b3f926,https://proceedings.neurips.cc/paper/2020/file/93d9033636450402d67cd55e60b3f926-Paper.pdf,"One of the current bottlenecks in machine learning is the lack of robustness and explainability. It is well known that kNN has properties (some of them cited in the introduction) that allow one to tackle these challenges. However, when it comes to accuracy, kNN on its own is often inferior to modern day machine learning methods, limiting the possible impact. In this paper we propose a novel theoretical framework aimed at understanding the best practices for employing kNN on top of pre-trained feature transformations, in order to gain on all positive aspects of kNN. In particular, we show that by using resources that are already widely available (i.e., open-sourced pre-trained embeddings), without the need of training from scratch, one can improve this already efficient, robust and interpretable classifier. We do not expect any direct negative impact from this work as we purely focus on the theoretical understanding of a classifier that itself is non-controversial.",Broader Impact,154,6,,,FALSE,TRUE,FALSE,On Convergence of Nearest Neighbor Classifiers over Feature Transformations,Algorithms -> Representation Learning,Algorithms -> Classification,Theory (including computational and statistical analyses),"['Luka Rimanic', ' Cedric Renggli', ' Bo Li', ' Ce Zhang']","{'ETH Zurich', 'UIUC'}",1,0,0,"{'USA', 'Switzerland'}"
Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments,"Steven Jecmen, Hanrui Zhang, Ryan Liu, Nihar Shah, Vincent Conitzer, Fei Fang",Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments,93fb39474c51b8a82a68413e2a5ae17a,https://proceedings.neurips.cc/paper/2020/file/93fb39474c51b8a82a68413e2a5ae17a-Paper.pdf,"We believe that our work can have a significant positive impact on the peer review processes of major conferences and journals. By mitigating our identified challenges, both program chairs and authors should benefit from the increased truthfulness of reviews. In addition, by allowing for paper assignment data and algorithms to be publicly released, this work can increase the transparency of the reviewing process and provide data for future research in this area. As we show in the experiments section, there is a tradeoff between the total similarity of the assignment and the mitigation of the challenges, so use of these algorithms will likely result in slightly poorer paper assignments in terms of reviewer fit. However, the program chairs are free to navigate this tradeoff as they see appropriate. An organizer’s poor choice of parameters could result in a poor paper assignment and hurt the quality of the published research, but this is the kind of choice that program chairs must always make with respect to the peer review process. By allowing program chairs to set different maximum probabilities for different paper-reviewer pairs, we do allow human biases to creep into the paper assignment process. To remedy this, we suggest setting the maximum probabilities in a principled way (such as according to a formula) that does not discriminate against papers or reviewers unfairly. Even if an individual paper-reviewer pair is unjustly suspected of being a bad match and the probability of that match is set low as a result, this alone is unlikely to negatively impact either the paper or the reviewer; this would be less problematic than if, for example, the paper is rejected because the program chairs are uncertain whether the reviews are trustworthy.",Broader Impact,285,9,,,FALSE,FALSE,FALSE,Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments,Theory -> Game Theory and Computational Economics,,Game theory (application: peer review),"['Steven Jecmen', ' Hanrui Zhang', ' Ryan Liu', ' Nihar Shah', ' Vincent Conitzer', ' Fei Fang']","{'CMU', 'Carnegie Mellon University', 'Duke University'}",1,0,0,{'USA'}
Contrastive learning of global and local features for medical image segmentation with limited annotations,"Krishna Chaitanya, Ertunc Erdil, Neerav Karani, Ender Konukoglu",Contrastive learning of global and local features for medical image segmentation with limited annotations,949686ecef4ee20a62d16b4a2d7ccca3,https://proceedings.neurips.cc/paper/2020/file/949686ecef4ee20a62d16b4a2d7ccca3-Paper.pdf,"It has been reported in the many countries 1 2 3 4 that there is a scarcity of radiologists in the hospitals compared to the number of patients being imaged, thereby leading to excessive workload and consequent delays in diagnosis, prognosis and interventions. Automation of time-consuming medical imaging analyses, such as image segmentation, can assist in reducing the workload for radiologists. Supervised deep learning provides state-of-the-art performance in image segmentation on several medical imaging datasets, if large labeled datasets are available. Obtaining a large set of labeled examples from medical experts is time-consuming and expensive. In most clinical scenarios, it is not practical to expect the understaffed radiologists to dedicate time to create such large annotated sets for each new application. This expectation to create large annotated sets is a bottleneck for the deployment of current deep learning algorithms in many clinical settings. Therefore, it is crucial to develop less data-hungry algorithms that can yield high performance with few annotations. Self-supervised learning is a promising approach to address this issue where the network is pre-trained to obtain a good initialization using the unlabeled data. Later, it is fine-tuned for a downstream task with limited annotations to yield high performance. In this work, we address this important issue by leveraging a self-supervised pre-training strategy to learn a good initialization with cheaply available unlabeled data. In this pre-training, we aim to learn useful global level and local level representations particularly useful for segmentation tasks by incorporating (1) domain-specific cues for contrasting strategies and (2) problem-specific cues with local contrastive loss to learn useful local features. We demonstrate on three medical datasets for the segmentation task that the proposed pre-training with unlabeled images can yield a good initialization, and reduce the need for large annotated sets to yield high performance when fine-tuned to the segmentation task. For instance, we get accuracy within 8% of benchmark performance by using just two 3D volumes for all datasets (for ACDC, this is just 4% of total labeled volumes) with our proposed pre-training strategy along with a simple augmentation. Extensive validation of automated algorithms is essential before they can be used in critical decision making avenues such as healthcare. In particular, deep learning based solutions are often vulnerable to the domain shift problem, which may occur when image acquisition settings or imaging modalities are varied. Further, uncertainty quantification and interpretability may additionally be required in such systems before they can be used in practice. Nonetheless, strategies to make such systems less data hungry, such as the one proposed in this paper, are likely to constitute an important part of such systems.",6 Broader Impact,434,17,,,FALSE,FALSE,FALSE,Contrastive learning of global and local features for medical image segmentation with limited annotations,Algorithms -> Representation Learning,Algorithms -> Semi-Supervised Learning; Applications -> Image Segmentation,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Krishna Chaitanya', ' Ertunc Erdil', ' Neerav Karani', ' Ender Konukoglu']",{'ETH Zurich'},1,0,0,{'Switzerland'}
Self-Supervised Graph Transformer on Large-Scale Molecular Data,"Yu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying WEI, Wenbing Huang, Junzhou Huang",Self-Supervised Graph Transformer on Large-Scale Molecular Data,94aef38441efa3380a3bed3faf1f9d5d,https://proceedings.neurips.cc/paper/2020/file/94aef38441efa3380a3bed3faf1f9d5d-Paper.pdf,"In this paper, we have developed a self-supervised pre-trained GNN model—GROVER to extract the useful implicit information from massive unlabelled molecules and the downstream tasks can largely benefit from this pre-trained GNN models. Below is the broader impact of our research: - For machine learning community: This work demonstrates the success of pre-training approach on Graph Neural Networks. It is expected that our research will open up a new venue on an in-depth exploration of pre-trained GNNs for broader potential applications, such as social networks and knowledge graphs. - For the drug discovery community: Researchers from drug discovery can benefit from GROVER from two aspects. First, GROVER has encoded rich structural information of molecules through the designing of self-supervision tasks. It can also produce feature vectors of atoms and molecule fingerprints, which can directly serve as inputs of downstream tasks. Second, GROVER is designed based on Graph Neural Networks and all the parameters are fully differentiable. So it is easy to fine-tune GROVER in conjunction with specific drug discovery tasks, in order to achieve better performance. We hope that GROVER can help with boosting the performance of various drug discovery applications, such as molecular property prediction and virtual screening.",Broader Impact,199,9,FALSE,FALSE,TRUE,TRUE,FALSE,Self-Supervised Graph Transformer on Large-Scale Molecular Data,Algorithms -> Representation Learning,Applications -> Computational Biology and Bioinformatics; Deep Learning -> Embedding Approaches,,,"{'University of Texas at Arlington / Tencent AI Lab', 'Tsinghua University', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
Generative Neurosymbolic Machines,"Jindong Jiang, Sungjin Ahn",Generative Neurosymbolic Machines,94c28dcfc97557df0df6d1f7222fc384,https://proceedings.neurips.cc/paper/2020/file/94c28dcfc97557df0df6d1f7222fc384-Paper.pdf,"The applicability of the proposed technology is broad and general. As a generative latent variable model that can infer a representation and also generate synthetic images, the proposed model generally share similar effects of the VAE-based generative models. However, its ability to learn object-centric properties in an unsupervised way can help various applications requiring heavy object-centric human annotations such as various computer vision tasks. The model could also be used to synthesize a scene which can be seen as novel or fake depending on the purpose of the end user. Although the presented model cannot generate images realistic enough to deceive humans, it may achieve this ability when combined with more powerful recent VAE models such as NVAE [39].",Broader Impact,119,5,,,FALSE,FALSE,FALSE,Generative Neurosymbolic Machines,Deep Learning -> Generative Models,Algorithms -> Representation Learning; Algorithms -> Unsupervised Learning; Deep Learning -> Deep Autoencoders; Probabilistic Methods -> Latent Variable Models,Probabilistic methods and inference,"['Jindong Jiang', ' Sungjin Ahn']",{'Rutgers University'},1,0,0,{'USA'}
How many samples is a good initial point worth in Low-rank Matrix Recovery?,"Jialun Zhang, Richard Zhang",How Many Samples is a Good Initial Point Worth in Low-rank Matrix Recovery?,94c4dd41f9dddce696557d3717d98d82,https://proceedings.neurips.cc/paper/2020/file/94c4dd41f9dddce696557d3717d98d82-Paper.pdf,"Many modern applications in engineering and computer science, and in machine learning in particular often have to deal with non-convex optimization. However, many aspects of non-convex optimization are still not well understood. Our paper provides more insight into the optimization landscape of a particular problem: low-rank matrix factorization. In addition, the methods we develop can potentially be used to understand many other non-convex problems. This is a step towards a more thorough analysis of current algorithms for non-convex optimization and also a step towards developing better and more efficient algorithms with theoretical guarantees.",Broader Impact,93,5,,,FALSE,FALSE,FALSE,How many samples is a good initial point worth in Low-rank Matrix Recovery?,Optimization,Applications -> Matrix and Tensor Factorization; Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),,"{'University of Illinois Urbana Champaign', 'UIUC'}",1,0,0,{'USA'}
CSER: Communication-efficient SGD with Error Reset,"Cong Xie, Shuai Zheng, Oluwasanmi O. Koyejo, Indranil Gupta, Mu Li, Haibin Lin",CSER: Communication-efficient SGD with Error Reset,94cb02feb750f20bad8a85dfe7e18d11,https://proceedings.neurips.cc/paper/2020/file/94cb02feb750f20bad8a85dfe7e18d11-Paper.pdf,"As this work is mainly algorithmic, the impact is mainly in scientific aspects rather than ethical and societal aspects. Hopefully, our work would enable faster training of machine learning models without regression in accuracy. It would save not only the time but also the expense cost by training large and complex models. On the other hand, there are some related aspects that we have not studied in this work. For example, we do not know how our approaches impact fairness and privacy of the model training, which will be our future work.",Broader Impact,92,5,,,FALSE,FALSE,FALSE,CSER: Communication-efficient SGD with Error Reset,Algorithms -> Large Scale Learning,Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Cong Xie', ' Shuai Zheng', ' Oluwasanmi Koyejo', ' Indranil Gupta', ' Mu Li', ' Haibin Lin']","{'UIUC', 'Hong Kong University of Science and Technology / Amazon Web Services', 'University of Illinois Urbana-Champaign', 'Amazon Web Services', 'Amazon'}",1,1,1,"{'USA', 'China'}"
Efficient estimation of neural tuning during naturalistic behavior,"Edoardo Balzani, Kaushik   Lakshminarasimhan, Dora Angelaki, Cristina Savin",Efficient estimation of neural tuning during naturalistic behavior,94d2a3c6dd19337f2511cdf8b4bf907e,https://proceedings.neurips.cc/paper/2020/file/94d2a3c6dd19337f2511cdf8b4bf907e-Paper.pdf,"We expect that our new fitting procedure and the associated python library will prove of broad utility to scientists in experimental neuroscience looking as a first pass analysis to their data, and to data scientists looking to develop new population level statistical models of neural activity. We do not foresee any potential negative outcomes arising from the availability of such a tool. The nature of this work makes the discussion on biases caused by data, and potential system failures not applicable.",Broader impact,81,3,,,TRUE,TRUE,FALSE,Efficient estimation of neural tuning during naturalistic behavior,Neuroscience and Cognitive Science,Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and cognitive science,"['Edoardo Balzani', ' Kaushik Lakshminarasimhan', ' Dora Angelaki', ' Cristina Savin']","{'New York University', 'Columbia University', 'NYU'}",1,0,0,{'USA'}
High-recall causal discovery for autocorrelated time series with latent confounders,"Andreas Gerhardus, Jakob Runge",High-recall causal discovery for autocorrelated time series with latent confounders,94e70705efae423efda1088614128d0b,https://proceedings.neurips.cc/paper/2020/file/94e70705efae423efda1088614128d0b-Paper.pdf,"Observational causal discovery is especially important for the analysis of systems where experimental manipulation is impossible due to ethical reasons, e.g., in climate research or neuroscience. Our work focuses on the challenging time series case that is of particular relevance in these fields. Understanding causal climate mechanisms from large observational satellite datasets helps climate researchers in understanding and modeling climate change as a main challenge of humanity. Since all code will be published open-source, our methods can be used by anyone. Causal discovery is a rather fundamental topic and we deem the potential for misuse as low.",Broader Impact,97,5,,,FALSE,FALSE,FALSE,High-recall causal discovery for autocorrelated time series with latent confounders,Probabilistic Methods -> Causal Inference,Applications -> Time Series Analysis,Causality,"['Andreas Gerhardus', 'German Aerospace Center', ' Jakob Runge', ' German Aerospace Center']",{'DLR'},1,0,0,{'Germany'}
Forget About the LiDAR: Self-Supervised Depth Estimators with MED Probability Volumes,"Juan Luis GonzalezBello, Munchurl Kim",Forget About the LiDAR: Self-Supervised Depth Estimators with MED Probability Volumes,951124d4a093eeae83d9726a20295498,https://proceedings.neurips.cc/paper/2020/file/951124d4a093eeae83d9726a20295498-Paper.pdf,"In this paper, we presented FAL-net, a method to “forget about the LiDAR” for the learning of monocular depth from stereo images. Our approach incorporates our proposed mirrored exponential disparity (MED) probability volumes and a two-stage learning strategy with our novel mirrored occlusion module (MOM). Our MOM computes very realistic occlusion masks to filter out invalid regions due to parallax. Our FAL-net showed superior performance and reduced number of parameters and inference times than the SOTA fully-, semi-, and self- supervised methods. Even though we focused on learning single image depth estimation (SIDE) from stereo pairs, our method can be easily extended when learning from monocular videos. Our MOM can be adopted as long as the network incorporates a disparity probability volume in its output layers and the relative camera poses are known or estimated. The camera-pose information can be integrated into the warping operation g(·) in Eq. (4) to obtain the mirrored occlusions for the corresponding frame pair. What could be at stake here is the exponential quantization, as inverse depths in structure-from-motion (SFM) are defined up to an unknown and inconsistent scale. The ambiguous scale could prevent the network from taking advantage of all disparity levels. A turn-around for this issue is to incorporate velocity supervision, as introduced in PackNet [11], or consistent SFM [27] to fully exploit the exponential quantization. Being depth estimation a low-level computer vision task, we authors do not consider that any ethical implication is involved in our research. However, we believe it is crucial to know if the network consistently under or overestimates depth. The second is considered more critical in robotics systems, in particular, self-driving cars. In this regard, our FAL-net seems to be on the safer side. We measured this by computing the mean median-scaling factor [35] between the GT and our depth estimates. We obtained a mean scale factor of 1.016, indicating that our network detects objects slightly closer than they are. Finally, we would like to remind the reader that, if one wants to use software-based depth estimators for safety-critical systems, all the necessary redundancy checks and safety norms must be followed.",Broader Impact,353,18,,,TRUE,TRUE,FALSE,Forget About the LiDAR: Self-Supervised Depth Estimators with MED Probability Volumes,Applications -> Computer Vision,Algorithms -> Unsupervised Learning; Applications -> Robotics; Deep Learning -> Efficient Training Methods,,"['Juan Luis Gonzalez', ' Munchurl Kim']",{'KAIST-VICLab'},1,1,1,{'South Korea'}
Joint Contrastive Learning with Infinite Possibilities,"Qi Cai, Yu Wang, Yingwei Pan, Ting Yao, Tao Mei",Joint Contrastive Learning with Infinite Possibilities,9523147e5a6707baf674941812ee5c94,https://proceedings.neurips.cc/paper/2020/file/9523147e5a6707baf674941812ee5c94-Paper.pdf,"Supervised learning has seen tremendous success in the AI community. By heavily relying on human annotations, supervised learning allows for convenient end-to-end training of deep neural networks. However, label acquisition is usually time-consuming and economically expensive. Particularly, when the algorithm needs to pre-train on massive datasets such as ImageNet, obtaining the labels for millions of data becomes an extremely tedious and expensive prerequisite that hinders one from trying out interesting ideas. This significantly limits and discourages the motivations for relatively small research communities without adequate financial supports. Another concern is the accuracy of the annotations, as labeling millions of data might very likely induce noisy and wrong labels owing to mistakes. What we have proposed in this paper is an unsupervised algorithm called JCL that solely depends on data itself without human annotations. JCL offers an alternative way to more efficiently exploit the pre-training dataset in an unsupervised way. One can even build up his/her own pre-training dataset by crawling data randomly from internet without any labeling efforts. However, one potential risk lies in the fact that if the usage of unsupervised visual representation learning aims at visual understanding systems (e.g., image classification and object detection), these systems may now be easily approached by those with lower levels of domain knowledge or machine learning expertise. This could expose the visual understanding model to some inappropriate usage and occasions without proper regulation or expertise.",Broader Impact,233,11,,,FALSE,FALSE,FALSE,Joint Contrastive Learning with Infinite Possibilities,Applications -> Computer Vision,Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Qi Cai', ' Yu Wang', ' Yingwei Pan', ' Ting Yao', ' Tao Mei']","{'University of Science and Technology of China', 'JD AI Research'}",1,1,1,{'China'}
Robust Gaussian Covariance Estimation in Nearly-Matrix Multiplication Time,"Jerry Li, Guanghao Ye",Robust Gaussian Covariance Estimation in Nearly-Matrix Multiplication Time,9529fbba677729d3206b3b9073d1e9ca,https://proceedings.neurips.cc/paper/2020/file/9529fbba677729d3206b3b9073d1e9ca-Paper.pdf,"Moving forward, it is imperative that machine learning systems cannot be gamed by malicious entities. This work builds upon a growing literature of principled algorithms for robust statistics, which are methods for defending against data poisoning attacks, where a training set may be tampered with by an adversary who wishes to change the behavior of the algorithm. For instance, such defenses are important in where the training data is crowdsourced, such as in federated learning, where we cannot fully trust the training data. In such settings, if the defense fails, attackers can completely invalidate the output of the model. That is why we believe it is critical to develop principled defenses, with provable worst-case guarantees, as we do here. With such defenses, we know that this worst-case behavior cannot happen. The algorithms developed here are also useful for exploratory data analysis, as demonstrated in [DKK + 17]. Most real-world high-dimensional datasets are inherently very noisy, and this noise can disguise interesting patterns from data analysts. These methods can be used in exploratory data analysis to remove this noise, and to recover these phenomena. We do not believe that this method leverages any biases in the data. Our generative model, as stated in the introduction, is very simple, and does not introduce any biases in this problem.",Broader Impact,216,11,,,FALSE,FALSE,FALSE,Robust Gaussian Covariance Estimation in Nearly-Matrix Multiplication Time,Theory -> Computational Learning Theory,Algorithms,,"['Jerry Li', ' Guanghao Ye']","{'Microsoft', 'University of Washington'}",1,1,1,{'USA'}
Adversarially-learned Inference via an Ensemble of Discrete Undirected Graphical Models,"Adarsh K Jeewajee, Leslie Kaelbling",Adversarially-learned Inference via an Ensemble of Discrete Undirected Graphical Models,95424358822e753eb993c97ee76a9076,https://proceedings.neurips.cc/paper/2020/file/95424358822e753eb993c97ee76a9076-Paper.pdf,"Graphical models are interpretable models as they expose their independence structures. Such models provide transparency that would allow practitioners to understand biases that may have been imparted to the parameters. If one wishes to understand ways in which a graphical model is biased, one may condition on variables of interest and see exactly how the rest of the variables react. The fact that our graphical model comes as an ensemble, makes it an editable model. For instance, if the model shows biases towards some characteristic of the data distribution being modeled, one can adapt our approach, and use a weighted recombination [Baruque, 2010] of the individual models in our ensemble, such that the models showing the undesirable bias are suppressed, or they can be completely zeroed out. This is not easy to do in black-box models such as neural networks. As with most approaches, there are modes of the failure to our model, and the consequences would depend on the setting where the model is used, but the ability to perform arbitrary conditioning with our model can be seen as a safety feature. If our model is used in critical situations where certain combinations of variables have high importance, then our models can be queried with those combinations of variables and their response to such conditions can be well understood and improved, or made safer, if needed.",Broader Impact,227,8,,,FALSE,FALSE,FALSE,Adversarially-learned Inference via an Ensemble of Discrete Undirected Graphical Models,Deep Learning -> Adversarial Networks,Algorithms -> Density Estimation; Algorithms -> Missing Data; Deep Learning -> Efficient Training Methods; Deep Learning -> Generative Models; Probabilistic Methods -> Belief Propagation; Probabilistic Methods -> Graphical Models,Probabilistic methods and inference,"['Adarsh K Jeewajee', ' Leslie Kaelbling']",{'MIT'},1,0,0,{'USA'}
GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators,"Dingfan Chen, Tribhuvanesh Orekondy, Mario Fritz",GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators,9547ad6b651e2087bac67651aa92cd0d,https://proceedings.neurips.cc/paper/2020/file/9547ad6b651e2087bac67651aa92cd0d-Paper.pdf,"The success of many machine learning methods hinges upon the availability of (large) datasets, which is problematic if the data is sensitive and contains private information, e.g., in the health domain, where diagnosis, treatment and personalized medicine are subject to strict privacy constraints. In contrast to direct privacy-preserving analysis, privacy-preserving generative models provide a safe way to release data, yielding several important implications: (1) allowing for wide applications without changing analysis algorithms as a result of sanitized data; (2) promoting new scientific discovery that could be handicapped due to data protection hurdles; (3) providing public benchmarks/datasets in domains with sensitive data to foster fair comparison and reproducible research. This work contributes to making the latest advances in generative modeling complying with data privacy—a commonly agreed societal value. Our method improves the state of the art in privacy- preserving data generation. In particular, the success of our approach on high-dimensional data shows its potential in a broader range of applications.",7 Broader Impact,159,5,,,FALSE,FALSE,FALSE,GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Deep Learning -> Generative Models,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Dingfan Chen', ' Tribhuvanesh Orekondy', ' Mario Fritz']","{'Max Planck Institute for Informatics', 'cispa- Helmholtz Center for Information Security'}",1,0,0,{'Germany'}
SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows,"Didrik Nielsen, Priyank Jaini, Emiel Hoogeboom, Ole Winther, Max Welling",SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows,9578a63fbe545bd82cc5bbe749636af1,https://proceedings.neurips.cc/paper/2020/file/9578a63fbe545bd82cc5bbe749636af1-Paper.pdf,"This work constitutes foundational research on generative models/unsupervised learning by providing a unified view on several lines of work and further by introducing new modules that expand the generative modelling toolkit. This work further suggests how to build software libraries to that allows more rapid implementation of a wider range of deep unsupervised models. Unsupervised learning has the potential to greatly reduce the need for labeled data and thus improve models in applications such as medical imaging where a lack of data can be a limitation. However, it may also potentially be used to improve deep fakes with potentially malicious applications.",Broader Impact,101,4,,,FALSE,FALSE,FALSE,SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows,Algorithms -> Unsupervised Learning,Algorithms -> Density Estimation; Deep Learning -> Generative Models; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Didrik Nielsen', ' Priyank Jaini', ' Emiel Hoogeboom', ' Ole Winther', ' Max Welling']","{'University of Waterloo', 'DTU and KU', 'University of Amsterdam', 'University of Amsterdam / Qualcomm AI Research', 'DTU Compute'}",1,1,1,"{'USA', 'Canada', 'Denmark', 'Netherlands'}"
Learning Causal Effects via Weighted Empirical Risk Minimization,"Yonghan Jung, Jin Tian, Elias Bareinboim",Learning Causal Effects via Weighted Empirical Risk Minimization,95a6fc111fa11c3ab209a0ed1b9abeb6,https://proceedings.neurips.cc/paper/2020/file/95a6fc111fa11c3ab209a0ed1b9abeb6-Paper.pdf,"Learning causal effects is essential throughout the data-driven sciences. Notable merits of our work include providing a practical solution to the estimation of causal effects from finite samples. By and large, these results should be useful in the field of complex systems (e.g., personalized medical treatment, social policy designing) to improve the interpretability/explainability in machine learning systems when deployed in real-world settings. Our work brings together two prominent fields in machine learning: ERM and causal inference, where the former is suitable to estimate high-dimensional functionals, while the latter is useful to determine which functional should be estimated that attains causal semantics.",Broader Impact,101,4,,,FALSE,FALSE,FALSE,Learning Causal Effects via Weighted Empirical Risk Minimization,Probabilistic Methods -> Causal Inference,Probabilistic Methods -> Graphical Models,Causality,"['Yonghan Jung', ' Jin Tian', ' Elias Bareinboim']","{'Columbia University', 'Iowa State University', 'Purdue University'}",1,0,0,{'USA'}
Revisiting the Sample Complexity of Sparse Spectrum Approximation of Gaussian Processes,"Minh Hoang, Nghia Hoang, Hai Pham, David Woodruff",Revisiting the Sample Complexity of Sparse Spectrum Approximation of Gaussian Processes,95b431e51fc53692913da5263c214162,https://proceedings.neurips.cc/paper/2020/file/95b431e51fc53692913da5263c214162-Paper.pdf,"Our work focuses on approximating Gaussian processes using a mixture of practical methods and theoretical analysis to reconfigure data in ways that reduce their approximation complexity. As such, it could have significant broader impact by allowing users to more accurately solve practical problems such as the ones discussed in our introduction, while still providing concrete theoretical guarantees. While applications of our work to real data could result in ethical considerations, this is an indirect (and unpredictable) side-effect of our work. Our experimental work uses publicly available datasets to evaluate the performance of our algorithms; no ethical considerations are raised.",6 Statement of Broader Impact,99,4,,,FALSE,FALSE,FALSE,Revisiting the Sample Complexity of Sparse Spectrum Approximation of Gaussian Processes,Theory -> Statistical Learning Theory,Algorithms -> Kernel Methods,,"['Minh Hoang', ' Nghia Hoang', ' Hai Pham', ' David Woodruff']","{'IBM Research', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Incorporating Interpretable Output Constraints in Bayesian Neural Networks,"Wanqian Yang, Lars Lorch, Moritz Graule, Himabindu Lakkaraju, Finale Doshi-Velez",Incorporating Interpretable Output Constraints in Bayesian Neural Networks,95c7dfc5538e1ce71301cf92a9a96bd0,https://proceedings.neurips.cc/paper/2020/file/95c7dfc5538e1ce71301cf92a9a96bd0-Paper.pdf,"Our work incorporates task-specific domain knowledge, in the form of output constraints, into BNNs. We wish to highlight two key positive impacts. ( 1) OC-BNNs allow us to manipulate an interpretable form of knowledge. They can be useful even to domain experts without technical machine learning expertise, who can easily specify such constraints for model behavior. A tool like this can be used alongside experts in the real world, such as physicians or judges. (2) Bayesian models like BNNs and OC-BNNs are typically deployed in “high-stakes” domains, which include those with societal impact. We intentionally showcase applications of high societal relevance , such as recidivism prediction and credit scoring, where the ability to specify and satisfy constraints can lead to fairer and more ethical model behavior. That being said, there are considerations and limitations. (1) If the model capacity is low (e.g. the BNN is small), constraints and model capacity may interact in unexpected ways that are not transparent to the domain expert. (2) Our sampling approach allows us to be very general in specifying constraints, but it also creates a trade-off between computational efficiency and accuracy of constraint enforcement. (3) Finally, the expert could mis-specify or even maliciously specify constraints. The first two considerations can be mitigated by careful optimization and robustness checks; the latter by making the constraints public and reviewable by others.",Broader Impact,225,12,,,FALSE,FALSE,FALSE,Incorporating Interpretable Output Constraints in Bayesian Neural Networks,Probabilistic Methods,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Probabilistic methods and inference,"['Wanqian Yang', ' Lars Lorch', ' Moritz Graule', ' Himabindu Lakkaraju', 'Velez']","{'Harvard University', 'Harvard'}",1,0,0,{'USA'}
Multi-Stage Influence Function,"Hongge Chen, Si Si, Yang Li, Ciprian Chelba, Sanjiv Kumar, Duane Boning, Cho-Jui Hsieh",Multi-Stage Influence Function,95e62984b87e90645a5cf77037395959,https://proceedings.neurips.cc/paper/2020/file/95e62984b87e90645a5cf77037395959-Paper.pdf,"Multi-stage training has been used in many real applications but currently there is no data attribution method to explain how pretraining data influence the model’s prediction in the end tasks. This paper provides a tool for doing this, which will be widely used in model debugging and fairness evaluation. For instance, our method can be used to investigate whether the bias of the end model is caused by a certain biased or malicious data in the pretraining stage. Although not mentioned in this paper, our method implicitly provides a way for data poisoning attack (similar to the origninal influence function paper). However, attacks will require full knowledge of training data and model, so we believe it is still impractical at the current stage.",Broader Impact,123,5,,,TRUE,TRUE,FALSE,Multi-Stage Influence Function,"Deep Learning -> Visualization, Interpretability, and Explainability",Deep Learning -> Analysis and Understanding of Deep Networks,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Hongge Chen', ' Si Si', ' Yang Li', ' Ciprian Chelba', ' Sanjiv Kumar', ' Duane Boning', 'Jui Hsieh']","{'UCLA', 'Google Research', 'Google', 'Massachusetts Institute of Technology', 'MIT'}",1,1,1,{'USA'}
Probabilistic Fair Clustering,"Seyed  Esmaeili, Brian Brubach, Leonidas Tsepenekas, John Dickerson",Probabilistic Fair Clustering,95f2b84de5660ddf45c8a34933a2e66f,https://proceedings.neurips.cc/paper/2020/file/95f2b84de5660ddf45c8a34933a2e66f-Paper.pdf,"Guaranteeing that the color proportions are maintained in each cluster satisfies group (demographic) fairness in clustering. In real-world scenarios, however, group membership may not be known with certainty but rather probabilistically (e.g., learned by way of a machine learning model). Our paper addresses fair clustering in such a scenario and therefore both generalizes that particular (and well-known) problem statement and widens the scope of the application. In settings where a groupfairness-aware clustering algorithm is appropriate to deploy, we believe our work could increase the robustness of those systems. That said, we do note (at least) two broader points of discussion that arise when placing potential applications of our work in the greater context of society: • We address a specific definition of fairness. While the formalization we address is a common one that draws directly on legal doctrine such as the notion of disparate impact, as expressed by Feldman et al. [2015] and others, we note that the Fairness, Accountability, Transparancy, and Ethics (FATE) in machine learning community has identified many such definitions Verma and Rubin [2018]. Yet, there is a growing body of work exploring the gaps between the FATE-style definitions of fairness and those desired in industry (see, e.g., recent work due to Holstein et al. [2019] that interviews developers about their wants and needs in this space), and there is growing evidence that stakeholders may not even comprehend those definitions in the first place Saha et al. [2020]. Indeed, “deciding on a definition of fairness” is an inherently morally-laden, application-specific decision, and we acknowledge that making a prescriptive statement about whether or not our model is appropriate for a particular use case is the purview of both technicians, such as ourselves, and policymakers and/or other stakeholders. • Our work is motivated by the assumption that, in many real-world settings, group membership may not be known deterministically. If group membership is being estimated by a machine-learning-based model, then it is likely that this estimator itself could incorporate bias into the membership estimate; thus, our final clustering could also reflect that bias. As an example, take a bank in the United States; here, it may not be legal for a bank to store information on sensitive attributes—a fact made known recently by the “Apple Card” fiasco of late 2019 Knight [2019]. Thus, to audit algorithms for bias, it may be the case that either the bank or a third-party service infers sensitive attributes from past data, which likely introduces bias into the group membership estimate itself. (See recent work due to Chen et al. [2019] for an in-depth discussion from the point of view of an industry-academic team.) We have tried to present this work without making normative statements about, e.g., the definition of fairness used; still, we emphasize the importance of open dialog with stakeholders in any system, and acknowledge that our proposed approach serves as one part of a larger application ecosystem.",Broader Impact,485,18,,,TRUE,TRUE,FALSE,Probabilistic Fair Clustering,Algorithms -> Clustering,"Optimization -> Discrete Optimization; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Seyed Esmaeili', ' Brian Brubach', ' Leonidas Tsepenekas', ' John Dickerson']","{'University of Maryland, College Park', 'University of Maryland'}",1,0,0,{'USA'}
Stochastic Segmentation Networks: Modelling Spatially Correlated Aleatoric Uncertainty,"Miguel Monteiro, Loic Le Folgoc, Daniel Coelho de Castro, Nick Pawlowski, Bernardo Marques, Konstantinos Kamnitsas, Mark van der Wilk, Ben Glocker",Stochastic Segmentation Networks: Modelling Spatially Correlated Aleatoric Uncertainty,95f8d9901ca8878e291552f001f67692,https://proceedings.neurips.cc/paper/2020/file/95f8d9901ca8878e291552f001f67692-Paper.pdf,"Proper uncertainty quantification is crucial to increase trust and interpretability in deep learning systems, which is of particular importance in healthcare applications. Reliable uncertainty estimates could help inform clinical decision making, and importantly, provide clinicians with feedback on when to ignore automatically derived measurements. Moreover, uncertainty estimates could be propagated to downstream clinical tasks such as radiotherapy planning, e.g., the amount of radiation delivered to each anatomical region. In medicine, the notion of a second opinion is well established and an essential part of scrutinising the decision process. The ability to generate and manipulate multiple plausible hypotheses could be of great benefit in semi-automatic settings, such as machine aided image segmentation, and help minimise the risk of missing important modes of the target distribution. A complementary prediction might be contradictory yet still very informative.",Broader Impact,134,6,,,FALSE,FALSE,FALSE,Stochastic Segmentation Networks: Modelling Spatially Correlated Aleatoric Uncertainty,Applications -> Image Segmentation,Algorithms -> Structured Prediction; Algorithms -> Uncertainty Estimation,Deep learning,"['Miguel Monteiro', ' Loic Le Folgoc', ' Daniel Coelho de Castro', ' Nick Pawlowski', ' Bernardo Marques', ' Konstantinos Kamnitsas', ' Mark van der Wilk', ' Ben Glocker']","{'Imperial College', 'Imperial College London'}",1,0,0,{'UK'}
ICE-BeeM: Identifiable Conditional Energy-Based Deep Models Based on Nonlinear ICA,"Ilyes Khemakhem, Ricardo Monti, Diederik Kingma, Aapo Hyvarinen",ICE-BeeM: Identifiable Conditional Energy-Based Deep Models Based on Nonlinear ICA,962e56a8a0b0420d87272a682bfd1e53,https://proceedings.neurips.cc/paper/2020/file/962e56a8a0b0420d87272a682bfd1e53-Paper.pdf,"This work is mainly theoretical, and aims to provide theoretical guarantees for the identifiability of a large family of deep models. Identifiability is very important, as it is key for reproducible science and interpretable results. For instance, if the networks behind search engines were identifiable, then their results would be consistent for most users. In addition, using perfectly identifiable networks in real life applications eliminates the randomness and arbitrariness of the system, and gives more control to the operator. In general, identifiability is a desirable property. The system we develop here does not make any decisions, and thus can not exhibit any bias. Our theoretical guarantees abstract away the nature of the data and the practical implementation. Therefore, our work doesn’t encourage the use of biased data or networks with potentially dangerous consequences.",Broader Impact,133,8,,,FALSE,FALSE,FALSE,ICE-BeeM: Identifiable Conditional Energy-Based Deep Models Based on Nonlinear ICA,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)",Algorithms -> Unsupervised Learning; Deep Learning -> Analysis and Understanding of Deep Networks; Probabilistic Methods -> Latent Variable Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Ilyes Khemakhem', ' Ricardo Monti', ' Kingma', ' Aapo Hyvarinen']","{'UCL', 'University of Helsinki', 'Google'}",1,1,1,"{'UK', 'USA', 'Finland'}"
Testing Determinantal Point Processes,"Khashayar Gatmiry, Maryam Aliakbarpour, Stefanie Jegelka",Testing Determinantal Point Processes,964d1775b722eff11b8ecd9e9ed5bd9e,https://proceedings.neurips.cc/paper/2020/file/964d1775b722eff11b8ecd9e9ed5bd9e-Paper.pdf,"Due to their ability to model negative dependencies and repulsion, DPPs have become a popular tool for modeling diversity in subset selection tasks. However, they are not the only models for negative dependence, and sometimes the decision for using DPPs may be solely based on their computational efficiency. If the true data distribution is far from being a DPP, the resulting approximation error may potentially induce biases. Our work poses the question of testing whether given data actually comes from a DPP. Being able to test for such a model fit can help avoid the biases from approximation error. Our work provides an initial theoretical understanding of the DPP testing problem. Our results settle the general sample complexity, and open avenues for further work to improve complexity over the general baseline by identifying additional mathematical structure that may exist in the data.",Broader Impact,142,7,,,FALSE,FALSE,FALSE,Testing Determinantal Point Processes,Theory -> Hardness of Learning and Approximations,Probabilistic Methods -> Graphical Models,Theory (including computational and statistical analyses),"['Khashayar Gatmiry', ' Maryam Aliakbarpour', ' Stefanie Jegelka']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
CogLTX: Applying BERT to Long Texts,"Ming Ding, Chang Zhou, Hongxia Yang, Jie Tang",CogLTX: Applying BERT to Long Texts,96671501524948bc3937b4b30d0e57b9,https://proceedings.neurips.cc/paper/2020/file/96671501524948bc3937b4b30d0e57b9-Paper.pdf,"Positive impact. The proposed method for understanding longer texts is inspired by the theory of working memory in the human brain. After the success of pretraining language models that learn from extremely large corpus, it still remains mysterious how human being can memorize, understand, and conduct efficient yet effective reasoning process within a small memory budget, given a very few examples. Exploring such methods in fact may help design more elegant mechanism, or architecture that connects sub-models to solve complex tasks that require rich context and information. From a societal perspective, the proposed method can be also applied to many applications, e.g., legal document analysis, public opinion monitoring and searching.  Negative impact. With the help of such methods, social platforms may get better understanding about their users by analysing their daily posts. Longer texts understanding specifically provide more accurate and coherent interpretation of who they are, which is a privacy threat.",Broader Impact,151,8,,,FALSE,TRUE,FALSE,CogLTX: Applying BERT to Long Texts,Applications -> Natural Language Processing,Neuroscience and Cognitive Science -> Cognitive Science,Natural language processing,"['Ming Ding', ' Chang Zhou', ' Hongxia Yang', ' Jie Tang']","{'Alibaba Group', 'Tsinghua University'}",1,1,1,{'China'}
f-GAIL: Learning f-Divergence for Generative Adversarial Imitation Learning,"Xin Zhang, Yanhua Li, Ziming Zhang, Zhi-Li Zhang",f -GAIL: Learning f -Divergence for Generative Adversarial Imitation Learning,967990de5b3eac7b87d49a13c6834978,https://proceedings.neurips.cc/paper/2020/file/967990de5b3eac7b87d49a13c6834978-Paper.pdf,"This paper aims to advance the imitation learning techniques, by learning an optimal discrepancy measure from f -divergence family, which has a wide range of applications in robotic engineering, system automation and control, etc. The authors do not expect the work will address or introduce any societal or ethical issues.",Broader Impact,50,2,TRUE,TRUE,FALSE,FALSE,FALSE,f-GAIL: Learning f-Divergence for Generative Adversarial Imitation Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Deep Learning -> Generative Models,Reinforcement learning and planning,"['Xin Zhang', ' Yanhua Li', ' Ziming Zhang', 'Li Zhang']","{'University of Minnesota', 'Worcester Polytechnic Institute'}",1,0,0,{'USA'}
Non-parametric Models for Non-negative Functions,"Ulysse Marteau-Ferey, Francis Bach, Alessandro Rudi",Non-parametric Models for Non-negative Functions,968b15768f3d19770471e9436d97913c,https://proceedings.neurips.cc/paper/2020/file/968b15768f3d19770471e9436d97913c-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Non-parametric Models for Non-negative Functions,Theory -> Spaces of Functions and Kernels,Algorithms -> Kernel Methods; Theory -> Models of Learning and Generalization ; Theory -> Regularization; Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Ferey', ' Francis Bach', ' Alessandro Rudi']","{'INRIA, Ecole Normale Superieure', 'DI ENS / INRIA', 'INRIA - Ecole Normale Superieure'}",1,0,0,{'France'}
Uncertainty Aware Semi-Supervised Learning on Graph Data,"Xujiang Zhao, Feng Chen, Shu Hu, Jin-Hee Cho",Uncertainty Aware Semi-Supervised Learning on Graph Data,968c9b4f09cbb7d7925f38aea3484111,https://proceedings.neurips.cc/paper/2020/file/968c9b4f09cbb7d7925f38aea3484111-Paper.pdf,"In this paper, we propose a uncertainty-aware semi-supervised learning framework of GNN for predicting multi-dimensional uncertainties for the task of semi-supervised node classification. Our proposed framework can be applied to a wide range of applications, including computer vision, natural language processing, recommendation systems, traffic prediction, generative models and many more [25]. Our proposed framework can be applied to predict multiple uncertainties of different roots for GNNs in these applications, improving the understanding of individual decisions, as well as the underlying models. While there will be important impacts resulting from the use of GNNs in general, our focus in this work is on investigating the impact of using our method to predict multi- source uncertainties for such systems. The additional benefits of this method include improvement of safety and transparency in decision-critical applications to avoid overconfident prediction, which can easily lead to misclassification. We see promising research opportunities that can adopt our uncertainty framework, such as investigating whether this uncertainty framework can further enhance misclassification detection or OOD detection. To mitigate the risk from different types of uncertainties, we encourage future research to understand the impacts of this proposed uncertainty framework to solve other real world problems.",Broader Impact,196,7,,,FALSE,FALSE,FALSE,Uncertainty Aware Semi-Supervised Learning on Graph Data,Algorithms -> Uncertainty Estimation,Algorithms -> Semi-Supervised Learning,Uncertainty,"['Xujiang Zhao', ' Feng Chen', ' Shu Hu', 'Hee Cho']","{'UT Dallas', 'Virginia Tech', 'The University of Texas at Dallas', 'University at Buffalo, State University of New York'}",1,0,0,{'USA'}
ConvBERT: Improving BERT with Span-based Dynamic Convolution,"Zi-Hang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan",ConvBERT: Improving BERT with Span-based Dynamic Convolution,96da2f590cd7246bbde0051047b0d6f7,https://proceedings.neurips.cc/paper/2020/file/96da2f590cd7246bbde0051047b0d6f7-Paper.pdf,"Positive impact The pre-training scheme has been widely deployed in the natural language processing field. It proposes to train a large model by self-supervised learning on large corpus at first and then fine-tune the model on downstream tasks quickly. Such a pre-training scheme has produced a series of powerful language models and BERT is one of the most popular one. In this work, we developed a new pre-training based language understanding model, ConvBERT. It offers smaller model size, lower training cost and better performance, compared with the BERT model. ConvBERT has multiple positive impacts. In contrary to the trend of further increasing model complexity for better performance, ConvBERT turns to making the model more efficient and saving the training cost. It will benefit the applications where the computation resource is limited. In terms of the methodology, it looks into the model backbone designs, instead of using distillation-alike algorithms that still require training a large teacher model beforehand, to make the model more efficient. We encourage researchers to build NLP models based on ConvBERT for tasks we can expect to be particularly beneficial, such as text-based counselling.  Negative impact Compared with BERT, ConvBERT is more efficient and saves the training cost, which can be used to detect and understand personal text posts on social platforms and brings privacy threat.",Broader impact,218,11,,,FALSE,TRUE,FALSE,ConvBERT: Improving BERT with Span-based Dynamic Convolution,Applications -> Natural Language Processing,Deep Learning -> Attention Models,Natural language processing,"['Hang Jiang', ' Weihao Yu', ' Daquan Zhou', ' Yunpeng Chen', ' Jiashi Feng', ' Shuicheng Yan']","{'Sun Yat-sen University', 'Yitu Technology', 'National University of Singapore'}",1,1,1,"{'Singapore', 'China'}"
Practical No-box Adversarial Attacks against DNNs,"Qizhang Li, Yiwen Guo, Hao Chen",Practical No-box Adversarial Attacks against DNNs,96e07156db854ca7b00b5df21716b0c6,https://proceedings.neurips.cc/paper/2020/file/96e07156db854ca7b00b5df21716b0c6-Paper.pdf,"This paper pushes the boundary of adversarial attacks on machine learning models by introducing a novel attack under a stronger threat model, where the attacker has neither white-box nor black-box access to the victim model. We show that the performance of our attack is sometimes even on par with that of black-box attacks. This significantly raises the bar for defending machine learning models, because it will no longer be adequate to keep the models confidential (against white-box attacks), and to keep the training data confidential and further limit the number of queries (against black-box attacks). Our findings call the machine learning and security communities into action to create novel defenses and robust models. Robust models shall make AI applicable to a wider range of business sectors, particularly those that are safety-critical, and accessible to a broader population, particularly those who are pessimistic about the trustworthiness of AI. Possible defenses to the proposed no-box attacks should be considered in future research. We found that adversarially trained models were not secure under these attacks, if the adversarial training was performed in a normal way (e.g., following the work of Madry et al.’s [29]). Specifically, our generated no-box adversarial examples led to a reasonably low accuracy (39.24%) on an adversarially trained ResNet, while the naive † baseline achieved 54.12%. A preliminary attempt of such a defense could be data augmentation using our adversarial examples, and it shall significantly improve the adversarial robustness to the proposed no-box attacks.",Broader Impact,244,9,,,FALSE,FALSE,FALSE,Practical No-box Adversarial Attacks against DNNs,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Unsupervised Learning; Deep Learning -> Deep Autoencoders; Deep Learning -> Supervised Deep Networks,Deep learning,"['Qizhang Li', ' Yiwen Guo', ' Hao Chen']","{'UC Davis', 'ByteDance AI Lab'}",1,1,1,"{'USA', 'China'}"
Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model,"Gen Li, Yuting Wei, Yuejie Chi, Yuantao Gu, Yuxin Chen",Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model,96ea64f3a1aa2fd00c72faacf0cb8ac9,https://proceedings.neurips.cc/paper/2020/file/96ea64f3a1aa2fd00c72faacf0cb8ac9-Paper.pdf,This work is a theoretical contribution to characterize the minimax optimality of model-based reinforcement learning. The insights from the proposed algorithm can potentially be leveraged in various reinforcement learning tasks in the future.,Broader Impact,33,2,FALSE,FALSE,FALSE,FALSE,FALSE,Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model,Reinforcement Learning and Planning,Algorithms -> Sparsity and Compressed Sensing; Reinforcement Learning and Planning -> Model-Based RL; Reinforcement Learning and Planning -> Planning; Theory -> High-Dimensional Inference; Theory -> Statistical Learning Theory,Reinforcement learning and planning,"['Gen Li', ' Yuting Wei', ' Yuejie Chi', ' Yuantao Gu', ' Yuxin Chen']","{'Princeton University', 'CMU', 'Tsinghua University', 'Carnegie Mellon University'}",1,0,0,"{'USA', 'China'}"
Walking in the Shadow: A New Perspective on Descent Directions for Constrained Minimization,"Hassan Mortagy, Swati Gupta, Sebastian Pokutta",Walking in the Shadow: A New Perspective on Descent Directions for Constrained Minimization,96f2d6069db8ad895c34e2285d25c0ed,https://proceedings.neurips.cc/paper/2020/file/96f2d6069db8ad895c34e2285d25c0ed-Paper.pdf,We believe that this work does not have any foreseeable negative ethical or societal impact.,8 Broader Impact,15,1,TRUE,FALSE,FALSE,FALSE,FALSE,Walking in the Shadow: A New Perspective on Descent Directions for Constrained Minimization,Optimization -> Convex Optimization,Optimization -> Discrete Optimization,Optimization Methods (continuous or discrete),"['Hassan Mortagy', ' Swati Gupta', ' Sebastian Pokutta']","{'Georgia Institute of Technology', 'Zuse Institute Berlin'}",1,0,0,"{'USA', 'Germany'}"
Path Sample-Analytic Gradient Estimators for Stochastic Binary Networks,"Alexander Shekhovtsov, Viktor Yanush, Boris Flach",Path Sample-Analytic Gradient Estimators for Stochastic Binary Networks,96fca94df72984fc97ee5095410d4dec,https://proceedings.neurips.cc/paper/2020/file/96fca94df72984fc97ee5095410d4dec-Paper.pdf,"The work promotes stochastic binary networks and improves the understanding and efficiency of training methods. We therefore believe ethical concerns are not applicable. At the same time, developing more efficient training methods for binary networks, we believe may further increase the researchers and engineers interest in low-energy binary computations and aid progress in embedded applications such as speech recognition and vision. In the field of stochastic computing, which is rather detached at the moment, the stochasticity is treated as a source of errors and accumulators are used in every layer just to mimic smooth activation function [14, 15]. It appears to us that when stochastic binary computations are made useful instead, the related hardware designs can be made more efficient and stable w.r.t. to errors.",Broader Impact,125,6,FALSE,FALSE,FALSE,FALSE,FALSE,Path Sample-Analytic Gradient Estimators for Stochastic Binary Networks,Deep Learning -> Efficient Training Methods,Algorithms -> Stochastic Methods; Deep Learning -> Optimization for Deep Networks; Optimization -> Stochastic Optimization; Probabilistic Methods -> Graphical Models,Probabilistic methods and inference,"['Alexander Shekhovtsov', ' Viktor Yanush', ' Boris Flach']","{'Czech Technical University in Prague, Czech Republic', 'Czech Technical University in Prague', 'Lomonosov Moscow State University'}",1,0,0,"{'Czech Republic', 'Russia'}"
Reward Propagation Using Graph Convolutional Networks,"Martin Klissarov, Doina Precup",Reward Propagation Using Graph Convolutional Networks,970627414218ccff3497cb7a784288f5,https://proceedings.neurips.cc/paper/2020/file/970627414218ccff3497cb7a784288f5-Paper.pdf,"We believe that our research provides scalable ways to learn potential functions for reward shaping yet maintaining guarantees of invariance with respect to the optimal policy of the original setting. We believe that one of the most promising attribute of our line of research is the fact that the optimal policy remains unchanged. This is a fundamental feature for sensitive applications such as healthcare, recommendation systems and financial trading. Moreover, by using potential based reward shaping, our method is meant to accelerate learning. This is another very important characteristic with regards to applications where sample complexity, memory and compute are of importance. Accelerating learning can also have downsides in the situations where there is competition between technologies. This could lead to one competitor obtaining an advantage due to faster learning, which can then exacerbate this advantage (rich get richer situation). We suggest that any publications that proceed in this line of research to be open about implementation details and hyperparameters. Another point to consider when proceeding to applications is related to the complexity of the MDP. If the application is small enough, it would be a good approach to try and store the whole underlying graph. We expect that in such settings our approach will provide significant improvements with reduced complexity when compared to approaches that require the eigen-decomposition of a transition model. If the MDP is too large to be reconstructed, we suggest applying our sampling strategy that will avoid increases in computational complexity. In these settings, we believe our approach can still provide robust improvements, however it might be more sensitive to the choice of hyperparameters. However, we have shown that across a wide range of games, high values of α provide good improvements and we expect this to be the case in many applications.",Broader Impact,297,14,,,FALSE,FALSE,FALSE,Reward Propagation Using Graph Convolutional Networks,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Martin Klissarov', ' Doina Precup']","{'McGill University / Mila / DeepMind Montreal', 'McGill University'}",1,1,1,{'Canada'}
"LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration","Bharat Lal Bhatnagar, Cristian Sminchisescu, Christian Theobalt, Gerard Pons-Moll","LoopReg : Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration",970af30e481057c48f87e101b61e6994,https://proceedings.neurips.cc/paper/2020/file/970af30e481057c48f87e101b61e6994-Paper.pdf,"Our work focuses on registering 3D scans with a controllable parametric model. Scan registration is a basic pre-requisite for many computer graphics and computer vision applications. Current approaches require manual intervention to accurately register scans. Our method could alleviate this restriction allowing for 3D data processing in aggregate. This line of work is especially important for applications such as animation, AR, VR, or gaming. One challenge of similar work (including ours) in human-centric 3D vision is ‘limited testing’. Given that 3D data is still limited compared to 2d images, extensive testing and demonstration of generalization is difficult. This makes systems brittle to out-of-sample inputs (e.g., in our case, rare human poses). This bottleneck needs to be overcome before this and similar work can find application in fields where reliability is important. With advancements in deep learning, a lot of current work requires collecting, processing and storing personal 3D human data. At this point in time, the awareness amongst general population regarding the negative potential of using this data is still relatively low. This could lead to privacy challenges without subjects even understanding the consequences. Processing data in aggregate as pursued here, as well as other forms of federated learning could offer convenient usability-privacy trade-offs, moving forward.",Broader Impact,206,13,,,FALSE,FALSE,FALSE,"LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration","Applications -> Body Pose, Face, and Gesture Analysis",,,"['Bharat Bhatnagar', ' Cristian Sminchisescu', ' Christian Theobalt', 'Moll']","{'MPI-INF', 'MPI Informatik', 'Google Research', 'MPII, Germany'}",1,1,1,"{'USA', 'Germany'}"
Fully Dynamic Algorithm for Constrained Submodular Optimization,"Silvio Lattanzi, Slobodan Mitrović, Ashkan Norouzi-Fard, Jakub M. Tarnawski, Morteza Zadimoghaddam",Fully Dynamic Algorithm for Constrained Submodular Optimization,9715d04413f296eaf3c30c47cec3daa6,https://proceedings.neurips.cc/paper/2020/file/9715d04413f296eaf3c30c47cec3daa6-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Fully Dynamic Algorithm for Constrained Submodular Optimization,Optimization -> Submodular Optimization,,Optimization Methods (continuous or discrete),"['Silvio Lattanzi', ' Slobodan Mitrović', 'Fard', ' Jakub Tarnawski', ' Morteza Zadimoghaddam']","{'MIT', 'Google Research', 'Microsoft Research'}",1,1,1,{'USA'}
Robust Optimal Transport with Applications in Generative Modeling and Domain Adaptation,"Yogesh Balaji, Rama Chellappa, Soheil Feizi",Robust Optimal Transport with Applications in Generative Modeling and Domain Adaptation,9719a00ed0c5709d80dfef33795dcef3,https://proceedings.neurips.cc/paper/2020/file/9719a00ed0c5709d80dfef33795dcef3-Paper.pdf,"The use of optimal transport (OT) distances such as the Wasserstein distance have become increasingly popular in machine learning with several applications in generative modeling, image-to-image translation, inpainting, domain adaptation, etc. One of the shortcomings of OT is its sensitivity to input noise. Hence, using OT for large-scale machine learning problems can be problematic since noise in large datasets is inevitable. Building on theoretical formulations of unbalanced OT which suffer from computational instability in deep learning applications, we have developed an efficient learning method that is provably robust against outliers and is amenable to complex deep learning applications such as deep generative modeling and domain adaptation. These attributes ensure broader impacts of this work in both theoretical and applied machine learning communities and can act as a bridge between the two. To the best of our knowledge, this work does not lead to any negative outcomes either in ethical or societal aspects.",6 Broader Impact,152,6,,,FALSE,FALSE,FALSE,Robust Optimal Transport with Applications in Generative Modeling and Domain Adaptation,Deep Learning -> Generative Models,Algorithms -> Adversarial Learning; Algorithms -> Multitask and Transfer Learning; Applications -> Computer Vision; Deep Learning -> Adversarial Networks,Deep learning,"['Yogesh Balaji', ' Rama Chellappa', ' Soheil Feizi']","{'University of Maryland', 'University of Maryland College Park'}",1,0,0,{'USA'}
Autofocused oracles for model-based design,"Clara Fannjiang, Jennifer Listgarten",Autofocused oracles for model-based design,972cda1e62b72640cb7ac702714a115f,https://proceedings.neurips.cc/paper/2020/file/972cda1e62b72640cb7ac702714a115f-Paper.pdf,"If adopted more broadly, our work could affect how novel proteins, small molecules, materials, and other entities are engineered. Because predictive models are imperfect, even with the advances pre- sented herein, care should be taken by practitioners to verify that any proposed design candidates are indeed safe and ethical for the intended downstream applications. The machine learning approach we present facilitates obtaining promising design candidates in a cost-effective manner, but practitioners must follow up on candidates proposed by our approach with conventional laboratory methods, as appropriate to the application domain.",7 Broader Impact,90,3,,,FALSE,FALSE,FALSE,Autofocused oracles for model-based design,Applications -> Computational Biology and Bioinformatics,Algorithms -> Continual Learning; Algorithms -> Regression; Optimization -> Evolutionary Computation,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Clara Fannjiang', ' Jennifer Listgarten']",{'UC Berkeley'},1,0,0,{'USA'}
Debiasing Averaged Stochastic Gradient Descent to handle missing values,"Aude Sportisse, Claire Boyer, Aymeric Dieuleveut, Julie Josses",Debiasing Averaged Stochastic Gradient Descent to handle missing values,972ededf6c4d7c1405ef53f27d961eda,https://proceedings.neurips.cc/paper/2020/file/972ededf6c4d7c1405ef53f27d961eda-Paper.pdf,"Our goal is to provide a solid and rigorous theoretical understanding, in simple enough situations, of what we can achieve with missing data, together with optimal algorithms. Being able to reduce the burden of missing entries in datasets can avoid the unnecessary effort of collecting new complete datasets, and facilitate learning in situations in which data has been collected from many different sources, without the possibility of a centralized coordination. This is typically the case in medical domains, in which different hospitals, or countries, typically gather different observations on the patients. This is why we evaluated its efficiency on real dataset of the medical register TraumaBase. The use of stochastic algorithms, which are widespread and crucial for large-scale learning allows us to focus on the generalization error, reducing the risk of overfitting. As missing data are ubiquitous in machine learning, and this work is not directly targeted at any type of applications, its impact is inherently dependent on the domain in which it is used.",Broader impact,165,6,,,FALSE,TRUE,FALSE,Debiasing Averaged Stochastic Gradient Descent to handle missing values,Algorithms -> Missing Data,Algorithms -> Large Scale Learning; Algorithms -> Regression; Algorithms -> Stochastic Methods; Applications -> Health; Optimization -> Stochastic Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Aude Sportisse', ' Claire Boyer', ' Aymeric Dieuleveut', ' Julie Josses']","{'LPSM, Sorbonne Université', 'Sorbonne University, Ecole Polytechnique', 'CMAP / CNRS', 'Ecole Polytechnique, IPParis'}",1,1,1,"{'France', 'Switzerland'}"
Trajectory-wise Multiple Choice Learning for Dynamics Generalization in Reinforcement Learning,"Younggyo Seo, Kimin Lee, Ignasi Clavera Gilaberte, Thanard Kurutach, Jinwoo Shin, Pieter Abbeel",Trajectory-wise Multiple Choice Learning for Dynamics Generalization in Reinforcement Learning,9739efc4f01292e764c86caa59af353e,https://proceedings.neurips.cc/paper/2020/file/9739efc4f01292e764c86caa59af353e-Paper.pdf,"While deep reinforcement learning (RL) has been successful in a range of challenging domains, it still suffers from a lack of generalization ability to unexpected changes in surrounding environmental factors [20, 30]. This failure of autonomous agents to generalize across diverse environments is one of the major reasoning behind the objection to real-world deployment of RL agents. To tackle this problem, in this paper, we focus on developing more robust and generalizable RL algorithm, which could improve the applicability of deep RL to various real-world applications, such as robotics manipulation [17] and package delivery [2]. Such advances in the robustness of RL algorithm could contribute to improved productivity of society via the safe and efficient utilization of autonomous agents in a diverse range of industries. Unfortunately, however, we could also foresee the negative long-term consequences of deploying autonomous systems in the real-world. For example, autonomous agents could be abused by specifying harmful objectives such as autonomous weapons. While such malicious usage of autonomous agents was available long before the advent of RL algorithms, developing an RL algorithm for dynamics generalization may accelerate the real-world deployment of such malicious robots, e.g., autonomous drones loaded with explosives, by making them more robust to changing dynamics or defense systems. We would like to recommend the researchers to recognize this potential misuse as we further improve RL systems.",Broader Impact,224,8,,,FALSE,FALSE,FALSE,Trajectory-wise Multiple Choice Learning for Dynamics Generalization in Reinforcement Learning,Reinforcement Learning and Planning -> Model-Based RL,Deep Learning,Reinforcement learning and planning,"['Younggyo Seo', ' Kimin Lee', ' Ignasi Clavera Gilaberte', ' Thanard Kurutach', ' Jinwoo Shin', ' Pieter Abbeel']","{'UC Berkeley', 'University of California Berkeley', 'KAIST'}",1,0,0,"{'South Korea', 'USA'}"
CompRess: Self-Supervised Learning by Compressing Representations,"Soroush Abbasi Koohpayegani, Ajinkya Tejankar, Hamed Pirsiavash",CompRess: Self-Supervised Learning by Compressing Representations,975a1c8b9aee1c48d32e13ec30be7905,https://proceedings.neurips.cc/paper/2020/file/975a1c8b9aee1c48d32e13ec30be7905-Paper.pdf,"Ethical concerns of AI: Most AI algorithms can be exploited for non-ethical applications. Unfortu- nately, our method is not an exception. For instance, rich self-supervised features may enable harmful surveillance applications. AI for all: Model compression reduces the computation needed in inference and self-supervised learning reduces annotation needed in training. Both these benefits may make rich deep models accessible to larger community that do not have access to expensive computation and labeling resources. Privacy and edge computation: Model compression enables running deep models on the devices with limited computational and power resources e.g., IoT devices. This reduces the privacy issues since the data does not need to be uploaded to the cloud. Moreover, compressing self-supervised learning models can be even better in this sense since a small model e.g., MobileNet that generalizes to new tasks well, can be finetuned on the device itself, so even the finetuning data does not need to be uploaded to the cloud.",Broader Impact,157,8,,,FALSE,FALSE,FALSE,CompRess: Self-Supervised Learning by Compressing Representations,Algorithms -> Representation Learning,Algorithms -> Unsupervised Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Soroush Abbasi Koohpayegani', ' Ajinkya Tejankar', ' Hamed Pirsiavash']","{'University of Maryland, Baltimore County', 'University of Maryland Baltimore County'}",1,0,0,{'USA'}
Sample complexity and effective dimension for regression on manifolds,"Andrew McRae, Justin Romberg, Mark Davenport",Sample complexity and effective dimension for regression on manifolds,977f8b33d303564416bf9f4ab1c39720,https://proceedings.neurips.cc/paper/2020/file/977f8b33d303564416bf9f4ab1c39720-Paper.pdf,"The results in this paper further illuminate the role of low-dimensional structure in machine learning algorithms. An improved theoretical understanding of the performance of these algorithms is increasingly important as tools from machine learning become ever-more-widely adopted in a range of applications with significant societal implications. Although, in general, there are well-known ethical issues that can arise from inherent biases in the way data are sampled and presented to regression and classification algorithms, we do not have reason to believe that the methods presented in this paper would either enhance or diminish these issues. Our analysis is abstract and, for better or for worse, assumes a completely neutral sampling model (uniform over a manifold).",Broader Impact,114,4,,,FALSE,FALSE,FALSE,Sample complexity and effective dimension for regression on manifolds,Theory -> Statistical Learning Theory,Algorithms -> Kernel Methods; Theory -> Hardness of Learning and Approximations; Theory -> High-Dimensional Inference; Theory -> Models of Learning and Generalization ; Theory -> Spaces of Functions and Kernels,Theory (including computational and statistical analyses),"['Andrew D McRae', ' Mark Davenport', ' Justin Romberg']",{'Georgia Institute of Technology'},1,0,0,{'USA'}
The phase diagram of approximation rates for deep neural networks,"Dmitry Yarotsky, Anton Zhevnerchuk",The phase diagram of approximation rates for deep neural networks,979a3f14bae523dc5101c52120c535e9,https://proceedings.neurips.cc/paper/2020/file/979a3f14bae523dc5101c52120c535e9-Paper.pdf,Not applicable.,9 Broader impact,2,1,TRUE,FALSE,FALSE,FALSE,FALSE,The phase diagram of approximation rates for deep neural networks,Theory -> Hardness of Learning and Approximations,Theory -> Information Theory; Theory -> Spaces of Functions and Kernels,Theory (including computational and statistical analyses),"['Dmitry Yarotsky', ' Anton Zhevnerchuk']",{'Skolkovo Institute of Science and Technology'},1,0,0,{'Russia'}
Timeseries Anomaly Detection using Temporal Hierarchical One-Class Network,"Lifeng Shen, Zhuocong Li, James Kwok",Timeseries Anomaly Detection using Temporal Hierarchical One-Class Network,97e401a02082021fd24957f852e0e475,https://proceedings.neurips.cc/paper/2020/file/97e401a02082021fd24957f852e0e475-Paper.pdf,"Timeseries anomaly detection is important for complex cyber-physical systems such as power plants, data centers, and smart factories. By monitoring the system’s real-time working conditions, timeseries anomaly detection techniques can automatically detect the abnormal status of the system such that potential risks and financial loss can be avoided. This is very beneficial to the development of social economy and urban security.",Broader Impact,61,3,FALSE,FALSE,FALSE,FALSE,FALSE,Timeseries Anomaly Detection using Temporal Hierarchical One-Class Network,Applications -> Time Series Analysis,Deep Learning -> Recurrent Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Lifeng Shen', ' Zhuocong Li', ' James Kwok']","{'Tencent', 'Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology'}",1,1,1,{'China'}
EcoLight: Intersection Control in Developing Regions Under Extreme Budget and Network Constraints,"Sachin Chauhan, Kashish Bansal, Rijurekha Sen",EcoLight: Intersection Control in Developing Regions Under Extreme Budget and Network Constraints,97e49161287e7a4f9b745366e4f9431b,https://proceedings.neurips.cc/paper/2020/file/97e49161287e7a4f9b745366e4f9431b-Paper.pdf,"Traffic intersection management has changed significantly over time, starting from in-person control, to timed-policy control, actuated control, network-switch control and currently to AI based control. With the wake of AI, utilizing deep learning and RL, we see greater power to control the traffic automatically without human intervention. But what if resource constraints make state-of-the-art DRL methods impossible to deploy in the developing world? The heuristics we learn in this paper using offline AI/ML algorithms, greatly improve metric values over traditional control methods currently deployed in the real world. We also demonstrate an end-to-end working system, that needed significant engineering and logistic efforts. But this boosted the confidence of our deployment partners, that we are more serious about this work than writing a couple of research papers. This paper, therefore, is an application of computer science methodologies, to the real world problem of traffic intersection control. Its potential impact on environment and sustainability overrides its academic contributions, which might feel like lacking novel contributions. However, exploiting the advances of CNN to learn better thresholds for low overhead computer vision methods, or DRL to populate LUTs to just look up at runtime, might be considered as novel and important optimizations towards building a practical, deployable system. We are working closely with the traffic control authorities, in collaboration with whom the intersection camera in this paper was deployed and data collected. Thus the extreme budget constraints, network unavailability issues etc. are real, as conveyed by anecdotal discussions with these deployment partners. More importantly, developing region datasets are not easy to come by. So to aid better collaborative research and more testing of these control ideas, labeled datasets on traffic flow and code will be released on paper acceptance. Video data will be shared individually, based on requests and discussions, to ensure privacy of people and cars captured in the camera view. In terms of safety concerns, if the traffic control system fails, it will have chaotic situation on the road, which may lead to human and mechanical injuries. So safety constraints, orthogonal to the control decisions, will be part of the deployed system. We also believe that our method will not be less stable than other state-of-the-art researches in the area and are constantly verifying our control decisions with the human experts (our deployment partners). In terms of data bias, we of course could collect and use data from only one intersection for developing region. Even that was non-trivial, unless we showed some benefits in terms of travel time etc. (as we do in this paper). The promising results in this paper is a good first step in gaining our deployment partners’ confidence, so that more data from different intersections, with possibly different traffic patterns, can be gathered in future (as much as research budget permits). This would remove bias, if any. We nonetheless use all open-source data that state-of-the-art DRL papers Wei et al. [2019a,b] experiment with, and match their performance. So our data/experiments are at least less biased than the state-of-the-art literature, which completely ignored developing region constraints.",Broader Impact,507,26,,,FALSE,FALSE,FALSE,EcoLight: Intersection Control in Developing Regions Under Extreme Budget and Network Constraints,Applications,Applications -> Sustainability,"Other applications (e.g., robotics, biology, climate, finance)","['Sachin Chauhan', ' Kashish Bansal', ' Rijurekha Sen']","{'IIT DELHI', 'IIT-Delhi', 'IIT Delhi'}",1,0,0,{'India'}
Reconstructing Perceptive Images from Brain Activity by Shape-Semantic GAN,"Tao Fang, Yu Qi, Gang Pan",Reconstructing Perceptive Images from Brain Activity by Shape-Semantic GAN,9813b270ed0288e7c0388f0fd4ec68f5,https://proceedings.neurips.cc/paper/2020/file/9813b270ed0288e7c0388f0fd4ec68f5-Paper.pdf,"The proposed Shape-Semantic GAN method provides a novel solution to visual reconstruction from brain activities and present a potential brain-reading technique. This method can help people recognize the human perception and thinking, and may help promote the development of neuroscience. However, the development of such brain-reading method may invade the privacy of the information within people’s mind, and may cause people to worry about the freedom of thought.",Broader Impact,68,3,,,FALSE,FALSE,FALSE,Reconstructing Perceptive Images from Brain Activity by Shape-Semantic GAN,Neuroscience and Cognitive Science -> Brain-Computer Interfaces and Neural Prostheses,Neuroscience and Cognitive Science -> Brain Imaging,Neuroscience and cognitive science,"['Tao Fang', ' Yu Qi', ' Gang Pan']",{'Zhejiang University'},1,0,0,{'China'}
Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design,"Michael Dennis, Natasha Jaques, Eugene Vinitsky, Alexandre Bayen, Stuart Russell, Andrew Critch, Sergey Levine",Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design,985e9a46e10005356bbaf194249f6856,https://proceedings.neurips.cc/paper/2020/file/985e9a46e10005356bbaf194249f6856-Paper.pdf,"Unsupervised environment design is a technique with a wide range of applications, including unsupervised RL, transfer learning, and Robust RL. Each of these applications has the chance of dramatically improving the viability of real-world AI systems. Real-world AI systems could have a variety of positive impacts, reducing the possibility for costly human error, increasing efficiency, and doing tasks that are dangerous or difficult for humans. However, there are a number of possible negative impacts: increasing unemployment by automating jobs [11] and improving the capabilities of automated weapons. These positives and negatives are potentially exacerbated by the emergent complexity we described in Section 5.1.2, which could lead to improved efficiency and generality allowing the robotics systems to be applied more broadly. However, if we are to receive any of the benefits of AI powered systems being deployed into real world settings, it is critical that we know how to make these systems robust and that they know how to make good decisions in uncertain environments. In Section 3 we discussed the deep connections between UED and decisions under ignorance , which shows that reasonable techniques for making decisions in uncertain settings correspond to techniques for UED, showing that the study of UED techniques can be thought of as another angle of attack at the problem of understanding how to make robust systems. Moreover, we showed in Section 5.2 that these connections are not just theoretical, but can lead to more effective ways of building robust systems. Continued work in this area can help ensure that the predominant impact of our AI systems is the impact we intended. Moreover, many of the risks of AI systems come from the system acting unexpectedly in a situation the designer had not considered. Approaches for Unsupervised Environment Design could work towards a solution to this problem, by automatically generating interesting and challenging environments, hopefully detecting troublesome cases before they appear in deployment settings.",Broader Impact,318,11,,,FALSE,FALSE,FALSE,Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement learning and planning,"['Michael Dennis', ' Natasha Jaques', ' Eugene Vinitsky', ' Alexandre Bayen', ' Stuart Russell', ' Andrew Critch', ' Sergey Levine']","{'UC Berkeley', 'MIT', 'University of California Berkeley'}",1,0,0,{'USA'}
A Spectral Energy Distance for Parallel Speech Synthesis,"Alexey Gritsenko, Tim Salimans, Rianne van den Berg, Jasper Snoek, Nal Kalchbrenner",A Spectral Energy Distance for Parallel Speech Synthesis,9873eaad153c6c960616c89e54fe155a,https://proceedings.neurips.cc/paper/2020/file/9873eaad153c6c960616c89e54fe155a-Paper.pdf,"The primary contributions of this paper introduce methodological innovations that improve the automated generation of speech audio from text. Positive aspects of automated text to speech could include improved accessibility for blind and elderly people or others who have poor eyesight. TTS is a cornerstone of assistive technology and e.g. is already used in the classroom to aid children with developmental disorders with reading comprehension. Although it is not within the scope of this work, automated TTS could be re-purposed to mimic a specific individual towards benevolent goals (e.g. to comfort someone with the voice of a loved one) or nefarious goals (e.g. to fake someone’s voice without their permission).",Broader impact,110,4,,,FALSE,FALSE,FALSE,A Spectral Energy Distance for Parallel Speech Synthesis,Deep Learning -> Generative Models,Applications -> Audio and Speech Processing; Deep Learning -> Adversarial Networks; Deep Learning -> Efficient Training Methods,Audio / Music / Speech,"['Alexey Gritsenko', ' Tim Salimans', ' Rianne van den Berg', ' Jasper Snoek', ' Nal Kalchbrenner']","{'Google', 'Google Brain', 'Google Brain Amsterdam'}",0,1,0,{'USA'}
Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations,"Joel Dapello, Tiago Marques, Martin Schrimpf, Franziska Geiger, David Cox, James J. DiCarlo",Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations,98b17f068d5d9b7668e19fb8ae470841,https://proceedings.neurips.cc/paper/2020/file/98b17f068d5d9b7668e19fb8ae470841-Paper.pdf,"From a technological perspective, the ethical implications of our work are largely aligned with those of computer vision in general. While there is undoubtedly potential for malicious and abusive uses of computer vision, particularly in the form of discrimination or invasion of privacy, we believe that our work will aid in the production of more robust and intuitive behavior of computer vision algorithms. As CNNs are deployed in real-world situations, it is critical that they behave with the same level of stability as their human counterparts. In particular, they should at the very least not be confused by changes in input statistics that do not confuse humans. We believe that this work will help to bridge that gap. Furthermore, while algorithms are often thought to be impartial or unbiased, much research has shown that data driven models like current CNNs are often even more biased than humans, implicitly keying in on and amplifying stereotypes. For this reason, making new CNNs that behave more like humans may actually reduce, or at least make more intuitive, their implicit biases. Unfortunately, we note that even with our work, these issues are not resolved, yet. While we developed a more neurobiologically-constrained algorithm, it comes nowhere close to human-like behaviour in the wide range of circumstances experienced in the real world. Finally, from the perspective of neuroscience, we think that this work introduces a more accurate model of the primate visual system. Ultimately, better models contribute to a better mechanistic understanding of how the brain works, and how to intervene in the case of illness or disease states. We think that our model contributes a stronger foundation for understanding the brain and building novel medical technology such as neural implants for restoring vision in people with impairments.",Broader Impact,292,12,,,FALSE,FALSE,FALSE,Simulating a Primary Visual Cortex at the Front of CNNs Improves Robustness to Image Perturbations,Neuroscience and Cognitive Science -> Neuroscience,Deep Learning -> Biologically Plausible Deep Networks; Neuroscience and Cognitive Science -> Visual Perception,Vision,"['Joel Dapello', ' Tiago Marques', ' Martin Schrimpf', ' Franziska Geiger', ' David Cox', ' James J DiCarlo']","{'Massachusetts Institute of Technology', 'Harvard University', 'MIT', 'MIT-IBM Watson AI Lab'}",1,1,1,{'USA'}
Learning from Positive and Unlabeled Data with Arbitrary Positive Shift,"Zayd Hammoudeh, Daniel Lowd",Learning from Positive and Unlabeled Data with Arbitrary Positive Shift,98b297950041a42470269d56260243a1,https://proceedings.neurips.cc/paper/2020/file/98b297950041a42470269d56260243a1-Paper.pdf,"The algorithms proposed in this work are general and could be applied to many different applications. Forecasting the broader impact of work like this is challenging and generally inaccurate. With that caveat, we discuss potential impacts based on possible applications. The case study on email spam suggests that our methods may be useful in adversarial domains, such as the detection of fraud, malware, network intrusion, distributed denial of service (DDoS) attacks, and many types of spam. In these settings, one class (e.g., spam) evolves quickly as attackers try to evade detection. For many of these domains, improved classifiers would benefit society by reducing spam and fraud. However, for domains such as facial recognition, improved robustness could lead to reduced privacy and other societal harms. See Albert et al. [41] for an extensive discussion of the politics of adversarial machine learning. In other domains, such as epidemiological analysis and land-cover classification, our work may lead to new or better models by reducing the need for labeled data and relaxing the SCAR assumption. As detailed in Section 1, only recently has the PU SCAR barrier been broken [12, 13, 14]. aPU learning pushes PU learning’s positive-shift boundary to a new extreme. We hope this paper will enable PU learning to be applied in domains where existing bPU\PU methods are impractical. This could also benefit society if used responsibly, with experts performing proper model validation and vetting risks. Careful model validation is especially important when labeled data is limited and biased.",9 Broader Impact,248,15,,,FALSE,FALSE,FALSE,Learning from Positive and Unlabeled Data with Arbitrary Positive Shift,Algorithms -> Semi-Supervised Learning,Algorithms -> Classification,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Zayd Hammoudeh', ' Daniel Lowd']",{'University of Oregon'},1,0,0,{'USA'}
Deep Energy-based Modeling of Discrete-Time Physics,"Takashi Matsubara, Ai Ishikawa, Takaharu Yaguchi",Deep Energy-Based Modeling of Discrete-Time Physics,98b418276d571e623651fc1d471c7811,https://proceedings.neurips.cc/paper/2020/file/98b418276d571e623651fc1d471c7811-Paper.pdf,"Novel paradigm of mathematical modeling. For computing the physical phenomena, one has to build a difference equation in discrete time. Mathematical models for physics are typically given as differential equations, and they are discretized using numerical integrators (see the lower part of Fig. 1). This discretization may destroy the geometrical structure from which the laws of physics follow. Most previous studies on neural networks for physical phenomena employ this approach [8, 19, 38, 41, 44, 45]. The discrete gradient method is a discrete-time approximation of a continuous-time structure (see the middle part of Fig. 1) [5, 6, 15, 16, 17, 18, 24, 32, 33]. It admits the laws of physics in discrete time, but it suffers from the discretization error, too. This method has been inapplicable in neural networks until this study. We addressed this issue by introducing the automatic discrete differentiation algorithm. Our approach is defined in discrete time and it learns discrete-time dynamics directly from discrete- time data (see the upper part of Fig. 1). As a result, it never suffers from the discretization error even though the modeling error matters. In this sense, this study provides a novel paradigm for mathematical modeling. Novel framework of scientific machine learning. The proposed approach combines neural networks and geometric integration, in particular, the discrete gradient method that is derived by the automatic discrete differentiation algorithm. As far as we know, the proposed framework is the first approach that unifies mathematical modeling from the first principles, data-driven modeling, and energetic-property-preserving numerical computations. From the viewpoint of scientific computing, the latter two may significantly accelerate scientific simulations. In practical simulations, modeling and numerical computations have been performed separately, while these must be unified because the results of the simulations often require modification of the mathematical models, and vice versa. In addition, as implemented by PyTorch, our programming codes for the proposed framework are naturally parallelized. This implementation is the first numerical library that provides parallelized numerical simulations while using the discrete gradient method, which widely accelerates the computation in scientific simulations.",Broader Impact,339,22,,,FALSE,FALSE,FALSE,Deep Energy-based Modeling of Discrete-Time Physics,Algorithms -> Dynamical Systems,Algorithms; Applications -> Time Series Analysis,dynamical system,"['Takashi Matsubara', ' Ai Ishikawa', ' Takaharu Yaguchi']","{'Osaka University', 'Kobe University'}",1,0,0,{'Japan'}
Quantifying Learnability and Describability of Visual Concepts Emerging in Representation Learning,"Iro Laina, Ruth Fong, Andrea Vedaldi",Quantifying Learnability and Describability of Visual Concepts Emerging in Representation Learning,98dce83da57b0395e163467c9dae521b,https://proceedings.neurips.cc/paper/2020/file/98dce83da57b0395e163467c9dae521b-Paper.pdf,"Interpretability tools for understanding feature representations. Recently, a number of works have focused on explaining or interpreting deep learning models; such research is often known as explainable AI (XAI) or interpretability [22]. Due to the highly-parameterized nature of CNNs, most researchers treat such models as black-boxes and primarily evaluate them based on task performance on well-curated datasets ( e . g . ImageNet classification). However, as deep learning is increasingly applied to high-impact, yet high-risk domains ( e . g . autonomous driving and medical applications), there is a great need for tools that help us understand CNNs, so that we can in turn understand their limitations and biases. Our work contributes to the development of interpretability tools that can help society to responsible use and interrogate advanced technology built on deep learning. We primarily do this in two ways. Development of principled interpretability metrics. First, we present a principled framework for evaluating the human-interpretability of CNN representations. While this may seem trivial, the interpretability research community has been lagging behind in the development of such metrics. There have been two main shortcomings of most interpretability evaluation: 1., they are often based on subjective or qualitative inspection, and 2., they fail to evaluate the faithfulness and interpretability of an explanation, that is, it should be both an accurate description of CNN behavior and easy-to- understand. These two shortcomings often go hand-in-hand. For example, [2, 20, 45, 58] highlight this issue for attribution heatmaps, which explain what parts of an image are responsible for the model’s output decision. In particular, [2] shows that a number of attribution methods that are typically preferred for their visual appearance actually do not accurately describe the CNN being explained. Most metrics focus on evaluating the interpretability of an explanation without also measuring its faithfulness. This is a major limitation, as an explanation is not useful if it does not accurately describe the phenomenon being explained. The typical methodology for human evaluation of CNN interpretability asks humans subjective questions like, “which explanatory visualization do you prefer or trust more?” [77], “do these images systematically describe a common visual concept?” [24], and “if so, name that concept” [76]. Such evaluations tend to evaluate the interpretability without faithfulness ( i . e . how can we verify that this is the most accurate name for the concept?). In contrast, our work evaluates using both criteria by shifting from using humans as subjective annotators to using them as more learners that can be evaluated objectively. Our coherence metric objectively measures how interpretable a CNN- discovered cluster of images is, while our describability metric quantifies how faithfully a natural language description accurately characterizes such a cluster. We hope that our work serves as a springboard for future work that enables the use of human annotators in evaluating the interpretability of CNNs in a more principled manner. Understanding self-supervised representations. Second, we focus on understanding self- supervised representations. Most work to date has focused on understanding CNNs trained for image classification. 4 However, supervised methods like image classifiers are limited in that they require expensive, manual annotation of highly-curated datasets. Thus, recent developments of self- and un-supervised methods is exciting, as they do not require manual labels. That said, there has been relatively little work dedicated to understanding self-supervised representations. The few works that do explore self-supervised representations typically apply techniques developed on supervised image classifiers to them [5, 19]. In contrast, we developed our evaluation paradigm with self-supervised methods in mind. In particular, we were motivated to develop an evaluation framework that could measure the interpretability of coherent, visual concepts that fall outside the limits of being described by labelled datasets. For example, in Fig. 3, we show that one self-supervised method discovered distinct clusters that highlight different environments of the same concept ( e . g . different environments for playing volleyball). Standard interpretability methods of describing such clusters using a labelled dataset [5, 19] would likely map them onto the same label ( e . g . “volleyball”) and fail to characterize the subtle nuances captured by different clusters. Lastly, by design, our paradigm is agnostic to method and can also be used to understand other kinds of image representations, including non-CNN ones. We hope our work encourages further research on understanding other kinds of representations beyond image classifiers and developing interpretability methods explicitly for those settings. 4 This machine learning workshop highlights this over-emphasis and encourages more diverse XAI work.",Broader Impact,743,45,,,TRUE,TRUE,FALSE,Quantifying Learnability and Describability of Visual Concepts Emerging in Representation Learning,"Deep Learning -> Visualization, Interpretability, and Explainability",Applications -> Computer Vision,Deep learning,"['Iro Laina', ' Ruth Fong', ' Andrea Vedaldi']","{'Facebook AI Research and University of Oxford', 'University of Oxford'}",1,0,0,{'UK'}
Self-Learning Transformations for Improving Gaze and Head Redirection,"Yufeng Zheng, Seonwook Park, Xucong Zhang, Shalini De Mello, Otmar Hilliges",Self-Learning Transformations for Improving Gaze and Head Redirection,98f2d76d4d9caf408180b5abfa83ae87,https://proceedings.neurips.cc/paper/2020/file/98f2d76d4d9caf408180b5abfa83ae87-Paper.pdf,"Our work can perform accurate and photo-realistic gaze and head orientation redirection which makes augmenting existing datasets possible. It can also be used for film post-editing, group photo editing and video conferencing to correct the gaze directions and head orientations. We believe the method may have applications in other problem settings and thus it should be possible to leverage it to generate training data for estimators beyond gaze. Given that the method can generate realistic looking images under fine-grained control of selected parameters, it could also be leveraged for malicious manipulation of imagery in the context of “deep-fakes”. Due to the limitations of currently available gaze datasets, our method does not yet handle extreme gaze directions that are beyond the distribution of the training dataset, nor fully faithfully preserve person-specific details in its redirection output. However, future developments should keep the ethical and privacy concerns in mind when refining such technologies.",Broader Impact,151,6,,,FALSE,FALSE,FALSE,Self-Learning Transformations for Improving Gaze and Head Redirection,"Applications -> Body Pose, Face, and Gesture Analysis",Algorithms -> Semi-Supervised Learning; Applications -> Computer Vision; Deep Learning -> Generative Models,Vision,"['Yufeng Zheng', ' Seonwook Park', ' Xucong Zhang', ' Shalini De Mello', ' Otmar Hilliges']","{'ETH Zurich', 'NVIDIA'}",1,1,1,"{'USA', 'Switzerland'}"
Language-Conditioned Imitation Learning for Robot Manipulation Tasks,"Simon Stepputtis, Joseph Campbell, Mariano Phielipp, Stefan Lee, Chitta Baral, Heni Ben Amor",Language-Conditioned Imitation Learning for Robot Manipulation Tasks,9909794d52985cbc5d95c26e31125d1a,https://proceedings.neurips.cc/paper/2020/file/9909794d52985cbc5d95c26e31125d1a-Paper.pdf,"Our work describes a machine-learning approach that fundamentally combined language, vision, and motion to produce changes in a physical environment. While each of these three topics has a large, dedicated community working on domain-relevant benchmarks and methodologies, there are only a few works that have addressed the challenge of integration. The presented robot simulation scenario, the experiments, and the presented algorithm 3 provide a reproducible benchmark for investigating the challenges at the intersection of language, vision, and control. Natural language as an input modality is likely to have a substantial impact on how users interact with embedded, automated, and/or autonomous systems. For instance, recent research on the Amazon Alexa [21] suggests that the fluency of the interaction experience is more important to users than the actual interaction output. Surprisingly, “users reported being satisfied with Alexa even when it did not produce sought information”[21]. Beyond the scope of this paper, having the ability to use a natural-language processing system to direct, for example, an autonomous wheelchair [33] may substantially improve the quality of life of many people with disabilities. Natural-language instructions, as discussed in this paper, could open up new application domains for machine learning and robotics, while at the same time improving transparency and reducing technological anxiety. Especially in elder care, there is evidence that interactive robots for physical and social support may substantially improve quality of care, as the average amount of in-person care in only around 24 hours a week. However, for the machine-learning community to enable such applications, it is important that natural-language instructions can be understood across a large number of users, without the need for specific sentence structures or perfect grammar. While far from conclusive, the generalization experiments with free-form instructions from novel human users (see Sec.4) are an essential step in this direction and represent a significant departure from typical evaluation metrics in robotics papers. In particular, we holistically tested whether the translation from verbal description to physical motion in the environment brought about the intended change and task success. Even before adoption in homes and healthcare facilities, robots with verbal instructions may become an important asset in small and medium-sized enterprises (SMEs). To date, robots have been rarely used outside of heavy manufacturing due to the added burden of complex reprogramming and motion adaptation. In the case of small product batch sizes, as typically used by SMEs, repeated programming becomes economically unsustainable. However, using systems that learn from human demonstration and explanation also comes with the risk of exploitation for nefarious objectives. We mitigated this problem in our work by carefully reviewing all demonstrations, as well as the provided verbal task descriptions, in order to ensure appropriate usage. In addition to the training process, another source of system failure could come from adversarial attacks on our model. This is of particular interest since our model does not only work as software but ultimately controls a physical robotic manipulator that may potentially harm a user in the real world. We addressed this issue in our work by utilizing an attention network that allowed users to verify the selected target object, thereby providing transparency regarding the robot’s intended behavior. Despite these features, we argue that more research needs to focus on the challenges posed by adversarial attacks. This statement is particularly true for domains like ours in which machine learning is connected to a physical system that can exert forces in the real world.",6 Broader impact,569,22,,,FALSE,FALSE,FALSE,Language-Conditioned Imitation Learning for Robot Manipulation Tasks,Applications -> Robotics,Algorithms -> Multimodal Learning; Deep Learning -> Supervised Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Simon Stepputtis', ' Joseph Campbell', ' Mariano Phielipp', ' Stefan Lee', ' Chitta Baral', ' Heni Ben Amor']","{'Oregon State University', 'Intel AI Labs', 'Arizona State University'}",1,1,1,{'USA'}
POMDPs in Continuous Time and Discrete Spaces,"Bastian Alt, Matthias Schultheis, Heinz Koeppl",POMDPs in Continuous Time and Discrete Spaces,992f0fed0720dbb9d4e060d03ed531ba,https://proceedings.neurips.cc/paper/2020/file/992f0fed0720dbb9d4e060d03ed531ba-Paper.pdf,Not applicable to this manuscript.,Broader Impact,5,1,TRUE,FALSE,FALSE,FALSE,FALSE,POMDPs in Continuous Time and Discrete Spaces,Reinforcement Learning and Planning -> Decision and Control,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Model-Based RL; Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> Control Theory,Reinforcement learning and planning,"['Bastian Alt', ' Matthias Schultheis', ' Heinz Koeppl']",{'Technische Universität Darmstadt'},1,0,0,{'Germany'}
Exemplar Guided Active Learning,"Jason S. Hartford, Kevin Leyton-Brown, Hadas Raviv, Dan Padnos, Shahar Lev, Barak Lenz",Exemplar Guided Active Learning,993edc98ca87f7e08494eec37fa836f7,https://proceedings.neurips.cc/paper/2020/file/993edc98ca87f7e08494eec37fa836f7-Paper.pdf,"This paper presents a method for better directing an annotation budget towards rare classes, with particular application to problems in NLP. The result could be more money spent on annotation because such efforts are more worthwhile (increasing employment) or less money spent on annotation if “brute force” approaches become less necessary (reducing employment). We think the former is more likely overall, but both are possible. Better annotation could lead to better language models, with uncertain social impact: machine reading and writing technologies can help language learners and knowledge workers, increasing productivity, but can also fuel various negative trends including misinformation, bots impersonating humans on social networks, and plagiarism.",Broader Impact,108,4,,,FALSE,FALSE,FALSE,Exemplar Guided Active Learning,Algorithms -> Active Learning,Applications -> Natural Language Processing,,"['Jason Hartford', 'Brown', ' Hadas Raviv', ' Dan Padnos', ' Shahar Lev', ' Barak Lenz']","{'University of British Columbia', 'AI21 Labs'}",1,1,1,"{'Canada', 'Israel'}"
Grasp Proposal Networks: An End-to-End Solution for Visual Learning of Robotic Grasps,"Chaozheng Wu, Jian Chen, Qiaoyu Cao, Jianchi Zhang, Yunxin Tai, Lin Sun, Kui Jia",Grasp Proposal Networks: An End-to-End Solution for Visual Learning of Robotic Grasps,994d1cad9132e48c993d58b492f71fc1,https://proceedings.neurips.cc/paper/2020/file/994d1cad9132e48c993d58b492f71fc1-Paper.pdf,"Traditional automation of robotic grasping requires availability of both object CAD models and annotations of grasp affordance. Recent data-driven solutions push the technologies towards a higher level of intelligence, by learning the grasp actuation directly from visual observations. However, most of these solutions are configured as 4 degrees of freedom, whose usage is restricted to a controlled planar grasp setting. The studied 6-DOF, visual grasp learning enables the technologies flexible enough to support a range of applications in industrial manufacturing, retail, and home assistance. However, the improved flexibility may cause downside impacts when the models are under adversarial attacks, causing failure of the automated system, and even life-threatening damage. Negative impact may also arise if the technology is abused. We encourage future research to mitigate these risks; we also expect policymakers would take active actions to penalize misuse of such technologies.",Broader Impact,141,7,,,FALSE,FALSE,FALSE,Grasp Proposal Networks: An End-to-End Solution for Visual Learning of Robotic Grasps,Applications -> Computer Vision,Applications -> Robotics,Vision,"['Chaozheng Wu', ' Jian Chen', ' Qiaoyu Cao', ' Jianchi Zhang', ' Yunxin Tai', ' Lin Sun', ' Kui Jia']","{'South China University of Technology ', 'South China University of Technology', 'Samsung, Stanford, HKUST', 'SCUT'}",1,1,1,"{'Chile', 'South Korea', 'USA', 'China'}"
Node Embeddings and Exact Low-Rank Representations of Complex Networks,"Sudhanshu Chanpuriya, Cameron Musco, Konstantinos Sotiropoulos, Charalampos Tsourakakis",Node Embeddings and Exact Low-Rank Representations of Complex Networks,99503bdd3c5a4c4671ada72d6fd81433,https://proceedings.neurips.cc/paper/2020/file/99503bdd3c5a4c4671ada72d6fd81433-Paper.pdf,"This paper contributes towards a better understanding of low-rank factorization, node embedding methods, and shows that a simple algorithm based on logistic PCA can output remarkably accurate low-rank factorizations. Our work may benefit researchers and also practitioners who (i) use node embeddings for downstream machine learning and data analysis tasks, (ii) develop novel node embedding methods, and/or (iii) study the interplay between privacy and node embeddings. Our work illustrates that node embeddings can capture significant specific information about edges in a graph, highlighting potential privacy risks of e.g., releasing such embeddings for users in a social network. We do not foresee direct negative outcomes of our work, although acknowledge that improved methods for network analysis (including those based on embeddings) have social consequences. For example, improved graph-based recommendations can contribute to issues of filter bubbles, polarization, and the spread of false information [Par11, LCKK14, MMT18]. They may also be associated with negative well-being impacts due to increased social media use [VLP + 15, SC17, VYR + 17]",Broader Impacts,167,6,,,TRUE,TRUE,FALSE,Node Embeddings and Exact Low-Rank Representations of Complex Networks,Applications -> Network Analysis,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA); Algorithms -> Representation Learning; Algorithms -> Spectral Methods; Applications -> Matrix and Tensor Factorization",Theory (including computational and statistical analyses),"['Sudhanshu Chanpuriya', ' Cameron Musco', ' Konstantinos Sotiropoulos', ' Charalampos Tsourakakis']","{'Boston University', 'University of Massachusetts Amherst', 'Microsoft Research'}",1,1,1,{'USA'}
Fictitious Play for Mean Field Games: Continuous Time Analysis and Applications,"Sarah Perrin, Julien Perolat, Mathieu Lauriere, Matthieu Geist, Romuald Elie, Olivier Pietquin",Fictitious Play for Mean Field Games: Continuous Time Analysis and Applications,995ca733e3657ff9f5f3c823d73371e1,https://proceedings.neurips.cc/paper/2020/file/995ca733e3657ff9f5f3c823d73371e1-Paper.pdf,"Applications of MFGs: The MFG model has inspired numerous applications [67] and we hope our work can help practitioners to solve MFGs problems at scale. A popular application focuses on population dynamics modeling [1, 33] including crowd motion modeling [7, 27, 46, 16, 8, 43], opinion dynamics and consensus formation [110, 18, 94], autonomous vehicles [75, 105] or sanitary vaccination [77, 51]. But MFGs have also naturally found applications in banking, finance and economics including banking systemic risk [38, 52], high frequency trading [82, 32], income and wealth distribution [6], economic contract design [53], economics in general [6, 2, 41, 61, 47] or price formation [84, 82, 63]. Energy management or production applications are studied in [10, 44, 50, 17, 79, 85, 67, 5, 42, 65], whereas security and communication applications appear in [89, 100, 70, 115, 80, 81]. Exploitability as a metric: One of the leading factor of progress for numerical or learning methods is the clear understanding of which metrics should be optimized. In reinforcement learning, the mean human normalized score is a standard metric of success. In supervised learning, the top 1 accuracy has been the foremost metric of success. We hope the exploitability can achieve such a role on the numerical aspects of MFGs.",Broader Impact,208,8,,,FALSE,FALSE,FALSE,Fictitious Play for Mean Field Games: Continuous Time Analysis and Applications,Theory -> Game Theory and Computational Economics,Reinforcement Learning and Planning -> Multi-Agent RL; Reinforcement Learning and Planning -> Reinforcement Learning,Theory (including computational and statistical analyses),"['Sarah Perrin', ' Julien Perolat', ' Mathieu Lauriere', ' Matthieu Geist', ' Romuald Elie', ' Olivier Pietquin']","{'Princeton University', 'Deepmind', 'Google Brain', 'DeepMind', 'Google Research Brain Team'}",1,1,1,"{'UK', 'USA'}"
Steering Distortions to Preserve Classes and Neighbors in Supervised Dimensionality Reduction,"Benoît Colange, Jaakko Peltonen, Michael Aupetit, Denys Dutykh, Sylvain Lespinats",Steering Distortions to Preserve Classes and Neighbors in Supervised Dimensionality Reduction,99607461cdb9c26e2bd5f31b12dcf27a,https://proceedings.neurips.cc/paper/2020/file/99607461cdb9c26e2bd5f31b12dcf27a-Paper.pdf,"This work proposes improvement on a dimensionality reduction technique for exploratory data analysis. Dimensionality reduction is intended to support data scientists in analyzing multidimensional data, and can also be used to visualize high-dimensional data representing physical objects or persons in a 2D map for the lay public to get an overview of the main groups of objects/persons based on similarities in their corresponding data. It is agnostic to the nature of the objects/persons represented by the data. Better understanding of trends and variation in large-scale datasets can improve the ability of society to learn about important phenomena. However, dimensionality reduction can generate biased representation of these objects/persons, either due to the inherent bias of the data themselves (over or under represented classes of objects/persons, missing or irrelevant features artificially gathering or separating (classes of) objects/persons), or due to unavoidable projection biases, called distortions, [3] artificially gathering in the 2D representation actually separated (classes of) objects/persons, or artificially separating in the 2D representation actually similar (classes of) objects/persons. The proposed ClassNeRV method is exactly intended to reduce this second type of bias.",6 Broader impact,181,6,,,FALSE,FALSE,FALSE,Steering Distortions to Preserve Classes and Neighbors in Supervised Dimensionality Reduction,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Benoît Colange', ' Jaakko Peltonen', ' Michael Aupetit', ' Denys Dutykh', ' Sylvain Lespinats']","{'CEA Tech, INES, Annecy, France', 'CEA', 'University of Tampere', 'CNRS', 'Qatar Computing Research Institute'}",1,0,0,"{'France', 'Qatar', 'Finland'}"
On Infinite-Width Hypernetworks,"Etai Littwin, Tomer Galanti, Lior Wolf, Greg Yang",On Infinite-Width Hypernetworks,999df4ce78b966de17aee1dc87111044,https://proceedings.neurips.cc/paper/2020/file/999df4ce78b966de17aee1dc87111044-Paper.pdf,"This work improves our understanding and design of hypernetworks and hopefully will help us improve the transparency of machine learning involving them. Beyond that, this work falls under the category of basic research and does not seem to have particular societal or ethical implications.",Broader Impact,44,2,TRUE,TRUE,FALSE,FALSE,FALSE,On Infinite-Width Hypernetworks,Deep Learning -> Analysis and Understanding of Deep Networks,Deep Learning,Theory (including computational and statistical analyses),"['Etai Littwin', ' Tomer Galanti', ' Lior Wolf', ' Greg Yang']","{'Apple', 'Microsoft Research', 'Facebook AI Research', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
Interferobot: aligning an optical interferometer by a reinforcement learning agent,"Dmitry Sorokin, Alexander Ulanov, Ekaterina Sazhina, Alexander Lvovsky",Interferobot: aligning an optical interferometer by a reinforcement learning agent,99ba5c4097c6b8fef5ed774a1a6714b8,https://proceedings.neurips.cc/paper/2020/file/99ba5c4097c6b8fef5ed774a1a6714b8-Paper.pdf,"The direct application of our work is the automation of complex optical experiments. A robotic agent will take over a mundane part of the experimentalist’s work, so scientists can concentrate on generating research ideas and analyzing the scientific results. A potential risk is associated with laser safety, which is a primary concern in optical experiments, as laser beams are able to permanently damage the eyesight. While standard precautions (goggles, barriers, etc.) are normally taken to reduce this risk, additional measures may be required to prevent beams from being misdirected outside the plane of the optical table by the robotic agent. This can be achieved, for example, by limiting the angular range of motorized mirror mounts at the hardware level.",Broader impact,119,6,,,FALSE,FALSE,FALSE,Interferobot: aligning an optical interferometer by a reinforcement learning agent,Applications -> Robotics,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Dmitry Sorokin', ' Alexander Ulanov', ' Ekaterina Sazhina', ' Alexander Lvovsky']","{'Oxford University', 'Russian Quantum Center'}",1,0,0,"{'UK', 'Russia'}"
Program Synthesis with Pragmatic Communication,"Yewen Pu, Kevin Ellis, Marta Kryven, Josh Tenenbaum, Armando Solar-Lezama",Program Synthesis with Pragmatic Communication,99c83c904d0d64fbef50d919a5c66a80,https://proceedings.neurips.cc/paper/2020/file/99c83c904d0d64fbef50d919a5c66a80-Paper.pdf,"We hope that naive end-users would benefit from this research, as we aim for a more natural interaction between human and machine. This would allow boarder access to computes by non-programmers, so that we may work along-side the machines rather than being replaced by them.",Broader Impact,45,2,FALSE,FALSE,FALSE,FALSE,FALSE,Program Synthesis with Pragmatic Communication,Algorithms -> Program Induction,Neuroscience and Cognitive Science -> Cognitive Science; Probabilistic Methods -> Probabilistic Programming,Neuroscience and cognitive science,"['Yewen Pu', ' Kevin Ellis', ' Marta Kryven', ' Josh Tenenbaum', 'Lezama']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Principal Neighbourhood Aggregation for Graph Nets,"Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Liò, Petar Veličković",Principal Neighbourhood Aggregation for Graph Nets,99cad265a1768cc2dd013f0e740300ae,https://proceedings.neurips.cc/paper/2020/file/99cad265a1768cc2dd013f0e740300ae-Paper.pdf,"Our work focuses mainly on theoretically analyzing the expressive power of Graph Neural Networks and can, therefore, play an indirect role in the (positive or negative) impacts that the field of graph representation learning might have on the domains where it will be applied. More directly, our contribution in proving the limitations of existing GNNs on continuous feature spaces should help to provide an insight into their behaviour. We believe this is a significant result which might motivate future research aimed at overcoming such limitations, yielding more reliable models. However, we also recognize that, in the short-term, proofs of such weaknesses might spark mistrust against applications of these systems or steer adversarial attacks towards existing GNN architectures. In an effort to overcome some of these short-term negative impacts and contribute to the search for more reliable models, we propose the Principal Neighbourhood Aggregation, a method that overcomes some of these theoretical limitations. Our tests demonstrate the higher capacity of the PNA compared to the prior art on both synthetic and real-world tasks; however, we recognize that our tests are not exhaustive and that our proofs do not allow for generating “optimal” aggregators for any task. As such, we do not rule out sub-optimal performance when applying the exact architecture proposed here to novel domains. We propose the usage of aggregation functions, such as standard deviation and higher-order moments, and logarithmic scalers. To the best of our knowledge, these have not been used before in GNN literature. To further test their behaviour, we conducted out-of-distribution experiments, testing our models on graphs much larger than those in the training set. While the PNA model consistently outperformed other models and baselines, there was still a noticeable drop in performance. We therefore strongly encourage future work on analyzing the stability and efficacy of these novel aggregation methods on new domains and, in general, on finding GNN architectures that better generalize to graphs from unseen distributions, as this will be essential for the transition to industrial applications.",Broader Impact,332,12,,,FALSE,FALSE,FALSE,Principal Neighbourhood Aggregation for Graph Nets,Algorithms -> Relational Learning,Algorithms -> Representation Learning,Deep learning,"['Gabriele Corso', ' Luca Cavalleri', ' Dominique Beaini', ' Pietro Liò', ' Petar Veličković']","{'University of Cambridge', 'Invivo AI', 'DeepMind'}",1,1,1,{'UK'}
Reliable Graph Neural Networks via Robust Aggregation,"Simon Geisler, Daniel Zügner, Stephan Günnemann",Reliable Graph Neural Networks via Robust Aggregation,99e314b1b43706773153e7ef375fc68c,https://proceedings.neurips.cc/paper/2020/file/99e314b1b43706773153e7ef375fc68c-Paper.pdf,"This work is one step on the path towards the adversarial robustness of GNNs. Consequently, all potential applications of GNNs could benefit. These applications are computer vision, knowledge graphs, recommender systems, physics engines, and many more [53, 57]. Robust machine learning models certainly come with less opportunity of (fraudulent) manipulation. Robust models will enable the application of artificial intelligence (AI) for new use cases (e.g. safety-critical systems)—with all the related pros and cons. Perhaps, at some point, the discussion of risks and opportunities for AI [3, 11] and robust machine learning will converge. Focusing on the negative aspects of contemporary applications, robust GNNs might cause, e.g., an increased automation bias [43], or fewer loopholes e.g. in the surveillance implemented in authoritarian systems [2].",Broader Impact,123,7,,,FALSE,FALSE,FALSE,Reliable Graph Neural Networks via Robust Aggregation,Algorithms -> Adversarial Learning,Algorithms -> Relational Learning; Algorithms -> Semi-Supervised Learning; Applications -> Network Analysis; Deep Learning -> Supervised Deep Networks; Theory -> Frequentist Statistics,Deep learning,,{'Technical University of Munich'},1,0,0,{'Germany'}
Instance Selection for GANs,"Terrance DeVries, Michal Drozdzal, Graham W. Taylor",Instance Selection for GANs,99f6a934a7cf277f2eaece8e3ce619b2,https://proceedings.neurips.cc/paper/2020/file/99f6a934a7cf277f2eaece8e3ce619b2-Paper.pdf,"The application of instance selection to the task of image generative modelling brings with it several benefits. Gains in image generation quality are an obvious improvement, but perhaps more impactful to the broader community are the reductions in model capacity and training time that are afforded. Reducing the computational barrier to entry for training large-scale generative models provides many individuals, including students, AI artists, and ML enthusiasts, with access to models that are otherwise restricted to only the most well resourced labs. In addition to greater accessibility, lowering the computational requirements for training large-scale generative models also reduces associated energy costs and CO 2 emissions associated with the training process. One side effect of our instance selection method is that, by nature of design, generated results are more likely to reflect the content that makes up the majority of the training set. As such, dataset bias is amplified as instances that are poorly represented in the dataset may be completely ignored. However, this limitation can be addressed by properly balancing the training set before instance selection is applied or alternatively, ensuring a more diverse & inclusive data collection effort to begin with.  As with any form of generative model, there is some potential for misuse. A common example is “deepfakes”, where a generative model is used to manipulate images or videos well enough that humans cannot distinguish real from fake. While often used to create humorous videos in which actors’ faces are swapped, deepfakes also have the potential for more nefarious uses, such as for blackmail or spreading misinformation. Fortunately, much recent effort has been dedicated towards automatic detection of these false images [30]. These techniques attempt to find manipulated media by detecting inconsistencies, such as in the synchronization of lip movement and speech audio, or generation artifacts, such as missing reflections or other minute details.",Broader Impact,306,12,,,FALSE,FALSE,FALSE,Instance Selection for GANs,Deep Learning -> Generative Models,Deep Learning -> Adversarial Networks,Deep learning,"['Terrance DeVries', ' Michal Drozdzal', ' Graham W Taylor']","{'FAIR', 'University of Guelph'}",1,1,1,"{'Canada', 'USA'}"
Linear Disentangled Representations and Unsupervised Action Estimation,"Matthew Painter, Adam Prugel-Bennett, Jonathon Hare",Linear Disentangled Representations and Unsupervised Action Estimation,9a02387b02ce7de2dac4b925892f68fb,https://proceedings.neurips.cc/paper/2020/file/9a02387b02ce7de2dac4b925892f68fb-Paper.pdf,"Representation learning as a whole does have the potential for unethical applications. Disentanglement if successfully applied to multi-object scenes could allow (or perhaps require, this is unclear) segmentation/separation of individual objects and their visual characteristics. Both segmentation and learning visual characteristics have numerous ethical and unethical uses on which we wont speculate. For our particular work, we don’t believe understanding and encouraging linear disentangled representations has any ethical considerations beyond the broad considerations of disentanglement work as a whole. We do believe that routes towards reducing the degree of human annotation in data (such as our proposed model) is beneficial for reducing human bias, although this can introduced even by the choice of base data to train on. Unfortunately for our work (and most unsupervised work), explicit supervision allows for more rapid convergence and consequently a lower environmental impact, a topic which is of increasing concern especially for deep learning which leans heavily on power intensive compute hardware.",8 Broader Impact,158,6,,,FALSE,FALSE,FALSE,Linear Disentangled Representations and Unsupervised Action Estimation,Algorithms -> Representation Learning,Deep Learning -> Deep Autoencoders; Probabilistic Methods -> Variational Inference,Deep learning,"['Matthew Painter', 'Bennett', ' Jonathon Hare']",{'University of Southampton'},1,0,0,{'UK'}
Video Frame Interpolation without Temporal Priors,"Youjian Zhang, Chaoyue Wang, Dacheng Tao",Video Frame Interpolation without Temporal Priors,9a11883317fde3aef2e2432a58c86779,https://proceedings.neurips.cc/paper/2020/file/9a11883317fde3aef2e2432a58c86779-Paper.pdf,"Video frame interpolation (VFI), which aims to overcome the temporal limitation of camera sensors, is a popular and important technology in a wide range of video processing tasks. For example, it could produce slow-motion videos without professional high-speed cameras, and it could perform the frame rate up-conversion (or video restoration) for archival footage. However, existing VFI researches can mainly apply to videos with pre-defined temporal priors, such as sharp video frames or blurry videos with known exposure settings. It may largely limit their performance in complicated real-world situations. To our best knowledge, the video frame interpolation framework we introduced in this paper made the first attempt to overcome these limitations. Our proposed technique may potentially benefit a series of real-world applications and users. On the one hand, it could be more practical and convenient for users who want to convert their own videos to slow-motion, since they are not required to figure out the video sources, i.e. the complicated parameters of camera sensors. On the other hand, it could reduce the workload of VFI-related applications, i.e. it would not need to retrain new models for different exposure settings. Since the video frame interpolation aims at video restoration and up-conversion ( i.e. the output video shares the same content as the given video), our method may not cause negative ethical impact, if we do not discuss the content of the input video.",Broader Impact,231,9,,,FALSE,FALSE,FALSE,Video Frame Interpolation without Temporal Priors,Applications -> Computer Vision,Applications -> Denoising,Vision,,"{'the University of Sydney', 'University of Sydney'}",1,0,0,{'Australia'}
Learning compositional functions via multiplicative weight updates,"Jeremy Bernstein, Jiawei Zhao, Markus Meister, Ming-Yu Liu, Anima Anandkumar, Yisong Yue",Learning compositional functions via multiplicative weight updates,9a32ef65c42085537062753ec435750f,https://proceedings.neurips.cc/paper/2020/file/9a32ef65c42085537062753ec435750f-Paper.pdf,This paper proposes that multiplicative update rules may be better suited to the compositional structure of neural networks than additive update rules. It concludes by discussing possible implications of this idea for chip design and neuroscience. The authors believe the work to be fairly neutral in terms of propensity to cause positive or negative societal outcomes.,Broader impact,56,3,FALSE,TRUE,FALSE,FALSE,FALSE,Learning compositional functions via multiplicative weight updates,Optimization -> Non-Convex Optimization,Deep Learning -> Biologically Plausible Deep Networks,Optimization Methods (continuous or discrete),"['Jeremy Bernstein', ' Jiawei Zhao', ' Markus Meister', 'Yu Liu', ' Anima Anandkumar', ' Yisong Yue']","{'NVIDIA / Caltech', 'Caltech', 'NVIDIA'}",1,1,1,{'USA'}
Sample Complexity of Uniform Convergence for Multicalibration,"Eliran Shabat, Lee Cohen, Yishay Mansour",Sample Complexity of Uniform Convergence for Multicalibration,9a96876e2f8f3dc4f3cf45f02c61c0c1,https://proceedings.neurips.cc/paper/2020/file/9a96876e2f8f3dc4f3cf45f02c61c0c1-Paper.pdf,"The generalization bounds we derive in this work can be utilized to measure the calibration error of predictors. When it comes to predictors that assign probabilities to individuals (e.g., probability of repaying a loan), verifying that predictors are “multicalibrated” provides society with fairness guarantees about their performances. While our work makes an important contribution to this significant societal matter, we point out some limitations. First, it is up to regulators to decide upon the subpopulations collection properly. For example, if subpopulations that are characterized by gender are excluded, it might harm major parts of the population. Second, even if the aforementioned issue is tackled, and good approximations for multicalibration are obtained, they do not dismiss other forms of fairness, and as a result, fairness as a general concept is still not guaranteed. In particular, the tools that derive from our work are not applicable for “negligible size” subpopulations (that is, U ∈ Γ such that Pr D [ x ∈ U ] < γ ). At the extreme, we might have subpopulations which are singletons (single individuals), for which one should use individual fairness rather than group fairness. In addition, regulators should use the tools we present with caution as unforeseeable trade-offs between other fairness constraints might also arise, and insuring one form of fairness could lead to worsening others. Overall, we emphasize that regulators should heavily consider the full meaning of their choices, and understanding them with respect to multicalibration is only a part of it.",Broader Impact,247,10,FALSE,FALSE,FALSE,FALSE,FALSE,Sample Complexity of Uniform Convergence for Multicalibration,Social Aspects of Machine Learning,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Eliran Shabat', ' Lee Cohen', ' Yishay Mansour']","{'Tel Aviv University / Google', 'Tel-Aviv University', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
Differentiable Neural Architecture Search in Equivalent Space with Exploration Enhancement,"Miao Zhang, Huiqi Li, Shirui Pan, Xiaojun Chang, Zongyuan Ge, Steven Su",Differentiable Neural Architecture Search in Equivalent Space with Exploration Enhancement,9a96a2c73c0d477ff2a6da3bf538f4f4,https://proceedings.neurips.cc/paper/2020/file/9a96a2c73c0d477ff2a6da3bf538f4f4-Paper.pdf,"Automatic Machine Learning (AutoML) aims to build a better machine learning model in a data- driven and automated manner, compensating for the lack of machine learning experts and lowering the threshold of various areas of machine learning to help all the amateurs to use machine learning without any hassle. These days, many companies, like Google and Facebook, are using AutoML to build machine learning models for handling different businesses automatically. They especially leverage the AutoML to automatically build Deep Neural Networks for solving various tasks, including computer vision, natural language processing, autonomous driving, and so on. AutoML is an up-and-coming tool to take advantage of the extracted data to find the solutions automatically. This paper focuses on the Neural Architecture Search (NAS) of AutoML, and it is the first attempt to enhance the intelligent exploration of differentiable One-Shot NAS in the latent space. The experimental results demonstrate the importance of introducing uncertainty into neural architecture search, and point out a promising research direction in the NAS community. It is worth notice that NAS is in its infancy, and it is still very challenging to use it to complete automation of a specific business function like marketing analytics, customer behavior, or other customer analytics.",Broader Impact,203,7,,,FALSE,FALSE,FALSE,Differentiable Neural Architecture Search in Equivalent Space with Exploration Enhancement,Algorithms -> AutoML,Algorithms -> Online Learning; Algorithms -> Uncertainty Estimation; Deep Learning -> CNN Architectures; Deep Learning -> Deep Autoencoders,AutoML,"['Miao Zhang', ' Huiqi Li', ' Shirui Pan', ' Xiaojun Chang', ' Zongyuan Ge', ' Steven Su']","{'University of Technology Sydney', 'Monash University', 'Beijing Institute of Technology'}",1,0,0,"{'Australia', 'China'}"
The interplay between randomness and structure during learning in RNNs,"Friedrich Schuessler, Francesca Mastrogiuseppe, Alexis Dubreuil, Srdjan Ostojic, Omri Barak",The interplay between randomness and structure during learning in RNNs,9ac1382fd8fc4b631594aa135d16ad75,https://proceedings.neurips.cc/paper/2020/file/9ac1382fd8fc4b631594aa135d16ad75-Paper.pdf,"This work is a theoretical study on the dynamics of learning in RNNs. We show which kind of connectivity changes are induced by gradient descent. We expect that our insights will help to understand learning in RNNs, which benefits the research community as a whole and may ultimately lead to the development of improved learning algorithms or schemes. As a possible application, we show that one can use our results to efficiently compress a multi-layer RNN trained on a natural language processing task. In this work, there are no new algorithms, tasks, or data sets introduced. Therefore, the questions regarding any disadvantages, failures of the system, or biases do not apply.",Broader Impact,111,6,,,FALSE,FALSE,FALSE,The interplay between randomness and structure during learning in RNNs,Deep Learning -> Recurrent Networks,Theory -> Models of Learning and Generalization ; Theory -> Statistical Learning Theory; Theory -> Statistical Physics of Learning,Theory (including computational and statistical analyses),"['Friedrich Schuessler', ' Francesca Mastrogiuseppe', ' Alexis Dubreuil', ' Srdjan Ostojic', ' Omri Barak']","{'Technion - Israeli institute of technology', 'UCL', 'Technion', 'Ecole Normale Superieure', 'ENS'}",1,1,1,"{'France', 'UK', 'Israel'}"
A Generalized Neural Tangent Kernel Analysis for Two-layer Neural Networks,"Zixiang Chen, Yuan Cao, Quanquan Gu, Tong Zhang",A Generalized Neural Tangent Kernel Analysis for Two-layer Neural Networks,9afe487de556e59e6db6c862adfe25a4,https://proceedings.neurips.cc/paper/2020/file/9afe487de556e59e6db6c862adfe25a4-Paper.pdf,"Deep learning has achieved tremendous success in various real-world applications such as image recognition, natural language processing, self-driving cars and disease diagnosis. However, many deep learning models are not interpretable, which greatly limits their application and can even cause danger in safety-critical applications. This work aims to theoretically explain the success of learning neural networks, and can help add transparency to deep learning methods that have been implemented and deployed in real applications. Our result makes deep learning more interpretable, which is crucial in applications such as self-driving cars and disease diagnosis. Moreover, our results can potentially guide the design of new deep learning models with better performance guarantees. As a paper focusing on theoretical results, no risk can be directly caused. However, if the theoretical results are over-interpreted and blindly used to design deep learning models for specific applications, bad performance may be expected as there is still some gap between theory and practice.",Broader Impact,155,7,,,FALSE,FALSE,FALSE,A Generalized Neural Tangent Kernel Analysis for Two-layer Neural Networks,Deep Learning -> Optimization for Deep Networks,Optimization -> Non-Convex Optimization,Deep learning,"['Zixiang Chen', ' Yuan Cao', ' Quanquan Gu', ' Tong Zhang']","{'UCLA', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
Instance-wise Feature Grouping,"Aria Masoomi, Chieh Wu, Tingting Zhao, Zifeng Wang, Peter Castaldi, Jennifer Dy",Instance-wise Feature Grouping,9b10a919ddeb07e103dc05ff523afe38,https://proceedings.neurips.cc/paper/2020/file/9b10a919ddeb07e103dc05ff523afe38-Paper.pdf,"In this paper, we introduce a novel algorithm for instance-wise feature group discovery and selection. The algorithm learns mapping functions that identify the appropriate group membership of each feature along with each group’s importance as an instance-wise label predictor. Namely, we have focused our paper on feature selection to model the features important for capturing the information in the underlying true posterior P ( Y | X ) . While we have focused on feature selection, there are also other strategies to define and approach interpretability [45]. Instead of estimating the posterior distribution P ( Y | X ) , one can apply our method to capture the information for trained black-box models P M ( Y | X ) , e.g., deep neural networks and random forests. Consequently, the algorithm can be used to perform instance-wise group feature selection on the black-box model, learning the features which a given black-box model perceives as important. In this approach to explainability, our method has the potential impact on making black-box models explainable in terms of knowing how the features were used during prediction. This gives rise to future research directions that can help data scientists check for bias, fairness, vulnerabilities of the models they use [46, 47]. Although this paper focuses on the machine learning aspect of our discovery, our work is also relevant from its consequential findings on the lung disease dataset. The feature selection results on the lung disease data allow us to discover the genes that interact together for predicting smoking and non-smoking. This can potentially impact our understanding of lung disease, in particular by identifying cooperative relationship between genes that can delineate important aspects of their biological functions. However, to make an impact to medical research would require further and careful investigation to confirm the findings with appropriate medical collaborators. As a warning to our ML and data analyst colleagues, we encourage applying ML to applications that is beneficial to society, such as health. But, to do so properly, one needs to work closely with domain expert collaborators to make nontrivial contributions to their fields of research. Beyond applications to lung disease, learning important features for prediction and the features that interact together is important in genetic understanding of other diseases [48, 49]. In general, feature selection has been impactful in a variety of domains beyond medicine – for example, climate [50], law[51]. Given the potential impact it can have, including on the most pressing diseases of today, we seek to widely disseminate this research and make our source code publicly available at https: //github.com/ariahimself/Instance-wise-Feature-Grouping . Lastly, while our method is useful in identifying feature groups that interact together for prediction. We caution that this does not imply causation, and poses a potential misuse of our technique. Additionally, since our model is learned from a training set, its conclusions are limited by the quality and characteristics of what it was trained on. Therefore, inherent biases that pre-existed in the data will lead to biased feature groups and conclusions. As with any supervised machine learning algorithms, our method can be applied to a variety of applications (e.g., health, climate, image analysis) with potential impact to multiple sectors of society. Our intent is to build such models for societal good and we encourage others to as well.",5 Broader Impacts,548,23,,,FALSE,FALSE,FALSE,Instance-wise Feature Grouping,Algorithms -> Sparsity and Compressed Sensing,Algorithms -> Representation Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Aria Masoomi', ' Chieh Wu', ' Tingting Zhao', ' Zifeng Wang', ' Peter Castaldi', ' Jennifer Dy']","{'Northeastern University', 'Northeastern'}",1,0,0,{'USA'}
Robust Disentanglement of a Few Factors at a Time,"Benjamin Estermann, Markus Marks, Mehmet Fatih Yanik",Robust Disentanglement of a Few Factors at a Time,9b22a40256b079f338827b0ff1f4792b,https://proceedings.neurips.cc/paper/2020/file/9b22a40256b079f338827b0ff1f4792b-Paper.pdf,"Robust disentangled representations are directly applicable to many domains within science and medicine. In recent years, many unsupervised methods, i.e. dimensionality reduction and manifold techniques, have been used to discover structure in complex datasets in physics [30], genomics [31, 32], neuroscience [33] and energy prediction [34]. Not only do these provide an opportunity in discovering underlying structure in natural phenomena, but also human biases can be reduced by data-driven analysis. Similarly, there has been a surge in use of unsupervised learning in medicine such as drug design [35], detection of brain lesions [36], cardiac image analysis [37] and drug side effect discovery [38]. Unsupervised approaches have been also highly successful in experimental Brain-Machine-Interfaces (BMI) [39], leading to higher stability of BMI readouts. However, the enhanced interpretability of disentangled representations in these applications might lead to undue sense of trust and greater negative consequences in case of failures. Thus, further research on reliability of AI approaches has to be done beyond the proof-of-principle. Our algorithm relies on training large numbers of models, requiring significant computational resources. Therefore energy consumption and resulting CO 2 footprint can be quite substantial [40]. The aforementioned benefits of utilizing disentangled representations to improve outcomes in science and medicine are difficult to weigh against the entailing environmental costs and need to be evaluated on a case-by-case basis. Alternatively, further research (such as use of spiking neural networks [41]) may make our approach much more computationally efficient.",7 Broader Impact,239,11,,,FALSE,FALSE,FALSE,Robust Disentanglement of a Few Factors at a Time using rPU-VAE,Algorithms -> Representation Learning,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Benjamin Estermann', ' Markus Marks', ' Mehmet Fatih Yanik']","{'ETH Zurich', 'ETH Zürich'}",1,0,0,{'Switzerland'}
PC-PG: Policy Cover Directed Exploration for Provable Policy Gradient Learning,"Alekh Agarwal, Mikael Henaff, Sham Kakade, Wen Sun",PC-PG: Policy Cover Directed Exploration for Provable Policy Gradient Learning,9b3a9fb4db30fc6594ec3990cbc09932,https://proceedings.neurips.cc/paper/2020/file/9b3a9fb4db30fc6594ec3990cbc09932-Paper.pdf,"This paper provides a provably efficient policy gradient algorithm. Though the nature of the paper is mostly theoretical and the paper heavily focuses on understanding the theoretical foundations of one of the most popular RL algorithms, i.e., policy gradient, we believe that our theoretical findings and the proposed new algorithm will have a broader impact on the society. Due to the high sample complexity of existing PG methods, they are often limited to applications related to video games. We believe that by providing global optimality and sample efficiency to PG methods, we will significantly broaden the application scope of PG methods. Specifically, our work potentially could enable PG methods to be deployed in real-world applications such as precision medicine, human robot interaction, and personalized eduction systems where safety and robustness are critical.",Broader Impact,132,5,,,FALSE,FALSE,FALSE,PC-PG: Policy Cover Directed Exploration for Provable Policy Gradient Learning,Theory -> Statistical Learning Theory,Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Reinforcement Learning,,,"{'Microsoft', 'University of Washington', 'Microsoft Research', 'Microsoft Research NYC'}",1,1,1,{'USA'}
Group Contextual Encoding for 3D Point Clouds,"Xu Liu, Chengtao Li, Jian Wang, Jingbo Wang, Boxin Shi, Xiaodong He",Group Contextual Encoding for 3D Point Clouds,9b72e31dac81715466cd580a448cf823,https://proceedings.neurips.cc/paper/2020/file/9b72e31dac81715466cd580a448cf823-Paper.pdf,"Our “Group Contextual Encoding” can be directly applied to the 3D point cloud scene understanding tasks including 3D object detection, voxel labeling, and segmentation. Our research can also support downstream research and applications such as autonomous driving, robotics, and AR/MR. We will investigate the generalizability of our method to other tasks and frameworks, e.g., Graph Convolution network, 3D sparse CNNs, where the global context plays a crucial role in these tasks. On the other hand, this technology may also endanger the employment of human servants and drivers because they may be replaced by autonomous robots and vehicles, which may cause the potential social problems. This issue should be taken seriously and measures should be taken for preparation.",Broader Impact,117,5,,,FALSE,FALSE,FALSE,Group Contextual Encoding for 3D Point Clouds,Applications -> Computer Vision,Applications -> Object Detection; Applications -> Robotics,Vision,"['Xu Liu', ' Chengtao Li', ' Jian Wang', ' Jingbo Wang', ' Boxin Shi', ' Xiaodong He']","{'Peking University', 'Carnegie Mellon University', 'JD AI research', 'MIT', 'The University of Tokyo'}",1,1,1,"{'Japan', 'USA', 'China'}"
Latent Bandits Revisited,"Joey Hong, Branislav Kveton, Manzil Zaheer, Yinlam Chow, Amr Ahmed, Craig Boutilier",Latent Bandits Revisited,9b7c8d13e4b2f08895fb7bcead930b46,https://proceedings.neurips.cc/paper/2020/file/9b7c8d13e4b2f08895fb7bcead930b46-Paper.pdf,"Our work develops improved algorithms for bandit-style exploration in a very general and abstract sense. We have demonstrated its ability to increase the rate at which interactive systems identify user latent state to improve long-term impact on user reward (e.g., engagement in a recommender system). Our work is agnostic to the form of the reward. We are strongly motivated by improving user positive engagement with interactive systems (e.g., by identifying user interests or preferences in a recommender system). However, other forms of reward that are unaligned with a user’s best interests could be used—our methods do not propose specific reward models. That said, our work has no social implications (welfare, fairness, privacy, etc.) beyond those already at play in the interactive system to which our methods might be applied.",Broader Impact,129,7,,,FALSE,FALSE,FALSE,Latent Bandits Revisited,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Joey Hong', ' Manzil Zaheer', ' Yinlam Chow', ' Branislav Kveton', ' Amr Ahmed', ' Craig Boutilier']","{'Google', 'Google AI', 'Google Research'}",0,1,0,{'USA'}
Is normalization indispensable for training deep neural network?,"Jie Shao, Kai Hu, Changhu Wang, Xiangyang Xue, Bhiksha Raj",Is normalization indispensable for training deep neural networks?,9b8619251a19057cff70779273e95aa6,https://proceedings.neurips.cc/paper/2020/file/9b8619251a19057cff70779273e95aa6-Paper.pdf,"Our research studies a lower level problem of deep learning, i.e., the architecture of neural networks. Researchers who are interested in the functionalities of normalization or more generally, the training of deep neural networks, may get some insights from our paper. Further, our method can be used to train neural networks with small batch size, thus researchers with limited computation resources may benefit from this. Since our research does not involve any specific high-level AI applications, we do not think there would be any people being put at disadvantage from this research to the best of our knowledge. The meaning of our research more lies in terms of theory, thus we cannot see any bad consequences of a failure of the system. We follow the most common settings in the deep learning community to process data and the task/method does not leverage biases in the data.",Broader Impact,146,6,,,FALSE,FALSE,FALSE,Is normalization indispensable for training deep neural network?,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Jie Shao', ' Kai Hu', ' Changhu Wang', ' Xiangyang Xue', ' Bhiksha Raj']","{'Carnegie Mellon University', 'Fudan University'}",1,0,0,"{'USA', 'China'}"
Optimization and Generalization of Shallow Neural Networks with Quadratic Activation Functions,"Stefano Sarao Mannelli, Eric Vanden-Eijnden, Lenka Zdeborová",Optimization and Generalization of Shallow Neural Networks with Quadratic Activation Functions,9b8b50fb590c590ffbf1295ce92258dc,https://proceedings.neurips.cc/paper/2020/file/9b8b50fb590c590ffbf1295ce92258dc-Paper.pdf,"Our work is theoretical in nature, and as such the potential societal consequence are difficult to foresee. We anticipate that deeper theoretical understanding of the functioning of machine learning systems will lead to their improvement in the long term.",Broader Impact,39,2,TRUE,FALSE,FALSE,FALSE,FALSE,Optimization and Generalization of Shallow Neural Networks with Quadratic Activation Functions,Theory -> Models of Learning and Generalization,Optimization -> Non-Convex Optimization; Theory -> Statistical Physics of Learning,Theory (including computational and statistical analyses),"['Stefano Sarao Mannelli', 'Eijnden', ' Lenka Zdeborová']","{'CEA Saclay', 'New York University', 'Institut de Physique Théorique'}",1,0,0,"{'France', 'USA'}"
Intra Order-preserving Functions for Calibration of Multi-Class Neural Networks,"Amir Rahimi, Amirreza Shaban, Ching-An Cheng, Richard Hartley, Byron Boots",Intra Order-Preserving Functions for Calibration of Multi-Class Neural Networks,9bc99c590be3511b8d53741684ef574c,https://proceedings.neurips.cc/paper/2020/file/9bc99c590be3511b8d53741684ef574c-Paper.pdf,"Predicting calibrated confidence scores for multi-class deep networks is important for avoiding rare but costly mistakes. Trusting the network’s output naively as confidence scores in system design could cause undesired consequences: a serious issue for applications where mistakes are costly, such as medical diagnosis, autonomous driving, suspicious events detection, or stock-market. As an example, in medical diagnosis, it is vital to estimate the chance of a patient being recovered by a certain operation given her/his condition. If the estimation is overconfident/underconfident this will put the life of the patient at risk. Confidence calibrated models would enable integration into downstream decision-making systems, allow machine learning interpretability, and help gain the user trust. While this work focuses primarily on some of the theoretical aspects of the neural network calibration, it also proposes novel techniques to potentially improve broader set of applications where preserving the rank of set of inputs is desired e.g. tone-mapping in images where tone-maps need to be monotonic, depth perception system calibration, and data compression. We need to remark that our research shows that methods perform differently under various calibration metrics. Unfortunately, discrepancy between different calibration metrics is not well understood and fully explored in the literature. We believe more insights into these inconsistencies would be valuable to the field. We report the performance under different calibration metrics to highlight these differences for the future research. This also means that integrating the proposed work or any other calibration method into decision making systems requires application specific considerations. Other than that, since this work is mostly on the theoretical aspect of improving calibration, we do not foresee any direct negative impacts.",Broader Impact,271,12,,,FALSE,FALSE,FALSE,Intra Order-preserving Functions for Calibration of Multi-Class Neural Networks,Algorithms -> Uncertainty Estimation,"Deep Learning -> Supervised Deep Networks; Deep Learning -> Visualization, Interpretability, and Explainability; Theory -> Regularization",Deep learning,"['Amir Rahimi', ' Amirreza Shaban', 'An Cheng', ' Richard I Hartley', ' Byron Boots']","{'Microsoft', 'Georgia Institute of Technology', 'Australian National University', 'University of Washington'}",1,1,1,"{'Australia', 'USA'}"
Linear Time Sinkhorn Divergences using Positive Features,"Meyer Scetbon, Marco Cuturi",Linear Time Sinkhorn Divergences using Positive Features,9bde76f262285bb1eaeb7b40c758b53e,https://proceedings.neurips.cc/paper/2020/file/9bde76f262285bb1eaeb7b40c758b53e-Paper.pdf,"Optimal Transport (OT) has gained interest last years in machine learning with many applications in neuroimaging, generative models, supervised learning, word embeddings, reconstruction cell trajectories or adversarial examples. This work brings new applications to OT in the high dimensional setting as it provides a linear time method to compute an approximation of the OT cost and gives a constructive method to learn an adapted kernel or equivalently an adapted cost function depending on the problem considered.",Broader Impact,76,2,,,FALSE,FALSE,FALSE,Linear Time Sinkhorn Divergences using Positive Features,Algorithms,Algorithms -> Kernel Methods; Algorithms -> Metric Learning; Deep Learning -> Generative Models,Optimal Transport,"['Meyer Scetbon', ' Marco Cuturi']",{'CREST-ENSAE'},1,0,0,"{'France', 'USA'}"
VarGrad: A Low-Variance Gradient Estimator for Variational Inference,"Lorenz Richter, Ayman Boustati, Nikolas Nüsken, Francisco Ruiz, Omer Deniz Akyildiz",VarGrad: A Low-Variance Gradient Estimator for Variational Inference,9c22c0b51b3202246463e986c7e205df,https://proceedings.neurips.cc/paper/2020/file/9c22c0b51b3202246463e986c7e205df-Paper.pdf,"Variational inference algorithms are approximate inference methods used in many practical applications, including computational neuroscience, natural language processing, and computer vision; see Blei et al. [2017]. The performance of variational inference often depends on the variance of the gradient estimator of its objective. High-variance estimators can make the resulting algorithm unstable and unreliable to use in real-world deployment scenarios; hence, deeper theoretical and empirical understanding of different gradient estimators is crucial for safe applicability of these methods in real-world settings. In our work, we provide an analysis of the VarGrad estimator. We show the connection between this estimator and the “log-variance loss” and demonstrate its relationship to the optimal score function control variate for Reinforce, providing a theoretical analysis. We support our theoretical analysis with empirical results. We believe our work contributes in the further understanding of variational inference methods and contributes to improving their safety and applicability. While our theoretical results are suggestive, we warn that the bounds depend on the nature of the model at hand. Therefore, the use of the results here while ignoring the model-specific aspects of our assumptions may lead to some risks in application.",Broader Impact,190,10,,,FALSE,FALSE,FALSE,VarGrad: A Low-Variance Gradient Estimator for Variational Inference,Probabilistic Methods -> Variational Inference,Probabilistic Methods; Probabilistic Methods -> Latent Variable Models,Probabilistic methods and inference,"['Lorenz Richter', ' Ayman Boustati', ' Nikolas Nüsken', ' Francisco Ruiz', ' Omer Deniz Akyildiz']","{'University of Warwick', 'Universität Potsdam', 'DeepMind', 'Freie Universität Berlin, BTU Cottbus-Senftenberg, dida'}",1,1,1,"{'UK', 'Germany'}"
A Convolutional Auto-Encoder for Haplotype Assembly and Viral Quasispecies Reconstruction,"Ziqi Ke, Haris Vikalo",A Convolutional Auto-Encoder for Haplotype Assembly and Viral Quasispecies Reconstruction,9c449771d0edc923c2713a7462cefa3b,https://proceedings.neurips.cc/paper/2020/file/9c449771d0edc923c2713a7462cefa3b-Paper.pdf,"Reconstruction of haplotypes and viral quasispecies from sequencing data are challenging due to limitations of high-throughput sequencing platforms and the large dimensions of these problems. In-depth studies of haplotypes are critical for understanding individual’s susceptibility to a broad range of chronic and acute diseases. Moreover, studies of viral quasispecies provide insight into viral dynamics and offer guidance in the development of effective medical therapeutics for diseases caused by RNA viruses such as HIV, HCV, Zika, coronavirus and so on. Therefore, the results of work presented in this manuscript have potential to benefit society by aiding medical research. Potential ethical concern may arise should the proposed haplotype reconstruction techniques be adopted to prenatal testing.",Broader Impact,113,5,,,FALSE,FALSE,FALSE,A Convolutional Auto-Encoder for Haplotype Assembly and Viral Quasispecies Reconstruction,Applications -> Computational Biology and Bioinformatics,Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Ziqi Ke', ' Haris Vikalo']","{'The University of Texas at Austin', 'University of Texas at Austin'}",1,0,0,{'USA'}
Promoting Stochasticity for Expressive Policies via a Simple and Efficient Regularization Method,"Qi Zhou, Yufei Kuang, Zherui Qiu, Houqiang Li, Jie Wang",Promoting Stochasticity for Expressive Policies via a Simple and Efficient Regularization Method,9cafd121ba982e6de30ffdf5ada9ce2e,https://proceedings.neurips.cc/paper/2020/file/9cafd121ba982e6de30ffdf5ada9ce2e-Paper.pdf,"This work focuses on promoting stochasticity for expressive policies via sample-based regularization. It has the following potential positive impact: a). it encourages future research on more expressive policy architectures; b). it proposes a novel sample-based regularization method, which inspires future work to find more efficient regularizers in regularized RL algorithm; c). it promotes the application of RL algorithms in more complex control tasks. However, any reinforcement learning method runs the risk of being applied to military activities. Our work is no exception.",Broader Impact,82,7,,,FALSE,FALSE,FALSE,Promoting Stochasticity for Expressive Policies via a Simple and Efficient Regularization Method,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Exploration,Reinforcement learning and planning,"['Qi Zhou', ' Yufei Kuang', ' Zherui Qiu', ' Houqiang Li', ' Jie Wang']",{'University of Science and Technology of China'},1,0,0,{'China'}
Adversarial Counterfactual Learning and Evaluation for Recommender System,"Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan",Adversarial Counterfactual Learning and Evaluation for Recommender System,9cd013fe250ebffc853b386569ab18c0,https://proceedings.neurips.cc/paper/2020/file/9cd013fe250ebffc853b386569ab18c0-Paper.pdf,"To the best of our knowledge, the approaches discussed in this paper raise no major ethical concerns and societal consequences. Researchers and practitioners from the recommender system domain may benefit from our research since robust offline learning and evaluation has been a significant challenge in real-world applications. The worst possible outcome when the proposed approach fails is that it reduces to the standard offline learning as the propensity model stops making the desired impact. Finally, the proposed approach aims at solving the identifiability issues of the data, the extent of which depends on the properties of the data.",Broader Impact,98,4,,,FALSE,FALSE,FALSE,Adversarial Counterfactual Learning and Evaluation for Recommender System,Applications -> Recommender Systems,Applications -> Information Retrieval,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Da Xu', ' Chuanwei Ruan', ' Evren Korpeoglu', ' Sushant Kumar', ' Kannan Achan']",{'Walmart Labs'},0,1,0,{'USA'}
Memory-Efficient Learning of Stable Linear Dynamical Systems for Prediction and Control,"Georgios Mamakoukas, Orest Xherija, Todd Murphey",Memory-Efficient Learning of Stable Linear Dynamical Systems for Prediction and Control,9cd78264cf2cd821ba651485c111a29a,https://proceedings.neurips.cc/paper/2020/file/9cd78264cf2cd821ba651485c111a29a-Paper.pdf,"Our methods can improve robotic tasks that are safety-critical, particularly those that include a human-in-the-loop (such as rehabilitation devices and prosthetics) where the human-robot interaction dynamics are not known ahead of time. For such tasks, a robotic platform prioritizes stability and safety during operation. Unstable data-driven models may lead to catastrophic robotic behavior, as we demonstrate in our simulations with the Franka Emika Panda robotic arm. Our work provides a mechanism for online learning of models that satisfy stability constraints, improving the safety and reliability of closed-loop control of those systems.",Broader Impact,91,4,,,FALSE,FALSE,FALSE,Memory-Efficient Learning of Stable Linear Dynamical Systems for Prediction and Control,Applications -> Robotics,Algorithms; Algorithms -> Dynamical Systems; Optimization -> Non-Convex Optimization; Theory -> Data-driven Algorithm Design,Optimization Methods (continuous or discrete),,"{'University of Chicago', 'Northwestern University'}",1,0,0,{'USA'}
Evolving Normalization-Activation Layers,"Hanxiao Liu, Andy Brock, Karen Simonyan, Quoc Le",Evolving Normalization-Activation Layers,9d4c03631b8b0c85ae08bf05eda37d0f,https://proceedings.neurips.cc/paper/2020/file/9d4c03631b8b0c85ae08bf05eda37d0f-Paper.pdf,"Since normalization-activation layers are critical components in state-of-the-art neural networks, we expect that the discovered modules to benefit a wide range of deep learning applications and yield positive impacts on healthcare, autonomous driving, manufacturing, agriculture and more. Insights derived from these layers may also deepen the community’s understanding about the optimization properties of neural networks hence result in theoretical advancements. The proposed layer search method can be used as a tool to discover new fundamental building blocks besides normalization- activation layers, accelerating scientific discovery about novel machine learning concepts in general. On the negative side, the layer search process requires a relatively large number of CPU cores hence may lead to increased carbon footprint over the manual approaches.",Broader Impact,118,4,,,FALSE,FALSE,FALSE,Evolving Normalization-Activation Layers,Algorithms -> AutoML,Applications -> Computer Vision; Deep Learning,AutoML,"['Hanxiao Liu', ' Andy Brock', ' Karen Simonyan', ' Quoc V Le']","{'Google Brain', 'DeepMind', 'Google'}",0,1,0,"{'UK', 'USA'}"
ScaleCom: Scalable Sparsified Gradient Compression for Communication-Efficient Distributed Training,"Chia-Yu Chen, Jiamin Ni, Songtao Lu, Xiaodong Cui, Pin-Yu Chen, Xiao Sun, Naigang Wang, Swagath Venkataramani, Vijayalakshmi (Viji) Srinivasan, Wei Zhang, Kailash Gopalakrishnan",ScaleCom: Scalable Sparsified Gradient Compression for Communication-Efficient Distributed Training,9d58963592071dbf38a0fa114269959c,https://proceedings.neurips.cc/paper/2020/file/9d58963592071dbf38a0fa114269959c-Paper.pdf,"The amount of compute for DNNs training doubles every 3 to 4 months [41]; this is faster than Moore’s law that doubles the number of transistors every 2 years. The latest language model GPT3 [42] takes 175 billion parameters to achieve state of the art performance on several NLP tasks such as common sense reasoning and word prediction. Training, designing, and optimizing these gigantic models require tremendous time (cost) and computation power. Our research results on compression in large-scale distributed training have two broad benefits: (i) Reducing time and cost to train DNN models: We believe that communication times will bottleneck training times of distributed systems and this will become even more severe with recent significant improvements in the computational capability of deep learning training hardware. To address this bottleneck, in the past few years, compression techniques have been eagerly researched and implemented in some practical training systems [43]. Our research results on scalability of gradient compression aim to push this to larger scale distributed training systems, which is needed for the training of expensive and powerful gigantic models. We believe that the scalable compression solution can accelerate machine learning research and save the cost for company and research institutes to develop state-of-art DNNs in real applications and complicated datasets. (ii) Energy consumption for environment concerns: Training DNNs especially for big models consumes tremendous energy and starts to cause concerns in CO 2 emission. As indicated in [44], Transformer training with neural architecture search could cause CO 2 emission as much as 5 cars’ lifetime. Today most DNNs training runs in distributed systems and energy is mainly consumed in data communication: 32-bit I/O communication took 3-4 orders of more energy (pJ) than 32-bit float ADD computation [45]. Thus, efficient communication is crucial to reduce energy consumption and mitigate concerns in carbon footprint of DNNs training, especially for large-scale distributed training of gigantic DNNs. Our research cuts communication data size by 65-400X and scale this method to larger scale distribution, which will reduce energy consumption and mitigate environment concerns in gigantic DNNs training. This helps to fight climate change and global warming. Meanwhile, we would like to point out, although our compression scheme guarantees theoretical convergence and shows no accuracy loss compared to baseline training over the tested models and applications, there could still be concerns about the impact of lossy gradient compression on neural network convergence performance. Especially when gradient compression is applied directly without fine tuning hyper-parameters, training could still be subject to instability, and thus it is recommended to examine the compression scheme over a wider range of models and applications. Our conservative compression selection rules (described in section 4) help mitigate this concern, however task-specific robustness studies are recommended for special applications.",Broader Impact,455,16,,,FALSE,FALSE,FALSE,ScaleCom: Scalable Sparsified Gradient Compression for Communication-Efficient Distributed Training,Deep Learning -> Efficient Training Methods,Algorithms -> Large Scale Learning; Applications -> Hardware and Systems,Deep learning,"['Yu Chen', ' Jiamin Ni', ' Songtao Lu', ' Xiaodong Cui', 'Yu Chen', ' Xiao Sun', ' Naigang Wang', ' Swagath Venkataramani', ' Vijayalakshmi', ' Srinivasan', ' Wei Zhang', ' Kailash Gopalakrishnan']","{'IBM Research AI', 'Viji', 'IBM research', 'IBM Research', 'IBM TJ Watson', 'IBM'}",0,1,0,{'USA'}
RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder,"Cheng Chi, Fangyun Wei, Han Hu",RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder,9d684c589d67031a627ad33d59db65e5,https://proceedings.neurips.cc/paper/2020/file/9d684c589d67031a627ad33d59db65e5-Paper.pdf,"This work aims for better object detection algorithms. Any object oriented visual applications may benefit from this work, as object detection is usually an indispensable component for them. There may be unpredictable failures, similar as most other detectors. The consequences of failures by this algorithm are determined on the down-stream applications, and please do not use it for scenarios where failures will lead to serious consequences. The method is data driven, and the performance may be affected by the biases in the data. So please also be careful about the data collection process when using it.",Broader Impact,96,6,,,FALSE,TRUE,FALSE,RelationNet++: Bridging Visual Representations for Object Detection via Transformer Decoder,Applications -> Object Detection,,Vision,,"{'University of Chinese Academy of Sciences', 'Microsoft Research Asia'}",1,1,1,"{'USA', 'China'}"
Efficient Learning of Discrete Graphical Models,"Marc Vuffray, Sidhant Misra, Andrey Lokhov",Efficient Learning of Discrete Graphical Models,9d702ffd99ad9c70ac37e506facc8c38,https://proceedings.neurips.cc/paper/2020/file/9d702ffd99ad9c70ac37e506facc8c38-Paper.pdf,"We believe that this work, as presented here, does not present any foreseeable societal consequence.",Broader Impact,15,1,TRUE,FALSE,TRUE,TRUE,TRUE,Efficient Learning of Discrete Graphical Models,Probabilistic Methods -> Graphical Models,Algorithms -> Model Selection and Structure Learning,,"['Marc Vuffray', ' Sidhant Misra', ' Andrey Lokhov']","{'Los Alamos National Laboratory', 'LANL'}",1,0,0,{'USA'}
Near-Optimal SQ Lower Bounds for Agnostically Learning Halfspaces and ReLUs under Gaussian Marginals,"Ilias Diakonikolas, Daniel Kane, Nikos Zarifis",Near-Optimal SQ Lower Bounds for Agnostically Learning Halfspaces and ReLUs under Gaussian Marginals,9d7311ba459f9e45ed746755a32dcd11,https://proceedings.neurips.cc/paper/2020/file/9d7311ba459f9e45ed746755a32dcd11-Paper.pdf,"Our work fits within the broader agenda of supervised learning in the presence of adversarial label noise. Specifically, we explore the fundamental computational limitations of learning halfspaces with label noise, even under very benign distributional assumptions. It has been a plausible conjecture that strong distributional assumptions make robust learning easy in practice. Understanding to what extent this may be true (or not), can have practical implications in the design of practical learners in such noisy environments. The primary focus of our work is theoretical and in particular we establish computational lower bounds. As such, we do not expect our results to have immediate societal impact. Nonetheless, we believe that our findings provide useful insights, as they suggest that state-of-the-art algorithms for the problem we study cannot be substantially improved.",Broader Impact,129,7,,,FALSE,FALSE,FALSE,Near-Optimal SQ Lower Bounds for Agnostically Learning Halfspaces and ReLUs under Gaussian Marginals,Theory -> Computational Learning Theory,,Theory (including computational and statistical analyses),"['Ilias Diakonikolas', ' Daniel Kane', ' Nikos Zarifis']","{'UW Madison', 'University of Wisconsin-Madison', 'UCSD'}",1,0,0,{'USA'}
Neurosymbolic Transformers for Multi-Agent Communication,"Jeevana Priya Inala, Yichen Yang, James Paulos, Yewen Pu, Osbert Bastani, Vijay Kumar, Martin Rinard, Armando Solar-Lezama",Neurosymbolic Transformers for Multi-Agent Communication,9d740bd0f36aaa312c8d504e28c42163,https://proceedings.neurips.cc/paper/2020/file/9d740bd0f36aaa312c8d504e28c42163-Paper.pdf,"Broadly speaking, reinforcement learning has the promise to significantly improve the usability of robotics in open-world settings. Our work focuses on leveraging reinforcement learning to help solve complex decentralized multi-agent planning problems, specifically by helping automate the design of communication policies that account for computational and bandwidth constraints. Solutions to these problems have a wide range of applications, both ones with positive societal impact—e.g., search and rescue, disaster response, transportation, agriculture, and constructions—and ones with controversial or negative impact—e.g., surveillance and military. These applications are broadly true of any work that improves the capabilities of multi-agent systems such as self-driving cars or drones. Restricting the capabilities of these systems based on ethical considerations is a key direction for future work. Beyond communication constraints, security and robustness are important requirements for multiagent systems. While we do not explicitly study these properties, a key advantage of reduced communication is to improve the resilience and robustness of the system and reduce the probability of failure, since there are fewer points of failure. Furthermore, communication policies that include  stochastic rules are typically more robust since they can replace a broken communication link with another randomly selected link without sacrificing performance. Furthermore, our research may have applications in other areas of machine learning. In general, there has been growing interest in learning programmatic representations to augment neural network models to improve interpretability, robustness, and generalizability. Along these dimensions, our work could potentially impact other applications such as NLP where transformers are state-of-the-art. In particular, our work takes a step in this direction by replacing soft attention weights in transformers with programmatic attention rules. The programmatic nature of these weights makes them much easier to interpret, as does the fact that the weights are hard rather than soft (since we now have a guarantee that parts of the input are irrelevant to the computation).",Broader Impact,308,13,,,FALSE,FALSE,FALSE,Neurosymbolic Transformers for Multi-Agent Communication,Reinforcement Learning and Planning -> Multi-Agent RL,Algorithms -> Program Induction,Multi-agent RL and Program induction,"['Jeevana Priya Inala', ' Yichen Yang', ' James Paulos', ' Yewen Pu', ' Osbert Bastani', ' Vijay Kumar', ' Martin Rinard', 'Lezama']","{'MIT', 'University of Pennsylvania', 'University of Pennysylvania'}",1,0,0,{'USA'}
Fairness in Streaming Submodular Maximization: Algorithms and Hardness,"Marwa El Halabi, Slobodan Mitrović, Ashkan Norouzi-Fard, Jakab Tardos, Jakub M. Tarnawski",Fairness in Streaming Submodular Maximization: Algorithms and Hardness,9d752cb08ef466fc480fba981cfa44a1,https://proceedings.neurips.cc/paper/2020/file/9d752cb08ef466fc480fba981cfa44a1-Paper.pdf,"Several recent studies have shown that automated data-driven methods can unintentionally lead to bias and discrimination [35, 56, 5, 10, 52]. Our proposed algorithms will help guard against these issues in data summarization tasks arising in various settings – from electing a parliament, over selecting individuals to influence for an outreach program, to selecting content in search engines and news feeds. As expected, fairness does come at the cost of a small loss in utility value, as observed in Section 6. It is worth noting that this “price of fairness” (i.e., the decrease in optimal objective value when fairness constraints are added) should not be interpreted as fairness leading to a less desirable outcome, but rather as a trade-off between two valuable metrics: the original application-dependent utility, and the fairness utility. Our algorithms ensure solutions achieving a close to optimal trade-off. Finally, despite the generality of the fairness notion we consider, it does not capture certain other notions of fairness considered in the literature (see e.g., [18, 58]). No universal metric of fairness exists. The question of which fairness notion to employ is an active area of research, and will be application dependent.",Broader Impact,193,8,,,FALSE,FALSE,FALSE,Fairness in Streaming Submodular Maximization: Algorithms and Hardness,Optimization -> Submodular Optimization,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Theory (including computational and statistical analyses),"['Marwa El Halabi', ' Slobodan Mitrović', 'Fard', ' Jakab Tardos', ' Jakub Tarnawski']","{'MIT', 'Google Research', 'Microsoft Research', 'EPFL'}",1,1,1,"{'USA', 'Switzerland'}"
Smoothed Geometry for Robust Attribution,"Zifan Wang, Haofan Wang, Shakul Ramkumar, Piotr Mardziel, Matt Fredrikson, Anupam Datta",Smoothed Geometry for Robust Attribution,9d94c8981a48d12adfeecfe1ae6e0ec1,https://proceedings.neurips.cc/paper/2020/file/9d94c8981a48d12adfeecfe1ae6e0ec1-Paper.pdf,"Our work is expected to have general positive broader impacts on the uses of machine learning in the broader society. Specifically, we are addressing the continual lack of transparency in deep learning and the potential of intentional abuse of systems employing deep learning. We hope that work such as ours will be used to build more trustworthy systems and make them more resilient to adversarial influence. As the impact of deep learning in general grows, so will the impact of transparency research such as ours. Depending on the use cases, such as work on algorithmic fairness, transparency tools such as hours can have positive impact on disadvantaged groups who either enjoy reduced benefits of machine learning or are susceptible to unfair decisioning from them. While any work in an adversarial setting can be misused as an instruction manual for defeating or subverting the proposed or similar methods, we believe the publication of the work is more directly useful in ways positive to the broader society.",Broader Impact,165,6,,,FALSE,TRUE,FALSE,Smoothed Geometry for Robust Attribution,"Deep Learning -> Visualization, Interpretability, and Explainability","Algorithms -> Adversarial Learning; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Deep learning,"['Zifan Wang', ' Haofan Wang', ' Shakul Ramkumar', ' Piotr Mardziel', ' Matt Fredrikson', ' Anupam Datta']","{'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Fast Adversarial Robustness Certification of Nearest Prototype Classifiers for Arbitrary Seminorms,"Sascha Saralajew, Lars Holdijk, Thomas Villmann",Fast Adversarial Robustness Certification of Nearest Prototype Classifiers for Arbitrary Seminorms,9da187a7a191431db943a9a5a6fec6f4,https://proceedings.neurips.cc/paper/2020/file/9da187a7a191431db943a9a5a6fec6f4-Paper.pdf,"With the more widespread application of machine learning methods in our everyday life, the potential negative impact of adversarial attacks on society increases. As discussed in the introduction, neither current empirical robustness methods nor certification or verification methods are sufficient to eliminate this problem. For applied machine learning research in medium to large companies, the current state-of-the-art methods for certifying or verifying adversarial robustness require a too large investment in compute time to truly incorporate the guaranteed robustness of a model as a formal requirement for the productization of machine learning. The theoretical robustness bound presented in this work can however be parallelized with the accuracy evaluation of a model and can therefore be easily incorporated in the already existing evaluation pipelines. With the upper bound on the robust test error calculable in constant time, it is even possible to incorporate the certification of an NPC as a metric in the training procedure—outputting the certified adversarial robustness after each epoch. A potential application of the reduced impact on inference time is also discussed in Section 5. Although deep neural networks frequently deliver excellent performances, the interpretability of those networks is difficult [69]. Recently, this has led to a wide line of research into the development of interpretable models, particularly for technical and medical applications [23, 24, 70, 71]. Having this in mind, the consideration of NPCs, as one of the most prominent interpretable paradigms [22], is of general interest. However, to ensure that interpretable models can be used without unwanted negative side effects, it is important to investigate their properties to the same extent as has been done for non-interpretable models. The investigation of the guaranteed adversarial robustness of NPCs is, therefore, a crucial step in this transition. In addition to this, the positive definiteness of norm-based distances can impose a significant restriction on the dissimilarity measure used in NPCs. By showing that this is not a requirement for constructing an adversarially robust NPC, this restriction is removed. Hence, more freedom is obtained in the selection of dissimilarity measures—for example, adaptive dissimilarity measures, as discussed in Section 6. This allows the application of NPCs as interpretable models in a wider variety of use cases. To summarize, we foresee two potential areas where the theoretical work presented here could have a direct and lasting impact on society. First, with the upper bound on the robust test error calculable in constant-time, the certification method presented here is more suitable for direct incorporation in the development of machine learning methods. This has been extensively discussed and evaluated in previous sections. Second, as a side effect, with NPCs now proven to be robust against adversarial attacks, they are better suited and more widely applicable as an interpretable alternative to NNs in real-world applications.",Broader impact,459,19,,,FALSE,FALSE,FALSE,Fast Adversarial Robustness Certification of Nearest Prototype Classifiers for Arbitrary Seminorms,Algorithms,Algorithms -> Adversarial Learning; Algorithms -> Classification; Algorithms -> Large Margin Methods; Algorithms -> Similarity and Distance Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Sascha Saralajew', ' Lars Holdijk', ' Thomas Villmann']","{'University of Amsterdam', 'University of Applied Sciences Mittweida'}",1,0,0,"{'Netherlands', 'Germany'}"
Multi-agent active perception with prediction rewards,"Mikko Lauri, Frans Oliehoek",Multi-agent active perception with prediction rewards,9db6faeef387dc789777227a8bed4d52,https://proceedings.neurips.cc/paper/2020/file/9db6faeef387dc789777227a8bed4d52-Paper.pdf,"This work is theoretical in nature, and therefore does not present any foreseeable societal consequence.",Broader Impact,15,1,TRUE,FALSE,FALSE,FALSE,FALSE,Multi-agent active perception with prediction rewards,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Planning,Reinforcement learning and planning,"['Mikko Lauri', ' Frans Oliehoek']","{'University of Hamburg', 'TU Delft'}",1,0,0,"{'Netherlands', 'Germany'}"
A Local Temporal Difference Code for Distributional Reinforcement Learning,"Pablo Tano, Peter Dayan, Alexandre Pouget",A Local Temporal Difference Code for Distributional Reinforcement Learning,9dd16e049becf4d5087c90a83fea403b,https://proceedings.neurips.cc/paper/2020/file/9dd16e049becf4d5087c90a83fea403b-Paper.pdf,"Understanding human decision-making in uncertain environments is critical not only for neuroscience and psychology but also to address economic, social and medical problems. In various such contexts, humans can benefit from recovering not only the probability distribution of possible events but also the specific times at which they are likely to occur. Here we propose a framework to solve this conundrum, showing how a distributional map of future events can be recovered from a simple extension of traditional reinforcement learning neural models.",8 Broader Impact,82,3,,,FALSE,FALSE,FALSE,A Local Temporal Difference Code for Distributional Reinforcement Learning,Neuroscience and Cognitive Science -> Human or Animal Learning,Neuroscience and Cognitive Science -> Neural Coding; Reinforcement Learning and Planning -> Reinforcement Learning,Neuroscience and cognitive science,"['Pablo Tano', ' Peter Dayan', ' Alexandre Pouget']","{'University of Geneva', 'Max Planck Institute for Biological Cybernetics'}",1,0,0,"{'Switzerland', 'Germany'}"
Learning with Optimized Random Features: Exponential Speedup by Quantum Machine Learning without Sparsity and Low-Rank Assumptions,"Hayata Yamasaki, Sathyawageeswar  Subramanian, Sho Sonoda, Masato Koashi",Learning with Optimized Random Features: Exponential Speedup by Quantum Machine Learning without Sparsity and Low-Rank Assumptions,9ddb9dd5d8aee9a76bf217a2a3c54833,https://proceedings.neurips.cc/paper/2020/file/9ddb9dd5d8aee9a76bf217a2a3c54833-Paper.pdf,"Quantum computation has recently been attracting growing attentions owing to its potential for achieving computational speedups compared to any conventional classical computation that runs on existing computers, opening the new field of accelerating machine learning tasks via quantum computation: quantum machine learning . To attain a large quantum speedup, however, existing algorithms for quantum machine learning require extreme assumptions on sparsity and low rank of matrices used in the algorithms, which limit applicability of the quantum computation to machine learning tasks. In contrast, the novelty of this research is to achieve an exponential speedup in quantum machine learning without the sparsity and low-rank assumptions, broadening the applicability of quantum machine learning. Advantageously, our quantum algorithm eliminates the computational bottleneck faced by a class of existing classical algorithms for scaling up kernel-based learning algorithms by means of random features. In particular, using this quantum algorithm, we can achieve the learning with the nearly optimal number of features, whereas this optimization has been hard to realize due to the bottleneck in the existing classical algorithms. A drawback of our quantum algorithm may arise from the fact that we use powerful quantum subroutines for achieving the large speedup, and these subroutines are hard to implement on existing or near-term quantum devices that cannot achieve universal quantum computation due to noise. At the same time, these subroutines make our quantum algorithm hard to simulate by classical computation, from which stems the computational advantage of our quantum algorithm over the existing classical algorithms. Thus, our results open a route to a widely applicable framework of kernel-based quantum machine learning with an exponential speedup, leading to a promising candidate of “killer applications” of universal quantum computers.",Broader Impact,280,8,,,FALSE,FALSE,FALSE,Learning with Optimized Random Features: Exponential Speedup by Quantum Machine Learning without Sparsity and Low-Rank Assumptions,Applications -> Quantum Learning,Algorithms -> Kernel Methods; Theory -> Computational Learning Theory,"Quantum machine learning, theory, supervised learning, computational complexity","['Hayata Yamasaki', ' Sathyawageeswar Subramanian', ' Sho Sonoda', ' Masato Koashi']","{'University of Cambridge', 'RIKEN AIP', 'The University of Tokyo'}",1,0,0,"{'Japan', 'UK'}"
CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations,"Davis Rempe, Tolga Birdal, Yongheng Zhao, Zan Gojcic, Srinath Sridhar, Leonidas J. Guibas",CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations,9de6d14fff9806d4bcd1ef555be766cd,https://proceedings.neurips.cc/paper/2020/file/9de6d14fff9806d4bcd1ef555be766cd-Paper.pdf,"CaSPR is a fundamental technology allowing the aggregation and propagation of dynamic point cloud information – and as such it has broad applications in areas like autonomous driving, robotics, virtual/augmented reality and medical imaging. We believe that our approach will have a mostly positive impact but we also identify potential undesired consequences below. Our method will enhance the capabilities of existing sensors and allow us to build models of objects from sparse observations. For instance, in autonomous driving or mixed reality, commonly used LIDAR/depth sensors are limited in terms of spatial and temporal resolution or sampling patterns. Our method creates representations that overcome these limitations due to the capability to continuously sample in space and time. This would enable these sensors to be cheaper and operate at lower spacetime resolutions saving energy and extending hardware lifespans. Our approach could also be useful in spatiotemporal information propagation. We can propagate sparse labels in the input over spacetime, leading to denser supervision. This would save manual human labeling effort. Like other learning-based methods, CaSPR can produce biased results missing the details in the input. In a self driving scenario, if an input LIDAR point cloud only partially observes a pedestrian, CaSPR may learn representations that misses the pedestrian completely. If real-world systems rely excessively on this incorrect representation it could lead to injuries or fatalities. We look forward to conducting and fostering more research in other applications and negative impacts of our work.",Broader Impact,241,13,,,FALSE,FALSE,FALSE,CaSPR: Learning Canonical Spatiotemporal Point Cloud Representations,Applications -> Computer Vision,Applications -> Visual Scene Analysis and Interpretation,Vision,"['Davis Rempe', ' Tolga Birdal', ' Yongheng Zhao', ' Zan Gojcic', ' Srinath Sridhar', ' Leonidas J Guibas']","{'Stanford University', 'University of Padova', 'ETH Zürich', 'Technical University of Munich'}",1,0,0,"{'Italy', 'USA', 'Switzerland', 'Germany'}"
Deep Automodulators,"Ari Heljakka, Yuxin Hou, Juho Kannala, Arno Solin",Deep Automodulators,9df81829c4ebc9c427b9afe0438dce5a,https://proceedings.neurips.cc/paper/2020/file/9df81829c4ebc9c427b9afe0438dce5a-Paper.pdf,"The presented line of work intends to shift the focus of generative models from random sample generation towards controlled semantic editing of existing inputs. In essence, the ultimate goal is to offer ‘knobs’ that allow content editing based on high-level features, and retrieving and combining desired characteristics based on examples. While we only consider images, the techniques can be extended to other data domains such as graphs and 3D structures. Ultimately, such research could reduce very complex design tasks into approachable ones and thus reduce dependency on experts. For instance, contrast an expert user of a photo editor or design software, carefully tuning details, with a layperson who simply finds images or designs with the desired characteristics and guiding the smart editor to selectively combine them.  Leveling the playing field in such tasks will empower larger numbers of people to contribute to design, engineering and science, while also multiplying the effectiveness of the experts. The downside of such empowerment will, of course, include the threats of deepfakes and spread of misinformation. Fortunately, public awareness of these abuses has been increasing rapidly. We attempt to convey the productive prospects of these technologies by also including image data sets with cars and bedrooms, while comparison with prior work motivates the focus on face images.",Broader Impact,212,9,,,TRUE,TRUE,FALSE,Deep Automodulators,Deep Learning -> Deep Autoencoders,Deep Learning -> Generative Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Ari Heljakka', ' Yuxin Hou', ' Juho Kannala', ' Arno Solin']",{'Aalto University'},1,0,0,{'Finland'}
Convolutional Tensor-Train LSTM for Spatio-Temporal Learning,"Jiahao Su, Wonmin Byeon, Jean Kossaifi, Furong Huang, Jan Kautz, Anima Anandkumar",Convolutional Tensor-Train LSTM for Spatio-Temporal Learning,9e1a36515d6704d7eb7a30d783400e5d,https://proceedings.neurips.cc/paper/2020/file/9e1a36515d6704d7eb7a30d783400e5d-Paper.pdf,"In this paper, the authors introduce Convolutional Tensor-Train LSTM model for spatio-temporal learning. Our model can be applied to any spatio-temporal data, e.g., physical system simulation and video understanding. For physical system simulation, our model could be used in weather or turbulence prediction, where no simple physics rule can be used to anticipate the future. The potential in these applications could reduce loss by extreme weathers, and the chance of aircraft encountering violent turbulence. For video understanding, our model can be applied to a wide range of applications including autonomous driving, robot control, human behavior analysis and object tracking. While these applications greatly relieve humans from tedious and repeat laboring, they have raised questions in the society. For example, (1) faulty predictions in autonomous driving systems - do we have safeguards in place? (2) human tracking and behavior analysis - are we protecting privacy? (3) finally, object tracking - how are we regulating? Therefore, it is crucial to consider whether the technology could be misused before they are deployed, and what needs to be in place to avoid an undesired consequence. We suggest the researcher in physical sciences and social sciences to investigate questions such as: • Can a machine learning approach simulate a physical system given sufficient data? If not, to what extent the physical system can be learned? • How to systematically verify the capacity of a machine learning model, such that certain behavior can be prohibited before deployment? • How to define the responsibility if an autonomous system produces an undesired outcome (for example, car crash and personal information leakage)?",Impact Statement,263,14,,,FALSE,TRUE,FALSE,Convolutional Tensor-Train LSTM for Spatio-Temporal Learning,Deep Learning,Applications -> Matrix and Tensor Factorization; Deep Learning -> Recurrent Networks,Deep learning,"['Jiahao Su', ' Wonmin Byeon', ' Jean Kossaifi', ' Furong Huang', ' Jan Kautz', ' Anima Anandkumar']","{'NVIDIA / Caltech', 'NVIDIA Research', 'University of Maryland', 'NVIDIA'}",1,1,1,{'USA'}
The Potts-Ising model for discrete multivariate data,"Zahra Razaee, Arash Amini",The Potts-Ising model for discrete multivariate data,9e5f64cde99af96fdca0e02a3d24faec,https://proceedings.neurips.cc/paper/2020/file/9e5f64cde99af96fdca0e02a3d24faec-Paper.pdf,"In cancer clinical trials, patients are assigned to different treatment groups, and for each patient, toxicities are collected. These toxicities are graded, high-dimensional and correlated. Patient reported outcome questionnaires also collect patients’ responses to quality of life questions on a Likert-type scale after treatments. It is crucial to correctly model these kind of data and estimate the main effects as well as the association between the toxicities, in order to determine the tolerability of treatments and their impact on patients quality of life. Our Potts-Ising model is a suitable such model designed for the toxicity data, but applicable far beyond it to any survey and rating data with limited range, as well as, sparse count data.",5 Broader Impact,116,5,,,FALSE,TRUE,FALSE,The Potts-Ising model for discrete multivariate data,Probabilistic Methods -> Graphical Models,Algorithms -> Regression; Optimization -> Convex Optimization,Probabilistic methods and inference,"['Zahra Razaee', ' Arash Amini']","{'UCLA', 'Cedars Sinai'}",1,0,0,{'USA'}
Interpretable multi-timescale models for predicting fMRI responses to continuous natural speech,"Shailee Jain, Vy Vo, Shivangi Mahto, Amanda LeBel, Javier S. Turek, Alexander Huth",Interpretable multi-timescale models for predicting fMRI responses to continuous natural speech,9e9a30b74c49d07d8150c8c83b1ccf07,https://proceedings.neurips.cc/paper/2020/file/9e9a30b74c49d07d8150c8c83b1ccf07-Paper.pdf,"Researchers working to understand temporal phenomena may consider the problems raised in this work, and may find the proposed methods useful for their analysis. More importantly, this work is a stepping stone towards building better models for language processing in the brain that can not only help investigate cortical language processing but also simulate brain responses. This could be useful for diagnosing, treating, and assisting people with language deficits like aphasia, especially since  processing information at different timescales is critical to human language. On the contrary, these tools may also serve as a stepping stone toward unethical brain decoding practices that could be used by, for example, insurance companies or attorneys for erroneous evidence collection on a trial. In general, advances in brain-reading technology may raise issues in neuroethics, especially regarding mental privacy. Negative consequences from this research may affect the participants themselves. The fMRI data for this work was acquired in accordance with IRB protocols, which included informed consent of the risks involved with MRI. In addition to physical risks, such as peripheral nerve stimulation, participants were informed about the steps taken to protect their data. While personal identifying information about participants is stored in a physical, locked, separate location from the neuroimaging data, a failure in this system could potentially lead to a breach of confidentiality. As with much of the research submitted to NeurIPS, training neural network models consumes large amounts of energy. If this energy was generated by non-renewable fuel, this would have a negative impact on the environment.",Broader Impact,253,11,,,FALSE,FALSE,FALSE,Interpretable multi-timescale models for predicting fMRI responses to continuous natural speech,Neuroscience and Cognitive Science -> Brain Mapping,Applications -> Natural Language Processing; Neuroscience and Cognitive Science -> Brain Imaging; Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and cognitive science,"['Shailee Jain', ' Vy Vo', ' Shivangi Mahto', ' Amanda LeBel', ' Javier Turek', ' Alexander Huth']","{'Intel Corporation', 'The University of Texas at Austin', 'Intel Labs'}",1,1,1,{'USA'}
Group-Fair Online Allocation in Continuous Time,"Semih Cayci, Swati Gupta, Atilla Eryilmaz",Group-Fair Online Allocation in Continuous Time,9ec0cfdc84044494e10582436e013e64,https://proceedings.neurips.cc/paper/2020/file/9ec0cfdc84044494e10582436e013e64-Paper.pdf,"Our work develops the theory of fair online learning, specifically analyzing the impact of reward- maximizing allocation policies on opportunities for different groups of people. Our proposal analyzes the trade-offs across various allocation policies (ranging from profit maximizing to equal opportunity for all), thus highlighting the choice of objectives that the controllers should carefully consider. This work does not have any foreseeable negative ethical or societal impact.",Broader Impact,67,3,FALSE,FALSE,FALSE,FALSE,FALSE,Group-Fair Online Allocation in Continuous Time,Algorithms -> Online Learning,"Algorithms -> Bandit Algorithms; Algorithms -> Stochastic Methods; Optimization -> Stochastic Optimization; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency; Theory -> Control Theory; Theory -> Data-driven Algorithm Design","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Semih Cayci', ' Swati Gupta', ' Atilla Eryilmaz']","{'The Ohio State University', 'Georgia Institute of Technology'}",1,0,0,{'USA'}
Decentralized TD Tracking with Linear Function Approximation and its Finite-Time Analysis,"Gang Wang, Songtao Lu, Georgios Giannakis, Gerald Tesauro, Jian Sun",Decentralized TD Tracking with Linear Function Approximation and its Finite-Time Analysis,9ec51f6eb240fb631a35864e13737bca,https://proceedings.neurips.cc/paper/2020/file/9ec51f6eb240fb631a35864e13737bca-Paper.pdf,"In its core, this work contributes to the development and performance analysis of DTDT, a faster multiagent reinforcement learning (MARL) algorithm for policy evaluation. Given the documented success of MARL in diverse challenging applications such as artificial intelligence [23], quantum computing [24], healthcare [12], cyber-physical systems [40], and drug design [25], the novel tools will also have major impact in several science and engineering fields, including control, communications and networking, robotics, transportation, neuroscience, as well as medicine and finance. The developed algorithms and tools will thus enable technology transfer to benefit a wide population and improve healthcare and autonomous driving. Taking the pandemic control of COVID-19 as an example, the proposed DTDT technique can be used to provide faster and more accurate outbreak response policies to curb the virus spread in the long term with the least disruption to the economic activity. Although it is capable of boosting the public health, the current approach may lead to several negative consequences due e.g., to privacy disclosure, data leakage, as well as lack of adversarial robustness and fairness guarantees.",Broader impact,177,5,,,FALSE,FALSE,FALSE,Decentralized TD Tracking with Linear Function Approximation and its Finite-Time Analysis,Reinforcement Learning and Planning -> Multi-Agent RL,Optimization -> Stochastic Optimization; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Gang Wang', ' Songtao Lu', ' Georgios Giannakis', ' Gerald Tesauro', ' Jian Sun']","{'University of Minnesota', 'IBM TJ Watson Research Center', 'Beijing Institute of Technology', 'Beijing Insitute of Technology', 'IBM Research'}",1,1,1,"{'USA', 'China'}"
Understanding Gradient Clipping in Private SGD: A Geometric Perspective,"Xiangyi Chen, Steven Z. Wu, Mingyi Hong",Understanding Gradient Clipping in Private SGD: A Geometric Perspective,9ecff5455677b38d19f49ce658ef0608,https://proceedings.neurips.cc/paper/2020/file/9ecff5455677b38d19f49ce658ef0608-Paper.pdf,"This paper aims to bridge the theory and practice of a commonly used privacy-preserving learning algorithm—differentially private SGD (DP-SGD). Our results provide theoretical understandings on the gradient clipping effects on the convergence behavior of the algorithm, which can further inform practical tuning of this important hyperparameter. As deep learning on sensitive data becomes increasingly common, our work provides theoretical insights for practitioners to perform reliable privacy-preserving machine learning.",7 Broader Impacts,68,3,,,FALSE,FALSE,FALSE,Understanding Gradient Clipping in Private SGD: A Geometric Perspective,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Optimization -> Stochastic Optimization; Theory -> Statistical Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Xiangyi Chen', ' Steven Wu', ' Mingyi Hong']","{'University of Minnesota', 'Carnegie Mellon University'}",1,0,0,{'USA'}
O(n) Connections are Expressive Enough: Universal Approximability of Sparse Transformers,"Chulhee Yun, Yin-Wen Chang, Srinadh Bhojanapalli, Ankit Singh Rawat, Sashank Reddi, Sanjiv Kumar",O ( n ) Connections are Expressive Enough: Universal Approximability of Sparse Transformers,9ed27554c893b5bad850a422c3538c15,https://proceedings.neurips.cc/paper/2020/file/9ed27554c893b5bad850a422c3538c15-Paper.pdf,"This work studies theoretical aspects of a class of widely used neural network models in NLP and related areas. Since we do not propose a new method nor a new dataset, we expect that the impact of this work on ethical aspects and future societal consequences will be small, if any. Other than that, this work brings new insights into the sparsity in attention models, hence may make an impact on the study of faster and more efficient NLP models.",Broader Impact,80,3,,,FALSE,FALSE,FALSE,O(n) Connections are Expressive Enough: Universal Approximability of Sparse Transformers,Deep Learning -> Analysis and Understanding of Deep Networks,Deep Learning -> Attention Models,Theory (including computational and statistical analyses),"['Chulhee Yun', 'Wen Chang', ' Srinadh Bhojanapalli', ' Ankit Singh Rawat', ' Sashank Reddi', ' Sanjiv Kumar']","{'Google', 'MIT', 'Google AI', 'Google Research'}",1,1,1,{'USA'}
Identifying signal and noise structure in neural population activity with Gaussian process factor models,"Stephen Keeley, Mikio Aoi, Yiyi Yu, Spencer Smith, Jonathan W. Pillow",Identifying signal and noise structure in neural population activity with Gaussian process factor models,9eed867b73ab1eab60583c9d4a789b1b,https://proceedings.neurips.cc/paper/2020/file/9eed867b73ab1eab60583c9d4a789b1b-Paper.pdf,"Here, we propose a new model for neuroscientists to uncover latent structure in trial-based neural population data. Trial-based neural recordings with identical stimuli are ubiquitous in neuroscience research. However, trial-by-trial variability in neural activity is not well understood. More broadly, it is unclear in general what the function of neural noise is in the brain. Our model works on neural population data to separate out neural noise latent representations from stimulus-locked representations. It additionally uses a novel inference technique that is rapid and stable. Here, we provide a general, easy-to-use tool for neuroscientists, and we hope others are encouraged to employ it to understand trial-based neural information in their own experimental set-up. We provide code for download here: https://github.com/skeeley/SNP_GPFA . We do not foresee any negative consequences to society resulting from this work.",Broader Impact,133,9,,,FALSE,FALSE,FALSE,Identifying signal and noise structure in neural population activity with Gaussian process factor models,Neuroscience and Cognitive Science,Neuroscience and Cognitive Science -> Neural Coding; Probabilistic Methods -> Gaussian Processes; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,Neuroscience and cognitive science,"['Stephen Keeley', ' Mikio Aoi', ' Yiyi Yu', ' Spencer Smith', ' Jonathan W Pillow']","{'UC Santa Barbara', 'Princeton University', 'UNC'}",1,0,0,"{'Canada', 'USA'}"
Equivariant Networks for Hierarchical Structures,"Renhao Wang, Marjan Albooyeh, Siamak Ravanbakhsh",Equivariant Maps for Hierarchical Structures,9efb1a59d7b58e69996cf0e32cb71098,https://proceedings.neurips.cc/paper/2020/file/9efb1a59d7b58e69996cf0e32cb71098-Paper.pdf,"As deep learning finds its way in various real-world applications, the practitioners are finding more constrains in representing their data in formats and structures amenable to existing deep architectures. The list of basic structures such as images, sets, and graphs that we can approach using deep models has been growing over the past few years. The theoretical contribution of this paper substantially expands this list by enabling deep learning on a hierarchy of structures. This could potentially unlock new applications in data-poor and structure-rich settings. The task we consider in our experiments is deep learning with large point-cloud data, which is finding growing applications, from autonomous vehicles to geographical surveys. While this is not a new task, our empirical results demonstrate the effectiveness of the proposed methodology in dealing with hierarchy in data structure.",Broader Impact,134,6,,,FALSE,FALSE,FALSE,Equivariant Networks for Hierarchical Structures,Algorithms -> Representation Learning,Deep Learning -> CNN Architectures; Deep Learning -> Supervised Deep Networks,,"['Renhao Wang', ' Marjan Albooyeh', ' Siamak Ravanbakhsh']","{'McGill / MILA', 'University of British Columbia'}",1,0,0,{'Canada'}
"MinMax Methods for Optimal Transport and Beyond: Regularization, Approximation and Numerics","Luca De Gennaro Aquino, Stephan Eckstein","MinMax Methods for Optimal Transport and Beyond: Regularization, Approximation and Numerics",9f067d8d6df2d4b8c64fb4c084d6c208,https://proceedings.neurips.cc/paper/2020/file/9f067d8d6df2d4b8c64fb4c084d6c208-Paper.pdf,"In this paper, we formally provide justification for utilizing neural networks when solving a frequently used class of optimization problems. We believe that our results can function as theoretical and practical guidelines for researchers (and practitioners) who are interested in exploring possible applications of optimal transport and related frameworks utilizing MinMax methods. However, it is important to emphasize that, generally speaking, theoretical insights might still be restricted by numerical convergence, thus we do not encourage overconfidence in the solution methods when resorting to neural networks. Nonetheless, we do not expect our work to feasibly induce any disadvantage for any group of people, nor that particular consequences for the failure of the proposed optimization methods might occur.",Broader Impact,116,4,,,FALSE,FALSE,FALSE,"MinMax Methods for Optimal Transport and Beyond: Regularization, Approximation and Numerics",Deep Learning -> Adversarial Networks,Algorithms -> Adversarial Learning; Algorithms -> Large Scale Learning; Algorithms -> Spectral Methods; Algorithms -> Stochastic Methods; Applications -> Quantitative Finance and Econometrics; Deep Learning -> Generative Models; Optimization -> Convex Optimization; Optimization -> Stochastic Optimization; Probabilistic Methods -> Latent Variable Models; Theory -> Hardness of Learning and Approximations; Theory -> Regularization,Optimization Methods (continuous or discrete),"['Luca De Gennaro Aquino', ' Stephan Eckstein']","{'Grenoble Ecole de Management', 'University of Konstanz'}",1,0,0,{'Germany'}
A Discrete Variational Recurrent Topic Model without the Reparametrization Trick,"Mehdi Rezaee, Francis Ferraro",A Discrete Variational Recurrent Topic Model without the Reparametrization Trick,9f1d5659d5880fb427f6e04ae500fc25,https://proceedings.neurips.cc/paper/2020/file/9f1d5659d5880fb427f6e04ae500fc25-Paper.pdf,"The model used in this paper is fundamentally an associative-based language model. While NVI does provide some degree of regularization, a significant component of the training criteria is still a cross-entropy loss. Further, this paper’s model does not examine adjusting this cross-entropy component. As such, the text the model is trained on can influence the types of implicit biases that are transmitted to the learned syntactic component (the RNN/representations ht), the learned thematic component (the topic matrix β and topic modeling variables θ and zt), and the tradeoff(s) between these two dynamics (lt and ρ). For comparability, this work used available datasets that have been previously published on. Based upon this work’s goals, there was not an in-depth exploration into any biases within those datasets. Note however that the thematic vs. non-thematic aspect of this work provides a potential avenue for examining this. While we treated lt as a binary indicator, future work could involve a more nuanced, gradient view. Direct interpretability of the individual components of the model is mixed. While the topic weights can clearly be inspected and analyzed directly, the same is not as easy for the RNN component. While lacking a direct way to inspect the overall decoding model, our approach does provide insight into the thematic component. We view the model as capturing thematic vs. non-thematic dynamics, though in keeping with previous work, for evaluation we approximated this with non-stopword vs. stopword dynamics. Within topic modeling stop-word handling is generally considered simply a preprocessing problem (or obviated by neural networks), we believe that preprocessing is an important element of a downstream user’s workflow that is not captured when preprocessing is treated as a stand-alone, perhaps boring step. We argue that future work can examine how different elements of a user’s workflow, such as preprocessing, can be handled with our approach.",Broader Impact,305,14,,,TRUE,TRUE,FALSE,A Discrete Variational Recurrent Topic Model without the Reparametrization Trick,Applications -> Natural Language Processing,Probabilistic Methods -> Topic Models; Probabilistic Methods -> Variational Inference,Natural language processing,"['Mohammad Mehdi Rezaee Taghiabadi', ' Francis Ferraro']","{'University of Maryland Baltimore County', 'university of maryland baltimore county'}",1,0,0,{'USA'}
Transferable Graph Optimizers for ML Compilers,"Yanqi Zhou, Sudip Roy,  Amirali  Abdolrashidi, Daniel Wong, Peter Ma, Qiumin Xu, Hanxiao Liu, Phitchaya  Phothilimtha, Shen Wang, Anna Goldie, Azalia Mirhoseini, James Laudon",Transferable Graph Optimizers for ML Compilers,9f29450d2eb58feb555078bdefe28aa5,https://proceedings.neurips.cc/paper/2020/file/9f29450d2eb58feb555078bdefe28aa5-Paper.pdf,"The increasing complexity and diversity of hardware accelerators has made the development of robust and adaptable ML frameworks onerous and time-consuming, often requiring multiple years of effort from hundreds of engineers. In this paper, we demonstrated that many of the optimization problems in such frameworks can be solved efficiently and optimally using a carefully designed learned approach. This has two significant benefits over a heuristic based hand-tuned approach. First, it can potentially save years worth of engineering effort needed to design and maintain the set of heuristics with each new generation of hardware. And second, the improved solutions found using a learned approach can have a multiplicative effect by improving hardware utilization and computational efficiency for all workloads. This increased efficiency may eventually lead to a reduction in the overall carbon footprint for many applications. We also want to highlight a broader effort in the community to use machine learning in the hardware design process[20]. The techniques presented in this paper can be instrumental in evaluating the behavior of benchmark workloads on new and unseen hardware architectures without requiring significant redesign of compilers. Therefore, we believe that the ideas introduced in this paper are an important step that can positively impact the larger ML for Systems research directions. One of the potential downside of the work is the loss of explainability for the choices made by the learned model. An advantage of heuristic based approaches deployed in current systems is the ability to explain the choices made by the algorithm based on the heuristics used. Often it is feasible to ""fix"" a poor decision by designing a customized heuristic. The current learned approaches to optimization problems including the ones presented in this paper do not lend themselves to explainable results. However, a principled approach to integrating domain specific knowledge of compiler developers with the learning based approach with the goal of improving explainability is an interesting direction for future research.",7 Broader Impact,320,14,,,FALSE,FALSE,FALSE,Transferable Graph Optimizers for ML Compilers,Applications -> Hardware and Systems,Algorithms -> AutoML; Algorithms -> Multitask and Transfer Learning; Deep Learning,ML for systems/ ML for compiler graph optimizations,"['Yanqi Zhou', ' Sudip Roy', ' Amirali Abdolrashidi', ' Daniel Wong', ' Peter Ma', ' Qiumin Xu', ' Hanxiao Liu', ' Phitchaya Phothilimtha', ' Shen Wang', ' Anna Goldie', ' Azalia Mirhoseini', ' James Laudon']","{'Google Inc', 'Google Brain', 'Carnegie Mellon University', 'Google', 'Google Brain / Stanford', 'UC Riverside'}",1,1,1,{'USA'}
Learning with Operator-valued Kernels in Reproducing Kernel Krein Spaces,"Akash Saha, Balamurugan Palaniappan",Learning with Operator-valued Kernels in Reproducing Kernel Krein Spaces,9f319422ca17b1082ea49820353f14ab,https://proceedings.neurips.cc/paper/2020/file/9f319422ca17b1082ea49820353f14ab-Paper.pdf,"The theoretical tools introduced in the paper for generalized operator valued kernels and function- valued Reproducing Kernel Krein Spaces (RKKS) are new and will promote research in investigating more sophisticated techniques for handling function data and other data with complicated structures. The proposed methods and algorithms have been applied on a speech inversion problem and accurate predictions of function-valued outputs in such applications might be useful for improving the current understanding of the speech generation process in humans. To the best of our knowledge, our work does not have any negative impact.",Broader Impact,92,3,,,FALSE,FALSE,FALSE,Learning with Operator-valued Kernels in Reproducing Kernel Krein Spaces,Algorithms -> Kernel Methods,Algorithms -> Regression; Theory -> Spaces of Functions and Kernels,Kernel Methods,"['Akash Saha', ' Balamurugan Palaniappan']",{'Indian Institute of Technology Bombay'},1,0,0,{'India'}
Learning Bounds for Risk-sensitive Learning,"Jaeho Lee, Sejun Park, Jinwoo Shin",Learning Bounds for Risk-sensitive Learning,9f60ab2b55468f104055b16df8f69e81,https://proceedings.neurips.cc/paper/2020/file/9f60ab2b55468f104055b16df8f69e81-Paper.pdf,"This paper is focused on the subject of risk-sensitivity , which is a topic that is deeply intertwined with the safety, reliability, and fairness of machine intelligence (see, e.g., [42]). While our primary aim is to enhance theoretical understandings on the risk-sensitive learning, instead of proposing a new algorithm, we expect our results to have two broader consequences. Facilitating algorithmic advances. For researchers trying to develop new risk-sensitive learning schemes, our general framework lowers the barrier to do so; we provide performance guarantees that applies for a broad class of algorithms that considers risk-seeking and risk-averse measures of loss (Theorems 4 and 7). Also, we provide a non-vacuous baseline to be compared with newly developed algorithms (Section 4). We believe that our theoretical framework will help stimulate further developments on risk-sensitive learning. Pondering on the cost of fairness. One of our theoretical results (Theorem 4) can be interpreted as a characterization of (an instance of) the cost of fairness [13, 15, 38]. Indeed, recalling that CVaR is a fairness risk measure with an individual fairness criterion [53], Theorem 4 implies that the performance gap may grow wider if we try to apply a stricter fairness criterion. Such quantification of the cost of making a fairer decision is a double-edged sword; the cost may scare the decision-maker away from taking the fairness into account at all, or the cost may guide the decision-maker to find a fairest solution under the operational constraints. We sincerely hope that the latter is the case. Indeed, we also provide a result (Theorem 7) that the drawback of making a fair decision may not be big for modern machine learning applications!",Broader impacts,275,12,,,FALSE,TRUE,FALSE,Learning Bounds for Risk-sensitive Learning,Theory -> Statistical Learning Theory,,Theory (including computational and statistical analyses),"['Jaeho Lee', ' Sejun Park', ' Jinwoo Shin']","{'University of Illinois at Urbana-Champaign', 'KAIST'}",1,0,0,"{'South Korea', 'USA'}"
Simplifying Hamiltonian and Lagrangian Neural Networks via Explicit Constraints,"Marc Finzi, Ke Alexander Wang, Andrew G. Wilson",Simplifying Hamiltonian and Lagrangian Neural Networks via Explicit Constraints,9f655cc8884fda7ad6d8a6fb15cc001e,https://proceedings.neurips.cc/paper/2020/file/9f655cc8884fda7ad6d8a6fb15cc001e-Paper.pdf,"Being able to model physical systems accurately has broad applications in robotics, model-based reinforcement learning, and data-driven control systems. A model that can learn the dynamics of arbitrary systems would greatly reduce the amount of expert-time needed to design safe and accurate controllers in a new environment. Although we believe that there are many advantages for using generic neural networks in robotics and control over traditional expert-in the-loop modeling and system identification, neural network models are harder to interpret and can lead to surprising and hard-to-understand failure cases. The adoption of neural network dynamics models in real world control and robotics systems will come with new challenges and may not be suitable for critical systems until we better understand their limitations.",9 Broader Impacts,121,4,,,TRUE,TRUE,FALSE,Simplifying Hamiltonian and Lagrangian Neural Networks via Explicit Constraints,Algorithms -> Dynamical Systems,Deep Learning -> Predictive Models,Deep learning,"['Marc Finzi', ' Ke Alexander Wang', ' Andrew Gordon Wilson']","{'New York University', 'Cornell University'}",1,0,0,{'USA'}
Beyond accuracy: quantifying trial-by-trial behaviour of CNNs and humans by measuring error consistency,"Robert Geirhos, Kristof Meding, Felix A. Wichmann",Beyond accuracy: quantifying trial-by-trial behaviour of CNNs and humans by measuring error consistency,9f6992966d4c363ea0162a056cb45fe5,https://proceedings.neurips.cc/paper/2020/file/9f6992966d4c363ea0162a056cb45fe5-Paper.pdf,"Error consistency is a statistical analysis for measuring whether two or more decision makers make similar errors. Like any statistical analysis, it can be used for better or worse. For instance, as a very simple example, calculating the mean of a number of observations can be used to quantify a world-wide temperature increase caused by human carbon emissions [ 61, 62] (positive impact). However, calculating the mean could just as well be utilised by authoritarian governments to obtain an aggregated credit score of “social”—i.e., conformist—behaviour (negative impact) [63]. Concerning error consistency, we could envisage the following broader impact. Potential positive impact. Quantifying differences between decision making strategies can con- tribute to a better understanding of algorithmic decisions. This improves model interpretability, which is a scientific goal by itself but also closely linked to societal requirements like accountability of algorithmic decision making and the “right to explanation” in the European Union [64]. Furthermore, calculating the error consistency between humans and CNNs can be used for fact-checking overly hyped “human-like AI” statements, e.g. by startups. We argue that human-level accuracy does not imply human-like decision making, which might contribute to increased rigour in model evaluation. Potential negative impact. While not intended to cause any harm, quantifying differences between individuals can be used to identify group-conform and outlier behaviour. Furthermore, measuring error consistency between machines and humans might be used to quantify progress towards building machines that mimic human decision making on certain tasks. While this might sound exciting to a scientist, it very likely sounds a lot more frightening from the perspective of someone losing their job because a machine would then be capable of doing the same work more cheaply. Depending on the complexity of the task, this may not be a problem in the near future but, given current trends in the use of machine learning for automation, perhaps in the distant future.",Broader Impact,313,15,,,FALSE,FALSE,FALSE,Beyond accuracy: quantifying trial-by-trial behaviour of CNNs and humans by measuring error consistency,Neuroscience and Cognitive Science -> Visual Perception,Deep Learning -> Analysis and Understanding of Deep Networks; Neuroscience and Cognitive Science; Neuroscience and Cognitive Science -> Perception,Neuroscience and cognitive science,"['Robert Geirhos', ' Kristof Meding', ' Wichmann']",{'University of Tübingen'},1,0,0,{'Germany'}
Provably Efficient Reinforcement Learning with Kernel and Neural Function Approximations,"Zhuoran Yang, Chi Jin, Zhaoran Wang, Mengdi Wang, Michael Jordan",Provably Efficient Reinforcement Learning with Kernel and Neural Function Approximations,9fa04f87c9138de23e92582b4ce549ec,https://proceedings.neurips.cc/paper/2020/file/9fa04f87c9138de23e92582b4ce549ec-Paper.pdf,"This is a theoretical paper. We do not foresee our work directly having any societal consequences. However, reinforcement learning is a tool that is increasingly used in practical machine learning applications, especially in the setting where nonlinear function approximation is involved. Theoret- ical explorations related to reinforcement learning with function approximation may help provide frameworks through which to reason about, and design safer and more reliable practical systems.",Broader Impact,68,4,,,FALSE,FALSE,FALSE,On Function Approximation in Reinforcement Learning: Optimism in the Face of Large State Spaces,Reinforcement Learning and Planning -> Exploration,Reinforcement Learning and Planning -> Reinforcement Learning,,"['Zhuoran Yang', ' Chi Jin', ' Zhaoran Wang', ' Mengdi Wang', ' Michael Jordan']","{'Princeton', 'UC Berkeley', 'Princeton University', 'Northwestern University'}",1,0,0,{'USA'}
Constant-Expansion Suffices for Compressed Sensing with Generative Priors,"Constantinos Daskalakis, Dhruv Rohatgi, Emmanouil Zampetakis",Constant-Expansion Suffices for Compressed Sensing with Generative Priors,9fa83fec3cf3810e5680ed45f7124dce,https://proceedings.neurips.cc/paper/2020/file/9fa83fec3cf3810e5680ed45f7124dce-Paper.pdf,"Our main contributions are mathematical in nature. We establish the notion of pseudo-Lipschitzness , along with a concentration inequality for random pseudo-Lipschitz functions, and random matrices, and we use our results to further the theoretical understanding of the non-convex optimization landscape arising in compressed sensing with deep generative priors. We foresee applications of our theorems in probability theory, learning theory, as well as inverse optimization problems involving deep neural networks. That said, compressed sensing with deep generative priors is of practical relevance as well. As shown in recent work, in the low number of measurements regime, compressed sensing with a deep generative prior may significantly outperform compressed sensing with a sparsity assumption. We emphasize, however, that users of a deep generative prior in compressed sensing (or other inverse problems) should be cognizant of the risk that the prior may introduce bias in the reconstruction. Indeed, the deep generative model was trained on data which might be biased, and even if it is not biased the training of the deep generative model might have failed for statistical or optimization reasons, resulting in a biased trained model. So the reconstruction will only be as good as the deep generative model is, as the reconstructed signal is in the range of the deep generative model. To conclude, our contributions are methodological but a prime application of our techniques is to improve the understanding of optimization problems arising in inverse problems involving a deep generative model. The users of deep generative priors in practical scenarios must be careful about the potential biases that their priors introduce. Their provenance and quality must be understood.",Broader Impact,269,11,,,FALSE,FALSE,FALSE,Constant-Expansion Suffices for Compressed Sensing with Generative Priors,Algorithms -> Sparsity and Compressed Sensing,Algorithms -> Regression; Deep Learning -> Generative Models; Theory -> High-Dimensional Inference; Theory -> Large Deviations and Asymptotic Analysis,Theory (including computational and statistical analyses),"['Constantinos Daskalakis', ' Dhruv Rohatgi', ' Emmanouil Zampetakis']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
RANet: Region Attention Network for Semantic Segmentation,"Dingguo Shen, Yuanfeng Ji, Ping Li, Yi Wang, Di Lin",RANet: Region Attention Network for Semantic Segmentation,9fe8593a8a330607d76796b35c64c600,https://proceedings.neurips.cc/paper/2020/file/9fe8593a8a330607d76796b35c64c600-Paper.pdf,"Our approach can help to achieve rich scene information, based on the large-scale image data that have been capturing by the cameras. It boosts the development of the AI systems (e.g., autonomous vehicle, video surveillance and ) in many scenarios. One should be cautious of using the data source, which belongs to the official or private organization, for training our segmentation model. This may give rise to the infringement of privacy or economic interest. The problematic segmentation results may lead to the misleading information, which may be released to the public.",Broader Impact,91,5,,,FALSE,FALSE,FALSE,RANet: Region Attention Network for Semantic Segmentation,Applications -> Computer Vision,Applications -> Image Segmentation,Vision,"['Dingguo Shen', ' Yuanfeng Ji', ' Ping Li', ' Yi Wang', ' Di Lin']","{'City University of Hong Kong', 'Shenzhen University', 'Tianjin University', 'The Hong Kong Polytechnic University'}",1,0,0,{'China'}
"A random matrix analysis of random Fourier features: beyond the Gaussian kernel, a precise phase transition, and the corresponding double descent","Zhenyu Liao, Romain Couillet, Michael W. Mahoney","A random matrix analysis of random Fourier features: beyond the Gaussian kernel, a precise phase transition, and the corresponding double descent",a03fa30821986dff10fc66647c84c9c3,https://proceedings.neurips.cc/paper/2020/file/a03fa30821986dff10fc66647c84c9c3-Paper.pdf,"In this article, we provide theoretical assessment of the popular random Fourier features (RFFs), in the practical setting where n, p, N are all large and comparable. Asymptotic performance guarantees are provided for RFF ridge regression in this n, p, N → ∞ limit, as an important positive impact of this work on the development of more reliable large-scale machine learning systems. The theoretical framework developed in this article presents fair and non-offensive societal consequence.",Broader Impact,75,3,FALSE,TRUE,TRUE,TRUE,FALSE,"A random matrix analysis of random Fourier features: beyond the Gaussian kernel, a precise phase transition, and the corresponding double descent",Theory,Algorithms -> Kernel Methods; Theory -> Large Deviations and Asymptotic Analysis; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Zhenyu Liao', ' Romain Couillet', ' Michael W Mahoney']","{'UC Berkeley', 'University of California, Berkeley', 'Université Grenoble Alpes'}",1,0,0,"{'France', 'USA'}"
Learning sparse codes from compressed representations with biologically plausible local wiring constraints,"Kion Fallah, Adam Willats, Ninghao Liu, Christopher Rozell",Learning sparse codes from compressed representations with biologically plausible local wiring constraints,a03fec24df877cc65c037673397ad5c0,https://proceedings.neurips.cc/paper/2020/file/a03fec24df877cc65c037673397ad5c0-Paper.pdf,"This paper presents a theoretical neuroscience model that aims to help improve our understanding of neural coding in biological sensory systems. While this may eventually have secondary effects as inspiration for machine learning systems, the current result is general and theoretical enough that we do not foresee particular applications or negative societal consequences. The images used in the experiments of this paper were the same as those used in previous work on sparse coding [50].",Broader Impact,75,3,,,FALSE,FALSE,FALSE,Learning sparse codes from compressed representations with biologically plausible local wiring constraints,Neuroscience and Cognitive Science -> Neural Coding,,Neuroscience and cognitive science,"['Kion Fallah', ' Adam A Willats', ' Ninghao Liu', ' Christopher Rozell']","{'Georgia Institute of Technology', 'Georgia Institute of Technology and Emory University'}",1,0,0,{'USA'}
Self-Imitation Learning via Generalized Lower Bound Q-learning,Yunhao Tang,Self-Imitation Learning via Generalized Lower Bound Q-learning,a0443c8c8c3372d662e9173c18faaa2c,https://proceedings.neurips.cc/paper/2020/file/a0443c8c8c3372d662e9173c18faaa2c-Paper.pdf,"Algorithms which learn from off-policy samples are critical for the applications of RL to more impactful real life domains such as autonomous driving and health care. Our work provides insights into SIL , and its close connections to popular off-policy learning techniques such as n -step Q-learning. We believe our work entails a positive step towards better understanding of efficient off-policy RL algorithms, which paves the way for future research into important applications.",8 Broader Impact,73,3,,,FALSE,FALSE,FALSE,Self-Imitation Learning via Generalized Lower Bound Q-learning,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,['Yunhao Tang'],{'Columbia University'},1,0,0,{'USA'}
Private Learning of Halfspaces: Simplifying the Construction and Reducing the Sample Complexity,"Haim Kaplan, Yishay Mansour, Uri Stemmer, Eliad Tsfadia",Private Learning of Halfspaces: Simplifying the Construction & Reducing the Sample Complexity,a08e32d2f9a8b78894d964ec7fd4172e,https://proceedings.neurips.cc/paper/2020/file/a08e32d2f9a8b78894d964ec7fd4172e-Paper.pdf,"In this work we develop algorithms that maintain the differential privacy of the samples. When the samples represent individuals, our work helps to maintain the privacy of those individuals.",Broader Impact,29,2,FALSE,FALSE,FALSE,FALSE,FALSE,Private Learning of Halfspaces: Simplifying the Construction and Reducing the Sample Complexity,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Theory -> Computational Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Haim Kaplan', ' Yishay Mansour', ' Uri Stemmer', ' Eliad Tsfadia']","{'TAU, GOOGLE', 'Tel Aviv University / Google', 'Tel Aviv University and Google', 'Ben-Gurion University'}",1,1,1,"{'USA', 'Israel'}"
Directional Pruning of Deep Neural Networks,"Shih-Kang Chao, Zhanyu Wang, Yue Xing, Guang Cheng",Directional Pruning of Deep Neural Networks,a09e75c5c86a7bf6582d2b4d75aad615,https://proceedings.neurips.cc/paper/2020/file/a09e75c5c86a7bf6582d2b4d75aad615-Paper.pdf,"Our paper belongs to the cluster of works focusing on efficient and resource-aware deep learning. There are numerous positive impacts of these works, including the reduction of memory footprint and computational time, so that deep neural networks can be deployed on devices equipped with less capable computing units, e.g. the microcontroller units. In addition, we help facilitate on-device deep learning, which could replace traditional cloud computation and foster the protection of privacy. Popularization of deep learning, which our research helps facilitate, may result in some negative societal consequences. For example, the unemployment may increase due to the increased automation enabled by the deep learning.",Broader Impact,104,5,,,FALSE,FALSE,FALSE,Directional Pruning of Deep Neural Networks,Deep Learning -> Efficient Training Methods,Deep Learning -> Efficient Inference Methods; Deep Learning -> Optimization for Deep Networks; Deep Learning -> Supervised Deep Networks,Deep learning,"['Kang Chao', ' Zhanyu Wang', ' Yue Xing', ' Guang Cheng']","{'University of Missouri', 'Purdue University'}",1,0,0,{'USA'}
Smoothly Bounding User Contributions in Differential Privacy,"Alessandro Epasto, Mohammad Mahdian, Jieming Mao, Vahab Mirrokni, Lijie Ren",Smoothly Bounding User Contributions in Differential Privacy,a0dc078ca0d99b5ebb465a9f1cad54ba,https://proceedings.neurips.cc/paper/2020/file/a0dc078ca0d99b5ebb465a9f1cad54ba-Paper.pdf,"Privacy is a fundamental concern in machine learning. Respecting the privacy of the users is a requirement of any real system and differential privacy allows to formalize such requirement. In this paper we provided algorithms with improved trade-offs of utility vs differential privacy. This may enable better outcomes for the users of a system at the same level of privacy. We stress that privacy is only one of the requirements of a real system. Any machine learning technology must also responsibly ensure utility of the system and fairness of the system to the users. Privacy requirements may negatively affect utility, and it is known that differential privacy potentially disparately impacts certain users [BPS19]. Such considerations are beyond the scope of the paper and we refer to the emerging literature on responsible machine learning for addressing them [KR19].",Broader Impact,137,8,,,FALSE,FALSE,FALSE,Smoothly Bounding User Contributions in Differential Privacy,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Regression,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Alessandro Epasto', ' Mohammad Mahdian', ' Jieming Mao', ' Vahab Mirrokni', ' Lijie Ren']","{'Google', 'Google Research', 'Google Research NYC'}",0,1,0,{'USA'}
Accelerating Training of Transformer-Based Language Models with Progressive Layer Dropping,"Minjia Zhang, Yuxiong He",Accelerating Training of Transformer-Based Language Models with Progressive Layer Dropping,a1140a3d0df1c81e24ae954d935e8926,https://proceedings.neurips.cc/paper/2020/file/a1140a3d0df1c81e24ae954d935e8926-Paper.pdf,"Pre-training large-scale language models like BERT have an incredible ability to extract textual information and apply to a variety of NLP tasks, but pre-training requires significant compute and time. Pre-training the BERT baseline model is typically done through hardware acceleration and scaling the training on 100s to 1000s of GPUs across multiple nodes. However, such a method is very costly and consumes magnitudes higher energy. The proposed solution achieves similar or better quality with shorter training time. It improves robustness to further reduce the hyperparameter tuning required, improving the productivity of AI scientists. It also saves hardware resources and trims down the total energy cost of in-situ, resource-constrained training, yielding a less amount of carbon footprint produced. Furthermore, the optimizations not only benefit BERT; they are also applicable to many other recent models such as RoBERTa [2], GPT-2 [9], XLNet [1], and UniLM [13], which all adopt Transformer as the backbone. Finally, our techniques can also help advance language understanding and inference, enabling enterprise or consumer-facing applications, such as conversational AI. We will open-source the code so that other practitioners and researchers can reproduce our results or re-use code into their ventures in this field. There are no apparent negative outcomes. However, like other AI technology, we should be mindful of using it to transform our systems to be more efficient in fulfilling goodwill.",Broader Impact,224,11,,,FALSE,TRUE,FALSE,Accelerating Training of Transformer-Based Language Models with Progressive Layer Dropping,Deep Learning -> Efficient Training Methods,Deep Learning -> Attention Models; Deep Learning -> Optimization for Deep Networks,,"['Minjia Zhang', ' Yuxiong He']",{'Microsoft'},0,1,0,{'USA'}
Online Planning with Lookahead Policies,"Yonathan Efroni, Mohammad Ghavamzadeh, Shie Mannor",Online Planning with Lookahead Policies,a18aa23ee676d7f5ffb34cf16df3e08c,https://proceedings.neurips.cc/paper/2020/file/a18aa23ee676d7f5ffb34cf16df3e08c-Paper.pdf,"Online planning algorithms, such as A* and RTDP, have been extensively studied and applied in AI for well over two decades. Our work quantifies the benefits of using lookahead-policies in this class of algorithms. Although lookahead-policies have also been widely used in online planning algorithms, their theoretical justification was lacking. Our study sheds light on the benefits of lookahead-policies. Moreover, the results we provide in this paper suggest improved ways for applying lookahead-policies in online planning with benefits when dealing with various types of approximations. This work opens up the room for practitioners to improve their algorithms and base lookahead policies on solid theoretical ground.",8 Broader Impact,105,6,,,TRUE,TRUE,FALSE,Online Planning with Lookahead Policies,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Planning,Reinforcement learning and planning,"['Yonathan Efroni', ' Mohammad Ghavamzadeh', ' Shie Mannor']","{'Technion', 'Google Research'}",1,1,1,"{'USA', 'Israel'}"
Learning Deep Attribution Priors Based On Prior Knowledge,"Ethan Weinberger, Joseph Janizek, Su-In Lee",Learning Deep Attribution Priors Based On Prior Knowledge,a19883fca95d0e5ec7ee6c94c6c32028,https://proceedings.neurips.cc/paper/2020/file/a19883fca95d0e5ec7ee6c94c6c32028-Paper.pdf,"DAPr can be applied to a wide variety of problems for which prior knowledge is available about a dataset’s individual features. In our work we focus on applying our method to a synthetic dataset and two real-world medical datasets, though it should be easily extendable to other problem domains. As discussed in the introduction, a major barrier to the adoption of modern machine learning tech- niques in real-world settings is that of trust . In high-stakes domains, such as medicine, practitioners are wary of replacing human judgement with that of black box algorithms, even if the black box consistently outperforms the human in controlled experiments. This concern is well-founded, as many high-performing systems developed in research environments have been found to overfit to quirks in a particular dataset, rather than learn more generalizable patterns. In our work we demonstrate that the DAPr framework does help deep networks generalize to our test sets when sample sizes are limited. While these results are encouraging, debugging model behavior in the real world, where data cannot simply be divided into training and test sets, is a more challenging problem. Feature attribution methods are one potential avenue for debugging models; however, while it may be easy to tell from a set of attributions if e.g. an image model is overfitting to noise, it would be much more difficult for a human to determine that a model trained on gene expression data was learning erroneous patterns simply by looking at attributions for individual genes. By learning to explain a given feature’s global importance using meta-features, we believe that DAPr can provide meaningful insights into model behavior that can help practitioners debug their models and potentially deploy them in real-world settings. Nevertheless, we recognize the potential downsides with the adoption of complex machine learning interpretability tools. Previous results have demonstrated that interpretability systems can in fact lead users to have too much trust in models when a healthy dose of skepticism would be more appropriate. More research is needed to understand how higher-order explanation tools like DAPr influence user behavior to determine directions for future work.",Broader Impact,349,12,,,FALSE,FALSE,FALSE,Learning Deep Attribution Priors Based On Prior Knowledge,"Deep Learning -> Visualization, Interpretability, and Explainability",Algorithms -> Few-Shot Learning; Applications -> Computational Biology and Bioinformatics,Deep learning,"['Ethan Weinberger', ' Joseph Janizek', 'In Lee']",{'University of Washington'},1,0,0,{'USA'}
Using noise to probe recurrent neural network structure and prune synapses,"Eli Moore, Rishidev Chaudhuri",Using noise to probe recurrent neural network structure and prune synapses,a1ada9947e0d683b4625f94c74104d73,https://proceedings.neurips.cc/paper/2020/file/a1ada9947e0d683b4625f94c74104d73-Paper.pdf,"While the larger question that motivates this study (how the brain might prune synapses) is of great practical interest, the results presented here are purely theoretical and quite abstract, and we do not foresee any immediate societal consequences or ethical issues.",Broader Impact,41,1,TRUE,FALSE,FALSE,FALSE,FALSE,Using noise to probe recurrent neural network structure and prune synapses,Neuroscience and Cognitive Science -> Plasticity and Adaptation,Algorithms -> Dynamical Systems; Algorithms -> Unsupervised Learning; Neuroscience and Cognitive Science,Neuroscience and cognitive science,"['Eli Moore', ' Rishidev Chaudhuri']","{'University of California, Davis'}",1,0,0,{'USA'}
NanoFlow: Scalable Normalizing Flows with Sublinear Parameter Complexity,"Sang-gil Lee, Sungwon Kim, Sungroh Yoon",NanoFlow: Scalable Normalizing Flows with Sublinear Parameter Complexity,a1c3ae6c49a89d92aef2d423dadb477f,https://proceedings.neurips.cc/paper/2020/file/a1c3ae6c49a89d92aef2d423dadb477f-Paper.pdf,"The main motivation of this study was to observe a major hurdle in incorporating a powerful generative capability of NFs to various application domains, where we need significantly larger neural network capacity to reach the desired level of performance. As our work would impact the practicality of NFs as a mainstream probabilistic toolkit, practitioners should be cautious about possible misrepresentations of our flow indication embedding methods depending on how one further augments the embedding to specific tasks of interest. In particular, although we demonstrated that our flow indication embedding is domain agnostic and independent variables, it is possible to incorporate task-specific priors into our framework, which can potentially achieve better control of the latent space. By contrast, there is a risk of potential misinterpretation of the embedding, together with the latent space, from biases inside the dataset. Because NFs have exact latent spaces that can be useful for downstream tasks such as facial manipulation [19], it would have a higher chance of direct exposure to various levels of biases. This could result in a potential exploitation of our embedding methods as an explainable or predictive embedding vector of the biased aspects that could be inherent in the data. Considering these possible directions for the downstream applications of NFs, one should be cautious about extrapolating our embedding scheme in attempts to build improved embedding methods for the target tasks, particularly when leveraging priors into the independent variables we demonstrated.",Broader Impact,238,7,,,FALSE,FALSE,FALSE,NanoFlow: Scalable Normalizing Flows with Sublinear Parameter Complexity,Deep Learning -> Generative Models,Algorithms -> Density Estimation,Probabilistic methods and inference,"['gil Lee', ' Sungwon Kim', ' Sungroh Yoon']",{'Seoul National University'},1,0,0,{'South Korea'}
Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge,"Chaoyang He, Murali Annavaram, Salman Avestimehr",Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge,a1d4c20b182ad7137ab3606f0e3fc8a4,https://proceedings.neurips.cc/paper/2020/file/a1d4c20b182ad7137ab3606f0e3fc8a4-Paper.pdf,"FedGKT can efficiently train large deep neural networks (CNNs) in resource-constrained edge devices (such as smartphones, IoT devices, and edge servers). Unlike past FL approaches, FedGKT demonstrates the feasibility of training a large server-side model by using many small client models. FedGKT preserves the data privacy requirements of the FL approach but also works within the constraints of an edge computing environment. Smartphone users may benefit from this technique because their private data is protected, and they may also simultaneously obtain a high-quality model service. Organizations such as hospitals, and other non-profit entities with limited training resources, can collaboratively train a large CNN model without revealing their datasets while achieving significant training cost savings. They can also meet requirements regarding the protection of intellectual property, confidentiality, regulatory restrictions, and legal constraints. As for the potential risks of our method, a client can maliciously send incorrect hidden feature maps and soft labels to the server, which may potentially impact the overall model accuracy. These effects must be detected and addressed to maintain overall system stability. Second, the relative benefits for each client may vary. For instance, in terms of fairness, edge nodes which have smaller datasets may obtain more model accuracy improvement from collaborative training than those which have a larger amount of training data. Our training framework does not consider how to balance this interest of different parties.",Broader Impact,228,11,,,FALSE,FALSE,FALSE,Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge,Deep Learning -> Efficient Training Methods,Algorithms -> Communication- or Memory-Bounded Learning; Algorithms -> Large Scale Learning; Applications -> Computer Vision,Federated Learning,,{'University of Southern California'},1,0,0,{'USA'}
Neural FFTs for Universal Texture Image Synthesis,"Morteza Mardani, Guilin Liu, Aysegul Dundar, Shiqiu Liu, Andrew Tao, Bryan Catanzaro",Neural FFTs for Universal Texture Image Synthesis,a23156abfd4a114c35b930b836064e8b,https://proceedings.neurips.cc/paper/2020/file/a23156abfd4a114c35b930b836064e8b-Paper.pdf,"Our AI research offers a powerful tool to synthesize a diverse range of textures with high fidelity and in a real-time manner. Our unique perspective of combining FFT, from signal processing tools, with deep learning for hallucinating images can be a great asset for other generation and style transfer tasks in graphics and vision. From the application standpoint, several applications in graphics and vision directly benefit from our tools to replace their tedious and manual synthesis platforms. In particular, it helps rapidly create natural scenes for computer game developers, interior designers, and artists. In addition, our AI-based tool can discover the generation process behind the real-world scenes, which can help the professionals to better prototype ideas and create new textures. In order to increase the positive impacts and reduce the downsides, we encourage further work to bring the users in the AI loop for additional guidance. This can allow artists to freely incorporate their creativity into the synthesis pipeline. We also recommend the researchers and industries to investigate methods for further squeezing the CNN architecture, and efficiently implement them on the processing hardware. This would help not only make our tools faster for edge computing applications, but also reduce the high computational power consumed for training neural networks, that positively impacts the environment.",7 Broader Impact,213,9,,,FALSE,FALSE,FALSE,Neural FFTs for Universal Texture Image Synthesis,Applications -> Computer Vision,Deep Learning -> CNN Architectures; Deep Learning -> Generative Models,,"['Morteza Mardani', ' Guilin Liu', ' Aysegul Dundar', ' Shiqiu Liu', ' Andrew Tao', ' Bryan Catanzaro']","{'Nvidia Corporation', 'NVIDIA'}",0,1,0,{'USA'}
Graph Cross Networks with Vertex Infomax Pooling,"Maosen Li, Siheng Chen, Ya Zhang, Ivor Tsang",Graph Cross Networks with Vertex Infomax Pooling,a26398dca6f47b49876cbaffbc9954f9,https://proceedings.neurips.cc/paper/2020/file/a26398dca6f47b49876cbaffbc9954f9-Paper.pdf,"In this work, we aim to propose a method for multiscale feature learning on graphs, achieving two basic but challenging tasks: graph classification and vertex classification. This work has the following potential impacts to the society and the research community. This work could be effectively used in many practical and important scenarios such as drug molecular analysis, social network mining, biometrics, human action recognition and motion prediction, etc., making our daily life more convenient and efficient. Due to the ubiquitous graph data, in most cases, we can try to construct multiscale graphs to comprehensively obtain rich detailed, abstract, and even global feature representations, and effectively improve downstream tasks. Our network structure can not only solve problem of feature learning with multiple graph scales, but also can be applied to the pattern learning of heterogeneous graphs, or other cross-modal or cross- view machine learning scenarios. This is of great significance for improving the ability of pattern recognition, feature transfer, and knowledge distillation to improve the computational efficiency. At the same time, this work may have some negative consequences. For example, in social networks, it is uncomfortable even dangerous to use the models based on this work to over-mine the behavior of users, because the user’s personal privacy and information security are crucial; companies should avoid mining too much users’ personal information when building social platforms, keeping a safe internet environment.",Broader Impact of Our Work,229,8,,,FALSE,FALSE,FALSE,Graph Cross Networks with Vertex Infomax Pooling,Algorithms -> Relational Learning,Algorithms -> Classification; Algorithms -> Representation Learning; Deep Learning -> Interaction-Based Deep Networks,,"['Maosen Li', ' Siheng Chen', ' Ya Zhang', ' Ivor Tsang']","{'MERL', 'University of Technology, Sydney', 'Shanghai Jiao Tong University', 'Cooperative Medianet Innovation Center, Shang hai Jiao Tong University'}",1,0,0,"{'Australia', 'USA', 'China'}"
Instance-optimality in differential privacy via approximate inverse sensitivity mechanisms,"Hilal Asi, John C. Duchi",Instance-optimality in differential privacy via approximate inverse sensitivity mechanisms,a267f936e54d7c10a2bb70dbe6ad7a89,https://proceedings.neurips.cc/paper/2020/file/a267f936e54d7c10a2bb70dbe6ad7a89-Paper.pdf,"The substantial growth in data collection and analysis and the increasing awareness for privacy concerns has led to a growing body of work on privacy risks in both academic [16] and industrial settings [17, 3]. Differential privacy [16] has emerged as the standard method for preserving privacy and has enjoyed several applications including in statistical estimation [11], machine learning [5], and game theory [24]. Unfortunately, it is usually challenging to develop private algorithms that achieve satisfactory utility [11]. Therefore, while differential privacy has been successfully deployed in several industrial companies, most applications instantiate a large privacy parameter ε to achieve acceptable utility, potentially compromising the privacy of users [1]. However, the standard approach in differential privacy to measure the performance of an algorithm is through its (worst case) minimax risk [11]. This—as our theory demonstrates—may be too pessimistic in general and may not capture the correct trade-off between privacy and utility for natural data that arises in real-life. An instance-specific understanding of this trade-off can therefore result in significant improvements in both utility and privacy. We hope that this work—and instance-optimality in differential privacy in general [4]—can lead to a better understanding of the privacy-utility trade-off of private algorithms for the underlying data at hand. By exploiting the average-case nature of data in real life, we believe that the instance-optimal algorithms we develop can achieve satisfying utility with significantly stronger privacy protections for users.",Broader Impact,234,9,,,FALSE,FALSE,FALSE,Instance-optimality in differential privacy via approximate inverse sensitivity mechanisms,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Hilal Asi', ' John Duchi']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Calibration of Shared Equilibria in General Sum Partially Observable Markov Games,"Nelson Vadori, Sumitra Ganesh, Prashant Reddy, Manuela Veloso",Calibration of Shared Equilibria in General Sum Partially Observable Markov Games,a2f04745390fd6897d09772b2cd1f581,https://proceedings.neurips.cc/paper/2020/file/a2f04745390fd6897d09772b2cd1f581-Paper.pdf,"The first part of our work attempts to bring a formal/theoretical understanding of equilibria reached by agents using a shared policy network and is difficultly applicable to this section. The second part of our work introduces a novel reinforcement learning based algorithm to cal- ibrate/constrain equilibria learnt by such agents in multi-agent systems/simulators to externally- specified objectives. It is easy to see how this new methodology could be used with fairness targets/objectives in mind, thus leading to more fair and ethical equilibria learnt by reinforcement learning agents. For example, one could constrain the learnt equilibrium to have as few observed non-ethical behaviors among agents as possible, the latter being quantified by a user-input metric that would simply need to be passed on to the RL calibrator agent’s reward function. We haven’t specifically explored this aspect in the present paper, but we believe that there is significant potential for research attempting to design and learn fair and ethical targets for equilibria using our algorithm in multi-agent systems.",Broader Impact,166,5,,,FALSE,FALSE,FALSE,Calibration of Shared Equilibria in General Sum Partially Observable Markov Games,Reinforcement Learning and Planning -> Multi-Agent RL,Theory -> Game Theory and Computational Economics,Reinforcement learning and planning,"['Nelson Vadori', ' Sumitra Ganesh', ' Prashant Reddy', ' Manuela Veloso']","{'JPMorgan - AI Research', 'JP Morgan', 'JPMorgan'}",0,1,0,{'USA'}
MOPO: Model-based Offline Policy Optimization,"Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano Ermon, James Y. Zou, Sergey Levine, Chelsea Finn, Tengyu Ma",MOPO: Model-based Offline Policy Optimization,a322852ce0df73e204b7e67cbbef0d0a,https://proceedings.neurips.cc/paper/2020/file/a322852ce0df73e204b7e67cbbef0d0a-Paper.pdf,"MOPO achieves significant strides in offline reinforcement learning, a problem setting that is particularly scalable to real-world settings. Offline reinforcement learning has a number of potential application domains, including autonomous driving, healthcare, robotics, and is notably amenable to safety-critical settings where online data collection is costly. For example, in autonomous driving, online interaction with the environment runs the risk of crashing and hurting people; offline RL methods can significantly reduce that risk by learning from a pre-recorded driving dataset collected by a safe behavioral policy. Moreover, our work opens up the possibility of learning policies offline for new tasks for which we do not already have expert data. However, there are still risks associated with applying learned policies to high-risk domains. We have shown the benefits of explicitly accounting for error, but without reliable out-of-distribution uncertainty estimation techniques, there is a possibility that the policy will behave unpredictably when given a scenario it has not encountered. There is also the challenge of reward design: although the reward function will typically be under the engineer’s control, it can be difficult to specify a reward function that elicits the desired behavior and is aligned with human objectives. Additionally, parametric models are known to be susceptible to adversarial attacks, and bad actors can potentially exploit this vulnerability. Advances in uncertainty quantification, human-computer interaction, and robustness will improve our ability to apply learning-based methods in safety-critical domains. Supposing we succeed at producing safe and reliable policies, there is still possibility of negative societal impact. An increased ability to automate decision-making processes may reduce companies’ demand for employees in certain industries (e.g. manufacturing and logistics), thereby affecting job availability. However, historically, advances in technology have also created new jobs that did not previously exist (e.g. software engineering), and it is unclear if the net impact on jobs will be positive or negative. Despite the aforementioned risks and challenges, we believe that offline RL is a promising setting with enormous potential for automating and improving sequential decision-making in highly impactful domains. Currently, much additional work is needed to make offline RL sufficiently robust to be applied in safety-critical settings. We encourage the research community to pursue further study in uncertainty estimation, particularly considering the complications that arise in sequential decision problems.",Broader Impact,375,15,,,FALSE,FALSE,FALSE,MOPO: Model-based Offline Policy Optimization,Reinforcement Learning and Planning -> Model-Based RL,,Reinforcement learning and planning,"['Tianhe Yu', ' Thomas', ' Lantao Yu', ' Stefano Ermon', ' James Zou', ' Sergey Levine', ' Chelsea Finn', ' Tengyu Ma']","{'Stanford', 'Stanford University', 'UC Berkeley'}",1,0,0,{'USA'}
Building powerful and equivariant graph neural networks with structural message-passing,"Clément Vignac, Andreas Loukas, Pascal Frossard",Building powerful and equivariant graph neural networks with structural message-passing,a32d7eeaae19821fd9ce317f3ce952a7,https://proceedings.neurips.cc/paper/2020/file/a32d7eeaae19821fd9ce317f3ce952a7-Paper.pdf,"This paper introduced a new methodology for building graph neural networks, conceived independently of a specific application. As graphs constitute a very abstract way to represent data, they have found a lot of different applications [56]. The wide applicability of graph neural networks makes it challenging to foresee how our method will be used and the ethical problems which might occur. Nevertheless, as we propose to overcome limitations of previous work in learning topological information, our method is likely to be used first and foremost in fields were graph topology is believed to be important. We hope in particular that it can contribute to the fields of quantum chemistry and drug discovery. The good performance obtained on the ZINC dataset is an encouraging sign of the potential of SMP in these fields. Other applications come to mind: material science [57], computational biology [58], combinatorial optimization [7, 8, 9] or code generation [59].",Broader Impact,152,7,,,FALSE,FALSE,FALSE,Building powerful and equivariant graph neural networks with structural message-passing,Algorithms -> Representation Learning,Algorithms -> Semi-Supervised Learning; Deep Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,{'EPFL'},1,0,0,{'Switzerland'}
Efficient Model-Based Reinforcement Learning through Optimistic Policy Search and Planning,"Sebastian Curi, Felix Berkenkamp, Andreas Krause",Efficient Model-Based Reinforcement Learning through Optimistic Policy Search and Planning,a36b598abb934e4528412e5a2127b931,https://proceedings.neurips.cc/paper/2020/file/a36b598abb934e4528412e5a2127b931-Paper.pdf,"Improving sample efficiency is one of the key bottlenecks in applying reinforcement learning to real-world problems with potential major societal benefit such as personal robotics, renewable energy systems, medical decisions making, etc. Thus, algorithmic and theoretical contributions as presented in this paper can help decrease the cost associated with optimizing RL policies. Of course, the overall RL framework is so general that potential misuse cannot be ruled out.",Broader Impact,68,3,,,FALSE,FALSE,FALSE,Efficient Model-Based Reinforcement Learning through Optimistic Policy Search and Planning,Reinforcement Learning and Planning -> Model-Based RL,Reinforcement Learning and Planning -> Exploration,Reinforcement learning and planning,"['Sebastian Curi', ' Felix Berkenkamp', ' Andreas Krause']","{'ETHz', 'ETH Zurich'}",1,0,0,{'Switzerland'}
Practical Low-Rank Communication Compression in Decentralized Deep Learning,"Thijs Vogels, Sai Praneeth Karimireddy, Martin Jaggi",Practical Low-Rank Communication Compression in Decentralized Deep Learning,a376802c0811f1b9088828288eb0d3f0,https://proceedings.neurips.cc/paper/2020/file/a376802c0811f1b9088828288eb0d3f0-Paper.pdf,"We believe that the field of decentralized learning plays a key role in translating the recent successes in deep learning from large organizations with large centralized datasets to smaller industry players and individuals. In particular, decentralized and therefore collaborative training on decentralized data is an important building block towards helping to better align each individual’s data ownership and privacy with the resulting utility from jointly trained machine learning models. The ability to train collaboratively on decentralized data may lead to transformative insights in many fields, especially in applications where data is user-provided and privacy sensitive (Nedic, 2020). In addition to privacy, efficiency gains in distributed training reduce the environmental impact of training large machine learning models. The introduction of a practical and reliable communication compression technique is a small step towards achieving these goals on collaborative privacy-preserving and efficient decentralized learning.",8 Broader Impact,141,5,,,FALSE,FALSE,FALSE,Practical Low-Rank Communication Compression in Decentralized Deep Learning,Deep Learning -> Optimization for Deep Networks,Optimization; Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Thijs Vogels', ' Sai Praneeth Karimireddy', ' Martin Jaggi']",{'EPFL'},1,0,0,{'Switzerland'}
Mutual exclusivity as a challenge for deep neural networks,"Kanishk Gandhi, Brenden M. Lake",Mutual exclusivity as a challenge for deep neural networks,a378383b89e6719e15cd1aa45478627c,https://proceedings.neurips.cc/paper/2020/file/a378383b89e6719e15cd1aa45478627c-Paper.pdf,"Our challenge highlights how biases learned by a model fail to align with the structure of the data. A model that successfully reasons with ME, through either prior knowledge or learning via a meta- strategy, would better on tail-end distributions where models map rare examples to frequent ones. By representing the structure of the data more accurately allows for quicker generalization, there is also potential for models to learn a wider range of undesirable biases present in the training data.",Broader Impact,80,3,,,FALSE,FALSE,FALSE,Mutual exclusivity as a challenge for deep neural networks,Neuroscience and Cognitive Science -> Cognitive Science,Algorithms -> Continual Learning; Algorithms -> Few-Shot Learning; Neuroscience and Cognitive Science -> Language for Cognitive Science,Neuroscience and cognitive science,"['Kanishk Gandhi', ' Brenden Lake']",{'New York University'},1,0,0,{'USA'}
3D Shape Reconstruction from Vision and Touch,"Edward Smith, Roberto Calandra, Adriana Romero, Georgia Gkioxari, David Meger, Jitendra Malik, Michal Drozdzal",3D Shape Reconstruction from Vision and Touch,a3842ed7b3d0fe3ac263bcabd2999790,https://proceedings.neurips.cc/paper/2020/file/a3842ed7b3d0fe3ac263bcabd2999790-Paper.pdf,"Our contributions allows for improved understanding of the three dimensional world in which we all live. The impact of this work lies mainly in the field of 3D object understanding, such as better 3D reconstruction of objects in simulated environments as well as potential improvements in shape understanding in real world robot-object manipulation. There are many benefits to using improved 3D object understanding, and it may prove especially useful for the fields of automation, robotic, computer graphics and augmented and virtual reality. Failures of these models could arise if automation tools are not properly introduced, and biases are not properly addressed. In particular, these models could result in poor recognition of 3D objects in diverse contexts, as has already been shown for 2D recognition systems. On the research side, to mitigate these risks, we encourage further investigation to outline the performance of 3D understanding systems in the wild in a diverse set of contexts and geographical locations, and to mitigate the associated performance drops.",Broader Impact,164,6,,,FALSE,FALSE,FALSE,3D Shape Reconstruction from Vision and Touch,Applications -> Computer Vision,Algorithms -> Multimodal Learning,Vision,"['Edward Smith', ' Roberto Calandra', ' Adriana Romero', ' Georgia Gkioxari', ' David Meger', ' Jitendra Malik', ' Michal Drozdzal']","{'Facebook', 'Facebook AI Research', 'University of California at Berkley', 'McGill University', 'FAIR'}",1,1,1,"{'Canada', 'USA'}"
GradAug: A New Regularization Method for Deep Neural Networks,"TAOJIANNAN YANG, Sijie Zhu, Chen Chen",GradAug: A New Regularization Method for Deep Neural Networks,a3a3e8b30dd6eadfc78c77bb2b8e6b60,https://proceedings.neurips.cc/paper/2020/file/a3a3e8b30dd6eadfc78c77bb2b8e6b60-Paper.pdf,"The proposed regularization method is a generic approach for deep neural networks training. Re- searchers in the machine learning and computer vision communities should benefit from this work. To the best of our knowledge, we don’t think this research will put anyone at disadvantage. All the experiments are based on the public datasets and follow the standard experimental settings. Thus the method does not leverage biases in the data.",Broader Impact,69,5,,,FALSE,FALSE,FALSE,GradAug: A New Regularization Method for Deep Neural Networks,Deep Learning,Algorithms -> Classification; Algorithms -> Representation Learning; Applications -> Computer Vision; Deep Learning -> CNN Architectures; Deep Learning -> Supervised Deep Networks,Deep learning,"['TAOJIANNAN YANG', ' Sijie Zhu', ' Chen Chen']",{'University of North Carolina at Charlotte'},1,0,0,{'USA'}
An Equivalence between Loss Functions and Non-Uniform Sampling in Experience Replay,"Scott Fujimoto, David Meger, Doina Precup",An Equivalence between Loss Functions and Non-Uniform Sampling in Experience Replay,a3bf6e4db673b6449c2f7d13ee6ec9c0,https://proceedings.neurips.cc/paper/2020/file/a3bf6e4db673b6449c2f7d13ee6ec9c0-Paper.pdf,"Our research focuses on developing the theoretical foundations for a commonly used technique in deep reinforcement learning, prioritized experience replay. Our insights could be used to improve reinforcement learning systems over a wide range of applications such as clinical trial design [50], educational games [51] and recommender systems [52, 53]. Non-uniform sampling may also have benefits for scaling offline reinforcement learning, in particular, when learning from large data sets where sampling only relevant or important data is critical. We expect our impact to be more significant for the reinforcement learning community itself. In the supplementary material we demonstrate our publicly released implementation of PER runs significantly faster (5-17 × ) than previous implementations published by corporate research groups [54, 55]. This improves the accessibility of non-uniform sampling strategy and state-of-the-art deep reinforcement learning research for groups with resource limitations.",Broader Impact,139,6,,,FALSE,FALSE,FALSE,An Equivalence between Loss Functions and Non-Uniform Sampling in Experience Replay,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Scott Fujimoto', ' David Meger', ' Doina Precup']","{'McGill University / Mila / DeepMind Montreal', 'McGill University'}",1,1,1,{'Canada'}
Learning Utilities and Equilibria in Non-Truthful Auctions,"Hu Fu, Tao Lin",Learning Utilities and Equilibria in Non-Truthful Auctions,a3c788c57e423fa9c177544a4d5d1239,https://proceedings.neurips.cc/paper/2020/file/a3c788c57e423fa9c177544a4d5d1239-Paper.pdf,"This work is theoretical in nature, and should be understood as providing understanding for existing or possible practice, rather than having immediate societal impacts. More accurate utility estimation in auctions can improve market efficiency, improve bidders’ profit in the short term, and help maintain the health of the markets in the long term. When such auctions are on online advertisements, for example, users eventually benefit from the long-term health of the markets. Third-party service providers may also help market participants optimize their performances via data collection and effective modeling. The authors do not see other negative ethical aspects or societal consequences, especially given the theoretical nature of the work.",Broader Impact,109,5,,,FALSE,FALSE,FALSE,Learning Utilities and Equilibria in Non-Truthful Auctions,Applications -> Computational Social Science,Theory -> Computational Learning Theory,Theory (including computational and statistical analyses),"['Hu Fu', ' Tao Lin']","{'University of British Columbia', 'Peking University'}",1,0,0,"{'Canada', 'China'}"
Rational neural networks,"Nicolas Boulle, Yuji Nakatsukasa, Alex Townsend",Rational neural networks,a3f390d88e4c41f2747bfa2f1b5f87db,https://proceedings.neurips.cc/paper/2020/file/a3f390d88e4c41f2747bfa2f1b5f87db-Paper.pdf,"Neural networks have applications in diverse fields such as facial recognition, credit-card fraud, speech recognition, and medical diagnosis. There is a growing understanding of the approximation power of neural networks, which is adding theoretical justification to their use in societal applications. We are particularly interested in the future applicability of rational neural networks in discovering and solving of partial differential equations (PDEs). Neural networks, in particular rational neural networks, have the potential to revolutionize fields where PDE models derived by mechanistic principles are lacking.",Broader Impact,84,4,,,FALSE,FALSE,FALSE,Rational neural networks,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Hardness of Learning and Approximations,Deep learning,"['Nicolas Boulle', ' Yuji Nakatsukasa', ' Alex J Townsend']","{'Cornell University', 'University of Oxford'}",1,0,0,"{'UK', 'USA'}"
DISK: Learning local features with policy gradient,"Michał Tyszkiewicz, Pascal Fua, Eduard Trulls",DISK: Learning local features with policy gradient,a42a596fc71e17828440030074d15e74,https://proceedings.neurips.cc/paper/2020/file/a42a596fc71e17828440030074d15e74-Paper.pdf,"There already are many applications that rely on keypoints, and although our method has the potential to make them more effective, we do not expect new, specific issues arising from our research. As all technology, it can also be used unethically. In this instance, use in visually guided missiles or localizing photographs without user consent, further compromising privacy on the web, could be of concern. More generally, all automation of data processing brings disproportionately larger gains for established players with access to such data and resources, furthering the imbalance in global competitiveness, despite the nominal openness of the research.",Broader impact,99,4,,,FALSE,FALSE,FALSE,DISK: Learning local features with policy gradient,Applications -> Computer Vision,Reinforcement Learning and Planning -> Reinforcement Learning,Vision,"['Michał Tyszkiewicz', ' Pascal Fua', ' Eduard Trulls']","{'EPFL, Switzerland', 'Google', 'EPFL'}",1,1,1,"{'USA', 'Switzerland'}"
Transfer Learning via ℓ1ℓ1 Regularization,"Masaaki Takada, Hironori Fujisawa",Transfer Learning via 1 Regularization,a4a83056b58ff983d12c72bb17996243,https://proceedings.neurips.cc/paper/2020/file/a4a83056b58ff983d12c72bb17996243-Paper.pdf,"In this paper, the authors introduce sparse transfer learning. While the sparse change approach has many potential applications, here we focus on applications that require transparency and interpretabil- ity of models. Sparsity is effective for model transparency because it explains a phenomenon with fewer features. This is why Lasso is widely used in science such as genomics and economics, and in industries such as advanced electronics/semiconductors, chemicals, and health-care systems. For example, production yield of factories and plants is one of the primary interests in manufacturing, and it could be analyzed by Lasso to screen and identify important factors from thousands or millions of candidates. Our approach enhances the effectiveness of models for routine decision making. This is because routine decision making requires the information of changes from the last time and our approach highlights sparse changes of features as well as sparse features using two kinds of regularizations. In manufacturing applications, quality managers only need to check the difference from the past in regular daily/weekly/monthly analyses. Our approach is also effective in a scenario of small data and many models. This is because source parameters help estimate target parameters from small data and small numbers of changes among many models are easy to manage. Data scientists would support decision making with little effort using our method, due to its simplicity, stability, and operability. Another possible application is transferring knowledge among different companies. They have only to share model parameters instead of data itself, hence secure and privacy-preserving transfer learning is possible. One negative perspective we consider is that transferring wrong knowledge results in inaccurate models and hence incorrect or biased knowledge. However, we can control which knowledge should be discarded by setting initial estimates to zeros intentionally, so that this concern could be mitigated using physical rules or domain knowledge. Such a collaboration of knowledge and data helps improve the effectiveness of models, and leads to a new paradigm of theory-guided data science [17] and informed machine learning [37].",Broader Impact,330,16,,,FALSE,FALSE,FALSE,Transfer Learning via $\ell_1$ Regularization,Algorithms -> Sparsity and Compressed Sensing,Algorithms -> Regression; Theory -> High-Dimensional Inference; Theory -> Regularization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'Toshiba Corporation', 'The Institute of Statistical Mathematics'}",1,1,1,{'Japan'}
GOCor: Bringing Globally Optimized Correspondence Volumes into Your Neural Network,"Prune Truong, Martin Danelljan, Luc V. Gool, Radu Timofte",GOCor: Bringing Globally Optimized Correspondence Volumes into Your Neural Network,a4a8a31750a23de2da88ef6a491dfd5c,https://proceedings.neurips.cc/paper/2020/file/a4a8a31750a23de2da88ef6a491dfd5c-Paper.pdf,"Our feature correspondence matching module can be beneficial in a wide range of applications relying on explicit or implicit matching between images, such as visual localization [46, 53], 3D- reconstruction [1], structure-from-motion [45], action recognition [50] and autonomous driving [22]. On the other hand, any image matching algorithm runs the risk of being used for malevolent tasks, such as malicious image manipulation or image surveillance system. However, our module is only one building block to be integrated in a larger pipeline. On its own, it therefore has little chances of being wrongfully used.",Broader Impact,93,4,,,FALSE,FALSE,FALSE,GOCor: Bringing Globally Optimized Correspondence Volumes into Your Neural Network,Applications -> Tracking and Motion in Video,,Vision,"['Prune Truong', ' Martin Danelljan', ' Luc V Gool', ' Radu Timofte']","{'ETH Zurich', 'Computer Vision Lab, ETH Zurich'}",1,0,0,{'Switzerland'}
Deep Inverse Q-learning with Constraints,"Gabriel Kalweit, Maria Huegle, Moritz Werling, Joschka Boedecker",Deep Inverse Q-learning with Constraints,a4c42bfd5f5130ddf96e34a036c75e0a,https://proceedings.neurips.cc/paper/2020/file/a4c42bfd5f5130ddf96e34a036c75e0a-Paper.pdf,"Our work contributes an advancement in Inverse Reinforcement Learning (IRL) methods that can be used for imitation learning. Importantly, they enable non-expert users to program robots and other technical devices merely by demonstrating a desired behavior. On the one hand, this is a crucial requirement for realising visions such as Industry 4.0, where people increasingly work alongside flexible and lightweight robots and both have to constantly adapt to changing task requirements. This is expected to boost productivity, lower production costs, and contribute to bringing back local jobs that were lost due to globalization strategies. Since the IRL approach we present can incorporate and enforce constraints on behavior even if the demonstrations violate them, it has interesting applications in safety critical applications, such as creating safe vehicle behaviors for automated driving. On the other hand, the improvements we present can potentially accelerate existing trends for automation, requiring less and less human workers if they can be replaced by flexible and easily programmable robots. Estimates for the percentage of jobs at risk for automation range between 14% (OECD report, [17]) and 47% [9] of available jobs (also depending on the country in question). Thus, our work could potentially add to the societal challenge to find solutions that mitigate these consequences (such as e.g. re-training, continuing education, universal basic income, etc.) and make sure that affected individuals remain active, contributing, and self-determined members of society. While it has been argued that IRL methods are essential for value-alignment of artificial intelligence agents [22, 2], the standard framework might not cover all aspects necessary [3]. Our Deep Constrained Inverse Q-learning approach, however, improves on this situation by providing a means to enforce additional behavioral rules and constraints to guarantee behavior imitation consistent within moral and ethical frames of society.",Broader Impact,294,11,,,FALSE,FALSE,FALSE,Deep Inverse Q-learning with Constraints,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Gabriel Kalweit', ' Maria Huegle', ' Moritz Werling', ' Joschka Boedecker']","{'BMWGroup, Unterschleissheim', 'University of Freiburg'}",1,1,1,{'Germany'}
Optimistic Dual Extrapolation for Coherent Non-monotone Variational Inequalities,"Chaobing Song, Zhengyuan Zhou, Yichao Zhou, Yong Jiang, Yi Ma",Optimistic Dual Extrapolation for Coherent Non-monotone Variational Inequalities,a4df48d0b71376788fee0b92746fd7d5,https://proceedings.neurips.cc/paper/2020/file/a4df48d0b71376788fee0b92746fd7d5-Paper.pdf,"In this paper, we discuss a systematic theoretical analysis for single-call extragradient methods, which has been widely used for modern machine learning applications. The theoretical results in this paper can bring in meaningful insight and understanding for practical algorithms.",Broader Impact,39,2,FALSE,FALSE,FALSE,FALSE,FALSE,Optimistic Dual Extrapolation for Coherent Non-monotone Variational Inequalities,Optimization -> Non-Convex Optimization,Optimization -> Convex Optimization; Optimization -> Stochastic Optimization,,,"{'UC Berkeley', 'Stanford University', 'Tsinghua University', 'Tsinghua'}",1,0,0,"{'USA', 'China'}"
Prediction with Corrupted Expert Advice,"Idan Amir, Idan Attias, Tomer Koren, Yishay Mansour, Roi Livni",Prediction with Corrupted Expert Advice,a512294422de868f8474d22344636f16,https://proceedings.neurips.cc/paper/2020/file/a512294422de868f8474d22344636f16-Paper.pdf,There are no foreseen ethical or societal consequences for the research presented herein.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Prediction with Corrupted Expert Advice,Algorithms -> Online Learning,Algorithms -> Adversarial Learning,Theory (including computational and statistical analyses),"['Idan Amir', ' Idan Attias', ' Tomer Koren', ' Yishay Mansour', ' Roi Livni']","{'Ben Gurion University', 'Tel-Aviv University', 'Tel Aviv University', 'Google', 'Tel Aviv University / Google'}",1,1,1,"{'USA', 'Israel'}"
Human Parsing Based Texture Transfer from Single Image to 3D Human via Cross-View Consistency,"Fang Zhao, Shengcai Liao, Kaihao Zhang, Ling Shao",Human Parsing Based Texture Transfer from Single Image to 3D Human via Cross-View Consistency,a516a87cfcaef229b342c437fe2b95f7,https://proceedings.neurips.cc/paper/2020/file/a516a87cfcaef229b342c437fe2b95f7-Paper.pdf,"Enabling machine learning models to understand and reconstruct 3D data is able to significantly improve the experience of human-machine interaction, such as virtual reality, clothes try-on and so on. Besides, it also facilitates the invariant and robust representation learning from the geometry effects, such as scales and views. Texture generation of 3D model is a critical part in 3D reconstruction. Particularly, the texture generation model based on a single image can extremely reduce the resources required by model learning and inference, and shows great potential for industrial applications. However, poses, shapes and textures estimated by the model could be abused to synthesize fake pictures of people, which is a negative aspect.",Broader Impact,111,5,,,FALSE,FALSE,FALSE,Human Parsing Based Texture Transfer from Single Image to 3D Human via Cross-View Consistency,Applications -> Computational Photography,Applications -> Computer Vision; Deep Learning,Vision,"['Fang Zhao', ' Shengcai Liao', ' Kaihao Zhang', ' Ling Shao']","{'Inception Institute of Artificial Intelligence', 'Australian National University'}",1,0,0,"{'UAE', 'Australia'}"
Knowledge Augmented Deep Neural Networks for Joint Facial Expression and Action Unit Recognition,"Zijun Cui, Tengfei Song, Yuru Wang, Qiang Ji",Knowledge Augmented Deep Neural Networks for Joint Facial Expression and Action Unit Recognition,a51fb975227d6640e4fe47854476d133,https://proceedings.neurips.cc/paper/2020/file/a51fb975227d6640e4fe47854476d133-Paper.pdf,"This work is focused on two computer vision tasks: facial expression recognition and facial action units detection. The potential broader impacts of this work are listed as follows: Benefits: Facial expression recognition can benefit many applications, including HCI, social robotics, medical diagnosis, games animation, etc. By leveraging the domain knowledge, our proposed models have less dependence on training data and thus the data efficiency is improved. In other words, it may release domain experts from the heavy workload on labeling data. Furthermore, as the domain  knowledge is generic, our propose model can generalize well to different datasets. Hence, given new datasets, additional training process is promised to be no longer necessary. Risks: Facial expression recognition has some privacy concerns. For example, through facial expression recognition systems, individuals’ emotional reactions to certain messages, news or figures can be tracked. Also individuals’ emotional reactions to events can be monitored in the public places with facial expression recognition systems.",Broader Impact,156,9,,,FALSE,TRUE,FALSE,Knowledge Augmented Deep Neural Networks for Joint Facial Expression and Action Unit Recognition,"Applications -> Body Pose, Face, and Gesture Analysis",,Vision,"['Zijun Cui', ' Tengfei Song', ' Yuru Wang', ' Qiang Ji']","{'Northeast Normal University', 'Rensselaer Polytechnic Institute', 'Southeast University'}",1,0,0,"{'USA', 'China'}"
Point process models for sequence detection in high-dimensional neural spike trains,"Alex Williams, Anthony Degleris, Yixin Wang, Scott Linderman",Point process models for sequence detection in high-dimensional neural spike trains,a5481cd6d7517aa3fc6476dc7d9019ab,https://proceedings.neurips.cc/paper/2020/file/a5481cd6d7517aa3fc6476dc7d9019ab-Paper.pdf,"Understanding neural computations in biological systems and ultimately the human brain is a grand and long-term challenge with broad implications for human health and society. The field of neuroscience is still taking early and incremental steps towards this goal. Our work develops a general-purpose, unsupervised method for identifying an important structure—neural sequences— which have been observed in a variety of experimental datasets and have been studied extensively by theorists. This work will serve to advance this growing understanding by providing new analytical tools for neuroscientists. We foresee no immediate impacts, positive or negative, concerning the general public.",Broader Impact,97,5,,,FALSE,TRUE,FALSE,Point process models for sequence detection in high-dimensional neural spike trains,Neuroscience and Cognitive Science,,Neuroscience and cognitive science,"['Alex H Williams', ' Anthony Degleris', ' Yixin Wang', ' Scott Linderman']","{'Stanford University', 'Columbia University'}",1,0,0,{'USA'}
Adversarial Attacks on Linear Contextual Bandits,"Evrard Garcelon, Baptiste Roziere, Laurent Meunier, Jean Tarbouriech, Olivier Teytaud, Alessandro Lazaric, Matteo Pirotta",Adversarial Attacks on Linear Contextual Bandits,a554f89dd61cabd2ff833d3468e2008a,https://proceedings.neurips.cc/paper/2020/file/a554f89dd61cabd2ff833d3468e2008a-Paper.pdf,"Adversarial attacks have been a major concerns in the machine learning community for some time [5, 6, 7, 8, 9] as they delve deeply into the robustness of such machine learning systems. Although, adversarial attacks have only been recently studied for bandits and reinforcement learning algorithms [12, 25]. Those settings are applied to a wide range of applications such as recommender systems or cooling down data centers [34]. In adversarial attacks on supervised algorithms and cryptography, it is well-accepted that the study and publication of attack schemes helps build trustful secure systems [35]. While there is a risk that our methods could be used by malicious attackers, we believe that they will also prompt some practitioners to ensure such modifications of the rewards or contexts of their data can be detected or even prevented.",Broader Impact,134,5,,,FALSE,FALSE,FALSE,Adversarial Attacks on Linear Contextual Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Adversarial Learning,Theory (including computational and statistical analyses),"['Evrard Garcelon', ' Baptiste Roziere', ' Laurent Meunier', ' Jean Tarbouriech', ' Olivier Teytaud', ' Alessandro Lazaric', ' Matteo Pirotta']","{'Dauphine University - FAIR Paris', 'Facebook', 'Facebook AI Research', 'Facebook Artificial Intelligence Research'}",1,1,1,{'USA'}
Meta-Consolidation for Continual Learning,"Joseph K J, Vineeth Nallure Balasubramanian",Meta-Consolidation for Continual Learning,a5585a4d4b12277fee5cad0880611bc6,https://proceedings.neurips.cc/paper/2020/file/a5585a4d4b12277fee5cad0880611bc6-Paper.pdf,"(as required by NeurIPS 2020 CFP) Continual learning is a key desiderata for Artificial General Intelligence (AGI). Hence, this line of research has the benefits as well as the pitfalls of any other research effort geared in this direction. In particular, our work can help deliver impact on making smarter AI products and services, which can learn and update themselves on-the-fly when newer tasks and domains are encountered, without forgetting previously acquired knowledge. This is a necessity in any large-scale deployments of machine learning and computer vision, including in social media, e-commerce, surveillance, e- governance, etc - each of which have newer settings, tasks or domains added continually over time. Any negative effect of our work, such as legal and ethical concerns, are not unique to this work - to the best of our knowledge, but are shared with any other new development in machine learning, in general.",Broader Impact,148,5,,,FALSE,FALSE,FALSE,Meta-Consolidation for Continual Learning,Algorithms -> Classification,Deep Learning -> Supervised Deep Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Joseph K J', ' Vineeth Nallure Balasubramanian']","{'Indian Institute of Technology Hyderabad', 'Indian Institute of Technology, Hyderabad'}",1,0,0,{'India'}
Organizing recurrent network dynamics by task-computation to enable continual learning,"Lea Duncker, Laura Driscoll, Krishna V. Shenoy, Maneesh Sahani, David Sussillo",Organizing recurrent network dynamics by task-computation to enable continual learning,a576eafbce762079f7d1f77fca1c5cc2,https://proceedings.neurips.cc/paper/2020/file/a576eafbce762079f7d1f77fca1c5cc2-Paper.pdf,"This work proposes a novel continual learning algorithm which will contribute to the advance of related methods. Continual learning of dynamic tasks has not been well-explored in machine learning so far, but will likely be important for fields such as robotics and developing artificial intelligent agents more generally. Furthermore, we utilize the framework of recurrent networks to test and refine hypotheses about computation in biological systems. Advances in this area will contribute to the design of new experiments and aid the analyses of recorded data in the field of neuroscience.",Broader Impact,90,4,,,FALSE,FALSE,FALSE,Organizing recurrent network dynamics by task-computation to enable continual learning,Neuroscience and Cognitive Science -> Neuroscience,Algorithms -> Continual Learning; Algorithms -> Dynamical Systems; Algorithms -> Multitask and Transfer Learning; Deep Learning -> Recurrent Networks; Neuroscience and Cognitive Science -> Memory,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Lea Duncker', ' Laura N Driscoll', ' Krishna V Shenoy', ' Maneesh Sahani', ' David Sussillo']","{'Stanford', 'Gatsby Unit, UCL', 'Stanford University'}",1,0,0,"{'UK', 'USA'}"
Lifelong Policy Gradient Learning of Factored Policies for Faster Training Without Forgetting,"Jorge Mendez, Boyu Wang, Eric Eaton",Lifelong Policy Gradient Learning of Factored Policies for Faster Training Without Forgetting,a58149d355f02887dfbe55ebb2b64ba3,https://proceedings.neurips.cc/paper/2020/file/a58149d355f02887dfbe55ebb2b64ba3-Paper.pdf,"One of the key contributions of our work is reducing the amount of experience required by RL agents to achieve proficiency at a multitude of tasks. The method we present here is a first plausible solution to solving a highly diverse set of RL tasks in a lifelong setting. Research in this direction that further reduces the amount of experience required to learn proficient policies would enable RL training on systems where experience is expensive, such as training real robotic systems or learning policies for medical treatments. In these settings, training RL policies has been impractical to date, but could potentially have a large positive impact by discovering policies superior to those conceivable by human experts with domain knowledge.",Broader Impact,119,4,,,FALSE,FALSE,FALSE,Lifelong Policy Gradient Learning of Factored Policies for Faster Training Without Forgetting,Algorithms -> Continual Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Jorge Mendez', ' Boyu Wang', ' Eric Eaton']","{'University of Pennsylvania', 'University of Western Ontario'}",1,0,0,"{'Canada', 'USA'}"
Kernel Methods Through the Roof: Handling Billions of Points Efficiently,"Giacomo Meanti, Luigi Carratino, Lorenzo Rosasco, Alessandro Rudi",Kernel methods through the roof: handling billions of points efficiently,a59afb1b7d82ec353921a55c579ee26d,https://proceedings.neurips.cc/paper/2020/file/a59afb1b7d82ec353921a55c579ee26d-Paper.pdf,"This work has the potential to greatly speed up a certain class of machine learning workloads, namely kernel methods on large datasets when GPU(s) are available. If deployed widely, the positive impact of the presented method could be twofold: on the one hand it may reduce electricity consumption necessary to run such large-scale predictions [15], thus positively impacting the environment; on the other hand it could enable analysis of large datasets which were previously only accessible to simpler methods. At the same time the speedup we obtain relies on GPU accelerators; since this type of hardware is generally expensive, it could increase disparity in access to fast algorithms.",Broader Impact,108,3,,,FALSE,FALSE,FALSE,Kernel Methods Through the Roof: Handling Billions of Points Efficiently,Algorithms -> Kernel Methods,"Algorithms -> Classification; Algorithms -> Regression; Data, Challenges, Implementations, and Software -> Benchmarks; Data, Challenges, Implementations, and Software -> Software Toolkits","Datasets, challenges, software","['Giacomo Meanti', ' Luigi Carratino', ' Lorenzo Rosasco', ' Alessandro Rudi']","{'INRIA, Ecole Normale Superieure', 'University of Genoa', 'University of Genova- MIT - IIT'}",1,0,0,"{'France', 'India', 'Italy', 'USA'}"
Spike and slab variational Bayes for high dimensional logistic regression,"Kolyan Ray, Botond Szabo, Gabriel Clara",Spike and slab variational Bayes for high dimensional logistic regression,a5bad363fc47f424ddf5091c8471480a,https://proceedings.neurips.cc/paper/2020/file/a5bad363fc47f424ddf5091c8471480a-Paper.pdf,"Our theoretical results seek to better understand how sparse VB approximations work and thus improve their performance and reliability in practice. Since our results have no specific applications in mind, seeking rather to explain and improve an existing method, any potential broader impact will derive from improved performance in fields where such methods are already used.",Impact statement,56,2,FALSE,FALSE,TRUE,TRUE,FALSE,Spike and slab variational Bayes for high dimensional logistic regression,Theory -> High-Dimensional Inference,Algorithms -> Classification; Probabilistic Methods -> Bayesian Nonparametrics; Probabilistic Methods -> Bayesian Theory; Probabilistic Methods -> Variational Inference; Theory; Theory -> Frequentist Statistics; Theory -> Large Deviations and Asymptotic Analysis; Theory -> Regularization,Theory (including computational and statistical analyses),"['Kolyan Ray', ' Botond Szabo', ' Gabriel Clara']","{'Leiden University', 'Vrije Universiteit Amsterdam', 'Imperial College London'}",1,0,0,"{'UK', 'Netherlands'}"
Maximum-Entropy Adversarial Data Augmentation for Improved Generalization and Robustness,"Long Zhao, Ting Liu, Xi Peng, Dimitris Metaxas",Maximum-Entropy Adversarial Data Augmentation for Improved Generalization and Robustness,a5bfc9e07964f8dddeb95fc584cd965d,https://proceedings.neurips.cc/paper/2020/file/a5bfc9e07964f8dddeb95fc584cd965d-Paper.pdf,"The proposed method will be used to train a perception system that can robustly and reliably classify object instances. For example, this system can be used in many fundamental real-world applications in which a user desires to classify object instances from a product database, such as products found on local supermarkets or online stores. Similar to most deep learning applications learning from data which run the risk of producing biased or offensive content reflecting the training data, our work that learns a data-driven classification model is no exception. Our method moderates this issue by producing efficient fictitious target domains that are largely shifted from the source training dataset, so that the trained model on these adversarial domains are less biased. However, a downside of this moderation is the introduction of new hyper-parameters to be tuned for different tasks. Compared with other methods that obtain the same robustness but have to be trained on larger datasets, the proposed research can significantly reduce the data collection from different domains to train classification models, thereby reducing the system development time and lower related costs.",Broader Impact,181,6,,,FALSE,FALSE,FALSE,Maximum-Entropy Adversarial Data Augmentation for Improved Generalization and Robustness,Algorithms -> Multitask and Transfer Learning,Algorithms -> Adversarial Learning; Applications -> Computer Vision; Deep Learning -> Efficient Training Methods; Theory -> Models of Learning and Generalization ; Theory -> Regularization,Vision,"['Long Zhao', ' Ting Liu', ' Xi Peng', ' Dimitris Metaxas']","{'Google', 'University of Delaware', 'Rutgers University'}",1,1,1,{'USA'}
Fast geometric learning with symbolic matrices,"Jean Feydy, Joan Glaunès, Benjamin Charlier, Michael Bronstein",Fast geometric learning with symbolic matrices,a6292668b36ef412fa3c4102d1311a62,https://proceedings.neurips.cc/paper/2020/file/a6292668b36ef412fa3c4102d1311a62-Paper.pdf,"Our work targets a wide range of machine learning applications, from kernel methods to geometric deep learning. In these fields, our library lowers the barrier of entry to state-of-the-art performances: fast nearest neighbors queries or point cloud convolutions can now be implemented by researchers who have no background in parallel computing. We hope that this will empower small research teams and organizations who don’t have access to dedicated teams of software engineers. More specifically, the flexibility of our library is ideally suited to the formulation of data-driven models for shape analysis and point cloud processing. Progress in these sectors can have a major impact in computer vision and medical imaging – topics that carry both risks and promises for society as a whole. We hope that our library will promote the growth of a diverse ecosystem of academic and industrial actors, and look forward to seeing applications of our work to e.g. computational anatomy.",Broader Impact,154,6,,,FALSE,FALSE,FALSE,Fast geometric learning with symbolic matrices,"Data, Challenges, Implementations, and Software -> Software Toolkits",Algorithms -> Kernel Methods; Applications -> Computer Vision; Probabilistic Methods -> Gaussian Processes,"Datasets, challenges, software","['Jean Feydy', ' Joan Glaunès', ' Benjamin Charlier', ' Michael Bronstein']","{'University of Montpellier', 'Imperial College London / Twitter', 'Université Paris 5', 'École Normale Supérieure'}",1,1,1,"{'France', 'UK', 'USA'}"
MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler,"Zhining Liu, Pengfei Wei, Jing Jiang, Wei Cao, Jiang Bian, Yi Chang",MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler,a64bd53139f71961c5c31a9af03d775e,https://proceedings.neurips.cc/paper/2020/file/a64bd53139f71961c5c31a9af03d775e-Paper.pdf,"In this work, we study the problem of imbalanced learning (IL), which is a common problem related to machine learning and data mining. Such a problem widely exists in many real-world application domains such as finance, security, biomedical engineering, industrial manufacturing, and information technology [15]. IL methods, including the proposed M ESA framework in this paper, aim to fix the bias of learning models introduced by skewed training class distribution. We believe that proper usage of these techniques will lead us to a better society. For example, better IL techniques can detect phishing websites/fraud transactions to protect people’s property, and help doctors diagnose rare diseases/develop new medicines to save people’s lives. With that being said, we are also aware that using these techniques improperly can cause negative impacts, as misclassification is inevitable in most of the learning systems. In particular, we note that when deploying IL systems in medical-related domains, misclassification (e.g., failure to identify a patient) could lead to medical malpractice. In such domains, these techniques should be used as auxiliary systems, e.g., when performing diagnosis, we can adjust the classification threshold to achieve higher recall and use the predicted probability as a reference for the doctor’s diagnosis. While there are some risks with IL research, as we mentioned above, we believe that with proper usage and monitoring, the negative impact of misclassification could be minimized and IL techniques can help people live a better life.",6 Statement of the Potential Broader Impact,237,9,,,FALSE,FALSE,FALSE,MESA: Boost Ensemble Imbalanced Learning with MEta-SAmpler,Algorithms -> Boosting and Ensemble Methods,Algorithms -> Classification; Algorithms -> Meta-Learning,class-imbalanced learning,,"{'MSRA', 'National University of Singapore', 'Microsoft', 'University of Technology Sydney', 'Jilin University'}",1,1,1,"{'Singapore', 'Australia', 'USA', 'China'}"
CoinPress: Practical Private Mean and Covariance Estimation,"Sourav Biswas, Yihe Dong, Gautam Kamath, Jonathan Ullman",CoinPress: Practical Private Mean and Covariance Estimation,a684eceee76fc522773286a895bc8436,https://proceedings.neurips.cc/paper/2020/file/a684eceee76fc522773286a895bc8436-Paper.pdf,"Our work provides realizable tools for private data analysis. Given recent concerns centered around large-scale data collection and surveillance, the production of a mature and robust set of tools which preserve privacy can help assuage public fears involving misuse of personal data. Additionally, we hope that developing tools which approach the non-private accuracy will inspire companies to adopt privacy by default. As differential privacy requires technical domain knowledge, incorrect use or misinterpretation of differential privacy is unfortunately easy and can lead to negative side effects including providing a misleading or false sense of security. Such issues can be avoided by sufficient training and/or consultation with experts in data privacy, although this may present more of a challenge for smaller, resource-constrained organizations.",Broader Impact,121,5,,,TRUE,TRUE,FALSE,CoinPress: Practical Private Mean and Covariance Estimation,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)",,"{'University of Waterloo', 'Microsoft', 'Northeastern University'}",1,1,1,"{'Canada', 'USA'}"
Planning with General Objective Functions: Going Beyond Total Rewards,"Ruosong Wang, Peilin Zhong, Simon S. Du, Russ R. Salakhutdinov, Lin Yang",Planning with General Objective Functions: Going Beyond Total Rewards,a6a767bbb2e3513233f942e0ff24272c,https://proceedings.neurips.cc/paper/2020/file/a6a767bbb2e3513233f942e0ff24272c-Paper.pdf,"This work is mainly theoretical. By devising provably efficient algorithms for planning with general objective functions, we believe our various algorithmic insights (discretization, augmenting state space) could potentially guide practitioners to design efficient and theoretically-principled planning algorithms that work for various settings.",Broader Impact,42,2,TRUE,TRUE,FALSE,FALSE,FALSE,Planning with General Objective Functions: Going Beyond Total Rewards,Theory,,,"['Ruosong Wang', ' Peilin Zhong', ' Simon Du', ' Russ Salakhutdinov', ' Lin Yang']","{'UCLA', 'Columbia University', 'Carnegie Mellon University', 'Institute for Advanced Study'}",1,0,0,{'USA'}
Scattering GCN: Overcoming Oversmoothness in Graph Convolutional Networks,"Yimeng Min, Frederik Wenkel, Guy Wolf",Scattering GCN: Overcoming Oversmoothness in Graph Convolutional Networks,a6b964c0bb675116a15ef1325b01ff45,https://proceedings.neurips.cc/paper/2020/file/a6b964c0bb675116a15ef1325b01ff45-Paper.pdf,"Node classification in graphs is an important task that gains increasing interest nowadays in multiple fields looking into network analysis applications. For example, they are of interest in social studies, where a natural application is the study of social networks and other interaction graphs. Other popular application fields include biochemistry and epidemiology. However, this work is computational in nature and addresses the foundations of graph processing and geometric deep learning. As such, by itself, it is not expected to raise ethical concerns nor to have adverse effects on society.",Broader Impact,89,5,,,FALSE,FALSE,FALSE,Scattering GCN: Overcoming Oversmoothness in Graph Convolutional Networks,Algorithms -> Semi-Supervised Learning,Algorithms -> Representation Learning; Applications -> Network Analysis; Applications -> Signal Processing,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yimeng Min', ' Frederik Wenkel', ' Guy Wolf']","{'MILA', 'Mila, Université de Montréal'}",1,0,0,{'Canada'}
KFC: A Scalable Approximation Algorithm for kk−center Fair Clustering,"Elfarouk Harb, Ho Shan Lam",KFC: A Scalable Approximation Algorithm for k − center Fair Clustering ∗,a6d259bfbfa2062843ef543e21d7ec8e,https://proceedings.neurips.cc/paper/2020/file/a6d259bfbfa2062843ef543e21d7ec8e-Paper.pdf,"Any clustering algorithm that doesn’t take into consideration the underlying bias in data for some minority groups risks producing biased results against these groups. For example, In the United States there are computer programs that predict whether a criminal is likely to re-offend, and is used by judges to decide on the sentence length. One such program is the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) sold by NORTHPOINTE and was used by judges in Wisconsin. In a report by Pro-Publica, it was shown that COMPAS is racially biased, where it was twice as likely to falsely flag African American defendants as future criminals as much as White defendants, holding everything else constant. This was because the features (137 features representing answers of questions) that were used when clustering potential re-offenders were heavily biased against African American defendants. Several other examples show the necessity of having a fair clustering algorithm that protects minority groups, as well as prevents a certain group from dominating any cluster. This justifies the necessity of studying this problem and proposing new fair algorithms. Our algorithm puts an effective boundary ensure all groups are neither dominating nor underrepre- sented, as guaranteed by the α , β parameters. It could be useful when we want to maintain diversity in clusters, as pointed out in the marketing and committee selection examples by [2]. However, putting our algorithm in the wrong hands can lead to intensifying the issue. A malicious adversary can restrict certain groups (by changing the α, β parameter) to bias the model against having clusters with a representative percentage of a certain group, and thus care must be taken when setting the α, β parameters to not pass one’s own bias into the clustering algorithm.",7 Broader Impact,290,11,,,FALSE,FALSE,FALSE,KFC: A Scalable Approximation Algorithm for $k$−center Fair Clustering,Algorithms -> Clustering,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology'}",1,0,0,{'China'}
Leveraging  Predictions in Smoothed Online Convex Optimization via Gradient-based Algorithms,"Yingying Li, Na Li",Leveraging Predictions in Smoothed Online Convex Optimization via Gradient-based Algorithms,a6e4f250fb5c56aaf215a236c64e5b0a,https://proceedings.neurips.cc/paper/2020/file/a6e4f250fb5c56aaf215a236c64e5b0a-Paper.pdf,"This paper conducts foundational research and theoretical study on online (real-time) decision making problems. In particular, we propose an online algorithm that leverages noisy predictions in online decision making with coupling among stages. This work can be potentially applied to real-time planning problems in e.g. data center management, robotics, smart grids, smart buildings, transportation systems, as well as other online control applications. Though the algorithm is promising and the analysis is insightful, the results are limited by the theoretical assumptions and should be carefully tested and adjusted before being used in real systems. Further, this paper focuses on the efficiency (i.e. the dynamic regret) and does not consider societal issues such as fairness and privacy. Lastly, we see no ethical concerns on this paper.",Broader Impact,124,6,,,FALSE,FALSE,FALSE,Leveraging  Predictions in Smoothed Online Convex Optimization via Gradient-based Algorithms,Algorithms -> Online Learning,Reinforcement Learning and Planning -> Decision and Control,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yingying Li', ' Na Li']",{'Harvard University'},1,0,0,{'USA'}
Learning the Linear Quadratic Regulator from Nonlinear Observations,"Zakaria Mhammedi, Dylan J. Foster, Max Simchowitz, Dipendra Misra, Wen Sun, Akshay Krishnamurthy, Alexander Rakhlin, John Langford",Learning the Linear Quadratic Regulator from Nonlinear Observations,a70145bf8b173e4496b554ce57969e24,https://proceedings.neurips.cc/paper/2020/file/a70145bf8b173e4496b554ce57969e24-Paper.pdf,"There is potential for research into the RichLQR setting, or more generally perception-based control, to have significant societal impact. Perception-based control systems are already being deployed in applications such as autonomous driving and aerial vehicles where algorithmic errors can have catas- trophic consequences. Unfortunately, there has been little research into the theoretical foundations of such systems, and so the methods being deployed do not enjoy the formal guarantees that we should demand for high-stakes applications. Thus, we are hopeful that with a principled understanding of the foundations of perception-based control, which we pursue here, we will develop the tools and techniques to make these systems safe, robust, and reliable.",Broader Impact,109,4,,,FALSE,FALSE,FALSE,Learning the Linear Quadratic Regulator from Nonlinear Observations,Theory -> Control Theory,Reinforcement Learning and Planning -> Decision and Control; Theory -> Statistical Learning Theory,,"['Zakaria Mhammedi', ' Dylan Foster', ' Max Simchowitz', ' Wen Sun', ' Dipendra Misra', ' Akshay Krishnamurthy', ' Alexander Rakhlin', ' John Langford']","{'The Australian National University', 'Microsoft Research NYC', 'Microsoft Research New York', 'Microsoft', 'Berkeley', 'MIT'}",1,1,1,"{'Australia', 'USA'}"
Reconciling Modern Deep Learning with Traditional Optimization Analyses: The Intrinsic Learning Rate,"Zhiyuan Li, Kaifeng Lyu, Sanjeev Arora",Reconciling Modern Deep Learning with Traditional Optimization Analyses: The Intrinsic Learning Rate,a7453a5f026fb6831d68bdc9cb0edcae,https://proceedings.neurips.cc/paper/2020/file/a7453a5f026fb6831d68bdc9cb0edcae-Paper.pdf,The observation of this paper may help understanding the generalization of deep learning and make hyper-parameter tuning easier for both researchers and practitioners.,Broader Impact,23,1,FALSE,FALSE,FALSE,FALSE,FALSE,Reconciling Modern Deep Learning with Traditional Optimization Analyses: The Intrinsic Learning Rate,Deep Learning -> Analysis and Understanding of Deep Networks,,Deep learning,"['Zhiyuan Li', ' Kaifeng Lyu', ' Sanjeev Arora']","{'Princeton University', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Scalable Graph Neural Networks via Bidirectional Propagation,"Ming  Chen, Zhewei Wei, Bolin Ding, Yaliang Li, Ye Yuan, Xiaoyong Du, Ji-Rong Wen",Scalable Graph Neural Networks via Bidirectional Propagation,a7789ef88d599b8df86bbee632b2994d,https://proceedings.neurips.cc/paper/2020/file/a7789ef88d599b8df86bbee632b2994d-Paper.pdf,"The proposed GBP algorithm addresses the challenge of scaling GNNs on large graphs. We consider this algorithm a general technical and theoretical contribution, without any foreseeable specific impacts. For applications in bioinformatics, computer vision, and natural language processing, applying the GBP algorithm may improve the scalability of existing GNN models. We leave the exploration of other potential impacts to future work.",Broader Impact,61,4,FALSE,TRUE,FALSE,FALSE,FALSE,Scalable Graph Neural Networks via Bidirectional Propagation,Algorithms -> Representation Learning,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Ming Chen', ' Zhewei Wei', ' Bolin Ding', ' Yaliang Li', ' Ye Yuan', ' Xiaoyong Du', 'Rong Wen']","{'Alibaba Group', 'Renmin University of China', ' Beijing Institute of Technology'}",1,1,1,{'China'}
Distribution Aligning Refinery of Pseudo-label for Imbalanced Semi-supervised Learning,"Jaehyung Kim, Youngbum Hur, Sejun Park, Eunho Yang, Sung Ju Hwang, Jinwoo Shin",Distribution Aligning Refinery of Pseudo-label for Imbalanced Semi-supervised Learning,a7968b4339a1b85b7dbdb362dc44f9c4,https://proceedings.neurips.cc/paper/2020/file/a7968b4339a1b85b7dbdb362dc44f9c4-Paper.pdf,"In this paper, we first identify that current state-of-the-art semi-supervised learning (SSL) algorithms can suffer from the class-imbalanced distribution of training data due to the biased prediction toward majority classes. Then, we propose a Distribution Aligning Refinery of Pseudo-label (DARP), which corrects such biased pseudo-labels from any SSL algorithms by solving the proposed optimization based on the knowledge of underlying distribution. While this paper focused on the ordinary classification problem under class-imbalanced distribution, we expect that our work can contribute in a broader way, such as resolving the undesirable bias of deep neural networks (DNNs). Recently, it has been revealed that DNNs are often misled to exploit unintended correlation when the dataset is highly biased, although they achieve state-of-the-art performances on many tasks in artificial intelligence. The lack of de-biased samples might incur this phenomenon, one can address this by gathering such data without labels. However, in this way, the situation can deteriorate, i.e., the bias of DNNs can be severed, as we have identified in this work since the existing SSL algorithms mainly rely on the current prediction. However, by leveraging the prior knowledge, our method provides a safe way for utilizing the unlabeled data in this scenario, so that one can get desired de-biased models. Simultaneously, our work reveals the vulnerability of recent state-of-the-art semi-supervised learning (SSL) algorithms under realistic scenarios. After [30] points out the limitation of current SSL algorithms, especially about the existence of out-of-distribution samples within unlabeled dataset, this scenario is recently considered by many researchers for stepping forward to the real-world application [10, 29]. However, as we have identified in this work, given class-imbalanced distribution can also be problematic. Even this scenario frequently occurs in the real-world, this direction is relatively under-explored so far [38]. Hence, we expect our work can encourage future researchers to focus on this crucial yet unnoticed direction for the application of semi-supervised learning in the real world.",Broader Impact,318,12,,,FALSE,FALSE,FALSE,Distribution Aligning Refinery of Pseudo-label for Imbalanced Semi-supervised Learning,Algorithms -> Semi-Supervised Learning,Deep Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jaehyung Kim', ' Youngbum Hur', ' Sejun Park', ' Eunho Yang', ' Sung Ju Hwang', ' Jinwoo Shin']","{'KAIST, AITRICS', 'Samsung Advanced Institute of Technology', 'KAIST'}",1,1,1,{'South Korea'}
Assisted Learning: A Framework for Multi-Organization Learning,"Xun Xian, Xinran Wang, Jie Ding, Reza Ghanadan",Assisted Learning: A Framework for Multi-Organization Learning,a7b23e6eefbe6cf04b8e62a6f0915550,https://proceedings.neurips.cc/paper/2020/file/a7b23e6eefbe6cf04b8e62a6f0915550-Paper.pdf,"The authors envision the following positive ethical and societal consequences. First, the developed concepts, methods, and theories will potentially benefit fields such as engineering, epidemiology, and biology that often involve multi-organizational collaborations since they may not need to share their private models and data. Second, the work will also benefit the general public, whose private data are often held by various organizations. The authors cannot think of a negative ethical or societal consequence of this work.",Broader Impact,76,4,,,FALSE,FALSE,FALSE,Assisted Learning: A Framework for Multi-Organization Learning,Algorithms -> Regression,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'Google', 'University of Minnesota'}",1,1,1,{'USA'}
The Strong Screening Rule for SLOPE,"Johan Larsson, Malgorzata Bogdan, Jonas Wallin",The Strong Screening Rule for SLOPE,a7d8ae4569120b5bec12e7b6e9648b86,https://proceedings.neurips.cc/paper/2020/file/a7d8ae4569120b5bec12e7b6e9648b86-Paper.pdf,"The predictor screening rules introduced in this article allow for a substantial improvement of the speed of SLOPE. This facilitates application of SLOPE to the identification of important predictors in huge data bases, such as collections of whole genome genotypes in Genome Wide Association Studies. It also paves the way for the implementation of cross-validation techniques and improved efficiency of the Adaptive Bayesian version SLOPE (ABSLOPE [39]), which requires multiple iterations of the SLOPE algorithm. Adaptive SLOPE bridges Bayesian and the frequentist methodology and enables good predictive models with FDR control in the presence of many hyper-parameters or missing data. Thus it addresses the problem of false discoveries and lack of replicability in a variety of important problems, including medical and genetic studies. In general, the improved efficiency resulting from the predictor screening rules will make the SLOPE family of models (SLOPE [3], grpSLOPE [6], and ABSLOPE) accessible to a broader audience, enabling researchers and other parties to fit SLOPE models with improved efficiency. The time required to apply these models will be reduced and, in some cases, data sets that were otherwise too large to be analyzed without access to dedicated high-performance computing clusters can be tackled even with modest computational means. We can think of no way by which these screening rules may put anyone at disadvantage. The methods we outline here do not in any way affect the model itself (other than boosting its performance) and can therefore only be of benefit. For the same reason, we do not believe that the strong rules for SLOPE introduces any ethical issues, biases, or negative societal consequences. In contrast, it is in fact possible that the reverse is true given that SLOPE serves as an alternative to, for instance, the lasso, and has superior model selection properties [10, 39] and lower bias [39].",Broader Impact,304,11,,,FALSE,TRUE,FALSE,The Strong Screening Rule for SLOPE,Algorithms,"Algorithms -> Regression; Algorithms -> Sparsity and Compressed Sensing; Applications; Data, Challenges, Implementations, and Software; Data, Challenges, Implementations, and Software -> Software Toolkits; Optimization; Optimization -> Convex Optimization; Theory; Theory -> High-Dimensional Inference; Theory -> Regularization",Optimization Methods (continuous or discrete),"['Johan Larsson', ' Malgorzata Bogdan', ' Jonas Wallin']","{'University of Wroclaw', 'Lund university', 'Lund University'}",1,0,0,{'Sweden'}
STLnet: Signal Temporal Logic Enforced Multivariate Recurrent Neural Networks,"Meiyi Ma, Ji Gao, Lu Feng, John Stankovic",STLnet: Signal Temporal Logic Enforced Multivariate Recurrent Neural Networks,a7da6ba0505a41b98bd85907244c4c30,https://proceedings.neurips.cc/paper/2020/file/a7da6ba0505a41b98bd85907244c4c30-Paper.pdf,"The approach created in this paper can be broadly applied to the tasks of sequence prediction using RNN models in application domains such as smart cities, smart health, and other CPS-IoT systems. In these systems prediction results are usually used to support monitoring and decision making processes. The goal is to improve the prediction accuracy and, more importantly, guarantee the satisfaction of critical properties. We envision that relevant systems and decision-makers will benefit from this work. In this way smart cities and smart health systems can improve safety and performance, thereby improving daily life and health for people. Failure of the system (i.e., the model produces wrong prediction results) could affect the decisions made based on the results. In practice, even if the prediction results are somewhat inaccurate (e.g., high RMSE), STLnet can still guarantee the satisfaction of key properties.",Broader Impact,140,7,,,FALSE,FALSE,FALSE,STLnet: Signal Temporal Logic Enforced Multivariate Recurrent Neural Networks,Deep Learning -> Recurrent Networks,Algorithms -> Regression; Applications -> Time Series Analysis; Social Aspects of Machine Learning -> AI Safety,Deep learning,"['Meiyi Ma', ' Ji Gao', ' Lu Feng', ' John A Stankovic']",{'University of Virginia'},1,0,0,{'USA'}
Election Coding for Distributed Learning: Protecting SignSGD against Byzantine Attacks,"Jy-yong Sohn, Dong-Jun Han, Beongjun Choi, Jaekyun Moon",Election Coding for Distributed Learning: Protecting SignSGD against Byzantine Attacks,a7f0d2b95c60161b3f3c82f764b1d1c9,https://proceedings.neurips.cc/paper/2020/file/a7f0d2b95c60161b3f3c82f764b1d1c9-Paper.pdf,"Since our scheme uses minimum communication burden across distributed nodes, it is useful for numerous time-sensitive applications including smart traffic systems and anomaly detection in stock markets. Moreover, our work is beneficial for various safety-critical applications that require the highest level of reliability and robustness, including autonomous driving, smart home systems, and healthcare services. In general, the failure in robustifying machine learning systems may cause some serious problems including traffic accidents or identity fraud. Fortunately, the robustness of the suggested scheme is mathematically proved, so that applying our scheme in safety-critical applications would not lead to such problems.",Broader Impact,98,4,,,FALSE,FALSE,FALSE,Election Coding for Distributed Learning: Protecting SignSGD against Byzantine Attacks,Theory -> Information Theory,,"Distributed Machine Learning, Information Theory","['yong Sohn', 'Jun Han', ' Beongjun Choi', ' Jaekyun Moon']","{'Korea Advanced Institute of Science and Technology', 'KAIST'}",1,0,0,{'South Korea'}
Reducing Adversarially Robust Learning to Non-Robust PAC Learning,"Omar Montasser, Steve Hanneke, Nati Srebro",Reducing Adversarially Robust Learning to Non-Robust PAC Learning,a822554e5403b1d370db84cfbc530503,https://proceedings.neurips.cc/paper/2020/file/a822554e5403b1d370db84cfbc530503-Paper.pdf,"Learning predictors that are robust to adversarial perturbations is an important challenge in contem- porary machine learning. Current machine learning systems have been shown to be brittle against different notions of robustness such as adversarial perturbations [Szegedy et al., 2013, Biggio et al., 2013, Goodfellow et al., 2014], and there is an ongoing effort to devise methods for learning predictors that are adversarially robust. As machine learning systems become increasingly integrated into our everyday lives, it becomes crucial to provide guarantees about their performance, even when they are used outside their intended conditions. We already have many tools developed for standard learning, and having a universal wrapper that can take any standard learning method and turn it into a robust learning method could greatly simplify the development and deployment of learning that is robust to test-time adversarial perturbations. The results that we present in this paper are still mostly theoretical, and limited to the realizable setting, but we expect and hope they will lead to further theoretical study as well as practical methodological development with direct impact on applications. In this work we do not deal with training-time adversarial attacks, which is a major, though very different, concern in many cases. As with any technology, having a more robust technology can have positive and negative societal consequences, and this depends mainly on how such technology is utilized. Our intent from this research is to help with the design of robust machine learning systems for application domains such as healthcare and transportation where its critical to ensure performance guarantees even outside intended conditions. In situations where there is a tradeoff between robustness and accuracy, this work might be harmful in that it would prioritize robustness over accuracy and this may not be ideal in some application domains.",Broader Impact,296,9,,,FALSE,FALSE,FALSE,Reducing Adversarially Robust Learning to Non-Robust PAC Learning,Algorithms -> Adversarial Learning,Theory -> Computational Learning Theory; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Omar Montasser', ' Steve Hanneke', ' Nati Srebro']","{'Toyota Technological Institute at Chicago', 'TTI-Chicago'}",1,1,1,"{'USA', 'Israel'}"
Top-k Training of GANs: Improving GAN Performance by Throwing Away Bad Samples,"Samarth Sinha, Zhengli Zhao, Anirudh Goyal ALIAS PARTH GOYAL, Colin A. Raffel, Augustus Odena",Top-k Training of GANs: Improving GAN Performance by Throwing Away Bad Samples,a851bd0d418b13310dd1e5e3ac7318ab,https://proceedings.neurips.cc/paper/2020/file/a851bd0d418b13310dd1e5e3ac7318ab-Paper.pdf,"In this paper we present a simple yet effective GAN training technique, which significantly improves the performance of many GAN variant while adding almost no additional training cost. This method can be useful for any practical application where GAN training can be useful, such as Computer Graphics. It can be used to boost GAN performance, and therefore help artists and content creators with their designs and creations. Our technique can also be useful when there is only a small amount of training data available for training, as training GANs on the data can help generate synthetic data, which the model can then use to train.",Broader Impact,105,4,,,FALSE,FALSE,FALSE,Top-k Training of GANs: Improving GAN Performance by Throwing Away Bad Samples,Deep Learning -> Generative Models,,,"['Samarth Sinha', ' Zhengli Zhao', ' Anirudh Goyal ALIAS PARTH GOYAL', ' Colin A Raffel', ' Augustus Odena']","{'Google Brain', 'University of Toronto, Vector Institute', 'UCI, Google Brain', 'Université de Montréal'}",1,1,1,"{'Canada', 'USA'}"
Black-Box Optimization with Local Generative Surrogates,"Sergey Shirobokov, Vladislav Belavin, Michael Kagan, Andrei Ustyuzhanin, Atilim Gunes Baydin",Black-Box Optimization with Local Generative Surrogates,a878dbebc902328b41dbf02aa87abb58,https://proceedings.neurips.cc/paper/2020/file/a878dbebc902328b41dbf02aa87abb58-Paper.pdf,"This work presents a method for black-box optimization, targeting situations where the black box is a stochastic simulator that is costly to evaluate. This work could impact scientific and engineering disciplines, which frequently need to optimize objectives represented by simulators, for instance for experiment design and design optimization. Such types of optimization often arise in fields including physics, biology, and chemistry. Speeding up such computations could lead to faster iteration of optimization cycles and reduce human intervention, thus providing faster discoveries and more efficient design of experimental apparatus. Any biases present in the simulator will also likely be present in the learned surrogate, and therefore could lead to negative outcomes. Careful analysis of the simulator and the optimization solution is required by domain experts to avoid any negative outcomes.",Broader Impact,129,6,,,FALSE,FALSE,FALSE,Black-Box Optimization with Local Generative Surrogates,Optimization,Applications; Deep Learning -> Generative Models; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Sergey Shirobokov', ' Vladislav Belavin', ' Michael Kagan', ' Andrei Ustyuzhanin', ' Atilim Gunes Baydin']","{'National Research University Higher School of Economics', 'SLAC / Stanford', 'University of Oxford', 'Imperial College London'}",1,0,0,"{'UK', 'USA', 'Russia'}"
Efficient Generation of Structured Objects with Constrained Adversarial Networks,"Luca Di Liello, Pierfrancesco Ardino, Jacopo Gobbi, Paolo Morettin, Stefano Teso, Andrea Passerini",Efficient Generation of Structured Objects with Constrained Adversarial Networks,a87c11b9100c608b7f8e98cfa316ff7b,https://proceedings.neurips.cc/paper/2020/file/a87c11b9100c608b7f8e98cfa316ff7b-Paper.pdf,"Broadly speaking, this work aims at improving the reliability of structures / configurations generated via machine learning approaches. This can have a strong impact on a wide range of research fields and application domains, from drug design and protein engineering to layout synthesis and urban planning. Indeed, the lack of reliability of machine-generated outcomes is one of main obstacles to a wider adoption of machine learning technology in our societies. On the other hand, there is a risk of overestimating the reliability of the outputs of CANs, which are only guaranteed to satisfy constraints in expectation. For applications in which invalid structures should be avoided, like safety-critical applications, the objects output by CANs should always be validated before use. From an artificial intelligence perspective, this work supports the line of thought that in order to overcome the current limitations of AI there is a need for combining machine learning and especially deep learning technology with approaches from knowledge representation and automated reasoning, and that principled ways to achieve this integration should be pursued.",Broader Impact,173,6,,,FALSE,FALSE,FALSE,Efficient Generation of Structured Objects with Constrained Adversarial Networks,Deep Learning -> Adversarial Networks,Algorithms -> Relational Learning; Algorithms -> Structured Prediction; Deep Learning -> Generative Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Luca Di Liello', ' Pierfrancesco Ardino', ' Jacopo Gobbi', ' Paolo Morettin', ' Stefano Teso', ' Andrea Passerini']","{'Università degli Studi di Trento', 'University of Trento'}",1,0,0,{'Italy'}
Hard Example Generation by Texture Synthesis for Cross-domain Shape Similarity Learning,"Huan Fu, Shunming Li, Rongfei Jia, Mingming Gong, Binqiang Zhao, Dacheng Tao",Hard Example Generation by Texture Synthesis for Cross-domain Shape Similarity Learning,a87d27f712df362cd22c7a8ef823e987,https://proceedings.neurips.cc/paper/2020/file/a87d27f712df362cd22c7a8ef823e987-Paper.pdf,"Based on our knowledge, our work may not have an adverse impact on ethical aspects and future societal consequences. With the growing number of 3D shapes, the studies of cross-domain image- based shape retrieval (IBSR) is significant. We thus believe our work in this paper may have a positive impact on related subjects and techniques. For example, it can help to build 3D virtual scenes for real-world houses by accurately identify the exact 3D shapes contained in the captured 2D scene images. Furthermore, designers may be able to develop their required 3D CAD models based on the retrieved highly similar 3D shapes instead of drawing 3D shapes from scratches. High-performing IBSR systems may also inspire and benefit studies in 3D object reconstruction from large-scale shape collections.",Broader Impact Statement,126,6,,,FALSE,FALSE,FALSE,Hard Example Generation by Texture Synthesis for Cross-domain Shape Similarity Learning,Applications -> Computer Vision,Deep Learning -> Embedding Approaches,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Shunming Li', ' Huan Fu', ' Rongfei Jia', ' Mingming Gong', ' Binqiang Zhao', ' Dacheng Tao']","{'Alibaba Group', 'University of Sydney', 'University of Melbourne', 'Alibaba Corp'}",1,1,1,"{'Australia', 'USA', 'China'}"
Recovery of sparse linear classifiers from mixture of responses,"Venkata Gandikota, Arya Mazumdar, Soumyabrata Pal",Recovery of sparse linear classifiers from mixture of responses,a89b71bb5227c75d463dd82a03115738,https://proceedings.neurips.cc/paper/2020/file/a89b71bb5227c75d463dd82a03115738-Paper.pdf,"This paper is a theoretical study that brings together two seemingly disjoint but equally impact- ful fields of sparse recovery and mixture models: the first having numerous applications in signal processing while the second being the main statistical model for clustering. Given that, this work belongs to the foundational area of data science and enhances our understanding of some basic the- oretical questions. We feel the methodology developed in this paper is instructive, and exemplifies the use of several combinatorial objects and techniques in signal recovery and classification, that are hitherto underused. Therefore we foresee the technical content of this paper to form good teach- ing material in foundational data science and signal processing courses. The content of this paper can raise interest of students or young researchers in discrete mathematics to applications areas and problems of signal processing and machine learning. While primarily of theoretical interest, the results of the paper can be immediately applicable to some real-life scenarios and be useful in recommendation systems, one of the major drivers of data science research. In particular, if in any case of feedback/rating from users of a service there is ambiguity about the source of the feedback, our framework can be used. This is also applicable to crowdsourcing applications.",Broader Impact,209,8,,,FALSE,TRUE,FALSE,Recovery of sparse linear classifiers from mixture of responses,Algorithms -> Sparsity and Compressed Sensing,Algorithms -> Active Learning; Algorithms -> Classification; Theory -> Information Theory,Theory (including computational and statistical analyses),"['Venkata Gandikota', ' Arya Mazumdar', ' Soumyabrata Pal']","{'University of Massachusetts, Amherst', 'University of Massachusetts Amherst'}",1,0,0,{'USA'}
Efficient Distance Approximation for Structured High-Dimensional Distributions via Learning,"Arnab Bhattacharyya, Sutanu Gayen, Kuldeep S Meel, N. V.  Vinodchandran",Efficient Distance Approximation for Structured High-Dimensional Distributions via Learning ∗,a8acc28734d4fe90ea24353d901ae678,https://proceedings.neurips.cc/paper/2020/file/a8acc28734d4fe90ea24353d901ae678-Paper.pdf,"This work presents basic algorithms for approximating distances between two high dimensional distributions. While the results are theoretical in nature and do not present any immediate societal consequences, the algorithms have potential to impact practice in the long term.",Broader Impact,39,2,FALSE,TRUE,TRUE,TRUE,FALSE,Efficient Distance Approximation for Structured High-Dimensional Distributions via Learning,Theory -> High-Dimensional Inference,Probabilistic Methods -> Bayesian Nonparametrics; Probabilistic Methods -> Causal Inference; Probabilistic Methods -> Graphical Models; Theory -> Computational Learning Theory; Theory -> Frequentist Statistics,Probabilistic methods and inference,"['Arnab Bhattacharyya', ' Sutanu Gayen', ' Kuldeep S Meel', ' Vinodchandran']","{'University of Nebraska', 'National University of SIngapore', 'National University of Singapore'}",1,0,0,{'Singapore'}
A Single Recipe for Online Submodular Maximization with Adversarial or Stochastic Constraints,"Omid Sadeghi, Prasanna Raut, Maryam Fazel",A Single Recipe for Online Submodular Maximization with Adversarial or Stochastic Constraints,a8e5a72192378802318bf51063153729,https://proceedings.neurips.cc/paper/2020/file/a8e5a72192378802318bf51063153729-Paper.pdf,"This theoretical paper studies online, sequential decision making with rewards and limited re- sources/budgets, with broad applications. The general idea of our algorithms is to be conservative enough in their resource use to guard against future unknowns, yet not miss too many opportunities over time, and to allocate limited resources better. There are many online resource allocation problems that could be cast in our framework (see Section 3.1), however, we believe that this work does not raise any potential ethical concerns.",Broader Impact,81,3,,,FALSE,FALSE,FALSE,A Single Recipe for Online Submodular Maximization with Adversarial or Stochastic Constraints,Algorithms -> Online Learning,Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization; Optimization -> Submodular Optimization,Optimization Methods (continuous or discrete),"['Omid Sadeghi', ' Prasanna Raut', ' Maryam Fazel']",{'University of Washington'},1,0,0,{'USA'}
Learning Sparse Prototypes for Text Generation,"Junxian He, Taylor Berg-Kirkpatrick, Graham Neubig",Learning Sparse Prototypes for Text Generation,a8ef1979aeec2737ae3830ec543ed0df,https://proceedings.neurips.cc/paper/2020/file/a8ef1979aeec2737ae3830ec543ed0df-Paper.pdf,"Our approach is likely to benefit researchers or practitioners who are interested in generating text through machines in practical scenarios such as writing news articles given facts, describing stock trends with stock data, generating headlines, etc. Many such applications have a small number of templates for generated text. On the one hand, our model is able to automatically induce those representative prototypes from a large corpus, helping knowing the salient prototypes or templates to help human writers to start with. On the other hand, our approach can be easily extended to these conditional text generation task directly, for example, with the edit vector depending on the input data instead of from a uniform distribution. Such way potentially allows our model to control the prototypes and directly generate text conditioned on the input data as well. Furthermore, the prototype library may be further explored in other formats in addition to training examples, opening a door to more flexible control under different notions of “prototypes”. With respect to possible disadvantages from this research from a societal perspective, as a contribution to the widely studied field of language modeling, the proposed method inherits some of the risks of the field as a whole. These may include models being used maliciously to create fake content (Zellers et al., 2019), or models being used in earnest being manipulated through adversarial attacks to generate undesirable or defamatory content (Wallace et al., 2019). With respect to the latter, as our method is more interpretable due to its use of readable prototypes, we actually expect that it may be more robust to adversarial attacks, and these attacks may be easier for human auditors to detect or defuse when they occur. However, this is speculation, and would have to be confirmed by further experiments.",Broader Impact,295,10,,,TRUE,TRUE,FALSE,Learning Sparse Prototypes for Text Generation,Applications -> Natural Language Processing,Deep Learning -> Generative Models,Natural language processing,"['Junxian He', 'Kirkpatrick', ' Graham Neubig']","{'University of California San Diego', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Implicit Rank-Minimizing Autoencoder,"Li Jing, Jure Zbontar, yann lecun",Implicit Rank-Minimizing Autoencoder,a9078e8653368c9c291ae2f8b74012e7,https://proceedings.neurips.cc/paper/2020/file/a9078e8653368c9c291ae2f8b74012e7-Paper.pdf,"This work provides a novel approach to representation learning and self-supervised learning. It has the potential of boosting general self-supervised learning performances with social benefits including requiring less human data labeling, reducing power consumption of AI models, improving data privacy.",Broader Impact,40,2,FALSE,FALSE,FALSE,FALSE,FALSE,Implicit Rank-Minimizing Autoencoder,Algorithms -> Representation Learning,Deep Learning -> Deep Autoencoders,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Li Jing', ' Jure Zbontar', ' yann lecun']","{'Facebook', 'Facebook AI Research'}",0,1,0,{'USA'}
Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning,"Jianda Chen, Shangyu Chen, Sinno Jialin Pan",Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning,a914ecef9c12ffdb9bede64bb703d877,https://proceedings.neurips.cc/paper/2020/file/a914ecef9c12ffdb9bede64bb703d877-Paper.pdf,This work is basic research on neural networks compression. We believe this is not applicable to our work.,Broader Impact,18,2,TRUE,FALSE,FALSE,FALSE,FALSE,Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning,Deep Learning,,Deep learning,"['Jianda Chen', ' Shangyu Chen', ' Sinno Jialin Pan']","{'Nanyang Technological University', 'Nanyang Technological University, Singapore'}",1,0,0,"{'Singapore', 'China'}"
Task-Oriented Feature Distillation,"Linfeng Zhang, Yukang Shi, Zuoqiang Shi, Kaisheng Ma, Chenglong Bao",Task-Oriented Feature Distillation,a96b65a721e561e1e3de768ac819ffbb,https://proceedings.neurips.cc/paper/2020/file/a96b65a721e561e1e3de768ac819ffbb-Paper.pdf,"The proposed TOFD is a novel knowledge distillation method, which can be utilized in the training of all kinds of neural networks. Since TOFD is not designed for a specific application, it’s impact on the society may not be very obvious. Its potential impact can be summarized as follows. Positive. TOFD can be utilized to compress and accelerate the neural networks or improve their accuracy. As a result, it can facilitate the computer vision application in resource-limited edge devices, such as mobile phones, self-driving cars and embedding devices and so on. Moreover, by reducing the size of neural networks, TOFD can reduce the energy consumption of neural networks, making them more environment-friendly. Negative. Unfortunately, computer vision techniques, if used improperly, or without permission, may have the potential for violation of image rights. This should be regularized by law.",Broader Impact,138,10,,,TRUE,TRUE,FALSE,Task-Oriented Feature Distillation,Deep Learning -> Efficient Inference Methods,Algorithms -> Classification; Algorithms -> Representation Learning,Deep learning,"['Linfeng Zhang', ' Yukang Shi', ' Zuoqiang Shi', ' Kaisheng Ma', ' Chenglong Bao']","{'Tsinghua University', 'Tsinghua university'}",1,0,0,{'China'}
Entropic Causal Inference: Identifiability and Finite Sample Results,"Spencer Compton, Murat Kocaoglu, Kristjan Greenewald, Dmitriy Katz",Entropic Causal Inference: Identifiability and Finite Sample Results,a979ca2444b34449a2c80b012749e9cd,https://proceedings.neurips.cc/paper/2020/file/a979ca2444b34449a2c80b012749e9cd-Paper.pdf,"Determining causal direction from data has numerous applications. The main challenge in using purely observational data for causal inference always lies in the set of assumptions that are made. Especially for safety-critical applications, the assumptions should be very carefully evaluated. In this work, we use the assumption that the exogenous variables have small entropy. This means that the factors which affect the effect variable have only a small number of states that are active, relative to the number of active states of the cause and effect variables. Only then there is some structure in the probability distribution in the context of entropic causality. Otherwise, the structure disappears and the approach will be unreliable. In an application, this assumption should first be evaluated by the field experts. If the expert believes this assumption might be violated, other observational methods that rely on a different set of assumptions should be used instead.",Broader Impact,150,9,,,FALSE,FALSE,FALSE,Entropic Causal Inference: Identifiability and Finite Sample Results,Probabilistic Methods -> Causal Inference,Theory -> Information Theory,Causality,"['Spencer Compton', ' Murat Kocaoglu', ' Kristjan Greenewald', ' Dmitriy Katz']","{'IBM Research', 'MIT'}",1,1,1,{'USA'}
Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement,"Ben Eysenbach, XINYANG GENG, Sergey Levine, Russ R. Salakhutdinov",Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement,a97da629b098b75c294dffdc3e463904,https://proceedings.neurips.cc/paper/2020/file/a97da629b098b75c294dffdc3e463904-Paper.pdf,"In this paper, we showed that hindsight relabeling is a form of inverse RL and used this insight to propose algorithms which can effectively share experience for solving multiple tasks. These algorithms may prove valuable in scenarios where data collection is costly or dangerous. Additionally, the use of inverse RL makes our algorithm robust to misspecification in the scale of the reward function (see Sec. 4.2 and Fig. 7b); an adversary cannot bias our algorithm to learn a certain task by scaling the reward for that task. Today, sharing data across tasks remains challenging, so users are forced to collect data anew when they want to solve new tasks. The result is that users with access to robots have an upper-hand in teaching robots to perform new tasks. If we were able to effectively share data across tasks, then this balance of power would shift towards owners of data, rather than owners of robots (though, in many cases, these are one and the same). Indeed, this seems to have been the trend in supervised learning [48]. This risk might be mitigated by sharing data across institutions, as is starting to be done for robot manipulation [9] and autonomous vehicles [4, 6, 27, 46, 49, 57].",Broader Impact,205,10,,,FALSE,FALSE,FALSE,Rewriting History with Inverse RL: Hindsight Inference for Policy Improvement,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Ben Eysenbach', ' Xinyang Geng', ' Sergey Levine', ' Russ Salakhutdinov']","{'Carnegie Mellon University', 'UC Berkeley'}",1,0,0,{'USA'}
Variance-Reduced Off-Policy TDC Learning: Non-Asymptotic Convergence Analysis,"Shaocong Ma, Yi Zhou, Shaofeng Zou",Variance-Reduced Off-Policy TDC Learning: Non-Asymptotic Convergence Analysis,a992995ef4f0439b258f2360dbb85511,https://proceedings.neurips.cc/paper/2020/file/a992995ef4f0439b258f2360dbb85511-Paper.pdf,"This work exploits techniques in multidisciplinary areas including reinforcement learning, stochastic optimization and statistics, and contributes new technical developments to analyze TD learning algorithm under stochastic variance reduction. The proposed two time-scale VRTDC significantly improves the solution quality of TD learning and reduces the variance and uncertainty in training reinforcement learning policies. Therefore it has the potential to be applied to reinforcement learning applications such as autonomous driving, decision making and control to reduce the risk caused by uncertainty of the policy.",Broader Impact,82,3,,,FALSE,FALSE,FALSE,Variance-Reduced Off-Policy TDC Learning: Non-Asymptotic Convergence Analysis,Reinforcement Learning and Planning -> Reinforcement Learning,Optimization; Optimization -> Stochastic Optimization,Reinforcement learning and planning,"['Shaocong Ma', ' Yi Zhou', ' Shaofeng Zou']","{'University at Buffalo, the State University of New York', 'University of Utah'}",1,0,0,{'USA'}
AdaTune: Adaptive Tensor Program Compilation Made Efficient,"Menghao Li, Minjia Zhang, Chi Wang, Mingqin Li",AdaTune: Adaptive Tensor Program Compilation Made Efficient,a9b7ba70783b617e9998dc4dd82eb3c5,https://proceedings.neurips.cc/paper/2020/file/a9b7ba70783b617e9998dc4dd82eb3c5-Paper.pdf,"Machine learning and deep learning applications are becoming ubiquitous in large scale production systems. With that growth and the scaling in model size and complexity, the focus on efficiently executing DNN models has become even greater. The push for increased energy efficiency has led to the emergence of diverse heterogeneous systems and hardware architectures. While it is possible to hire deployment engineers to produce highly optimized code for diverse architectures, such an approach is time-consuming. It requires significant manual effort, which is difficult to scale, as new DNN models and operators are coming out on a regular basis. Compilers have historically been the bridge between programming efficiency and high-performance code, which allows fast innovation while producing high-performance code for diverse architectures. Auto-tuning techniques such as AutoTVM modernize a compiler by automatically learning the compiler’s optimization decisions as opposed to using heuristic rules. However, the actual cost of running such a tuning process is very expensive. Our techniques speed up the auto-tuning process significantly. It improves the agility of deploying DNN models, fostering fast innovations. It also reduces the amount of hardware resources needed for optimizing DNN models, reducing the corresponding energy consumption and carbon footprint produced.",Broader Impact,196,11,,,FALSE,FALSE,FALSE,AdaTune: Adaptive Tensor Program Compilation Made Efficient,Deep Learning -> Efficient Inference Methods,Applications -> Hardware and Systems; Deep Learning -> Optimization for Deep Networks,Deep learning,"['Menghao Li', ' Minjia Zhang', ' Chi Wang', ' Mingqin Li']","{'Microsoft', 'Microsoft Research'}",1,1,1,{'USA'}
When Do Neural Networks Outperform Kernel Methods?,"Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, Andrea Montanari",When Do Neural Networks Outperform Kernel Methods?,a9df2255ad642b923d95503b9a7958d8,https://proceedings.neurips.cc/paper/2020/file/a9df2255ad642b923d95503b9a7958d8-Paper.pdf,"This paper focuses on theoretical aspects of modern machine learning. While we expect the results of this paper to be illuminating for the theory community, we do not anticipate any direct societal impact of our work.",Broader Impact,36,2,TRUE,FALSE,FALSE,FALSE,FALSE,When Do Neural Networks Outperform Kernel Methods?,Theory,Algorithms -> Kernel Methods; Deep Learning; Theory -> Spaces of Functions and Kernels,Theory (including computational and statistical analyses),"['Behrooz Ghorbani', ' Song Mei', ' Theodor Misiakiewicz', ' Andrea Montanari']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
STEER : Simple Temporal Regularization For Neural ODE,"Arnab Ghosh, Harkirat Behl, Emilien Dupont, Philip Torr, Vinay Namboodiri",STEER: Simple Temporal Regularization For Neural ODEs,a9e18cb5dd9d3ab420946fa19ebbbf52,https://proceedings.neurips.cc/paper/2020/file/a9e18cb5dd9d3ab420946fa19ebbbf52-Paper.pdf,"Neural ODEs operate under the broad umbrella of ‘Implicit Methods in Deep Learning’. The last decade in deep learning was characterized by layer based deep neural networks. The limits of that framework are starting to approach whereby one can fit only so many layers in the GPU of a computer. Thus, alternate forms of computational frameworks are emerging whereby the function is not explicitly modeled. Rather a pseudo function is learnt from which the original function that needed to be approximated can be retrieved. This shows a different model of computation and previous work has shown signs that it is much more parameter efficient than resnet based deep neural networks. Our work is in the broad area of Neural ODEs which provides continuous depth neural networks. This line of work would have a similar impact as most supervised deep learning techniques. How- ever,current continuous depth neural networks show limitations that are improved through our proposed regularization scheme. Thus, our models converge faster during training by reducing the number of function evaluations and effective training time. The resulting trained models also require fewer function evaluations at inference, thus reducing the computation at test time too. Our research could potentially encourage the search for more such efficient techniques for training neural ODEs.  Although we have highlighted some drawbacks of existing Neural ODEs in the context of Stiff ODEs. We do not fully understand why our solution works better in the case of stiff ODEs. The issue of stiff ODEs has a rich history of research in engineering. Inevitably during training, there is a possibility that the dynamics learnt by the neural network might be an instance of a stiff equation. This cannot be prevented with the current formulation. As Neural ODEs become more stable and mature we need to understand the effects of stiffness. These models can be truly useful if we understand it from all possible points of failure.",6 Broader Impact,318,19,,,FALSE,FALSE,FALSE,STEER : Simple Temporal Regularization For Neural ODE,Algorithms -> Dynamical Systems,Deep Learning -> Generative Models,Deep learning,"['Arnab Ghosh', ' Harkirat Behl', ' Emilien Dupont', ' Philip Torr', ' Vinay Namboodiri']","{'University of Bath', 'Oxford University', 'University of Oxford'}",1,0,0,{'UK'}
A Variational Approach for Learning from Positive and Unlabeled Data,"Hui Chen, Fangqing Liu, Yin Wang, Liyue Zhao, Hao Wu",A Variational Approach for Learning from Positive and Unlabeled Data,aa0d2a804a3510442f2fd40f2100b054,https://proceedings.neurips.cc/paper/2020/file/aa0d2a804a3510442f2fd40f2100b054-Paper.pdf,"VPU is a general framework for PU learning, and it overcomes some limitations of previous methods, including requirement of class prior known beforehand and data separability, so is more applicable to real-world applications. Thus discussion of the potential impacts of VPU actually leads to the discussion of potential impacts of applications of PU learning itself. With VPU, less labels are needed, which saves cost and improves efficiency. Moreover, VPU is able to mine the negative pattern that is missing in the PU datasets. This will be helpful if finding out the negative pattern is beneficial, such as discovering drugs for diseases and identifying deceptive reviews for recommendation systems. However, malicious tasks can also be conducted with VPU, such as discovery of harmful chemical substance. Another unethical scenario is that sometimes the negative pattern could be hidden on purpose for the sake of privacy or other ethical considerations, but with VPU, people might be able to find out about the hidden information.",Broader Impact,161,7,,,FALSE,FALSE,FALSE,A Variational Approach for Learning from Positive and Unlabeled Data,Algorithms -> Semi-Supervised Learning,Algorithms -> Classification,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Hui Chen', ' Fangqing Liu', ' Yin Wang', ' Liyue Zhao', ' Hao Wu']",{'Tongji University'},1,0,0,{'China'}
Efficient Clustering Based On A Unified View Of KK-means And Ratio-cut,"Shenfei Pei, Feiping Nie, Rong Wang, Xuelong Li",Efficient Clustering Based On A Unified View Of K -means And Ratio-cut,aa108f56a10e75c1f20f27723ecac85f,https://proceedings.neurips.cc/paper/2020/file/aa108f56a10e75c1f20f27723ecac85f-Paper.pdf,Not applicable.,Broader Impact,2,1,TRUE,FALSE,FALSE,FALSE,FALSE,Efficient Clustering Based On A Unified View Of K-means And Ratio-cut,Algorithms -> Clustering,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'University of Texas Arlington', 'Northwestern Polytechnical University'}",1,0,0,"{'USA', 'China'}"
Recurrent Switching Dynamical Systems Models for Multiple Interacting Neural Populations,"Joshua Glaser, Matthew Whiteway, John P. Cunningham, Liam Paninski, Scott Linderman",Recurrent Switching Dynamical Systems Models for Multiple Interacting Neural Populations,aa1f5f73327ba40d47ebce155e785aaf,https://proceedings.neurips.cc/paper/2020/file/aa1f5f73327ba40d47ebce155e785aaf-Paper.pdf,"Understanding neural computation, and the interaction between multiple brain regions, is critical for better treating neurological disorders. Here, we develop an analysis tool that can help to understand multiple populations of neurons, and aims to make progress towards this long-term goal. However, this is a decades-long effort and we foresee no immediate societal consequences of this work.",Broader Impact,57,3,FALSE,TRUE,FALSE,FALSE,FALSE,Recurrent Switching Dynamical Systems Models for Multiple Interacting Neural Populations,Neuroscience and Cognitive Science -> Neuroscience,Algorithms -> Unsupervised Learning; Probabilistic Methods -> Latent Variable Models,Neuroscience and cognitive science,"['Joshua Glaser', ' Matthew Whiteway', ' John Cunningham', ' Liam Paninski', ' Scott Linderman']","{'Columbia', 'Stanford University', 'University of Columbia', 'Columbia University'}",1,0,0,{'USA'}
Coresets via Bilevel Optimization for Continual Learning and Streaming,"Zalán Borsos, Mojmir Mutny, Andreas Krause",Coresets via Bilevel Optimization for Continual Learning and Streaming,aa2a77371374094fe9e0bc1de3f94ed9,https://proceedings.neurips.cc/paper/2020/file/aa2a77371374094fe9e0bc1de3f94ed9-Paper.pdf,"Coresets can efficiently handle large datasets under computational constraints, thus significantly reducing computational costs and possibly the energy consumption for applications. They also provide an avenue towards limiting the amount of data that needs to be stored, with possible privacy benefits. Explicitly optimizing representativeness of the retained samples beyond accuracy (e.g., for counteracting biases in the data) is a promising direction for future work.",Broader Impact,64,3,,,FALSE,FALSE,FALSE,Coresets via Bilevel Optimization for Continual Learning and Streaming,Algorithms,Algorithms -> Communication- or Memory-Bounded Learning; Algorithms -> Continual Learning; Algorithms -> Data Compression; Algorithms -> Multitask and Transfer Learning; Deep Learning; Optimization -> Discrete Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Zalán Borsos', ' Mojmir Mutny', ' Andreas Krause']",{'ETH Zurich'},1,0,0,{'Switzerland'}
Generalized Independent Noise Condition for Estimating Latent Variable Causal Graphs,"Feng Xie, Ruichu Cai, Biwei Huang, Clark Glymour, Zhifeng Hao, Kun Zhang",Generalized Independent Noise Condition for Estimating Latent Variable Causal Graphs,aa475604668730af60a0a87cc92604da,https://proceedings.neurips.cc/paper/2020/file/aa475604668730af60a0a87cc92604da-Paper.pdf,"Causal modeling is a fundamental problem in multiple disciplines of science and data analysis, and causal discovery from observational data has attracted much attention. Existing methods for causal discovery usually assume that there is no confounder (a confounder is a latent direct common cause of two measured variables) or that the confounders for different variables are unrelated. However, it is often the case that observed variables are just reflections of the underlying hidden causal variables, which may be causally related to each other. This is particular true in psychology, neuoscience, and social sciences. Unfortunately, existing methods for finding such latent variables all involve very strong assumptions (e.g., factor analysis assumes that the latent factors are rather low-dimensional and mutually independent), and there is no principle approach to estimating the causal relations between them, especially the causal order. The methodologies and the framework developed in the work have the power to infer the right causal structure, including that over the latent variables, and enable us to correctly understand the systems, which then helps make proper policies, avoid bias or discrimination, and achieve a more transparent and fair world.",Broader Impact,187,6,,,FALSE,FALSE,FALSE,Generalized Independent Noise Condition for Estimating Latent Variable Causal Graphs,Probabilistic Methods -> Causal Inference,,Causality,,"{'Guangdong University of Technology', 'CMU', 'Carnegie Mellon University'}",1,0,0,"{'USA', 'China'}"
Understanding and Exploring the Network with Stochastic Architectures,"Zhijie Deng, Yinpeng Dong, Shifeng Zhang, Jun Zhu",Understanding and Exploring the Network with Stochastic Architectures,aa85e45da94cb0d78853c50ba636a15a,https://proceedings.neurips.cc/paper/2020/file/aa85e45da94cb0d78853c50ba636a15a-Paper.pdf,"This work manages to understand a wide range of properties of the network with stochastic architectures (NSA), and apply it to several challenging tasks to sufficiently exploit its potential. It has the following positive impacts in the society. First, as NSA is a broadly used technique in neural architecture search (NAS), our analyses can provide valuable insights for the following research on NAS. Second, the proposed improvements upon NSA are practically applicable, and NSA with such improvements has shown promise in various scenarios such as ensemble learning and semi-supervised learning. Third, as the architecture stochasticity can be leveraged to provide uncertainty estimates during inference, NSA has a potential to be used in practical applications where the uncertainty measures are crucial, such as finance, automatic driving, etc. At the same time, this work may have some possible negative consequences. For example, just like other NAS works, it would enable searching better neural architectures automatically, which may potentially result in job loss of many researchers and engineers in the future.",Broader Impact,168,7,,,FALSE,TRUE,FALSE,Understanding and Exploring the Network with Stochastic Architectures,Deep Learning -> CNN Architectures,Algorithms -> AutoML; Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Zhijie Deng', ' Yinpeng Dong', ' Shifeng Zhang', ' Jun Zhu']","{'Tsinghua University', 'Department of Computer Science and Technology, Tsinghua University'}",1,0,0,{'China'}
All-or-nothing statistical and computational phase transitions in sparse spiked matrix estimation,"jean barbier, Nicolas Macris, Cynthia Rush",All-or-nothing statistical and computational phase transitions in sparse spiked matrix estimation,aaa5ebec57257fa776a1990c2bd025c1,https://proceedings.neurips.cc/paper/2020/file/aaa5ebec57257fa776a1990c2bd025c1-Paper.pdf,"One cannot underestimate the relevance of sparse estimation in modern technology, and although this work is valid within the limits of a theoretical model, it participates towards better fundamental understanding of necessary resources in terms of energy and quantity of data when this data is sparse. Besides radical transitions in behaviour under small changes of control parameters, we also show that an estimation task can become computationally hard or impossible, even with (practically) unbounded signal strengths. Broadly speaking, such results provide guidelines for better design and less wasteful engineering systems.",Broader impact,90,3,,,FALSE,FALSE,FALSE,All-or-nothing statistical and computational phase transitions in sparse spiked matrix estimation,Theory -> Statistical Physics of Learning,Algorithms -> Sparsity and Compressed Sensing; Applications -> Matrix and Tensor Factorization; Probabilistic Methods -> Bayesian Theory; Theory -> High-Dimensional Inference; Theory -> Information Theory,,"['jean barbier', ' Nicolas Macris', ' Cynthia Rush']","{'Columbia University', 'EPFL'}",1,0,0,"{'USA', 'Switzerland'}"
Deep Evidential Regression,"Alexander Amini, Wilko Schwarting, Ava Soleimany, Daniela Rus",Deep Evidential Regression,aab085461de182608ee9f607f3f7d18f,https://proceedings.neurips.cc/paper/2020/file/aab085461de182608ee9f607f3f7d18f-Paper.pdf,"Uncertainty estimation for neural networks has very significant societal impact. Neural networks are increasingly being trained as black-box predictors and being placed in larger decision systems where errors in their predictions can pose immediate threat to downstream tasks. Systematic methods for calibrated uncertainty estimation under these conditions are needed, especially as these systems are deployed in safety critical domains, such for autonomous vehicle control [29], medical diagnosis [43], or in settings with large dataset imbalances and bias such as crime forecasting [24] and facial recognition [3]. This work is complementary to a large portion of machine learning research which is continually pushing the boundaries on neural network precision and accuracy. Instead of solely optimizing larger models for increased performance, our method focuses on how these models can be equipped with the ability to estimate their own confidence. Our results demonstrating superior calibration of our method over baselines are also critical in ensuring that we can place a certain level of trust in these algorithms and in understanding when they say “I don’t know”. While there are clear and broad benefits of uncertainty estimation in machine learning, we believe it is also important to recognize potential societal challenges that may arise. With increased performance and uncertainty estimation capabilities, humans will inevitably become increasingly trusting in a model’s predictions, as well as its ability to catch dangerous or uncertain decisions before they are executed. Thus, it is important to continue to pursue redundancy in such learning systems to increase the likelihood that mistakes can be caught and corrected independently.",Broader Impact,257,9,,,FALSE,FALSE,FALSE,Deep Evidential Regression,Algorithms -> Uncertainty Estimation,,Deep learning,"['Alexander Amini', ' Wilko Schwarting', ' Ava Soleimany', ' Daniela Rus']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Analytical Probability Distributions and Exact Expectation-Maximization for Deep Generative Networks,"Randall Balestriero, Sebastien PARIS, Richard Baraniuk",Analytical Probability Distributions and Exact Expectation-Maximization for Deep Generative Networks,aaf2979785deb27864047e0ea40ef1b7,https://proceedings.neurips.cc/paper/2020/file/aaf2979785deb27864047e0ea40ef1b7-Paper.pdf,"We have derived the analytical form of the posterior, marginal and conditional distributions of DGNs based on CPA architectures. Our approach provides an approximation-free alternative to VAEs to train DGNs. In addition to improving DGN algorithms, our analytical forms will enable researchers to probe more deeply into the inner workings of DGNs and VAE, making them more interpretable and thus trustworthy. Our calculations will also enable accurate anomaly detection and model selection, which should find wide application in sensitive applications where accurately computing the probability of a data point is crucial.",Broader Impacts,91,4,,,FALSE,FALSE,FALSE,Analytical Probability Distributions and Exact Expectation-Maximization for Deep Generative Networks,Probabilistic Methods -> Graphical Models,"Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Generative Models; Deep Learning -> Visualization, Interpretability, and Explainability",Probabilistic methods and inference,,"{'University of Toulon', 'Rice University'}",1,0,0,{'USA'}
Bayesian Pseudocoresets,"Dionysis Manousakas, Zuheng Xu, Cecilia Mascolo, Trevor Campbell",Bayesian Pseudocoresets,ab452534c5ce28c4fbb0e102d4a4fb2e,https://proceedings.neurips.cc/paper/2020/file/ab452534c5ce28c4fbb0e102d4a4fb2e-Paper.pdf,"Pseudocoreset variational inference is a general-purpose Bayesian inference algorithm, hence shares implications mostly encountered in approximate inference methods. For example, replacing the full dataset with a pseudocoreset has the potential to cause inferential errors; these can be partially tempered by using a pseudocoreset of larger size. Note also that the optimization algorithm in this work aims to reduce KL divergence: however the proposed variational objective might be misleading in many applications and lead to incorrect conclusions in certain statistical models (e.g. point estimates and uncertainties might be far off despite KL being almost zero [24]). Moreover, Bayesian inference in general is prone to model misspecification. Therefore, a pseudocoreset summarization based on a wrong statistical model will lead to non-representative compression for inferential purposes. Constructing the coreset on a statistical model suited for robust inference instead of the original one [31, 40], can offer protection against modelling mismatches. Naturally, the utility of generated dataset summary becomes task-dependent, as it has been optimized for a specific learning objective, and cannot be fully transferable to multiple different inference tasks on the same dataset. Our learnable pseudodata are also generally not as interpretable as the points of previous coreset methods, as they are not real data. And the level of interpretability is model specific. This creates a risk of misinterpretation of pseudocoreset points in practice. On the other hand, our optimization framework does allow the introduction of interpretability constraints (e.g. pseudodata sparsity) to explicitly capture interpretability requirements. Pseudocoreset-based summarization is susceptible to reproducing potential biases and unfairness existing in the original dataset. Majority-group datapoints in the full dataset which capture information relevant to the statistical task of interest are expected to remain over-represented in the learned summary; while minority-group datapoints might be eliminated, if their distinguishing features are not related to inference. Amending the initialization step to contain such datapoints, or using a prior that strongly favors a debiased version of the dataset, could both mitigate these concerns; but more study is warranted.",Broader Impact,329,14,,,TRUE,TRUE,FALSE,Bayesian Pseudocoresets,Algorithms -> Large Scale Learning,"Algorithms -> Data Compression; Optimization -> Stochastic Optimization; Probabilistic Methods -> Variational Inference; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security; Theory -> High-Dimensional Inference",Probabilistic methods and inference,"['Dionysis Manousakas', ' Zuheng Xu', ' Cecilia Mascolo', ' Trevor Campbell']","{'University of Cambridge', 'UBC', 'University of British Columbia'}",1,0,0,"{'Canada', 'UK', 'Singapore'}"
"See, Hear, Explore: Curiosity via Audio-Visual Association","Victoria Dean,  Shubham Tulsiani, Abhinav Gupta","See, Hear, Explore: Curiosity via Audio-Visual Association",ab6b331e94c28169d15cca0cb3bbc73e,https://proceedings.neurips.cc/paper/2020/file/ab6b331e94c28169d15cca0cb3bbc73e-Paper.pdf,"The lasting impact of RL will be from these algorithms working in the real world. As such, our work is centered around increasing sample efficiency and adaptability. By leveraging self-supervision, we can avoid cumbersome reward shaping, which becomes exponentially more difficult as tasks grow more complex. Although our work here uses simulated agents, our longer-term goal is to deploy multimodal curiosity on physical robots, enabling them to explore in a more sample-efficient manner. Multimodal learning could have a near-immediate impact in autonomous driving, where different sensory modalities are used for perception of near, far, small, and large entities. Autonomous RL agents have many potential positive outcomes, such as home robots aiding elderly people or those with disabilities. They will save time and money in many sectors of industry. However, they also have the potential to displace parts of the workforce [43]. There could be privacy concerns if merged multimodal data is hard to anonymize or de-identify. There could also be privacy concerns with respect to recording audio data in the wild [44]. With unsupervised RL, it can be hard to predict what behaviors will be learned. For example, a robot using our algorithm might learn to damage sensors to create novel associations. The inability to predict agent behavior can make ensuring safety difficult, which would have consequences in safety-critical settings like autonomous driving or healthcare. Some work has been done on safety in RL [45], and there is more to be done, especially on analyzing the safety of RL exploration policies during training.",Broader Impact,253,14,,,FALSE,FALSE,FALSE,"See, Hear, Explore: Curiosity via Audio-Visual Association",Reinforcement Learning and Planning -> Exploration,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Victoria Dean', ' Shubham Tulsiani', ' Abhinav Gupta']","{'Facebook AI Research', 'Facebook AI Research/CMU', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Adversarial Training is a Form of Data-dependent Operator Norm Regularization,"Kevin Roth, Yannic Kilcher, Thomas Hofmann",Adversarial Training is a Form of Data-dependent Operator Norm Regularization,ab7314887865c4265e896c6e209d1cd6,https://proceedings.neurips.cc/paper/2020/file/ab7314887865c4265e896c6e209d1cd6-Paper.pdf,"The existence of adversarial examples, i.e. small perturbations of the input signal, often imperceptible to humans, that are sufficient to induce large changes in the model output, poses a real danger when deep neural networks are deployed in the real world, as potentially safety-critical machine learning systems become vulnerable to attacks that can alter the system’s behaviour in malicious ways. Understanding the origin of this vulnerability and / or acquiring an understanding of how to robustify deep neural networks against such attacks thus becomes crucial for a safe and responsible deployment of machine learning systems. Who may benefit from this research Our work contributes to understanding the origin of this vulnerability in that it sheds new light onto the attack algorithms used to find adversarial examples. It also contributes to building robust machine learning systems in that it allows practitioners to make more informed and well-founded decisions when training robust models. Who may be put at a disadvantage from this research Our work, like any theoretical work on adversarial examples, may increase the level of understanding of a malevolent person intending to mount adversarial attacks against deployed machine learning systems which may ultimately put the end-users of these systems at risk. We would like to note, however, that the attack algorithms we analyze in our work already exist and that we believe that the knowledge gained from our work is more beneficial to making models more robust than it could possibly be used to designing stronger adversarial attacks. Consequences of failure of the system Our work does not by itself constitute a system of any kind, other than providing a rigorous mathe- matical framework within which to better understand adversarial robustness.",Broader Impact,281,7,,,FALSE,FALSE,FALSE,Adversarial Training is a Form of Data-dependent Operator Norm Regularization,Algorithms -> Adversarial Learning,Algorithms -> Spectral Methods; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Optimization for Deep Networks; Theory; Theory -> Regularization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Kevin Roth', ' Yannic Kilcher', ' Thomas Hofmann']",{'ETH Zurich'},1,0,0,{'Switzerland'}
A Biologically Plausible Neural Network for Slow Feature Analysis,"David Lipshutz, Charles Windolf, Siavash Golkar, Dmitri Chklovskii",A biologically plausible neural network for Slow Feature Analysis,ab73f542b6d60c4de151800b8abc0a6c,https://proceedings.neurips.cc/paper/2020/file/ab73f542b6d60c4de151800b8abc0a6c-Paper.pdf,An important problem in neuroscience is to understand the computational principles the brain uses to process information. Progress on this front has the potential to have wide ranging benefits for helping to manage the adverse effects of neurological diseases and disorders. This work represents a small step in that direction.,Broader impact,50,3,FALSE,FALSE,FALSE,FALSE,FALSE,A Biologically Plausible Neural Network for Slow Feature Analysis,Neuroscience and Cognitive Science -> Neuroscience,Algorithms -> Online Learning; Applications -> Time Series Analysis,Neuroscience and cognitive science,"['David Lipshutz', ' Charles Windolf', ' Siavash Golkar', ' Dmitri Chklovskii']","{'Flatiron Institute, Simons Foundation', 'Flatiron Institute'}",1,0,0,{'USA'}
Learning Feature Sparse Principal Subspace,"Lai Tian, Feiping Nie, Rong Wang, Xuelong Li",Learning Feature Sparse Principal Subspace,ab7a710458b8378b523e39143a6764d6,https://proceedings.neurips.cc/paper/2020/file/ab7a710458b8378b523e39143a6764d6-Paper.pdf,"This paper provides efficient, effective, and provable algorithms to solve the feature sparse PCA problem. The researcher who working on feature selection, dimension reduction, and graph analysis might find the techniques in this paper interesting and highly usable for real-world applications.",Broader Impact,41,2,FALSE,FALSE,FALSE,FALSE,FALSE,Learning Feature Sparse Principal Subspace,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)",Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Lai Tian', ' Feiping Nie', ' Rong Wang', ' Xuelong Li']","{'University of Texas Arlington', 'Northwestern Polytechnical University'}",1,0,0,"{'USA', 'China'}"
Online Adaptation for Consistent Mesh Reconstruction in the Wild,"Xueting Li, Sifei Liu, Shalini De Mello, Kihwan Kim, Xiaolong Wang, Ming-Hsuan Yang, Jan Kautz",Online Adaptation for Consistent Mesh Reconstruction in the Wild,aba3b6fd5d186d28e06ff97135cade7f,https://proceedings.neurips.cc/paper/2020/file/aba3b6fd5d186d28e06ff97135cade7f-Paper.pdf,"The developed method will make significant contributions to both the 3D vision and endangered species research. The method provides a way to study animals that can only be captured in the wild as 2D videos, e.g., endangered animal species of birds and zebras. The broader impact includes enhancing our understanding of such endangered animals simply from videos, as they can be reconstructed and viewed in 3D. The method can also be applied to tasks such as bird watching, motion analysis, shape analysis, to name a few. Furthermore, another important application is to simplify an artists workflow, as an initial animated and textured 3D shape can be directly derived from a video.",Broader Impact,111,5,,,FALSE,FALSE,FALSE,Online Adaptation for Consistent Mesh Reconstruction in the Wild,Applications -> Computer Vision,Applications -> Video Analysis,Vision,"['Xueting Li', ' Sifei Liu', ' Shalini De Mello', ' Kihwan Kim', ' Xiaolong Wang', 'Hsuan Yang', ' Jan Kautz']","{'UCSD/UC Berkeley', 'Google / UC Merced', 'NVIDIA', 'University of California, Merced'}",1,1,1,{'USA'}
Online learning with dynamics: A minimax perspective,"Kush Bhatia, Karthik Sridharan",Online learning with dynamics: A minimax perspective,abb451a12cf1a9d93292e81f0d4fdd7a,https://proceedings.neurips.cc/paper/2020/file/abb451a12cf1a9d93292e81f0d4fdd7a-Paper.pdf,"This work is mainly theoretical in nature and hopes to provide theoretical foundations for learning under dynamical systems. The work is expected to have a broader impact in the future by opening up research on learning and non-linear dynamical systems with complex policy classes. In the future, we hope that our work will enable ML systems to be deployed reliably in more reactive environments.",Broader Impact,64,3,,,FALSE,FALSE,FALSE,Online learning with dynamics: A minimax perspective,Algorithms -> Online Learning,Theory,Theory (including computational and statistical analyses),"['Kush Bhatia', ' Karthik Sridharan']","{'UC Berkeley', 'Cornell University'}",1,0,0,{'USA'}
Learning to Select Best Forecast Tasks for Clinical Outcome Prediction,"Yuan Xue, Nan Du, Anne Mottram, Martin Seneviratne, Andrew M. Dai",Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction,abc99d6b9938aa86d1f30f8ee0fd169f,https://proceedings.neurips.cc/paper/2020/file/abc99d6b9938aa86d1f30f8ee0fd169f-Paper.pdf,"This work presents a method for efficiently learning patient representations using EMR data. Although this is demonstrated with a subset of the full raw EMR, and for only a handful of clinical outcomes in intensive care patients, it is a proof-of-concept that may be useful for a range of other predictive modeling using various types of longitudinal health data. The impact may be greatest in low-data scenarios - e.g. clinical use-cases where labeling is very challenging or where there are few eligible patients in the EMR. The code for this method will be made available to the research community on GitHub. There are numerous ethical considerations associated with any EMR modeling, which have been discussed in the literature [38, 39]. Issues include numerous biases in the observational EMR data, e.g. on the basis of gender, ethnicity or socioeconomic status, which can propagate into predictive models. These fairness considerations also apply to representation learning architectures as presented here. Finally, if this method were to be brought forward to real world deployment in conjunction with a decision support tool, it would have to be subject to appropriate clinical safety review and trials across different populations, with consideration given to issues such as drift and robustness.",7 Broader Impact,203,8,,,FALSE,FALSE,FALSE,Learning to Select Best Forecast Tasks for Clinical Outcome Prediction,Applications -> Health,Algorithms -> Meta-Learning; Algorithms -> Multitask and Transfer Learning; Applications -> Time Series Analysis,,"['Yuan Xue', ' Nan Du', ' Anne Mottram', ' Martin Seneviratne', ' Andrew Dai']","{'Google', 'Google Health', 'Google Brain'}",0,1,0,{'USA'}
Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping,"Eduard Gorbunov, Marina Danilova, Alexander Gasnikov",Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping,abd1c782880cc59759f4112fda0b8f98,https://proceedings.neurips.cc/paper/2020/file/abd1c782880cc59759f4112fda0b8f98-Paper.pdf,"Our contribution is primarily theoretical. Therefore, a broader impact discussion is not applicable.",Broader Impact,13,2,TRUE,FALSE,FALSE,FALSE,FALSE,Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping,Optimization -> Stochastic Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Eduard Gorbunov', ' Marina Danilova', ' Alexander Gasnikov']","{'SkolTech', 'Moscow Institute of Physics and Technology', 'ICS RAS'}",1,0,0,{'Russia'}
Adaptive Experimental Design with Temporal Interference: A Maximum Likelihood Approach,"Peter W. Glynn, Ramesh Johari, Mohammad Rasouli",Adaptive Experimental Design with Temporal Interference: A Maximum Likelihood Approach,abd987257ff0eddc2bc6602538cb3c43,https://proceedings.neurips.cc/paper/2020/file/abd987257ff0eddc2bc6602538cb3c43-Paper.pdf,"This is a theoretical work on experimental design, and does not present any foreseeable societal consequence.",Broader Impact,16,1,TRUE,FALSE,FALSE,FALSE,FALSE,Adaptive Experimental Design with Temporal Interference: A Maximum Likelihood Approach,Probabilistic Methods -> Causal Inference,Reinforcement Learning and Planning -> Markov Decision Processes; Theory -> Control Theory; Theory -> Frequentist Statistics,,"['Peter W Glynn', ' Ramesh Johari', ' Mohammad Rasouli']",{'Stanford University'},1,0,0,{'USA'}
From Trees to Continuous Embeddings and Back: Hyperbolic Hierarchical Clustering,"Ines Chami, Albert Gu, Vaggos Chatziafratis, Christopher Ré",From Trees to Continuous Embeddings and Back: Hyperbolic Hierarchical Clustering,ac10ec1ace51b2d973cd87973a98d3ab,https://proceedings.neurips.cc/paper/2020/file/ac10ec1ace51b2d973cd87973a98d3ab-Paper.pdf,"Clustering is arguably one of the most commonly used tools in computer science applications. Here, we study a variation where the goal is to output a hierarchy over clusters, as data often contain hierarchical structures. We believe our approach based on triplet sampling and optimization should not raise any ethical considerations, to the extent that the input data for our algorithm is unbiased. Of course, bias in data is by itself another challenging problem, as biases can lead to unfair clustering and discriminatory decisions for different datapoints. However here we study a downstream application, after data has been collected. As such, we hope only a positive impact can emerge from our work, by more faithfully finding hierarchies in biological, financial, or network data, as these are only some of the applications that we listed in the introduction.",Broader Impact,137,6,,,FALSE,FALSE,FALSE,From Trees to Continuous Embeddings and Back: Hyperbolic Hierarchical Clustering,Algorithms -> Clustering,Algorithms -> Metric Learning; Algorithms -> Representation Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Ines Chami', ' Albert Gu', ' Vaggos Chatziafratis', ' Christopher Ré']","{'Stanford', 'Stanford University', 'Stanford University, California'}",1,0,0,{'USA'}
The Autoencoding Variational Autoencoder,"Taylan Cemgil, Sumedh Ghaisas, Krishnamurthy Dvijotham, Sven Gowal, Pushmeet Kohli",The Autoencoding Variational Autoencoder,ac10ff1941c540cd87c107330996f4f6,https://proceedings.neurips.cc/paper/2020/file/ac10ff1941c540cd87c107330996f4f6-Paper.pdf,"General Research Direction. In recent years, researchers have trained deep generative models that can generate synthetic examples, often indistinguishable from natural data. The high quality of these samples suggest that these models may be able to learn latent representations useful for other downstream tasks. Learning such representations without task specific supervision facilitates transfer to yet unseen, future tasks. This also fosters label efficiency, and interpretability. Unsupervised representation learning would have a high societal impact as it could enable learning representations from data that can be shared with a wider community of researchers who do not have the computational resources for training such a representations, or do not have direct access to training data due to privacy/security/commercial considerations. However, the properties of these representations in terms of test accuracy, robustness, privacy preservation must be carefully studied before their release, especially if systems will be deployed in the real world. In the current work, we have taken a step towards learning representations in an unsupervised way, that exhibit robustness against transformations of the input. Ethical Considerations. The current work studies representations learned by a specific generative model, the VAE and shares a finding that training a VAE by enforcing an additional natural autoen- coding specification is able to provide significant robustness on the learned representation without adversarial training. The study is not proposing a particular system for a specific application. The human face dataset CelebA is choosen as a standard benchmark dataset with several attributes to illustrate the viability of the approach. Still, we have decided to exclude potentially sensitive and subjective attributes from the original dataset, such as ’big-nose’ or ’Asian’, and use only 17 neutral attributes that we have selected using our own judgment.",6 Societal Impact,284,13,,,FALSE,FALSE,FALSE,The Autoencoding Variational Autoencoder,Algorithms -> Representation Learning,Algorithms -> Adversarial Learning; Deep Learning -> Deep Autoencoders; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,,"['Taylan Cemgil', ' Sumedh Ghaisas', ' Krishnamurthy Dvijotham', ' Sven Gowal', ' Pushmeet Kohli']",{'DeepMind'},0,1,0,{'UK'}
A Fair Classifier Using Kernel Density Estimation,"Jaewoong Cho, Gyeongjo Hwang, Changho Suh",A Fair Classifier Using Kernel Density Estimation,ac3870fcad1cfc367825cda0101eee62,https://proceedings.neurips.cc/paper/2020/file/ac3870fcad1cfc367825cda0101eee62-Paper.pdf,"The optimality-efficiency-stability aspects of our algorithm will offer an opportunity to replace the current fair classifiers which either are far from optimality, entail high complexity, and/or suffer from the stability issue. In particular, our optimization framework will play a role in stabilizing the training, which many of the GAN-based fair classifiers suffer from. Hence, it can give significant impacts upon a widening array of machine learning systems that have relied upon GAN-based architectures, being powerful in a wide variety of applications. The current KDE approach is tailored for the binary classifier setting. Hence, a naive extension to general multiclass classifiers (high-dimensional settings) might incur an inaccurate estimate of an interested distribution, thus potentially exhibiting a poor accuracy-fairness tradeoff. Another flip side lies in its robustness against adversarial attacks. It was recently reported in [29] that existing fair classifiers are vulnerable to biased and/or poisoned data. An initial effort has also been made in the same paper to address both fairness and robustness issues. Hence, one future work of great potential might be to gracefully merge the idea in [29] with ours, potentially together with a non-straightforward extension to multiclass classifier settings.",Broader Impact,191,9,,,FALSE,FALSE,FALSE,A Fair Classifier Using Kernel Density Estimation,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Jaewoong Cho', ' Gyeongjo Hwang', ' Changho Suh']",{'KAIST'},1,0,0,{'South Korea'}
A Randomized Algorithm to Reduce the Support of Discrete Measures,"Francesco Cosentino, Harald Oberhauser, Alessandro Abate",A Randomized Algorithm to Reduce the Support of Discrete Measures,ac4395adcb3da3b2af3d3972d7a10221,https://proceedings.neurips.cc/paper/2020/file/ac4395adcb3da3b2af3d3972d7a10221-Paper.pdf,"The authors do not think this section is applicable to the present work, this work does not present any foreseeable societal consequence.",Broader Impact,22,1,TRUE,FALSE,FALSE,FALSE,FALSE,A Randomized Algorithm to Reduce the Support of Discrete Measures,Algorithms,Algorithms -> Data Compression; Algorithms -> Large Scale Learning; Algorithms -> Stochastic Methods,"Algorithms: Large Scale Learning, Data Compression, Stochastic Methods","['Francesco Cosentino', ' Harald Oberhauser', ' Alessandro Abate']",{'University of Oxford'},1,0,0,{'UK'}
Distributionally Robust Federated Averaging,"Yuyang Deng, Mohammad Mahdi Kamani, Mehrdad Mahdavi",Distributionally Robust Federated Averaging,ac450d10e166657ec8f93a1b65ca1b14,https://proceedings.neurips.cc/paper/2020/file/ac450d10e166657ec8f93a1b65ca1b14-Paper.pdf,"This work advocates a distributionally robust algorithm for federated learning. The algorithmic solution is designed to preserve the privacy of users, while training a high quality model. The proposed algorithm tries to minimize the maximum loss among worst case distribution over clients’ data. Hence, we can ensure that even if the data distribution among users is highly heterogeneous, the trained model is reasonably good for everyone, and not benefiting only a group of clients. This will ensure the fairness in training a global model with respect to every user, and it is vitally important for critical decision making systems such as healthcare. In such a scenario, the model learned by simple algorithms such as FedAvg would have an inconsistent performance over different distributions, which is not acceptable. However, the resulting model from our algorithm will have robust performance over different distributions it has been trained on.",Broader Impact,146,7,,,FALSE,FALSE,FALSE,Distributionally Robust Federated Averaging,Optimization -> Convex Optimization,Algorithms -> Large Scale Learning,Optimization Methods (continuous or discrete),"['Yuyang Deng', ' Mohammad Mahdi Kamani', ' Mehrdad Mahdavi']","{'Penn State', 'Pennsylvania State University'}",1,0,0,{'USA'}
Sharp uniform convergence bounds through empirical centralization,"Cyrus Cousins, Matteo Riondato",Sharp uniform convergence bounds through empirical centralization,ac457ba972fb63b7994befc83f774746,https://proceedings.neurips.cc/paper/2020/file/ac457ba972fb63b7994befc83f774746-Paper.pdf,"The goal of our work is to make it possible to get the best possible bounds to the SD as possible from the available data. By reducing the amount of data needed to achieve a certain bound to the SD, we essentially increase the value of each data point, or on the flip side, make each “unit of bound” cheaper. We make essentially no assumption on the family of functions we consider, thus our results are very broadly applicable. As concepts and results from uniform convergence are being used in fields very different than learning (e.g., graph analysis, statistical hypothesis testing, and more, see the Introduction for some references), we believe that enabling machine learning practitioners to better understand their models , and scientists in other fields to make better use of their data is a positive effort. Certainly, we cannot predict possible misuse of our results, either voluntary or involuntary, in the same way that theoretical results of general applicability are often misused or misapplied (as an example, consider secure cryptographic ciphers that are implemented in the wrong way or used in a cryptographic system is not end-to-end secure).",Statement of broader impact,190,5,,,FALSE,FALSE,FALSE,Sharp uniform convergence bounds through empirical centralization,Theory -> Statistical Learning Theory,Theory -> Computational Learning Theory; Theory -> Large Deviations and Asymptotic Analysis; Theory -> Spaces of Functions and Kernels,,"['Cyrus Cousins', ' Matteo Riondato']","{'Amherst College', 'Brown University'}",1,0,0,{'USA'}
COBE: Contextualized Object Embeddings from Narrated Instructional Video,"Gedas Bertasius, Lorenzo Torresani",COBE: Contextualized Object Embeddings from Narrated Instructional Video,acaa23f71f963e96c8847585e71352d6,https://proceedings.neurips.cc/paper/2020/file/acaa23f71f963e96c8847585e71352d6-Paper.pdf,"This work considers the learning of object embeddings from narrated video. In terms of positive impact, our system is particularly relevant for language-based applications on unlabeled video (e.g., text-based retrieval) and may facilitate a tighter integration of vision and NLP methods in the future. As for the potential negative effects, we note that COBE learns to capture various aspects of human actions. Thus, because we are using videos from an uncurated Web dataset, it is possible that COBE might learn contextualized representations that are subjective towards particular characteristics. Furthermore, we note that any algorithm that is relevant to action recognition–and to retrieving videos based on arbitrary language queries–may potentially be used for surveillance purposes.",Broader Impact,114,5,,,FALSE,FALSE,FALSE,COBE: Contextualized Object Embeddings from Narrated Instructional Video,Applications -> Object Recognition,Algorithms -> Multimodal Learning; Applications -> Computer Vision; Applications -> Object Detection,"Object Recognition, Multi-Modal Learning","['Gedas Bertasius', ' Lorenzo Torresani']","{'Facebook Research', 'Facebook AI'}",0,1,0,{'USA'}
Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control,"Zhiyuan Xu, Kun Wu, Zhengping Che, Jian Tang, Jieping Ye",Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control,acab0116c354964a558e65bdd07ff047,https://proceedings.neurips.cc/paper/2020/file/acab0116c354964a558e65bdd07ff047-Paper.pdf,"This work presents a multi-task learning framework for training a single (instead of multiple) DRL agent to undertake multiple different tasks. Even though there is still a long way to go, we believe this work may lead us one step closer to Artificial General Intelligence (AGI). The proposed algorithm may be used in a large variety of domains (such as transportation, medical care, home services, and manufacturing) to train a machine or robot to master many skills and handle different tasks. This work and the corresponding applications may reduce workload and improve the quality of life for human beings with much less computing and energy resources (which could potentially benefit the environment too). In addition, our task/method does not leverage biases in the data. However, at the same time, this kind of technology may have some negative consequences because when a machine or robot is able to gain more skills or capabilities than a human, then we may have to face losses of jobs. What is more, by using our framework, a machine could potentially learn unexpected skills from malicious teachers, and this increases the risk of technology being used incorrectly and hazardously. Therefore, we should pay careful attention to multi-task learning for machines and robots.",Broader Impact,206,8,,,FALSE,FALSE,FALSE,Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Multitask and Transfer Learning,Reinforcement learning and planning,"['Zhiyuan Xu', ' Kun Wu', ' Zhengping Che', ' Jian Tang', ' Jieping Ye']","{'DiDi AI Labs, Didi Chuxing', 'DiDi AI Labs, DiDi Chuxing', 'Didi Chuxing', 'Syracuse University'}",1,1,1,{'USA'}
Finite Versus Infinite Neural Networks: an Empirical Study,"Jaehoon Lee, Samuel Schoenholz, Jeffrey Pennington, Ben Adlam, Lechao Xiao, Roman Novak, Jascha Sohl-Dickstein",Finite Versus Infinite Neural Networks: an Empirical Study,ad086f59924fffe0773f8d0ca22ea712,https://proceedings.neurips.cc/paper/2020/file/ad086f59924fffe0773f8d0ca22ea712-Paper.pdf,"Developing theoretical understanding of neural networks is crucial both for understanding their biases, and predicting when and how they will fail. Understanding biases in models is of critical importance if we hope to prevent them from perpetuating and exaggerating existing racial, gender, and other social biases [ 120, 121, 122, 123]. Understanding model failure has a direct impact on human safety, as neural networks increasingly do things like drive cars and control the electrical grid [124, 125, 126]. We believe that wide neural networks are currently the most promising direction for the development of neural network theory. We further believe that the experiments we present in this paper will provide empirical underpinnings that allow better theory to be developed. We thus believe that this paper will in a small way aid the engineering of safer and more just machine learning models.",Broader Impact,141,6,,,FALSE,FALSE,FALSE,Finite Versus Infinite Neural Networks: an Empirical Study,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Kernel Methods; Probabilistic Methods -> Gaussian Processes; Theory -> Statistical Physics of Learning,Deep learning,"['Jaehoon Lee', ' Samuel Schoenholz', ' Jeffrey Pennington', ' Ben Adlam', ' Lechao Xiao', ' Roman Novak', 'Dickstein']","{'Google Brain', 'Google'}",0,1,0,{'USA'}
Supermasks in Superposition,"Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi, Mohammad Rastegari, Jason Yosinski, Ali Farhadi",Supermasks in Superposition,ad1f8bb9b51f023cdc80cf94bb615aa9,https://proceedings.neurips.cc/paper/2020/file/ad1f8bb9b51f023cdc80cf94bb615aa9-Paper.pdf,"A goal of continual learning is to solve many tasks with a single model. However, it is not exactly clear what qualifies as a single model. Therefore, a concrete objective has become to learn many tasks as efficiently as possible. We believe that SupSup is a useful step in this direction. However, there are consequences to more efficient models, both positive and negative. We begin with the positive consequences: • Efficient models require less compute, and are therefore less harmful for the environment then learning one model per task [44]. This is especially true if models are able to leverage information from past tasks, and training on new tasks is then faster. • Efficient models may be run on the end device. This helps to preserve privacy as a user’s data does not have to be sent to the cloud for computation. • If models are more efficient then large scale research is not limited to wealthier institutions. These institutions are more likely in privileged parts of the world and may be ignorant of problems facing developing nations. Moreover, privileged institutions may not be a representative sample of the research community. We would also like to highlight and discuss the negative consequences of models which can efficiently learn many tasks, and efficient models in general. When models are more efficient, they are also more available and less subject to regularization and study as a result. For instance, when a high-impact model is released by an institution it will hopefully be accompanied by a Model Card [34] analyzing the bias and intended use of the model. By contrast, if anyone is able to train a powerful model this may no longer be the case, resulting in a proliferation of models with harmful biases or intended use. Taking the United States for instance, bias can be harmful as models show disproportionately more errors for already marginalized groups [2], furthering existing and deeply rooted structural racism.",Broader Impact,323,17,,,TRUE,TRUE,FALSE,Supermasks in Superposition,Algorithms -> Continual Learning,Deep Learning -> Efficient Inference Methods,Deep learning,"['Mitchell Wortsman', ' Vivek Ramanujan', ' Rosanne Liu', ' Aniruddha Kembhavi', 'Allen Institute for Artificial Intelligence', ' Mohammad Rastegari', ' Jason Yosinski', ' Ali Farhadi']","{'University of Washington', 'University of Washington, Allen Institute for Artificial Intelligence', 'Uber AI Labs', 'AI2', 'Allen Institute for Artificial Intelligence'}",1,1,1,{'USA'}
Nonasymptotic Guarantees for Spiked Matrix Recovery with Generative Priors,"Jorio Cocola, Paul Hand, Vlad Voroninski",Nonasymptotic Guarantees for Spiked Matrix Recovery with Generative Priors,ad62cfd33e3870262d6bf5331c1f13b0,https://proceedings.neurips.cc/paper/2020/file/ad62cfd33e3870262d6bf5331c1f13b0-Paper.pdf,"This work promotes the wider use of generative priors in statistical inverse problems. As demonstrated, they can lead to optimal sample-complexity and allow for efficient reconstruction algorithms. The impact of these developments in many applied areas, e.g. medical imaging and diagnostic, will be therefore rather significant as they permit faster measurements acquisition and reduced costs, bringing  a number positive effects including increased accuracy, image quality and potentially scientific discoveries. As noted by [49], one of the advantages of using a generative priors for inverse problems, is that the measurement operator needs to be known only at test time and only samples from the prior signal distribution are required in order to train the generative network. This means that, once trained, a generative network can be used to solve many different statistical inverse problems. On the other hand, as [49] observes, the use of generative priors leads to reconstructed images which are highly likely with respect to the empirical distribution that was used for training the generative network. As such they suffer from the same biases of the training data set and can lead to artifacts and hallucinated features.",Broader Impact,188,7,,,FALSE,FALSE,FALSE,Nonasymptotic Guarantees for Spiked Matrix Recovery with Generative Priors,Theory -> High-Dimensional Inference,Algorithms -> Sparsity and Compressed Sensing; Optimization -> Non-Convex Optimization,Theory (including computational and statistical analyses),,{'Northeastern University'},1,0,0,{'USA'}
Almost Optimal Model-Free Reinforcement Learningvia Reference-Advantage Decomposition,"Zihan Zhang, Yuan Zhou, Xiangyang Ji",Almost Optimal Model-Free Reinforcement Learning via Reference-Advantage Decomposition,ad71c82b22f4f65b9398f76d8be4c615,https://proceedings.neurips.cc/paper/2020/file/ad71c82b22f4f65b9398f76d8be4c615-Paper.pdf,This work is theoretical and a broader impact discussion is not applicable.,Broader Impact,12,1,TRUE,FALSE,FALSE,FALSE,FALSE,Almost Optimal Model-Free Reinforcement Learningvia Reference-Advantage Decomposition,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Zihan Zhang', ' Yuan Zhou', ' Xiangyang Ji']","{'UIUC', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Learning to Incentivize Other Learning Agents,"Jiachen Yang, Ang Li, Mehrdad Farajtabar, Peter Sunehag, Edward Hughes, Hongyuan Zha",Learning to Incentivize Other Learning Agents,ad7ed5d47b9baceb12045a929e7e2f66,https://proceedings.neurips.cc/paper/2020/file/ad7ed5d47b9baceb12045a929e7e2f66-Paper.pdf,"Our work is a step toward the goal of ensuring the common good in a potential future where independent reinforcement learning agents interact with one another and/or with humans in the real world. We have shown that cooperation can emerge by introducing an additional learned incentive function that enables one agent to affect another agent’s reward directly. However, as agents still independently maximize their own individual rewards, it is open as to how to prevent an agent from misusing the incentive function to exploit others. One approach for future research to address this concern is to establish new connections between our work and the emerging literature on reward tampering [11]. By sparking a discussion on this important aspect of multi-agent interaction, we believe our work has a positive impact on the long-term research endeavor that is necessary for RL agents to be deployed safely in real-world applications.",Broader Impact,147,5,,,FALSE,FALSE,FALSE,Learning to Incentivize Other Learning Agents,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Jiachen Yang', ' Ang Li', ' Mehrdad Farajtabar', ' Peter Sunehag', ' Edward Hughes', ' Hongyuan Zha']","{'Google - DeepMind', 'DeepMind', 'Georgia Tech', 'Georgia Institute of Technology', 'DeepMind, Mountain View'}",1,1,1,"{'UK', 'USA'}"
Displacement-Invariant Matching Cost Learning for Accurate Optical Flow Estimation,"Jianyuan Wang, Yiran Zhong, Yuchao Dai, Kaihao Zhang, Pan Ji, Hongdong Li",Displacement-Invariant Matching Cost Learning for Accurate Optical Flow Estimation,add5aebfcb33a2206b6497d53bc4f309,https://proceedings.neurips.cc/paper/2020/file/add5aebfcb33a2206b6497d53bc4f309-Paper.pdf,"This paper proposes to predict accurate optical flows via matching cost learning. With the rapid development of optical flow estimation, we have seen its wide applications on autonomous driving [6, 23], medical analysis [28, 36], human motion recognition [1, 31], and so on. These downstream tasks are closely associated with people’s lives and some of them ( e.g. , autonomous driving) may reshape the division of labour in our society. Our proposed efficient and accurate flow estimation method can be generally applied in these fields and bring more convenience. However, we should also see the risks besides the positive impacts. First, the development of new technologies may take away some people’s jobs and threaten the related families’ living. Additionally, reliance on optical flow methods possibly results in potential safety hazards, since current optical flow estimation methods may fail in challenging cases especially for occlusion areas or fast motions. Moreover, the risk of the inaccurate usage also increases. Unfortunately, the risks mentioned above are mainly raised from the usage of technologies and cannot be solved by the academic community only. Machine learning researchers should carefully consider the abuse of their algorithms and advocate for related social research. The involvement of policy makers and companies is necessary to avoid the risks above.",Broader Impact,210,11,,,FALSE,FALSE,FALSE,Displacement-Invariant Matching Cost Learning for Accurate Optical Flow Estimation,Applications -> Computer Vision,,Vision,,"{'Northwestern Polytechnical University', 'NEC Labs', 'Australian National University'}",1,1,1,"{'Australia', 'USA', 'China'}"
Distributionally Robust Local Non-parametric Conditional Estimation,"Viet Anh Nguyen, Fan Zhang, Jose Blanchet, Erick Delage, Yinyu  Ye",Distributionally Robust Local Non-parametric Conditional Estimation,adf854f418fc96fb01ad92a2ed2fc35c,https://proceedings.neurips.cc/paper/2020/file/adf854f418fc96fb01ad92a2ed2fc35c-Paper.pdf,"Our paper contributes theoretical insights at the intersection of statistics and optimization, with potential applications in diverse areas of machine learning. In particular, our proposed estimator can be used in almost all applications in which the non-parametric conditional estimators (including k-nearest neighbors and kernel estimators) are currently utilized, including regression and classification tasks with potential impact in health sciences, economics, business, finance, climate, various engineering areas, logistics, risk analysis, etc. Using ideas from the distributionally robust optimization framework, we propose a principled and systematic way to obtain a robustification of the popular k-nearest neighbors. At a methodological level, we contribute a novel paradigm that can be used to enhance robustness of conditional statistical estimation against model misspecification and adversarial attacks. Because our paper provides novel techniques for conditional estimation in the context structured and contaminated data, we believe that we have the potential of enabling more applications in which data sets are pulled together from different sources (e.g., for prediction of health care policy evaluations in which information from different environments needs to be put together to mitigate the lack of data given the need for quick decision making under time constraints; for online advertisement recommendation system in which the behaviors of many customers are employed to predict the behavior of incoming customers conditional on their profile). In addition, the results in this paper are a part of the thesis work of a Ph.D. student, thus promoting the training for highly qualified personnel.",Broader Impact,243,6,,,TRUE,TRUE,FALSE,Distributionally Robust Local Non-parametric Conditional Estimation,Optimization -> Convex Optimization,Algorithms -> Density Estimation,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Viet Anh Nguyen', ' Fan Zhang', ' Jose Blanchet', ' Erick Delage', ' Yinyu Ye']","{'Stanford University', 'Standord', 'HEC Montréal'}",1,0,0,"{'Canada', 'USA'}"
Robust Multi-Object Matching via Iterative Reweighting of the Graph Connection Laplacian,"Yunpeng Shi, Shaohan Li, Gilad Lerman",Robust Multi-object Matching via Iterative Reweighting of the Graph Connection Laplacian,ae06fbdc519bddaa88aa1b24bace4500,https://proceedings.neurips.cc/paper/2020/file/ae06fbdc519bddaa88aa1b24bace4500-Paper.pdf,"Our proposed algorithms and ideas can be integrated in common 3D reconstruction software. Three- dimensional reconstruction has important applications in autonomous driving, virtual reality and augmented re- ality. In the past decade, the 3D reconstruction community has been switching from incremental reconstruction procedures to global optimization schemes [21]. We thus globally estimate correlations to provide consistent image matches as initial data for common global reconstruction pipelines. In order to address real applied scenarios of high corruption, it is important to further develop and utilize robust estimation methods within real- time 3D reconstruction. In addition to developing robust methods, we also provide some theoretical guarantees for a special setting of nonuniform corruption. Another important reason for detecting abnormal data in an un- supervised and interpretable way is to alleviate the vulnerability of deep learning based methods to adversarial attacks. Our work takes a step towards this aim through robust extraction of image or camera correspondence information without pre-training. This work is of interest to a broad community of machine learners that care about and use robustness, discrete optimization methods and iteratively reweighted least squares (IRLS). In fact, we show that the common IRLS method does not work well in our setting and explain how to carefully modify it. We use core and well-established testing methods and prove various mathematical propositions.",8 Broader Impact,219,11,,,FALSE,FALSE,FALSE,Robust Multi-Object Matching via Iterative Reweighting of the Graph Connection Laplacian,Applications -> Computer Vision,Algorithms -> Spectral Methods; Optimization -> Non-Convex Optimization,Vision,"['Yunpeng Shi', ' Shaohan Li', ' Gilad Lerman']","{'University of Minnesota', 'Princeton University'}",1,0,0,{'USA'}
Meta-Gradient Reinforcement Learning with an Objective Discovered Online,"Zhongwen Xu, Hado P. van Hasselt, Matteo Hessel, Junhyuk Oh, Satinder Singh, David Silver",Meta-Gradient Reinforcement Learning with an Objective Discovered Online,ae3d525daf92cee0003a7f2d92c34ea3,https://proceedings.neurips.cc/paper/2020/file/ae3d525daf92cee0003a7f2d92c34ea3-Paper.pdf,"This work is situated within a broad and important long-term research program for reinforcement learning: how might a machine discover its own algorithm for RL? Specifically, the research considers one strand of potential research in this area, which is how a machine might discover its own objective for RL. Because our research focuses on the online setting (compared, for example, to much prior work on meta-learning that learns offline from a distribution of tasks), it is applicable to any RL problem. In principle, therefore, any benefits demonstrated in this paper might potentially be applicable to other future RL problems. Thus, the ethical consequences of this research are similar to those for any other research on the RL problem itself: it may provide some progress and accelerate research towards all RL problems, which may benefit any users and use-cases of RL (both ""good"" and ""bad""). Our algorithm learns entirely from interaction with its environment, and does not utilise any external source of data.",Broader Impact,162,6,,,FALSE,FALSE,FALSE,Meta-Gradient Reinforcement Learning with an Objective Discovered Online,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Zhongwen Xu', ' Hado van Hasselt', ' Matteo Hessel', ' Junhyuk Oh', ' Satinder Singh', ' David Silver']","{'Google DeepMind', 'DeepMind'}",0,1,0,{'UK'}
Learning Strategy-Aware Linear Classifiers,"Yiling Chen, Yang Liu, Chara Podimata",Learning Strategy-Aware Linear Classifiers,ae87a54e183c075c494c4d397d126a66,https://proceedings.neurips.cc/paper/2020/file/ae87a54e183c075c494c4d397d126a66-Paper.pdf,"In this paper we put forth and study a model for strategic classification against real-life agents. We believe that when Machine Learning (ML) algorithms are deployed for real-life decision-making, the agents that we face (e.g., the human subjects that we wish to “classify”) will not try to sabotage the decision-making algorithms, but they will try to manipulate them. The power and the ability to manipulate a decision-making rule is inherently tied to the learned outcome for the rule. Strategic ML aims to address these concerns with the construction of ML algorithms that are either strategyproof (i.e., they provide no incentive to the agents to manipulate) or that are strategy-aware (i.e., they are not affected too much by strategic manipulations). 12 Truthful agents are δ -BMR agents, so the lower bound holds for the whole family of δ -BMR agents.  We think that since classification is a fundamental ML task, computer scientists together with economists should try to understand two key questions: 1. What is the “correct” behavioral model to explain the agents’ reports? 2. How do we design ML algorithms that take this behavioral model into account, before deploying the algorithms for policy making? However, blindly optimizing predictive accuracy and the role of incentives in it, can have detrimen- tal societal effects. For example, there have been works recently analyzing the disparate effects that strategic manipulation can have among different groups ([20, 28]) when the agents’ utility functions are similar to the ones considered by Hardt et al. [19]. We believe that a next step for learning strategy-aware linear classifiers against δ -BMR is to study whether there exist algorithms that con- currently satisfy the no-regret property and provide better societal guarantees.",Broader Impact,282,13,,,FALSE,FALSE,FALSE,Learning Strategy-Aware Linear Classifiers,Theory -> Game Theory and Computational Economics,,Theory (including computational and statistical analyses),"['Yiling Chen', ' Yang Liu', ' Chara Podimata']","{'Harvard University', 'UC Santa Cruz'}",1,0,0,{'USA'}
Upper Confidence Primal-Dual Reinforcement Learning for CMDP with Adversarial Loss,"Shuang Qiu, Xiaohan Wei, Zhuoran Yang, Jieping Ye, Zhaoran Wang",Upper Confidence Primal-Dual Reinforcement Learning for CMDP with Adversarial Loss,ae95296e27d7f695f891cd26b4f37078,https://proceedings.neurips.cc/paper/2020/file/ae95296e27d7f695f891cd26b4f37078-Paper.pdf,"The wide application of reinforcement learning urges researchers to design models with certain constraints enforcing the fairness and safety so that the learned policy is under control. In this line of research, there have been many empirical studies focusing on constrained Markov decision process, including autonomous vehicle control, power systems, robotics, and social fairness. However, their theoretical understandings are rather limited. In this paper, we aim at providing theoretical analysis of constrained Markov decision process, helping researchers to better understand how to design effective constrained reinforcement learning algorithms and what their theoretical guarantees are.",Broader Impact,94,4,,,FALSE,FALSE,FALSE,Upper Confidence Primal-Dual Reinforcement Learning for CMDP with Adversarial Loss,Reinforcement Learning and Planning -> Markov Decision Processes,Optimization -> Non-Convex Optimization; Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Shuang Qiu', ' Xiaohan Wei', ' Zhuoran Yang', ' Jieping Ye', ' Zhaoran Wang']","{'Princeton', 'University of Southern California', 'Northwestern University', 'University of Michigan'}",1,0,0,{'USA'}
Calibrating Deep Neural Networks using Focal Loss,"Jishnu Mukhoti, Viveka Kulharia, Amartya Sanyal, Stuart Golodetz, Philip Torr, Puneet Dokania",Calibrating Deep Neural Networks using Focal Loss,aeb7b30ef1d024a76f21a1d40e30c302,https://proceedings.neurips.cc/paper/2020/file/aeb7b30ef1d024a76f21a1d40e30c302-Paper.pdf,"Our work shows that using the right kind of loss function can lead to a calibrated model. This helps in improving the reliability of these models when used in real-world applications. It can help in deployment of the models such that users can be alerted when its prediction may not be trustworthy. We do not directly see a situation where calibrated neural networks can have a negative impact on society, but we do believe that research on making models more calibrated will help improve fairness and trust in AI.",7 Broader Impact,89,4,,,FALSE,FALSE,FALSE,Calibrating Deep Neural Networks using Focal Loss,Algorithms -> Uncertainty Estimation,Applications -> Computer Vision; Social Aspects of Machine Learning -> AI Safety,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jishnu Mukhoti', ' Viveka Kulharia', ' Amartya Sanyal', ' Stuart Golodetz', ' Philip Torr', ' Puneet Dokania']",{'University of Oxford'},1,0,0,{'UK'}
Optimizing Mode Connectivity via Neuron Alignment,"Norman Tatro, Pin-Yu Chen, Payel Das, Igor Melnyk, Prasanna Sattigeri, Rongjie Lai",Optimizing Mode Connectivity via Neuron Alignment,aecad42329922dfc97eee948606e1f8e,https://proceedings.neurips.cc/paper/2020/file/aecad42329922dfc97eee948606e1f8e-Paper.pdf,"This work examines solving the problem of mode connectivity up to a symmetry in the weights of the given models. Our method allows for the computation of a curve of nearly optimal models, where this curve itself has a simple parameterization. We discuss the broader impacts of this work from the following perspectives: • Who may benefit from this research: In this work we show the ability to learn simply parameterized curves along which each model is seen to be robust. This could have potential applications in ensembling, where an ensemble of robust networks can be learned without training each individual model. Generally, an attack on an ensemble will be less effective than on a direct attack on any of its component models. Additionally, regarding CIFAR100, we see the ability to find comparable robust models of greater accuracy along the curve. Thus, this work can benefit systems for which robustness is critical. • Who may be disadvantaged from this research: As mentioned, this work can benefit systems for which robustness is critical. Such systems are typically part of a movement towards trusted artificial intelligence. As trust in systems increases, these systems may see wider use and adoption, such as self-driving cars. With increased automation, workers such as truck drivers stand to have declining career prospects. Thus, this work is part of a broader push in research that may disadvantage these peoples. • Consequences of failure: If our method fails for a given instance, then it means that we were unable to learn a simple curve along which the models are nearly optimal. This means the method cannot be used in that instance for an application such as providing a set of models for ensembling. In the case of adversarial models, this means that the learned models are vulnerable to attacks and becoming compromised. • Biases in the data: In our experiments, we validated our results for three different datasets to confirm that our method does not depend on a bias uniquely associated with an individual dataset.",Broader Impact,336,16,,,TRUE,TRUE,FALSE,Optimizing Mode Connectivity via Neuron Alignment,Deep Learning -> Analysis and Understanding of Deep Networks,Deep Learning -> Optimization for Deep Networks; Optimization -> Discrete Optimization; Optimization -> Non-Convex Optimization,Theory (including computational and statistical analyses),"['Norman Tatro', 'Yu Chen', ' Payel Das', ' Igor Melnyk', ' Prasanna Sattigeri', ' Rongjie Lai']","{'IBM Research', 'Rensselaer Polytechnic Institute', 'IBM Research AI'}",1,1,1,{'USA'}
Information Theoretic Regret Bounds for Online Nonlinear Control,"Sham Kakade, Akshay Krishnamurthy, Kendall Lowrey, Motoya Ohnishi, Wen Sun",Information Theoretic Regret Bounds for Online Nonlinear Control,aee5620fa0432e528275b8668581d9a8,https://proceedings.neurips.cc/paper/2020/file/aee5620fa0432e528275b8668581d9a8-Paper.pdf,"In this work, we present the first provably efficient algorithm for learning to control for Kernelized Nonlinear Regulator which is originally proposed in control literature as Gaussian Process model. Though our work focuses on the theoretical foundations of learning in nonlinear control, we believe our work has broader impact in the following aspects. Our work connects two communities: Reinforcement Learning Theory and Control Theory. Existing models considered in RL literature that have provable guarantees hardly capture any continuous control problems while existing control theory does not focus on the sample complexity aspect of controlling unknown dynamical systems. Our work, for the first time, demonstrates that the popular KNR model from control literature, is learnable from a learning theoretical perspective. While it seems that two communities are more separated than would be ideal, we believe our work paves a new way for further communication between two communities. From a practical application perspective, the sample efficiency of our algorithm enables control in complex dynamical settings without onerous large scale data collection, hence demonstrates potentials for model learning and control in real world applications such as dexterous manipulation, medical robotics, human robot interaction, and self-driving cars where complicated nonlinear dynamics are involved and data is often extremely expensive to collect. Also, this line of work may be helpful to provide new means for handling model uncertainty in nonlinear planning, which may be relevant in the broader context of safety and reliability. A clear caveat here is understanding the role of model misspecification. Lastly, but probably most importantly, our proposed algorithm along with other reinforcement learning algorithms could be ethically or physically harmful if misused; one needs to be very careful about if the assumptions we made in this paper are reasonable in the application domains of interest and if the cost function design is technically/ethically validated.",6 Broader Impact,303,10,,,FALSE,FALSE,FALSE,Information Theoretic Regret Bounds for Online Nonlinear Control,Theory -> Control Theory,Theory -> Statistical Learning Theory,Reinforcement learning and planning,"['Sham Kakade', ' Akshay Krishnamurthy', ' Kendall Lowrey', ' Motoya Ohnishi', ' Wen Sun']","{'Microsoft', 'University of Washington', 'Microsoft Research NYC'}",1,1,1,{'USA'}
A kernel test for quasi-independence,"Tamara Fernandez, Wenkai Xu, Marc Ditzhaus, Arthur Gretton",A kernel test for quasi-independence,aeefb050911334869a7a5d9e4d0e1689,https://proceedings.neurips.cc/paper/2020/file/aeefb050911334869a7a5d9e4d0e1689-Paper.pdf,"Potential benefits to society Finding dependencies is a key tool in a broad variety of scientific domains, including clinical treatments, demography, business strategy development, and public policy formulation, with applications spanning the natural and social sciences. Our work addresses these questions by studying the dependence relationships between observed data, where the data already have an intrinsic dependence due to natural order. Moreover, the dependence need not be monotonic, but can take a variety of forms. Detecting the dependence of variables in this setting, which corresponds to many real-life scenarios, will allow scientists or policymakers to better understand their data and research problems, and guide the better design of future research questions. The dependence detection strategy may be used to detect bias in data collection procedures. Such bias could be avoided by verifying the absence of inadvertent dependency relationships in collected data.  Potential risks to society There are a number of ways in which statistical tests can be mis-applied in the wider scientific community, and these must be guarded against. As one example, p-value hacking/failure to correct for multiple testing can result in false positives. In the event that these false positives are surprising or controversial, they can gain considerable traction in the media. In some cases, peoples’ health can be at risk. A second risk, specific to tests of dependence, is for correlation and causation to be confused. Our tests detect correlation, however, a misunderstanding of such tests might result in false conclusions of cause and effect. There have been especially pernicious instances when using statistics in domains such as crime prediction.",7 Broader Impact,262,13,,,FALSE,TRUE,FALSE,A kernel test for quasi-independence,Algorithms -> Kernel Methods,Theory -> Large Deviations and Asymptotic Analysis,kernel methods,"['Tamara Fernandez', ' Wenkai Xu', ' Marc Ditzhaus', ' Arthur Gretton']","{'TU Dortmund University', 'Gatsby Unit, UCL', 'University College London'}",1,0,0,"{'UK', 'Germany'}"
First Order Constrained Optimization in Policy Space,"Yiming Zhang, Quan Vuong, Keith Ross",First Order Constrained Optimization in Policy Space,af5d5ef24881f3c3049a7b9bfe74d58b,https://proceedings.neurips.cc/paper/2020/file/af5d5ef24881f3c3049a7b9bfe74d58b-Paper.pdf,Safety is a critical element in real-world applications of RL. We argue in this paper that scalar reward signals alone is often insufficient in motivating the agent to avoid harmful behavior. An RL systems designer needs to carefully balance how much to encourage desirable behavior and how much to penalize unsafe behavior where too much penalty could prevent the agent from sufficient exploration and too little could lead to hazardous consequences. This could be extremely difficult in practice. Constraints are a more natural way of quantifying safety requirements and we advocate for researchers to consider including constraints in safety-critical RL systems.,6 Broader Impact,101,5,,,FALSE,FALSE,FALSE,First Order Constrained Optimization in Policy Space,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning; Social Aspects of Machine Learning -> AI Safety,Reinforcement learning and planning,"['Yiming Zhang', ' Quan Vuong', ' Keith Ross']","{'University of California, San Diego', 'NYU Shanghai', 'New York University'}",1,0,0,"{'USA', 'China'}"
Learning Augmented Energy Minimization via Speed Scaling,"Etienne Bamas, Andreas Maggiori, Lars Rohwedder, Ola Svensson",Learning Augmented Energy Minimization via Speed Scaling,af94ed0d6f5acc95f97170e3685f16c0,https://proceedings.neurips.cc/paper/2020/file/af94ed0d6f5acc95f97170e3685f16c0-Paper.pdf,"As climate change is a severe issue, trying to minimize the environmental impact of modern computer systems has become a priority. High energy consumption and the CO 2 emissions related to it are some of the main factors increasing the environmental impact of computer systems. While our work considers a specific problem related to scheduling, we would like to emphasize that a considerable percentage of real-world systems already have the ability to dynamically scale their computing resources 2 to minimize their energy consumption. Thus, studying models (like the one presented in this paper) with the latter capability is a line of work with huge potential societal impact. In addition to that, although the analysis of the guarantees provided by our algorithm is not straightforward, the algorithm itself is relatively simple. The latter fact makes us optimistic that insights from this work can be used in practice contributing to minimizing the environmental impact of computer infrastructures.",Broader impact,155,6,,,FALSE,FALSE,FALSE,Learning Augmented Energy Minimization via Speed Scaling,Optimization -> Discrete Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Etienne Bamas', ' Andreas Maggiori', ' Lars Rohwedder', ' Ola Svensson']",{'EPFL'},1,0,0,{'Switzerland'}
Exploiting MMD and Sinkhorn Divergences for Fair and Transferable Representation Learning,"Luca Oneto, Michele Donini, Giulia Luise, Carlo Ciliberto, Andreas Maurer, Massimiliano Pontil",Exploiting MMD and Sinkhorn Divergences for Fair and Transferable Representation Learning,af9c0e0c1dee63e5acad8b7ed1a5be96,https://proceedings.neurips.cc/paper/2020/file/af9c0e0c1dee63e5acad8b7ed1a5be96-Paper.pdf,"Algorithmic fairness has a potential high social importance. The goal is to make safer the application of automatic agents as decision makers in our society. We think that learning a fair representation can be a practical way to pursue the goal of generating unbiased machine learning. A fair machine learning is needed in our society, especially after several discoveries of unfair biases in the current standard machine learning models. With less biased and more fair machine learning models, we can increase the trust of people in automatic agents – and we can also spread awareness of the possible issue of bias in machine learning models among colleagues in our research community. We have the possibility to enhance the benefits that using machine learning can provide to society and we need to avoid translating the negative human biases to the learned models. We are aware that statistical measures of fairness (such as statistical parity or equal opportunity) cannot be considered as the unique definitions for bias. In fact, many others have been presented, exploring areas like – for example – causality. Indeed, we know that the choice of a definition of fairness for the task at hand has to be carefully understood by the user (i.e., a human) and not selected by an automatic agent. In this sense, it is well known that different definitions of fairness are even in contrast one each other. Consequently, enforcing one definition, we are simultaneously forcing other definitions to be violated. The choice of the right definition is fundamental but it is out of the scope of our proposal, and requires a careful human-in-the-loop approach.",Broader impact,270,12,,,FALSE,FALSE,FALSE,Exploiting MMD and Sinkhorn Divergences for Fair and Transferable Representation Learning,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Theory -> Statistical Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)",,"{'Adalbertstr 55', 'IIT', 'University of Genoa', 'Imperial College London', 'Amazon', 'University College London'}",1,1,1,"{'USA', 'UK', 'Italy', 'India'}"
Deep Rao-Blackwellised Particle Filters for Time Series Forecasting,"Richard Kurle, Syama Sundar Rangapuram, Emmanuel de Bézenac, Stephan Günnemann, Jan Gasthaus",Deep Rao-Blackwellised Particle Filters for Time Series Forecasting,afb0b97df87090596ae7c503f60bb23f,https://proceedings.neurips.cc/paper/2020/file/afb0b97df87090596ae7c503f60bb23f-Paper.pdf,"This paper stems from the author’s work on time series forecasting and anomaly detection in industrial settings. The proposed methods are applicable to forecasting from univariate and multivariate data streams more generally. Business applications include supply chain monitoring and sales prediction. Furthermore, accurate forecasts allows better resource management, such as waste reduction and optimisation of energy consumption.",Broader impact,57,4,FALSE,FALSE,FALSE,FALSE,FALSE,Deep Rao-Blackwellised Particle Filters for Time Series Forecasting,Probabilistic Methods -> Variational Inference,Algorithms -> Dynamical Systems; Probabilistic Methods -> Latent Variable Models,,"['Richard Kurle', ' Syama Sundar Rangapuram', ' Emmanuel de Bézenac', ' Stephan Günnemann', ' Jan Gasthaus']","{'Sorbonne Université', 'Technical University of Munich', 'Volkswagen Group', 'Amazon Research'}",1,1,1,"{'France', 'USA', 'Germany'}"
Why are Adaptive Methods Good for Attention Models?,"Jingzhao Zhang, Sai Praneeth Karimireddy, Andreas Veit, Seungyeon Kim, Sashank Reddi, Sanjiv Kumar, Suvrit Sra",Why are Adaptive Methods Good for Attention Models?,b05b57f6add810d3b7490866d74c0053,https://proceedings.neurips.cc/paper/2020/file/b05b57f6add810d3b7490866d74c0053-Paper.pdf,"We study convergence rates of gradient methods under a more relaxed noise condition. The result under this setting reaches conclusions that are closer to practice compared to results under the standard setting. Hence, our work provides one way to bridge the theory-practice gap and can facilitate more future works in this direction.",Broader impact,52,3,FALSE,FALSE,FALSE,TRUE,FALSE,Why are Adaptive Methods Good for Attention Models?,Optimization -> Stochastic Optimization,,Deep learning,"['Jingzhao Zhang', ' Sai Praneeth Karimireddy', ' Andreas Veit', ' Seungyeon Kim', ' Sashank Reddi', ' Sanjiv Kumar', ' Suvrit Sra']","{'MIT', 'Google Research', 'Google', 'EPFL'}",1,1,1,"{'USA', 'Switzerland'}"
Neural Sparse Representation for Image Restoration,"Yuchen Fan, Jiahui Yu, Yiqun Mei, Yulun Zhang, Yun Fu, Ding Liu, Thomas S. Huang",Neural Sparse Representation for Image Restoration,b090409688550f3cc93f4ed88ec6cafb,https://proceedings.neurips.cc/paper/2020/file/b090409688550f3cc93f4ed88ec6cafb-Paper.pdf,"Image restoration algorithms can recover high-quality images from low-quality counterparts. The algorithms can help people who cannot afford professional cameras to take photos with low-end devices. However, many low-quality photos are taken under unwanted scenarios, i . e ., sneak shots. Powerful image restoration algorithms may contribute to related abuse. Low-level vision models cannot identify inappropriate images because of lacking the capability for high-level understanding of images. Our method can dramatically increase model capacity and increase the possibility to identify inappropriate patterns by models. Moreover, as shown in Fig. 6, our model can automatically explore high-level features, which benefits the capability to discover inappropriate images if we add corresponding supervision in training.",6 Broader Impact,112,9,,,FALSE,FALSE,FALSE,Neural Sparse Representation for Image Restoration,Applications -> Computer Vision,Applications -> Denoising,Vision,"['Yuchen Fan', ' Jiahui Yu', ' Yiqun Mei', ' Yulun Zhang', ' Yun Fu', ' Ding Liu', ' Thomas Huang']","{'Northeastern University', 'UIUC', 'Bytedance AI Lab', 'University of Illinois', 'University of Illinois at Urbana-Champaign'}",1,1,1,"{'USA', 'China'}"
Boosting First-Order Methods by Shifting Objective: New Schemes with Faster Worst-Case Rates,"Kaiwen Zhou, Anthony Man-Cho So, James Cheng",Boosting First-Order Methods by Shifting Objective: New Schemes with Faster Worst-Case Rates,b096577e264d1ebd6b41041f392eec23,https://proceedings.neurips.cc/paper/2020/file/b096577e264d1ebd6b41041f392eec23-Paper.pdf,This work studies the performance limit of solving a class of convex problem. Data scientists and machine learning researchers may benefit from this work by using the proposed methods to boost the training speed of their models. We are not aware of clear negative outcomes of this work since we focus more on the fundamental understanding of convex optimization.,Broader Impact,59,3,FALSE,FALSE,FALSE,FALSE,FALSE,Boosting First-Order Methods by Shifting Objective: New Schemes with Faster Worst-Case Rates,Optimization -> Convex Optimization,,Optimization Methods (continuous or discrete),"['Kaiwen Zhou', 'Cho So', ' James Cheng']","{'The Chinese University of Hong Kong', 'CUHK'}",1,0,0,{'China'}
Robust Sequence Submodular Maximization,"Gamal Sallam, Zizhan Zheng, Jie Wu, Bo Ji",Robust Sequence Submodular Maximization,b0c7ae2316c7e8214fd659e4bc8a0dea,https://proceedings.neurips.cc/paper/2020/file/b0c7ae2316c7e8214fd659e4bc8a0dea-Paper.pdf,"This work contributes to the state-of-the-art theory of submodular optimization. The proposed algorithms and the presented approximation results can be applied to real-world applications where the stated assumptions of sequence submodularity and monotonicity or their approximate versions are satisfied. Several real-world applications, including machine learning based recommendation systems, ads allocation, and automation and control, involve the selection of elements in sequence.",7 Broader Impact,61,3,,,FALSE,FALSE,FALSE,Robust Sequence Submodular Maximization,Optimization -> Submodular Optimization,,Theory (including computational and statistical analyses),"['Gamal A Sallam', ' Zizhan Zheng', ' Jie Wu', ' Bo Ji']","{'Virginia Tech', 'Temple University', 'Tulane University'}",1,0,0,{'USA'}
Certified Monotonic Neural Networks,"Xingchao Liu, Xing Han, Na Zhang, Qiang Liu",Certified Monotonic Neural Networks,b139aeda1c2914e3b579aafd3ceeb1bd,https://proceedings.neurips.cc/paper/2020/file/b139aeda1c2914e3b579aafd3ceeb1bd-Paper.pdf,"Our method can simplify and improve the process of incorporating monotonic constraints in deep learning systems, which can potentially improve the fairness, security and interpretability of black-box deep models. Since it is a fundamental machine learning methodology, We do not foresee negative impact to the society implied by the algorithm directly.",Broader Impact Statement,51,2,TRUE,TRUE,TRUE,TRUE,FALSE,Certified Monotonic Neural Networks,Deep Learning -> Supervised Deep Networks,"Deep Learning -> Predictive Models; Social Aspects of Machine Learning -> AI Safety; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Deep learning,"['Xingchao Liu', ' Xing Han', ' Na Zhang', ' Qiang Liu']","{'UT Austin', 'The University of Texas at Austin', 'Tsinghua University', 'University of Texas at Austin'}",1,0,0,"{'USA', 'China'}"
System Identification with Biophysical Constraints: A Circuit Model of the Inner Retina,"Cornelius Schröder, David Klindt, Sarah Strauss, Katrin Franke, Matthias Bethge, Thomas Euler, Philipp Berens",System Identification with Biophysical Constraints: A Circuit Model of the Inner Retina,b139e104214a08ae3f2ebcce149cdf6e,https://proceedings.neurips.cc/paper/2020/file/b139e104214a08ae3f2ebcce149cdf6e-Paper.pdf,"We present a model for temporal processing in the inner retina that combines system identification approaches with biophysically interpretable modules. The investigation of these modules allowed us to not only reproduce earlier experimental observations but also make predictions for the underlying biological system. First, this firmly grounds predictive models of neural activity in the biology of the underlying neural system, which is of high interest from a theoretical perspective. Second, the developed techniques for combining predictive and mechanistic models can likely be applied in other regions of the central nervous system, as the necessary data to provide the mechanistic constraints become available. Finally, our model may provide a first step towards establishing data driven in  silico experiments. This is not only valuable in the interest of reducing animal research, but also for assessing the mechanisms of retinal degeneration and may inform future generations of targeted therapies aimed at curing the underlying diseases. At this time, we cannot envision any negative consequences to arise of this research.",Broader Impact,166,7,,,FALSE,FALSE,FALSE,System Identification with Biophysical Constraints: A Circuit Model of the Inner Retina,Neuroscience and Cognitive Science -> Neuroscience,,Neuroscience and cognitive science,"['Cornelius Schröder', ' David Klindt', ' Sarah Strauss', ' Katrin Franke', ' Matthias Bethge', ' Thomas Euler', ' Philipp Berens']",{'University of Tübingen'},1,0,0,{'Germany'}
Efficient Algorithms for Device Placement of DNN Graph Operators,"Jakub M. Tarnawski, Amar Phanishayee, Nikhil Devanur, Divya Mahajan, Fanny Nina Paravecino",Efficient Algorithms for Device Placement of DNN Graph Operators,b14680dec683e744ada1f2fe08614086,https://proceedings.neurips.cc/paper/2020/file/b14680dec683e744ada1f2fe08614086-Paper.pdf,"This work does not present any direct foreseeable societal consequence. In general, work that makes machine learning more scalable and efficient will indirectly magnify its positive and negative impacts.",Broader Impact,29,2,TRUE,TRUE,FALSE,FALSE,FALSE,Efficient Algorithms for Device Placement of DNN Graph Operators,Optimization -> Discrete Optimization,Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,Machine learning systems / efficient inference/training,"['Jakub Tarnawski', ' Amar Phanishayee', ' Nikhil Devanur', ' Divya Mahajan', ' Fanny Nina Paravecino']","{'Microsoft', 'Amazon', 'Microsoft Research'}",1,1,1,{'USA'}
Active Invariant Causal Prediction: Experiment Selection through Stability,"Juan Gamella, Christina Heinze-Deml",Active Invariant Causal Prediction: Experiment Selection through Stability,b197ffdef2ddc3308584dce7afa3661b,https://proceedings.neurips.cc/paper/2020/file/b197ffdef2ddc3308584dce7afa3661b-Paper.pdf,"Any method that learns from finite data is subject to statistical estimation errors and model assumptions that necessarily limit the full applicability of its findings. Unfortunately, study outcomes are not always communicated with the required qualifications. As an example, statistical hypothesis testing is often employed carelessly, e.g. by using p-values to claim “statistical significance” without paying attention to the underlying assumptions [5]. There is a danger that this problem gets exacerbated when one aims to estimate causal structures. Estimates from causal inference algorithms could be claimed to “prove” a given causal relationship, ruling out various alternative explanations that one would consider when explaining a statistical association. For example, ethnicity could be claimed to have a causal effect on criminality and thereby used as a justification for oppressive political measures. While this would represent a clear abuse of the technology, we as researchers have to ensure that similar mistakes in interpretation are not made unintentionally. This implies being conscientious about understanding as well as stating the limitations of our research. While there is a risk that causal inference methods are misused as described above, there is of course also an array of settings where causal learning—and in particular active causal learning—can be extremely useful. As our main motivation we envision the empirical sciences where interventions correspond to physical experiments which can be extremely costly in terms of time and/or money. For complex systems, as for example gene regulatory networks in biology, it might be difficult for human scientists to choose informative experiments, particularly if they are forced to rely on data alone. Our goal is to develop methods to aid scientists to better understand their data and perform more effective experiments, resulting in significant resource savings. The specific impact of our proposed methodology will depend on the application. For the method we propose in this work, one requirement for application would be that the experiments yield more than one data point (and ideally many), so that our invariance-based approach can be employed. In future work, we aim to develop methodology that is geared towards the setting where only very few data points per experiment are available.",Discussion of broader impact,355,15,,,FALSE,FALSE,FALSE,Active Invariant Causal Prediction: Experiment Selection through Stability,Probabilistic Methods -> Causal Inference,Algorithms -> Active Learning; Probabilistic Methods -> Graphical Models,Causality,"['Juan Gamella', 'Deml']","{'ETH Zurich', 'ETH Zürich'}",1,0,0,{'Switzerland'}
BOSS: Bayesian Optimization over String Spaces,"Henry Moss, David Leslie, Daniel Beck, Javier Gonzalez, Paul Rayson",BOSS: Bayesian Optimization over String Spaces,b19aa25ff58940d974234b48391b9549,https://proceedings.neurips.cc/paper/2020/file/b19aa25ff58940d974234b48391b9549-Paper.pdf,"The primary contribution of our work is methodological, providing an efficient and user-friendly framework for optimizing over discrete sequences. As noted in the paper, this is a broad class of problems with a growing interest in the machine learning literature. We hope that our accessible code base will encourage the deployment of our method by practitioners and researchers alike. We have highlighted two real-world applications by demonstrating efficiency improvements within automatic gene and molecule design loops. Such gains are of considerable interest to biological and chemical research labs. Reducing the wet-lab resources required when searching for chemicals or genes with desirable properties provides not only a substantial environmental and monetary saving, but can even enable new technologies. For example, a fast search over genes is a necessary step in providing custom medical treatments. On the other hand, wherever our method can be applied to find structures with beneficial properties, it could similarly be used to find structures with malicious properties. Although the optimization itself is automatic, a human should always has the final say in how a particular optimized structure is to be used. This decision making process should in turn incorporate any ethical frameworks specific to the task at hand.",Broader Impact,201,10,,,FALSE,FALSE,FALSE,BOSS: Bayesian Optimization over String Spaces,Probabilistic Methods -> Gaussian Processes,,Optimization Methods (continuous or discrete),,"{'Lancaster University', 'University of Melbourne'}",1,0,0,"{'UK', 'Australia'}"
Model Interpretability through the lens of Computational Complexity,"Pablo Barceló, Mikaël Monet, Jorge Pérez, Bernardo Subercaseaux",Model Interpretability through the Lens of Computational Complexity,b1adda14824f50ef24ff1c05bb66faf3,https://proceedings.neurips.cc/paper/2020/file/b1adda14824f50ef24ff1c05bb66faf3-Paper.pdf,"Although interpretability as a subject may have a broad practical impact, our results in this paper are mostly theoretic, so we think that this work does not present any foreseeable societal consequences.",7 Broader impact,32,1,TRUE,FALSE,FALSE,FALSE,FALSE,Model Interpretability through the Lens of Computational Complexity,"Deep Learning -> Visualization, Interpretability, and Explainability",Deep Learning -> Analysis and Understanding of Deep Networks,Theory (including computational and statistical analyses),"['Pablo Barceló', ' Mikaël Monet', ' Jorge Pérez', ' Bernardo Subercaseaux']","{'Millenium Instititute for Foundational Research on Data', 'Universidad de Chiel', 'Universidad de Chile'}",1,0,0,{'Chile'}
Markovian Score Climbing: Variational Inference with KL(p||q),"Christian Naesseth, Fredrik Lindsten, David Blei",Markovian Score Climbing: Variational Inference with KL(p||q),b20706935de35bbe643733f856d9e5d6,https://proceedings.neurips.cc/paper/2020/file/b20706935de35bbe643733f856d9e5d6-Paper.pdf,"MSC is a general purpose approximate statistical inference method. The main goal is to remove systematic errors due to biased estimates of the gradient of the optimization objective function. This can allow for more reliable and robust inferences based on the posterior approximation. However, just like other standard inference methods it does not protect from any bias introduced by applying it to specific models and data [ 13, 41 ] .",Broader Impact,71,4,,,FALSE,FALSE,FALSE,Markovian Score Climbing: Variational Inference with KL(p||q),Probabilistic Methods -> Variational Inference,Probabilistic Methods -> MCMC,Probabilistic methods and inference,"['Christian Naesseth', ' Fredrik Lindsten', ' David Blei']","{'Linköping University', 'Columbia University'}",1,0,0,"{'Sweden', 'USA'}"
Improved Analysis of Clipping Algorithms for Non-convex Optimization,"Bohang Zhang, Jikai Jin, Cong Fang, Liwei Wang",Improved Analysis of Clipping Algorithms for Non-convex Optimization,b282d1735283e8eea45bce393cefe265,https://proceedings.neurips.cc/paper/2020/file/b282d1735283e8eea45bce393cefe265-Paper.pdf,"Deep neural networks have achieved great success in recent years. In this paper, we provide a strong justification for the clipping technique in training deep neural networks and provides a satisfactory answer on how to efficiently optimize a general possibly non-convex ( L 0 , L 1 ) -smooth objective function. It closely aligns with the community’s pursuit of explainability, controllability, and practicability of machine learning. Besides its efficiency in training deep neural networks, a series of recent work ( Thakkar et al. [2019], Chen et al. [2020], Lee and Kifer [2020] ) also studies the relation between clipping and privacy preservation, which appears to be a major concern in machine learning applications. Therefore, we hope that a thorough understanding of clipping methods will be beneficial to the modern society.",Broader Impact,130,7,,,FALSE,FALSE,FALSE,Improved Analysis of Clipping Algorithms for Non-convex Optimization,Optimization -> Non-Convex Optimization,Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Bohang Zhang', ' Jin Jikai', ' Cong Fang', ' Liwei Wang']",{'Peking University'},1,0,0,{'China'}
Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs,"Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang",Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs,b2ea5e977c5fc1ccfa74171a9723dd61,https://proceedings.neurips.cc/paper/2020/file/b2ea5e977c5fc1ccfa74171a9723dd61-Paper.pdf,"This work is mostly theoretical, and we do not foresee any negative ethical or societal outcomes. Researchers working on theoretical aspects of online learning, bandit problems, and Markov Decision Processes may benefit from our results and find our techniques useful for other problems. In the long run, our results might lead to more stable and practical learning algorithms for applications with partial information feedback such as network routing or recommendation systems.",Broader Impact,71,3,,,FALSE,FALSE,FALSE,Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning; Theory,Theory (including computational and statistical analyses),"['Wei Lee', ' Haipeng Luo', 'Yu Wei', ' Mengxiao Zhang']",{'University of Southern California'},1,0,0,{'USA'}
"A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection","Kemal Oksuz, Baris Can Cam, Emre Akbas, Sinan Kalkan","A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection",b2eeb7362ef83deff5c7813a67e14f0a,https://proceedings.neurips.cc/paper/2020/file/b2eeb7362ef83deff5c7813a67e14f0a-Paper.pdf,"We anticipate our work to significantly impact the following domains: 1. Object detection: Our loss function is unique in many important aspects: It unifies localisation and classification in a single loss function. It uses ranking for both classification and localisation. It provides provable balance between negatives and positives, similar to AP Loss. These unique merits will contribute to a paradigm shift in the object detection community towards more capable and sophisticated loss functions such as ours. 2. Other computer vision problems with multiple objectives: Problems including multiple objectives (such as instance segmentation, panoptic segmentation – which actually has classification and regression objectives) will benefit significantly from our proposal of using ranking for both classification and localisation. 3. Problems that can benefit from ranking: Many vision problems can be easily converted into a ranking problem. They can then exploit our generalized framework to easily define a loss function and to determine the derivatives. Our paper does not have direct social implications. However, it inherits the following implications of object detectors: Object detectors can be used for surveillance purposes for the betterness of society albeit privacy concerns. When used for detecting targets, an object detector’s failure may have severe consequences depending on the application (e.g. self-driving cars). Moreover, such detectors are affected by the bias in data, although they will not try to exploit them for any purposes.",Broader Impact,226,14,FALSE,FALSE,TRUE,TRUE,FALSE,"A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection",Applications -> Object Detection,,Vision,,"{'Roketsan', 'Middle East Technical University'}",1,1,1,{'Turkey'}
StratLearner: Learning a Strategy for Misinformation Prevention in Social Networks,Guangmo Tong,StratLearner: Learning a Strategy for Misinformation Prevention in Social Networks,b2f627fff19fda463cb386442eac2b3d,https://proceedings.neurips.cc/paper/2020/file/b2f627fff19fda463cb386442eac2b3d-Paper.pdf,"The work in this paper focuses on operational diffusion models without specifying a particular social network platform. Our work proposes a framework for computing protectors, but more importantly and broadly, it suggests a new method for solving learning problems by integrating graph input into the structured prediction. In addition, we do not anticipate any bias in the data used for experiments because the involved subgraphs, underlying triggering model, training examples, and training-testing partition were all randomly determined with enough repetitions. One exception is that we have considered only three graph types, Kronecker, Power-law, and Erd os-Rényi, which may lead to the bias on the graph structure. However, given that the results of StratLearner are robust over these graphs, we believe the observations can be generalized to other graph structures.",Broader Impact,129,5,,,FALSE,FALSE,FALSE,StratLearner: Learning a Strategy for Misinformation Prevention in Social Networks,Applications -> Computational Social Science,Algorithms -> Kernel Methods; Algorithms -> Structured Prediction; Optimization -> Submodular Optimization; Theory -> Hardness of Learning and Approximations,"Other applications (e.g., robotics, biology, climate, finance)",['Guangmo Tong'],{'University of Delaware'},1,0,0,{'USA'}
A Unified Switching System Perspective and Convergence Analysis of Q-Learning Algorithms,"Donghwan Lee, Niao He",A Unified Switching System Perspective and Convergence Analysis of Q-Learning Algorithms,b30958093daeed059670b35173654dc9,https://proceedings.neurips.cc/paper/2020/file/b30958093daeed059670b35173654dc9-Paper.pdf,"By bridging Q-learning with switching systems, this work has full potential to promote synergy between two closely related fields/communities: control theory and reinforcement learning, as well as to stimulate further developments in the theory, algorithms and applicability of reinforcement learning. Meanwhile, this paper provides an accessible material on the basics of stochastic approximation, switching system theory, and reinforcement learning theory, which could be beneficial to graduate students, researchers, and even reinforcement learning practitioners. Our analysis could potentially inspire the development of more efficient and robust algorithms that benefit a broad spectrum of data-intensive applications in the realm of reinforcement learning.",Broader Impact,100,3,,,FALSE,FALSE,FALSE,A Unified Switching System Perspective and Convergence Analysis of Q-Learning Algorithms,Theory -> Control Theory,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Niao He', ' Donghwan Lee']","{'UIUC', 'KAIST'}",1,0,0,"{'South Korea', 'USA'}"
Kernel Alignment Risk Estimator: Risk Prediction from Training Data,"Arthur Jacot, Berfin Simsek, Francesco Spadaro, Clement Hongler, Franck Gabriel",Kernel Alignment Risk Estimator: Risk Prediction from Training Data,b367e525a7e574817c19ad24b7b35607,https://proceedings.neurips.cc/paper/2020/file/b367e525a7e574817c19ad24b7b35607-Paper.pdf,"This work is fundamental and may be used in any research area using Kernel methods, possibly leading to indirect social impacts. However, we do not predict any direct social impact.",Broader Impact,30,2,TRUE,TRUE,FALSE,FALSE,FALSE,Kernel Alignment Risk Estimator: Risk Prediction from Training Data,Algorithms -> Kernel Methods,Theory; Theory -> Models of Learning and Generalization ; Theory -> Regularization; Theory -> Spaces of Functions and Kernels; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Arthur Jacot', ' Berfin Simsek', ' Francesco Spadaro', ' Clement Hongler', ' Franck Gabriel']",{'EPFL'},1,0,0,{'Switzerland'}
Calibrating CNNs for Lifelong Learning,"Pravendra Singh, Vinay Kumar Verma, Pratik Mazumder, Lawrence Carin, Piyush Rai",Calibrating CNNs for Lifelong Learning,b3b43aeeacb258365cc69cdaf42a68af,https://proceedings.neurips.cc/paper/2020/file/b3b43aeeacb258365cc69cdaf42a68af-Paper.pdf,"Our proposed lifelong learning method is very light-weight and shows no catastrophic forgetting. It will help in improving the performance of models on existing lifelong learning based classification problems. It can also be extended to other applications like image/video segmentation, object detection. Since our method involves calibrating the outputs of the convolutional layers in the model, researchers can use it to convert standard deep learning models to work in lifelong learning settings. For example, a model trained to identify specific crop diseases can be easily extended to also identify rare/new crop diseases restricted to a few regions. Since our approach shows an insignificant increase in parameters, the models produced by our approach will also be more scalable than other methods and thereby better for the deployment of lifelong learning models in light-weight end-user systems. Therefore, both government and non-government entities can provide tailor-made AI services to specific regions/communities in addition to the standard services. This method can be misutilized to perform non-licensed extension to commercially available models. However, we can prevent this by keeping the model architecture encrypted/hidden.",Broader Impact,178,9,,,FALSE,FALSE,FALSE,Calibrating CNNs for Lifelong Learning,Applications -> Computer Vision,Algorithms -> Continual Learning; Algorithms -> Multitask and Transfer Learning,Vision,"['Pravendra Singh', ' Vinay Kumar Verma', ' Pratik Mazumder', ' Lawrence Carin', ' Piyush Rai']","{'IIT Kanpur', 'Indian Institute of Technology, Kanpur', 'Indian Institute of Technology Kanpur', 'Duke University'}",1,0,0,"{'India', 'USA'}"
Online Convex Optimization Over Erdos-Renyi Random Networks,"Jinlong Lei, Peng Yi, Yiguang Hong, Jie Chen, Guodong Shi",Online Convex Optimization Over Erd os-Rényi Random Networks,b3d6e130a30b176f2ca5af7d1e73953f,https://proceedings.neurips.cc/paper/2020/file/b3d6e130a30b176f2ca5af7d1e73953f-Paper.pdf,"The work provides the theoretical understanding of the performance limits about distributed online convex optimization over random networks, and could be applied in processing streaming data to various Internet of Things systems, such as machine learning with personal wearable devices. Currently, it does not present any foreseeable societal consequence.",Broader Impact Section,49,2,TRUE,TRUE,FALSE,FALSE,FALSE,Online Convex Optimization Over Erdos-Renyi Random Networks,Algorithms -> Online Learning,Optimization -> Convex Optimization,,"['Jinlong Lei', ' Peng Yi', ' Yiguang Hong', ' Jie Chen', ' Guodong Shi']","{'Academy of Mathematics and Systems Science, Chinese Academy of Sciences', 'University of Sydney', 'Tongji University', 'Beijing Institute of Technology'}",1,0,0,"{'Australia', 'China'}"
Robustness of Bayesian Neural Networks to Gradient-Based Attacks,"Ginevra Carbone, Matthew Wicker, Luca Laurenti, Andrea Patane', Luca Bortolussi, Guido Sanguinetti",Robustness of Bayesian Neural Networks to Gradient-Based Attacks,b3f61131b6eceeb2b14835fa648a48ff,https://proceedings.neurips.cc/paper/2020/file/b3f61131b6eceeb2b14835fa648a48ff-Paper.pdf,"This work is a theoretical investigation in the large data limit of vulnerability of Bayesian Neural Networks to gradient-based attacks. The main result is that, in this limit, BNNs are not vulnerable to such attacks, as the input gradient vanishes in expectation. This advancement provides a theoretically- provable rational for selecting BNNs in applications where there is concern about attackers performing fast, gradient-based attacks. However, it does not provide any guarantee on the actual safety of BNNs trained on a fi nite amount of data. Our work may positively bene fi t the study of adversarial robustness for BNNs and the investigation of properties that make these networks less vulnerable than deterministic ones. These features could then potentially be transferred to other network paradigms and lead to greater robustness of machine learning algorithms in general. However, there may still exist different attacks leading BNNs to misclassi fi cations and our contribution does not provide any defence technique against them. In the last few years adversarial examples have presented a major hurdle to the adoption of AI systems in any security related fi eld, whose applications go from self-driving vehicles to medical diagnoses. Machine learning algorithms show remarkable performance and generalization capabilities, but they also manifest weaknesses that are not consistent with human understanding of the world. Ultimately, the lack of knowledge about the difference between human and machine interpretation of reality leads to an issue of public trust. The development of procedures that are robust to changes in the output and that represent calibrated uncertainty, would inherently be more trust-worthy and allow for wide-spread adoption of deep learning in safety and security critical tasks.",7 Broader Impact,274,11,,,FALSE,FALSE,FALSE,Robustness of Bayesian Neural Networks to Gradient-Based Attacks,Probabilistic Methods -> Bayesian Theory,Deep Learning -> Analysis and Understanding of Deep Networks; Probabilistic Methods -> Gaussian Processes; Social Aspects of Machine Learning -> AI Safety,Probabilistic methods and inference,"['Ginevra Carbone', ' Matthew Wicker', ' Luca Laurenti', '', ' Luca Bortolussi', ' Guido Sanguinetti']","{'University of Oxford', 'University of Trieste, Department of Mathematics and Geosciences', 'University of Trieste', 'University of Edinburgh'}",1,0,0,{'UK'}
Parametric Instance Classification for Unsupervised Visual Feature learning,"Yue Cao, Zhenda Xie, Bin Liu, Yutong Lin, Zheng Zhang, Han Hu",Parametric Instance Classification for Unsupervised Visual Feature Learning,b427426b8acd2c2e53827970f2c2f526,https://proceedings.neurips.cc/paper/2020/file/b427426b8acd2c2e53827970f2c2f526-Paper.pdf,"Since this work is about unsupervised pre-training, which could be directly adopted in the downstream tasks. Researchers and engineers engaged in visual recognition, object detection and segmentation tasks may benefit from this work. In the future, the people who are engaged in annotating images may be put at disadvantage from this research. If there is any failure in this system, the random initialized model is the lower bound of this unsupervised pre-trained model. This pre-trained model may leverage biases in the dataset used for pre-training, but the biases of unsupervised pre-trained model may be smaller than that of supervised pre-trained model which also used manual annotations.",Broader Impact,106,5,,,FALSE,TRUE,FALSE,Parametric Instance Classification for Unsupervised Visual Feature learning,Algorithms -> Unsupervised Learning,Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yue Cao', ' Zhenda Xie', ' Bin Liu', ' Yutong Lin', ' Zheng Zhang', ' Han Hu']","{'Tsinghua University', 'Microsoft Research Asia', 'MSRA', 'Microsoft Research'}",1,1,1,"{'USA', 'China'}"
Sparse Weight Activation Training,"Md Aamir Raihan, Tor Aamodt",Sparse Weight Activation Training,b44182379bf9fae976e6ae5996e13cd8,https://proceedings.neurips.cc/paper/2020/file/b44182379bf9fae976e6ae5996e13cd8-Paper.pdf,"This work has the following potential positive impact in society: 1) It is an entirely sparse training algorithm for emerging sparse hardware accelerators. 2) It makes training efficient and faster. Thus,  decreasing the model training cost. 3) It can reduce the overall carbon footprint of model training, which is a huge problem. Strubell et al. [54] shows that the carbon footprint of training models can release 5 × the carbon emission of a car during its lifetime. 4) It can enable us to train even bigger models, thus allowing us to achieve new state-of-the-art accuracies. At the same time, this work may have some negative consequences because SWAT can enable us to develop better AI and better AI technologies may have negative societal implications such as strict surveillance, privacy concerns, and job loss.",6 Broader Impact,133,8,,,FALSE,FALSE,FALSE,Sparse Weight Activation Training,Deep Learning -> Efficient Training Methods,Deep Learning -> Efficient Inference Methods,Deep learning,"['Md Aamir Raihan', ' Tor Aamodt']",{'University of British Columbia'},1,0,0,{'Canada'}
Collapsing Bandits and Their Application to Public Health Intervention,"Aditya Mate, Jackson Killian, Haifeng Xu, Andrew Perrault, Milind Tambe",Collapsing Bandits and Their Application to Public Health Interventions,b460cf6b09878b00a3e1ad4c72344ccd,https://proceedings.neurips.cc/paper/2020/file/b460cf6b09878b00a3e1ad4c72344ccd-Paper.pdf,"Our work is largely motivated by resource constrained health intervention delivery. This setting is common in both the Global North and South where community health workers (CHWs) are recruited to deliver basic care to a cohort of patients or benefactors. In fact, CHWs have been critical to achieving global health initiatives for over five decades, and evidence shows that CHWs have had a positive impact in myriad domains including maternal and newborn health [6, 9], (non-)communicable diseases [6, 29], and sexual/reproductive health [37] in low-resource communities across the world [7, 9, 29, 35]. Our modeling has the potential to improve the delivery of care in these highly resource-constrained settings. However, a deployment of our system to any setting must be done responsibly. For instance, the system is designed with the intention of assisting human CHWs plan limited interventions. However, we also present results that highlight our algorithm’s ability to plan among thousands of processes at a time, far more than for which a human could independently plan. Just making this capability available could encourage the automation of applicable interventions via automated calls or texts, potentially displacing CHW jobs, reducing human contact with patients, and unfairly limiting care for patients with limited access to technology. Additionally, users of the system must be dutifully aware that its recommendations will be based solely on the data entered in the system. In the context of medication adherence monitoring, if the worker makes an error when entering data, e.g., the patient was adhering (“good” state) but they accidentally mark the patient as not-adhering (“bad” state), then the algorithm could make the wrong recommendation about the patient the next day, since its belief of the patient’s adherence could be very wrong. Finally, our AI system is inherently a blackbox scheduler which would likely be replacing an interpretable scheduling heuristic. This would limit any user or administrator’s ability to audit decisions around why certain patients were recommended for intervention. As with any potential deployment of a blackbox system to a domain that affects the allocation of resources to humans, system designers should be acutely aware of balance between their needs to be able to perform audits vs. their need for optimization.",Broader Impact,364,13,,,TRUE,TRUE,FALSE,Collapsing Bandits and Their Application to Public Health Intervention,Algorithms -> Bandit Algorithms,Reinforcement Learning and Planning -> Planning,Reinforcement learning and planning,"['Aditya Mate', ' Jackson Killian', ' Haifeng Xu', ' Andrew Perrault', ' Milind Tambe']","{'Harvard University', 'Harvard University/Google', 'University of Virginia'}",1,1,1,{'USA'}
Neural Sparse Voxel Fields,"Lingjie  Liu, Jiatao Gu, Kyaw Zaw Lin, Tat-Seng Chua, Christian Theobalt",Neural Sparse Voxel Fields,b4b758962f17808746e9bb832a6fa4b8,https://proceedings.neurips.cc/paper/2020/file/b4b758962f17808746e9bb832a6fa4b8-Paper.pdf,"NSVF provides a new way to learn a neural implicit scene representation from images that is able to better allocate network capacity to relevant parts of a scene. In this way, it enables learning representations of large-scale scenes at higher detail than previous approaches, which also leads to higher visual quality of the rendered images. In addition, the proposed representation enables much faster rendering than the state-of-the-art, and enables more convenient scene editing and compositing. This new approach to 3D scene modeling and rendering from images complements and partially improves over established computer graphics concepts, and opens up new possibilities in many applications, such as mixed reality, visual effects, and training data generation for computer vision tasks. At the same time it shows new ways to learn spatially-aware scene representations of potential relevance in other domains, such as object scene understanding, object recognition, robot navigation, or training data generation for image-based reconstruction. The ability to capture and re-render, only from 2D images, models of real world scenes at very high visual fidelity, also enables the possibility to reconstruct and re-render humans in a scene. Therefore, any research on and practical application of this and all related reconstruction methods have to strictly respect personality rights and privacy regulations.",7 Broader Impact,207,7,,,FALSE,FALSE,FALSE,Neural Sparse Voxel Fields,Applications -> Computer Vision,Deep Learning,Vision,"['Lingjie Liu', ' Jiatao Gu', ' Kyaw Zaw Lin', 'Seng Chua', ' Christian Theobalt']","{'Facebook AI Research', 'National university of Singapore', 'National University of Singapore', 'Max Planck Institute for Informatics', 'MPI Informatik'}",1,1,1,"{'Singapore', 'USA', 'Germany'}"
A Flexible Framework for Designing Trainable Priors with Adaptive Smoothing and Game Encoding,"Bruno Lecouat, Jean Ponce, Julien Mairal",A Flexible Framework for Designing Trainable Priors with Adaptive Smoothing and Game Encoding,b4edda67f0f57e218a8e766927e3e5c5,https://proceedings.neurips.cc/paper/2020/file/b4edda67f0f57e218a8e766927e3e5c5-Paper.pdf,"Our main field of application is in image processing, with a focus on image restoration and reconstruction, whose benefits for society are clear and well established, even though a misuse of such a technology is of course possible; for instance, the same total variation penalty may be used in medical imaging, for personal photography, in astronomical imaging, or for restoring images produced by military devices. More specifically, our paper is addressing the issue of interpretability of neural networks, by considering models admitting a functional (mathematical) description of their decision functions, and with less parameters than classical deep learning models. As we mentioned in the discussion section, we believe that these are first steps to build systems producing explanable decisions, and that are more data and energy efficient. These are important issues going beyond image processing, which we would like to address in future work.",Broader Impact,144,4,,,FALSE,FALSE,FALSE,A Flexible Framework for Designing Trainable Priors with Adaptive Smoothing and Game Encoding,Algorithms -> Sparsity and Compressed Sensing,Algorithms -> Sparse Coding and Dimensionality Expansion,Vision,,{'Inria'},1,0,0,{'France'}
The Discrete Gaussian for Differential Privacy,"Clément L. Canonne, Gautam Kamath, Thomas Steinke",The Discrete Gaussian for Differential Privacy,b53b3a3d6ab90ce0268229151c9bde11,https://proceedings.neurips.cc/paper/2020/file/b53b3a3d6ab90ce0268229151c9bde11-Paper.pdf,"We have provided a thorough analysis of the privacy and utility properties of the discrete Gaussian and the practicality of sampling it. The impact of this work is that it makes the real-world deployment of differential privacy more practical and secure. In particular, we bridge the gap between the theory (which considers continuous distributions) and the practice (where precision is finite and numerical errors can cause a dramatic privacy failures). We hope that the discrete Gaussian will be used in practice and, further, that our work is critical to enabling these real-world deployments. The positive impact of this work is clear: Differential privacy provides a principled and quantitative way to balance rigorous privacy guarantees and statistical utility in data analysis. If this technology is adopted, it can provide untrusted third parties controlled access to data (e.g., to enable scientific research), while affording the data subjects (i.e., the general public) an adequate level of privacy protection. In any case, our methods are better than using flawed methods (i.e., naïve floating-point implementations of continuous distributions) that inject noise without actually protecting privacy or using methods (such as rounding or discrete Laplace) that offer a worse privacy-utility tradeoff. The negative impact of this work is less clear. All technologies can be misused. For example, an organization may be able to deceptively claim that their system protects privacy on the basis that it is differentially private, when, in reality, it is not private at all, because their privacy parameter is enormous (e.g., ε = 10 6 ). One needs to be careful and critical about promises made by such companies, and educate the general audience about what differential privacy does provide, what it does not, and when guarantees end up being meaningless. However, we must acknowledge that there is a small – but vocal – group of people who do not want differential privacy to be deployed in practice. In particular, the US Census Bureau’s planned adoption of differential privacy for the 2020 US Census has met staunch opposition from some social scientists. We cannot speak for the opponents of differential privacy; many of their objections do not make sense to us and thus it would be inappropriate for us to try summarizing them. However, there is a salient point that needs to be discussed: Differential privacy provides a principled and quantitative way to balance rigorous privacy guarantees and statistical utility in data analysis. This is good, in theory, but, in practice, privacy versus utility is a heated and muddy debate. On one hand, data users (such as social scientists) want unfettered access to the raw data. On the other hand, privacy advocates want the data locked up or never collected in the first place. The technology of differential privacy offers a vehicle for compromise. Yet, some parties are not interested in compromise. In particular, users of census data users are accustomed to largely unrestricted data access. From a privacy perspective, this is unsustainable – the development of reconstruction attacks and the availability of large auxiliary datasets for linking/re-identification has shown that census data needs more robust protections. Understandably, those who rely on census data are deeply concerned about anything that may compromise their ability to conduct research. The adoption of differential privacy has prompted uncomfortable (but necessary) discussions about the value of providing data access relative to the privacy cost. In particular, it is necessary to decide how to allocate the privacy budget – which statistics are most important to release accurately? Another dimension of the privacy-versus-utility debate is how it affects small communities, such as racial/ethnic minorities or rural populations. Smaller populations inherently suffer a harsher privacy- utility tradeoff. Differential privacy is almost always defined so that it provides every person with an equal level of privacy. Consequently, differentially private statistics for smaller populations (e.g., Native Americans in a small settlement) will be less accurate than for larger populations (e.g., Whites in a large US city). More precisely, noise addition methods like ours offer the same absolute accuracy on all populations, but the relative accuracy will be worse when the denominator (i.e., population size) is smaller. The only alternative is to offer small communities weaker privacy protections. We stress that this issue is not specific to differential privacy. For example, if we rely on anonymity or de-identification, then we must grapple with the fact that minorities are more easily re-identified, since, by definition, minorities are more unique. This is a fundamental tradeoff that needs to be carefully considered with input from the minorities and communities concerned. Ultimately, computer scientists can only provide tools and it is up to policymakers in government and other organizations to decide how to use them. This work, along with the broader literature on differential privacy, provides such tools. However, the research community also has a responsibility to provide instructions for how these tools should and should not be used.",Broader Impact,812,37,,,FALSE,TRUE,FALSE,The Discrete Gaussian for Differential Privacy,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Clement Canonne', ' Gautam Kamath', ' Thomas Steinke']","{'University of Waterloo', 'Stanford University', 'IBM Almaden'}",1,1,1,"{'Canada', 'USA'}"
Robust Sub-Gaussian Principal Component Analysis and Width-Independent Schatten Packing,"Arun Jambulapati, Jerry Li, Kevin Tian",Robust Sub-Gaussian Principal Component Analysis and Width-Independent Schatten Packing,b58144d7e90b5a43edcce1ca9e642882,https://proceedings.neurips.cc/paper/2020/file/b58144d7e90b5a43edcce1ca9e642882-Paper.pdf,"Our work provides frameworks for learning properties about the covariance of sub-Gaussian distributions which have been corrupted under noise. As a key subroutine, we develop solvers for smoothed positive linear and semidefinite programs. We believe these results are interesting from an academic perspective, e.g. our techniques may be applicable generally for robust statistics and convex optimization researchers. Moreover, because our primary results concern robustness of models to arbitrarily corrupted data, we believe our methods may have practical implications for downstream tasks where protection against a malicious adversary is warranted. Similarly, as our main subroutine is a solver attaining strong computational guarantees for a wider variety of objectives than was previously known, it is possible that our methods can be leveraged to broaden the types of downstream tasks that can be performed. Namely, as lp norm packing linear program solvers have found applications in fair resource allocation, our hope is that our smoothed and mixed-norm guarantee semidefinite solvers can find similar applications in learning algorithms for objectives designed with fairness or privacy in mind.",Broader Impact,173,6,,,FALSE,TRUE,FALSE,Robust Sub-Gaussian Principal Component Analysis and Width-Independent Schatten Packing,Optimization -> Convex Optimization,Algorithms -> Spectral Methods; Theory -> Computational Learning Theory; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Arun Jambulapati', ' Jerry Li', ' Kevin Tian']","{'Stanford University', 'Microsoft'}",1,1,1,{'USA'}
Adaptive Importance Sampling for Finite-Sum Optimization and Sampling with Decreasing Step-Sizes,"Ayoub El Hanchi, David Stephens",Adaptive Importance Sampling for Finite-Sum Optimization and Sampling with Decreasing Step-Sizes,b58f7d184743106a8a66028b7a28937c,https://proceedings.neurips.cc/paper/2020/file/b58f7d184743106a8a66028b7a28937c-Paper.pdf,"Our work develops a new method for variance reduction for stochastic optimization and sampling algorithms. On the optimization side, we expect our method to be very useful in accelerating the training of large scale neural networks, particularly since our method is expected to provide significant performance gains when the model is able to fit the data nearly perfectly. On the sampling side, we expect our method to be useful in accelerating the convergence of MCMC algorithms, opening the door for the use of accurate Bayesian methods at a large scale.",Broader Impact,90,3,,,FALSE,FALSE,FALSE,Adaptive Importance Sampling for Finite-Sum Optimization and Sampling with Decreasing Step-Sizes,Optimization -> Stochastic Optimization,Algorithms -> Online Learning; Probabilistic Methods -> MCMC,Optimization Methods (continuous or discrete),"['Ayoub El Hanchi', ' David Stephens']",{'McGill University'},1,0,0,{'Canada'}
Learning efficient task-dependent representations with synaptic plasticity,"Colin Bredenberg, Eero Simoncelli, Cristina Savin",Learning efficient task-dependent representations with synaptic plasticity,b599e8250e4481aaa405a715419c8179,https://proceedings.neurips.cc/paper/2020/file/b599e8250e4481aaa405a715419c8179-Paper.pdf,"Here we develop a theoretical framework for the neural substrates of perceptual learning in animals and humans. The moral valence of this work is largely determined by its application: understanding perceptual learning could potentially have a beneficial impact by leading to a better theory of developmental disorders, such as amblyopia, autism, or schizophrenia, but it could also have a potentially negative impact by being used as a tool to manipulate learning in consenting individuals. As our work is theoretical, biases caused by data, and potential system failures are not applicable.",5 Broader Impact,90,3,FALSE,FALSE,FALSE,FALSE,FALSE,Learning efficient task-dependent representations with synaptic plasticity,Neuroscience and Cognitive Science,Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Plasticity and Adaptation,Neuroscience and cognitive science,"['Colin Bredenberg', ' Eero Simoncelli', ' Cristina Savin']","{'New York University', 'HHMI / New York University', 'NYU'}",1,0,0,{'USA'}
A Contour Stochastic  Gradient Langevin Dynamics Algorithm for Simulations of Multi-modal Distributions,"Wei Deng, Guang Lin, Faming Liang",A Contour Stochastic Gradient Langevin Dynamics Algorithm for Simulations of Multi-modal Distributions,b5b8c484824d8a06f4f3d570bc420313,https://proceedings.neurips.cc/paper/2020/file/b5b8c484824d8a06f4f3d570bc420313-Paper.pdf,"Our algorithm ensures AI safety by providing more robust predictions and helps build a safer environment. It is an extension of the flat histogram algorithms from the Metropolis kernel to the Langevin kernel and paves the way for future research in various dynamic importance samplers and adaptive biasing force (ABF) techniques for big data problems. The Bayesian community and the researchers in the area of Monte Carlo methods will enjoy the benefit of our work. To our best knowledge, the negative society consequences are not clear and no one will be put at disadvantage.",Broader Impact,94,4,,,FALSE,FALSE,FALSE,A Contour Stochastic  Gradient Langevin Dynamics Algorithm for Simulations of Multi-modal Distributions,Probabilistic Methods -> MCMC,Deep Learning -> Optimization for Deep Networks,Probabilistic methods and inference,"['Wei Deng', ' Guang Lin', ' Faming Liang']",{'Purdue University'},1,0,0,{'USA'}
Error Bounds of Imitating Policies and Environments,"Tian Xu, Ziniu Li, Yang Yu",Error Bounds of Imitating Policies and Environments ∗,b5c01503041b70d41d80e3dbe31bbd8c,https://proceedings.neurips.cc/paper/2020/file/b5c01503041b70d41d80e3dbe31bbd8c-Paper.pdf,"This work focuses on the theoretical understanding about imitation learning methods in imitating policies and environments, which does not present any direct societal consequence. This work indicates possible improvement direction for MBRL, which might help reinforcement learning get better used in the real world. There could be some consequence when reinforcement learning is getting abused, such as manipulate information presentation to control people’s behaviors.",Broader Impact,64,3,,,FALSE,FALSE,FALSE,Error Bounds of Imitating Policies and Environments,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Tian Xu', ' Ziniu Li', ' Yang Yu']",{'Nanjing University'},1,0,0,{'China'}
Disentangling Human Error from Ground Truth in Segmentation of Medical Images,"Le Zhang, Ryutaro Tanno, Moucheng Xu, Chen Jin, Joseph Jacob, Olga Cicarrelli, Frederik Barkhof, Daniel Alexander",Disentangling Human Error from the Ground Truth in Segmentation of Medical Images,b5d17ed2b502da15aa727af0d51508d6,https://proceedings.neurips.cc/paper/2020/file/b5d17ed2b502da15aa727af0d51508d6-Paper.pdf,"Image segmentation has been one of the main challenges in modern medical image analysis, and describes the process of assigning each pixel or voxel in images with biologically meaningful discrete labels, such as anatomical structures and tissue types (e.g. pathology and healthy tissues). The task is required in many clinical and research applications, including surgical planning [41, 42], and the study of disease progression, aging or healthy development [43, 44, 45]. However, there are many cases in practice where the correct delineation of structures is challenging; this is also reflected in the well-known presence of high inter- and intra-reader variability in segmentation labels obtained from trained experts [9, 23, 5]. Although expert manual annotations of lesions is feasible in practice, this task is time consuming. It usually takes 1.5 to 2 hours to label a MS patient with average 3 visit scans. Meanwhile, the long-established gold standard for segmentation of medical images has been manually voxel-by-voxel labeled by an expert anatomist. Unfortunately, this process is fraught with both interand intra-rater variability (e.g., on the order of approximately 10% by volume [46, 47]). Thus, developing an automatic segmentation technique to fix the variability among inter- and intra-readers could be meaningful not only in terms of the accuracy in delineating MS lesions but also in the related reductions in time and economic costs derived from manual lesion labeling. The lack of consistency in labelling is also common to see in other medical imaging applications, e.g., in lung abnormalities segmentation from CT images. A lesion might be clearly visible by one annotator, but the information about whether it is cancer tissue or not might not be clear to others. While our work in the current form has only been demonstrated on medical images, we would like to stress that the medical imaging domain offers a considerably broad range of opportunities for impact; e.g., diagnosis/prognosis in radiology, surgical planning and study of disease progression and treatment, etc. In addition, the annotator information could be potentially utilised for the purpose of education. Another potential opportunity is to integrate such information into the data/label acquisition scheme in order to train reliable segmentation algorithms in a data-efficient manner.",Boarder Impact Statement,361,13,,,FALSE,FALSE,FALSE,Disentangling Human Error from Ground Truth in Segmentation of Medical Images,Applications -> Computer Vision,"Algorithms -> Representation Learning; Algorithms -> Structured Prediction; Algorithms -> Uncertainty Estimation; Data, Challenges, Implementations, and Software -> Benchmarks; Deep Learning -> CNN Architectures; Social Aspects of Machine Learning -> AI Safety","Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Le Zhang', ' Ryutaro Tanno', ' Moucheng Xu', ' Chen Jin', ' Joseph Jacob', ' Olga Cicarrelli', ' Frederik Barkhof', ' Daniel Alexander']","{'University College London', 'Microsoft Research / UCL', 'Queen Square Multiple Sclerosis Centre'}",1,1,1,"{'UK', 'USA'}"
Consequences of Misaligned AI,"Simon Zhuang, Dylan Hadfield-Menell",Consequences of Misaligned AI,b607ba543ad05417b8507ee86c54fcb7,https://proceedings.neurips.cc/paper/2020/file/b607ba543ad05417b8507ee86c54fcb7-Paper.pdf,"As AI systems become more capable in today’s society, the consequences of misspecified reward functions increase as well. Instances where the goal of the AI system and the preferences of individuals diverge are starting to emerge in the real world. For example, content recommendation algorithms optimizing for clicks causes clickbait and misinformation to proliferate (33). Our work rigorously defines this general problem and suggests two separate approaches for dealing with incomplete or misspecified reward functions. In particular, we argue that, in the absence of a full description of attributes, the incentives for real-world systems need to be plastic and dynamically adjust based on changes in behavior of the agent and the state of the world.",Broader Impact,115,5,,,TRUE,TRUE,FALSE,Consequences of Misaligned AI,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Ranking and Preference Learning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Simon Zhuang', 'Menell']",{'UC Berkeley'},1,0,0,{'USA'}
Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning,"Julien Roy, Paul Barde, Félix Harvey, Derek Nowrouzezahrai, Chris Pal",Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning,b628386c9b92481fab68fbf284bd6a64,https://proceedings.neurips.cc/paper/2020/file/b628386c9b92481fab68fbf284bd6a64-Paper.pdf,"In this work, we present and study methods to enforce coordination in MARL algorithms. It goes without saying that multi-agent systems can be employed for positive and negative applications alike. We do not propose methods aimed at making new applications possible or improving a particular set of applications. We instead propose methods that allow to better understand and improve multi-agent RL algorithms in general. Therefore, we do not aim in this section at discussing the impact of Multi- Agent Reinforcement Learning applications themselves but focus on the impact of our contribution: promoting multi-agent behaviors that are coordinated. We first observe that current Multi-Agent Reinforcement Learning (MARL) algorithms may fail to train agents that leverage information about the behavior of their teammates and that even when  explicitly given their teammates observations, action and current policy during the training phase. We believe that this is an important observation worth raising some concern among the community since there is a widespread belief that centralized training (like MADDPG) should always outperform decentralize training (DDPG). Not only is this belief unsupported by empirical evidence (at least in our experiments) but it also prevents the community from investigating and tackling this flaw that is an important limitation for learning safer and more effective multi-agent behavior. By not accounting for the behavior of its teammates, an agent could not adapt to a new teammate or even a change in the teammates behavior. This prevents current methods to be applied in the real world where there is external perturbations and uncertainties and where an artificial agent may need to interact with various different individuals. We propose to focus on coordination and sketch a definition of coordination: an agent behavior should be predictable given its teammate behavior. While this definition is restrictive, we believe that it is a good starting point to consider. Indeed, enforcing that criterion should make learning agents more aware of their teammates in order to coordinate with them. Yet, coordination alone does not ensure success, as agents could be coordinated in an unproductive manner. More so, coordination could have detrimental effects if it enables an attacker to influence an agent through taking control of a teammate or using a mock-up teammate. For these reasons, when using multi-agent RL algorithms (or even single-agent RL for that matter) for real world applications, additional safeguards are absolutely required to prevent the system from misbehaving, which is highly probable if out-of-distribution states are to be encountered.",Broader Impact,407,16,,,FALSE,FALSE,FALSE,Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning -> Exploration,Reinforcement learning and planning,"['Julien Roy', ' Paul Barde', ' Félix G Harvey', ' Derek Nowrouzezahrai', ' Chris Pal']","{'Quebec AI institute - Ubisoft La Forge', 'MILA, Polytechnique Montréal, Element AI', 'Polytechnique Montréal', 'McGill University', 'Mila'}",1,1,1,{'Canada'}
Emergent Reciprocity and Team Formation from Randomized Uncertain Social Preferences,Bowen Baker,Emergent Reciprocity and Team Formation from Randomized Uncertain Social Preferences,b63c87b0a41016ad29313f0d7393cee8,https://proceedings.neurips.cc/paper/2020/file/b63c87b0a41016ad29313f0d7393cee8-Paper.pdf,"The human world is social; we often find ourselves in conflict at multiple scales, from our daily lives with a friend or colleague to the international stage. As we continue to deploy artificial agents into our world and give them increasing amounts of responsibility, it will be important that they understand our social dilemmas. Were we to train completely cooperative agents against each other, the notion of defection would never emerge, uncooperative behavior would be out of distribution, and we would have no guarantees on their behavior. For instance, if two entities with possibly misaligned objectives send artificial agents to negotiate a deal or collaborate on a project, those agents should be able to cooperate without being exploited. Similarly, say an entity sends a fully cooperative agent to collaborate with two humans who have misaligned objectives; that agent should expect potential uncooperative behavior from one of them and plan accordingly rather than assume all parties involved will be cooperative. In order for agents to generalize to a world with heterogeneous motives, they must see instances of mixed-motive interactions during training. One very reasonable avenue for agents to gain this knowledge would be to collect enough real data from a variety of human social dilemmas, train agents on the solutions, and hope that they generalize to new social dilemmas in the future. The data collection path is likely to yield fruit in the short term, but learning from human collected data may have a limit. For instance, in the recent work producing super-human agents in Starcraft 2, (3) they directly compare agents trained solely with supervised data from human games to a combination of supervised learning and self-play, and they found the latter to be far superior. Just as self-play and self-supervised learning processes have proven critical in training superhuman agents in challenging video games, they may also provide an avenue to producing agents superior to humans at solving our own social issues if paired with the right environments. However, as we’ve seen in this work and others, the naive multi-agent algorithms that have been extremely successful in zero-sum two-team settings dismally fail when confronted with social dilemmas, converging to all-defect equilibria. Allowing agents to learn and choose when to defect and when to cooperate may bring a host of additional safety problems. For instance, a commonly known issue with the tit-for-tat strategy is that if agents make an error, they won’t be able to recover and will defect forever. Making guarantees that agents are safe and making correct choices will be even more of an issue than with purely cooperative agents. In this work we propose a generic method that leads to both reciprocity and team formation, hallmark behaviors of sustained human cooperation. While not directly relevant to current applications of artificial intelligence, we hope that this work in tandem with prior methods will lay the ground for future artificial agents to (1) have experience in solving social dilemmas similar to those in the human world and (2) endlessly learn and complexify from the pressure of social autocurricula. (53)",8 Broader Impact,509,17,,,TRUE,TRUE,FALSE,Emergent Reciprocity and Team Formation from Randomized Uncertain Social Preferences,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning -> Reinforcement Learning,,['Bowen Baker'],{'OpenAI'},0,1,0,{'USA'}
Hitting the High Notes: Subset Selection for Maximizing Expected Order Statistics,"Aranyak Mehta, Uri Nadav, Alexandros Psomas, Aviad Rubinstein",Hitting the High Notes: Subset Selection for Maximizing Expected Order Statistics,b6417f112bd27848533e54885b66c288,https://proceedings.neurips.cc/paper/2020/file/b6417f112bd27848533e54885b66c288-Paper.pdf,"Our results apply to a wide range of resource allocation problems in society. The applications stated in the introduction — search, auctions, vaccine development, or team selection — all have broad benefits. In this work we focused on optimizing the expected maximum subject to the uncertainty about outcome of each random variable. An interesting question arising from our work is how the availability of more data affects the choices of the algorithms we consider. This question has broad implications given recent research that shows that machine learning training sets are often biased and include less samples corresponding to underrepresented subgroups of the population (e.g. [MMS+19]). Sparseness of data may have two competing effects on the probability of a candidate to be selected: On one hand, our algorithms favor high variance variables, so candidates with less data may be more likely to be selected. On the other hand, our algorithms focus on values in the far tail, and candidates with sparse data may not have any values high enough to show their potential. It is an interesting question to understand how these two affects balance. As an initial step toward understanding how availability of data affects the probability of a candidate being selected, we consider the following experiment: We take n = 500 normal random variables with parameters drawn independently from the same distribution as in Section 6. We randomly partition the variables into More-Data and Less-Data types. For the More-Data types, we take the empirical distribution from 5000 samples; for Less-Data types, we use 10 samples. We then run different algorithms for selecting k = 30 variables using the empirical distribution. For each algorithm, we measure the fraction of Less-Data types selected among the k winners, and the overall max when drawing a fresh sample from each of the k true distributions. We observe (Figure 2) that in terms of expected max (our main objective function), Greedy, Quantile-0.9, and KR-0.9 all perform almost equally well, and Expectation is close after. But Greedy and to some extent Quantile-0.9 under-select Less-Data types, whereas KR-0.9 selects Less-Data types at a higher rate than their fraction (50%) of the population.",Broader impact,356,15,,,TRUE,TRUE,FALSE,Hitting the High Notes: Subset Selection for Maximizing Expected Order Statistics,Theory -> Game Theory and Computational Economics,,Theory (including computational and statistical analyses),,"{'Google', 'Stanford', 'Google Research', 'Purdue University'}",1,1,1,{'USA'}
Towards Scale-Invariant Graph-related Problem Solving by Iterative Homogeneous GNNs,"Hao Tang, Zhiao Huang, Jiayuan Gu, Bao-Liang Lu, Hao Su",Towards Scale-Invariant Graph-related Problem Solving by Iterative Homogeneous Graph Neural Networks,b64a70760bb75e3ecfd1ad86d8f10c88,https://proceedings.neurips.cc/paper/2020/file/b64a70760bb75e3ecfd1ad86d8f10c88-Paper.pdf,"Our methods provide general tools to improve the generalizability of GNNs with respect to scales. This work can thus be applied to many applications of GNNs, such as natural language processing, traffic prediction, and recommendation systems. They have many potential positive impact in the society. For example, better traffic prediction enables shorter traffic time for all vehicles, which could help protect the environment. Improved recommendation system could promote the transition of information for more productivity and more fairness. Moreover, by improving the generalizability with respect to scales, models can be trained on graphs of much smaller scales than reality. It reduces the cost of collecting and storing large datasets with large samples, which can then alleviate the risks of violating privacy and of harming the environment. On the other hand, this work may also have negative consequences. Improving techniques in the field of natural language processing can help monitor and collect personal information of each individual. Stronger recommendation system can also hurt the fairness as different information targeted to different groups of people.",8 Broader Impact,173,10,,,FALSE,FALSE,FALSE,Towards Scale-Invariant Graph-related Problem Solving by Iterative Homogeneous GNNs,Algorithms -> Relational Learning,,Deep learning,"['Hao Tang', ' Zhiao Huang', ' Jiayuan Gu', 'Liang Lu', ' Hao Su']","{'University of California San Diego', 'University of California, San Diego', 'Shanghai Jiao Tong University', 'UCSD'}",1,0,0,"{'USA', 'China'}"
Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses,"Yihan Zhou, Victor Sanches Portella, Mark Schmidt, Nicholas Harvey",Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses,b67fb3360ae5597d85a005153451dd4e,https://proceedings.neurips.cc/paper/2020/file/b67fb3360ae5597d85a005153451dd4e-Paper.pdf,"In this paper we study the performance of online convex optimization algorithms when the functions are not necessarily Lipschitz continuous, a requirement in classical regret bounds. This opens up the range of applications for which we can use OCO with good guarantees and guides how such parameters such as regularizers/mirror maps and step sizes should be chosen. It is our hope that this aids practitioners to develop more efficient ways to optimize and train their current models. Furthermore, we hope theoreticians to be inspired to delve deep into the setting of non-smooth optimization beyond Lipschitz continuity. It not only opens up the range of applications, but sheds light onto the fundamental conditions on the cost functions and regularizers/mirror maps needed for OCO algorithms to have good guarantees. Due to the theoretical nature of this work, we do not see potentially bad societal or ethical impacts.",7 Statement of Broader Impact,145,6,,,FALSE,FALSE,FALSE,Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses,Optimization -> Convex Optimization,Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Yihan Zhou', ' Victor Sanches Portella', ' Mark Schmidt', ' Nicholas Harvey']",{'University of British Columbia'},1,0,0,{'Canada'}
The Lottery Ticket Hypothesis for Pre-trained BERT Networks,"Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang, Zhangyang Wang, Michael Carbin",The Lottery Ticket Hypothesis for Pre-trained BERT Networks,b6af2c9703f203a2794be03d443af2e3,https://proceedings.neurips.cc/paper/2020/file/b6af2c9703f203a2794be03d443af2e3-Paper.pdf,"We do not believe that this research poses significant risk of societal harm. This research is scientific in nature, exploring the behavior of an empirical phenomenon (the lottery ticket hypothesis) in a new setting. In general, lottery ticket subnetworks appear to have the same expressive power as the full networks from which they originate, meaning we have not enabled new learning paradigms that were not already possible with the full BERT model. The largest potential societal impact of the research is that, on the appropriate hardware platforms, it may be possible to reduce the cost (both energy costs and financial costs) of fine-tuning BERT models on downstream tasks by using our universal subnetworks rather than the full BERT network.",Broader Impact,119,4,,,FALSE,FALSE,FALSE,The Lottery Ticket Hypothesis for Pre-trained BERT Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Applications -> Natural Language Processing; Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,AutoML,,"{'MIT CSAIL', 'MIT-IBM Watson AI Lab, IBM Research AI', 'University of Texas at Austin', 'Unversity of Texas at Austin', 'MIT-IBM Watson AI Lab', 'MIT'}",1,1,1,{'USA'}
Label-Aware Neural Tangent Kernel: Toward Better Generalization and Local Elasticity,"Shuxiao Chen, Hangfeng He, Weijie Su",Label-Aware Neural Tangent Kernel: Toward Better Generalization and Local Elasticity,b6b90237b3ebd1e462a5d11dbc5c4dae,https://proceedings.neurips.cc/paper/2020/file/b6b90237b3ebd1e462a5d11dbc5c4dae-Paper.pdf,"While this work may have certain implications on the design and analysis of new kernel methods, here we focus on how this work can potentially influence the interpretation of deep learning systems. In real-world decision-making problems, interpretability is almost always a crucial factor to consider if one is to deploy a machine learning system. For example, in autonomous driving where NNs are used to detect pedestrians and traffic lights, it is important to understand why this detection network outputs a certain prediction and how confident it is for such a prediction, lack of which can cause damages to the surrounding pedestrians and other drivers. Such a call for interpretability is underlying many works on the “calibration” of NNs (see, e.g., Guo et al. 2017). Kernel methods, due to its linearity in the feature space, are easier to interpret than highly non-linear NNs, which is typically treated as a black-box. Thus, having a high-quality “neural-network- simulating” kernel can greatly simplify the design of “neural network interpreters” (like prediction intervals) and may lead to savings of computational resources. However, depending on the user of our technology, there may be negative outcomes. For example, if the user is ignorant of the underlying assumptions behind the validity of our proposed kernels, he/she may have an overt optimism or undue trust on these kernels and make misleading decisions. We see many potential research directions on improving neural network interpretability by using our kernels. For example, our constructions can be generalized to higher-level truncations of the Hoeffding composition, which may give rise to even better “neural-network-simulating” kernels. However, to mitigate the risks associated with the question of “when a kernel is indeed simulating a neural network”, we encourage researchers to carefully examine the validity of the imposed assumptions in a case-by-case manner.",Broader Impact,296,12,,,FALSE,FALSE,FALSE,Label-Aware Neural Tangent Kernel: Toward Better Generalization and Local Elasticity,Deep Learning -> Analysis and Understanding of Deep Networks,"Algorithms -> Kernel Methods; Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,"['Shuxiao Chen', ' Hangfeng He', ' Weijie Su']","{'University of Pennsylvania', 'The Wharton School, University of Pennsylvania'}",1,0,0,{'USA'}
Beyond Perturbations: Learning Guarantees with Arbitrary Adversarial Test Examples,"Shafi Goldwasser, Adam Tauman Kalai, Yael Kalai, Omar Montasser",Beyond Perturbations: Learning Guarantees with Arbitrary Adversarial Test Examples,b6c8cf4c587f2ead0c08955ee6e2502b,https://proceedings.neurips.cc/paper/2020/file/b6c8cf4c587f2ead0c08955ee6e2502b-Paper.pdf,"In adversarial learning, this work can benefit users when adversarial examples are correctly identified. It can harm users by misidentifying such examples, and the misidentifications of examples as suspicious could have negative consequences just like misclassifications. This work ideally could benefit groups who are underrepresented in training data, by abstaining rather than performing harmful incorrect classification. However, it could also harm such groups: (a) by providing system designers an alternative to collecting fully representative data if possible; (b) by harmfully abstaining at different rates for different groups; (c) when those labels would have otherwise been correct but are instead being withheld; and (d) by identifying them when they would prefer to remain anonymous. Our experiments on handwriting recognition have few ethical concerns but also have less ecological validity than real-world experiments on classifying explicit images or medical scans. A note of caution. Inequities may be caused by using training data that differs from the test distribution on which the classifier is used. For instance, in classifying a person’s gender from a facial image, Buolamwini and Gebru [2018] have demonstrated that commercial classifiers are highly inaccurate on dark-skinned faces, likely because they were trained on light-skinned faces. In such cases, it is preferable to collect a more diverse training sample even if it comes at greater expense, or in some cases to abstain from using machine learning altogether. In such cases, PQ learning should not be used, as an unbalanced distribution of rejections can also be harmful. 4 4We are grateful to an anonymous reviewer who pointed out that gender classification is an example of when not to use PQ learning.",Broader Impact,270,11,,,TRUE,TRUE,FALSE,Beyond Perturbations: Learning Guarantees with Arbitrary Adversarial Test Examples,Theory -> Computational Learning Theory,Algorithms -> Adversarial Learning; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Shafi Goldwasser', ' Adam Tauman Kalai', ' Yael Kalai', ' Omar Montasser']","{'Toyota Technological Institute at Chicago', 'Microsoft Research', 'The Simons Institute for the Theory of Computing', 'Micr'}",1,1,1,{'USA'}
AdvFlow: Inconspicuous Black-box Adversarial Attacks using Normalizing Flows,"Hadi Mohaghegh Dolatabadi, Sarah Erfani, Christopher Leckie",AdvFlow: Inconspicuous Black-box Adversarial Attacks using Normalizing Flows,b6cf334c22c8f4ce8eb920bb7b512ed0,https://proceedings.neurips.cc/paper/2020/file/b6cf334c22c8f4ce8eb920bb7b512ed0-Paper.pdf,"In this paper, we introduce a novel adversarial attack algorithm called AdvFlow. It uses pre-trained normalizing flows to generate adversarial examples. This study is crucial as it indicates the vulnerability of deep neural network (DNN) classifiers to adversarial attacks. More precisely, our study reveals that the common assumption made by adversarial example detectors (such as the Mahalanobis detector [32]) that the adversaries come from a different distribution than the data may not be an accurate one. In particular, we show that we can generate adversaries that come from a close distribution to the data, yet they intend to mislead the classifier decision. Thus, we emphasize that adversarial example detectors need to adjust their assumption about the distribution of adversaries before being deployed in real-world situations. Furthermore, since our adversarial examples are closely related to the data distribution, our method shows that DNN classifiers are not learning to classify the data based on their underlying distribution. Otherwise, they would have resisted the attacks generated by AdvFlow. Thus, it can bring the attention of the machine learning community to training their DNN classifiers in a distributional sense. All in all, we pinpoint a failure of DNN classifiers to the rest of the community so that they can become familiar with the limitations of the status-quo. This study, and similar ones, could raise awareness among researchers about the real-world pitfalls of DNN classifiers, with the aim of consolidating them against such threats in the future.",Broader Impact,242,11,,,FALSE,TRUE,FALSE,AdvFlow: Inconspicuous Black-box Adversarial Attacks using Normalizing Flows,Algorithms -> Adversarial Learning,Deep Learning -> Generative Models,Deep learning,"['Hadi Mohaghegh Dolatabadi', ' Sarah Erfani', ' Christopher Leckie']",{'University of Melbourne'},1,0,0,{'Australia'}
Few-shot Image Generation with Elastic Weight Consolidation,"Yijun Li, Richard Zhang, Jingwan (Cynthia) Lu, Eli Shechtman",Few-shot Image Generation with Elastic Weight Consolidation,b6d767d2f8ed5d21a44b0e5886680cb9,https://proceedings.neurips.cc/paper/2020/file/b6d767d2f8ed5d21a44b0e5886680cb9-Paper.pdf,"AI for creativity. The motivation of this work is to expand the amount of data in domains where originally there is limited data available. It is especially useful for artistic domains where manually making a creation takes a lot of work and time. With the generated data, many existing AI-based image synthesis pipelines could be facilitated with the large-scale training. We believe more creative applications could benefit from our work in terms of constructing the indispensable dataset. Detectability. While our use cases in this work are geared towards creative applications, a concern is the generated imagery can be used for the purpose of deception. A potential mitigation is if generated imagery can be reliably detected; there are recent efforts [40, 33] made in this area. The latest work by Wang et al. [40] shows that a classifier trained on images generated by one method, could generalize to others, despite different architectural components or loss functions. As we are using an architecture with many shared components, we expect this generalization ability to hold. We conduct a small study, using the Blur+Jpeg(0.5) model from [40] on our Cat and CelebA-Female datasets. We find the model achieves 94.9 % and 99 . 6% average precision (AP), respectively, for classifying generated images. This indicates our method is similarly detectable to already existing CNN-generated methods. While these results are strong, they are not 100 % . Furthermore, performance can degrade as the images are degraded in real use cases (e.g., compressed, re-scanned). The issue of content authenticity remains a significant challenge, likely requiring multiple layers of solutions, from technical (such as this detector from [40]), to social, to regulatory.",Broader Impact,274,18,,,FALSE,FALSE,FALSE,Few-shot Image Generation with Elastic Weight Consolidation,Applications -> Computer Vision,Deep Learning -> Generative Models,Deep learning,"['Yijun Li', ' Richard Zhang', ' Jingwan', ' Lu', ' Eli Shechtman']","{'Adobe Research', 'Adobe Research, US', 'Cynthia', 'Adobe'}",0,1,0,{'USA'}
On the Expressiveness of Approximate Inference in Bayesian Neural Networks,"Andrew Foong, David Burt, Yingzhen Li, Richard Turner",On the Expressiveness of Approximate Inference in Bayesian Neural Networks,b6dfd41875bc090bd31d0b1740eb5b1b,https://proceedings.neurips.cc/paper/2020/file/b6dfd41875bc090bd31d0b1740eb5b1b-Paper.pdf,"Bayesian approaches to deep learning problems are often proposed in situations where uncertainty estimation is critical. Often the justification given for this approach is the probabilistic framework of Bayesian inference. However, in cases where approximations are made, the quality of these approximations should also be taken into account. Our work illustrates that the uncertainty estimates given by approximate inference with commonly used algorithms may not qualitatively resemble the uncertainty estimates implied by Bayesian modelling assumptions. This may possibly have adverse consequences if Bayesian neural networks are used in safety-critical applications. Our work motivates a careful consideration of these situations.",Broader Impact,99,6,,,FALSE,FALSE,FALSE,On the Expressiveness of Approximate Inference in Bayesian Neural Networks,Probabilistic Methods -> Variational Inference,Algorithms -> Uncertainty Estimation,Probabilistic methods and inference,"['Andrew Foong', ' David Burt', ' Yingzhen Li', ' Richard E Turner']","{'University of Cambridge', 'Microsoft Research Cambridge'}",1,1,1,"{'UK', 'USA'}"
Non-Crossing Quantile Regression for Distributional Reinforcement Learning,"Fan Zhou, Jianing Wang, Xingdong Feng",Non-crossing quantile regression for deep reinforcement learning,b6f8dc086b2d60c5856e4ff517060392,https://proceedings.neurips.cc/paper/2020/file/b6f8dc086b2d60c5856e4ff517060392-Paper.pdf,"This work has broad social impact because reinforcement learning is useful in many applied areas including automatic car driving, industrial robotics, and so on. The proposed method on distributional reinforcement learning can more precisely capture the intrinsic uncertainty of MDPs by ensuring the non-crossing of quantile estimates, which helps AI to better understand some complicated real- world decision making problems. Our method highly increases the exploration efficiency of DRL algorithms, and can be widely used in some difficult tasks that have extremely large state-reward spaces. On the other hand, allowing the agent to explore more uncertainty of the environment may change the way robots think and lead to some negative outcomes in real-life.",Broader Impact,113,4,,,FALSE,FALSE,FALSE,Non-Crossing Quantile Regression for Distributional Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Fan Zhou', ' Jianing Wang', ' Xingdong Feng']",{'Shanghai University of Finance and Economics'},1,0,0,{'China'}
"Dark Experience for General Continual Learning: a Strong, Simple Baseline","Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, SIMONE CALDERARA","Dark Experience for General Continual Learning: a Strong, Simple Baseline",b704ea2c39778f07c617f6b7ce480e9e,https://proceedings.neurips.cc/paper/2020/file/b704ea2c39778f07c617f6b7ce480e9e-Paper.pdf,"We hope that this work will prove useful to the Continual Learning (CL) scientific community as it is fully reproducible and includes: • a clear and extensive comparison of the state of the art on multiple datasets; • Dark Experience Replay (DER), a simple baseline that outperforms all other methods while maintaining a limited memory footprint. As revealed by the analysis in Section 5, DER also proves to be better calibrated than a simple Experience Replay baseline, which means that it could represent a useful starting point for the study of CL decision-making applications where an overconfident model would be detrimental. We especially hope that the community will benefit from the introduction of MNIST-360, the first evaluation protocol adhering to the General Continual Learning scenario. The latter has been recently proposed to describe the requirement of a CL system that can be applied to real-world problems. Widespread adoption of our protocol (or new ones of similar design) can close the gap between the current CL studies and practical AI systems. Due to the abstract nature of MNIST-360 (it only contains digits), we believe that ethical and bias concerns are not applicable.",Broader Impact,191,6,,,TRUE,TRUE,FALSE,"Dark Experience for General Continual Learning: a Strong, Simple Baseline",Algorithms -> Continual Learning,Algorithms -> Multitask and Transfer Learning; Algorithms -> Online Learning,Continual Learning,"['Pietro Buzzega', ' Matteo Boschini', ' Angelo Porrello', ' Davide Abati', ' SIMONE CALDERARA']","{'University of Modena and Reggio Emilia, Italy', 'University of Modena and Reggio Emilia'}",1,0,0,{'Italy'}
Learning to Utilize Shaping Rewards: A New Approach of Reward Shaping,"Yujing Hu, Weixun Wang, Hangtian Jia, Yixiang Wang, Yingfeng Chen, Jianye Hao, Feng Wu, Changjie Fan",Learning to Utilize Shaping Rewards: A New Approach of Reward Shaping,b710915795b9e9c02cf10d6d2bdb688c,https://proceedings.neurips.cc/paper/2020/file/b710915795b9e9c02cf10d6d2bdb688c-Paper.pdf,"Reward design is an important and difficult problem in real-world applications of reinforcement learning (RL). In many cases, researchers or algorithm engineers have some prior knowledge (such as rules and constraints) about the problem to be solved, but cannot represent the knowledge as numeric values very exactly. Improper reward settings may be exploited by an RL algorithm to obtain higher rewards, but with unexpected behaviors learnt. This paper provides an adaptive approach of reward shaping to avoid the repeated and tedious tuning of rewards in RL applications (e.g., video games). A direct impact of our paper is that researchers or algorithm engineers can be liberated from hard work of reward tuning. The shaping weights learnt by our methods indicate the quality of the designed rewards, and thus can help the designers to better understand the problems. Our paper also proposes a general principle for utilizing prior knowledge in the machine learning domain, namely trying to get rid of human cognitive error when the qualitative or rule-based prior knowledge is transformed into numeric values to help with learning.",Broader Impact,177,7,,,FALSE,FALSE,FALSE,Learning to Utilize Shaping Rewards: A New Approach of Reward Shaping,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Decision and Control,Reinforcement learning and planning,"['Yujing Hu', ' Weixun Wang', ' Hangtian Jia', ' Yixiang Wang', ' Yingfeng Chen', ' Jianye Hao', ' Feng Wu', ' Changjie Fan']","{'University of Science and Technology of China', 'Netease Fuxi AI Lab', 'Tianjin University', 'NetEase Fuxi AI Lab'}",1,1,1,{'China'}
Neural encoding with visual attention,"Meenakshi Khosla, Gia Ngo, Keith Jamison, Amy Kuceyeski, Mert Sabuncu",Neural encoding with visual attention,b71f5aaf3371c2cdfb7a7c0497f569d4,https://proceedings.neurips.cc/paper/2020/file/b71f5aaf3371c2cdfb7a7c0497f569d4-Paper.pdf,"Understanding the link between sensory stimulation and evoked neural activity in humans as revealed with encoding models, can provide foundations for developing novel therapies. Viewed in this regard, an improved understanding of information processing in the brain has tremendous potential. However, encoding models can be very sensitive to biases in the training set. Our models were trained using data from the Human Connectome Project database. While this large-scale project has made a lot of valuable data publicly available to the scientific community for studying brain structure and function, it is important to consider the representational bias in the dataset. For instance, the data we analyzed is exclusively limited to a young adult population. Such biases can possibly lead to poorer generalization of models trained with these large-scale datasets on other population groups that are inadequately represented. Once these encoding models are ripe for therapeutic applications, this dataset bias could prevent under-represented groups from deriving the benefits of a useful technology, resulting in uneven access across populations. Given these considerations, it is important to address potential representation biases in fMRI datasets and develop solutions for improving diversity and inclusion. More generally, fMRI studies involving human subjects can raise a wide range of other ethical issues as well, including data privacy issues and informed consent. Further, one should be cautious about the deployment of attention or gaze prediction models in applications such as advertising. Given the value of eye tracking based attention in marketing spaces, public policy notices or political campaigns, it is important to be wary of a malicious use of these attention prediction methods for profit-seeking or by ill-intentioned parties seeking to further their own agendas. These applications regard attention as a commodity to be captured and the adopted technologies can be used to manipulate users in subtle ways. An improved understanding about the link between stimuli and perceptual processing in the brain, as provided with encoding models, can also be exploited to further design or identify stimuli likely to elicit a specific emotional or cognitive response. The fact that these technologies can be deployed without the targeted individual’s knowledge or consent indicates it is important to protect users from the vulnerabilities exploited by these agents.",Broader Impact,366,15,,,FALSE,FALSE,FALSE,Neural encoding with visual attention,Neuroscience and Cognitive Science -> Brain Imaging,Deep Learning -> Attention Models; Deep Learning -> Predictive Models; Neuroscience and Cognitive Science -> Cognitive Science; Neuroscience and Cognitive Science -> Neural Coding; Neuroscience and Cognitive Science -> Visual Perception,Neuroscience and cognitive science,"['Meenakshi Khosla', ' Gia Ngo', ' Keith Jamison', ' Amy Kuceyeski', ' Mert Sabuncu']","{'Cornell', 'Cornell University'}",1,0,0,{'USA'}
On the linearity of large non-linear models: when and why the tangent kernel is constant,"Chaoyue Liu, Libin Zhu, Mikhail Belkin",On the linearity of large non-linear models: when and why the tangent kernel is constant,b7ae8fecf15b8b6c3c69eceae636d203,https://proceedings.neurips.cc/paper/2020/file/b7ae8fecf15b8b6c3c69eceae636d203-Paper.pdf,Our work concentrates on the theoretical aspects of neural networks. We believe that better understanding of the mathematical structures underlying their empirical success is a necessary component of further progress on their practical applications.,Broader impact,34,2,FALSE,FALSE,FALSE,FALSE,FALSE,On the linearity of large non-linear models: when and why the tangent kernel is constant,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Spaces of Functions and Kernels,Deep learning,,"{'UC San Diego', 'The Ohio State University'}",1,0,0,{'USA'}
PLLay: Efficient Topological Layer based on Persistent Landscapes,"Kwangho Kim, Jisu Kim, Manzil Zaheer, Joon Kim, Frederic Chazal, Larry Wasserman",PLLay: Efficient Topological Layer based on Persistence Landscapes,b803a9254688e259cde2ec0361c8abe4,https://proceedings.neurips.cc/paper/2020/file/b803a9254688e259cde2ec0361c8abe4-Paper.pdf,"This paper proposes a novel method of adapting tools in applied mathematics to enhance the learnability of deep learning models. Even though our methodology is generally applicable to any complex modern data, it is not tuned to a specific application that might improperly incur direct societal/ethical consequences. So the broader impact discussion is not needed for our work.",Broader Impact,58,3,TRUE,FALSE,FALSE,FALSE,FALSE,PLLay: Efficient Topological Layer based on Persistent Landscapes,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning,Deep Learning,Deep learning,,"{'INRIA', 'Google Research', 'Carnegie Mellon University', 'Inria Saclay'}",1,1,1,"{'France', 'USA'}"
Decentralized Langevin Dynamics for Bayesian Learning,"Anjaly Parayil, He Bai, Jemin George, Prudhvi Gurram",Decentralized Langevin Dynamics for Bayesian Learning,b8043b9b976639acb17b035ab8963f18,https://proceedings.neurips.cc/paper/2020/file/b8043b9b976639acb17b035ab8963f18-Paper.pdf,"This work presents a basic line of research on reducing computational complexity, enhancing speed of convergence, and addressing potential privacy issues associated with centralized Bayesian learning.  Experiments and empirical results cover a broad set of applications including parameter estimation for local non-convex models, logistic regression, image classification and outlier detection. We have used publicly available datasets, which have no implications on machine learning bias, fairness or ethics. Hence, we believe that this section about potential negative impact of our work on society is not applicable to the proposed work.",Broader Impact,89,4,TRUE,FALSE,FALSE,FALSE,FALSE,Decentralized Langevin Dynamics for Bayesian Learning,Probabilistic Methods -> MCMC,Algorithms -> Stochastic Methods; Deep Learning -> Optimization for Deep Networks; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization; Probabilistic Methods -> Bayesian Theory,Probabilistic methods and inference,"['Anjaly Parayil', ' He Bai', ' Jemin George', ' Prudhvi Gurram']","{'Postdoctoral Associate, Army Research Laboratory ', 'Booz Allen Hamilton', 'Army Research Laboratory', 'Oklahoma State University'}",1,1,1,{'USA'}
Shared Space Transfer Learning for analyzing multi-site fMRI data,"Muhammad Yousefnezhad, Alessandro Selvitella, Daoqiang Zhang, Andrew Greenshaw, Russell Greiner",Shared Space Transfer Learning for analyzing multi-site fMRI data,b837305e43f7e535a1506fc263eee3ed,https://proceedings.neurips.cc/paper/2020/file/b837305e43f7e535a1506fc263eee3ed-Paper.pdf,"In this paper, we develop the Shared Space Transfer Learning (SSTL) as a novel transfer learning (TL) approach that can functionally align homogeneous multi-site fMRI datasets and so improve the prediction performance in every site. Although the proposed method is used to analyzed multi-site fMRI datasets, it can also be seen as a general-purpose machine learning method for any multi-view domain adaption applications. The proposed method is evaluated by using publicly-available fMRI datasets —- provided by Open NEURO. SSTL is an open-source technique and can also be used via our GUI-based toolbox called easy fMRI. We do not anticipate any negative consequences for this study. We believe that SSTL’s multi-view technique for transfer learning will have strong practical applications — including, but not limited, neuroscience, computational psychiatry, human-brain interface, etc. In the future, we plan to utilize the proposed framework to analyze high-level cognitive processes such as movie stimuli.",Broader Impact,149,7,,,FALSE,FALSE,FALSE,Shared Space Transfer Learning for analyzing multi-site fMRI data,Neuroscience and Cognitive Science -> Neuroscience,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA); Algorithms -> Representation Learning; Neuroscience and Cognitive Science -> Brain Mapping; Neuroscience and Cognitive Science -> Cognitive Science",Neuroscience and cognitive science,"['Muhammad Yousefnezhad', ' Alessandro Selvitella', ' Daoqiang Zhang', ' Andrew Greenshaw', ' Russell Greiner']","{'Purdue University Fort Wayne', 'Nanjing University of Aeronautics and Astronautics', 'University of Alberta'}",1,0,0,"{'Canada', 'China'}"
The Diversified Ensemble Neural Network,"Shaofeng Zhang, Meng Liu, Junchi Yan",The Diversified Ensemble Neural Network,b86e8d03fe992d1b0e19656875ee557c,https://proceedings.neurips.cc/paper/2020/file/b86e8d03fe992d1b0e19656875ee557c-Paper.pdf,"Ensemble is a general technology to improve the performance of machine learning models. This paper makes contributions to ensemble technology, which may ultimately improve the performance of AI systems. The potential risk is the possible formation of super AI out of the control of human beings. Also, individual privacy may be put at risk due to the strengthened AI capability.",Broader Impact,60,4,FALSE,FALSE,FALSE,TRUE,FALSE,The Diversified Ensemble Neural Network,Algorithms -> Boosting and Ensemble Methods,Algorithms -> Classification; Algorithms -> Regression; Deep Learning -> Supervised Deep Networks,Deep learning,"['Shaofeng Zhang', ' Meng Liu', ' Junchi Yan']","{' university of electronic science and technology of china', 'University of Electronic Science and Technology of China', 'Shanghai Jiao Tong University'}",1,0,0,{'China'}
Inductive Quantum Embedding,"Santosh Kumar Srivastava, Dinesh Khandelwal, Dhiraj Madan, Dinesh Garg, Hima Karanam, L Venkata Subramaniam",Inductive Quantum Embedding,b87039703fe79778e9f140b78621d7fb,https://proceedings.neurips.cc/paper/2020/file/b87039703fe79778e9f140b78621d7fb-Paper.pdf,"Knowledge Representation (KR) is an important subfield of Artificial Intelligence and plays a crucial role in designing any complex AI system that aims to mimic human like reasoning. Prominent examples of such a system include automated question answering, document search, and retrieval, product recommendation, automated dialogue/conversation, automated navigation, etc. The purpose of KR is to encode a symbolic Knowledge-Base (KB) within a machine reasoning system. These KBs could be domain/application-specific, such as medical, fashion, retail, e-commerce, etc; could be in public domain , or proprietary to an organization/enterprise . The most common examples of KBs in the public domain include DBPedia [27] and WordNet [28]. There are two key approaches to KR - (i) Discrete symbolic representation , (ii) Continuous vector representation [2]. In symbolic representation, knowledge facts are represented by symbols, and some form of logical reasoning (for example, first-order logic) is used to infer new facts and make deductions. Symbolic reasoning is exact but slow, brittle, and noise-sensitive . Vector representation stems from the field of Statistical Relational Learning [4, 5], where knowledge is embedded into a vector space using a distributional representation capturing the (dis)similarities among entities and predicates. Vector representations are fast, noise-robust , but approximate . Despite being fast, most of the vector representation techniques do not offer explicit means of preserving the logical structure of the input Knowledge-Base (KB) inside vector space. Making these observations, Dominic [6, 7] hinted at using Quantum Logic [8] framework to fix the word meaning disambiguation problem in keyword-based search engines. This idea was further developed and extended recently by Garg et al. [1], where they have proposed a new approach for vector representation of symbolic KBs – called as Quantum Embedding (QE) . This paper identifies two critical gaps in the QE approach [1] for KR. The end outcome is a refinement of the QE idea bridging these gaps. Specifically, we noticed that the original idea of quantum embedding [1] is transductive (and not inductive ) in nature. That is, it can learn to embed a given symbolic KB; however, for an unseen knowledge element (entity or predicate), it does not prescribe any recipe to embed the same in an incremental way. The only way seems to restart from scratch and reproduce the whole embedding by including the new knowledge element. This, in our view, limits the applicability of the quantum embeddings in practical applications. Further, we also noticed that the computational scheme suggested in [1] for generating quantum embedding is quite slow because it is based on the general-purpose Stochastic Gradient Descent (SGD) algorithm. To address the above gaps, we first propose a reformulation of the original model [1] that allows ingestion of entities’ initial feature vectors and thereby, opening a way for the inductive extension. We call this optimization problem as I nductive Qu antum E mbedding (IQE) problem. Next, we discover some interesting analytic and geometric properties and leverage them to design a faster training scheme. As an application, we consider the well-known NLP task of fine-grained entity type classification [16, 17, 18, 19, 20, 21, 22]. We show that one can use IQE formulation for this task to infer quantum embeddings of unseen test entities and subsequently use those quantum embedding (instead of initial feature vectors) to infer the entity’s class label. We show that our proposed IQE approach achieves a state-of-the-art performance on this task and runs 9 -times faster than the original QE scheme. Although, a good part of this paper is theoretical in nature, the refinements proposed in this paper can impact the adoption of QE idea for knowledge representation in broad range of applications including automated question answering, document search and retrieval, product recommendation, automated dialogue/conversation systems, etc. These applications are now an integral part of our daily lives. We witness them in customer support service, e-commerce platforms, online education platforms, voice-based search, home automation, vehicle navigation, etc. Improving such systems’ performance offers huge societal benefits such as cost/time savings, removing repetitive tasks, and increasing autonomy for the elderly/children. However, this also poses societal risks, including adversarial attacks, hacking into such systems, and biasing them with malicious intents, risk of having different kinds of biases in training data, etc. We would encourage the research community to study further the extent to which such representations can be manipulated by an adversary either by biasing the training data or hacking the system.",7 Broader Impact,730,33,,,FALSE,TRUE,FALSE,Inductive Quantum Embedding,Deep Learning -> Embedding Approaches,Algorithms -> Relational Learning; Neuroscience and Cognitive Science -> Reasoning; Optimization,Knowledge Representation and Reasoning,"[' Srivastava', ' Dinesh Khandelwal', ' Dhiraj Madan', ' Dinesh Garg', ' Hima Karanam', ' L Venkata Subramaniam']","{'IBM Research', 'IBM Research AI', 'IBM Research AI, India', 'IBM Research AI - India'}",0,1,0,{'USA'}
Variational Bayesian Unlearning,"Quoc Phong Nguyen, Bryan Kian Hsiang Low, Patrick Jaillet",Variational Bayesian Unlearning,b8a6550662b363eb34145965d64d0cfb,https://proceedings.neurips.cc/paper/2020/file/b8a6550662b363eb34145965d64d0cfb-Paper.pdf,"As discussed in our introduction (Sec. 1), a direct contribution of our work to the society in this information age is to the implementation of personal data ownership (i.e., enforced by the General Data Protection Regulation in the European Union [24]) by studying the problem of machine unlearning for Bayesian models. Such an implementation can boost the confidence of users about sharing their data with an application/organization when they know that the trace of their data can be reduced/erased, as requested. As a result, organizations/applications can gather more useful data from users to enhance their service back to the users and hence to the society. Our unlearning work can also contribute to the defense against data poisoning attacks (i.e., injecting malicious training data). Instead of retraining the tampered machine learning model from scratch to recover the quality of a service, unlearning the model from the detected malicious data may incur much less time, which improves the user experience and reduces the cost due to the service disruption. In contrast, the ability to unlearn machine learning models may also open the door to new adversarial activities. For example, in the context of data sharing, multiple parties share their data to train a common machine learning model. An unethical party can deliberately share a low-quality dataset instead of its high-quality one. After obtaining the model trained on datasets from all parties (including the low-quality dataset), the unethical party can unlearn the low-quality dataset and continue to train the model with its high-quality dataset. By doing this, the unethical party achieves a better model than other parties in the collaboration. Therefore, the possibility of machine unlearning should be considered in the design of different data sharing frameworks.",Broader Impact,284,12,,,FALSE,FALSE,FALSE,Variational Bayesian Unlearning,Probabilistic Methods -> Variational Inference,,Probabilistic methods and inference,"['Quoc Phong Nguyen', ' Bryan Kian Hsiang Low', ' Patrick Jaillet']","{'MIT', 'National University of Singapore'}",1,0,0,"{'Singapore', 'USA'}"
Batched Coarse Ranking in Multi-Armed Bandits,"Nikolai Karpov, Qin Zhang",Batched Coarse Ranking in Multi-Armed Bandits,b8b9c74ac526fffbeb2d39ab038d1cd7,https://proceedings.neurips.cc/paper/2020/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf,"This work can help with ranking objects in various settings such as recommendation systems, peer grading in massive open online courses and paid crowdsourcing platforms. Our ranking algorithms are based on unbiased mathematical mechanisms, and is fair to everyone in this regards.",Broader Impact,42,2,FALSE,FALSE,TRUE,TRUE,TRUE,Batched Coarse Ranking in Multi-Armed Bandits,Algorithms -> Bandit Algorithms,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Nikolai Karpov', ' Qin Zhang']",{'Indiana University Bloomington'},1,0,0,{'USA'}
Understanding and Improving Fast Adversarial Training,"Maksym Andriushchenko, Nicolas Flammarion",Understanding and Improving Fast Adversarial Training,b8ce47761ed7b3b6f48b583350b7f9e4,https://proceedings.neurips.cc/paper/2020/file/b8ce47761ed7b3b6f48b583350b7f9e4-Paper.pdf,"Our work focuses on a systematic study of the failure reasons behind computationally efficient adversarial training methods. We suggest a new regularization approach which helps to overcome the shortcoming of the existing methods that is known as catastrophic overfitting .  We see primarily positive outcomes from our work since adversarial robustness is a desirable property that improves the reliability of machine learning models. Therefore, it is crucial to be able to train robust models efficiently and without limiting efficient training only to perturbations of a small size.",Broader Impact,87,4,,,FALSE,FALSE,FALSE,Understanding and Improving Fast Adversarial Training,Algorithms -> Adversarial Learning,,Deep learning,"['Maksym Andriushchenko', ' Nicolas Flammarion']",{'EPFL'},1,0,0,{'Switzerland'}
Coded Sequential Matrix Multiplication For Straggler Mitigation,"Nikhil Krishnan Muralee Krishnan, Seyederfan Hosseini, Ashish Khisti",Coded Sequential Matrix Multiplication For Straggler Mitigation,b8fd7211e5247891e4d4f0562418868a,https://proceedings.neurips.cc/paper/2020/file/b8fd7211e5247891e4d4f0562418868a-Paper.pdf,"The new coding schemes that we propose here aim to reduce the cumulative processing time of a sequence of matrix multiplication jobs. This could result in energy savings. Hence, our work has the potential to contribute towards energy initiatives.",Broader Impact,39,3,FALSE,FALSE,FALSE,FALSE,FALSE,Coded Sequential Matrix Multiplication For Straggler Mitigation,Theory -> Information Theory,Algorithms -> Large Scale Learning,Theory (including computational and statistical analyses),"['Nikhil Krishnan Muralee Krishnan', ' Seyederfan Hosseini', ' Ashish Khisti']",{'University of Toronto'},1,0,0,{'Canada'}
"Attack of the Tails: Yes, You Really Can Backdoor Federated Learning","Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, Dimitris Papailiopoulos","Attack of the Tails: Yes, You Really Can Backdoor Federated Learning",b8ffa41d4e492f0fad2f13e29e1762eb,https://proceedings.neurips.cc/paper/2020/file/b8ffa41d4e492f0fad2f13e29e1762eb-Paper.pdf,"Federated Learning has been proposed recently as a new paradigm to train predictive models on heterogeneous user data, so that applications like personal assistants can be more personalized, while simultaneously ensuring user privacy. Because this technique is expected to be deployed on millions or even billions of devices in the future, a tight scrutiny on all aspects of this framework is necessitated. Fundamental security risks of FL We hope that our work will act as a strong signal to the FL community by showcasing strong edge-case backdoors . Edge-case data refers to data points that reside on the tails of the input distribution, i.e., rare, but natural inputs. Edge-case backdoors are attacks that target such data points and force them to be misclassified by the predictive global model. We show that it is easy to build these backdoors across many tasks, ranging from image classification to next-word prediction, and demonstrate that edge-case backdoors can be hard-wired to FL models. Edge-case backdoors can further bypass state-of-the-art defense mechanisms proposed in the literature. More worryingly, since they do not affect the majority of the data, they tend to go unnoticed, especially when the metrics which test the quality of the system look at aggregate performance measures. This problem is unfortunately not new, and there have been incidents in the past that have brought it to light [36]. For example, in autonomous vehicles, backdoor attacks have been known to compromise security [37, 38]. Security mechanisms can lead unequal user treatment Another untactful aspect of our work is that it highlights that attempts to improve the security and robustness of FL systems may result in an unfair treatment of the clients served. That is, secure and robustness mechanisms for FL may successfully defend against backdoor attacks, but they may also filter out users that simply hold data that are simply diverse compared to the average user. This leads to an alarming fairness counter-effect with regards to robustness and demonstrates a largely unexplored fairness and robustness trade-off which has already been conjectured in [12]. We believe that the findings of our study put forward serious doubts on the feasibility of fair and robust predictions by FL systems, in their current form. In summary, the results of our work is to question the robustness, security, and fairness guarantees of FL system providers, and present several important challenges to the related research community.",6 Broader Impacts,396,15,,,FALSE,FALSE,FALSE,"Attack of the Tails: Yes, You Really Can Backdoor Federated Learning",Algorithms -> Large Scale Learning,Algorithms -> Adversarial Learning; Optimization,federated learning,"['Hongyi Wang', ' Kartik Sreenivasan', ' Shashank Rajput', ' Harit Vishwakarma', 'yong Sohn', ' Saurabh Agarwal', ' Kangwook Lee', ' Dimitris Papailiopoulos']","{'University of Wisconsin - Madison', 'University of Wisconsin Madison', 'UW Madison', 'UW-Madison', 'University of Wisconsin-Madison', 'KAIST'}",1,0,0,"{'South Korea', 'USA'}"
Certifiably Adversarially Robust Detection of Out-of-Distribution Data,"Julian Bitterwolf, Alexander Meinke, Matthias Hein",Certifiably Adversarially Robust Detection of Out-of-Distribution Data,b90c46963248e6d7aab1e0f429743ca0,https://proceedings.neurips.cc/paper/2020/file/b90c46963248e6d7aab1e0f429743ca0-Paper.pdf,"In order to use machine learning in safety-critical systems it is required that the machine learning system correctly flags its uncertainty. As neural networks have been shown to be overconfident far away from the training data, this work aims at overcoming this issue by not only enforcing low confidence on out-distribution images but even guaranteeing low confidence in a neighborhood around it. As a neural network should not flag that it knows when it does not know, this paper contributes to a safer use of deep learning classifiers.",Broader Impact,88,3,,,FALSE,FALSE,FALSE,Certifiably Adversarially Robust Detection of Out-of-Distribution Data,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Adversarial Learning; Applications -> Computer Vision,"Social aspects of machine learning (e.g., fairness, safety, privacy)",,{'University of Tübingen'},1,0,0,{'Germany'}
Domain Generalization via Entropy Regularization,"Shanshan Zhao, Mingming Gong, Tongliang Liu, Huan Fu, Dacheng Tao",Domain Generalization via Entropy Regularization,b98249b38337c5088bbc660d8f872d6a,https://proceedings.neurips.cc/paper/2020/file/b98249b38337c5088bbc660d8f872d6a-Paper.pdf,"Model generalization is a significant subject, since it is almost impossible for us to train a model for each scenario. However, due to the domain bias, the model trained on a domain often performs worse on other domains. Through exploiting the domain generalization techniques, we can train a model on the publicly available datasets, and then deploy it on other related scenarios directly or with few adaptations. Therefore, the industries can reduce their costs in repeating training the models. On the other hand, since the model is trained on multiple datasets sampled from different domains, the domain generalization techniques can reduce over-fitting, and thus courage the model generate fair results. Based on our knowledge, our work may not have an adverse impact on ethical aspects and future societal consequences.",Broader Impact,129,6,,,FALSE,FALSE,FALSE,Domain Generalization via Entropy Regularization,Applications -> Computer Vision,Applications -> Object Recognition,Vision,"['Shanshan Zhao', ' Mingming Gong', ' Tongliang Liu', ' Huan Fu', ' Dacheng Tao']","{'Alibaba Group', 'University of Sydney', 'The University of Sydney', 'University of Melbourne'}",1,1,1,"{'Australia', 'China'}"
Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels,"Massimiliano Patacchiola, Jack Turner, Elliot J. Crowley, Michael O'Boyle, Amos J. Storkey",Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels,b9cfe8b6042cf759dc4c0cccb27a6737,https://proceedings.neurips.cc/paper/2020/file/b9cfe8b6042cf759dc4c0cccb27a6737-Paper.pdf,"The main motivation of this work has been to design a simple yet effective Bayesian method for dealing with the few-shot learning setting. The ability to learn from a reduced amount of data is crucial if we want to have systems that are able to deal with concrete real-world problems. Applications include (but are not limited to): classification and regression under constrained computational resources, medical diagnosis from small datasets, biometric identification from a handful of images, etc. Our method is one of the few which is able to provide a measure of uncertainty as a feedback for the decision maker. However, it is important to wisely choose the data on which the system is trained, since the low-data regime may be prone to bias more than the standard counterpart. If data is biased our method is not guaranteed to provide a correct estimation; this could harm the final users and should be carefully taken into account.",Broader Impact,156,6,,,FALSE,FALSE,FALSE,Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels,Algorithms -> Few-Shot Learning,Algorithms -> Meta-Learning; Algorithms -> Regression; Probabilistic Methods -> Bayesian Nonparametrics,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Massimiliano Patacchiola', ' Jack Turner', ' Crowley', 'Boyle', ' Amos Storkey']",{'University of Edinburgh'},1,0,0,{'UK'}
Skeleton-bridged Point Completion: From Global Inference to Local Adjustment,"Yinyu Nie, Yiqun Lin, Xiaoguang Han, Shihui Guo, Jian Chang, Shuguang Cui, Jian.J Zhang",Skeleton-bridged Point Completion: From Global Inference to Local Adjustment,ba036d228858d76fb89189853a5503bd,https://proceedings.neurips.cc/paper/2020/file/ba036d228858d76fb89189853a5503bd-Paper.pdf,"Shape completion techniques have wide applications in industries, such as 3D data acquisition, shape surface recovery and robot navigation. Our research focuses on point cloud completion from scanning data. It shows benefits in improving the efficiency of 3D scanning in real-world environments, where objects are usually partly observable (e.g., occluded or with poor illumination conditions). Besides, it can also enhance the 3D scene reconstruction results from scanned data. On this base, It further helps collision detection for robots in automatic navigation. With the development of 3D cultural hetritage digitalization, it also shows potential capability in restoring 3D shapes of ancient artifacts. It also can be used as a 3D geometry restoration and repairing tool in computer graphics. We think there are no ethical or societal risks with this technique.",Broader Impact,129,8,,,FALSE,FALSE,FALSE,Skeleton-bridged Point Completion: From Global Inference to Local Adjustment,Applications -> Computer Vision,Applications -> Robotics,Vision,"['Yinyu Nie', ' Xiaoguang Han', ' the Chinese University of Hong Kong', ' Yiqun Lin', ' Shihui Guo', ' Jian Chang', ' Shuguang Cui', 'J Zhang']","{'Bournemouth University', 'Xiamen University', 'Shenzhen', 'The Chinese University of Hong Kong, Shenzhen'}",1,0,0,"{'UK', 'China'}"
Compressing Images by Encoding Their Latent Representations with Relative Entropy Coding,"Gergely Flamich, Marton Havasi, José Miguel Hernández-Lobato",Compressing Images by Encoding Their Latent Representations with Relative Entropy Coding,ba053350fe56ed93e64b3e769062b680,https://proceedings.neurips.cc/paper/2020/file/ba053350fe56ed93e64b3e769062b680-Paper.pdf,"Our work presents a novel data compression framework and hence inherits both its up and downsides. In terms of positive societal impacts, data compression reduces the bandwidth requirements for many applications and websites, making them more inexpensive to access. This increases accessibility to online content in rural areas with limited connectivity or underdeveloped infrastructure. Moreover, it reduces the energy requirement and hence the environmental impact of information processing systems. However, care must be taken when storing information in a compressed form for long time periods, and backwards-compatibility of decoders must be maintained, as data may otherwise be irrevocably lost, leading to what has been termed the Digital Dark Ages (Kuny, 1997).",8 Broader Impact,111,5,,,FALSE,FALSE,FALSE,Compressing Images by Encoding Their Latent Representations with Relative Entropy Coding,Algorithms -> Data Compression,Probabilistic Methods -> Latent Variable Models; Theory -> Information Theory,Probabilistic methods and inference,"['Gergely Flamich', ' Marton Havasi', 'Lobato']",{'University of Cambridge'},1,0,0,{'UK'}
Improved Guarantees for k-means++ and k-means++ Parallel,"Konstantin Makarychev, Aravind Reddy, Liren Shan",Improved Guarantees for k -means++ and k -means++ Parallel,ba304f3809ed31d0ad97b5a2b5df2a39,https://proceedings.neurips.cc/paper/2020/file/ba304f3809ed31d0ad97b5a2b5df2a39-Paper.pdf,"In this paper, we analyze very popular clustering algorithms and provide new approximation guaran- tees for them. We believe that our work gives new insights that will lead to development of better clustering algorithms.",Broader Impact,34,2,FALSE,FALSE,FALSE,FALSE,FALSE,Improved Guarantees for k-means++ and k-means++ Parallel,Algorithms -> Clustering,Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Konstantin Makarychev', ' Aravind Reddy', ' Liren Shan']",{'Northwestern University'},1,0,0,{'USA'}
Sparse Spectrum Warped Input Measures for Nonstationary Kernel Learning,"Anthony Tompkins, Rafael Oliveira, Fabio T. Ramos",Sparse Spectrum Warped Input Measures for Nonstationary Kernel Learning,ba3c95c2962d3aab2f6e667932daa3c5,https://proceedings.neurips.cc/paper/2020/file/ba3c95c2962d3aab2f6e667932daa3c5-Paper.pdf,"The problem we address in this paper of efficient modelling of nonstationary stochastic processes is fundamental in geostatistics, time-series analysis, and the study of dynamical systems. To this end, our technique is directly applicable to spatial-temporal problems such as air pollution monitoring, the spread of diseases, and the study of natural resources such as underground water. In all of these problems, the strength of the spatial relationships between inputs varies with respect to the location. For example, during the current pandemic, nearby cities might exhibit different levels of infection rates within their boundaries but still being related due to infected people travelling between them Senanayake et al. [48]. Our approach is directly applicable to these cases and can be incorporated within epidemiological models that typically aggregate populations in large regions for a more refined prediction and study of intervention policies such as social distancing.",Broader Impact,144,6,,,FALSE,FALSE,FALSE,Sparse Spectrum Warped Input Measures for Nonstationary Kernel Learning,Algorithms -> Kernel Methods,Algorithms -> Regression; Algorithms -> Spectral Methods; Probabilistic Methods -> Gaussian Processes,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Anthony Tompkins', ' Rafael Oliveira', ' Fabio Ramos']","{'The University of Sydney', 'University of Sydney, NVIDIA'}",1,1,1,"{'Australia', 'USA'}"
An Efficient Adversarial Attack for Tree Ensembles,"Chong Zhang, Huan Zhang, Cho-Jui Hsieh",An Efficient Adversarial Attack for Tree Ensembles,ba3e9b6a519cfddc560b5d53210df1bd,https://proceedings.neurips.cc/paper/2020/file/ba3e9b6a519cfddc560b5d53210df1bd-Paper.pdf,"To the best of our knowledge, this is the first practical attack algorithm (in terms of both computational time and solution quality) that can be used to evaluate the robustness of tree ensembles. The study of robustness training algorithms for tree ensemble models have been difficult due to the lack of attack tools to evaluate their robustness, and our method can serve as the benchmark tool for robustness evaluation (similar to FGSM, PGD and C&W attacks for neural networks) (Goodfellow et al., 2015; Madry et al., 2018; Carlini, Wagner, 2017) to stimulate the research in the robustness of tree ensembles.",Broader Impact,100,2,,,FALSE,FALSE,FALSE,An Efficient Adversarial Attack for Tree Ensembles,Algorithms -> Boosting and Ensemble Methods,Algorithms -> Adversarial Learning,Boosting and Ensemble Methods,"['Chong Zhang', ' Huan Zhang', 'Jui Hsieh']",{'UCLA'},1,0,0,{'USA'}
Learning Continuous System Dynamics from Irregularly-Sampled Partial Observations,"Zijie Huang, Yizhou Sun, Wei Wang",Learning Continuous System Dynamics from Irregularly-Sampled Partial Observations,ba4849411c8bbdd386150e5e32204198,https://proceedings.neurips.cc/paper/2020/file/ba4849411c8bbdd386150e5e32204198-Paper.pdf,"Learning system dynamics is an important task in various of fields such as biology, physics, robotics, etc. Existing models only work for fully observable systems, requiring the observations of all object at each sample timestamp. However in reality, data is usually incomplete due to various reasons such as broken sensors. More challengingly, observations can happen at non-uniform intervals. Our model is able to learn system dynamics from such irregularly-sampled partial observations, and can be applied to various applications such as planning and control in robotics especially when data is incomplete.",Broader Impact,90,5,,,FALSE,FALSE,FALSE,Learning Continuous System Dynamics from Irregularly-Sampled Partial Observations,Deep Learning,Algorithms -> Dynamical Systems; Deep Learning -> Generative Models; Deep Learning -> Predictive Models,Deep learning,,"{'UCLA', 'University of California, Los Angeles'}",1,1,1,{'USA'}
Online Bayesian Persuasion,"Matteo Castiglioni, Andrea Celli, Alberto Marchesi, Nicola Gatti",Online Bayesian Persuasion,ba5451d3c91a0f982f103cdbe249bc78,https://proceedings.neurips.cc/paper/2020/file/ba5451d3c91a0f982f103cdbe249bc78-Paper.pdf,"Bayesian persuasion is a fascinating model that suffers from some limiting assumptions, which prevented a widespread use of the framework in practical applications. This work tries to amend one of such limitations, by relaxing the constraint that the sender has to have a perfect knowledge of the payoff structure of the game. This goes in the direction of developing a complete theory of Bayesian persuasion from data as a framework based solely on sender’s and receiver’s historical observations. In the future, an application of this framework at scale ( e.g. , on large social platforms) could raise some societal challenges (see, e.g. , recent works on Bayesian persuasion as an election- manipulation tool). Therefore, future research in this direction should prioritize the study of how to protect receivers from excessive information garbling, and how to incentivize senders to work towards a socially-acceptable outcome.",Broader Impact,143,5,,,FALSE,FALSE,FALSE,Online Bayesian Persuasion,Theory -> Game Theory and Computational Economics,,Game Theory,"['Matteo Castiglioni', ' Andrea Celli', ' Alberto Marchesi', ' Nicola Gatti']",{'Politecnico di Milano'},1,0,0,{'Italy'}
Robust Pre-Training by Adversarial Contrastive Learning,"Ziyu Jiang, Tianlong Chen, Ting Chen, Zhangyang Wang",Robust Pre-Training by Adversarial Contrastive Learning,ba7e36c43aff315c00ec2b8625e3b719,https://proceedings.neurips.cc/paper/2020/file/ba7e36c43aff315c00ec2b8625e3b719-Paper.pdf,"Defending machine learning models against adversarial attacks is a crucial component towards the goal of making AI systems more secure and trustworthy. Our proposed framework of Adversarial Contrastive Learning can be a powerful tool to improve model robustness in a data-efficient fashion. It advances the latest achievement in robustness-aware pre-training, and the results further raise the state-the-art bars for both supervised and semi-supervised adversarial training. We expect our techniques to contribute to the grand goal of building more secured and trustworthy AI.",Acknowledgments Broader Impact,82,4,,,FALSE,FALSE,FALSE,Robust Pre-Training by Adversarial Contrastive Learning,Algorithms -> Adversarial Learning,Algorithms -> Semi-Supervised Learning; Algorithms -> Unsupervised Learning,AutoML,,"{'Google', 'University of Texas at Austin', 'Unversity of Texas at Austin'}",1,1,1,{'USA'}
Random Walk Graph Neural Networks,"Giannis Nikolentzos, Michalis Vazirgiannis",Random Walk Graph Neural Networks,ba95d78a7c942571185308775a97a3a0,https://proceedings.neurips.cc/paper/2020/file/ba95d78a7c942571185308775a97a3a0-Paper.pdf,"GNNs have attracted a lot of attention in the past years and have been applied to a wide range of problems, mainly in chemoinformatics, bioinformatics, computer vision and natural language processing [50]. We claim that GNNs bear a stark representational power and can thus be used in more application domains. What is currently missing is interpretability of the structures learned as they are counter-intuitive. Our research in this paper offers a novel architecture tackling these problems by representing input graphs in terms of learnable discriminative small graphs that can be interpreted by human experts in the specific domain. Importantly, due to its transparency, our model can provide explanations of the results in these applications, improving understanding of decisions and of the underlying models. In addition to the intrepretability it brings, the model is also competitive in terms of performance (e. g., accuracy in classification tasks). Depending on the application, it can help mitigate different risks or can also give rise to new opportunities. For instance, the learned graph features could assist pharmaceutical chemists in drug design or physicists in explaining laws of physics. However, there are also potential risks associated with our research. First, blind trust in our model (or machine learning models in general) which may incur risks. Second, if systems are used by individuals that do not have the necessary level of knowledge and skills, it is likely that the models will not be properly applied to the underlying problems and/or there will be an incorrect interpretation of the results. Therefore, our model, as all AI methods, needs sufficient human supervision and involvement of human experts. We thus encourage research efforts to understand the impacts and limitations of using our model in real-world scenarios.",Broader Impact,286,13,,,FALSE,FALSE,FALSE,Random Walk Graph Neural Networks,Applications -> Network Analysis,Algorithms -> Classification; Deep Learning -> Supervised Deep Networks,Graph learning,"['Giannis Nikolentzos', ' Michalis Vazirgiannis']","{'Athens University of Economics and Business', 'École Polytechnique'}",1,0,0,"{'Greece', 'France'}"
"Explore Aggressively, Update Conservatively: Stochastic Extragradient Methods with Variable Stepsize Scaling","Yu-Guan Hsieh, Franck Iutzeler, Jérôme Malick, Panayotis Mertikopoulos","Explore Aggressively, Update Conservatively: Stochastic Extragradient Methods with Variable Stepsize Scaling",ba9a56ce0a9bfa26e8ed9e10b2cc8f46,https://proceedings.neurips.cc/paper/2020/file/ba9a56ce0a9bfa26e8ed9e10b2cc8f46-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader impact,9,1,TRUE,FALSE,FALSE,TRUE,FALSE,"Explore Aggressively, Update Conservatively: Stochastic Extragradient Methods with Variable Stepsize Scaling",Optimization,Optimization -> Convex Optimization; Optimization -> Stochastic Optimization; Theory -> Game Theory and Computational Economics,Optimization Methods (continuous or discrete),"['Guan Hsieh', ' Franck Iutzeler', ' Jérôme Malick', ' Panayotis Mertikopoulos', 'CNRS']","{'French National Center for Scientific Research', 'Université Grenoble Alpes / École Normale Supérieure Paris', 'CNRS and LJK'}",1,0,0,{'France'}
Fast and Accurate kk-means++ via Rejection Sampling,"Vincent Cohen-Addad, Silvio Lattanzi, Ashkan Norouzi-Fard, Christian Sohler, Ola Svensson",Fast and Accurate k -means++ via Rejection Sampling,babcff88f8be8c4795bd6f0f8cccca61,https://proceedings.neurips.cc/paper/2020/file/babcff88f8be8c4795bd6f0f8cccca61-Paper.pdf,"Our work focuses on speeding-up the very popular K - MEANS ++ algorithm for clustering. The K - MEANS ++ algorithm is used in a variety of domains and is an important tool for extracting information, compressing data, or unsupervised classification tasks. Our result shows that one can obtain a much faster implementation of the k -means++ algorithm while preserving its approximation guarantees both in theory and in practice. Therefore, we expect that our new algorithm could have impact in several domains in which clustering plays an important role. A broader concrete impact in society is harder to predict since this is mainly fundamental research.",Broader Impact,105,5,,,FALSE,FALSE,FALSE,Fast and Accurate $k$-means++ via Rejection Sampling,Algorithms -> Clustering,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Addad', ' Silvio Lattanzi', 'Fard', ' Christian Sohler', ' Ola Svensson']","{'EPFL', 'CNRS & Sorbonne Université', 'University of Cologne', 'Google Research'}",1,1,1,"{'France', 'USA', 'Switzerland', 'Germany'}"
Variational Amodal Object Completion,"Huan Ling, David  Acuna, Karsten Kreis, Seung Wook Kim, Sanja Fidler",Variational Amodal Object Completion,bacadc62d6e67d7897cef027fa2d416c,https://proceedings.neurips.cc/paper/2020/file/bacadc62d6e67d7897cef027fa2d416c-Paper.pdf,"Our proposed model can be used in a wide range of applications that require reasoning on occluded objects. These include planning tasks in robotics, object tracking, and editing a photo or video. We focus on two significant impacts of using our model. The first is in the context of autonomous driving. An autonomous driving car must infer the geometry and identity of surrounding objects for its decision-making process. Partially visible objects could lead to wrong estimates for motion planning, and thus reasoning about the full extent of objects can lead to much safer control. Our approach infers the complete shapes of the occluded objects for this purpose. The other major impact is on augmented reality. One could use our technology to snap a photograph of their environment, and ""delete"" existing objects from the photograph, replacing them with alternatives. The crux of our approach is in deleting content from an image, which could be subject to misuse. We encourage work on detecting fakes as the standard technology to deal with image manipulation approaches.",7 Broader Impact,172,11,,,FALSE,FALSE,FALSE,Variational Amodal Object Completion,Applications -> Computer Vision,Applications -> Visual Scene Analysis and Interpretation,Deep learning,"['Huan Ling', ' David Acuna', ' Karsten Kreis', ' Seung Wook Kim', ' Sanja Fidler']","{'University of Toronto, NVIDIA', 'NVIDIA', 'University of Toronto'}",1,1,1,"{'Canada', 'USA'}"
When Counterpoint Meets Chinese Folk Melodies,"Nan Jiang, Sheng Jin, Zhiyao Duan, Changshui Zhang",When Counterpoint Meets Chinese Folk Melodies,bae876e53dab654a3d9d9768b1b7b91a,https://proceedings.neurips.cc/paper/2020/file/bae876e53dab654a3d9d9768b1b7b91a-Paper.pdf,"The idea of integrating Western counterpoint into Chinese folk music generation is innovative. It would make positive broader impacts on three aspects: 1) It would facilitate more opportunities and challenges of music cultural exchanges at a much larger scale through automatic generation. For example, the inter-cultural style fused music could be used in Children’s enlightenment education to stimulate their interest in both cultures. 2) It would further the idea of collaborative counterpoint improvisation between two parts ( e . g ., a human and a machine) to music traditions where such interaction was less common. 3) The computer-generated music may “reshape the musical idiom”[23], which may bring more opportunities and possibilities to produce creative music. The proposed work may also have some potential negative societal impacts: 1) Similar to other computational creativity research, the generated music has the possibility of plagiarism by copying short snippets from the training corpus, even though copyright infringement is not a concern as neither folk melodies nor Bach’s music has copyright. That being said, our online music generation approach conditions music generation on past human and machine generation, and is less likely to directly copy snippets than offline approaches do. 2) The proposed innovative music generation approach may cause disruptions to current music professions, even deprive them of their means of existence[23]. However, it also opens new areas and creates new needs in this we-media era . Overall, we believe that the positive impacts significantly outweigh the negative impacts.",6 Broader Impact,244,11,,,FALSE,FALSE,FALSE,When Counterpoint Meets Chinese Folk Melodies,Applications -> Music Modeling and Analysis,Reinforcement Learning and Planning -> Reinforcement Learning,Audio / Music / Speech,"['Nan Jiang', ' Sheng Jin', ' Zhiyao Duan', ' Changshui Zhang']","{'Unversity of Rochester', 'Tsinghua University'}",1,0,0,{'China'}
Sub-linear Regret Bounds for Bayesian Optimisation in Unknown Search Spaces,"Hung Tran-The, Sunil Gupta, Santu Rana, Huong Ha, Svetha Venkatesh",Sub-linear Regret Bounds for Bayesian Optimisation in Unknown Search Spaces,bb073f2855d769be5bf191f6378f7150,https://proceedings.neurips.cc/paper/2020/file/bb073f2855d769be5bf191f6378f7150-Paper.pdf,"This work has potential to enable the scientists and researchers from the experimental design com- munity to optimise the design of products and processes without the need to specify a search space, which is usually not known accurately when pursuing new products and processes. There are no unethical side of this research or any ill-effects on society.",Broader Impact Statement,57,2,FALSE,FALSE,FALSE,FALSE,FALSE,Sub-linear Regret Bounds for Bayesian Optimisation in Unknown Search Spaces,Optimization -> Non-Convex Optimization,Probabilistic Methods -> Gaussian Processes,Optimization Methods (continuous or discrete),"['The', ' Sunil Gupta', ' Santu Rana', ' Huong Ha', ' Svetha Venkatesh']",{'Deakin University'},1,0,0,{'Australia'}
Universal Domain Adaptation through Self Supervision,"Kuniaki Saito, Donghyun Kim, Stan Sclaroff, Kate Saenko",Universal Domain Adaptation through Self-Supervision,bb7946e7d85c81a9e69fee1cea4a087c,https://proceedings.neurips.cc/paper/2020/file/bb7946e7d85c81a9e69fee1cea4a087c-Paper.pdf,"Our work is applicable to training deep neural networks with less supervision via knowledge transfer from auxiliary datasets. Modern deep networks outperform humans on many datasets given a lot of annotated data, such as in ImageNet. Our proposed method can help reduce the burden of collecting large-scale supervised data in many applications where large related datasets are available. The positive impact of our work is to reduce the data gathering effort for data-expensive applications. This can make the technology more accessible for institutions and individuals that do not have rich resources. It can also help applications where data is protected by privacy laws and is therefore difficult to gather, or in sim2real applications where simulated data is easy to create but real data is difficult to collect. The negative impacts could be to make these systems more accessible to companies, governments or individuals that attempt to use them for criminal activities such as fraud. Furthermore, As with all current deep learning systems, ours is susceptible to adversarial attacks and lack of interpretability. Finally, while we show improved performance relative to state-of-the-art, negative transfer could still occur, therefore our approach should not be used in mission-critical applications or to make important decisions without human oversight.",Broader Impact,204,9,,,FALSE,FALSE,FALSE,Universal Domain Adaptation through Self Supervision,Algorithms -> Multitask and Transfer Learning,Algorithms -> Clustering; Algorithms -> Semi-Supervised Learning; Algorithms -> Unsupervised Learning; Applications -> Computer Vision; Applications -> Object Recognition,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Kuniaki Saito', ' Donghyun Kim', ' Stan Sclaroff', ' Kate Saenko']",{'Boston University'},1,0,0,{'USA'}
Patch2Self: Denoising Diffusion MRI with Self-Supervised Learning​,"Shreyas Fadnavis, Joshua Batson, Eleftherios Garyfallidis",Patch2Self: Denoising Diffusion MRI with Self-Supervised Learning,bc047286b224b7bfa73d4cb02de1238d,https://proceedings.neurips.cc/paper/2020/file/bc047286b224b7bfa73d4cb02de1238d-Paper.pdf,"The broader impacts of this work fall into three categories: the direct impact on medical imaging, the theoretical impact on self-supervised learning more broadly, and the societal impact of improvements to those two technologies. In medical imaging, better denoising allows for higher quality images with fewer or shorter acquisitions, potentially making advanced acquisition schemes clinically viable, allowing for new bio-markers, and visualizing small structures such as the spinal cord in MRI. Patch2Self provides a method for doing fast local matrix approximations, which could be used for matrix completion, subspace tracking, and subspace clustering, with applications across signal processing domain. To the extent that self-supervision enhances the ability to extract signal from poor measurements, it may expand the reach of state or private surveillance apparatuses allowing people’s identities, movements, or disease status to be obtained from a greater distance and at lower cost. If a cache of easily acquired low-quality data can be efficiently used, it may open the door to exploitation by new actors.",Broader Impacts,164,5,,,FALSE,FALSE,FALSE,Patch2Self: Denoising Diffusion MRI with Self-Supervised Learning​,Neuroscience and Cognitive Science -> Brain Imaging,Algorithms -> Unsupervised Learning; Applications -> Denoising,Neuroscience and cognitive science,"['Shreyas Fadnavis Fadnavis', ' Joshua Batson', ' Eleftherios Garyfallidis']","{'Indiana University Bloomington', 'CZ Biohub', 'Indiana University'}",1,1,1,{'USA'}
Stochastic Normalization,"Zhi Kou, Kaichao You, Mingsheng Long, Jianmin Wang",Stochastic Normalization,bc573864331a9e42e4511de6f678aa83,https://proceedings.neurips.cc/paper/2020/file/bc573864331a9e42e4511de6f678aa83-Paper.pdf,"This paper proposes a new network module called StochNorm as the basic building block of deep neural networks. It can greatly improve fine-tuning of pretrained models in the small data regime. Its broader impact depends on the usage scenario of fine-tuning in deep learning applications. In addition, it may inspire some researchers for further investigation of regularization techniques.",Broader Impact,58,4,FALSE,TRUE,TRUE,TRUE,FALSE,Stochastic Normalization,Deep Learning -> CNN Architectures,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Zhi Kou', ' Kaichao You', ' Mingsheng Long', ' Jianmin Wang']",{'Tsinghua University'},1,0,0,{'China'}
Constrained episodic reinforcement learning in concave-convex and knapsack settings,"Kianté Brantley, Miro Dudik, Thodoris Lykouris, Sobhan Miryoosefi, Max Simchowitz, Aleksandrs Slivkins, Wen Sun",Constrained episodic reinforcement learning in concave-convex and knapsack settings,bc6d753857fe3dd4275dff707dedf329,https://proceedings.neurips.cc/paper/2020/file/bc6d753857fe3dd4275dff707dedf329-Paper.pdf,"Our work focuses on the theoretical foundations of reinforcement learning by addressing the important challenge of constrained optimization in reinforcement learning. We strongly believe that understanding the theoretical underpinnings of the main machine learning paradigms is essential and can guide principled and effective deployment of such methods. Beyond its theoretical contribution, our work may help the design of reinforcement learning algorithms that go beyond classical digital applications of RL (board games and video games) and extend to settings with complex and often competing objectives. We believe that constraints constitute a fundamental limitation in extending RL beyond the digital world, as they exist in a wide variety of sequential decision-making applications (robotics, medical treatment, education, advertising). Our work provides a paradigm to design algorithms with efficient exploration despite the presence of constraints. That said, one needs to ensure that an algorithm offers acceptable quality in applications. Any exploration method that does not rely on off-policy samples will inevitably violate constraints sometimes in order to learn. In some applications, this is totally acceptable: a car staying out of fuel in rare circumstances is not detrimental, an advertiser exhausting their budget some month is even less significant, a student dissatisfaction in an online test is unpleasant but probably acceptable. On the other hand, if the constraint violation involves critical issues like drug recommendation for severe diseases or decisions by self-driving cars that can cause physical harm to passengers then the algorithm needs to be carefully reviewed. It may be necessary to “prime” the algorithm with some data collected in advance (however costly it may be). One may need to make a judgement call on whether the ethical or societal standards are consistent with deploying an algorithm in a particular setting. To summarize, our work is theoretical in nature and makes significant progress on a problem at the heart of RL. It has the potential to guide deployment of constrained RL methods in many important applications and tackle a fundamental bottleneck in deploying RL beyond the digital world. However, an application needs to be carefully reviewed before deployment.",Broader Impact,344,14,FALSE,FALSE,TRUE,TRUE,FALSE,Constrained episodic reinforcement learning in concave-convex and knapsack settings,Reinforcement Learning and Planning,Algorithms -> Bandit Algorithms; Theory -> Statistical Learning Theory,Reinforcement learning and planning,"['Kianté Brantley', ' Miro Dudik', ' Thodoris Lykouris', ' Sobhan Miryoosefi', ' Max Simchowitz', ' Aleksandrs Slivkins', ' Wen Sun']","{'Princeton University', 'Microsoft Research', 'Microsoft Research NYC', 'The University of Maryland College Park', 'Berkeley'}",1,1,1,{'USA'}
On Learning Ising Models under Huber's Contamination Model,"Adarsh Prasad, Vishwak Srinivasan, Sivaraman Balakrishnan, Pradeep Ravikumar",On Learning Ising Models under Huber’s Contamination Model,bca382c81484983f2d437f97d1e141f3,https://proceedings.neurips.cc/paper/2020/file/bca382c81484983f2d437f97d1e141f3-Paper.pdf,"In this work, we provide statistically optimal estimators for learning Ising models under contamination. Ising models are themselves used in a variety of domains to learning relationship between pairs of binary random variables. One extremely interesting application is in the field of opinion analysis and voting network analysis. For instance, the nodes of the graph represent the voting base and the samples given to us are votes made of a series of topics as obtained via polls. Such estimators will help capture associations between voters. However, in a day and age where voting patterns are susceptible to adversarial corruptions, it is safe to assume that the vote samples are corrupted too. Using standard methods such as 1 -regularized logistic regression could have the unintended consequence of amplifying the biases from corrupted data, leading to poor judgements, whereas our methods are optimal resilient to such corruptions. However, if used without prior analysis of the data presented, this could potentially reduce the effect of outlier samples, which in the case of voting patterns, are representative of a minority groups.",Broader Impact,177,8,,,FALSE,FALSE,FALSE,On Learning Ising Models under Huber's Contamination Model,Theory -> Frequentist Statistics,Algorithms -> Model Selection and Structure Learning; Probabilistic Methods -> Graphical Models; Theory -> High-Dimensional Inference; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Adarsh Prasad', ' Vishwak Srinivasan', ' Sivaraman Balakrishnan', ' Pradeep Ravikumar']",{'Carnegie Mellon University'},1,0,0,{'USA'}
Cross-validation Confidence Intervals for Test Error,"Pierre Bayle, Alexandre Bayle, Lucas Janson, Lester Mackey",Cross-validation Confidence Intervals for Test Error,bce9abf229ffd7e570818476ee5d7dde,https://proceedings.neurips.cc/paper/2020/file/bce9abf229ffd7e570818476ee5d7dde-Paper.pdf,This work will benefit both users and developers of machine learning methods who want to rigor- ously assess or compare learning algorithms. Failure of the methods we discuss (which can only happen when the assumptions we state are not satisfied) may lead to the over- or under-estimation of the performance of a learning algorithm on a particular dataset.,Broader Impact,58,2,FALSE,FALSE,FALSE,FALSE,FALSE,Cross-validation Confidence Intervals for Test Error,Theory -> Large Deviations and Asymptotic Analysis,Algorithms -> Uncertainty Estimation,Theory (including computational and statistical analyses),"['Pierre Bayle', ' Alexandre Bayle', ' Lucas Janson', ' Lester Mackey']","{'Harvard University', 'Princeton University', 'Microsoft Research'}",1,1,1,{'USA'}
DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation,"Alexandre Carlier, Martin Danelljan, Alexandre Alahi, Radu Timofte",DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation,bcf9d6bd14a2095866ce8c950b702341,https://proceedings.neurips.cc/paper/2020/file/bcf9d6bd14a2095866ce8c950b702341-Paper.pdf,"DeepSVG can be used as animation tool by performing interpolations and other latent space operations on user-drawn SVGs. Similarly to recent advances in rasterized content creation, we believe this work will serve as a potential way for creators and digital artists to enhance their creativity and productivity.",Broader Impact,47,2,FALSE,FALSE,FALSE,FALSE,FALSE,DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation,Applications -> Computer Vision,Deep Learning -> Generative Models,,"['Alexandre Carlier', ' Martin Danelljan', ' Alexandre Alahi', ' Radu Timofte']","{'ETH Zurich', 'EPFL'}",1,0,0,{'Switzerland'}
Bayesian Attention Modules,"Xinjie Fan, Shujian Zhang, Bo Chen, Mingyuan Zhou",Bayesian Attention Modules,bcff3f632fd16ff099a49c2f0932b47a,https://proceedings.neurips.cc/paper/2020/file/bcff3f632fd16ff099a49c2f0932b47a-Paper.pdf,"Attention modules have become critical components for state-of-the-art neural network models in various applications, including computer vision, natural language processing, graph analysis, and multi-modal tasks, to name a few. While we show improvements brought by our work on five representative tasks from a broad range of domains, our framework is general enough that it could be used to improve potentially any attention based models. Also, our framework solves two main issues of previously proposed probabilistic attentions that restrict their popularity, i.e. , optimization difficulty and complicated model design. We hope that our work will encourage the community to pay more attention to stochastic attention and study from a probabilistic perspective. Considering that attention models have been adopted in many machine learning systems, our work could have an important impact on those systems, such as self-driving [63], healthcare [64], and recommender systems [65]. However, there are potential risks of applying such systems in real-life scenario, because the data we encounter in real-life is biased and long-tailed, and also the discrepancy between training data and testing data might be large. Therefore, an undue trust in deep learning models, incautious usage or imprecise interpretation of model output by inexperienced practitioners might lead to unexpected false reaction in real-life and unexpected consequences. However, we see opportunities that our work can help mitigate the risks with uncertainty estimation. Knowing when mistakes happen would enable us to know when to ask for human-aid if needed for real-life applications [66].",Broader Impact,243,9,,,FALSE,FALSE,FALSE,Bayesian Attention Modules,Deep Learning -> Attention Models,Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,Deep learning,"['Xinjie Fan', ' Shujian Zhang', ' Bo Chen', ' Mingyuan Zhou']","{'Xidian University', 'University of Texas at Austin', 'UT Austin'}",1,0,0,"{'USA', 'China'}"
Robustness Analysis of Non-Convex Stochastic Gradient Descent using Biased Expectations,"Kevin Scaman, Cedric Malherbe",Robustness Analysis of Non-Convex Stochastic Gradient Descent using Biased Expectations,bd4d08cd70f4be1982372107b3b448ef,https://proceedings.neurips.cc/paper/2020/file/bd4d08cd70f4be1982372107b3b448ef-Paper.pdf,"Based of the theoretical nature of the work, the authors do not believe this section is applicable to the present contribution, as its first goal is to provide some insights on a classical algorithm of the machine learning community and does not provide novel applications per se.",Broader impact,47,1,TRUE,FALSE,FALSE,FALSE,FALSE,Robustness Analysis of Non-Convex Stochastic Gradient Descent using Biased Expectations,Optimization -> Stochastic Optimization,Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Kevin Scaman', ' Cedric Malherbe']",{'Huawei Noah's Ark Lab'},0,1,0,{'China'}
SoftFlow: Probabilistic Framework for Normalizing Flow on Manifolds,"Hyeongju Kim, Hyeonseung Lee, Woo Hyun Kang, Joun Yeop Lee, Nam Soo Kim",SoftFlow: Probabilistic Framework for Normalizing Flow on Manifolds,bdbca288fee7f92f2bfa9f7012727740,https://proceedings.neurips.cc/paper/2020/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf,"This paper introduces a new way of designing a generative model for manifold data. This paper will motivate other researchers and engineers to employ the proposed framework for various applications. Like other generative models, the proposed model could produce biased samples if the training set is not properly set up. However, we believe that this paper will not cause a bad influence to the society in general use.",Broader Impact,68,4,,,FALSE,FALSE,FALSE,SoftFlow: Probabilistic Framework for Normalizing Flow on Manifolds,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Applications -> Computer Vision,Deep learning,"['Hyeongju Kim', ' Hyeonseung Lee', ' Woo Hyun Kang', ' Joun Yeop Lee', ' Nam Soo Kim']",{'Seoul National University'},1,0,0,{'South Korea'}
A meta-learning approach to (re)discover plasticity rules that carve a desired function into a neural network,"Basile Confavreux, Friedemann Zenke, Everton Agnes, Timothy Lillicrap, Tim Vogels",A meta-learning approach to (re)discover plasticity rules that carve a desired function into a neural network,bdbd5ebfde4934142c8a88e7a3796cd5,https://proceedings.neurips.cc/paper/2020/file/bdbd5ebfde4934142c8a88e7a3796cd5-Paper.pdf,"There may be up to 140 different synaptic plasticity rules at play in everyday behaviours such as making a simple memory. We have only begun to understand five or less of these rules, and for the foreseeable future experimental neuroscience will not be able to deliver the necessary data to dis-entwine this difficult puzzle. Machine learning and modern computing, on the other hand, have made huge advances in being able to simulate and analyse highly complex tasks. Utilising this power to infer plasticity rules and thus create experimental hypothesis is entirely possible, timely and urgent. We thus propose a first step in the development of a set of computational tools that allows us to discover the synaptic plasticity mechanisms responsible for developing and maintaining complex  structures through neuronal activity. Machine learning techniques give us the benefit of targeted, gradient-directed searches combined with fast and computationally powerful searches. We aim to eventually run our meta-learning algorithms to achieve connectivity and function of healthy and aberrant neural phenomena. Soon, we will be able to directly affect translational approaches that aim to utilise plasticity protocols for therapeutic approaches. Finding the families of plasticity rules that create functional neuronal networks in the brain will be a crucial and long lasting contribution to basic and applied science. Finally, our findings may also inspire the development of new ML tools, both for the analysis and training of artificial neural networks, which still have to live up to their potential in terms of generalisation and semantic knowledge representation. Biologically inspired rules may just prove to be the solution to many a problem at hand.",Broader Impact,267,11,FALSE,FALSE,FALSE,FALSE,FALSE,A meta-learning approach to (re)discover plasticity rules that carve a desired function into a neural network,Neuroscience and Cognitive Science -> Plasticity and Adaptation,Algorithms -> Meta-Learning; Neuroscience and Cognitive Science -> Neuroscience; Optimization -> Stochastic Optimization,Neuroscience and cognitive science,,"{'Friedrich Miescher Institute', 'University of Oxford', 'Institute of Science and Technology'}",1,0,0,"{'UK', 'Germany'}"
Greedy Optimization Provably Wins the Lottery: Logarithmic Number of Winning Tickets is Enough,"Mao Ye, Lemeng Wu, Qiang Liu",Greedy Optimization Provably Wins the Lottery: Logarithmic Number of Winning Tickets is Enough,be23c41621390a448779ee72409e5f49,https://proceedings.neurips.cc/paper/2020/file/be23c41621390a448779ee72409e5f49-Paper.pdf,"This work proposes a greedy optimization based pruning method, which has strong theoretical guarantee and good empirical performance. It gives positive improvement to the community of network efficiency. Our work do not have any negative societal impacts that we can foresee in the future.",Broader Impact Statement ,44,3,TRUE,TRUE,TRUE,TRUE,FALSE,Greedy Optimization Provably Wins the Lottery: Logarithmic Number of Winning Tickets is Enough,Deep Learning -> Efficient Inference Methods,Applications -> Computer Vision; Deep Learning -> CNN Architectures,,,"{'The University of Texas at Austin', 'UT Austin'}",1,0,0,{'USA'}
Path Integral Based Convolution and Pooling for Graph Neural Networks,"Zheng Ma, Junyu Xuan, Yu Guang Wang, Ming Li, Pietro Liò",Path Integral Based Convolution and Pooling for Graph Neural Networks,be53d253d6bc3258a8160556dda3e9b2,https://proceedings.neurips.cc/paper/2020/file/be53d253d6bc3258a8160556dda3e9b2-Paper.pdf,"The path integral based graph neural network presented in this paper provides a general framework for graph classification/regression tasks. We observe its advantages on the accuracy, convergence rate, and stability against many previous models. Given the physical ideas behind this framework, we believe PAN might be a powerful tool in analyzing biological, chemical, and physical systems. Specifically, the success over the simple point pattern dataset preludes its potentials in more sophisticated tasks such as detecting phase transitions and learning force fields in molecular dynamics, thus may accelerate materials discovery [7, 25]. Additionally, the study of PAN will potentially link the communities of both physics and machine learning. On the other hand, the PANPool strategy maintains a delicate balance on selecting representative nodes from both well-connected and “underrepresented"" regions; this pooling method might be of particular interest to social scientists under specific contexts. However, one must be aware that the use of graph neural networks in commercial settings, such as recommendation systems, lending preferences, and fraud detection, may lead to negative ethical or social consequences. Since graph neural networks tend to relate a node’s behavior to its environment, the abuse of this feature may, for example, enhance the growing opinion polarization in our society, and pose risks of systematic discrimination towards certain groups. Thus its use under these settings must be done with full mindfulness.",Broader Impact,224,9,,,FALSE,FALSE,FALSE,Path Integral Based Convolution and Pooling for Graph Neural Networks,Deep Learning,"Algorithms -> Classification; Algorithms -> Model Selection and Structure Learning; Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories",Deep learning,"['Zheng Ma', ' Junyu Xuan', ' Yu Guang Wang', ' Ming Li', ' Pietro Liò']","{'Princeton University', 'University of New South Wales', 'University of Cambridge', 'University of Technology Sydney', 'Zhejiang Normal University'}",1,0,0,"{'Australia', 'UK', 'USA', 'China'}"
Estimating the Effects of Continuous-valued Interventions using Generative Adversarial Networks,"Ioana Bica, James Jordon, Mihaela van der Schaar",Estimating the Effects of Continuous-valued Interventions using Generative Adversarial Networks,bea5955b308361a1b07bc55042e25e54,https://proceedings.neurips.cc/paper/2020/file/bea5955b308361a1b07bc55042e25e54-Paper.pdf,"The impact of this problem in the healthcare setting is clear - being able to better estimate individu- alised responses to dosages will help us select treatments that result in improved patient outcomes. Moreover, clinicians and patients will often need to consider several different outcomes (such as potential side effects); better estimates of such outcomes allow the patients to make a more informed decision that is suitable for them. Going beyond predictions by using causal inference methods to estimate the effect of interventions will result in more accurate and robust estimates and thus create more reliable components for use as part of decision support systems. Much of the recent work in causal inference has focused on binary or categorical treatments. Nevertheless, continuous interventions arise in many practical scenarios and building reliable methods for estimating their effects is paramount. We believe that our proposed model, SCIGAN, represents an important step forward in this direction. Nevertheless, we acknowledge the fact that the work presented in this paper is on the theoretical side and significant testing, potentially through clinical trials, will be needed before such methods can be used in practice, particularly due to the life-threatening implications of incorrect estimates. The risk of incorrectly assigning treatments can be significantly mitigated by ensuring that such models are used as support systems alongside clinicians, rather than instead of clinicians. All work towards better estimating and understanding interventions can be used negatively, where someone wishing to cause harm can use the estimated outcomes to select the worst outcome.",Broader Impact,252,9,,,FALSE,FALSE,FALSE,Estimating the Effects of Continuous-valued Interventions using Generative Adversarial Networks,Probabilistic Methods -> Causal Inference,Applications -> Health,Causality,"['Ioana Bica', ' James Jordon', ' Mihaela van der Schaar']","{'University of Cambridge', 'University of Oxford'}",1,0,0,{'UK'}
Latent Dynamic Factor Analysis of High-Dimensional Neural Recordings,"Heejong Bong, Zongge Liu, Zhao Ren, Matthew Smith, Valerie Ventura, Kass E. Robert",Latent Dynamic Factor Analysis of High-Dimensional Neural Recordings,beb04c41b45927cf7e9f8fd4bb519e86,https://proceedings.neurips.cc/paper/2020/file/beb04c41b45927cf7e9f8fd4bb519e86-Paper.pdf,"While progress in understanding the brain is improving life through research, especially in mental health and addiction, in no case is any brain disorder well understood mechanistically. Faced with the reality that each promising discovery inevitably reveals new subtleties, one reasonable goal is to be able to change behavior in desirable ways by modifying specific brain circuits and, in animals, technologies exist for circuit disruptions that are precise in both space and time. However, to determine the best location and time for such disruptions to occur, with minimal off-target effects, will require far greater knowledge of circuits than currently exists: we need good characterizations of interactions among brain regions, including their timing relative to behavior. The over-arching aim of our research is to provide methods for describing the flow of information, based on evolving neural activity, among multiple regions of the brain during behavioral tasks. Such methods can lead to major advances in experimental design and, ultimately, to far better treatments than currently exist.",Broader Impact,164,5,,,FALSE,FALSE,FALSE,Latent Dynamic Factor Analysis of High-Dimensional Neural Recordings,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)",Neuroscience and Cognitive Science -> Neural Coding; Probabilistic Methods -> Latent Variable Models,Neuroscience and cognitive science,"['Heejong Bong', ' Zongge Liu', ' Zhao Ren', ' Matthew Smith', ' Valerie Ventura', ' Kass E Robert']","{'University of Pittsburgh', 'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Conditioning and Processing: Techniques to Improve Information-Theoretic Generalization Bounds,"Hassan Hafez-Kolahi, Zeinab Golgooni, Shohreh Kasaei, Mahdieh Soleymani",Conditioning and Processing: Techniques to Improve Information-Theoretic Generalization Bounds,befe5b0172188ad14d48c3ebe9cf76bf,https://proceedings.neurips.cc/paper/2020/file/befe5b0172188ad14d48c3ebe9cf76bf-Paper.pdf,"As a theoretical work, the direct foreseeable impact is on the academic community. In particular, in the field of machine learning, this work should be viewed along a series of works trying to understand learning algorithms from the lens of information theory. The unified framework introduced in this paper provides an intuitive and convenient way to derive tighter generalization bounds. This can increase the ability of researchers to apply information theory to derive bounds for their learning algorithms and to easily communicate their ideas. These contributions have the potential to boost the ongoing paradigm shift toward an information-theoretic understanding of machine learning. It should also be noted that the studied techniques are not limited to deriving generalization bounds, which is evident from the quite general structure of graphical models and techniques. As such, these kinds of graphical representations along the conditioning and chaining techniques may find their way to be used in other fields beside learning theory as well.",Broader Impact,159,7,FALSE,FALSE,FALSE,FALSE,FALSE,Conditioning and Processing: Techniques to Improve Information-Theoretic Generalization Bounds,Theory -> Statistical Learning Theory,Theory -> Information Theory; Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Kolahi', ' Zeinab Golgooni', ' Shohreh Kasaei', ' Mahdieh Soleymani']",{'Sharif University of Technology'},1,0,0,{'Iran'}
Bongard-LOGO: A New Benchmark for Human-Level Concept Learning and Reasoning,"Weili Nie, Zhiding Yu, Lei Mao, Ankit B. Patel, Yuke Zhu, Anima Anandkumar",Bongard-LOGO: A New Benchmark for Human-Level Concept Learning and Reasoning,bf15e9bbff22c7719020f9df4badc20a,https://proceedings.neurips.cc/paper/2020/file/bf15e9bbff22c7719020f9df4badc20a-Paper.pdf,"Our work created a new visual concept learning benchmark inspired by the Bongard Problems. Our preliminary evaluations have illustrated a considerable gap between human cognition and machine recognition, highlighting the shortcomings of existing pattern recognition methods. In Machine Learning and Computer Vision, we have witnessed the integral role of standardized benchmarks [ 1, 2] in promoting the development of new AI algorithms. We would encourage future work to develop new visual cognition algorithms towards human-level visual concept learning and reasoning. We envision our benchmark to serve as a driving force for research on context-dependent and analogical perception beyond standard visual recognition. We believe that endowing machine perception with the abilities to learn and reason in a human-like way is an essential step towards building robust and reliable AI systems in the wild. It could potentially lead to more human-interpretable AI systems and address concerns about ethics and fairness arising from today’s data-driven learning systems that inherit or augment the biases in training data. A potential risk of our new benchmark is that it might skew research towards highly customized methods without much applicability for more general concept learning and reasoning. We encourage researchers to develop new algorithms for our benchmark from the first principles and avoid highly customized solutions, to retain the generality and broad applicability of the resultant algorithms.",Broader Impact,220,9,,,TRUE,TRUE,FALSE,Bongard-LOGO: A New Benchmark for Human-Level Concept Learning and Reasoning,Algorithms -> Few-Shot Learning,"Data, Challenges, Implementations, and Software -> Benchmarks; Neuroscience and Cognitive Science -> Reasoning","Datasets, challenges, software","['Weili Nie', ' Zhiding Yu', ' Lei Mao', ' Ankit Patel', ' Yuke Zhu', ' Anima Anandkumar']","{'NVIDIA / Caltech', 'University of Texas - Austin', 'NVIDIA', 'Rice University'}",1,1,1,{'USA'}
GAN Memory with No Forgetting,"Yulai Cong, Miaoyun Zhao, Jianqiao Li, Sijia Wang, Lawrence Carin",GAN Memory with No Forgetting,bf201d5407a6509fa536afc4b380577e,https://proceedings.neurips.cc/paper/2020/file/bf201d5407a6509fa536afc4b380577e-Paper.pdf,"Capable of remembering a stream of data generative processes with no forgetting, our GAN memory has the following potential positive impact in the society: ( i ) it may serve as a powerful generative replay for challenging lifelong applications such as self-driving; ( ii ) as no original data are saved, the concerns on data privacy may be well addressed; ( iii ) GAN memory enables flexible control over the replayed contents, which is of great value to practical applications, where training data are unbalanced, or where one needs to flexibly select which model capability to maintain/forget during training; ( iv ) the counter-intuitive discovery that lays the foundation of our GAN memory may disclose another dimension for transfer learning, i.e., the kernel shape is generally applicable while the corresponding kernel statistics/style is task-specific; similar patterns may also apply to classifiers. Since our GAN memory is built on top of GANs, it may inherit their ethical and societal impact. Despite being versatility, GANs may be improperly used to synthesize fake images/news/videos, resulting in negative consequences. Furthermore, we should be cautious of the failure of adversarial training due to mode collapse, which may compromise the generative capability on the current task. Note that training failure, if it happens, will not hurt the performance on other tasks, showing certain robustness of our GAN memory.",Broader impact,222,5,,,FALSE,FALSE,FALSE,GAN Memory with No Forgetting,Algorithms -> Continual Learning,Algorithms -> Multitask and Transfer Learning; Applications -> Computer Vision; Deep Learning; Deep Learning -> Adversarial Networks; Deep Learning -> Generative Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Chunyuan Li', ' Miaoyun Zhao', ' Jianqiao Li', ' Sijia Wang', ' Lawrence Carin']","{'UNC', 'Microsoft Research', 'Duke University'}",1,1,1,"{'Canada', 'USA'}"
Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games,"Yunqiu Xu, Meng Fang, Ling Chen, Yali Du, Joey Tianyi Zhou, Chengqi Zhang",Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games,bf65417dcecc7f2b0006e1f5793b7143,https://proceedings.neurips.cc/paper/2020/file/bf65417dcecc7f2b0006e1f5793b7143-Paper.pdf,"The high-level goal of this work is to bridge artificial intelligence with human intelligence, cognition and language learning. Researchers in reinforcement learning will benefit from this work by the appropriate use of knowledge graphs. By recording and organizing the information in a structural way, the difficulty of learning can be largely reduced. Besides, KGs can be used to conduct reasoning to interpret the decision making process. Researchers in multi-modal learning will also benefit from the attention mechanism proposed in this work. Although the stacked hierarchical attention is used to aggregate text representation and graph representation, it can also be extended to other forms of inputs such as visual and audio signals. Our work can also be served as an initial study before conducting experiments in real life and with animal / human participants, since it’s performed in simulated systems and there’s no safety consideration. Regarding the ethical implications, although currently our work is conducted in games, where language commands are constrained in limited action spaces, for more practical applications this system will be deployed with a richer corpus. From the perspective of language generation, the inappropriate use of generated language commands should be seriously taken into consideration. Another concern lies in the unintended behavior and decision making process, which may lead to dangerous conditions in real world applications. Although we try to improve interpretability through reasoning, there’s still a long way to go to make human-AI interaction in a safe and reasonable way.",Broader Impact,243,11,,,FALSE,FALSE,FALSE,Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games,Reinforcement Learning and Planning,Applications -> Natural Language Processing; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Yunqiu Xu', ' Meng Fang', ' Ling Chen', ' Yali Du', ' Joey Tianyi Zhou', ' Chengqi Zhang']","{'University of Technology Sydney', 'University College London', 'IHPC, A*STAR', 'Tencent'}",1,1,1,"{'Australia', 'UK', 'China'}"
Gaussian Gated Linear Networks,"David Budden, Adam Marblestone, Eren Sezener, Tor Lattimore, Gregory Wayne, Joel Veness",Gaussian Gated Linear Networks,c0356641f421b381e475776b602a5da8,https://proceedings.neurips.cc/paper/2020/file/c0356641f421b381e475776b602a5da8-Paper.pdf,"Regression models have long been ubiquitous in both industry and academia, and we are optimistic that our work can provide improvement to existing practice and results. Like any supervised learning technique, the output of this model is a function of its input data, so appropriate due diligence is required during all stages of data collection, training and deployment, e.g. with respect to issues of algorithmic fairness and bias, as well as safety and robustness.",Broader Impact,74,2,FALSE,FALSE,FALSE,FALSE,FALSE,Gaussian Gated Linear Networks,Algorithms -> Regression,Algorithms -> Density Estimation; Algorithms -> Online Learning; Optimization -> Convex Optimization,,"['David Budden', ' Adam Marblestone', ' Eren Sezener', ' Tor Lattimore', ' Gregory Wayne', ' Joel Veness']","{'Google DeepMind', 'DeepMind', 'Deepmind'}",0,1,0,{'UK'}
Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding,"Lin Lan, Pinghui Wang, Xuefeng Du, Kaikai Song, Jing Tao, Xiaohong Guan",Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding,c055dcc749c2632fd4dd806301f05ba6,https://proceedings.neurips.cc/paper/2020/file/c055dcc749c2632fd4dd806301f05ba6-Paper.pdf,"In general, this work has potential positive impact on graph-related fields that need to deal with the classification problem with respect to few-shot novel labels. For instance, our work is beneficial for social networking service providers such as Facebook and Twitter. These providers can obtain quick and effective feedback on newly developed features through distributing surveys among a small group of users on social networks. In addition, our work can also help biologists, after discovering a new function of certain existing proteins, quickly understand whether other proteins in a protein- protein interaction network have the new function, which improves the efficiency of wet laboratory experimentation. Moreover, many recommender systems model users and items as a graph and enhance the recommendation performance with the aid of network embedding. To some extent, our work is potentially useful to alleviate the cold-start problem as well. At the same time, our model could be biased towards the few-shot setting after training and not provide superior performance on those labels with many support nodes. In practice, if the original few-shot label gradually has enough support nodes (e.g., biologists identify more proteins with and without the new function through laboratory experiments), we recommend using general unsupervised or semi-supervised methods (e.g., Node2vec [8] or Planetoid [32]) to recognize the label.",Broader Impact,213,8,,,FALSE,FALSE,FALSE,Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding,Algorithms,Algorithms -> Few-Shot Learning; Algorithms -> Meta-Learning; Algorithms -> Semi-Supervised Learning; Applications -> Network Analysis,Graph learning,"['Lin Lan', ' Pinghui Wang', ' Xuefeng Du', ' Kaikai Song', ' Jing Tao', ' Xiaohong Guan']","{'MOE Key Laboratory of Intelligent Networks and Network Security, Xi’an Jiaotong University', 'University of Wisconsin-Madison', 'Huawei Noah’s Ark Lab', 'Department of Automation and NLIST Lab, Tsinghua University’}",1,0,0,"{'USA', 'China'}"
Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning,"Massimo Caccia, Pau Rodriguez, Oleksiy Ostapenko, Fabrice Normandin, Min Lin, Lucas Page-Caccia, Issam Hadj Laradji, Irina Rish, Alexandre Lacoste, David Vázquez, Laurent Charlin",Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning,c0a271bc0ecb776a094786474322cb82,https://proceedings.neurips.cc/paper/2020/file/c0a271bc0ecb776a094786474322cb82-Paper.pdf,"Our work proposes a more-realistic (synthetic) continual-learning environment. This research could help accelerate the deployment of CL algorithms into applications such as autonomous driving, recommendation systems, information extraction, anomaly detection, and others. A domain often associated with continual learning is health care. In health care, patient data is (usually) very sensitive, CL algorithms can be the solution to accumulating knowledge from different hospitals: they can be trained continually across hospitals without the data ever leaving the premise. Possible negative impacts: Our framework enables previous tasks to be forgotten at different rates. If data is patient-level data and different tasks relate to different subset of patients, then it means that the system’s performance on past patients could vary. A diagnostic system, for example, could forget how to properly diagnose a patient from a previous population whilst learning about a new one. Further research, possibly at the intersection of continual learning and fairness, is needed before the safe deployment of these algorithms. Possible positive impacts: The aforementioned negative impact may also be its greatest asset for having a positive impact. Returning to our example, practitioners could understand to what extent a diagnostic system forgets previous diagnostics. They could then use and develop OSAKA to calibrate their algorithms to match their desiderata (e.g., by choosing when the negative consequence of forgetting may outweight the benefits of additional training data).",Broader Impact,226,11,,,FALSE,FALSE,FALSE,Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning,Algorithms -> Continual Learning,Algorithms -> Meta-Learning; Algorithms -> Online Learning,lifelong/continual learning,"['Massimo Caccia', ' Pau Rodriguez', ' Oleksiy Ostapenko', ' Fabrice Normandin', ' Min Lin', 'Caccia', ' Issam Hadj Laradji', ' Irina Rish', ' Alexandre Lacoste', ' David Vázquez', ' Laurent Charlin']","{'CVC', 'MILA', 'Element AI', 'University of British Columbia', 'University of Montreal, MILA', 'Mila/UdeM', 'McGill University', 'MILA / U.Montreal'}",1,1,1,"{'Canada', 'Spain'}"
Convex optimization based on global lower second-order models,"Nikita Doikov, Yurii Nesterov",Convex optimization based on global lower second-order models,c0c3a9fb8385d8e03a46adadde9af3bf,https://proceedings.neurips.cc/paper/2020/file/c0c3a9fb8385d8e03a46adadde9af3bf-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Convex optimization based on global lower second-order models,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Nikita Doikov', ' Yurii Nesterov', 'Catholic University of Louvain']","{'UCL', 'Catholic University of Louvain'}",1,0,0,"{'UK', 'Belgium'}"
Simultaneously Learning Stochastic and Adversarial Episodic MDPs with Known Transition,"Tiancheng Jin, Haipeng Luo",Simultaneously Learning Stochastic and Adversarial Episodic MDPs with Known Transition,c0f971d8cd24364f2029fcb9ac7b71f5,https://proceedings.neurips.cc/paper/2020/file/c0f971d8cd24364f2029fcb9ac7b71f5-Paper.pdf,"This work is mostly theoretical, with no negative outcomes. Researchers working on theoretical aspects of online learning, bandit problems, and reinforcement learning (RL) may benefit from our results. Although our algorithm deals with the tabular setting and is not directly applicable to common RL applications with a large state and action space, it sheds light on how to increase robustness of a learning algorithm while adapting to specific instances, and serves as an important step towards developing more practical, adaptive, and robust RL algorithms, which in the long run might find its applications in the real world.",Broader Impact,97,3,,,FALSE,FALSE,FALSE,Simultaneously Learning Stochastic and Adversarial Episodic MDPs with Known Transition,Algorithms -> Online Learning,Algorithms -> Bandit Algorithms; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning; Theory,Reinforcement learning and planning,"['Tiancheng Jin', ' Haipeng Luo']",{'University of Southern California'},1,0,0,{'USA'}
Relative gradient optimization of the Jacobian term in unsupervised deep learning,"Luigi Gresele, Giancarlo Fissore, Adrián Javaloy, Bernhard Schölkopf, Aapo Hyvarinen",Relative gradient optimization of the Jacobian term in unsupervised deep learning,c10f48884c9c7fdbd9a7959c59eebea8,https://proceedings.neurips.cc/paper/2020/file/c10f48884c9c7fdbd9a7959c59eebea8-Paper.pdf,"As this paper presents novel theoretical results in unsupervised learning, the authors do not see any immediate ethical or societal concern. An important aspect of our paper is the improvement in computational efficiency with respect to naive methods. This can hopefully lead to reduced energy consumption to achieve comparable model performance.",Broader impact,51,3,TRUE,TRUE,FALSE,FALSE,FALSE,Relative gradient optimization of the Jacobian term in unsupervised deep learning,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)",Algorithms -> Density Estimation; Probabilistic Methods -> Latent Variable Models,Probabilistic methods and inference,"['Luigi Gresele', ' Giancarlo Fissore', ' Adrián Javaloy', ' Bernhard Schölkopf', ' Aapo Hyvarinen']","{'MPI for Intelligent Systems, Tübingen', 'MPI for Intelligent Systems', 'University of Helsinki', 'Saarland University', 'Inria'}",1,0,0,"{'France', 'Finland', 'Germany'}"
Self-Supervised Visual Representation Learning from Hierarchical Grouping,"Xiao Zhang, Michael Maire",Self-Supervised Visual Representation Learning from Hierarchical Grouping,c1502ae5a4d514baec129f72948c266e,https://proceedings.neurips.cc/paper/2020/file/c1502ae5a4d514baec129f72948c266e-Paper.pdf,"As an advance in self-supervised visual representation learning, our work may serve as a technical approach for a wide variety of applications that learn from unlabeled image datasets, with impact as varied as the potential applications. We believe that a compelling and practical use case is likely to be in domains where human annotation is especially difficult, such as medical imaging, and are hopeful that that further development of these techniques will eventually have a positive impact in medical and scientific domains.",7 Broader Impact,82,2,,,FALSE,FALSE,FALSE,Self-Supervised Visual Representation Learning from Hierarchical Grouping,Applications -> Computer Vision,Algorithms -> Representation Learning; Applications -> Image Segmentation,Vision,"['Xiao Zhang', ' Michael Maire']",{'University of Chicago'},1,0,0,{'USA'}
Optimal Variance Control of the Score-Function Gradient Estimator for Importance-Weighted Bounds,"Valentin Liévin, Andrea Dittadi, Anders Christensen, Ole Winther",Optimal Variance Control of the Score Function Gradient Estimator for Importance Weighted Bounds,c15203a83f778ce8934d0efaf2d5c6f3,https://proceedings.neurips.cc/paper/2020/file/c15203a83f778ce8934d0efaf2d5c6f3-Paper.pdf,"This work proposes OVIS, an improvement to the score function gradient estimator in the form of optimal control variates for variance reduction. As briefly touched upon in the introduction, OVIS has potential practical use cases across several branches of machine learning. As such, the potential impact of this research is broad, and we will therefore limit the scope of this section to a few clear applications. Improved inference over discrete spaces such as action spaces encountered within e.g. model-based reinforcement learning has the potential of reducing training time and result in more optimal behavior of the learning agent. This advancement has the capability to increase efficiency of e.g. autonomous robots used within manufacturing. Such progress is often coveted due to cost optimization, increased safety, and reduced manual labor for humans. However, as argued in [ 39], this development can also lead to immediate disadvantages such as worker displacement, potentially in terms of both tasks and geographic location. Another probable avenue of impact of this research is within machine comprehension. A topic within this field is reading, with practical applications such as chatbots. This use of machine learning has seen rapid growth and commercial interest over recent years [40]. Apart from the clear consumer benefits of these bots, focus has also broadened to other cases of use for social benefits [41]. However, as with most other machine learning inventions, chatbots can be exploited for malicious purposes such as automated spread of misinformation, e.g. during elections [42]. As with other theoretical advances such as those presented in this paper, consequences are not immediate and depend on the applications in which the research is utilized. It is our hope that this research will ultimately be of practical use with a tangible positive impact.",9 Broader Impact,290,14,,,FALSE,FALSE,FALSE,Optimal Variance Control of the Score-Function Gradient Estimator for Importance-Weighted Bounds,Probabilistic Methods -> Variational Inference,Optimization -> Discrete Optimization; Optimization -> Stochastic Optimization; Probabilistic Methods -> Latent Variable Models,Probabilistic methods and inference,"['Valentin Liévin', ' Andrea Dittadi', ' Anders Christensen', ' Ole Winther']","{'Technical University of Denmark', 'DTU and KU'}",1,0,0,{'Denmark'}
Explicit Regularisation in Gaussian Noise Injections,"Alexander Camuto, Matthew Willetts, Umut Simsekli, Stephen J. Roberts, Chris C. Holmes",Explicit Regularisation in Gaussian Noise Injections,c16a5320fa475530d9583c34fd356ef5,https://proceedings.neurips.cc/paper/2020/file/c16a5320fa475530d9583c34fd356ef5-Paper.pdf,"This paper uncovers a new mechanism by which a widely used regularisation method operates and paves the way for designing new regularisation methods which take advantage of our findings. Reg- ularisation methods produce models that are not only less likely to overfit, but also have better calibrated predictions that are more robust to distribution shifts. As such improving our understand- ing of such methods is critical as machine learning models become increasingly ubiquitous and embedded in decision making.",Impact Statement,78,3,,,FALSE,FALSE,FALSE,Explicit Regularisation in Gaussian Noise Injections,Deep Learning -> Analysis and Understanding of Deep Networks,,Deep learning,"['Alexander Camuto', ' Matthew Willetts', ' Umut Simsekli', ' Stephen J Roberts', ' Chris C Holmes']","{'Institut Polytechnique de Paris/ University of Oxford', 'University of Oxford'}",1,0,0,"{'France', 'UK'}"
Numerically Solving Parametric Families of High-Dimensional Kolmogorov Partial Differential Equations via Deep Learning,"Julius Berner, Markus Dablander, Philipp Grohs",Numerically Solving Parametric Families of High-Dimensional Kolmogorov Partial Differential Equations via Deep Learning,c1714160652ca6408774473810765950,https://proceedings.neurips.cc/paper/2020/file/c1714160652ca6408774473810765950-Paper.pdf,"The deep-learning technique presented in this work is the first computationally scalable method for the numerical solution of high-dimensional parametric Kolmogorov PDEs. It is also the first method which allows for a straightforward sensitivity analysis of the associated high-dimensional PDE solution manifold with respect to input parameters. In addition, it newly allows for high-dimensional data-driven model calibration and uncertainty quantification. While it is a difficult task to precisely estimate the cascading effects of technological innovations on wider society, it is reasonable to assume that the ubiquity of Kolmogorov equations in science and engineering will lead to a positive impact of our new findings on a multitude of technical areas of social importance. As an example, Kolmogorov PDEs are heavily used in physics for the modelling of heat flow and diffusion processes [42, 58]. Simultaneously, Fokker-Planck equations, which take the form of Kolmogorov equations in particular special cases, are used in the geophysical and atmospheric sciences as modelling tools for climate change projections [25, 54]. Our described algorithm has clear promise to make previously intractable high-dimensional physical models computationally accessible to scientists. Additionally, our method allows for an easy investigation of changes in complex model forecasts as input parameters are varied during sensitivity analysis. Such advancements have the potential to accelerate scientific research and can directly lead to better predictive models in applied physics and engineering. Reliable and efficient predictive models in turn are essential to rationally inform public policy. A conceivable risk posed by our work might come in the form of the uncritical use of our algorithm in applications related to financial engineering. The Black-Scholes equation and associated models have been notoriously misused in the last decades by semi-technical users working in financial sectors around the world [31, 59]. The naive usage of technical tools in computational finance has thus likely been a contributing factor to periods of economic instability in recent history. Our technique can now add a powerful solver for high-dimensional parametric PDE problems to the tool kits of individual end-users in finance with various degrees of scientific expertise. Inexperienced users without appropriate quantitative background might be prone to erroneously taking the complexity of a high-dimensional financial model as an indicator for its accuracy. Therefore, one must take great care to systematically inform users without suitable experience in such a scenario that merely increasing the dimension of an inadequate financial model might not necessarily make its results more accurate. In total, we are confident that the net impact of our work on the scientific community as well as broader society is positive. The probability of uncritical use of our technique and other algorithms in financial engineering can likely be substantially mitigated by targeted educational interventions and we would encourage practical research in this direction. At the same time, we note that our technical contribution is a general-purpose tool which has the potential to stimulate the acceleration of scientific progress in a wide variety of disciplines.",Broader Impact,488,19,,,FALSE,FALSE,FALSE,Numerically Solving Parametric Families of High-Dimensional Kolmogorov Partial Differential Equations via Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Regression; Algorithms -> Stochastic Methods; Deep Learning -> Supervised Deep Networks; Theory -> Statistical Learning Theory,Deep learning,"['Julius Berner', ' Markus Dablander', ' Philipp Grohs']","{'University of Vienna', 'University of Oxford'}",1,0,0,"{'Austria', 'UK'}"
Finite-Time Analysis for Double Q-learning,"Huaqing Xiong, Lin Zhao, Yingbin Liang, Wei  Zhang",Finite-Time Analysis for Double Q-learning,c20bb2d9a50d5ac1f713f8b34d9aac5a,https://proceedings.neurips.cc/paper/2020/file/c20bb2d9a50d5ac1f713f8b34d9aac5a-Paper.pdf,"Reinforcement learning has achieved great success in areas such as robotics and game playing, and thus has aroused broad interests and more potential real-world applications. Double Q-learning is a commonly used technique in deep reinforcement learning to improve the implementation stability and speed of deep Q-learning. In this paper, we provided the fundamental analysis on the convergence rate for double Q-learning, which theoretically justified the empirical success of double Q-learning in practice. Such a theory also provides practitioners desirable performance guarantee to further develop such a technique into various transferable technologies.",Broader Impact,91,4,,,FALSE,FALSE,FALSE,Finite-Time Analysis for Double Q-learning,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement Learning and Planning -> Decision and Control,Reinforcement learning theory,"['Huaqing Xiong', ' Lin Zhao', ' Yingbin Liang', ' Wei Zhang']","{'The Ohio State University', 'Southern University of Science and Technology', 'Ohio State University', 'National University of Singapore'}",1,0,0,"{'Singapore', 'USA', 'China'}"
Learning to Detect Objects with a 1 Megapixel Event Camera,"Etienne Perot, Pierre de Tournemire, Davide Nitti, Jonathan Masci, Amos Sironi",Learning to Detect Objects with a 1 Megapixel Event Camera,c213877427b46fa96cff6c39e837ccee,https://proceedings.neurips.cc/paper/2020/file/c213877427b46fa96cff6c39e837ccee-Paper.pdf,"The integration of an event-based object detection pipeline in real-world applications could positively impact several aspects of existing systems. First, the camera’s high temporal resolution would allow faster reaction time and be more robust in situations where standard cameras suffer from motion blur or high latency. Secondly, they could also improve performance in HDR or low light scenes. Both these aspects are essential to increase the safety of driving assistance solutions or autonomous vehicles [58]. Similarly, these characteristics could be useful in applications where there is an interaction between humans and robots (e.g., in a production line or in a warehouse). Finally, the adoption of similar pipelines in other contexts, like the Internet of Things, could reduce the power consumption and the data storage of existing systems [59]. Although, as demonstrated in [10], the possibility to reconstruct intensity images from events stream could create privacy issues, the proposed method allows better privacy management. Encoding events in not human-readable structures and not requiring to have an image-like representation prevents the easy use of the recorded data for purposes different than those defined by the original algorithm, and it limits the possibility to identify people, vehicles or places. Further advances in event-based processing and neuromorphic architectures might also open the future to a new class of extremely low-power and low-latency artificial intelligence systems [60]. In a world where power-hungry deep learning techniques are becoming a commodity, and at the same time, environmental concerns are increasingly pressuring our way of life, neuromorphic systems could be an essential component of a sustainable society [61]. Concerning possible negative outcomes, since our method relies on training data, it will leverage the bias and the limitations contained in it. Similarly, since it relies on deep learning architectures, it might be deceived by adversarial attacks. To mitigate these consequences, several methods have been recently proposed to de-bias deep learning models and make them more robust to adversarial examples [62, 63, 64, 65]. A failure of the system might cause dangerous incidents and have severe consequences on people and facilities [66]. Similarly, its integration in a fully autonomous vehicle, poses the ethical question of replacing the human morale in the so called Trolley Problem [67]. Moreover, autonomous vehicles may impact the careers of millions of people [68]. Finally, we think it is essential to be aware that the event-based perception and similar detection systems could be exploited to harm people and threaten human rights. For example, developing modified versions of this algorithm for mass surveillance [69] or military applications [70, 71].",Broader Impact,422,18,,,FALSE,FALSE,FALSE,Learning to Detect Objects with a 1 Megapixel Event Camera,Applications -> Computer Vision,Applications -> Object Detection,Vision,"['Etienne Perot', ' Pierre de Tournemire', ' Davide Nitti', ' Jonathan Masci', ' Amos Sironi']","{'NNAISENSE', 'PROPHESEE'}",0,1,0,"{'France', 'Switzerland'}"
End-to-End Learning and Intervention in Games,"Jiayang Li, Jing Yu, Yu Nie, Zhaoran Wang",End-to-End Learning and Intervention in Games,c21f4ce780c5c9d774f79841b81fdc6d,https://proceedings.neurips.cc/paper/2020/file/c21f4ce780c5c9d774f79841b81fdc6d-Paper.pdf,"Our work helps understand and resolve social dilemmas resulting from pervasive conflict between self- and collective interest in human societies. The potential applications of the proposed modeling framework range from addressing externality in economic systems to guiding large-scale infrastructure investment. Planners, regulators, policy makers of various human systems could benefit from the decision making tools derived from this work.",Broader Impact,59,3,FALSE,FALSE,FALSE,FALSE,FALSE,End-to-End Learning and Intervention in Games,Theory -> Game Theory and Computational Economics,,Game theory and machine learning,"['Jiayang Li', ' Jing Yu', ' Yu Nie', ' Zhaoran Wang']",{'Northwestern University'},1,0,0,{'USA'}
Least Squares Regression with Markovian Data: Fundamental Limits and Algorithms,"Dheeraj Nagaraj, Xian Wu, Guy Bresler, Prateek Jain, Praneeth Netrapalli",Least Squares Regression with Markovian Data: Fundamental Limits and Algorithms,c22abfa379f38b5b0411bc11fa9bf92f,https://proceedings.neurips.cc/paper/2020/file/c22abfa379f38b5b0411bc11fa9bf92f-Paper.pdf,"We build foundational theoretical groundwork for the fundamental problem of optimization with Markovian data. We think that our work sheds light on the possibilities and impossibilities in this space. For practitioners, our focus on the popular SGD algorithm provides them with a rigorously justified understanding of what SGD can achieve and for specially structured chains, experience replay with SGD can be provably helpful (though not in the general case). We also think that the proof techniques in this paper could impact future research in this space and beyond.",Broader Impact,88,4,,,FALSE,FALSE,FALSE,Least Squares Regression with Markovian Data: Fundamental Limits and Algorithms,Optimization -> Stochastic Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Dheeraj Nagaraj', ' Xian Wu', ' Guy Bresler', ' Prateek Jain', ' Praneeth Netrapalli']","{'Massachusetts Institute of Technology', 'Stanford University', 'MIT', 'Microsoft Research'}",1,1,1,{'USA'}
"Predictive coding in balanced neural networks with noise, chaos and delays","Jonathan Kadmon, Jonathan Timcheck, Surya Ganguli","Predictive coding in balanced neural networks with noise, chaos and delays",c236337b043acf93c7df397fdb9082b3,https://proceedings.neurips.cc/paper/2020/file/c236337b043acf93c7df397fdb9082b3-Paper.pdf,"Our work is primarily theoretical and is designed to elucidate fundamental phenomena in nonlinear neural circuit computation. Such a scientific understanding, may, in the long term, lead to more robust technology.",Broader impact,31,2,FALSE,FALSE,FALSE,FALSE,FALSE,"Predictive coding in balanced neural networks with noise, chaos and delays",Neuroscience and Cognitive Science -> Neural Coding,Neuroscience and Cognitive Science -> Neuroscience; Theory -> Statistical Physics of Learning,Neuroscience and cognitive science,"['Jonathan Kadmon', ' Jonathan Timcheck', ' Surya Ganguli']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Interpolation Technique to Speed Up Gradients Propagation in Neural ODEs,"Talgat Daulbaev, Alexandr Katrutsa, Larisa Markeeva, Julia Gusak, Andrzej Cichocki, Ivan Oseledets",Interpolation Technique to Speed Up Gradients Propagation in Neural ODEs,c24c65259d90ed4a19ab37b6fd6fe716,https://proceedings.neurips.cc/paper/2020/file/c24c65259d90ed4a19ab37b6fd6fe716-Paper.pdf,"We proposed a method for fast and stable Neural ODEs training. This method can be applied to any domain, where it is possible to use Neural ODEs. Since the IRDM reduces the time needed to train Neural ODEs, it has the potential to reduce the carbon footprint of building AI models.",Broader Impact,51,3,FALSE,FALSE,FALSE,FALSE,FALSE,Interpolation Technique to Speed Up Gradients Propagation in Neural ODEs,Algorithms -> Dynamical Systems,,Neural ODEs,,"{'Skolkovo Institute of Science and Technology', 'Skoltech'}",1,0,0,{'Russia'}
On the Equivalence between Online and Private Learnability beyond Binary Classification,"Young Jung, Baekjin Kim, Ambuj Tewari",On the Equivalence between Online and Private Learnability beyond Binary Classification,c24fe9f765a44048868b5a620f05678e,https://proceedings.neurips.cc/paper/2020/file/c24fe9f765a44048868b5a620f05678e-Paper.pdf,"As this paper is purely theoretical, discussing broader impact is not applicable.",Broader Impact,12,1,TRUE,FALSE,FALSE,FALSE,FALSE,On the Equivalence between Online and Private Learnability beyond Binary Classification,Theory -> Statistical Learning Theory,"Algorithms -> Online Learning; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Theory (including computational and statistical analyses),"['Young Hun Jung', ' Baekjin Kim', ' Ambuj Tewari']","{'Microsoft', 'University of Michigan'}",1,1,1,{'USA'}
AViD Dataset: Anonymized Videos from Diverse Countries,"AJ Piergiovanni, Michael Ryoo",AViD Dataset: Anonymized Videos from Diverse Countries,c28e5b0c9841b5ef396f9f519bf6c217,https://proceedings.neurips.cc/paper/2020/file/c28e5b0c9841b5ef396f9f519bf6c217-Paper.pdf,"We quantitatively confirmed that existing video datasets for action recognition are highly biased. In order to make people and researchers in diverse countries more fairly benefit from a public action recognition dataset, we propose the AViD dataset. We took care to query multiple websites from many countries in many languages to build a dataset that represents as many countries as possible. We experimentally showed that by doing this, we can reduce the bias of learned models. We are not aware of any other large-scales datasets (with hundreds of video hours) which took such country diversity into the consideration during the collection process. As this dataset contains a wide variety of actions, it could enable malicious parties to build systems to monitor people. However, we took many steps to preserve the identity of people and eliminate the ability to learn face-based actions, which greatly reduces the negative uses of the data. The positive impacts of this dataset are enabling reproducible research on video understanding which will help more advance video understanding research with consistent and reliable baselines. We emphasize once more that our dataset is a static dataset respecting the licences of all its videos.",Broader Impacts,194,9,,,FALSE,FALSE,FALSE,AViD Dataset: Anonymized Videos from Diverse Countries,"Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories","Applications -> Activity and Event Recognition; Applications -> Computer Vision; Data, Challenges, Implementations, and Software -> Benchmarks",,"['Anthony J Piergiovanni', ' Michael S Ryoo']","{'Stony Brook University', 'Indiana University'}",1,0,0,{'USA'}
Probably Approximately Correct Constrained Learning,"Luiz Chamon, Alejandro Ribeiro",Probably Approximately Correct Constrained Learning,c291b01517f3e6797c774c306591cc32,https://proceedings.neurips.cc/paper/2020/file/c291b01517f3e6797c774c306591cc32-Paper.pdf,"As learning becomes an ubiquitous technological solution and begins to affect real societal impact, its shortcomings become more evident. A growing number of reports show that its solutions can be prejudiced and prone to tampering or unsafe behaviors [1, 2, 3, 4, 5, 6]. Constrained learning allows requirements to be imposed during learning, so that the models and solutions obtained are guaranteed to behave in the desired way despite being learned fully from data. This work provides a framework under which to study learning under requirements and shows how and when it can be done. By providing generalization guarantees on the solutions, it enables learning to be used in critical applications in which there is little tolerance for failure. Naturally, solutions learned under constraints are not necessarily safe or fair. How the learning problem is formulated, i.e., which constraints are imposed, play a definite role on these outcomes and policies determining such requirements can be (and indeed are [76, 77, 78]) important sources of biases.",Broader Impact,165,7,,,FALSE,FALSE,FALSE,Probably Approximately Correct Constrained Learning,Theory -> Statistical Learning Theory,"Algorithms -> Adversarial Learning; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency; Theory -> Spaces of Functions and Kernels",Theory (including computational and statistical analyses),"['Luiz Chamon', ' Alejandro Ribeiro']",{'University of Pennsylvania'},1,0,0,{'USA'}
RATT: Recurrent Attention to Transient Tasks for Continual Image Captioning,"Riccardo Del Chiaro, Bartłomiej Twardowski, Andrew Bagdanov, Joost van de Weijer",RATT: Recurrent Attention to Transient Tasks for Continual Image Captioning,c2964caac096f26db222cb325aa267cb,https://proceedings.neurips.cc/paper/2020/file/c2964caac096f26db222cb325aa267cb-Paper.pdf,"Automatic image captioning has applications in image indexing, Content-Based Image Retrieval (CBIR), and industries like commerce, education, digital libraries, and web searching. Social media platforms could use it to directly generate descriptions of multimedia content. Image captioning systems can support peoples with disabilities, providing an access to the visual content unreachable before by changing its representation. Continual learning contrasts with the joint-training paradigm in common use today. It has the advantage that it can better protect privacy concerns since, once learned, the data not need to be retained. Furthermore, it is more efficient since networks continue learning and are not initialized from scratch every time a new task arrives. This ability is crucial for development of systems like virtual personal assistants, where the adaption to new tasks and environments is fundamental, especially where multi-modal communication channels are ubiquitous. Finally, the algorithm considered in this paper will reflect the biases present in the dataset. Therefore, special care should be taken when applying this technique to applications where possible biases in the dataset might result in biased outcomes towards minority and/or under-represented groups in the data.",Broader impact,184,9,,,FALSE,FALSE,FALSE,RATT: Recurrent Attention to Transient Tasks for Continual Image Captioning,Algorithms -> Continual Learning,Deep Learning -> Recurrent Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Riccardo Del Chiaro', ' Bartłomiej Twardowski', ' Andrew D Bagdanov', ' Joost van de Weijer']","{'Computer Vision Center Barcelona', 'Computer Vision Center, UAB', 'University of Florence'}",1,0,0,"{'Spain', 'Italy'}"
"Decisions, Counterfactual Explanations and Strategic Behavior","Stratis Tsirtsis, Manuel Gomez Rodriguez","Decisions, Counterfactual Explanations and Strategic Behavior",c2ba1bc54b239208cb37b901c0d3b363,https://proceedings.neurips.cc/paper/2020/file/c2ba1bc54b239208cb37b901c0d3b363-Paper.pdf,"In recent years, there has been a heated debate concerning the (lack of) transparency of machine learning models used to inform decisions that have significant consequences for individuals. In this context, decision makers are usually reluctant to share their decision policy with the individuals they decide upon because of trade secret concerns. In our work, we show that, if explanations for (semi-)automated decisions are chosen taking into account how individuals will best respond to them, the explanations can significantly increase the decision-maker’s utility while also helping the individuals to self-improve, making transparency desirable for both sides.",8 Broader Impact,96,3,,,FALSE,FALSE,FALSE,"Decisions, Counterfactual Explanations and Strategic Behavior",Social Aspects of Machine Learning,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency; Theory -> Game Theory and Computational Economics","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Stratis Tsirtsis', ' Manuel Gomez Rodriguez']","{'MPI-SWS', 'Max Planck Institute for Software Systems'}",1,0,0,{'Germany'}
Hierarchical Patch VAE-GAN: Generating Diverse Videos from a Single Sample,"Shir Gur, Sagie Benaim, Lior Wolf",Hierarchical Patch VAE-GAN: Generating Diverse Videos from a Single Sample,c2f32522a84d5e6357e6abac087f1b0b,https://proceedings.neurips.cc/paper/2020/file/c2f32522a84d5e6357e6abac087f1b0b-Paper.pdf,"The ability to create synthetic videos can be used for creating fake videos. Humans tend to perceive media as genuine, which creates a risk. On the other hand, the development of methods such as ours enable the study of methods to detect fake videos. A positive societal outcome may arise by the privacy-preserving aspect of providing videos in which identifiable elements such as the arrangement of the scene and the people within it have been altered. This can promote privacy, which is an aspect of great societal value as online media sharing continually increases.",Broader Impact,94,5,,,FALSE,FALSE,FALSE,Hierarchical Patch VAE-GAN: Generating Diverse Videos from a Single Sample,Applications -> Computer Vision,Algorithms -> Unsupervised Learning; Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models,Vision,"['Shir Gur', ' Sagie Benaim', ' Lior Wolf']","{'Facebook AI Research', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
A Feasible Level Proximal Point Method for Nonconvex Sparse Constrained Optimization,"Digvijay Boob, Qi Deng, Guanghui Lan, Yilin Wang",A Feasible Level Proximal Point Method for Nonconvex Sparse Constrained Optimization,c336346c777707e09cab2a3c79174d90,https://proceedings.neurips.cc/paper/2020/file/c336346c777707e09cab2a3c79174d90-Paper.pdf,"This paper presents a new model for sparse optimization and performs an algorithmic study for the proposed model. A rigorous statistical study of this model is still missing. We believe this was due to the tacit assumption that constrained optimization was more challenging compared to regularized optimization. This work takes the first step in showing that efficient algorithms can be developed for the constrained model as well. Contributions made in this paper has the potential to inspire new research from statistical, algorithmic as well as experimental point of view in the wider sparse optimization area.",Broader Impact,95,5,,,FALSE,FALSE,FALSE,A Feasible Level Proximal Point Method for Nonconvex Sparse Constrained Optimization,Optimization -> Non-Convex Optimization,Algorithms -> Sparsity and Compressed Sensing,Optimization Methods (continuous or discrete),"['Digvijay Boob', ' Qi Deng', ' Guanghui Lan', ' Yilin Wang']","{'Georgia Tech', 'Georgia Institute of Technology', 'Shanghai University of Finance and Economics'}",1,0,0,"{'USA', 'China'}"
Reservoir Computing meets Recurrent Kernels and Structured Transforms,"Jonathan Dong, Ruben Ohana, Mushegh Rafayelyan, Florent Krzakala",Reservoir Computing meets Recurrent Kernels and Structured Transforms,c348616cd8a86ee661c7c98800678fad,https://proceedings.neurips.cc/paper/2020/file/c348616cd8a86ee661c7c98800678fad-Paper.pdf,"Our work consists in a theoretical and numerical study of acceleration techniques for random RNNs. Theoretical studies are important to understand machine learning to avoid relying on black boxes, towards a more responsible use of these algorithms as more and more applications appear in our daily life. On the other hand, efficient machine learning is necessary due to the ever-increasing power consump- tion required for computation. The Recurrent Kernels and Structured Reservoir Computing methods we developed pave the way towards much more efficient Reservoir Computing algorithms.",Broader Impact,86,4,,,FALSE,TRUE,FALSE,Reservoir Computing meets Recurrent Kernels and Structured Transforms,Deep Learning -> Recurrent Networks,Algorithms -> Dynamical Systems; Algorithms -> Kernel Methods; Applications -> Time Series Analysis; Theory -> Spaces of Functions and Kernels,Deep learning,"['Jonathan Dong', ' Ruben Ohana', ' Mushegh Rafayelyan', 'Brossel Laboratory', ' Florent Krzakala']","{'Ecole Normale Supérieure', 'Laboratoire Kastler-Brossel'}",1,0,0,{'France'}
Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection,"Zeyi Huang, Yang Zou, B. V. K. Vijaya Kumar, Dong Huang",Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection,c3535febaff29fcb7c0d20cbe94391c7,https://proceedings.neurips.cc/paper/2020/file/c3535febaff29fcb7c0d20cbe94391c7-Paper.pdf,"This paper pushes the frontier of the weakly supervised object detection and reduce its performance gap with the supervised detection. This work is also a general regularization approach that may benefit semi-supervised learning, weakly-supervised learning, and self-supervised representation learning. The ultimate research vision is to potentially relieve the burden of human annotations on training data. This effort may reduce the cost, balance human bias, accelerate the evolution of machine perception technology, and help us to understand how to enable learning with minimal supervision.",Broader Impact,83,4,FALSE,FALSE,FALSE,TRUE,FALSE,Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection,Deep Learning -> Attention Models,Algorithms -> Semi-Supervised Learning; Applications -> Object Detection,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Zeyi Huang', ' Yang Zou', ' Vijaya Kumar', ' Dong Huang']","{'CMU, USA', 'carnegie mellon university', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Linear Dynamical Systems as a Core Computational Primitive,Shiva Kaul,Linear Dynamical Systems as a Core Computational Primitive,c3581d2150ff68f3b33b22634b8adaea,https://proceedings.neurips.cc/paper/2020/file/c3581d2150ff68f3b33b22634b8adaea-Paper.pdf,"The broad impact of our work is to make RNNs faster and more trustworthy. Trustworthiness encompassing the topics of robustness, interpretability, and fairness - is a major concern about deep learning. In many applications, trustworthiness is as important as the traditional metrics of speed and accuracy. Lack of trust is now hindering adoption of machine learning in healthcare, law, social media, and other fields. In this work, we hope to bolster society’s faith in machine learning models, particularly recurrent neural networks, without sacrificing the speed and accuracy which are also required of them. Responsible applications of our work will balance trustworthiness, speed, and accuracy according to the best interests of those affected by the resulting algorithm.",8 Broader Impact,116,6,,,FALSE,FALSE,FALSE,Linear Dynamical Systems as a Core Computational Primitive,Algorithms,"Algorithms -> Dynamical Systems; Applications -> Time Series Analysis; Deep Learning -> Recurrent Networks; Deep Learning -> Visualization, Interpretability, and Explainability","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",['Shiva Kaul'],{'Carnegie Mellon University'},1,0,0,{'USA'}
Ratio Trace Formulation of Wasserstein Discriminant Analysis,"Hexuan Liu, Yunfeng Cai, You-Lin Chen, Ping Li",Ratio Trace Formulation of Wasserstein Discriminant Analysis,c37f9e1283cbd4a6edfd778fc8b1c652,https://proceedings.neurips.cc/paper/2020/file/c37f9e1283cbd4a6edfd778fc8b1c652-Paper.pdf,"In the era of big data, business providers, data scientists, and governments try to explore opportu- nities in the large scale and high-dimensional datasets. Nevertheless, several major computational challenges arise and prevent practitioners from constructing effective algorithms or tools to analyze their datasets. Dimensionality reduction (DR) plays an essential role in supervised and unsupervised learning tasks when the datasets are high dimensional. One benefit of reducing the data dimension before classification or clustering is to save storage and reduce computational cost for the later steps, however, the DR technique itself can be costly. We study a recently proposed and promising DR technique, the Wasserstein discriminant analysis, and propose a different formulation that could achieve comparable or better results with less computational cost. We also analyze the problem from a different perspective that was originated from electronic structure calculations, which could be of interest to a broader audience in the machine learning community.",Broader Impact,152,6,,,FALSE,FALSE,FALSE,Ratio Trace Formulation of Wasserstein Discriminant Analysis,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)",Algorithms -> Classification; Algorithms -> Clustering,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Hexuan Liu', ' Yunfeng Cai', 'Lin Chen', ' Ping Li']","{'Department of Statistics, University of Chicago', 'University of Washington', 'Baidu Research', 'Baidu Research USA'}",1,1,1,"{'USA', 'China'}"
PAC-Bayes Analysis Beyond the Usual Bounds,"Omar Rivasplata, Ilja Kuzborskij, Csaba Szepesvari, John Shawe-Taylor",PAC-Bayes Analysis Beyond the Usual Bounds,c3992e9a68c5ae12bd18488bc579b30d,https://proceedings.neurips.cc/paper/2020/file/c3992e9a68c5ae12bd18488bc579b30d-Paper.pdf,"We think this work will have a positive impact on the theoretical machine learning community. However, since this work presents a high-level theoretical framework, its direct impact on society will be linked to the particular user-specific applications where this framework may be instantiated.",Broader Impact,43,2,FALSE,FALSE,FALSE,FALSE,FALSE,PAC-Bayes Analysis Beyond the Usual Bounds,Theory -> Statistical Learning Theory,Algorithms -> Classification; Algorithms -> Regression; Algorithms -> Stochastic Methods,,"['Omar Rivasplata', ' Ilja Kuzborskij', ' Csaba Szepesvari', 'Taylor']","{'UCL', 'DeepMind', 'DeepMind / University of Alberta'}",1,1,1,"{'Canada', 'UK'}"
Few-shot Visual Reasoning with Meta-Analogical Contrastive Learning,"Youngsung Kim, Jinwoo Shin, Eunho Yang, Sung Ju Hwang",Few-shot Visual Reasoning with Meta-analogical Contrastive Learning,c39e1a03859f9ee215bc49131d0caf33,https://proceedings.neurips.cc/paper/2020/file/c39e1a03859f9ee215bc49131d0caf33-Paper.pdf,"We investigated a low-shot visual reasoning problem, which requires a higher-level relational reasoning skills that goes beyond perception of each individual elements. To this end, we introduce a new visual analogical learning framework that allowed the model to learn relational structure among the set elements from a pair of problems, which achieves significantly improved generalization performance with a limited amount of training samples, and generalizes well to problems with unseen attributes. Although we only considered a specific visual reasoning problem in this work, the proposed method is sufficiently general and we believe that the same analogical learning scheme could be applied to a wide variety of applications from non-vision domains, such as natural language understanding. Analogical reasoning is also a unique property of human intelligence and thus our work may be in the footsteps of the progress toward implementing artificial general intelligence (AGI).",Statement of Broader Impact,143,4,,,FALSE,FALSE,FALSE,Few-shot Visual Reasoning with Meta-Analogical Contrastive Learning,Neuroscience and Cognitive Science -> Reasoning,Algorithms -> Meta-Learning,Visual Reasoning,"['Youngsung Kim', ' Jinwoo Shin', ' Eunho Yang', ' Sung Ju Hwang']","{'KAIST, AITRICS', 'KAIST', 'SAIT'}",1,1,1,"{'Canada', 'South Korea'}"
MPNet: Masked and Permuted Pre-training for Language Understanding,"Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu",MPNet: Masked and Permuted Pre-training for Language Understanding,c3a690be93aa602ee2dc0ccab5b7b67e,https://proceedings.neurips.cc/paper/2020/file/c3a690be93aa602ee2dc0ccab5b7b67e-Paper.pdf,"In natural language processing, pre-trained models have achieved rapid progress and a lot of pretraining methods are proposed. In terms of positive impacts, MPNet can help people to rethink current popular pre-trained methods ( i.e. , MLM in BERT and PLM in XLNet) and thus inspire future researchers to explore more advanced pre-training methods. Currently, the pre-trained models have been considered as the most powerful tools, which help machine to obtain amazing performance in a series of NLP tasks. The final goal of the pre-trained models is to enable machine understands natural languages as human being, which is an important step towards artificial intelligence. In terms of negative impact, pre-training models are usually of large model size and training cost, which makes it too expensive for both research and product. In the future, we will develop more light-weight and low-cost pre-training models.",Broader Impact,142,6,,,FALSE,FALSE,FALSE,MPNet: Masked and Permuted Pre-training for Language Understanding,Applications -> Natural Language Processing,,Natural language processing,"['Kaitao Song', ' Xu Tan', ' Tao Qin', ' Jianfeng Lu', 'Yan Liu']","{'Microsoft Research Asia', 'Microsoft Research', 'Nanjing University of Science and technology', 'Nanjing University of Science and Technology'}",1,1,1,"{'USA', 'China'}"
Reinforcement Learning with Feedback Graphs,"Christoph Dann, Yishay Mansour, Mehryar Mohri, Ayush Sekhari, Karthik Sridharan",Reinforcement Learning with Feedback Graphs,c41dd99a69df04044aa4e33ece9c9249,https://proceedings.neurips.cc/paper/2020/file/c41dd99a69df04044aa4e33ece9c9249-Paper.pdf,"This work is of theoretical nature and the presented insights are unlikely to have a direct impact on society at large. That said, it might guide future research with such impact.",Broader Impact,31,2,TRUE,TRUE,FALSE,FALSE,FALSE,Reinforcement Learning with Feedback Graphs,Reinforcement Learning and Planning -> Exploration,Algorithms -> Bandit Algorithms; Algorithms -> Online Learning,Reinforcement learning and planning,"['Christoph Dann', ' Yishay Mansour', ' Mehryar Mohri', ' Ayush Sekhari', ' Karthik Sridharan']","{'Google', 'Carnegie Mellon University', 'Cornell University'}",1,1,1,{'USA'}
Zap Q-Learning With Nonlinear Function Approximation,"Shuhang Chen, Adithya M Devraj, Fan Lu, Ana Busic, Sean Meyn",Zap Q-learning with Nonlinear Function Approximation,c42f891cebbc81aa59f8f183243ac2b9,https://proceedings.neurips.cc/paper/2020/file/c42f891cebbc81aa59f8f183243ac2b9-Paper.pdf,"This paper has focused on formulating Q-learning algorithms for which reliability is guaranteed by design. It is hoped that it will inspire the creation of a larger tool kit for ODE algorithm design, and methods to more efficiently translate the ODE to obtain better algorithms for reinforcement learning, especially in other contexts such as actor-critic methods. Given the importance of stochastic approximation in so many other fields, such as optimization, it is hoped that the impact will extend far beyond reinforcement learning.",Broader Impact,82,3,,,FALSE,FALSE,FALSE,Zap Q-Learning With Nonlinear Function Approximation,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Decision and Control,Reinforcement learning and planning,"['Shuhang Chen', ' Adithya M Devraj', ' Fan Lu', ' Ana Busic', ' Sean Meyn']","{'INRIA', 'University of Florida'}",1,0,0,"{'France', 'USA'}"
Lipschitz-Certifiable Training with a Tight Outer Bound,"Sungyoon Lee, Jaewook Lee, Saerom Park",Lipschitz-Certifiable Training with a Tight Outer Bound,c46482dd5d39742f0bfd417b492d0e8e,https://proceedings.neurips.cc/paper/2020/file/c46482dd5d39742f0bfd417b492d0e8e-Paper.pdf,"Verifiable training can be used as one of a general learning scheme for applications to security- sensitive domains such as self-driving cars, face recognition, and medical diagnostics. In these applications, an adversarial example is a potential safety hazard that we want to avoid. By training a model with BCP, we can guarantee that no adversarial attack within a given norm-based perturbation can break the model. However, we should note that there is a trade-off between security and performance. Our work tends to lean to the security aspect, having relatively low accuracy on natural data. The sacrifice of performance can halve the benefits of applying deep learning models, and security concerns can restrain deployments in the real system. We are already familiar with deep learning models embedded in our everyday products or services, such as a smart speaker, ridesharing apps, and social media services. Therefore, a balance of performance and security is required depending on the characteristics of the application. The development of verifiable training algorithm enables to improve standard accuracy, exactly quantifying the security. In addition, the quantification of performance and security can help to adjust the balance between them.",Broader Impact,190,10,,,FALSE,FALSE,FALSE,Lipschitz-Certifiable Training with a Tight Outer Bound,Algorithms -> Adversarial Learning,Social Aspects of Machine Learning -> AI Safety,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Sungyoon Lee', ' Jaewook Lee', ' Saerom Park']",{'Seoul National University'},1,0,0,{'South Korea'}
Fast Adaptive Non-Monotone Submodular Maximization Subject to a Knapsack Constraint,"Georgios Amanatidis, Federico Fusco, Philip Lazos, Stefano Leonardi, Rebecca Reiffenhäuser",Fast Adaptive Non-Monotone Submodular Maximization Subject to a Knapsack Constraint,c49e446a46fa27a6e18ffb6119461c3f,https://proceedings.neurips.cc/paper/2020/file/c49e446a46fa27a6e18ffb6119461c3f-Paper.pdf,"While the performance of our algorithms constitutes a significant improvement over existing methods with regard to speed as well as the handling of uncertain environments, there already exists a vast body of research on the type of problems they can be applied to. Our methods could lead to handling those problems, e.g., summarising training data, recommendation systems, viral marketing, etc., more efficiently. Even though these applications revolutionized many areas of business and society, we do not expect the impact of our research to be substantially different from existing methods.",Broader Impact,89,3,,,FALSE,FALSE,FALSE,Fast Adaptive Non-Monotone Submodular Maximization Subject to a Knapsack Constraint,Optimization -> Submodular Optimization,Optimization -> Discrete Optimization; Optimization -> Stochastic Optimization,Theory (including computational and statistical analyses),"['Georgios Amanatidis', ' Federico Fusco', ' Philip Lazos', ' Stefano Leonardi', ' Rebecca Reiffenhäuser']","{'Sapienza University of Rome', 'University of Essex'}",1,0,0,"{'UK', 'Italy'}"
Conformal Symplectic and Relativistic Optimization,"Guilherme Franca, Jeremias Sulam, Daniel Robinson, Rene Vidal",Conformal Symplectic and Relativistic Optimization,c4b108f53550f1d5967305a9a8140ddd,https://proceedings.neurips.cc/paper/2020/file/c4b108f53550f1d5967305a9a8140ddd-Paper.pdf,"The techniques introduced in this paper significantly broaden the applicability of existing results in dynamical systems theory, classical Lagrangian/Hamiltonian mechanics, and numerical analysis of differential equation to optimization, which have widespread applications in several areas of statisti- cal machine learning. This work also lead to cross-fertilization between dynamical systems theory, physics, machine learning and optimization, which can impact emerging work at the intersection of learning and control. We do not see any disadvantages or implications due to failure of this research at this point.",Broader Impact,84,3,,,FALSE,FALSE,FALSE,Conformal Symplectic and Relativistic Optimization,Theory -> Statistical Physics of Learning,Deep Learning -> Optimization for Deep Networks,Optimization Methods (continuous or discrete),"['Guilherme Starvaggi Franca', ' Jeremias Sulam', ' Daniel Robinson', ' Rene Vidal']","{'Johns Hopkins University, USA', 'Johns Hopkins University'}",1,0,0,{'USA'}
Bayes Consistency vs. H-Consistency: The Interplay between Surrogate Loss Functions and the Scoring Function Class,"Mingyuan Zhang, Shivani Agarwal",Bayes Consistency vs. H -Consistency: The Interplay between Surrogate Loss Functions and the Scoring Function Class,c4c28b367e14df88993ad475dedf6b77,https://proceedings.neurips.cc/paper/2020/file/c4c28b367e14df88993ad475dedf6b77-Paper.pdf,"The primary goal of this paper is to better understand the statistical consistency properties of surrogate risk minimization algorithms in machine learning. The insights and results of the paper will benefit readers who wish to be aware of these properties when designing or selecting learning algorithms. We do not expect this research to put anyone at a disadvantage. Nevertheless, issues related to data bias and fairness can potentially affect any algorithm that learns models from data [9], and users should keep this in mind when applying the ideas discussed here to domains where such issues may be important. In the future, it may also be of interest to consider incorporating fairness constraints in the types of algorithms discussed here.",Broader Impact,119,5,,,FALSE,FALSE,FALSE,Bayes Consistency vs. H-Consistency: The Interplay between Surrogate Loss Functions and the Scoring Function Class,Algorithms -> Classification,Theory -> Models of Learning and Generalization ; Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Mingyuan Zhang', ' Shivani Agarwal']",{'University of Pennsylvania'},1,0,0,{'USA'}
Inverting Gradients - How easy is it to break privacy in federated learning?,"Jonas Geiping, Hartmut Bauermeister, Hannah Dröge, Michael Moeller",Inverting Gradients - How easy is it to break privacy in federated learning?,c4ede56bbd98819ae6112b20ac6bf145,https://proceedings.neurips.cc/paper/2020/file/c4ede56bbd98819ae6112b20ac6bf145-Paper.pdf,"Recent works on privacy attacks in federated learning setups ([25, 24, 31, 35, 34]) have hinted at the fact that previous hopes that “Privacy is enhanced by the ephemeral and focused nature of the [Federated Learning] updates” [3] are not true in general. In this work, we demonstrated that improved optimization strategies such as a cosine similarity loss and a signed Adam optimizer allow for image recovery in a federated learning setup in industrially realistic settings for computer vision: Opposed to the idealized architectures of previous works we demonstrate that image recovery is possible in deep, non-smooth and trained architectures over multiple federated averaging steps of the optimizer and even in batches of 100 images. We note that image classification is possibly especially vulnerable to these types of attacks, given the inherent structure of image data, the size of image classification networks, and the comparatively small number of images a single user might own, relative to other personal information. On the other hand, this attack is likely only a first step towards stronger attacks. Therefore, this work points out that the question how to protect the privacy of our data while collaboratively training highly accurate machine learning approaches remains largely unsolved: While differential privacy offers provable guarantees, it also reduces the accuracy of the resulting models significantly [12]. As such differential privacy and secure aggregation can be costly to implement so that there is some economic incentive for data companies to use only basic federated learning. For a more general discussion, see [30]. There is strong interest in further research on privacy preserving learning techniques that render the attacks proposed in this paper ineffective. This might happen via defensive mechanisms or via computable guarantees that allow practitioners to verify whether their specific application is vulnerable to such an attack and within which bounds.",Broader Impact - Federated Learning does not guarantee privacy,303,9,,,FALSE,FALSE,FALSE,Inverting Gradients - How easy is it to break privacy in federated learning?,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Applications -> Computer Vision; Optimization -> Non-Convex Optimization,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Jonas Geiping', ' Hartmut Bauermeister', ' Hannah Dröge', ' Michael Moeller']",{'University of Siegen'},1,0,0,{'Germany'}
Dynamic allocation of limited memory resources in reinforcement learning,"Nisheet Patel, Luigi Acerbi, Alexandre Pouget",Dynamic allocation of limited memory resources in reinforcement learning,c4fac8fb3c9e17a2f4553a001f631975,https://proceedings.neurips.cc/paper/2020/file/c4fac8fb3c9e17a2f4553a001f631975-Paper.pdf,"We believe that this work has the potential to lead to a net-positive change in the reinforcement learning community and more broadly in society as a whole. Our work enables researchers to represent the uncertainty in memories due to resource constraints and perform well in the face of such constraints by prioritizing the knowledge that really matters. While our work is preliminary, we believe that furthering this line of work may prove to be highly beneficial in reducing the overall carbon footprint of the artificial intelligence (AI) industry, which has recently come under scrutiny for the jarring energy consumption of several common large AI models that produce up to five times as much CO 2 than an average American car does in its lifetime [51, 52]. In terms of ethical aspects, our method is neutral per se. The advancement of energy-efficient algorithms may enable autonomous agents to function for long hours in remote areas, the applications for which could be used for both constructive and destructive things alike, e.g. they may be deployed for rescue missions [53] or weaponized for military applications [54, 55], but this holds true for any RL agent.",Broader Impact,192,5,,,FALSE,FALSE,FALSE,Dynamic allocation of limited memory resources in reinforcement learning,Neuroscience and Cognitive Science -> Memory,Neuroscience and Cognitive Science -> Cognitive Science; Neuroscience and Cognitive Science -> Neuroscience; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Model-Based RL; Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning,Neuroscience and cognitive science,"['Nisheet Patel', ' Luigi Acerbi', ' Alexandre Pouget']","{'University of Geneva', 'University of Helsinki'}",1,0,0,"{'Finland', 'Switzerland'}"
CryptoNAS: Private Inference on a ReLU Budget,"Zahra Ghodsi, Akshaj Kumar Veldanda, Brandon Reagen, Siddharth Garg",CryptoNAS: Private Inference on a ReLU Budget,c519d47c329c79537fbb2b6f1c551ff0,https://proceedings.neurips.cc/paper/2020/file/c519d47c329c79537fbb2b6f1c551ff0-Paper.pdf,"Privacy is an increasingly and critically important societal concern, especially given the fraying bonds of trust between individuals, organizations and governments. By enabling users to protect the privacy of their data and organizations to protect the privacy of their models without compromising accuracy and at reasonable latency, CryptoNAS seeks to herald a new suite of private inference solutions based on cryptography. On the other hand, performing computations in the encrypted domain can inadvertently affect the ability to detect other types of attacks on machine learning systems, e.g. inference attacks.",Broader Impact,89,3,,,FALSE,FALSE,FALSE,CryptoNAS: Private Inference on a ReLU Budget,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Deep Learning -> CNN Architectures; Deep Learning -> Efficient Inference Methods,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Zahra Ghodsi', ' Akshaj Kumar Veldanda', ' Brandon Reagen', ' Siddharth Garg']","{'New York University', 'NYU'}",1,0,0,{'USA'}
A Stochastic Path Integral Differential EstimatoR  Expectation Maximization Algorithm,"Gersende Fort, Eric Moulines, Hoi-To Wai",A Stochastic Path-Integrated Differential EstimatoR Expectation Maximization Algorithm,c589c3a8f99401b24b9380e86d939842,https://proceedings.neurips.cc/paper/2020/file/c589c3a8f99401b24b9380e86d939842-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,TRUE,TRUE,FALSE,A Stochastic Path Integral Differential EstimatoR  Expectation Maximization Algorithm,Optimization -> Stochastic Optimization,Algorithms; Algorithms -> Large Scale Learning; Algorithms -> Missing Data; Optimization -> Non-Convex Optimization; Probabilistic Methods -> Latent Variable Models,Theory (including computational and statistical analyses),"['Gersende Fort', ' Eric Moulines', 'To Wai']","{'The Chinese University of Hong Kong', 'CNRS', 'Ecole Polytechnique'}",1,0,0,"{'France', 'China', 'Switzerland'}"
CHIP: A Hawkes Process Model for Continuous-time Networks with Scalable and Consistent Estimation,"Makan Arastuie, Subhadeep Paul, Kevin Xu",CHIP: A Hawkes Process Model for Continuous-time Networks with Scalable and Consistent Estimation,c5a0ac0e2f48af1a4e619e7036fe5977,https://proceedings.neurips.cc/paper/2020/file/c5a0ac0e2f48af1a4e619e7036fe5977-Paper.pdf,"Our proposed CHIP model can be applied to analyze any type of timestamped relational event data. In this paper, we considered analysis of mobile phone calls, emails, and user interactions on on-line social networks. However, timestamped relational event data is used in a variety of other disciplines, including financial mathematics, e.g. transactions between traders in financial markets [19]; political science, e.g. military deployments between countries [2, 67]; and sociology, e.g. homicides between gangs in a city [43, 68]. Thus, our CHIP model can have broader impact to society through the advancement of multiple research disciplines. The CHIP model, like other generative models for dynamic networks, can be used for forecasting, e.g. to predict which nodes are likely to have an event, as well as the number of events during a specified time interval. For some applications, the forecasts may themselves be used to affect decision making. For example, in public policy, crime forecasting can be used for predictive policing, which affects the allocation of police resources to different locations over time. This can have societal benefits, as a recent randomized controlled field trial for predictive policing using Hawkes process models for prediction demonstrated a 7% reduction in crime [69], but also potential for negative consequences like arrests that are biased with respect to minority communities, although such consequences were not observed in the randomized trial [70]. In this paper, we analyzed a publicly available anonymized Facebook on-line social network dataset, so we are not aware of negative consequences that may result from our proposed model.",Broader Impact,255,9,,,FALSE,FALSE,FALSE,CHIP: A Hawkes Process Model for Continuous-time Networks with Scalable and Consistent Estimation,Applications -> Network Analysis,Algorithms -> Clustering; Algorithms -> Relational Learning; Applications -> Web Applications and Internet Data; Theory -> Frequentist Statistics,Probabilistic methods and inference,,"{'The Ohio State University', 'University of Toledo'}",1,0,0,{'USA'}
SAC: Accelerating and Structuring Self-Attention via Sparse Adaptive Connection,"Xiaoya Li, Yuxian Meng, Mingxin Zhou, Qinghong  Han, Fei Wu, Jiwei Li",SAC: Accelerating and Structuring Self-Attention via Sparse Adaptive Connection,c5c1bda1194f9423d744e0ef67df94ee,https://proceedings.neurips.cc/paper/2020/file/c5c1bda1194f9423d744e0ef67df94ee-Paper.pdf,"Accelerating fully-connected self-attention has been a research trend in recent years. Vanilla self- attention models, such as Transformers and BERT, are not able to process extremely long text, where text must be in advance segmented into pieces and then can be individually modelled. The lack of adequate context leads to poor performances in generating long, coherent and fluent text. The goal of our proposed method, SAC, is to provide a way of relieving the computation burden of vanilla self-attention by automatically searching for the best attention patterns. We believe SAC has great potentials to generate high-quality long text. While there is risk of abuse, like generating fake news, the value of SAC is generally safe and weighs more than abuse to the whole society.",Broader Impact,124,6,,,FALSE,FALSE,FALSE,SAC: Accelerating and Structuring Self-Attention via Sparse Adaptive Connection,Applications -> Natural Language Processing,Deep Learning -> Attention Models,Natural language processing,"['Xiaoya Li', ' Yuxian Meng', ' Mingxin Zhou', ' Qinghong Han', ' Fei Wu', ' Jiwei Li']",{'Zhejiang University'},1,0,0,{'China'}
Design Space for Graph Neural Networks,"Jiaxuan You, Zhitao Ying, Jure Leskovec",Design Space for Graph Neural Networks,c5c3d4fe6b2cc463c7d7ecba17cc9de7,https://proceedings.neurips.cc/paper/2020/file/c5c3d4fe6b2cc463c7d7ecba17cc9de7-Paper.pdf,"Impact on GNN research . Our work brings in many valuable mindsets to the field of GNN research. For example, we fully adopt the principle of controlling model complexity when comparing different models, which is not yet adopted in most GNN papers. We focus on finding guidelines / principles when designing GNNs, rather than particular GNN instantiations. We emphasize that the best GNN designs can drastically differ across tasks (the state-of-the-art GNN model on one task may have poor performance on other tasks). We thus propose to evaluate models on diverse tasks measured by quantitative similarity metric. Rather than criticizing the weakness of existing GNN architectures, our goal is to build a framework that can help researchers understand GNN design choices when developing new models suitable for different applications. Our approach serves as a tool to demonstrate the innovation of a novel GNN model ( e.g. , in what kind of design spaces / task spaces, a proposed algorithmic advancement is helpful), or a novel GNN task ( e.g. , showing that the task is not similar to any existing tasks thus calls for new challenges of algorithmic development). Impact on machine learning research . Our approach is in fact applicable to general machine learning model design. Specifically, we hope the proposed controlled random search technique can assist fair evaluation of novel algorithmic advancements. To show whether a certain algorithmic advancement is useful, it is important to sample random model-task combinations, then investigate in what scenarios the algorithmic advancement indeed improves the performance. Additionally, the proposed task similarity metric can be used to understand similarities between general machine learning tasks, e.g. , classification of MNIST and CIFAR-10. Our ranking-based similarity metric is fully general, as long as different designs can be ranked by their performance. Impact on other research domains . Our framework provides an easier than ever support for experts in other disciplines to solve their problems via GNNs. Domain experts only need to provide properly formatted domain-specific datasets, then recommended GNN designs will be automatically picked and applied to the dataset. In the fastest mode, anchor GNN models will be applied to the novel task in order to measure its similarity with known GNN tasks, where the corresponding best GNN designs have been saved. Top GNN designs in the tasks with high similarity to the novel task will be applied. If computational resources permitted, a full grid search / random search over the design space can also be easily carried out to the new task. We believe this pipeline can significantly lower the barrier for applying GNN models, thus greatly promote the application of GNNs in other research domains. Impact on the society . As is discussed above, given its clarity and accessibility, we are confident that our general approach can inspire novel applications that are of high impact to the society. Additionally, its simplicity can also provide great opportunities for AI education, where students can learn from SOTA deep learning models and inspiring applications at ease.",Broader Impact,499,24,,,FALSE,FALSE,FALSE,Design Space for Graph Neural Networks,Algorithms -> Relational Learning,"Algorithms -> Representation Learning; Data, Challenges, Implementations, and Software -> Benchmarks",Deep learning,"['Jiaxuan You', ' Zhitao Ying', ' Jure Leskovec']","{'Stanford University', 'Stanford University and Pinterest'}",1,0,0,{'USA'}
HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis,"Jungil Kong, Jaehyeon Kim, Jaekyoung Bae",HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis,c5d736809766d46260d816d8dbc9eb44,https://proceedings.neurips.cc/paper/2020/file/c5d736809766d46260d816d8dbc9eb44-Paper.pdf,"Speech synthesis technology has been developed for a long time, and recently, it has reached the level of producing speech at human level by applying neural networks. However, although the quality of synthesized audio is very high, there are several limitations for applying the neural network based speech synthesis technology in real production due to the high computation cost and slow synthesis speed. Speech synthesis models that perform high speed synthesis have also been studied, but the quality of these models needed to be improved compared to that of human. Our work addressed these problems, and showed that the proposed model achieves both high quality and fast speech synthesis. This could bring advantages to service providers who provide voice interfaces. Service providers can improve user satisfaction by providing natural and higher quality speech audio allows listeners to understand content more quickly and accurately. In addition, the high computational efficiency obtained in our work could reduce the usage of computing devices such as GPUs and CPUs, which can contribute to the cost savings of the service providers. It could also enable on-device operation of neural network based speech synthesis, which could lower the service latency and computation cost on servers. Meanwhile, the high efficiency and quality of the speech samples that our work is capable of generating can accompany certain adverse effects. First, the demand for recordings of professional voice actors may be reduced. In many applications such as subway announcements, recordings of professional voice actors are embedded. So, when a new announcement is needed, a professional voice actor will record the utterance for the announcement. However, if the neural network based speech synthesis model is capable of producing natural speech like humans, it can replace the work of professional voice actors. This could be considered an inevitable change in the job due to technological advancements. However, we need to devise a way such as contracts for the use of voice, not the cost of recording, to mitigate the sudden impact on our society. Furthermore, high-performance speech synthesis technology can be used for criminal activities such as voice phishing. If a neural network based speech synthesis model was trained with a dataset consisting of speaker characteristics that give someone confidence, such as those of news anchors, it might be used for making people feel secure in the deceptions. In addition, our work has shown that it is possible to generate high-quality speech audio with extremely fast inference speed, which could be used for voice phishing attackers to generate response in real-time during conversation with targets. By combining the speaker characteristics and fast speech synthesis, it might result in increasing the success rate of the voice phishing attacks. The unintended abuse of voice in datasets could also be a problem. Since the speech synthesis models based on neural networks are trained with audio clips of real human speech, the synthesized audio is also very similar to the voice of a speaker who recorded audio clips in the training data. It would not be a problem if the trained model is only to be used in a controlled environment. However, if the model is stolen by a malicious person or if the speech synthesis model is released as a service to allow synthesizing any utterances without restrictions, it could be abused regardless of the original intention of the voice owners or the model owner. Therefore, we believe that institutes and companies that study and use speech synthesis models should pay particular attention to the security of the models and the training datasets. The results of our model failure could be audio clips with noise, distortion, or inaccurate or missing pronunciation. These issues might be acceptable in most cases, but could be a problem when the model is applied to critical tasks such as emergencies or applications designed to listen to audio only once. As is known, most neural network based models are not fully controllable. Therefore, it is difficult to guarantee that it works 100% robust under any conditions. We believe that neural network based speech synthesis technology should be carefully applied in mission critical domains.",Broader Impact,683,29,,,FALSE,TRUE,FALSE,HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis,Applications -> Audio and Speech Processing,Deep Learning -> Generative Models,Audio / Music / Speech,"['Jungil Kong', ' Jaehyeon Kim', ' Jaekyoung Bae']",{'Kakao Enterprise'},0,1,0,{'South Korea'}
Unbalanced Sobolev Descent,"Youssef Mroueh, Mattia Rigotti",Unbalanced Sobolev Descent,c5f5c23be1b71adb51ea9dc8e9d444a8,https://proceedings.neurips.cc/paper/2020/file/c5f5c23be1b71adb51ea9dc8e9d444a8-Paper.pdf,"Our work provides a practical particle descent algorithm that comes with a formal convergence proof and theoretically guaranteed acceleration over previous competing algorithms. Moreover, our algorithm can naturally handle situations where the objects of the descent are particles sampled from a source distribution descending towards a target distribution with different mass. The type of applications that this enables range from theoretically principled modeling of biological growths processes (like tumor growth) and developmental processes (like the differentiation of cells in their gene expression space), to faster numerical simulation of advection-reaction systems. Since our advance is mainly theoretical and algorithmic (besides the empirical demonstrations), its implications are necessarily tied to the utilization for which it is being deployed. Beside the applications that we mentioned, particle descent algorithms like ours have been proposed as a paradigm to characterize and study the dynamics of Generative Adversarial Network (GANs) training. As such, they could indirectly contribute to the risks associated with the nefarious uses of GANs such as deepfakes. On the other hand, by providing a tools to possibly analyze and better understand GANs, our theoretical results might serve as the basis for mitigating their abuse.",Broader Impact Statement,191,7,,,FALSE,FALSE,FALSE,Unbalanced Sobolev Descent,Algorithms -> Kernel Methods,Algorithms -> Unsupervised Learning; Deep Learning -> Generative Models; Optimization; Theory -> Spaces of Functions and Kernels,,"['Youssef Mroueh', ' Mattia Rigotti']",{'IBM Research AI'},0,1,0,{'USA'}
Identifying Mislabeled Data using the Area Under the Margin Ranking,"Geoff Pleiss, Tianyi Zhang, Ethan Elenberg, Kilian Q. Weinberger",Identifying Mislabeled Data using the Area Under the Margin Ranking,c6102b3727b2a7d8b1bb6981147081ef,https://proceedings.neurips.cc/paper/2020/file/c6102b3727b2a7d8b1bb6981147081ef-Paper.pdf,"This paper introduces a method to identify mislabeled or harmful training examples. This has implications for two types of datasets. First, it can enable the widespread use of “weakly-labeled” data [e.g. 28, 35, 60], which are often cheap to acquire but have suffered from data quality issues. Secondly, it can be used to audit existing datasets such as ImageNet [13], which are widely used by both researchers and practitioners to benchmark new machine learning methods and applications. Many research and commercial applications rely on standard datasets for pre-training, like ImageNet [13] or large text corpora [14]. Recent work demonstrates brittle properties of these datasets [9, 49]; therefore, improving their quality could impact numerous downstream tasks. However, it is also worth noting that any automated identification procedure has the potential to create or amplify existing biases in these datasets. Auditing and curation might also have unintended consequences in sensitive applications that require security or data privacy. On common datasets like ImageNet/CIFAR, it is worthwhile to note if identification errors are prone to any particular biases.",Broader Impact,174,9,,,TRUE,TRUE,FALSE,Identifying Mislabeled Data using the Area Under the Margin Ranking,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Geoff Pleiss', ' Tianyi Zhang', ' Ethan Elenberg', ' Kilian Weinberger']","{'ASAPP', 'Cornell University / ASAPP Research', 'Columbia University'}",1,1,1,{'USA'}
Combining Deep Reinforcement Learning and Search for Imperfect-Information Games,"Noam Brown, Anton Bakhtin, Adam Lerer, Qucheng Gong",Combining Deep Reinforcement Learning and Search for Imperfect-Information Games,c61f571dbd2fb949d3fe5ae1608dd48b,https://proceedings.neurips.cc/paper/2020/file/c61f571dbd2fb949d3fe5ae1608dd48b-Paper.pdf,"We believe ReBeL is a major step toward general equilibrium-finding algorithms that can be deployed in large-scale multi-agent settings while requiring relatively little domain knowledge. There are numerous potential future applications of this work, including auctions, negotiations, cybersecurity, and autonomous vehicle navigation, all of which are imperfect-information multi-agent interactions. The most immediate risk posed by this work is its potential for cheating in recreational games such as poker. While AI algorithms already exist that can achieve superhuman performance in poker, these algorithms generally assume that participants have a certain number of chips or use certain bet sizes. Retraining the algorithms to account for arbitrary chip stacks or unanticipated bet sizes requires more computation than is feasible in real time. However, ReBeL can compute a policy for arbitrary stack sizes and arbitrary bet sizes in seconds. Partly for this reason, we have decided not to release the code for poker. We instead open source our implementation for Liar’s Dice, a recreational game that is not played as competitively by humans. The implementation in Liar’s Dice is also easier to understand and the size of Liar’s Dice can be more easily adjusted, which we believe makes the game more suitable as a domain for research.",Broader Impact,203,9,,,FALSE,FALSE,FALSE,Combining Deep Reinforcement Learning and Search for Imperfect-Information Games,Theory -> Game Theory and Computational Economics,Applications -> Game Playing; Reinforcement Learning and Planning -> Multi-Agent RL; Reinforcement Learning and Planning -> Planning,Reinforcement learning and planning,"['Noam Brown', ' Anton Bakhtin', ' Adam Lerer', ' Qucheng Gong']",{'Facebook AI Research'},0,1,0,{'USA'}
High-Throughput Synchronous Deep RL,"Iou-Jen Liu, Raymond Yeh, Alexander Schwing",High-Throughput Synchronous Deep RL,c6447300d99fdbf4f3f7966295b8b5be,https://proceedings.neurips.cc/paper/2020/file/c6447300d99fdbf4f3f7966295b8b5be-Paper.pdf,"We think artificial intelligence (AI) algorithms can significantly improve people’s lives and should be accessible to everyone. This paper introduces a high-throughput system which permits efficient deep RL training on a single machine. We believe efficient training of deep RL with limited computational resources is critical to make artificial intelligence more accessible, particularly for people and institutions who can not afford a costly distributed system. In the past decade, deep RL achieved impressive results on complex tasks such as GO and 3D video games. However, those achievements rely on a huge amount of computing resources, e.g ., AlphaGo [28] requires 1920 CPUs and 280 GPUs. In contrast, regular personal desktops have only 4 to 16 CPUs and no more than 4 GPUs. As a result, deep RL’s huge demand for computational resources makes it a research privilege for large companies and institutions which can afford these resources. This paper serves as a step toward making deep RL AI accessible to everyone. With the proposed HTS-RL it is possible to train deep RL agents on 3D video games using a regular desktop with 16 CPUs and 4 GPUs instead of requiring a costly distributed system.",Broader Impact,194,9,,,FALSE,FALSE,FALSE,High-Throughput Synchronous Deep RL,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Jen Liu', ' Raymond Yeh', ' Alexander Schwing']","{'University of Illinois at Urbana-Champaign', 'UIUC'}",1,0,0,{'USA'}
Contrastive Learning with Adversarial Examples,"Chih-Hui Ho, Nuno Nvasconcelos",Contrastive Learning with Adversarial Examples,c68c9c8258ea7d85472dd6fd0015f047,https://proceedings.neurips.cc/paper/2020/file/c68c9c8258ea7d85472dd6fd0015f047-Paper.pdf,"This work advances the general use of deep learning technology, especially in the case that dataset annotations are difficult to obtain, and could have many applications. It advances several state of the art solutions on self-supervised learning (SSL), where no labels are provided. Moreover, while prior works in SSL suggest training with larger network, larger batch size and longer training epochs, the experiments in this works demonstrates that these factors are less critical by optimizing on effective training pairs. This can be beneficial in the scenario where time and gpu resource are limited. While this work mainly focuses on the study of image recognition, we hope this work can be extended to other application domains of SSL in the future.",6 Broader Impact,120,5,,,FALSE,FALSE,FALSE,Contrastive Learning with Adversarial Examples,Algorithms -> Unsupervised Learning,Algorithms -> Adversarial Learning,Vision,"['Hui Ho', ' Nuno Nvasconcelos']","{'University of California San Diego', 'UC San Diego'}",1,0,0,{'USA'}
Mixed Hamiltonian Monte Carlo for Mixed Discrete and Continuous Variables,Guangyao Zhou,Mixed Hamiltonian Monte Carlo for Mixed Discrete and Continuous Variables,c6a01432c8138d46ba39957a8250e027,https://proceedings.neurips.cc/paper/2020/file/c6a01432c8138d46ba39957a8250e027-Paper.pdf,"Probabilistic modeling with structured models leads to more interpretable modeling of data and proper uncertainty quantification. M-HMC enables efficient inference for probabilistic models with mixed support, allowing applicability of probabilistic modeling to a broader set of problems. This can contribute to more principled and interpretable decision making process based on probabilistic modeling of data. As with any technology, negative consequences are possible but difficult to predict at this time. This is not a deployed system with immediate failure consequences or that can leverage potentially harmful biases.",Broader Impact,86,5,,,FALSE,FALSE,FALSE,Mixed Hamiltonian Monte Carlo for Mixed Discrete and Continuous Variables,Probabilistic Methods -> MCMC,Probabilistic Methods -> Probabilistic Programming,Probabilistic methods and inference,['Guangyao Zhou'],{'Vicarious AI'},0,1,0,{'USA'}
Adversarial Sparse Transformer for Time Series Forecasting,"Sifan Wu, Xi Xiao, Qianggang Ding, Peilin Zhao, Ying Wei, Junzhou Huang",Adversarial Sparse Transformer for Time Series Forecasting,c6b8c8d762da15fa8dbbdfb6baf9e260,https://proceedings.neurips.cc/paper/2020/file/c6b8c8d762da15fa8dbbdfb6baf9e260-Paper.pdf,"Our proposed new Time series forecasting model– AST improves the time series forecasting by adversarial training and Sparse Transformer, and it achieves impressive performance. AST can better model time series data and alleviate the error accumulation in inference. We believe our work will inspire the related research of time series forecasting. Our work will benefit the application of time series forecasting such as business and industrial decision-making. And we think there are no one will be disadvantaged by our work. Our model does not take advantage of data bias, it is general and scalable.",Broader Impact,94,6,,,FALSE,FALSE,FALSE,Adversarial Sparse Transformer for Time Series Forecasting,Applications -> Time Series Analysis,Deep Learning -> Predictive Models,"Other applications (e.g., robotics, biology, climate, finance)","['Sifan Wu', ' Xi Xiao', ' Qianggang Ding', ' Peilin Zhao', ' Ying Wei', ' Junzhou Huang']","{'University of Texas at Arlington / Tencent AI Lab', 'Tsinghua University', 'Tencent AI Lab'}",1,1,1,"{'USA', 'China'}"
The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks,"Wei Hu, Lechao Xiao, Ben Adlam, Jeffrey Pennington",The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks,c6dfc6b7c601ac2978357b7a81e2d7ae,https://proceedings.neurips.cc/paper/2020/file/c6dfc6b7c601ac2978357b7a81e2d7ae-Paper.pdf,This work is theoretical and does not present any foreseeable societal consequence.,Broader Impact,12,1,TRUE,FALSE,FALSE,FALSE,FALSE,The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks,Deep Learning -> Analysis and Understanding of Deep Networks,,Deep learning,"['Wei Hu', ' Lechao Xiao', ' Ben Adlam', ' Jeffrey Pennington']","{'Google Brain', 'Princeton University', 'Google'}",1,1,1,{'USA'}
CLEARER: Multi-Scale Neural Architecture Search for Image Restoration,"Yuanbiao Gou, Boyun Li, Zitao Liu, Songfan Yang, Xi Peng",CLEARER: Multi-Scale Neural Architecture Search for Image Restoration,c6e81542b125c36346d9167691b8bd09,https://proceedings.neurips.cc/paper/2020/file/c6e81542b125c36346d9167691b8bd09-Paper.pdf,"The proposed method is a specifically designed neural architecture search (NAS) method for image restoration. Namely, two areas, NAS and image restoration, are involved. Image restoration is a common topic in low-level vision tasks which aims to restore the clean image from the degraded one and mainly used to improve the quality of digital images. NAS aims to automatically design the high-performance neural architectures and has been applied to many vision tasks. Therefore, we will discuss the impacts of our method from both aspects. First, there is a risk of removing some necessary degradations during recoveries, such as watermark, subtitle, and mosaic. Namely, such a technology has the potential of prejudicing the rights of others with improper use. Second, NAS could help people to search for an effective neural architecture for some specific tasks. This technology saves a lot of labors and greatly reduces the domain expertise required in the manual design process. However, NAS would further intensify the black-box nature of deep neural networks which brings tremendous security risks when applied to some critical fields such as autopilot and medical. In addition, to search for a desirable architecture, a lot of energy will be consumed, while causing massive CO2 emissions. For example, using NAS to find a specialized neural network and train it from scratch for each case, which causes CO2 emission as much as five cars’ lifetime [36].",Broader Impact,230,12,,,FALSE,FALSE,FALSE,CLEARER: Multi-Scale Neural Architecture Search for Image Restoration,Applications -> Denoising,,Vision,"['Yuanbiao Gou', ' Boyun Li', ' Zitao Liu', ' Songfan Yang', ' Xi Peng', ' Technology and Research']","{'TAL AI Lab', 'College of Computer Science, Sichuan University', 'A*STAR'}",1,1,1,{'China'}
Hierarchical Gaussian Process Priors for Bayesian Neural Network Weights,"Theofanis Karaletsos, Thang D. Bui",Hierarchical Gaussian Process Priors for Bayesian Neural Network Weights,c70341de2c112a6b3496aec1f631dddd,https://proceedings.neurips.cc/paper/2020/file/c70341de2c112a6b3496aec1f631dddd-Paper.pdf,"Our work targets studying priors of neural networks with respect to two specific aspects: first, we aim at obtaining weights which are sharp close to the training data and uncertain away from training data, in order to calibrate the model’s confidence. This is essential for many applications where predictions of neural networks are consumed to drive decisions, which may occur a cost. In case our model produces ""I don’t know"" predictions as we showed it is capable of in OOD data, ML-systems can either probe an expert or utilize a fallback plan for decisions. Such cases occur across industrial applications of algorithmic decision making and impact economics and fairness, but are even more critical in fields such as healthcare or autonomy where wrong but overconfident predictions may lead to catastrophic decisions. The second area of impact centers around the ability of a practitioner to express specific types of prior knowledge for the functions learned by a neural network via auxiliary kernels. This can help practitioners utilize neural networks as less of a black box and ultimately may lead to the ability to train networks with rich weight-based function spaces with little data. These types of network regularization are application-dependent, but ultimately we hope structures such as the ones we propose may be able to aid with generalization outside the training data by encoding prior knowledge into networks, an ability that would potentially help in a variety of real world scenarios where data paucity exists but prior knowledge can be used to fill the gaps.",Broader Impact,254,7,,,FALSE,FALSE,FALSE,Hierarchical Gaussian Process Priors for Bayesian Neural Network Weights,Probabilistic Methods,Deep Learning; Probabilistic Methods -> Gaussian Processes; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Theofanis Karaletsos', ' Thang Bui']","{'Uber AI Labs', 'Uber AI / University of Sydney'}",1,1,1,"{'Australia', 'USA'}"
Compositional Explanations of Neurons,"Jesse Mu, Jacob Andreas",Compositional Explanations of Neurons,c74956ffb38ba48ed6ce977af6727275,https://proceedings.neurips.cc/paper/2020/file/c74956ffb38ba48ed6ce977af6727275-Paper.pdf,"Tools for model introspection and interpretation are crucial for better understanding the behavior of black-box models, especially as they make increasingly important decisions in high-stakes societal applications. We believe that the explanations generated in this paper can help unveil richer concepts that represent spurious correlations and potentially problematic biases in models, thus helping practitioners better understand the decisions made by machine learning models. Nonetheless, we see two limitations with this method as it stands: (1) it currently requires technical expertise to implement, limiting usability by non-experts; (2) it relies on annotated datasets which may be expensive to collect, and may be biased in the kinds of features they contain (or omit). If a potential feature of interest is not present in the annotated dataset, it cannot appear in an explanation. Both of these issues can be ameliorated with future work in (1) building easier user interfaces for explainability, and (2) reducing data annotation requirements. In high stakes cases, e.g. identifying model biases, care should also be taken to avoid relying too heavily on these explanations as causal proof that a model is encoding a concept, or assuming that the absence of an explanation is proof that the model does not encode the concept (or bias). We provide evidence that neurons exhibit surface-level behavior that is well-correlated with human-interpretable concepts, but by themselves, neuron-level explanations cannot identify the full array of concepts encoded in representations, nor establish definitive causal chains between inputs and decisions.",Broader Impact,243,7,,,FALSE,FALSE,FALSE,Compositional Explanations of Neurons,"Deep Learning -> Visualization, Interpretability, and Explainability",Applications -> Computer Vision; Applications -> Natural Language Processing; Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Jesse Mu', ' Jacob Andreas']","{'Stanford University', 'MIT'}",1,0,0,{'USA'}
Calibrated Reliable Regression using Maximum Mean Discrepancy,"Peng Cui, Wenbo Hu, Jun Zhu",Calibrated Reliable Regression using Maximum Mean Discrepancy,c74c4bf0dad9cbae3d80faa054b7d8ca,https://proceedings.neurips.cc/paper/2020/file/c74c4bf0dad9cbae3d80faa054b7d8ca-Paper.pdf,"Uncertainty exists in many aspects of our daily life, which plays a critical role in the application of modern machine learning methods. Unreliable uncertainty quantification may bring safety and reliability issues in these applications like medical diagnosis, autonomous driving, and demand forecasting. Despite deep learning has achieved impressive accuracies on many tasks, NNs are poor to provide accurate predictive uncertainty. Machine learning models should provide accurate confidence bounds (i.e., uncertainty estimation) on these safety-critical tasks. This paper aims to solve the problem of inaccurate predictive quantification for regression models. Our method produces the well-calibrated predictive distribution while achieving the high-precision forecasting for regression tasks, and naturally generate reliable prediction intervals at any confidence level we need. Our proposal has a positive impact on a variety of tasks using the regression models. For example, our proposed model produces more accurate demand forecasting based on the historical sales data for a retail company, which can calculate the safety stock to make sure you don’t lose customers. We  believe that it is necessary to consider the uncertainty calibration for many machine learning models, which will improve the safety and reliability of machine learning and deep learning methods.",Statement of Potential Broader Impact,194,9,,,FALSE,FALSE,FALSE,Calibrated Reliable Regression using Maximum Mean Discrepancy,Algorithms -> Uncertainty Estimation,Algorithms -> Regression; Applications -> Time Series Analysis,Uncertainty Estimation,"['Peng Cui', ' Wenbo Hu', ' Jun Zhu']",{'Tsinghua University'},1,0,0,{'China'}
Directional convergence and alignment in deep learning,"Ziwei Ji, Matus Telgarsky",Directional convergence and alignment in deep learning,c76e4b2fa54f8506719a5c0dc14c2eb9,https://proceedings.neurips.cc/paper/2020/file/c76e4b2fa54f8506719a5c0dc14c2eb9-Paper.pdf,"This paper constitutes theoretical work, with an aim of enhancing human understanding, and laying the groundwork for further theoretical and applied work. The authors hope that advancing the foundations of deep networks leads moreover to a better understanding of their failure modes, and manipulation thereof, and thus an increase in safety.",Broader impact,51,2,FALSE,FALSE,FALSE,FALSE,FALSE,Directional convergence and alignment in deep learning,Deep Learning -> Optimization for Deep Networks,Deep Learning -> Analysis and Understanding of Deep Networks; Optimization -> Non-Convex Optimization; Theory -> Computational Learning Theory,Deep learning,"['Ziwei Ji', ' Matus Telgarsky']","{'UIUC', 'University of Illinois Urbana-Champaign'}",1,0,0,{'USA'}
Functional Regularization for Representation Learning: A Unified Theoretical Perspective,"Siddhant Garg, Yingyu Liang",Functional Regularization for Representation Learning: A Unified Theoretical Perspective,c793b3be8f18731f2a4c627fb3c6c63d,https://proceedings.neurips.cc/paper/2020/file/c793b3be8f18731f2a4c627fb3c6c63d-Paper.pdf,"Our paper is mostly theoretical in nature and thus we foresee no immediate negative societal impact. We are of the opinion that our theoretical framework may inspire development of improved representation learning methods on unlabeled data, which may have a positive impact in practice. In addition to the theoretical machine learning community, we perceive that our precise and easy-to-read formu- lation of unsupervised learning for downstream tasks can be highly beneficial to engineering-inclined machine learning researchers.",Broader Impact,76,3,,,FALSE,FALSE,FALSE,Functional Regularization for Representation Learning: A Unified Theoretical Perspective,Theory -> Statistical Learning Theory,Algorithms -> Representation Learning; Theory -> Regularization,Theory (including computational and statistical analyses),"['Siddhant Garg', ' Yingyu Liang']","{'University of Wisconsin Madison', 'University of Wisconsin-Madison'}",1,0,0,{'USA'}
Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits,"Jack Parker-Holder, Vu Nguyen, Stephen J. Roberts",Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits,c7af0926b294e47e52e46cfebe173f20,https://proceedings.neurips.cc/paper/2020/file/c7af0926b294e47e52e46cfebe173f20-Paper.pdf,"Population Based Training (PBT) has become a prominent algorithm in machine learning research, leading to gains in reinforcement learning (e.g. IMPALA [17]) and industrial applications (e.g. Waymo). As such, we believe the gains provided by PB2 will have a significant impact. We believe this work will allow labs with small to medium sized computational resources to gain the benefit of population-based training without the excessive computational cost required to ensure sufficient exploration. This should be particularly helpful for achieving competitive performance in reinforcement learning experiments. To aid this, our implementation is integrated with the widely used ray library [43].",Broader Impact,99,5,,,FALSE,FALSE,FALSE,Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits,Algorithms -> AutoML,Algorithms -> Bandit Algorithms; Deep Learning -> Efficient Training Methods; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Holder', ' Vu Nguyen', ' Stephen J Roberts']",{'University of Oxford'},1,0,0,{'UK'}
Understanding Global Feature Contributions With Additive Importance Measures,"Ian Covert, Scott M. Lundberg, Su-In Lee",Understanding Global Feature Contributions With Additive Importance Measures,c7bf0b7c1a86d5eb3be2c722cf2cf746,https://proceedings.neurips.cc/paper/2020/file/c7bf0b7c1a86d5eb3be2c722cf2cf746-Paper.pdf,"This work contributes to a growing literature of methods that can provide researchers, engineers, and users with an understanding of how machine learning models work. By focusing on global explanations, our method produces succinct insights that the target audience may find more digestible than a large number of local explanations. Our work aims to contribute positive social impact, but as with any model explanation tool, there is a danger of deliberate misuse or adversarial use that could provide misleading information or be used to gain approval for bad practices.",Broader Impact,89,3,,,FALSE,FALSE,FALSE,Understanding Global Feature Contributions With Additive Importance Measures,"Deep Learning -> Visualization, Interpretability, and Explainability",Applications -> Computational Biology and Bioinformatics,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Ian Covert', ' Scott Lundberg', 'In Lee']","{'University of Washington', 'Microsoft Research'}",1,1,1,{'USA'}
Online Non-Convex Optimization with Imperfect Feedback,"Amélie Héliou, Matthieu Martin, Panayotis Mertikopoulos, Thibaud Rahier",Online Non-Convex Optimization with Imperfect Feedback,c7c46d4baf816bfb07c7f3bf96d88544,https://proceedings.neurips.cc/paper/2020/file/c7c46d4baf816bfb07c7f3bf96d88544-Paper.pdf,This is a theoretical work which does not present any foreseeable societal consequence.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,Online Non-Convex Optimization with Imperfect Feedback,Optimization -> Non-Convex Optimization,Algorithms -> Online Learning; Optimization -> Stochastic Optimization; Theory -> Game Theory and Computational Economics,Optimization Methods (continuous or discrete),"['Amélie Héliou', ' Matthieu Martin', ' Panayotis Mertikopoulos', 'CNRS', ' Thibaud J Rahier']","{'Criteo', 'Criteo AI Lab', 'French National Center for Scientific Research', 'INRIA'}",1,1,1,{'France'}
Co-Tuning for Transfer Learning,"Kaichao You, Zhi Kou, Mingsheng Long, Jianmin Wang",Co-Tuning for Transfer Learning,c8067ad1937f728f51288b3eb986afaa,https://proceedings.neurips.cc/paper/2020/file/c8067ad1937f728f51288b3eb986afaa-Paper.pdf,"The framework proposed in this paper can be applied to transfer learning scenarios with classification tasks. It can improve the effect of fine-tuning. The broader impact of this paper depends on where fine-tuning is applied. If fine-tuning is used in a suitable way (e.g. train a classifier to automatically recognize if some waste is recyclable or not), then our work can have positive impact in the society. If people use fine-tuning in an evil way (e.g. train a classifier for automatic weapons), then our work can have negative impact in the society. Nevertheless, we hold a positive view of the broader impact of this paper in general.",Broader Impact,107,6,,,FALSE,FALSE,FALSE,Co-Tuning for Transfer Learning,Algorithms -> Multitask and Transfer Learning,Deep Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Kaichao You', ' Zhi Kou', ' Mingsheng Long', ' Jianmin Wang']",{'Tsinghua University'},1,0,0,{'China'}
Multifaceted Uncertainty Estimation for Label-Efficient Deep Learning,"Weishi Shi, Xujiang Zhao, Feng Chen, Qi Yu",Multifaceted Uncertainty Estimation for Label-Efficient Deep Learning,c80d9ba4852b67046bee487bcd9802c0,https://proceedings.neurips.cc/paper/2020/file/c80d9ba4852b67046bee487bcd9802c0-Paper.pdf,"The ability to train high-quality supervised learning models opens the gate to effectively leveraging machine intelligence in many critical domains, where domain expertise is scarce and data labeling is costly. The proposed research suggests a paradigm shift to train statistical models that is fundamentally different from existing data-intensive statistical analysis tools, including most deep learning models, where massive amounts of training data are required to ensure model performance. Furthermore, the research will also contribute novel (both theoretical and empirical) methodologies to conduct uncertainty analysis of neural network/deep learning models. The importance of uncertainty analysis plays an essential role to establish human-machine trust to support complex human-machine collaborative decision-making in critical missions and to ensure AI safety as AI systems have been more broadly adopted in society.",Broader Impact,126,4,,,FALSE,FALSE,FALSE,Multifaceted Uncertainty Estimation for Label-Efficient Deep Learning,Algorithms -> Uncertainty Estimation,Deep Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Weishi Shi', ' Xujiang Zhao', ' Feng Chen', ' Qi Yu']","{'UT Dallas', 'Rochester Institute of Technology', 'The University of Texas at Dallas'}",1,0,0,{'USA'}
Continuous Surface Embeddings,"Natalia Neverova, David Novotny, Marc Szafraniec, Vasil Khalidov, Patrick Labatut, Andrea Vedaldi",Continuous Surface Embeddings,c81e728d9d4c2f636f067f89cc14862c,https://proceedings.neurips.cc/paper/2020/file/c81e728d9d4c2f636f067f89cc14862c-Paper.pdf,"In our paper, we help improve the ability of machines to understand the pose of articulated objects such as humans in images. In particular, we make the process of learning new object categories much more efficient. An application of our method is the observation of the human body. This may come with some concerns on possible negative uses of the technology. However, we should note that our approach cannot be considered biometrics, because from pose alone, even if dense, it is not possible to as- certain the identity of an individual (in particular, we do not perform 3D reconstruction, nor we reconstruct facial features). This mitigates the potential risk when our method is applied to humans. We believe that our work has significant opportunities for a positive impact by opening up the possi- bility that machines could ultimately understand the pose of thousands of animal classes. In addition to numerous applications in VR, AR, marketing and the like, such a technology can benefit animal- human-machine interaction (e.g. in aid of the visually impaired), can be used to better safeguard animals on the Internet (e.g. by detecting animal abuse), and, perhaps most importantly, can allow conservationists and other researchers to observe animals in the wild at an unprecedented scale, automatically analysing their motion and activities, and thus collecting information on their num- ber, state of health, and other statistics. Thus, while we acknowledge that this technology may find negative uses (as almost any technology does), we believe that the positives far outweigh them.",Broader impact,252,9,,,FALSE,FALSE,FALSE,Continuous Surface Embeddings,Applications -> Computer Vision,"Applications -> Body Pose, Face, and Gesture Analysis; Deep Learning -> Embedding Approaches",Vision,"['Natalia Neverova', ' David Novotny', ' Marc Szafraniec', ' Vasil Khalidov', ' Patrick Labatut', ' Andrea Vedaldi']","{'University of Oxford / Facebook AI Research', 'Facebook AI Research'}",1,1,1,"{'UK', 'USA'}"
Succinct and Robust Multi-Agent Communication With Temporal Message Control,"Sai Qian Zhang, Qi  Zhang, Jieyu Lin",Succinct and Robust Multi-Agent Communication With Temporal Message Control,c82b013313066e0702d58dc70db033ca,https://proceedings.neurips.cc/paper/2020/file/c82b013313066e0702d58dc70db033ca-Paper.pdf,"MARL has been widely applied to many real-world applications, such as autonomous driving [27], game playing [20] and swarm robotics [15]. Recent work [12, 13, 39] have demonstrated that allowing inter-agent communication during execution can greatly enhance the overall performance. However, in practice, the communication channel are usually bandwidth-limited and potentially lossy, which may impact the transmission of the messages and further degrade the overall MARL performance. TMC presents a solution that allows agents to operate under these practical restrictions on communication channel. This is of paramount importance for the adoption of MARL in practice. TMC also paves the way towards enabling MARL applications to work in severe environments caused by natural disasters ( e.g. , earthquake, tsunami, etc), where the public communication infrastructure is seriously devastated and only limited transmission capability is provided. However, depending on the intended purpose of the MARL system, TMC can be used either to benefit or hurt social welfare. For instance, terrorists can adopt TMC to control multiple drones for urban terrorism attack. These security concerns can be a major flaw and future research direction for the current version of TMC. We encourage the machine learning researchers to consider applying the idea of TMC to the other AI fields whose performance heavily depends on quality of the communication channel ( e.g. , federated learning). We also encourage the researchers from the other related fields ( e.g. , social science) to investigate the efficient communication pattern for Human-Computer Interaction (HCI) by leveraging the insight of TMC.",Broader Impact,251,11,,,FALSE,FALSE,FALSE,Succinct and Robust Multi-Agent Communication With Temporal Message Control,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Sai Qian Zhang', ' Qi Zhang', ' Jieyu Lin']","{'Harvard University', 'Amazon', 'University of Toronto'}",1,1,1,"{'Canada', 'USA'}"
Big Bird: Transformers for Longer Sequences,"Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed",Big Bird: Transformers for Longer Sequences,c8512d142a2d849725f31a9a7a361ab9,https://proceedings.neurips.cc/paper/2020/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf,"Inference Efficiency: Quadratic attention mechanisms cannot capture long range dependencies which exist in natural text and other datasets. Moreover, there is a growing concern in the ML community about the resource and energy requirement training large scale systems [81]. Moreover, that sparse, computationally efficient systems, like B IG B IRD , can capture long range dependencies in an energy efficient way without losing expressive power. Wide Applicability: Beyond the impact of our model on NLP tasks that require longer context, our proposed contextualized representations of DNA using attention based models, should help in better modeling effects of longer sequences of DNA. Our effort continues a long line of research that bridges the gap between computational models designed for NLP and those for computational biology.",Broader Impacts,124,5,,,FALSE,FALSE,FALSE,Big Bird: Transformers for Longer Sequences,Deep Learning -> Efficient Inference Methods,Applications -> Computational Biology and Bioinformatics; Applications -> Natural Language Processing,Natural language processing,"['Manzil Zaheer', ' Guru Guruganesh', ' Kumar Avinava Dubey', ' Joshua Ainslie', ' Chris Alberti', ' Santiago Ontanon', ' Philip Pham', ' Anirudh Ravula', ' Qifan Wang', ' Li Yang', ' Amr Ahmed']","{'Google', 'Google Research', 'Carnegie Mellon University', 'Google LLC'}",1,1,1,{'USA'}
Neural Execution Engines: Learning to Execute Subroutines,"Yujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan, Milad Hashemi",Neural Execution Engines: Learning to Execute Subroutines,c8b9abffb45bf79a630fb613dcd23449,https://proceedings.neurips.cc/paper/2020/file/c8b9abffb45bf79a630fb613dcd23449-Paper.pdf,"This work is a very incremental step in a much broader initiative towards neural networks that can perform algorithmic reasoning. Neural networks are currently very powerful tools for perceptual reasoning, and being able to combine this with algorithmic reasoning in a single unified system could form the foundation for the next generation of AI systems. True strong generalization has a number of advantages: strongly generalizing systems are inherently more reliable. They would not be subject to issues of data imbalance, adversarial examples, or domain shift. This could be especially useful in many important domains like medicine. Strong generalization can also reduce the size of datasets required to learn tasks, thereby also providing environmental savings by reducing the carbon footprint of running large-scale workloads. However, strong generalization could be more susceptible to inheriting the biases of the algorithms on which they are based. If the underlying algorithm is based on incorrect assumptions, or limited information, then strong generalization will simply reflect this, rather than correct it.",8 Broader Impact of this Work,165,8,,,FALSE,FALSE,FALSE,Neural Execution Engines: Learning to Execute Subroutines,Applications -> Program Understanding and Generation,Algorithms -> Relational Learning; Deep Learning -> Attention Models,Program synthesis and understanding,"['Yujun Yan', ' Kevin Swersky', ' Danai Koutra', ' Parthasarathy Ranganathan', ' Milad Hashemi']","{'Google', 'U Michigan', 'University of Michigan'}",1,1,1,{'USA'}
Random Reshuffling: Simple Analysis with Vast Improvements,"Konstantin Mishchenko, Ahmed Khaled Ragab Bayoumi, Peter Richtarik",Random Reshuffling: Simple Analysis with Vast Improvements,c8cc6e90ccbff44c9cee23611711cdc4,https://proceedings.neurips.cc/paper/2020/file/c8cc6e90ccbff44c9cee23611711cdc4-Paper.pdf,"Our contribution is primarily theoretical. Moreover, we study methods that are already in use in practice, but are notoriously hard to analyze. We believe we have made a breakthrough in this area by developing new and remarkably simple proof techniques, leading to sharp bounds. This, we hope, will inspire other researchers to apply and further develop our techniques to other contexts and algorithms. These applications may one day push the state of the art in practice for existing or new supervised machine learning applications, which may then have broader impacts. Besides this, we do not expect any direct or short term societal consequences.",Broader Impact,103,6,,,FALSE,FALSE,FALSE,Random Reshuffling: Simple Analysis with Vast Improvements,Optimization,Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Konstantin Mishchenko', ' Ahmed Khaled Ragab Bayoumi', ' Peter Richtarik']","{'Cairo University', 'KAUST'}",1,0,0,"{'Egypt', 'Saudi Arabia'}"
Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors,"Karl Pertsch, Oleh Rybkin, Frederik Ebert, Shenghao Zhou, Dinesh Jayaraman, Chelsea Finn, Sergey Levine",Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors,c8d3a760ebab631565f8509d84b3b3f1,https://proceedings.neurips.cc/paper/2020/file/c8d3a760ebab631565f8509d84b3b3f1-Paper.pdf,"We proposed a method for visual prediction and planning that is able to solve long-horizon tasks autonomously. This method may have a broader impact on capabilities of robots performing tasks such as autonomous navigation or object manipulation, and may be applicable in settings such as navigation of zones dangerous for humans, search and rescue, as well as warehouse robotics applications. While the method, and in general all planning and reinforcement learning methods, may be applied to a variety of settings, including those with questionable ethical motivation, we are optimistic of the general positive impact of future autonomous robotic systems, especially in the areas described above. Another ethical consideration is that, since the model is able to produce long videos targeted to a particular goal, it might be used to produce fake videos of people performing a certain action, and provides a degree of control about that action through the specification of the goal image. This might enable forging fake videos targeted at specific persons. However, recent research has shown that most current methods for generating fake videos are easily detectable, both by people and automatic detection methods [18, 1, 38].",Broader Impact,190,6,,,FALSE,FALSE,FALSE,Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors,Reinforcement Learning and Planning -> Model-Based RL,Deep Learning -> Predictive Models,Reinforcement learning and planning,"['Karl Pertsch', ' Oleh Rybkin', ' Frederik Ebert', ' Shenghao Zhou', ' Dinesh Jayaraman', ' Chelsea Finn', ' Sergey Levine']","{'UC Berkeley', 'University of Pennsylvania', 'University of Southern California', 'Stanford'}",1,0,0,{'USA'}
Statistical Optimal Transport posed as Learning Kernel Embedding,"Saketha Nath Jagarlapudi, Pratik Kumar Jawanpuria",Statistical Optimal Transport posed as Learning Kernel Mean Embedding,c8ecfaea0b7e3aa83b017a786d53b9e8,https://proceedings.neurips.cc/paper/2020/file/c8ecfaea0b7e3aa83b017a786d53b9e8-Paper.pdf,"Our work complements the ongoing research explorations towards a better understanding of sample complexity in regularized optimal transport problems. Our contributions are mainly theoretical with some empirical results on standard optimal transport applications. Overall, this work does not present any foreseeable societal consequence.",Broader Impact Statement,43,3,TRUE,FALSE,FALSE,FALSE,FALSE,Statistical Optimal Transport posed as Learning Kernel Embedding,Algorithms -> Kernel Methods,,Optimal transport and Kernels,"['Saketha Nath Jagarlapudi', ' Pratik Kumar Jawanpuria']","{'IIT Hyderabad', 'Microsoft'}",1,1,1,"{'India', 'USA'}"
Dual-Resolution Correspondence Networks,"Xinghui Li, Kai Han, Shuda Li, Victor Prisacariu",Dual-Resolution Correspondence Networks,c91591a8d461c2869b9f535ded3e213e,https://proceedings.neurips.cc/paper/2020/file/c91591a8d461c2869b9f535ded3e213e-Paper.pdf,"The proposed model enjoys great potential to improve a wide range of industrial applications including image alignment, image retrieval, 3D reconstruction, camera pose estimation, etc. Particularly, the proposed method sets a new record of accuracy on both indoor and outdoor relocalization benchmarks which strongly indicates that it will directly benefit many fields in the near future including robotics, autonomous driving and gaming industry, where the vision-based relocalisation is the foundation. It is particularly important if the application has to work in a GPS-denied environment. Furthermore, with the potential of being able to deploy on mobile platforms such as robots, drones, smartphones, head- mounted displays, the proposed method could be used to boost mixed/virtual reality for entertainment or education. It may be applied to build large-scale long-term indoor/outdoor maps which allows pinpointing a user’s location without GPS using images. This may also improve existing navigation capability of robots or drones and enable a more intelligent agent for various tasks such as delivery, searching and rescue. In the meanwhile, the proposed model, like many other machine learning technology, does have some unwelcomed repercussions. The accurate and robust vision-only correspondence estimation and the subsequent localisation can be used to illegally locate a person or property without permission using an image circulated online. It may even be weaponized to guide a UAV to carry out a terrorism attack. However, these negative impacts are more related to the fields of application rather than the technology itself. Generally, proper legislation may be required to prevent any machine learning method from being used for evil purposes. Fortunately, many countries have already started to debate and evaluate the pros and cons of specific AI technologies. For example, some countries have banned using facial recognition or restricted employing AI for surveillance. Therefore, we believe, under strict supervision, that our work will bring more benefits than harms to society.",Broader Impact,309,14,,,FALSE,FALSE,FALSE,Dual-Resolution Correspondence Networks,Applications -> Computer Vision,Algorithms -> Representation Learning; Applications -> Robotics,Vision,"['Xinghui Li', ' Kai Han', ' Shuda Li', ' Victor Prisacariu']",{'University of Oxford'},1,0,0,{'UK'}
"Advances in Black-Box VI: Normalizing Flows, Importance Weighting, and Optimization","Abhinav Agrawal, Daniel R. Sheldon, Justin Domke","Advances in Black-Box VI: Normalizing Flows, Importance Weighting, and Optimization",c91e3483cf4f90057d02aa492d2b25b1,https://proceedings.neurips.cc/paper/2020/file/c91e3483cf4f90057d02aa492d2b25b1-Paper.pdf,"Mechanistic modeling of natural phenomenons is a fundamental quest for modern scientists, and probabilistic models are a potent tool in such expeditions. However, automatically inferring hidden variables in these models is a challenge to date. Our approach and observations can prove instrumental for researchers in various fields–epidemiologists, ecologists, political scientists, social scientists, experimental psychologists, and others. While some other inference methods may perform better for a particular model, our ideas provide a formidable baseline. Our framework combines several ideas–for a practitioner, this can make diagnosing the source of sub-optimality tricky. While it is possible to conduct comprehensive searches for hyper-parameters, the ability to do so hinges on access to adequate computation resources.",Broader Impact,112,6,,,FALSE,FALSE,FALSE,"Advances in Black-Box VI: Normalizing Flows, Importance Weighting, and Optimization",Probabilistic Methods -> Variational Inference,Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Probabilistic Programming,Probabilistic methods and inference,"['Abhinav Agrawal', ' Daniel Sheldon', ' Justin Domke']","{'University of Massachusetts, Amherst', 'University of Massachusetts Amherst', 'UMass Amherst'}",1,0,0,{'USA'}
f-Divergence Variational Inference,"Neng Wan, Dapeng Li, NAIRA HOVAKIMYAN",f -Divergence Variational Inference,c928d86ff00aeb89a39bd4a80e652a38,https://proceedings.neurips.cc/paper/2020/file/c928d86ff00aeb89a39bd4a80e652a38-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,f-Divergence Variational Inference,Probabilistic Methods -> Variational Inference,Algorithms -> Stochastic Methods; Optimization -> Stochastic Optimization; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> MCMC; Theory -> Computational Learning Theory; Theory -> Information Theory,Probabilistic methods and inference,"['Neng Wan', ' Dapeng Li', ' NAIRA HOVAKIMYAN']","{'Anker Innovations', 'University of Illinois at Urbana Champaign', 'UIUC'}",1,1,1,{'USA'}
Unfolding recurrence by Green’s functions for optimized reservoir computing,"Sandra Nestler, Christian Keup, David Dahmen, Matthieu Gilson, Holger Rauhut, Moritz Helias",Unfolding recurrence by Green’s functions for optimized reservoir computing,c94a589bdd47870b1d74b258d1ce3b33,https://proceedings.neurips.cc/paper/2020/file/c94a589bdd47870b1d74b258d1ce3b33-Paper.pdf,"The main motivation of this work is to provide conceptual insight. Analytically unrolling recurrent dynamics into a (functional) Taylor series, where coefficients are given by Green’s functions, is a versatile approach that may be used as a general purpose scheme to analyze recurrent networks and to optimize reservoir computing. This expansion reveals how the non-linear interactions and recurrence pick up higher order correlations in the input statistics, quantifying how non-linear networks provide a richer feature space than linear ones. We consider the presented application as a proof-of-principle for optimized processing of complex time series data. The presented application to health-related data (heartbeat classification) hints at possible societal consequences by providing better diagnostic tools.",Broader impact,113,5,,,FALSE,FALSE,FALSE,Unfolding recurrence by Green’s functions for optimized reservoir computing,Applications -> Time Series Analysis,Algorithms -> Classification; Algorithms -> Kernel Methods; Theory -> Statistical Physics of Learning,Theory (including computational and statistical analyses),,"{'Juelich Research Centre', 'RWTH Aachen University', 'Jülich Research Centre', 'Juelich Forschungszentrum'}",1,0,0,{'Germany'}
The Dilemma of TriHard Loss and an Element-Weighted TriHard Loss for Person Re-Identification,"Yihao Lv, Youzhi Gu, Liu Xinggao",The Dilemma of TriHard Loss and an Element-Weighted TriHard Loss for Person Re-Identification,c96c08f8bb7960e11a1239352a479053,https://proceedings.neurips.cc/paper/2020/file/c96c08f8bb7960e11a1239352a479053-Paper.pdf,"The shortcoming of TriHard loss [31] is proved theoretically and a series of element-weighted TriHard losses is proposed and tested in this paper. It is strongly explainable and easy to implement, which can be used in the existing methods of person re-identification (ReID). The most obvious positive outcome is that improving the accuracy of results makes the automatic person identification technology more practicable in security, autonomous driving and other fields. That will improve efficiency and effectiveness of work or save human costs in these areas. And the ideas proposed in this paper may inspire more valuable and innovative researches in the future. The negative outcomes result from the increasing accuracy of person identification and more used surveillance cameras. That may raise the risk of privacy breaches and other security issues, which may put everyone under monitoring. In the meanwhile, The public datasets for person ReID are usually non-consensual surveillance data, which are supposed to be an invasion of privacy. Therefore, the collection process should be public and informed to everyone who is contained in the collection. And the utilization of these datasets should be is subject to scrutiny and regulation.",Broader Impact,190,10,,,FALSE,TRUE,FALSE,The Dilemma of TriHard Loss and an Element-Weighted TriHard Loss for Person Re-Identification,Applications -> Computer Vision,Algorithms -> Metric Learning; Algorithms -> Similarity and Distance Learning; Deep Learning -> Supervised Deep Networks,Deep learning,"['Yihao Lv', ' Youzhi Gu', ' Liu Xinggao']",{'Zhejiang University'},1,0,0,{'China'}
Disentangling by Subspace Diffusion,"David Pfau, Irina Higgins, Alex Botev, Sébastien Racanière",Disentangling by Subspace Diffusion,c9f029a6a1b20a8408f372351b321dd8,https://proceedings.neurips.cc/paper/2020/file/c9f029a6a1b20a8408f372351b321dd8-Paper.pdf,"The present work is primarily theoretical, making its broader impact difficult to ascertain. We consider the algorithm presented here to be a potential core machine learning method, and as such it could have an impact in any area that machine learning can be applied to, but particularly in unsupervised learning, computer vision and robotic manipulation.",Broader Impact,55,2,FALSE,TRUE,FALSE,FALSE,FALSE,Disentangling by Subspace Diffusion,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning,Algorithms -> Metric Learning; Algorithms -> Spectral Methods; Algorithms -> Unsupervised Learning,,"['David Pfau', ' Irina Higgins', ' Alex Botev', ' Sébastien Racanière']","{'Google DeepMind', 'DeepMind'}",0,1,0,{'UK'}
Towards Neural Programming Interfaces,"Zachary Brown, Nathaniel Robinson, David Wingate, Nancy Fulda",Towards Neural Programming Interfaces,c9f06bc7b46d0247a91c8fc665c13d0e,https://proceedings.neurips.cc/paper/2020/file/c9f06bc7b46d0247a91c8fc665c13d0e-Paper.pdf,"The ultimate aim of this research is to provide individuals and organizations who use neural networks - natural language models or otherwise - with tools that enable them to test, debug, and regulate the outputs of their machine learning models. As the NPIs in this paper learned to interpret and control the previously uninterpretable GPT-2 language model, we hope this approach can be used to debug and interpret the inner workings of other neural networks in addition to controlling their output. As such, the primary beneficiaries of this work are individuals or organizations that wish to incorporate neural network modeling capabilities with domain knowledge and/or high-level commands which require a high degree of granular control. In addition to the general benefits of increased interpretability, our particular approach enables those with access to a pretrained neural network to re-purpose it for highly specific tasks without the need for specialized training data in the pretrained network‘s original training domain; so long as the model is capable of generating the desired output on occasion, the NPI approach can be used to amplify this aspect of the pretrained model. Therefore, individuals and organizations working in data-restricted domains such as healthcare and news broadcasting, groups with limited funding for data curation, or individuals and groups who might be under-represented in large public data sets (such as minority groups or public figures without extensive media coverage) also stand to benefit from this work. Going even further, we envision systems capable of leveraging a series of neural classifiers to detect bias such as political slant or other ideologies in language model output as it is produced in real-time. When the classifiers detect that the output is heavily biased towards one ideology, corresponding NPIs are activated in order to encourage output that leans in the opposite direction, thus facilitating more balanced text generation and greater representation of the full range of human dialogue and thought. A third purpose of this paper is to prevent the abuse of controllable neural network technologies by making our approach widely known and open to public discussion. In particular, the spread of misinformation and offensive speech through automated conversational agents is a modern regulatory challenge, and we are concerned that controllable natural language generation has the capability to worsen this modern problem. As such, we desire to aid the public discourse regarding these technologies by informing individuals at all levels of society about the current state-of-the-art capabilities of these systems. Our team has therefore chosen to make our project’s Github repository publicly available at the time of publication along with the weights of some of our classification, NPI, and fine-tuned GPT-2 models. However, in the interest of preventing malicious actors from easily converting our NPI models into tools for promoting offensive speech or political disinformation campaigns, we have also chosen to make the weights of some of our data sets and models - those trained on offensive speech, with political target behaviors, or of a similarly controversial nature only available upon request, on a case-by-case basis, for academics and researchers also interested in ethical machine learning. We are the first to acknowledge that the Neural Programming Interfaces (NPIs) presented in this research are not fail-safe regulatory tools, and should never be used as a final quality check for natural language generation (or any other) tasks. The failure-modes of NPIs include total degradation of neural network output quality (in the case that the NPI model over-aggressively alters the output of the original model) and insufficient change to the output of a pretrained neural network (in the case that target content is not sufficiently adhered to in the NPI output). To mitigate these failure modes, we suggest that the NPIs presented here be used as back-end procedures for pretrained neural network fault analysis, data bias analysis, and cached language generation (which would subsequently be filtered through a battery of quality checks). As more sophisticated Neural Programming Interfaces (NPIs) are developed, it may become possible for some of these recommendations to be eased. In the course of training classifier neural networks for the adversarial training of NPI networks, we observed that the content classifier networks were susceptible to leveraging bias in heavily imbalanced data sets. Because content classifier networks form a portion of the NPI loss signal, it is likely that any bias baked into the classifier weights will contribute to bias in the NPI network itself. We therefore recommend that researchers and developers ensure training data sets are sufficiently balanced to mitigate bias in the methods described above.",Broader Impact,753,19,,,FALSE,TRUE,FALSE,Towards Neural Programming Interfaces,Applications -> Natural Language Processing,Algorithms -> Adversarial Learning; Deep Learning -> Adversarial Networks; Deep Learning -> Generative Models,Natural language processing,,"{'Brigham Young University', 'Duke University'}",1,0,0,{'USA'}
Discovering Symbolic Models from Deep Learning with Inductive Biases,"Miles Cranmer, Alvaro Sanchez Gonzalez, Peter Battaglia, Rui Xu, Kyle Cranmer, David Spergel, Shirley Ho",Discovering Symbolic Models from Deep Learning with Inductive Biases,c9f2f917078bd2db12f23c3b413d9cba,https://proceedings.neurips.cc/paper/2020/file/c9f2f917078bd2db12f23c3b413d9cba-Paper.pdf,"The approach we present has enormous potential for scientific research. Machine learning is traditionally focuses on prediction and pattern recognition, and science on understanding. The method we describe in this paper allows one to do both: understand, in an explicit algebraic language, how to model a dynamical system or how properties in a graph-like dataset relate to each other, using a deep neural network. Furthermore, our finding that a symbolic model extracted from components of a neural network will generalize better than the same neural network it was extracted from, is profound. We believe this interesting phenomenon is worth detailed followup studies to understand how this can be exploited more generally in machine learning. In more specific terms: • Scientists can now study graph-like datasets and potentially derive explicit symbolic expressions for interactions among the nodes. This could have a huge impact on learning new scientific models from data. • Scientists can take deep learning models that can be easily trained and designed flexibly and use them to observe a system. Once the model is trained, scientists can easily take out a part of the model that they find important (such as the messages in the graph network) and use symbolic regression on that particular component to discover symbolic expressions governing properties of a physical system. • More broadly, the technique we describe and then use graph networks to illustrate, can be applied to any trained networks, so long as the network has subcomponents that have an interpretable and modular form. It is not often obvious what components of a network would contain more important or interesting “laws” to extract, however, once that is identified, the approach presented in this paper can be used to extract an interpretable symbolic model.",6 Broader impact,290,11,,,TRUE,TRUE,FALSE,Discovering Symbolic Models from Deep Learning with Inductive Biases,Deep Learning -> Interaction-Based Deep Networks,Algorithms -> Relational Learning; Algorithms -> Representation Learning; Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Miles Cranmer', ' Alvaro Sanchez Gonzalez', ' Peter Battaglia', ' Rui Xu', ' Kyle Cranmer', ' David Spergel', ' Shirley Ho']","{'Princeton University', 'DeepMind', 'Flatiron Institute', 'New York University', 'Flatiron institute'}",1,1,1,"{'UK', 'USA'}"
Real World Games Look Like Spinning Tops,"Wojciech M. Czarnecki, Gauthier Gidel, Brendan Tracey, Karl Tuyls, Shayegan Omidshafiei, David Balduzzi, Max Jaderberg",Real World Games Look Like Spinning Tops,ca172e964907a97d5ebd876bfdd4adbd,https://proceedings.neurips.cc/paper/2020/file/ca172e964907a97d5ebd876bfdd4adbd-Paper.pdf,"This work focuses on better understanding of mathematical properties of real world games and how they could be used to understand successful AI techniques that were developed in the past. Since we focus on retrospective analysis of a mathematical phenomenon, on exposing an existing structure, and deepening our understanding of the world, we do not see any direct risks it entails. Introduced notions and insights could be used to build better, more engaging AI agents for people to play with in real world games (e.g. AIs that grow with the player, matching their strengths and weaknesses). In a broader spectrum, some of the insights could be used for designing and implementing new games, that humans would fine enjoyable though challenges they pose. In particular it could be a viewed as a model for measuring how much notion of progress the game consists of. However, we acknowledge that methods enabling improved analysis of games may be used for designing products with potentially negative consequences (e.g., games that are highly addictive) rather than positive (e.g., games that are enjoyable and mentally developing).",Broader Impact,180,6,,,FALSE,FALSE,FALSE,Real World Games Look Like Spinning Tops,Reinforcement Learning and Planning -> Multi-Agent RL,Applications -> Game Playing; Reinforcement Learning and Planning; Reinforcement Learning and Planning -> Reinforcement Learning; Theory; Theory -> Game Theory and Computational Economics,Game theory and Machine learning,"['Wojciech Czarnecki', ' Gauthier Gidel', ' Brendan Tracey', ' Karl Tuyls', ' Shayegan Omidshafiei', ' David Balduzzi', ' Max Jaderberg']","{'DeepMind', 'Mila'}",1,1,1,"{'Canada', 'UK'}"
Cooperative Heterogeneous Deep Reinforcement Learning,"Han Zheng, Pengfei Wei, Jing Jiang, Guodong Long, Qinghua Lu, Chengqi Zhang",Cooperative Heterogeneous Deep Reinforcement Learning,ca3a9be77f7e88708afb20c8cdf44b60,https://proceedings.neurips.cc/paper/2020/file/ca3a9be77f7e88708afb20c8cdf44b60-Paper.pdf,"The DRL agent that learns from an incompletely known environment runs the risk of making wrong decisions. This could lead to catastrophic consequences in practice, such as automated driving, the stock market, or medical robots. One approach to alleviate this risk is to combine with other techniques or involve human beings’ supervision. In terms of benefits, DRL can be deployed in a safe environment where a wrong decision will not lead to a significant loss, e.g., the recommendation system. Moreover, in some environments that we can simulate well, it would be very promising to develop an intelligent robot to work in such an environment.",Broader Impact,104,5,,,FALSE,FALSE,FALSE,Cooperative Heterogeneous Deep Reinforcement Learning,Reinforcement Learning and Planning,Optimization -> Evolutionary Computation ; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Han Zheng', ' Pengfei Wei', ' Jing Jiang', ' Guodong Long', 'University of Technology Sydney', ' Qinghua Lu', ' Chengqi Zhang']","{'Data61, CSIRO', 'University of Technology Sydney', 'UTS', 'National University of Singapore'}",1,1,1,"{'Singapore', 'Australia'}"
Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization,"Hung-Jen Chen, An-Chieh Cheng, Da-Cheng Juan, Wei Wei, Min Sun",Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization,ca4b5656b7e193e6bb9064c672ac8dce,https://proceedings.neurips.cc/paper/2020/file/ca4b5656b7e193e6bb9064c672ac8dce-Paper.pdf,"Our work belongs to the category of continual learning, specifically online continual learning, which is crucial for deep learning model to maintain the knowledge it has learned. It may help deep learning models to keep learning new tasks and integrate the knowledge, eventually become a lifelong learning system. We believe that in the future, AI devices will be a crucial part of society. Our model will be effective when the embedding device required private data to learn and are not able to store the whole data locally.",Broader Impact,87,4,,,FALSE,FALSE,FALSE,Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization,Algorithms -> Continual Learning,Algorithms -> AutoML; Algorithms -> Classification; Algorithms -> Online Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jen Chen', 'Chieh Cheng', 'Cheng Juan', ' Wei Wei', ' Min Sun']","{'Google', 'National Tsing Hua University', 'CMU'}",1,1,1,"{'USA', 'China', 'Taiwan'}"
ImpatientCapsAndRuns: Approximately Optimal Algorithm Configuration from an Infinite Pool,"Gellert Weisz, András György, Wei-I Lin, Devon Graham, Kevin Leyton-Brown, Csaba Szepesvari, Brendan Lucier",ImpatientCapsAndRuns: Approximately Optimal Algorithm Configuration from an Infinite Pool,ca5520b5672ea120b23bde75c46e76c6,https://proceedings.neurips.cc/paper/2020/file/ca5520b5672ea120b23bde75c46e76c6-Paper.pdf,"We expect that our theorems will guide the design of future algorithm configuration procedures. We note that speeding up computationally expensive algorithms saves time, money, and electricity, arguably reducing carbon emissions and yielding social benefit. The algorithms we study can be be applied to a limitless range of problems and so could yield both positive and negative impacts; however, we do not foresee our work particularly amplifying such impacts beyond the computational speedups already discussed.",Broader Impact,75,3,,,FALSE,FALSE,FALSE,ImpatientCapsAndRuns: Approximately Optimal Algorithm Configuration from an Infinite Pool,Theory -> Statistical Learning Theory,Algorithms -> Bandit Algorithms,AutoML,"['Gellert Weisz', ' András György', 'I Lin', ' Devon Graham', 'Brown', ' Csaba Szepesvari', ' Brendan Lucier']","{'Deepmind', 'Microsoft Research', 'UBC', 'DeepMind', 'University of British Columbia', 'DeepMind / University of Alberta'}",1,1,1,"{'Canada', 'UK', 'Singapore', 'USA'}"
Dense Correspondences between Human Bodies via Learning Transformation Synchronization on Graphs,"Xiangru Huang, Haitao Yang, Etienne Vouga, Qixing Huang",Dense Correspondences between Human Bodies via Learning Transformation Synchronization on Graphs,ca7be8306ecc3f5fa30ff2c41e64fa7b,https://proceedings.neurips.cc/paper/2020/file/ca7be8306ecc3f5fa30ff2c41e64fa7b-Paper.pdf,"Computing dense correspondences between a partial scan and a template, or between two partial scans, is a fundamental task for analyzing and understanding 3D data captured from the real world. Our work is foundational, improving the accuracy and robustness of this important task, and will benefit downstream applications that rely on the ability to find accurate dense correspondences. One such application area is human subject tracking, where the correspondences between the partial scan the the complete template model can be used to deform the template to obtain complete deformed shape that corresponds to each partial scan. Our research will allow reconstruction of higher-fidelity animation sequences that better captures nuanced motion from large-scale, real-world data. Applications that will benefit from this improved tracking include imitation learning, where a system can learn from motion of each observed subject, especially of fine motor skills not able to be tracked before; movie/game industry, where one can insert the reconstructed motion of an actor into virtual environment, with unprecedented expressiveness of the reconstructed actor; and sports, where one can reconstruct and analyze the athletes’ motions to make recommendations both for improving athletic performance as well as enhancing athlete safety. Another application area is full body reconstruction from a few scans. In this setting, the template mesh serves as an intermediate object to establish dense correspondences between partial scans. Our research represents an important steps towards allowing ordinary users to scan themselves with high accuracy at home using commodity hardware. Access to a high-quality digital avatar facilitates many applications such as virtual fitting for on-line shopping, improved telepresence and telemedicine, and new forms of entertainment and social media where users can place and animate themselves in a 3D environment. Potential abuses and negative impacts of improved tracking and reconstruction include the ability to identify people without their consent, based on body shape or motion characteristics, in settings where traditional facial recognition algorithms fail. 3D avatars of a person reconstructed from surreptitious partial scans might also be used to create “deep fakes” or to otherwise infringe on the privacy rights of the subject. From a technical perspective, the problem falls into the category of structure prediction that combines point-wise predictions and priors on correlations among multiple points. Unlike the standard MRF formulation, this paper explores a new data representation, which turns structure prediction into a continuous optimization problem. This methodology can inspire future research on relevant problems, where the problem space lies in a continuous domain. Moreover, there is growing interest in turning optimization problems into neural networks with hyper-parameters trained end-to-end. Our approach contributes to this effort, and we hope the insights we used to design the resulting neural network for training (including our analysis of robust recovery conditions for the transformation synchronization problem) can be applied to and stimulate future research on similar problems. Finally, like any algorithm for computing dense correspondences, our approach is not guaranteed to generate correct correspondences in all the settings. Additional checks and verification (by humans using interactive tools, for instance) should be used to validate and rectify the outputs, especially if the results are used in safety- or health-critical applications such as personalized medicine.",6 Statement of Broader Impacts,525,18,,,FALSE,FALSE,FALSE,Dense Correspondences between Human Bodies via Learning Transformation Synchronization on Graphs,Applications -> Computer Vision,Deep Learning -> Optimization for Deep Networks; Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization,Vision,"['Xiangru Huang', ' Haitao Yang', ' Etienne Vouga', ' Qixing Huang']","{'The University of Texas at Austin', 'University of Texas at Austin'}",1,0,0,{'USA'}
Reasoning about Uncertainties in Discrete-Time Dynamical Systems using Polynomial Forms.,"Sriram Sankaranarayanan, Yi Chou, Eric Goubault, Sylvie Putot",Reasoning about Uncertainties in Discrete-Time Dynamical Systems using Polynomial Forms.,ca886eb9edb61a42256192745c72cd79,https://proceedings.neurips.cc/paper/2020/file/ca886eb9edb61a42256192745c72cd79-Paper.pdf,"We, as a society, rely on mathematical models and their predictions a lot more than we realize. The current COVID-19 pandemic, the kerfuffle during winter 2019 over the predicted course of hurricane Dorian, or one of the many causes of the 2008 great depression involving trading in derivatives based on faulty modeling assumptions, all bear witness to this fact. Beyond this, many safety critical applications to autonomous control systems such as closed loop medical devices rely on selecting optimal control strategies based on predictions provided by dynamical system models. The present work uses tail inequalities to mechanize the derivation of mathematically rigorous bounds on predictions over future states of stochastic dynamical models. This has beneficial impacts in that, where it is applicable, such analysis can help us carefully analyze models and quantify uncertainty in the model predictions. For instance, our work may be used to predict that an aircraft flown using the control strategy in Ex. 1 will remain free from collision with building 30 meters away from its predicted trajectory with at least 99% confidence. At the same time, it is important to realize that in many instances, assumptions that are made such as “this disturbance behaves like a Gaussian random variable” are, at best, approximations. These approximations often become less valid when higher order moments or the tail behavior of these random variables are examined. We note that this paper uses approaches that rely intimately on knowing the higher order moments and reasoning about tail behaviors of polynomial functions of random variables. Negative impacts could include a false sense of confidence or trust in the reliability of a prediction in the case of forecast models or in a control strategy, derived from modeling assumptions that may be unsound. This negative impact is best mitigated in multiple ways which we hope to address in our future work: (a) provide a sensitivity analysis on how the conclusions change if the distributions are perturbed; or (b) work with partially specified families of distributions with uncertain expectations, variances and higher moments. We note that our approaches in this paper are highly suited for the latter approach.",7 Broader Impact,354,13,,,FALSE,FALSE,FALSE,Reasoning about Uncertainties in Discrete-Time Dynamical Systems using Polynomial Forms.,Probabilistic Methods,Applications -> Robotics; Probabilistic Methods -> Probabilistic Programming; Theory; Theory -> Control Theory; Theory -> Large Deviations and Asymptotic Analysis,Probabilistic methods and inference,"['Sriram Sankaranarayanan', ' Yi Chou', ' Eric Goubault', ' Sylvie Putot']","{'Ecole Polytechnique', 'University of Colorado, Boulder', 'University of Colorado Boulder'}",1,0,0,"{'France', 'USA', 'Switzerland'}"
Applications of Common Entropy for Causal Inference,"Murat Kocaoglu, Sanjay Shakkottai, Alexandros G. Dimakis, Constantine Caramanis, Sriram Vishwanath",Applications of Common Entropy for Causal Inference,cae7115f44837c806c9b23ed00a1a28a,https://proceedings.neurips.cc/paper/2020/file/cae7115f44837c806c9b23ed00a1a28a-Paper.pdf,"This work lays the foundations for using the information-theoretic notion of common entropy within the context of discovering causal relations from data. Problems that require discovering causal relations from observational data are prominent across many different fields. Causality is also central to the development of AI. Therefore, we expect this work to have a positive impact by providing a new methodology and identifying settings in which causality can be inferred using this framework. In terms of the negative effects, we do not foresee an immediate negative effect that may arise because of this work. The only risks would be due to the risks associated with having stronger machine learning models, and better AI that could be misused or exploited.",Broader Impact,119,6,,,FALSE,FALSE,FALSE,Applications of Common Entropy for Causal Inference,Probabilistic Methods -> Causal Inference,Theory -> Information Theory,Causality,"['Murat Kocaoglu', ' Sanjay Shakkottai', ' Alexandros Dimakis', ' Constantine Caramanis', ' Sriram Vishwanath']","{'University of Texas at Austin', 'University of Texas, Austin', 'IBM Research', 'UT Austin'}",1,1,1,{'USA'}
SGD with shuffling: optimal rates without component convexity and large epoch requirements,"Kwangjun Ahn, Chulhee Yun, Suvrit Sra",SGD with shuffling: optimal rates without component convexity and large epoch requirements,cb8acb1dc9821bf74e6ca9068032d623,https://proceedings.neurips.cc/paper/2020/file/cb8acb1dc9821bf74e6ca9068032d623-Paper.pdf,"This work is about developing theoretical guarantees for widely used stochastic optimization methods. Therefore, the discussion on its ethical aspects or future societal consequences is not particularly relevant. However, this work definitely brings new insights into the practical methods, which could possibly impact other ML researches.",Broader Impact,46,3,TRUE,TRUE,FALSE,FALSE,FALSE,SGD with shuffling: optimal rates without component convexity and large epoch requirements,Optimization -> Stochastic Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Kwangjun Ahn', ' Chulhee Yun', ' Suvrit Sra']",{'MIT'},1,0,0,{'USA'}
Unsupervised Joint k-node Graph Representations with Compositional Energy-Based Models,"Leonardo Cotta, Carlos H. C. Teixeira, Ananthram Swami, Bruno Ribeiro",Unsupervised Joint k -node Graph Representations with Compositional Energy-Based Models,cba0a4ee5ccd02fda0fe3f9a3e7b89fe,https://proceedings.neurips.cc/paper/2020/file/cba0a4ee5ccd02fda0fe3f9a3e7b89fe-Paper.pdf,"This work presents an unsupervised model together with a stochastic optimization procedure to generate k -node representations from graphs, such as online social networks, product networks, citation networks, coauthorship networks, etc. As is the case with any learning algorithm, it is susceptible to produce biased representations if trained with biased data. Moreover, although the representations might be bias free, the downstream task defined by the user might be biased and thus, also produce biased decisions.",Broader Impact,75,3,,,FALSE,FALSE,FALSE,Unsupervised Joint k-node Graph Representations with Compositional Energy-Based Models,Algorithms -> Relational Learning,Algorithms -> Representation Learning; Deep Learning -> Embedding Approaches,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Leonardo Cotta', ' Teixeira', ' Ananthram Swami', ' Bruno Ribeiro']","{'Army Research Laboratory, Adelphi', 'Universidade Federal de Minas Gerais', 'Purdue', 'Purdue University'}",1,1,1,"{'USA', 'Brazil'}"
Neural Manifold Ordinary Differential Equations,"Aaron Lou, Derek Lim, Isay Katsman, Leo Huang, Qingxuan Jiang, Ser Nam Lim, Christopher M. De Sa",Neural Manifold Ordinary Differential Equations,cbf8710b43df3f2c1553e649403426df,https://proceedings.neurips.cc/paper/2020/file/cbf8710b43df3f2c1553e649403426df-Paper.pdf,"As mentioned in the introduction, our method has applications to physics, robotics, and biology. While there are ethical and social concerns with parts of these fields, our work is too theoretical for us to say for sure what the final impact will be. For deep generative models, there are overarching concerns with generating fake data for malicious use (e.g. deepfake impersonations). However, our work is more concerned with accurately modelling data topology rather than generating hyper-realistic vision or audio samples, so we do not expect there to be any negative consequence in this area.",9 Broader Impact,94,4,,,FALSE,FALSE,FALSE,Neural Manifold Ordinary Differential Equations,Deep Learning -> Generative Models,Algorithms -> Representation Learning,Probabilistic methods and inference,"['Aaron Lou', ' Derek Lim', ' Isay Katsman', ' Leo Huang', ' Qingxuan Jiang', ' Ser Nam Lim', ' Christopher De Sa']","{'Cornell', 'Facebook AI', 'Cornell University'}",1,1,1,{'USA'}
CO-Optimal Transport,"Vayer Titouan, Ievgen Redko, Rémi Flamary, Nicolas Courty",CO-Optimal Transport,cc384c68ad503482fb24e6d1e3b512ae,https://proceedings.neurips.cc/paper/2020/file/cc384c68ad503482fb24e6d1e3b512ae-Paper.pdf,"Despite its evident usefulness the problem of finding the correspondences between two datasets is rather general and may arise in many fields in machine learning. Consequently it is quite difficult to exhaustively state all the potential negative ethical impacts that may occur when using our method. As described in the paper, it could be used to solve the so-called election isomorphism problem [ 27] where one wants to find how similar are two elections based on the knowledge of votes and candidates. Although having these type of datasets seems unrealistic in modern democracies, using our approach 3 https://grouplens.org/datasets/movielens/100k/ on this problem runs the risk of breaking some privacy standards by revealing precisely how the votes have been moved from one election to the other. Generally speaking, and when given access to two datasets with sensitive data, our method is able to infer correspondences between instances and features which could possibly lead to privacy issues for a malicious user. From a different perspective, the Optimal Transport framework is known to be quite computationally expensive and even recent improvements turns out to be super-linear in terms of the computational complexity. It is not an energy-free tool and in a time when carbon footprints must be drastically reduced, one should have in mind the potential negative impact that computationally demanding algorithms might have on the planet.",Broader impact,223,7,,,TRUE,TRUE,FALSE,CO-Optimal Transport,Algorithms,Algorithms -> Clustering; Algorithms -> Multitask and Transfer Learning; Algorithms -> Unsupervised Learning,,"['Vayer Titouan', ' Ievgen Redko', ' Rémi Flamary', ' Nicolas Courty']","{'IRISA', 'IRISA, Universite Bretagne-Sud', 'Hubert Curien laboratory'}",1,0,0,{'France'}
Continuous Meta-Learning without Tasks,"James Harrison, Apoorva Sharma, Chelsea Finn, Marco Pavone",Continuous Meta-Learning without Tasks,cc3f5463bc4d26bc38eadc8bcffbc654,https://proceedings.neurips.cc/paper/2020/file/cc3f5463bc4d26bc38eadc8bcffbc654-Paper.pdf,"Our work provides a method to extend meta-learning algorithms beyond the task-segmented case, to the time series series domain. Equivalently, our work extends core methods in changepoint detection, enabling the use of highly expressive predictive models via empirical Bayes. This work has the potential to extend the domain of applicability of both of these methods. Standard meta-learning relies on a collection of datasets, each corresponding to discrete tasks. A natural question is how such datasets are constructed; in many cases, these datasets rely on segmentation of time series data by experts. Thus, our work has the potential to make meta-learning algorithms applicable to problems that, previously, would have been too expensive or impossible to segment. Moreover, our work has the potential to improve the applicability of changepoint detection methods to difficult time series forecasting problems. While MOCA has the potential to expand the domain of problems addressable via meta-learning, this has the effect of amplifying the risks associated with these methods. Meta-learning enables efficient learning for individual members of a population via leveraging empirical priors. There are clear risks in few-shot learning generally: for example, efficient facial recognition from a handful of images has clear negative implications for privacy. Moreover, while there is promising initial work on fairness for meta-learning [39], we believe considerable future research is required to understand the degree to which meta-learning algorithms increase undesirable bias or decrease fairness. While it is plausible that fine-tuning to the individual results in reduced bias, there are potential unforeseen risks associated with the adaptation process, and future research should address how bias is potentially introduced in this process. Relative to decision making rules that are fixed across a population, algorithms which fine-tune decision making to the individual present unique challenges in analyzing fairness. Further research is required to ensure that the adaptive learning enabled by algorithms such as MOCA do not lead to unfair outcomes.",Broader Impact,315,14,,,FALSE,FALSE,FALSE,Continuous Meta-Learning without Tasks,Algorithms -> Meta-Learning,Algorithms -> Continual Learning; Algorithms -> Few-Shot Learning; Applications -> Time Series Analysis,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['James Harrison', ' Apoorva Sharma', ' Chelsea Finn', ' Marco Pavone']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
A mathematical theory of cooperative communication,"Pei Wang, Junqi Wang, Pushpi Paranamana, Patrick Shafto",A mathematical theory of cooperative communication,cc58f7abf0b0cf2d5ac95ab60e4f14e9,https://proceedings.neurips.cc/paper/2020/file/cc58f7abf0b0cf2d5ac95ab60e4f14e9-Paper.pdf,"The theoretical approach introduced in this paper unifies models that have been proposed in the literatures on human language, education, and human-robot interaction—domains with significant societal implications. Our analysis highlights conditions under which they may be robust to violations of assumptions, and through mathematical analysis of previously algorithmic proposals, provides a means by which we may understand and improve the robustness of these models. This provides a mathematical framework within which we may understand their safe and responsible use in applications. More generally, the field of machine learning has not traditionally considered possibility that humans are a collaborative partner both in generating the datasets of interest and in using model’s predictions. The theory advanced herein is explicitly models this collaboration toward the goal of more effective human-machine teaming. Thus, while the contributions of the current work are primarily theoretical, there are potential positive implications in areas of society interest.",Broader Impact,149,6,,,FALSE,FALSE,FALSE,A mathematical theory of cooperative communication,Probabilistic Methods -> Bayesian Theory,Neuroscience and Cognitive Science -> Cognitive Science,Probabilistic methods and inference,"['Pei Wang', ' Junqi Wang', ' Pushpi Paranamana', ' Patrick Shafto']","{'Rutgers University - Newark', 'Rutgers University-Newark'}",1,0,0,{'USA'}
Penalized Langevin dynamics with vanishing penalty  for smooth and log-concave targets,"Avetik Karagulyan, Arnak Dalalyan",Penalized Langevin dynamics with vanishing penalty for smooth and log-concave targets,cc75c256acc04ce25a291c4b7a9856c0,https://proceedings.neurips.cc/paper/2020/file/cc75c256acc04ce25a291c4b7a9856c0-Paper.pdf,"We have developed a mathematical framework, that allows us to give quantitative non-asymptotic results for approximate sampling from non-strongly log-concave distributions. The main idea lies in adjusting the well-known Langevin SDE, in a way that the solution of the new equation converges to the target distribution. In this paper we have done the analysis of the continuous process. As a continutation of our work, one can extend it for the case of discrete-time processes, which can later be used in applications in Machine Learning and Computer Vision, where sampling from high-dimensional distributions is often required. This paper is purely theoretical, thus we expect no direct or indirect ethical risks from it. Nevertheless the described results provide a solid ground for future works that can directly be applied to tackle real-world problems.",7 Broader impact,131,6,,,FALSE,FALSE,FALSE,Penalized Langevin dynamics with vanishing penalty  for smooth and log-concave targets,Theory,Probabilistic Methods -> MCMC,Theory (including computational and statistical analyses),"['Avetik Karagulyan', ' Arnak Dalalyan']","{'Center for Research in Economics and Statistics / ENSAE / IPP', 'ENSAE ParisTech'}",1,0,0,{'France'}
Learning Invariances in Neural Networks from Training Data,"Gregory Benton, Marc Finzi, Pavel Izmailov, Andrew G. Wilson",Learning Invariances in Neural Networks,cc8090c4d2791cdd9cd2cb3c24296190,https://proceedings.neurips.cc/paper/2020/file/cc8090c4d2791cdd9cd2cb3c24296190-Paper.pdf,"Our work is largely methodological and we anticipate that Augerino will primarily see use within the machine learning community. Augerino’s ability to uncover invariances present within the data, without modifying the training procedure and with a very plug-and-play design that is compatible with any network architecture makes it an appealing method to be deployed widely. We hope that learning invariances from data is an avenue that will see continued inquiry and that Augerino will motivate further exploration.",Broader Impacts,77,3,,,FALSE,FALSE,FALSE,Learning Invariances in Neural Networks from Training Data,Deep Learning -> CNN Architectures,Deep Learning -> Supervised Deep Networks,Deep learning,"['Gregory Benton', ' Marc Finzi', ' Pavel Izmailov', ' Andrew Gordon Wilson']",{'New York University'},1,0,0,{'USA'}
A Finite-Time Analysis of Two Time-Scale Actor-Critic Methods,"Yue Wu, Weitong ZHANG, Pan Xu, Quanquan Gu",A Finite-Time Analysis of Two Time-Scale Actor-Critic Methods,cc9b3c69b56df284846bf2432f1cba90,https://proceedings.neurips.cc/paper/2020/file/cc9b3c69b56df284846bf2432f1cba90-Paper.pdf,"This work could positively impact the industrial application of actor-critic algorithms and other reinforcement learning algorithms. The theorem exhibits the sample complexity of actor-critic algorithms, which could be used to estimate required training time of reinforcement learning models. Another direct application of our result is to set the learning rate according to the finite-time bound, by optimizing the constant factors of the dominant terms. In this sense, the result could potentially reduce the overhead of hyper-parameter tuning, thus saving both human and computational resources. Moreover, the new analysis in this paper can potentially help people in different fields to understand the broader class of two-time scale algorithms, in addition to actor-critic methods. To our knowledge, this algorithm and theory studied in our paper do not have any ethical issues.",Broader impact,129,6,,,FALSE,FALSE,FALSE,A Finite-Time Analysis of Two Time-Scale Actor-Critic Methods,Reinforcement Learning and Planning,,Reinforcement learning and planning,"['Yue Wu', ' Weitong ZHANG', ' Pan Xu', ' Quanquan Gu']","{'UCLA', 'University of California, Los Angeles'}",1,1,1,{'USA'}
Pruning Filter in Filter,"Fanxu Meng, Hao Cheng, Ke Li, Huixiang Luo, Xiaowei Guo, Guangming Lu, Xing Sun",Pruning Filter in Filter,ccb1d45fb76f7c5a0bf619f979c6cf36,https://proceedings.neurips.cc/paper/2020/file/ccb1d45fb76f7c5a0bf619f979c6cf36-Paper.pdf,"Advantage of our project: • Training deep neural networks require a huge amount of time and resources. Pruning can reduce the network to a small size, thus resulting in reducing the cost of training. More importantly, our method does not need retraining (fine-tuning) which is more efficient in training deep neural networks. We are not aware of a negative impact on our society. However, the pruned network may lose performance compared to an untouched state. Thus some hyper-parameters may need to be tuned very carefully.",Broader Impact,85,6,,,TRUE,TRUE,FALSE,Pruning Filter in Filter,Deep Learning,Deep Learning -> CNN Architectures; Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,Deep learning,"['Fanxu Meng', ' Hao Cheng', ' Ke Li', ' Huixiang Luo', ' Xiaowei Guo', ' Guangming Lu', ' Xing Sun']","{'Tencent Youtu Lab', 'Harbin Institute of Technology, Shenzhen', 'Tencent'}",1,1,1,{'China'}
Learning to Mutate with Hypergradient Guided Population,"Zhiqiang Tao, Yaliang Li, Bolin Ding, Ce Zhang, Jingren Zhou, Yun Fu",Learning to Mutate with Hypergradient Guided Population,ccb421d5f36c5a412816d494b15ca9f6,https://proceedings.neurips.cc/paper/2020/file/ccb421d5f36c5a412816d494b15ca9f6-Paper.pdf,The proposed HPM algorithm addresses the challenge of combining local gradient and global search for solving the hyperparameter optimization problem. The proposed framework could be incorporated in many automated machine learning systems to provide an effective hyperparameter schedule solution. The outcome of this work will benefit both the academic and industry communities by liberating researchers from the tedious hyperparameter tuning work.,Broader Impact,61,3,,,FALSE,FALSE,FALSE,Learning to Mutate with Hypergradient Guided Population,Algorithms -> AutoML,,AutoML,"['Zhiqiang Tao', ' Yaliang Li', ' Bolin Ding', ' Ce Zhang', ' Jingren Zhou', ' Yun Fu']","{'Santa Clara University', 'Northeastern University', 'ETH Zurich', 'Alibaba Group'}",1,1,1,"{'USA', 'Switzerland', 'China'}"
A convex optimization formulation for multivariate regression,Yunzhang Zhu,A convex optimization formulation for multivariate regression,ccd2d123f4ec4d777fc6ef757d0fb642,https://proceedings.neurips.cc/paper/2020/file/ccd2d123f4ec4d777fc6ef757d0fb642-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,A convex optimization formulation for multivariate regression,Probabilistic Methods -> Graphical Models,Theory -> Regularization; Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",['Yunzhang Zhu'],{'Ohio State University'},1,0,0,{'USA'}
Online Meta-Critic Learning for Off-Policy Actor-Critic Methods,"Wei Zhou, Yiying Li, Yongxin Yang, Huaimin Wang, Timothy Hospedales",Online Meta-Critic Learning for Off-Policy Actor-Critic Methods,cceff8faa855336ad53b3325914caea2,https://proceedings.neurips.cc/paper/2020/file/cceff8faa855336ad53b3325914caea2-Paper.pdf,"We introduced a framework for meta RL where learning is improved through the addition of an auxiliary meta-critic which is trained online to maximise learning progress. This technology could benefit all current and potential future downstream applications of reinforcement learning, where learning speed and/or asymptotic performance can still be improved – such as in game playing agents and robot control. Faster reinforcement learning algorithms such as meta-critic could help to reduce the energy requirements training agents, which can add up to a significant environmental cost [35]; and bring us one step closer to enabling learning-based control of physical robots, which is currently rare due to the sample inefficiency of RL algorithms in comparison to the limited robustness of real robots to physical wear and tear of prolonged operation. Returning to our specific algorithmic contribution, introducing learnable reward functions rather than relying solely on manually specified rewards introduces a certain additional level of complexity and associated risk above that of conventional reinforcement learning. If the agent participates in defining its own reward, one might like to be able to interpret the learned reward function and validate that it is reasonable and will not lead to the robot learning to perform undesirable behaviours. This suggests that development of explainable AI techniques suited for reward function analysis could be a good topic for future research.",Broader Impact,222,6,,,FALSE,FALSE,FALSE,Online Meta-Critic Learning for Off-Policy Actor-Critic Methods,Algorithms -> Meta-Learning,Reinforcement Learning and Planning -> Reinforcement Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Wei Zhou', ' Yiying Li', ' Yongxin Yang', ' Huaimin Wang', ' Timothy Hospedales']","{'University of Edinburgh', 'University of Edinburgh ', 'National University of Defense Technology'}",1,0,0,"{'UK', 'China'}"
The All-or-Nothing Phenomenon in Sparse Tensor PCA,"Jonathan Niles-Weed, Ilias Zadik",The All-or-Nothing Phenomenon in Sparse Tensor PCA,cd0b43eac0392accf3624b7372dec36e,https://proceedings.neurips.cc/paper/2020/file/cd0b43eac0392accf3624b7372dec36e-Paper.pdf,This work does not present any questions of immediate societal impact.,Broader impact,11,1,TRUE,FALSE,FALSE,FALSE,FALSE,The All-or-Nothing Phenomenon in Sparse Tensor PCA,Theory -> Information Theory,Theory -> High-Dimensional Inference; Theory -> Statistical Learning Theory,,"['Weed', ' Ilias Zadik']",{'NYU'},1,0,0,{'USA'}
"Synthesize, Execute and Debug: Learning to Repair for Neural Program Synthesis","Kavi Gupta, Peter Ebert Christensen, Xinyun Chen, Dawn Song","Synthesize, Execute and Debug: Learning to Repair for Neural Program Synthesis",cd0f74b5955dc87fd0605745c4b49ee8,https://proceedings.neurips.cc/paper/2020/file/cd0f74b5955dc87fd0605745c4b49ee8-Paper.pdf,"Program synthesis has many potential real-world applications. One significant challenge of program synthesis is that the generated program needs to be precisely correct. SED mitigates this challenge by not requiring the solution to be generated in one shot, and instead allowing partial solutions to be corrected via an iterative improvement process, achieving an overall improvement in performance as a result. We thus believe SED-like frameworks could be applicable for a broad range of program synthesis tasks.",Broader Impacts,76,4,,,FALSE,FALSE,FALSE,"Synthesize, Execute and Debug: Learning to Repair for Neural Program Synthesis",Applications -> Program Understanding and Generation,Algorithms -> Program Induction,"Other applications (e.g., robotics, biology, climate, finance)","['Kavi Gupta', ' Xinyun Chen', ' Peter Ebert Christensen', ' Dawn Song']","{'UC Berkeley', 'Technical University of Denmark'}",1,0,0,"{'USA', 'Denmark'}"
ARMA Nets: Expanding Receptive Field for Dense Prediction,"Jiahao Su, Shiqi Wang, Furong Huang",ARMA Nets: Expanding Receptive Field for Dense Prediction,cd10c7f376188a4a2ca3e8fea2c03aeb,https://proceedings.neurips.cc/paper/2020/file/cd10c7f376188a4a2ca3e8fea2c03aeb-Paper.pdf,"Our presented ARMA layer is a plug-and-play module that can replace any convolutional layer in neural networks. The module is particularly effective in dense prediction problems, including video prediction, object detection and medical image segmentation. These improved performance in all these applications could revolutionize people’s daily life; it could alarm humans potential risks, relieve workers from repeat laboring, and help experts in making better decisions. For examples, video prediction in autonomous system helps to anticipate future risks and contributes to safe self-driving, and medical image segmentation could provide additional information to doctors and help them to make more reliable decisions on high-stakes tasks. However, these applications also raise controversies in the society. For examples, a faulty prediction in self-driving car or medical diagnostic system could lead to deadly consequence. Furthermore, object detection could be misused for military purposes. To understand and thus mitigate these potential risks, we suggest researchers in engineering and social sciences to investigate questions such as: • How to systematically verify the capacity of a machine learning model, such that certain behavior can be prohibited before deployment? • How to define the responsibility if a machine learning system produces an undesired outcome (e.g. car crash or misdiagnosis)?",Impact Statement,200,9,,,FALSE,TRUE,FALSE,ARMA Nets: Expanding Receptive Field for Dense Prediction,Deep Learning,Deep Learning -> CNN Architectures; Deep Learning -> Recurrent Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jiahao Su', ' Shiqi Wang', ' Furong Huang']","{'University of Maryland', 'Nanjing University '}",1,0,0,"{'USA', 'China'}"
Diversity-Guided Multi-Objective Bayesian Optimization With Batch Evaluations,"Mina Konakovic Lukovic, Yunsheng Tian, Wojciech Matusik",Diversity-Guided Multi-Objective Bayesian Optimization With Batch Evaluations,cd3109c63bf4323e6b987a5923becb96,https://proceedings.neurips.cc/paper/2020/file/cd3109c63bf4323e6b987a5923becb96-Paper.pdf,"Bayesian optimization has successfully been used for a wide range of applications, including pa- rameter tuning [ 4, 42], recommender systems and advertising [23, 40, 7], robotics [28, 30], resource allocation [18, 49], environmental monitoring [29], clinical drug trials [47, 50], experimental de- sign [44, 14]. This list is not exhaustive; many more examples can be found and new problems could exploit Bayesian optimization methods. We present a novel approach for multi-objective Bayesian optimization that aims to enable parallelized evaluations and increased time efficiency of the opti- mization process. Our approach is not limited to specific applications. In general, any problem that requires sample-efficient optimization of multiple black-box functions that are expensive to evaluate could benefit from using our approach. The proposed method exhibits improved performance over the current state-of-the-art methods and offers a new perspective on the diversity of explored solutions. In particular, the extracted diversity regions of Pareto-optimal solutions may provide important material for further investigation of the problem. Examining the shared properties among samples in each region could deliver a better understanding of the interaction between design variables (base ingredients) and their contribution to optimal performance. Our method may be especially useful for applications in areas such as materials science, chemistry, and pharmaceutical industry, where the experiments are long (e.g., days or weeks), but can easily be carried out in parallel. An important benefit of our work may be found in sustainability. The method specifically cares about preserving the resources used in experiments, such as energy consumption, chemical ingredients, and time. The reduced number of evaluations may significantly lower the testing waste. We hope that our approach will initiate more research in this direction and attract more attention to saving resources as much as possible alongside with rapid technological advances. We plan to release an open-source codebase with a user interface for users with limited prior exposure to machine learning or multi-objective optimization algorithms. We hope that this codebase will perpetuate research in various scientific disciplines and enable the growth of interdisciplinary work. On the negative side, we cannot guarantee that our approach will be used solely for a good cause with no negative use cases. Our contribution is mainly improving the efficiency of the experiments and saving more resources; however, we cannot prevent the abuse of this technology. The failure in our system would mean an inability to improve the set of Pareto-optimal solutions received from the initial set of samples. This inability may be caused by inadequate input data, such as too limited design space, or evaluations with intractable oscillations in noise. The failure can be detected after only a few iterations and experiments could be terminated. At this point, we cannot think of any further disadvantages of using our approach. We see further opportunities in the development of automated experimental design systems in research and technology. Our approach can be integrated as a “brain” of an autonomous production and testing system, to drive the design of experiments and evaluations without human supervision and hand-picking of the design samples to evaluate. The automation process may cause some job loss of repetitive tasks. However, it may also result in increased productivity of researchers and accelerate the development of important products, such as drugs, chemicals, and new materials. It may provide new job opportunities for algorithm engineers and data scientists to build more intelligent optimization workflows according to the specific needs of different problems.",Broader Impact,567,26,,,FALSE,FALSE,FALSE,Diversity-Guided Multi-Objective Bayesian Optimization With Batch Evaluations,Algorithms -> Active Learning,Optimization -> Evolutionary Computation,Optimization Methods (continuous or discrete),"['Mina Konakovic Lukovic', ' Yunsheng Tian', ' Wojciech Matusik']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
SOLOv2: Dynamic and Fast Instance Segmentation,"Xinlong Wang, Rufeng Zhang, Tao Kong, Lei Li, Chunhua Shen",SOLOv2: Dynamic and Fast Instance Segmentation,cd3afef9b8b89558cd56638c3631868a,https://proceedings.neurips.cc/paper/2020/file/cd3afef9b8b89558cd56638c3631868a-Paper.pdf,"One of the primary goals of computer vision is understanding of visual scenes. Scene understanding involves numerous tasks ( e . g ., recognition, detection, segmentation, etc .). Among them, instance segmentation is probably one of the most challenging tasks, which requires to detect object instances at the pixel level. Albeit being challenging, instance segmentation is beneficial to a wide range of applications, including autonomous driving, augmented reality, medical image analysis, and image/video editing. The proposed accurate and fast instance segmentation solution benefits broader applications. Autonomous driving becomes safer. Doctors could find the lesion part in medical images with less effort. Moreover, we believe that our method can serve as a strong baseline for researchers and engineers in the field. This new paradigm may encourage future work to deeply analyze and further enhance research along this direction. Practitioners may develop interesting applications built upon our approach.",Broader Impact,146,11,,,FALSE,FALSE,FALSE,SOLOv2: Dynamic and Fast Instance Segmentation,Applications,Applications -> Computer Vision; Applications -> Image Segmentation,Vision,,"{'Bytedance', 'ByteDance AI Lab', 'Tongji University', 'University of Adelaide'}",1,1,1,"{'Australia', 'China'}"
Robust Recovery via Implicit Bias of Discrepant Learning Rates for Double Over-parameterization,"Chong You, Zhihui Zhu, Qing Qu, Yi Ma",Robust Recovery via Implicit Bias of Discrepant Learning Rates for Double Over-parameterization,cd42c963390a9cd025d007dacfa99351,https://proceedings.neurips.cc/paper/2020/file/cd42c963390a9cd025d007dacfa99351-Paper.pdf,"Robust learning of structured signals from high-dimensional data has a wide range of applications, including imaging processing, computer vision, recommender systems, generative models and many more. In this work, we presented a new type of practical methods and provided improved understandings of solving these problems via over-parameterized models. In particular, our method ex- ploits the implicit bias introduced by the learning algorithm, with the underlying driving force being the intrinsic structure of the data itself rather than human handcrafting. Such a design methodology helps to eliminate human bias in the design process, hence provides the basis for developing truly fair machine learning systems.",Broader Impact,103,4,,,FALSE,FALSE,FALSE,Robust Recovery via Implicit Bias of Discrepant Learning Rates for Double Over-parameterization,Algorithms -> Sparsity and Compressed Sensing,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA); Applications -> Computer Vision; Applications -> Matrix and Tensor Factorization; Optimization -> Non-Convex Optimization; Theory -> Models of Learning and Generalization",Deep learning,"['Chong You', ' Zhihui Zhu', ' Qing Qu', ' Yi Ma']","{'UC Berkeley', 'University of California, Berkeley', 'New York University', 'Johns Hopkins University'}",1,0,0,{'USA'}
Axioms for Learning from Pairwise Comparisons,"Ritesh Noothigattu, Dominik Peters, Ariel D. Procaccia",Axioms for Learning from Pairwise Comparisons,cdaa9b682e10c291d3bbadca4c96f5de,https://proceedings.neurips.cc/paper/2020/file/cdaa9b682e10c291d3bbadca4c96f5de-Paper.pdf,"Our work is motivated by the observation that the RUM-based approach for aggregating pairwise comparisons is already being considered for societal applications such as kidney exchange and food allocation. Our goal is to assess this choice from a normative viewpoint. Therefore, we view the potential implications of our work as being strictly positive. That said, one should keep in mind that learning-to-rank algorithms face a variety of ethical challenges, with fairness being one potential concern [Singh and Joachims, 2019, Beutel et al., 2019].",Broader Impact,83,4,,,FALSE,FALSE,FALSE,Axioms for Learning from Pairwise Comparisons,Theory -> Game Theory and Computational Economics,Algorithms -> Ranking and Preference Learning,,"['Ritesh Noothigattu', ' Dominik Peters', ' Ariel Procaccia']","{'Harvard University', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Continuous Regularized Wasserstein Barycenters,"Lingxiao Li, Aude Genevay, Mikhail Yurochkin, Justin M. Solomon",Continuous Regularized Wasserstein Barycenters,cdf1035c34ec380218a8cc9a43d438f9,https://proceedings.neurips.cc/paper/2020/file/cdf1035c34ec380218a8cc9a43d438f9-Paper.pdf,"In this paper, we propose new techniques for estimating Wasserstein barycenters. The Wasserstein barycenter is a purely mathematical notion that can be applied to solve a variety of problems in practice. Beyond generic misuses of statistical and machine learning techniques, we are not aware of any unethical applications specifically of Wasserstein barycenters and hope that practitioners will find use cases for our methodology that can benefit society.",6 Broader Impact,67,3,,,FALSE,FALSE,FALSE,Continuous Regularized Wasserstein Barycenters,Algorithms -> Stochastic Methods,,Optimal transport,"['Lingxiao Li', ' Aude Genevay', ' Mikhail Yurochkin', ' Justin M Solomon']","{'MIT', 'IBM Research, MIT-IBM Watson AI Lab'}",1,1,1,{'USA'}
Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting,"Defu Cao, Yujing Wang, Juanyong Duan, Ce Zhang, Xia Zhu, Congrui Huang, Yunhai Tong, Bixiong Xu, Jing Bai, Jie Tong, Qi Zhang",Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting,cdf6581cb7aca4b7e19ef136c6e601a5,https://proceedings.neurips.cc/paper/2020/file/cdf6581cb7aca4b7e19ef136c6e601a5-Paper.pdf,"Time-series analysis is an important research domain for machine learning, while multivariate time- series forecasting is one of the most prevalent tasks in this domain. This paper proposes a novel model, StemGNN, for the task of multivariate time-series forecasting. For the first time, we model the inter-series correlations and temporal patterns jointly in the spectral domain, which improves the representation power of multivariate time-series. Signals in the time domain can be easily restored by the orthogonal basis in the frequency domain, so we could leverage the rich information beneath the hood of the frequency domain to improve the forecasting results. StemGNN is neat yet powerful as proved by extensive experiments and analyses. It is one of the first attempts that incorporate Discrete Fourier Transform with Graph Neural Networks. We believe it will motivate more exploration along this direction in other related domains with temporal features, such as social graph mining and sentiment analysis. Moreover, StemGNN adopts a latent correlation layer in an end-to-end framework to learn relationships among multivariate signals automatically. This makes StemGNN a general approach that could be applied to a wide range of applications, including surveillance of traffic flows, healthcare data monitoring, natural disaster forecasting and economy. Multivariate time-series forecasting has significant societal implications as well. A sophisticated supply chain management system may be built if we can predict market trend precisely. It also brings benefit to our daily life. For example, there is a real case about ‘Flooding Risk Analysis’. The task is to predict when there will be a flooding in certain areas near the city. The prediction mainly depend on two external factors, tides and rainfalls. Accurate prediction can alert people to keep away from the area at the corresponding time to avoid unnecessary losses. For COVID-19, accurate prediction of the trend may help the government make suitable decisions to control the spread of the epidemic. According to a case study on COVID-19 in this paper, we can reasonably forecast the daily number of newly confirmed cases four weeks in advance based on historical data. Nevertheless, how to predict the trend from the beginning without sufficient historical data is more challenging and remained to be investigated. Moreover, we are aware of the negative impact of this technique to infringement of personal privacy. Customers’ behavior may be predicted by unscrupulous business persons on historical records, which provides a convenient way to send spam information. Hackers may also use the predicted data to avoid surveillance of a bank’s security system for fraud credit card transactions. Although current models are still far away from predicting future data absolutely correct, we do believe that the margin is decreasing rapidly. We hope that researchers could understand and mitigate the potential risks in this domain. We would like to mention the concept of responsible AI, which guides us to integrate fairness, interpretability, privacy, security, accountability into the design of AI systems. We suggest researchers to take a people-centered approach to research, development, and deployment of AI and cultivate a responsible AI-ready culture.",Broader Impact,502,26,,,FALSE,FALSE,FALSE,Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting,Applications -> Time Series Analysis,Algorithms -> Regression; Algorithms -> Spectral Methods,Deep learning,"['Defu Cao', ' Yujing Wang', ' Juanyong Duan', ' Ce Zhang', ' Xia Zhu', ' Congrui Huang', ' Yunhai Tong', ' Bixiong Xu', ' Jing Bai', ' Jie Tong', ' Qi Zhang']","{'MSRA', 'Microsoft', 'Peking University', 'ETH Zurich'}",1,1,1,"{'USA', 'China', 'Switzerland'}"
Online Multitask Learning with Long-Term Memory,"Mark Herbster, Stephen Pasteris, Lisa Tse",Online Multitask Learning with Long-Term Memory,cdfa4c42f465a5a66871587c69fcfa34,https://proceedings.neurips.cc/paper/2020/file/cdfa4c42f465a5a66871587c69fcfa34-Paper.pdf,"In general this work does not present any specific foreseeable societal consequence in the authors’ joint opinion. This is foundational research in regret-bounded online learning . As such it is not targeted towards any particular application area. Although this research may have societal impact for good or for ill in the future, we cannot foresee the shape and the extent.",Broader Impact,61,4,TRUE,FALSE,FALSE,TRUE,FALSE,Online Multitask Learning with Long-Term Memory,Algorithms -> Online Learning,,Theory (including computational and statistical analyses),"['Mark Herbster', ' Stephen Pasteris', ' Fai Yu Lisa Tse']",{'University College London'},1,0,0,{'UK'}
Fewer is More: A Deep Graph Metric Learning Perspective Using Fewer Proxies,"Yuehua Zhu, Muli Yang, Cheng Deng, Wei Liu",Fewer is More: A Deep Graph Metric Learning Perspective Using Fewer Proxies,ce016f59ecc2366a43e1c96a4774d167,https://proceedings.neurips.cc/paper/2020/file/ce016f59ecc2366a43e1c96a4774d167-Paper.pdf,"a) Who may benefit from this research? In this paper we proposed a new pipeline for deep metric learning. Like many other relevant studies in this area, our work aims at establishing similarity or dissimilarity relationships among data inputs. Our work can be applied to many practical scenarios, such as big data analysis, face/object recognition, person re-identification, voice verification, etc . Corporations or other non-profit organizations/persons with such purposes may benefit from our work. b) Who may be put at disadvantage from this research? Since our work can be used in social media  companies or any other occasions where user data can be accessed, people who are worried about their privacy being analyzed or targeted may be put at disadvantage. c) What are the consequences of failure of the system? Before formal deployment, the DML model should be properly trained and tested with available data samples, i . e ., the risk should be controllable. If any failure happens, the most immediate consequence can be recognition/analysis errors for the systems in which our proposed model is leveraged, which may further result in unnecessary economic costs or losses of other resources. d) Whether the task/method leverages biases in the data? Our work is posed with a general purpose of learning a more discriminative feature embedding without specific requirements on training data. Thus, our work does not leverage biases in the data, but rather, may possess the ability to suppress/capture such biases (if any) using our adaptive proxy strategy.",Broader Impact,247,14,,,FALSE,FALSE,FALSE,Fewer is More: A Deep Graph Metric Learning Perspective Using Fewer Proxies,Applications -> Computer Vision,Algorithms -> Classification; Algorithms -> Clustering; Algorithms -> Metric Learning; Deep Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'Xidian University', 'Tencent AI Lab'}",1,1,1,{'China'}
Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting,"LEI BAI, Lina Yao, Can Li, Xianzhi Wang, Can Wang",Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting,ce1aad92b939420fc17005e5461e6f48,https://proceedings.neurips.cc/paper/2020/file/ce1aad92b939420fc17005e5461e6f48-Paper.pdf,"In general, this work enables more accurate traffic forecasting, which facilities the higher-lever traffic scheduling such as taxi dispatch and route planing. In this way, our work can help save time for travelers, improve efficiency and income for transport operators, and save energy consumption. In a broad sense, adaptability is desirable in correlated time series analysis for broad social and business applications in the era of big data. The proposed adaptive modules enable elevated robustness of data analysis and relevant applications based on dynamic, interdependent, time-series data. This research generally supports better modeling and analysis of multiple channels of data based on graph structures with complex explicit and implicit correlations. It has implications and potentially accelerates the research progress in address many world-scale economic and societal issues that rely on complex times series data, such as predictions of influenza outbreak, economic growth, and climate change. A potential negative impact of this work is the fairness problem in the ride-sharing platforms. In the case that cabs supply cannot guarantee demand, platforms may emphasize the predicted high-demand areas too much, which would increase the waiting time of travelers in the low-demand areas.",Broader Impact,190,8,,,FALSE,FALSE,FALSE,Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting,Applications -> Time Series Analysis,Deep Learning -> Predictive Models,"Other applications (e.g., robotics, biology, climate, finance)","['LEI BAI', ' Lina Yao', ' Can Li', ' Xianzhi Wang', ' Can Wang']","{'University of Technology Sydney', 'UNSW, Sydney', 'University of New South Wales', 'Griffith University'}",1,0,0,{'Australia'}
On Reward-Free Reinforcement Learning with Linear Function Approximation,"Ruosong Wang, Simon S. Du, Lin Yang, Russ R. Salakhutdinov",On Reward-Free Reinforcement Learning with Linear Function Approximation ∗,ce4449660c6523b377b22a1dc2da5556,https://proceedings.neurips.cc/paper/2020/file/ce4449660c6523b377b22a1dc2da5556-Paper.pdf,This work is mainly theoretical. Our theoretical results on reward-free RL with linear function approximation could potentially guide practitioners to design theoretically principled and robust exploration algorithms that can be deployed in practical RL systems.,Broader Impact,35,2,FALSE,FALSE,FALSE,FALSE,FALSE,On Reward-Free Reinforcement Learning with Linear Function Approximation,Reinforcement Learning and Planning -> Exploration,Theory,,"['Ruosong Wang', ' Simon Du', ' Lin Yang', ' Russ Salakhutdinov']","{'UCLA', 'Institute for Advanced Study', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Robustness of Community Detection to Random Geometric Perturbations,"Sandrine Peche, Vianney Perchet",Robustness of Community Detection to Random Geometric Perturbations,ce46f09027b218b46063eb2b858f622d,https://proceedings.neurips.cc/paper/2020/file/ce46f09027b218b46063eb2b858f622d-Paper.pdf,"This paper deals with theoretical detection of community in networks. Even if an entity wants to use community detection with some mercantile objectives (maybe in order to target some specific community), it would probably use spectral methods, no matter if the existing theory gives it guarantee that it is going to work. At worst, our paper will provide a positive answer: the very specific assumptions of stochastic block models are not required for theoretical (and certainly practical) recovery. On the other hand, theoretical robustness results as ours can lead to substantial follow up research on finding the transition between regimes in complex models (almost ill-posed). Theory papers like this one are therefore win-win.",Broader Impact,113,5,,,FALSE,FALSE,FALSE,Robustness of Community Detection to Random Geometric Perturbations,Algorithms -> Spectral Methods,Applications -> Network Analysis,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Sandrine Peche', ' Vianney Perchet']","{'LPSM, Université Paris Diderot'}",1,0,0,{'France'}
Learning outside the Black-Box: The pursuit of interpretable models,"Jonathan Crabbe, Yao Zhang, William Zame, Mihaela van der Schaar",Learning outside the Black-Box: The pursuit of interpretable models,ce758408f6ef98d7c7a7b786eca7b3a8,https://proceedings.neurips.cc/paper/2020/file/ce758408f6ef98d7c7a7b786eca7b3a8-Paper.pdf,"As mentioned at the very beginning of this paper, the lack of easy interpretation of ML models has proved a serious obstacle to their adoption – despite their demonstrated accuracy. Because ML models are more accurate than previous models, anything that makes ML models more widely used is likely to have enormous positive affects in practice – simply by providing better predictions. Even interpretations that provide only first-order information will surely prove to be important – not least by allowing for easier correction of measurement/recording errors. Two examples may illustrate. (1) It is well-documented that “No-Fly” lists often flag the wrong people who happen to have the same names as the right people, and that getting removed from such lists can be a difficult task. (2) It is similarly well-documented that measurement/recording errors are common in the calculation of credit scores – but because those calculations are often quite opaque, such errors are often left uncorrected, so some who should be approved for loans are declined, and others who should be declined are approved . This paper has offered a method for producing accurate and parsimonious interpretations of black-box models. In no sense do we view this as providing the final or best method for interpretation; indeed we view this work as taking, along with [1], only the first few steps in a new and very promising direction. We have already noted that, because the interpretations our algorithm produces are continuous, our method may not be suitable for interpretation of black-box models such as Decision Trees or Random Forests, and may not be suitable for classification problems unless they are transformed into regression problems by assigning probabilities instead of decisions. In itself, this transformation is simple and unobjectionable, but clients who expect “Buy” or “Sell” advice from their financial advisor may not be happy with a recommendation to “Buy with probability 0 . 7 and Sell with probability 0 . 3 .” Despite the fact that our symbolic models contain few terms, which is a significant improvement compared to [1], we still have to deal with some Meijer G-functions or hypergeometric functions that don’t reduce to familiar expressions. If this family of functions is explicitly used in some scientific communities, such as in physics [14], they are not likely to be deemed interpretable by some practitioners. A possible way to deal with this issue would be to enforce the cancellation between some zeroes and poles of the Meijer G-functions. This can be done by adding a lasso penalty to the loss, this approach is detailed in Section 4 of the supplementary material. We are convinced that the Symbolic Pursuit algorithm opens up several interesting research paths in the ML intepretability landscape. We hope that this paper will convince the ML community to walk along them to explore this emerging paradigm of interpretability.",Broader Impact,472,17,,,FALSE,FALSE,FALSE,Learning outside the Black-Box: The pursuit of interpretable models,"Deep Learning -> Visualization, Interpretability, and Explainability",,Interpretability,"['Jonathan Crabbe', ' Yao Zhang', ' William Zame', ' Mihaela van der Schaar']","{'University of Cambridge', 'UCLA'}",1,0,0,"{'UK', 'USA'}"
Breaking Reversibility Accelerates Langevin Dynamics for Non-Convex Optimization,"Xuefeng GAO, Mert Gurbuzbalaban, Lingjiong  Zhu",Breaking Reversibility Accelerates Langevin Dynamics for Non-Convex Optimization,cebd648f9146a6345d604ab093b02c73,https://proceedings.neurips.cc/paper/2020/file/cebd648f9146a6345d604ab093b02c73-Paper.pdf,"Langevin algorithms are core Markov Chain Monte Carlo (MCMC) methods for solving machine learning problems. These methods arise in several contexts in machine learning and data science. For example, they can be applied to Bayesian inference problems. They can also be used to solve stochastic non-convex optimization problems including the challenging problems arising in deep learning. Our paper argues that the non-reversible variants of the classical Langevin algorithms can perform better by providing rigorous mathematical analysis, and bridges a gap between theory and practice. Therefore, our paper contributes to the growing literature on theoretical foundations of MCMC methods. Researchers in the machine learning community and beyond will benefit from this research by having a better understanding of why non-reversible variants of the classical Langevin algorithms can improve performance.",Broader Impact,128,7,,,FALSE,FALSE,FALSE,Breaking Reversibility Accelerates Langevin Dynamics for Non-Convex Optimization,Optimization,Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Xuefeng GAO', ' Mert Gurbuzbalaban', ' Lingjiong Zhu']","{'The Chinese University of Hong Kong', 'Florida State University', 'Rutgers'}",1,0,0,"{'USA', 'China'}"
Robust large-margin learning in hyperbolic space,"Melanie Weber, Manzil Zaheer, Ankit Singh Rawat, Aditya K. Menon, Sanjiv Kumar",Robust large-margin learning in hyperbolic space,cec6f62cfb44b1be110b7bf70c8362d8,https://proceedings.neurips.cc/paper/2020/file/cec6f62cfb44b1be110b7bf70c8362d8-Paper.pdf,"The paper proposes novel algorithms for large-margin learning in hyperbolic space. The paper’s scope is theoretical and does not discuss specific applications with societal consequences. Therefore, a discussion of the broader impact of this work is not applicable.",Broader Impact,38,3,TRUE,FALSE,FALSE,FALSE,FALSE,Robust large-margin learning in hyperbolic space,Algorithms -> Large Margin Methods,Algorithms -> Adversarial Learning,Theory (including computational and statistical analyses),"['Melanie Weber', ' Manzil Zaheer', ' Ankit Singh Rawat', ' Aditya Menon', ' Sanjiv Kumar']","{'Google', 'Princeton University', 'Google Research'}",1,1,1,{'USA'}
Replica-Exchange Nos\'e-Hoover Dynamics for Bayesian Learning on Large Datasets,"Rui Luo, Qiang Zhang, Yaodong Yang, Jun Wang",Replica-Exchange Nosé-Hoover Dynamics for Bayesian Learning on Large Datasets,cfd382c5eb817d52c7faf45a96f20b81,https://proceedings.neurips.cc/paper/2020/file/cfd382c5eb817d52c7faf45a96f20b81-Paper.pdf,"This paper proposes a practical solution to Bayesian learning. By simulating a collection of replicas at different temperatures, the proposed solution is able to efficiently draw samples from complex posterior distributions. Consequently, the performance of Bayesian learning is improved. Since Bayesian learning is a common tool for many machine learning problems, the social and ethical impacts of this solution are upon specific applications.",Broader Impact,63,4,,,FALSE,FALSE,FALSE,Replica-Exchange Nos\'e-Hoover Dynamics for Bayesian Learning on Large Datasets,Probabilistic Methods -> MCMC,,,"['Rui Luo', ' Qiang Zhang', ' Yaodong Yang', ' Jun Wang']",{'University College London'},1,0,0,{'UK'}
Adversarially Robust Few-Shot Learning: A Meta-Learning Approach,"Micah Goldblum, Liam Fowl, Tom Goldstein",Adversarially Robust Few-Shot Learning: A Meta-Learning Approach,cfee398643cbc3dc5eefc89334cacdc1,https://proceedings.neurips.cc/paper/2020/file/cfee398643cbc3dc5eefc89334cacdc1-Paper.pdf,"Few-shot learning systems are already deployed in real-world settings, but practitioners may remain unaware of the robustness properties of their models. Our work thoroughly studies this topic using methods which these practitioners may deploy, and we contribute a method for hardening their systems. Our work can benefit both organizations deploying few-shot learning systems as well as their customers and clients.",Broader Impact,60,3,FALSE,FALSE,FALSE,FALSE,FALSE,Adversarially Robust Few-Shot Learning: A Meta-Learning Approach,Algorithms -> Meta-Learning,Algorithms -> Adversarial Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Micah Goldblum', ' Liam Fowl', ' Tom Goldstein']",{'University of Maryland'},1,0,0,{'USA'}
Neural Anisotropy Directions,"Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard",Neural Anisotropy Directions,cff02a74da64d145a4aed3a577a106ab,https://proceedings.neurips.cc/paper/2020/file/cff02a74da64d145a4aed3a577a106ab-Paper.pdf,"In this work we reveal the directional inductive bias of deep learning and describe its role in controlling the type of functions that neural networks can learn. The algorithm that we introduced to characterize it can help understand the reasons for the success or alternatively the modes of failure of most modern CNNs. Our work is mainly fundamental in the sense that it is not geared towards an application, but theory always has some downstream implications on the society as enabler of future applications. We see potential applications of our work on AutoML [34] as the main positive impact of our research. In particular, we believe that incorporating prior knowledge into the neural architecture search loop [35] can cut most computational and environmental costs of this procedure. Specifically, with the current trend in deep learning towards building bigger and computationally greedier models [36], the impact of machine learning on the environment is becoming a pressing issue [37]. Meanwhile, this trend is raising the bar on the needed resources to use these models and research in deep learning is getting concentrated around a few big actors. In this sense, we believe that gaining a better understanding of our current models will be key in circumventing the heavy heuristics necessary to deploy deep learning today, thus enabling the democratization of this technology [38]. On the other hand, we see the main possible negative implication of our work in the malicious use of NADs to boost the adversarial capacity of new evasion/backdoor attacks [39]. This could poten- tially exploit the sensitivity of neural networks to NADs to generate more sophisticated adversarial techniques. Machine learning engineers should be aware of such vulnerabilities when designing new architectures, especially for safety-critical applications.",Broader Impact,286,11,,,FALSE,FALSE,FALSE,Neural Anisotropy Directions,Deep Learning -> Analysis and Understanding of Deep Networks,Deep Learning; Deep Learning -> CNN Architectures,Deep learning,"['Jimenez', ' Apostolos Modas', 'Dezfooli', ' Pascal Frossard']","{'ETHZ', 'EPFL'}",1,0,0,{'Switzerland'}
Digraph Inception Convolutional Networks,"Zekun Tong, Yuxuan Liang, Changsheng Sun, Xinke Li, David Rosenblum, Andrew Lim",Digraph Inception Convolutional Networks,cffb6e2288a630c2a787a64ccc67097c,https://proceedings.neurips.cc/paper/2020/file/cffb6e2288a630c2a787a64ccc67097c-Paper.pdf,"GCNs could be applied to a wide range of applications, including image segmentation [27], speech recognition [14], recommender system [17], point cloud [50, 24], traffic prediction [25] and many more [45]. Our method can help to expand the graph types from undirected to directed in the above application scenarios and obtain multi-scale features from the high-order hidden directed structure. For traffic prediction, our method can be used in map applications to obtain more fine-grained and accurate predictions. This requires users to provide location information, which has a risk of privacy leakage. The same concerns also arise in social network analysis [38], person re-ID [35] and NLP [49], which use graph convolutional networks as their feature extraction methods. Another potential risk is that our model may be adversarial attacked by adding new nodes or deleting existing edges. For example, in a graph-based recommender system, our model may produce completely different recommendation results due to being attacked. We see opportunities for research applying DiGCN to beneficial purposes, such as investigating the ability of DiGCN to discover hidden complex directed structure, the limitation of approximate method based on personalized PageRank and the feature oversmoothing problem in digraphs. We also encourage follow-up research to design derivative methods for different tasks based on our method.",Broader Impact,210,9,,,FALSE,FALSE,FALSE,Digraph Inception Convolutional Networks,Deep Learning,Algorithms -> Classification; Algorithms -> Semi-Supervised Learning; Applications -> Network Analysis; Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Zekun Tong', ' Yuxuan Liang', ' Changsheng Sun', ' Xinke Li', ' David Rosenblum', ' Andrew Lim']",{'National University of Singapore'},1,0,0,{'Singapore'}
PAC-Bayesian Bound for the Conditional Value at Risk,"Zakaria Mhammedi, Benjamin Guedj, Robert C. Williamson",PAC-Bayesian Bound for the Conditional Value at Risk,d02e9bdc27a894e882fa0c9055c99722,https://proceedings.neurips.cc/paper/2020/file/d02e9bdc27a894e882fa0c9055c99722-Paper.pdf,"Coherent risk measures (including conditional value at risk) have been gaining significant traction in the machine learning community recently, as they allow for capturing in a much richer way the behaviour and performance of algorithms’ outputs. This comes at the expense of a much harder theoretical analysis and such measures are not supported by as many guarantees than the traditional mean risk (expectation of the loss). We provide in this paper one of the few generalisation bounds for CV A R and we believe this will shed light on the advantages of using CV A R in machine learning. We intend our contributions to be of prime interest to theoreticians, but also to practitioners.",Broader Impact,114,4,,,FALSE,FALSE,FALSE,PAC-Bayesian Bound for the Conditional Value at Risk,Theory -> Statistical Learning Theory,,Theory (including computational and statistical analyses),"['Zakaria Mhammedi', ' Benjamin Guedj', ' Robert Williamson']","{'The Australian National University', 'ANU'}",1,0,0,{'Australia'}
Stochastic Stein Discrepancies,"Jackson Gorham, Anant Raj, Lester Mackey",Stochastic Stein Discrepancies,d03a857a23b5285736c4d55e0bb067c8,https://proceedings.neurips.cc/paper/2020/file/d03a857a23b5285736c4d55e0bb067c8-Paper.pdf,"This work provides both producers and consumers of approximate inference techniques with a valid diagnostic for assessing those approximations at scale. It also analyzes a scalable algorithm (SSVGD) for improving approximate inference. We expect that many existing users of Stein discrepancies will want to employ stochastic Stein discrepancies to reduce their overall computational costs. In addition, the ready availability of a scalable diagnostic may stimulate the more widespread use of approximate MCMC methods. However, any inferential tool combined with the wrong data or inappropriate model can lead to incorrect and harmful conclusions, so care must be taken in interpreting the results of any downstream analysis.",Broader Impact,105,5,,,FALSE,FALSE,FALSE,Stochastic Stein Discrepancies,Probabilistic Methods,Probabilistic Methods -> MCMC,Probabilistic methods and inference,"['Jackson Gorham', ' Anant Raj', ' Lester Mackey']","{'Stanford University', 'Microsoft Research', 'Max Planck Institute for Intelligent Systems'}",1,1,1,"{'USA', 'Germany'}"
On the Role of Sparsity and DAG Constraints for Learning Linear DAGs,"Ignavier Ng, AmirEmad Ghassami, Kun Zhang",On the Role of Sparsity and DAG Constraints for Learning Linear DAGs,d04d42cdf14579cd294e5079e0745411,https://proceedings.neurips.cc/paper/2020/file/d04d42cdf14579cd294e5079e0745411-Paper.pdf,"The proposed method is able to estimate graphical structure from the linear DAG model, and can be efficiently scaled up to thousands of nodes while retaining a high accuracy. DAG structure learning has been a fundamental problem in machine learning in the past decades, with applications in many areas such as biology [37]. Thus, we believe that our method could be applied for beneficial purposes. Traditionally, score-based methods, such as GES [11], rely on local heuristics partly owing to the large search space of possible graphs. The continuous optimization formulation of structure learning has changed the nature of the task, which enables the usage of well-studied gradient-based solvers and GPU acceleration, as demonstrated in Section 5.4. Nevertheless, in practice, we comment that the graphical structure estimated by our method, as well as other structure learning methods, should be treated with care. In particular, it should be verified by domain experts before putting into decision-critical real world applications (e.g., healthcare). This is because the estimated structure may contain spurious edges, or may be affected by other factors, such as confounders, latent variables, measurement errors and selection bias.",Broader Impact,186,8,,,FALSE,FALSE,FALSE,On the Role of Sparsity and DAG Constraints for Learning Linear DAGs,Algorithms -> Model Selection and Structure Learning,Probabilistic Methods -> Causal Inference,Model Selection and Structure Learning,"['Zhi Yong Ignavier Ng', ' AmirEmad Ghassami', ' Kun Zhang']","{'CMU', 'Johns Hopkins University', 'University of Toronto'}",1,0,0,"{'Canada', 'USA'}"
Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural Architecture Search,"Houwen Peng, Hao Du, Hongyuan Yu, QI LI, Jing Liao, Jianlong Fu",Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural Architecture Search,d072677d210ac4c03ba046120f0802ec,https://proceedings.neurips.cc/paper/2020/file/d072677d210ac4c03ba046120f0802ec-Paper.pdf,"Similar to previous NAS works, this work does not have immediate societal impact, since the algorithm is only designed for image classification, but it can indirectly impact society. As an example, our work may inspire the creation of new algorithms and applications with direct societal implications. Moreover, compared with other NAS methods that require additional teacher model to guide the training process, our method does not need any external teacher models. So our method can be used in a closed data system, ensuring the privacy of user data.",7 Broader Impact,88,4,,,FALSE,FALSE,FALSE,Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural Architecture Search,Algorithms -> AutoML,Applications -> Computer Vision; Applications -> Object Recognition,AutoML,"['Houwen Peng', ' Hao Du', ' Hongyuan Yu', ' QI LI', ' Jing Liao', ' Jianlong Fu']","{'MSRA', 'Tsinghua Univeristy', 'Microsoft Research', 'City University of Hong Kong'}",1,1,1,"{'USA', 'China'}"
Fair Multiple Decision Making Through Soft Interventions,"Yaowei Hu, Yongkai Wu, Lu Zhang, Xintao Wu",Fair Multiple Decision Making Through Soft Interventions,d0921d442ee91b896ad95059d13df618,https://proceedings.neurips.cc/paper/2020/file/d0921d442ee91b896ad95059d13df618-Paper.pdf,"Our research could benefit any organization or system that uses computer algorithms to make important decisions, especially for large systems that consist of multiple decision tasks. By adopting our method, decision makers can build multiple decision models simultaneously just from one historical dataset and ensure that all decision models will be fair after the deployment. Our research could also benefit users who get involved in the system, in particular the users from disadvantage groups, by preventing them from receiving biased decisions.",Broader Impact,81,3,,,FALSE,FALSE,FALSE,Fair Multiple Decision Making Through Soft Interventions,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yaowei Hu', ' Yongkai Wu', ' Lu Zhang', ' Xintao Wu']","{'Clemson University', 'University of Arkansas'}",1,0,0,{'USA'}
Representation Learning for Integrating Multi-domain Outcomes to Optimize Individualized Treatment,"Yuan Chen, Donglin Zeng, Tianchen Xu, Yuanjia Wang",Representation Learning for Integrating Multi-domain Outcomes to Optimize Individualized Treatments,d0bb8259d8fe3c7df4554dab9d7da3c9,https://proceedings.neurips.cc/paper/2020/file/d0bb8259d8fe3c7df4554dab9d7da3c9-Paper.pdf,"Current treatments for mental health disorders are largely inadequate, in part due to the extensive heterogeneity between patients. This work may improve treatment responses for patients with mental disorders by facilitating clinical decision makings in prescribing personalized treatments depending on patient-specific measures. We note that it is possible that the latent constructs derived from poor instruments can have bias in certain subpopulations. Therefore, the psychometric measures to be included in the model need to be carefully studied including their reliability, validity and differential item functioning or item-response bias in populations of diverse racial or socioeconomic factors. For best practice, the latent constructs should be validated on external studies or among different subgroups. Our application uses carefully chosen instruments, which have been shown to exhibit adequate psychometric properties and widely used in clinical settings. Failure in recommending optimal treatments in certain populations may lead to patients’ sub-optimal treatment responses. However, our research serves as a recommendation tool to assist clinical decision making.",Broader impact,161,8,,,FALSE,FALSE,FALSE,Representation Learning for Integrating Multi-domain Outcomes to Optimize Individualized Treatment,Applications -> Health,Probabilistic Methods -> Causal Inference; Probabilistic Methods -> Latent Variable Models,Healthcare,,"{'Columbia University', 'University of North Carolina at Chapel Hill'}",1,0,0,{'USA'}
Learning to Play No-Press Diplomacy with Best Response Policy Iteration,"Thomas Anthony, Tom Eccles, Andrea Tacchetti, János Kramár, Ian Gemp, Thomas Hudson, Nicolas Porcel, Marc Lanctot, Julien Perolat, Richard Everett, Satinder Singh, Thore Graepel, Yoram Bachrach",Learning to Play No-Press Diplomacy with Best Response Policy Iteration,d1419302db9c022ab1d48681b13d5f8b,https://proceedings.neurips.cc/paper/2020/file/d1419302db9c022ab1d48681b13d5f8b-Paper.pdf,"We discuss the potential impact of our work, examining possible positive and negative societal impact. What is special about Diplomacy? Diplomacy [19] has simple rules but high emergent complexity. It was designed to accentuate dilemmas relating to building alliances, negotiation and teamwork in the face of uncertainty about other agents. The tactical elements of Diplomacy form a difficult environment for AI algorithms: the game is played by seven players, it applies simultaneous moves, and has a very large combinatorial action space. What societal impact might it have? We distinguish immediate societal impact arising from the availability of the new training algorithm, and indirect societal impact due to the future work on many-agent strategic decision making enabled or inspired by this work. Immediate Impact. Our methods allow training agents in Diplomacy and other temporally extended environments where players take simultaneous actions, and the action of a player can be decomposed into multiple sub-actions, in domains that can can be simulated well, but in which learning has been difficult so far. Beyond the direct impact on Diplomacy, possible applications of our method include business, economic, and logistics domains, in as far as the scenario can be simulated sufficiently accurately. Examples include games that require a participant to control multiple units (Starcraft and Dota [119, 14] have this structure, but there are many more), controlling fleets of cars or robots [1, 93, 118] or sequential resource allocation [95, 91]. However, applications such as in business or logistics are hard to capture realistically with a simulator, so significant additional work is needed to apply this technology in real-world domains involving multi-agent learning and planning. While Diplomacy is themed as a game of strategy where players control armies trying to gain control of provinces, it is a very abstract game - not unlike Chess or Checkers. It seems unlikely that real- world scenarios could be successfully reduced to the level of abstraction of a game like Diplomacy. In particular, our current algorithms assume a known rule set and perfect information between turns, whereas the real world would require planning algorithms that can manage uncertainty robustly. Future Impact. In providing the capability of training a tactical baseline agent for Diplomacy or similar games, this work also paves the way for research into agents that are capable of forming alliances and use more advanced communication abilities, either with other machines or with humans. In Diplomacy and related games this may lead to more interesting AI partners to play with. More generally, this line of work may inspire further work on problems of cooperation. We believe that a key skill for a Diplomacy player is to ensure that, wherever possible, their pairwise interactions with other players are positive sum. AIs able to play Diplomacy at human level must be able to achieve this in spite of the incentive to unilaterally exploit trust established with other agents. More long term, this work may pave the way towards research into agents that play the full version of the game of Diplomacy, which includes communication. In this version, communication is used to broker deals and form alliances, but also to misrepresent situations and intentions. For example, agents may learn to establish trust, but might also exploit that trust to mislead their co-players and gain the upper hand. In this sense, this work may facilitate the development of manipulative agents that use false communication as a means to achieve their goals. To mitigate this risk, we propose using games like Diplomacy to study the emergence and detection of manipulative behaviours in a sandbox — to make sure that we know how to mitigate such behaviours in real-world applications. Overall, our work provides an algorithmic building block for finding good strategies in many-agent systems. While prior work has shown that the default behaviour of independent reinforcement learning agents can be non-cooperative [74, 36, 54], we believe research on Diplomacy could pave the way towards creating artificial agents that can successfully cooperate with others, including handling difficult questions that arise around establishing and maintaining trust and alliances.",Broader Impact,673,28,,,FALSE,TRUE,FALSE,Learning to Play No-Press Diplomacy with Best Response Policy Iteration,Reinforcement Learning and Planning -> Multi-Agent RL,Applications -> Game Playing; Reinforcement Learning and Planning; Reinforcement Learning and Planning -> Model-Based RL; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> Game Theory and Computational Economics,Reinforcement learning and planning,"['Thomas Anthony', ' Tom Eccles', ' Andrea Tacchetti', ' János Kramár', ' Ian Gemp', ' Thomas Hudson', ' Nicolas Porcel', ' Marc Lanctot', ' Julien Perolat', ' Richard Everett', ' Satinder Singh', ' Thore Graepel', ' Yoram Bachrach']",{'DeepMind'},0,1,0,{'UK'}
Inverse Learning of Symmetries,"Mario Wieser, Sonali Parbhoo, Aleksander Wieczorek, Volker Roth",Inverse Learning of Symmetries,d15426b9c324676610fbb01360473ed8,https://proceedings.neurips.cc/paper/2020/file/d15426b9c324676610fbb01360473ed8-Paper.pdf,"Our society is currently faced with various existential threats such as climate change and fast spreading infectious diseases (Covid-19) that require immediate solutions. Many of these solutions, such as organic solar cells or drugs rely on the discovery of novel molecules. However, designing such molecules manually is heavily time-consuming as they have to fulfill specific properties. To overcome this limitation, we introduced a method to explore and generate candidate molecules that drastically speed up the discovery process. Despite the fact that our method constitutes an important contribution to tackle the described challenges, there might also be negative consequences. A potential downside is that drugs or techniques which rely on this method might not be available to individuals in developing countries for economic reasons. Therefore, it is crucial for us as a community as well as a society to monitor the usage of such models and correct potential deficiencies.",7 Broader Impact,148,7,,,FALSE,FALSE,FALSE,Inverse Learning of Symmetries,Deep Learning -> Deep Autoencoders,Deep Learning -> Generative Models,Deep learning,"['Mario Wieser', ' Sonali Parbhoo', ' Aleksander Wieczorek', ' Volker Roth']","{'Harvard University', 'University of Basel'}",1,0,0,"{'USA', 'Switzerland'}"
DiffGCN: Graph Convolutional Networks via Differential Operators and Algebraic Multigrid Pooling,"Moshe Eliasof, Eran Treister",DiffGCN: Graph Convolutional Networks via Differential Operators and Algebraic Multigrid Pooling,d16a974d4d6d0d71b29bfbfe045f1da7,https://proceedings.neurips.cc/paper/2020/file/d16a974d4d6d0d71b29bfbfe045f1da7-Paper.pdf,"The method we propose can be used for additional tasks in which the data have a geometric meaning. For instance, data sourced from geographic information systems (GIS) can be used for prediction of elections results [64]. Thus, it may have an impact on other fields. In addition, our method is lighter than other GCNs, which can be beneficial for power and time consumption. We are not aware of an ethical problem or negative societal consequences.",Broader Impact,75,5,,,FALSE,FALSE,FALSE,DiffGCN: Graph Convolutional Networks via Differential Operators and Algebraic Multigrid Pooling,Applications -> Computer Vision,"Algorithms -> Classification; Applications -> Object Recognition; Deep Learning -> CNN Architectures; Deep Learning -> Predictive Models; Deep Learning -> Supervised Deep Networks; Deep Learning -> Visualization, Interpretability, and Explainability",Graph Neural Networks,"['Moshe Eliasof', ' Eran Treister']",{'Ben-Gurion University of the Negev'},1,0,0,{'Israel'}
Distributed Newton Can Communicate Less and Resist Byzantine Workers,"Avishek Ghosh, Raj Kumar Maity, Arya Mazumdar",Distributed Newton Can Communicate Less and Resist Byzantine Workers,d17e6bcbcef8de3f7a00195cfa5706f1,https://proceedings.neurips.cc/paper/2020/file/d17e6bcbcef8de3f7a00195cfa5706f1-Paper.pdf,"The advent of computationally-intensive machine learning (ML) models has changed the technology landscape in the past decade. The most powerful learning models are also the most expensive to train. For example, OpenAI’s GPT-3 language model has 175 billion parameters and takes USD 12 million to train 1 ! On top of that machine learning training has a costly environmental footprint: recent study shows that training a transformer with neural architecture search can have as much as five times CO 2 emission of a standard car in its lifetime 2 . While the really expensive models are relatively rare, training of moderately large ML models is now ubiquitous over the data science industry and elsewhere. Most of the training of machine learning model today is performed in distributed platforms  (such as Amazon’s EC2). Any savings in energy - in forms of computation or communication - in distributed optimization will have a large positive impact. This paper seeks to speed up distributed optimization algorithms by minimizing inter-server communication and at the same time makes the optimization algorithms robust to adversarial failures. The protocols resulting from this paper are immediately implementable and can be adapted to any large scale distributed training of a machine learning model. Further, since our algorithms are robust to Byzantine failure, the training process becomes more reliable and fail-safe. In addition to that, we think the theoretical content of this paper is instructive and some elements can be included in the coursework of a graduate class of distributed optimization, to exemplify the trade-off between some fundamental quantities in distributed optimization. 1 https://venturebeat.com/2020/06/01/ai-machine-learning-openai-gpt-3-size-isnt-everything/ 2 MIT Tech. Review article dated 2019/06/06",Broader Impact,270,13,,,TRUE,TRUE,FALSE,Distributed Newton Can Communicate Less and Resist Byzantine Workers,Optimization,Algorithms -> Adversarial Learning; Algorithms -> Communication- or Memory-Bounded Learning; Algorithms -> Large Scale Learning; Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Avishek Ghosh', ' Raj Kumar Maity', ' Arya Mazumdar']","{'University of California, Berkeley', 'University of Massachusetts Amherst'}",1,0,0,{'USA'}
Efficient Nonmyopic Bayesian Optimization via One-Shot Multi-Step Trees,"Shali Jiang, Daniel Jiang, Maximilian Balandat, Brian Karrer, Jacob Gardner, Roman Garnett",Efficient Nonmyopic Bayesian Optimization via One-Shot Multi-Step Trees,d1d5923fc822531bbfd9d87d4760914b,https://proceedings.neurips.cc/paper/2020/file/d1d5923fc822531bbfd9d87d4760914b-Paper.pdf,"The central concern of this investigation is Bayesian optimization of an expensive-to-evaluate objective function. As is standard in this body of literature, our proposed algorithms make minimal assumptions about the objective, effectively treating it as a “black box.” This abstraction is mathemat- ically convenient but ignores ethical issues related to the chosen objective. Traditionally, Bayesian optimization has been used for a variety of applications, including materials design and drug discovery [7], and could have future applications to algorithmic fairness. We anticipate that our methods will be utilized in these reasonable applications, but there is nothing inherent to this work, and Bayesian optimization as a field more broadly, that preclude the possibility of optimizing a nefarious or at least ethically complicated objective.",Broader Impact,121,4,,,FALSE,FALSE,FALSE,Efficient Nonmyopic Bayesian Optimization via One-Shot Multi-Step Trees,Probabilistic Methods -> Gaussian Processes,Algorithms -> Active Learning; Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Shali Jiang', ' Daniel Jiang', ' Maximilian Balandat', ' Brian Karrer', ' Jacob Gardner', ' Roman Garnett']","{'University of Pennsylvania', 'Facebook'}",1,1,1,{'USA'}
Effective Diversity in Population Based Reinforcement Learning,"Jack Parker-Holder, Aldo Pacchiano, Krzysztof M. Choromanski, Stephen J. Roberts",Effective Diversity in Population Based Reinforcement Learning,d1dc3a8270a6f9394f88847d7f0050cf,https://proceedings.neurips.cc/paper/2020/file/d1dc3a8270a6f9394f88847d7f0050cf-Paper.pdf,"We believe our approach could be relevant for a multitude of settings, from population-based methods [32] to ensembles of models [39, 29]. There are two benefits to increased diversity: 1. The biggest short term advantage is performance gains for existing methods. We see improved sample efficiency and asymptotic gains from our approach to diversity, which may benefit any application with a population of agents [32] or ensemble of models. This may be used for a multitude of reasons, and one would hope the majority would be positive, such as model-based reinforcement learning for protein folding [2] (with an ensemble). 2. Having more diverse members of an ensemble may improve generalization, since it reduces the chance of models overfitting to the same features. This may improve robustness, helping real-world applications of reinforcement learning (RL). It may also lead to fairer algorithms, since a diverse ensemble may learn to make predictions based on a broader range of characteristics. For reinforcement learning specifically, we believe our behavioral embeddings can be used as the new standard for novelty search methods. We have shown these representations are robust to design choices, and can work across a variety of tasks without domain knowledge. This counteracts a key weakness of existing novelty search methods, as noted by [26]. In addition, we are excited by future work building upon this, potentially by learning embeddings (as in [16]).",Broader Impact,229,13,,,FALSE,FALSE,FALSE,Effective Diversity in Population Based Reinforcement Learning,Reinforcement Learning and Planning,Deep Learning -> Optimization for Deep Networks; Optimization -> Evolutionary Computation ; Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Hierarchical RL,Reinforcement learning and planning,"['Holder', ' Aldo Pacchiano', ' Krzysztof M Choromanski', ' Stephen J Roberts']","{'UC Berkeley', 'Google Brain Robotics', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Class-Imbalanced Data,"Utkarsh Ojha, Krishna Kumar Singh, Cho-Jui Hsieh, Yong Jae Lee",Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Class-Imbalanced Data,d1e39c9bda5c80ac3d8ea9d658163967,https://proceedings.neurips.cc/paper/2020/file/d1e39c9bda5c80ac3d8ea9d658163967-Paper.pdf,"Image datasets, particularly the ones with human faces, have a potential problem of not being diverse enough. This conceptualizes in some form of imbalance in the dataset, where, for example, a dataset of human faces might not represent faces from all ethnical communities in appropriate proportions. A popular application of GANs is to use synthetic images for data augmentations. With traditional GANs, however, it is possible that the underrepresented classes might not be modeled as accurately (mode dropping problem), thus limiting their applicability. The idea presented in this work is specifically tailored to handle such cases, by discovering both, the over and under-represented classes. This could then enable data augmentation using generated images, and help increase the proportions of underrepresented classes. GANs in general pose some ethical concerns, in terms of creating/altering visual content (e.g., deepfakes). Our work, which is a derivative of GAN, is no exception in that regard, as it could have some malicious applications, such as image fabrication. We do want to point out that such applications are not that straightforward with the method proposed in its current form, as our method doesn’t operate directly on real images (the input to the generator is latent vectors).",Broader Impact,199,9,,,FALSE,FALSE,FALSE,Elastic-InfoGAN: Unsupervised Disentangled Representation Learning in Class-Imbalanced Data,Algorithms -> Representation Learning,Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Utkarsh Ojha', ' Krishna Kumar Singh', 'Jui Hsieh', ' Yong Jae Lee']","{'UCLA', 'University of California Davis', 'University of California, Davis'}",1,0,0,{'USA'}
Direct Policy Gradients: Direct Optimization of Policies in Discrete Action Spaces,"Guy Lorberbom, Chris J. Maddison, Nicolas Heess, Tamir Hazan, Daniel Tarlow",Direct Policy Gradients: Direct Optimization of Policies in Discrete Action Spaces,d1e7b08bdb7783ed4fb10abe92c22ffd,https://proceedings.neurips.cc/paper/2020/file/d1e7b08bdb7783ed4fb10abe92c22ffd-Paper.pdf,"This work presents a general theoretical and algorithmic contribution to reinforcement learning (RL) research. One contribution (Appendix A.3) is an analysis of the risk-sensitive behavior of the algorithm as parameter is varied. This provides an axis of control beyond simply maximizing expected future reward, which is likely a beneficial analysis to perform (though far-removed from well-defined impacts). We’ll refrain from commenting on the future societal consequences of general advances in RL research, because this work is more theoretical and conceptual in nature, and it is a complex topic that is better covered in the context of work that is closer to specific impacts.",Broader Impact,103,4,,,FALSE,FALSE,FALSE,Direct Policy Gradients: Direct Optimization of Policies in Discrete Action Spaces,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Stochastic Methods; Probabilistic Methods -> Latent Variable Models,Reinforcement learning and planning,"['Guy Lorberbom', ' Maddison', ' Nicolas Heess', ' Tamir Hazan', ' Daniel Tarlow']","{'Google Brain', 'Technion', 'Google DeepMind', 'University of Toronto'}",1,1,1,"{'Canada', 'UK', 'USA', 'Israel'}"
Hybrid Models for Learning to Branch,"Prateek Gupta, Maxime Gasse, Elias Khalil, Pawan Mudigonda, Andrea Lodi, Yoshua Bengio",Hybrid Models for Learning to Branch,d1e946f4e67db4b362ad23818a6fb78a,https://proceedings.neurips.cc/paper/2020/file/d1e946f4e67db4b362ad23818a6fb78a-Paper.pdf,"This paper establishes a bridge between the work done in ML in the last years on learning to branch and the traditional MILP solvers used to routinely solve thousands of optimization applications in energy, telecommunications, logistics, biology, just to mention a few. The MILP solvers are executed on CPU-only machines and the technical challenge of using GPU- based algorithmic techniques to hybridize them had been neglected thus far. Admittedly, such a challenge was not urgent when the learning to branch literature was in its early stages. That situation has changed drastically with the GNN implementation in [17], the first approach to show significant benefit with respect to the default version of a state-of-the-art MILP solver like SCIP. For this reason, the current paper comes at the due time for the literature in the field and addresses the challenge, for the first time, in a sophisticated, yet relatively simple way. Thus, our work provides the first viable way for commercial and noncommercial MILP solver developers to implement and integrate a ML-based “learning to branch"" framework and for hundreds of thousands of users and practitioners to use it. In an even broader sense, the fact that we were able to approximate the performance of GPU-based models with a sophisticated integration of CPU-based techniques is consistent with, for example, Hinton et al. [25], and widens the space of problems to which ML techniques can be successfully applied.",Broader Impact,234,8,,,FALSE,FALSE,FALSE,Hybrid Models for Learning to Branch,Optimization -> Discrete Optimization,Applications -> Automated Reasoning and Formal Methods; Applications -> Hardware and Systems,Optimization Methods (continuous or discrete),"['Prateek Gupta', ' Maxime Gasse', ' Elias Khalil', ' Pawan K Mudigonda', ' Andrea Lodi', ' Yoshua Bengio']","{'University of Toronto', 'École Polytechnique Montréal', 'University of Oxford', 'Polytechnique Montréal'}",1,0,0,"{'Canada', 'UK'}"
WoodFisher: Efficient Second-Order Approximation for Neural Network Compression,"Sidak Pal Singh, Dan Alistarh",WoodFisher: Efficient Second-Order Approximation for Neural Network Compression,d1ff1ec86b62cd5f3903ff19c3a326b2,https://proceedings.neurips.cc/paper/2020/file/d1ff1ec86b62cd5f3903ff19c3a326b2-Paper.pdf,"Our work provides a general method for estimating second-order information at the scale of neural networks, and applies it to obtain state-of-the-art results on model compression. Our aim in doing so is to improve the performance of such machine learning applications. We apply our method to image classification, but our methods could be extended to any applications of neural networks. Our work could enable new, highly-accurate compressed models reducing inference times and resources required. The impact of any such application, such as for instance in surveillance, would need to be analyzed on a case-by-case basis and goes back to broader questions about the applicability of machine learning.",Broader Impact,107,5,,,FALSE,FALSE,FALSE,WoodFisher: Efficient Second-Order Approximation for Neural Network Compression,Algorithms -> Sparsity and Compressed Sensing,Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,Resource aware machine learning,"['Sidak Pal Singh', ' Dan Alistarh']",{'EPFL'},1,0,0,{'Switzerland'}
Bi-level Score Matching for Learning Energy-based Latent Variable Models,"Fan Bao, Chongxuan LI, Taufik Xu, Hang Su, Jun Zhu, Bo Zhang",Bi-level Score Matching for Learning Energy-based Latent Variable Models,d25a34b9c2a87db380ecd7f7115882ec,https://proceedings.neurips.cc/paper/2020/file/d25a34b9c2a87db380ecd7f7115882ec-Paper.pdf,"In many real world applications, such as bioinformatics, social network analysis and so on, sometimes energy-based models are preferable than directed models. The ability of the proposed BiSM to learn general energy-based latent variable models can potentially benefit such applications and therefore benefit the society. However, as a way to train deep generative models, this work can be abused to produce fake images, videos and news, similarly to the generative adversarial nets.",Broader Impact,72,3,,,FALSE,FALSE,FALSE,Bi-level Score Matching for Learning Energy-based Latent Variable Models,Deep Learning -> Generative Models,,Probabilistic methods and inference,"['Fan Bao', ' Chongxuan LI', ' Taufik Xu', ' Hang Su', ' Jun Zhu', ' Bo Zhang']","{'Tsinghua Univiersity', 'Tsinghua University'}",1,0,0,{'China'}
Counterfactual Contrastive Learning for Weakly-Supervised Vision-Language Grounding,"Zhu Zhang, Zhou Zhao, Zhijie Lin, jieming zhu, Xiuqiang He",Counterfactual Contrastive Learning for Weakly-Supervised Vision-Language Grounding,d27b95cac4c27feb850aaa4070cc4675,https://proceedings.neurips.cc/paper/2020/file/d27b95cac4c27feb850aaa4070cc4675-Paper.pdf,"This paper introduces a novel CCL paradigm for weakly-supervised vision-language grounding and improves grounding performance. Vision-language grounding is a crucial technique in multi-modal understanding and can be applied to the human-computer interaction field. So this research can promote the development of a multi-modal interaction system and facilitate people’s daily lives. And the exploration of weakly-supervised training in this paper can save the labor cost for data annotations. The failure of this technique may lead to an inaccurate multi-modal understanding and cause the mistake of the system based on the grounding results. Moreover, we validate our method on large-scale public vision-language datasets and do not leverage biases in the data.",Broader Impact,109,6,,,FALSE,FALSE,FALSE,Counterfactual Contrastive Learning for Weakly-Supervised Vision-Language Grounding,Applications -> Computer Vision,Applications -> Activity and Event Recognition; Applications -> Video Analysis,,"['Zhu Zhang', ' Zhou Zhao', ' Zhijie Lin', ' jieming zhu', ' Xiuqiang He']",{'Zhejiang University'},1,0,0,{'China'}
Decision trees as partitioning machines to characterize their generalization properties,"Jean-Samuel Leboeuf, Frédéric LeBlanc, Mario Marchand",Decision trees as partitioning machines to characterize their generalization properties,d2a10b0bd670e442b1d3caa3fbf9e695,https://proceedings.neurips.cc/paper/2020/file/d2a10b0bd670e442b1d3caa3fbf9e695-Paper.pdf,This work could be profitable to machine learning practitioners that use decision trees to produce predictive models. The methods and results presented in this work are not incompatible with methods that try to correct the bias present in some datasets and with machine learning fairness methods that should be applied when the learned model attempts to make predictions on some aspects of human behaviour.,Broader Impact,64,2,,,FALSE,FALSE,FALSE,Decision trees as partitioning machines to characterize their generalization properties,Theory -> Statistical Learning Theory,Algorithms -> Classification; Algorithms -> Model Selection and Structure Learning; Theory -> Computational Learning Theory,Theory (including computational and statistical analyses),"['Samuel Leboeuf', ' Frédéric LeBlanc', ' Mario Marchand']","{'Université de Moncton', 'Université Laval'}",1,0,0,{'Canada'}
Learning to Prove Theorems by Learning to Generate Theorems,"Mingzhe Wang, Jia Deng",Learning to Prove Theorems by Learning to Generate Theorems,d2a27e83d429f0dcae6b937cf440aeb1,https://proceedings.neurips.cc/paper/2020/file/d2a27e83d429f0dcae6b937cf440aeb1-Paper.pdf,"Our work addresses automated theorem proving. A successful automated theorem prover can help us write programs that are provably correct, which is essential to safety-critical applications, such as software for autonomous driving. On the other hand, since the correctness of the found proofs and synthesized programs relies on the correctness of the underlying theorem prover, bugs in the prover can lead to catastrophic failure.",Broader Impact,64,3,,,FALSE,FALSE,FALSE,Learning to Prove Theorems by Learning to Generate Theorems,Applications -> Automated Reasoning and Formal Methods,,Formal reasoning.,"['Mingzhe Wang', ' Jia Deng']","{'Princeton University', 'Pinceton University'}",1,0,0,{'USA'}
3D Self-Supervised Methods for Medical Imaging,"Aiham Taleb, Winfried Loetzsch, Noel  Danz, Julius Severin, Thomas Gaertner, Benjamin Bergner, Christoph Lippert",3D Self-Supervised Methods for Medical Imaging,d2dc6368837861b42020ee72b0896182,https://proceedings.neurips.cc/paper/2020/file/d2dc6368837861b42020ee72b0896182-Paper.pdf,"Due to technological advancements in 3D data sensing, and to the growing number of its applications, the attention to machine learning algorithms that perform analysis tasks on such data has grown rapidly in the past few years. As mentioned before, 3D imaging has multitude of applications [2], such as in Robotics, in CAD imaging, in Geology, and in Medical Imaging. In this work, we developed multiple 3D Deep Learning algorithms, and evaluated them on multiple 3D medical imaging benchmarks. Our focus on medical imaging is motivated by the pressing demand for automatic (and instant) analysis systems, that may aid the medical community. Medical imaging plays an important role in patient healthcare, as it aids in disease prevention, early detection, diagnosis, and treatment. With the continuous digitization of medical images, the hope that physicians and radiologists are able to instantly analyze them with Machine Learning algorithms is slowly shaping as a reality. Achieving this has become more critical recently, as the number of patients which contracted with a novel Coronavirus, called COVID-19, reached a high record. Radiography images provide a rich and a quick diagnosis tool, because other types of tests, e.g. RT-PCR which is an RNA/DNA based test, have low sensitivity and may require hours/days of processing [71]. Therefore, as imaging allows such instant insights into human body organs, it receives growing attention from both machine learning and medical communities. Yet efforts to leverage advancements in machine learning, particularly the supervised algorithms, are often hampered by the sheer expense of expert annotation required [4]. Generating expert annotations of patient data at scale is non-trivial, expensive, and time-consuming, especially for 3D medical scans. Even current semi-automatic software tools fail to sufficiently address this challenge. Consequently, it is necessary to rely on annotation-efficient machine learning algorithms, such as self-supervised (unsupervised) approaches for representation learning from unlabelled data. Our work aims to provide the necessary tools for 3D image analysis, in general, and to aid physicians and radiologists in their diagnostic tasks from 3D scans, in particular. And as the main consequence of this work, the developed methods can help reduce the effort and cost of annotation required by these practitioners. In the larger goal of leveraging Machine Learning for good, our work is only a small step toward achieving this goal for patient healthcare.",Broader Impact,382,16,,,FALSE,FALSE,FALSE,3D Self-Supervised Methods for Medical Imaging,Algorithms -> Representation Learning,Algorithms -> Unsupervised Learning; Applications -> Computer Vision; Applications -> Health; Deep Learning -> Embedding Approaches,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Aiham Taleb', ' Winfried Loetzsch', ' Noel Danz', ' Julius Severin', ' Thomas Gaertner', ' Benjamin Bergner', ' Christoph Lippert']","{'Hasso Plattner Institute for Digital Engineering', 'HPI', 'Hasso-Plattner-Institute, Potsdam University'}",1,0,0,{'Germany'}
Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods,Laurence Aitchison,Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods,d33174c464c877fb03e77efdab4ae804,https://proceedings.neurips.cc/paper/2020/file/d33174c464c877fb03e77efdab4ae804-Paper.pdf,"As neural networks are increasingly being used in safety-critical settings such as medical imaging, it is important to ensure that practical neural network optimizers are capable of achieving effective performance in limited training time. We provide a neural network optimization algorithm inspired by Bayesian filtering that is indeed capable of learning rapidly and generalising well. More importantly, by highlighting the connections between Bayesian inference and optimization, we hope to provide a general approach to building new optimization algorithms that will be exploited by future research.",6 Broader Impact,85,3,,,FALSE,FALSE,FALSE,Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods,Deep Learning -> Optimization for Deep Networks,Probabilistic Methods,,['Laurence Aitchison'],{'University of Cambridge'},1,0,0,{'UK'}
Worst-Case Analysis for Randomly Collected Data,"Justin Chen, Gregory Valiant, Paul Valiant",Worst-Case Analysis for Randomly Collected Data,d34a281acc62c6bec66425f0ad6dd645,https://proceedings.neurips.cc/paper/2020/file/d34a281acc62c6bec66425f0ad6dd645-Paper.pdf,"The question of how to extract accurate statistics based on nonuniform/biased samples is of utmost societal importance. And this basic question is still far from solved—one need only look to the consistent errors across political polls, or more recent discussion on estimating the rate of COVID exposure based on different strategies for recruiting participants and then “correcting” for these biased samples. The vast majority of work on accurate estimation is based on strong distributional assumptions on the data values. The risk is that when these assumptions do not hold, the estimates and their confidence bounds, are meaningless. In this work, we introduce a very general framework that allows one to ask (and answer) the question of whether a given data collection procedure can admit an estimation algorithm which will be accurate, even for worst-case data values. We hope that this framework, which we refer to as worst case analysis for randomly collected data , will offer better estimators in some settings, and offer new perspectives on collecting and inferring information from data samples.",Broader Impact,173,6,,,FALSE,FALSE,FALSE,Worst-Case Analysis for Randomly Collected Data,Theory -> Models of Learning and Generalization,Algorithms; Algorithms -> Uncertainty Estimation; Theory; Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)",,"{'Stanford', 'Stanford University', 'Brown University'}",1,0,0,{'USA'}
Truthful Data Acquisition via Peer Prediction,"Yiling Chen, Yiheng Shen, Shuran Zheng",Truthful Data Acquisition via Peer Prediction,d35b05a832e2bb91f110d54e34e2da79,https://proceedings.neurips.cc/paper/2020/file/d35b05a832e2bb91f110d54e34e2da79-Paper.pdf,"The results in this work are mainly theoretical. They contribute to the ongoing efforts on encouraging data sharing, ensuring data quality and distributing values of generated from data back to data contributors.",Broader Impact,32,2,FALSE,FALSE,FALSE,FALSE,FALSE,Truthful Data Acquisition via Peer Prediction,Theory -> Game Theory and Computational Economics,Theory -> Data-driven Algorithm Design,Theory (including computational and statistical analyses),"['Yiling Chen', ' Yiheng Shen', ' Shuran Zheng']","{'Harvard University', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Learning Robust Decision Policies from Observational Data,"Muhammad Osama, Dave Zachariah, Peter Stoica",Learning Robust Decision Policies from Observational Data,d3696cfb815ab692407d9362e6f06c28,https://proceedings.neurips.cc/paper/2020/file/d3696cfb815ab692407d9362e6f06c28-Paper.pdf,"We believe the work presented herein can provide a useful tool for decision support, especially in safety-critical applications where it is of interest to reduce the risk of incurring high costs. The methodology can leverage large and heterogeneous data on past decisions, contexts and outcomes, to improve human decision making, while providing an interpretable statistical guarantee for its recommendations. It is important, however, to consider the population from which the training data is obtained and used. If the method is deployed in a setting with a different population it may indeed fail to provide cost-reducing decisions. Moreover, if there are categories of features that are sensitive and subject to unwarranted biases, the population may need to be split into appropriate subpopulations or else the biases can be reproduced in the learned policies.",Broader Impact,132,5,,,FALSE,FALSE,FALSE,Learning Robust Decision Policies from Observational Data,Probabilistic Methods -> Causal Inference,Algorithms -> Uncertainty Estimation,Robust machine learning,"['Muhammad Osama', ' Dave Zachariah', ' Peter Stoica']",{'Uppsala University'},1,0,0,{'Sweden'}
Byzantine Resilient Distributed Multi-Task Learning,"Jiani Li, Waseem Abbas, Xenofon Koutsoukos",Byzantine Resilient Distributed Multi-Task Learning,d37eb50d868361ea729bb4147eb3c1d8,https://proceedings.neurips.cc/paper/2020/file/d37eb50d868361ea729bb4147eb3c1d8-Paper.pdf,"The problem of Byzantine resilient aggregation of distributed machine learning models has been actively studied in recent years; however, the issue of Byzantine resilient distributed learning in multi-task networks has received much less attention. It is a general intuition that MTL is robust and resilient to cyber-attacks since it can identify attackers by measuring similarities between neighbors. In this paper, we have shown that some commonly used similarity measures are not resilient against certain attacks. With an increase in data heterogeneity, we hope this work could highlight the security and privacy concerns in designing distributed MTL frameworks.",Broader Impact,97,4,,,FALSE,FALSE,FALSE,Byzantine Resilient Distributed Multi-Task Learning,Algorithms,"Algorithms -> Multitask and Transfer Learning; Algorithms -> Online Learning; Algorithms -> Similarity and Distance Learning; Optimization -> Convex Optimization; Optimization -> Stochastic Optimization; Social Aspects of Machine Learning -> Privacy, Anonymity, and Security","Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['JIANI LI', ' Waseem Abbas', ' Xenofon Koutsoukos']",{'Vanderbilt University'},1,0,0,{'USA'}
Reinforcement Learning in Factored MDPs: Oracle-Efficient Algorithms and Tighter Regret Bounds for the Non-Episodic Setting,"Ziping Xu, Ambuj Tewari",Reinforcement Learning in Factored MDPs: Oracle-Efficient Algorithms and Tighter Regret Bounds for the Non-Episodic Setting,d3b1fb02964aa64e257f9f26a31f72cf,https://proceedings.neurips.cc/paper/2020/file/d3b1fb02964aa64e257f9f26a31f72cf-Paper.pdf,"As a theoretical paper, we can not foresee any direct societal consequences in the near future. Factored MDP, the main problem we study in this paper, may be used in multi-agent Reinforcement Learning scenario.",8 Broader Impacts,34,2,TRUE,TRUE,FALSE,TRUE,FALSE,Reinforcement Learning in Factored MDPs: Oracle-Efficient Algorithms and Tighter Regret Bounds for the Non-Episodic Setting,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Model-Based RL,Reinforcement learning and planning,"['Ziping Xu', ' Ambuj Tewari']",{'University of Michigan'},1,0,0,{'USA'}
Improving model calibration with accuracy versus uncertainty optimization,"Ranganath Krishnan, Omesh Tickoo",Improving model calibration with accuracy versus uncertainty optimization,d3d9446802a44259755d38e6d163e820,https://proceedings.neurips.cc/paper/2020/file/d3d9446802a44259755d38e6d163e820-Paper.pdf,"As AI systems backed by deep learning are used in safety-critical applications like autonomous vehicles, medical diagnosis, robotics etc., it is important for these systems to be explainable and trustworthy for successful deployment in real-world. Having the ability to derive uncertainty estimates provides a big step towards explainability of AI systems based on Deep Learning. Having calibrated uncertainty quantification provides grounded means for uncertainty measurement in such models. A principled way to measure reliable uncertainty is the basis on which trustworthy AI systems can be built. Research results and multiple resulting frameworks have been released for AI Fairness measurement that base components of fairness quantification on uncertainty measurements of classified output of deep learning models. We believe that our work can be a big step towards measuring such uncertainties in a reliable fashion. The resulting, well calibrated, uncertainty measures can then be used as an input for building fair and trustworthy AI models that implement explainable behavior. This explanation is also critical for building AI systems that are robust to adversarial blackbox and whitebox attacks. These well calibrated uncertainties can guide AI practitioners to better understand the predictions for reliable decision making, i.e. to know “when to trust” and “when not to trust” the model predictions (especially in high-risk domains like healthcare, financial, legal etc). In addition, calibrated uncertainty opens the doors for wider adoption of deep network architectures in interesting applications like multimodal fusion, anomaly detection and active learning. Using calibrated uncertainty as a measure for distributional shift (out-of-distribution and dataset shift) detection is also a key enabler for self-learning systems that form a critical component of realizing the dream of Artificial General Intelligence (AGI).",Broader Impact,276,11,,,FALSE,FALSE,FALSE,Improving model calibration with accuracy versus uncertainty optimization,Algorithms -> Uncertainty Estimation,Algorithms -> Classification; Deep Learning -> Efficient Training Methods; Optimization -> Stochastic Optimization; Probabilistic Methods -> Variational Inference,Deep learning,"['Ranganath Krishnan', ' Omesh Tickoo']","{'Intel', 'Intel Labs'}",0,1,0,{'USA'}
The Convolution Exponential and Generalized Sylvester Flows,"Emiel Hoogeboom, Victor Garcia Satorras, Jakub Tomczak, Max Welling",The Convolution Exponential and Generalized Sylvester Flows,d3f06eef2ffac7faadbe3055a70682ac,https://proceedings.neurips.cc/paper/2020/file/d3f06eef2ffac7faadbe3055a70682ac-Paper.pdf,"This paper discusses methods to improve the flexibility of normalizing flows, a method to learn high-dimensional distributions. Methods based on our work could potentially be used to generate realistic looking photographs. On the other hand, distribution modelling could also be used for fraud detection via outlier detection, which could help detect generated media. In summary, we believe this method may be somewhat distant from direct applications, but a future derived method could be used in the above mentioned scenarios.",Broader Impact,79,4,,,FALSE,FALSE,FALSE,The Convolution Exponential and Generalized Sylvester Flows,Deep Learning -> Generative Models,Algorithms -> Unsupervised Learning,Deep learning,"['Emiel Hoogeboom', ' Victor Garcia Satorras', ' Jakub Tomczak', ' Max Welling']","{'University of Amsterdam', 'University of Amsterdam / Qualcomm AI Research', 'Qualcomm AI Research'}",1,1,1,"{'USA', 'Netherlands'}"
An Improved Analysis of Stochastic Gradient Descent with Momentum,"Yanli Liu, Yuan Gao, Wotao Yin",An Improved Analysis of Stochastic Gradient Descent with Momentum,d3f5d4de09ea19461dab00590df91e4f,https://proceedings.neurips.cc/paper/2020/file/d3f5d4de09ea19461dab00590df91e4f-Paper.pdf,"The results of this paper improves the performance of stochastic gradient descent with momentum as well as its multistage version. Our study will also benefit the machine learning community. We do not believe that the results in this work will cause any ethical issue, or put anyone at a disadvantage in our society.",Broader Impact,53,3,FALSE,TRUE,FALSE,FALSE,FALSE,An Improved Analysis of Stochastic Gradient Descent with Momentum,Optimization -> Stochastic Optimization,Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Yanli Liu', ' Yuan Gao', ' Wotao Yin']","{'UCLA', 'Columbia University', 'Alibaba US, DAMO Academy'}",1,1,1,"{'USA', 'China'}"
Precise expressions for random projections: Low-rank approximation and randomized Newton,"Michal Derezinski, Feynman T. Liang, Zhenyu Liao, Michael W. Mahoney",Precise expressions for random projections: Low-rank approximation and randomized Newton,d40d35b3063c11244fbf38e9b55074be,https://proceedings.neurips.cc/paper/2020/file/d40d35b3063c11244fbf38e9b55074be-Paper.pdf,"In this paper, we investigate the spectral properties of residual (random) projection matrices, com- monly appearing in various sketching-based methods. The precise theoretical description given in this paper provides performance guarantees for popular algorithms such as low-rank approximation and many randomized (iterative) optimization methods, and contributes to the development of more robust and reliable large-scale learning systems. The theoretical framework developed in this work presents no foreseeable negative societal consequence.",Broader Impact,70,3,TRUE,TRUE,FALSE,TRUE,FALSE,Precise expressions for random projections: Low-rank approximation and randomized Newton,Theory -> Computational Learning Theory,,Theory (including computational and statistical analyses),"['Michal Derezinski', ' Feynman T Liang', ' Zhenyu Liao', ' Michael W Mahoney']","{'UC Berkeley', 'University of California, Berkeley', 'Berkeley'}",1,0,0,{'USA'}
The MAGICAL Benchmark for Robust Imitation,"Sam Toyer, Rohin Shah, Andrew Critch, Stuart Russell",The MAGICAL Benchmark for Robust Imitation,d464b5ac99e74462f321c06ccacc4bff,https://proceedings.neurips.cc/paper/2020/file/d464b5ac99e74462f321c06ccacc4bff-Paper.pdf,"This paper presents a new benchmark for robust IL and argues for an increased focus on algorithms that can generalise demonstrator intent across different settings. We foresee several possible follow-on effects from improved IL robustness: Economic effects of automation Better IL generalisation could allow for increased automation in some sectors of the economy. This has the positive flow-on effect of increased economic productivity, but could lead to socially disruptive job loss. Because our benchmark focuses on robust IL in robotics-like environments, it’s likely that any effect on employment would be concentrated in sectors involving activities that are expensive to record. This could include tasks like surgery (where few demonstrators are qualified to perform the task, and privacy considerations make it difficult to collect data) or packaging retail goods for postage (where few-shot learning might be important when there are many different types of goods to handle). Identity theft and model extraction More robust IL could enable better imitation of specific people, and not just imitation of people in general. This could lead to identify theft, for instance by mimicking somebody’s speech or writing, or by fooling biometric systems. Because this benchmark focuses on control and manipulation rather than media synthesis, it’s unlikely that algorithms designed to solve our benchmark will be immediately useful for this purpose. On the other hand, this concern is still relevant when applied to machine behaviour, rather than human behaviour. In NLP, it’s known that weights for ML models can be “stolen” by observing the model’s outputs for certain carefully chosen inputs [28]. Similarly, more robust IL could make it possible to clone a robot’s policy by observing its behaviour, which could make it harder to sell robot control algorithms as standalone products. Learnt objectives Hadfield-Menell et al. [21] argues that it is desirable for AI systems to infer their objectives from human behaviour, rather than taking them as fixed. This can avoid problems that arise when an agent (human, robot, or organisation) doggedly pursues an easyto-measure but incorrect objective, such as a corporate executive optimising for quarterly profit (which is easy to measure) over long-term profitability (which is actually desired by shareholders). IL makes it possible to learn objectives from observed human behaviour, and more robust IL may therefore lead to AI systems that better serve their designers’ goals. However, it’s worth noting that unlike, say, HAMDPs [16] or CIRL games [21], IL cannot request clarification from a demonstrator if the supplied demonstrations are ambiguous, which limits its ability to learn the right objective in general. Nevertheless, we hope that insights from improved IL algorithms will still be applicable to such interactive systems.",7 Broader impact,438,17,,,TRUE,TRUE,FALSE,The MAGICAL Benchmark for Robust Imitation,Reinforcement Learning and Planning,"Algorithms -> Multitask and Transfer Learning; Applications -> Robotics; Data, Challenges, Implementations, and Software -> Benchmarks; Reinforcement Learning and Planning -> Reinforcement Learning",Reinforcement learning and planning,"['Sam Toyer', ' Rohin Shah', ' Andrew Critch', ' Stuart Russell']",{'UC Berkeley'},1,0,0,{'USA'}
X-CAL: Explicit Calibration for Survival Analysis,"Mark Goldstein, Xintian Han, Aahlad Puli, Adler Perotte , Rajesh Ranganath",X-CAL: Explicit Calibration for Survival Analysis,d4a93297083a23cc099f7bd6a8621131,https://proceedings.neurips.cc/paper/2020/file/d4a93297083a23cc099f7bd6a8621131-Paper.pdf,"In this paper, we study calibration of survival analysis models and suggest an objective for improving calibration during model training. Since calibration means that modeled probabilities correspond to the actual observed risk of an event, practitioners may feel more confident about using model outputs directly for decision making e.g. to decide how many emergency room staff members qualified for performing a given procedure should be present tomorrow given all current ER patients. But if the distribution of event times in these patients differs from validation data, because say the population has different demographics, calibration should not provide the practitioner with more confidence to directly use such model outputs.",Broader Impact,108,3,,,FALSE,FALSE,FALSE,X-CAL: Explicit Calibration for Survival Analysis,Applications -> Health,,Healthcare,"['Xintian Han', ' Mark Goldstein', ' Aahlad Manas Puli', ' Adler Perotte', ' Rajesh Ranganath']","{'New York University', 'Columbia University', 'NYU'}",1,0,0,{'USA'}
Decentralized Accelerated Proximal Gradient Descent,"Haishan Ye, Ziang Zhou, Luo Luo, Tong Zhang",Decentralized Accelerated Proximal Gradient Descent,d4b5b5c16df28e61124e13181db7774c,https://proceedings.neurips.cc/paper/2020/file/d4b5b5c16df28e61124e13181db7774c-Paper.pdf,"Our work focuses on the decentralized optimization which has been applied in multi-robot system such as to optimize the motion of multiple robots. Our efficient decentralized algorithm maybe promotes the performance of some multi-robot systems. However, due to wide applications of robots in wars, our algorithm may also cause some negative consequences.",6 Broader Impact,52,3,FALSE,FALSE,FALSE,FALSE,FALSE,Decentralized Accelerated Proximal Gradient Descent,Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Haishan Ye', ' Ziang Zhou', ' Luo Luo', ' Tong Zhang']","{'The Chinese University of Hong Kong, Shenzen', 'The Hong Kong University of Science and Technology', 'Hong Kong University of Science and Technology', 'Fudan University'}",1,0,0,{'China'}
Making Non-Stochastic Control (Almost) as Easy as Stochastic,Max Simchowitz,Making Non-Stochastic Control (Almost) as Easy as Stochastic,d4ca950da1d6fd954520c45ab19fef1c,https://proceedings.neurips.cc/paper/2020/file/d4ca950da1d6fd954520c45ab19fef1c-Paper.pdf,"Though this paper is primarily theoretical in nature, we believe that the non-stochastic control setting is an important one. Historically, one of the greatest strengths of control theory is its ability to provide robust, mathematical guarantees on performance quality. As control theory merges with recent developments in reinforcement learning, we see novel applications in domains with little room for error: control algorithms in automated transportation, server cooling, and industrial robotics can wreak havoc when gone awry. These tasks may range from easy-to-model to wildly unpredictable, and purely stochastic models may not suffice to capture the full extent of the uncertainty in the task. On the other hand, traditional techniques from robust control may be overly conservative, and deem certain tasks infeasible from the outset. While far from perfect, we believe that the non-stochastic control model inches us closer towards robustness to modeling assumptions, without succumbing to excessive pessimism. As such, we find it important to understand what, if any, challenges this more accomodating model poses to data-driven control. We hope that our central theoretical contribution - demonstrating that the uncertainty in the noise model is in fact not a significant barrier to achieving near optimal performance - may encour- age practioners not to abandon considerations of robustness for fear of sacrificing performance. But there is still a long road ahead, and we recognize that non-stochastic control does not capture many important senses of robustness in the decades-old control literature. We also recognize that there are, and will continue to be, instances when performance must be sacrificed for robustness, and hope our work will contribute a small but helpful part in a broader dialogue about the tensions between safety and performance in data-driven control.",Broader Impact,283,10,,,FALSE,FALSE,FALSE,Making Non-Stochastic Control (Almost) as Easy as Stochastic,Theory -> Control Theory,Algorithms -> Online Learning; Reinforcement Learning and Planning -> Decision and Control,Reinforcement learning and planning,['Max Simchowitz'],{'Berkeley'},1,0,0,{'USA'}
BERT Loses Patience: Fast and Robust Inference with Early Exit,"Wangchunshu Zhou, Canwen Xu, Tao Ge, Julian McAuley, Ke Xu, Furu Wei",BERT Loses Patience: Fast and Robust Inference with Early Exit,d4dd111a4fd973394238aca5c05bebe3,https://proceedings.neurips.cc/paper/2020/file/d4dd111a4fd973394238aca5c05bebe3-Paper.pdf,"As an efficient inference technique, our proposed PABEE can facilitate more applications on mobile and edge computing, and also help reduce energy use and carbon emission [54]. Since our method serves as a plug-in for existing pretrained language models, it does not introduce significant new ethical concerns but more work is needed to determine its effect on biases (e.g., gender bias) that have already been encoded in a PLM.",Broader Impact,69,2,,,FALSE,FALSE,FALSE,BERT Loses Patience: Fast and Robust Inference with Early Exit,Applications -> Natural Language Processing,Deep Learning -> Efficient Inference Methods,Natural language processing,"['Wangchunshu Zhou', ' Canwen Xu', ' Tao Ge', ' Julian McAuley', ' Ke Xu', ' Furu Wei']","{'Beihang University', 'Wuhan University', 'Microsoft Research Asia', 'UCSD'}",1,1,1,"{'USA', 'China'}"
Optimal and Practical Algorithms for Smooth and Strongly Convex Decentralized Optimization,"Dmitry Kovalev, Adil SALIM, Peter Richtarik",Optimal and Practical Algorithms for Smooth and Strongly Convex Decentralized Optimization,d530d454337fb09964237fecb4bea6ce,https://proceedings.neurips.cc/paper/2020/file/d530d454337fb09964237fecb4bea6ce-Paper.pdf,"Our paper is of a fundamental theoretical nature. We designed new decentralized optimization algorithms, and proved that they are optimal in a certain rigorous mathematical sense. We trust that our methods will have impact wherever decentralized optimization is needed and used, at present (e.g., sensor networks) and in the future (e.g., fully decentralized federated learning). Having said that, our methods are generic as we did not investigate any particular application. Hence, we do not expect any immediate societal impact beyond impact on the research community developing the foundational tools for AI. We hope, however, that AI practitioners will be inspired by this work and will use the fruits of our labor to benefit humanity through concrete applications and machine learning models.",6 Broader Impact,121,6,,,FALSE,FALSE,FALSE,Optimal and Practical Algorithms for Smooth and Strongly Convex Decentralized Optimization,Algorithms -> Communication- or Memory-Bounded Learning,Optimization -> Convex Optimization,,"['Dmitry Koralev', ' Adil SALIM', ' Peter Richtarik']",{'KAUST'},1,0,0,{'Saudi Arabia'}
BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning,"Xinyue Chen, Zijian Zhou, Zheng Wang, Che Wang, Yanqiu Wu, Keith Ross",BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning,d55cbf210f175f4a37916eafe6c04f0d,https://proceedings.neurips.cc/paper/2020/file/d55cbf210f175f4a37916eafe6c04f0d-Paper.pdf,"This research may potentially lead to mechanisms for training robots and self-driving vehicles to perform complex tasks. Batch RL enables reusing the data collected by a policy to possibly improve the policy without further interactions with the environment. A batch RL algorithm can be deployed as part of a growing-batch algorithm, where the batch algorithm seeks a high-performing exploitation policy using the data in an experience replay buffer, combines this policy with exploration to add fresh data to the buffer, and then repeats the whole process. Batch RL may also be necessary for learning a policy in safety-critical systems where a partially trained policy cannot be deployed online to collect data. Compared to policy constraint methods discussed in the paper, BAIL uses a much smaller amount of computation to achieve good performance, its efficiency means a smaller computation cost and less consumption of energy.",Broader Impact,144,5,,,FALSE,FALSE,FALSE,BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Deep Learning,Reinforcement learning and planning,"['Xinyue Chen', ' Zijian Zhou', ' Zheng Wang', ' Che Wang', ' Yanqiu Wu', ' Keith Ross']","{'New York University', 'NYU Shanghai'}",1,0,0,"{'USA', 'China'}"
Regularizing Towards Permutation Invariance In Recurrent Models,"Edo Cohen-Karlik, Avichai Ben David, Amir Globerson",Regularizing Towards Permutation Invariance in Recurrent Models,d58f36f7679f85784d8b010ff248f898,https://proceedings.neurips.cc/paper/2020/file/d58f36f7679f85784d8b010ff248f898-Paper.pdf,"In this work, we analyze an approach for learning recurrent models in cases where there is an underlying permutation invariance. The method can improve sequence labeling systems. We do not see any ethical aspects with the contribution. Societal aspects are positive in terms of improving accuracy of models in healthcare for example.",8 Broader Impact,52,4,FALSE,FALSE,FALSE,FALSE,FALSE,Regularizing Towards Permutation Invariance In Recurrent Models,Deep Learning -> Recurrent Networks,,Deep learning,"['Karlik', ' Avichai Ben David', ' Amir Globerson']","{'Tel Aviv University, Google', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
What Did You Think Would Happen? Explaining Agent Behaviour through Intended Outcomes,"Herman Ho-Man Yau, Chris Russell, Simon Hadfield",What Did You Think Would Happen? Explaining Agent Behaviour through Intended Outcomes,d5ab8dc7ef67ca92e41d730982c5c602,https://proceedings.neurips.cc/paper/2020/file/d5ab8dc7ef67ca92e41d730982c5c602-Paper.pdf,"By making important early steps into explainability for Reinforcement Learning, this work has strong potential impact across a broad range of areas from autonomous vehicles to medical robotics. Beneficiaries of this work include researchers and developers who wish to gain additional insight into their agents behaviour, in order to improve performance. Additionally, if accidents arise in a deployed system, our work provides a mechanism to introspect these and attempt to prevent the same thing from happening in the future. A failure in the proposed system could lead to an incorrect intention being attributed to an agents behaviour. Our proofs show that this cannot happen for table-based Q-learning, but it is potentially possible for DQN. An incorrectly attributed intention could potentially lead to unnecessary or harmful remedial action being taken to correct the agents behaviour. In extreme cases a failure of the system may lead to accountability being incorrectly attributed. Therefore it is vital to keep in mind the limitations of the theoretical guarantees provided with this work. Our technique does not rely on any dataset biases. However the generated explanations are specific to a single instance of an agent’s policy. There are no guarantees about generalization of intention between agents, even those which are similarly trained.",Broader Impact,206,11,,,FALSE,FALSE,FALSE,What Did You Think Would Happen? Explaining Agent Behaviour through Intended Outcomes,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Deep Learning -> Visualization, Interpretability, and Explainability; Neuroscience and Cognitive Science -> Reasoning","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Ho Man Herman Yau', ' Chris Russell', ' Simon Hadfield']","{'University of Surrey', 'The Alan Turing Institute/ The University of Surrey'}",1,0,0,{'UK'}
Batch normalization provably avoids ranks collapse for randomly initialised deep networks,"Hadi Daneshmand, Jonas Kohler, Francis Bach, Thomas Hofmann, Aurelien Lucchi",Batch Normalization Provably Avoids Rank Collapse for Randomly Initialised Deep Networks,d5ade38a2c9f6f073d69e1bc6b6e64c1,https://proceedings.neurips.cc/paper/2020/file/d5ade38a2c9f6f073d69e1bc6b6e64c1-Paper.pdf,"As we only contribute to a better understanding of neural network training in general, we consider our work fundamental research without any specific application. Hence a broader impact discussion is not applicable.",Broader impact,32,2,TRUE,FALSE,FALSE,FALSE,FALSE,Batch normalization provably avoids ranks collapse for randomly initialised deep networks,Deep Learning -> Optimization for Deep Networks,Optimization; Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Hadi Daneshmand', ' Jonas Kohler', ' Francis Bach', ' Thomas Hofmann', ' Aurelien Lucchi']","{'ETHZ', 'ETH Zurich', 'INRIA - Ecole Normale Superieure', 'Inria'}",1,0,0,"{'France', 'Switzerland'}"
Choice Bandits,"Arpit Agarwal, Nicholas Johnson, Shivani Agarwal",Choice Bandits,d5fcc35c94879a4afad61cacca56192c,https://proceedings.neurips.cc/paper/2020/file/d5fcc35c94879a4afad61cacca56192c-Paper.pdf,"The purpose of this paper is to understand whether efficient learning is possible in a bandit setting where one does not receive quantitative feedback for an individual arm but rather relative feedback in the form of a multiway choice. It is well-known that quantitative judgments of humans can have biases; our algorithm, which learns from relative multiway choices, can help alleviate these biases. Moreover, by receiving larger choice sets from our algorithm, humans can have a better sense of the quality distribution of arms, and can make more informed choices. 5 We also considered the SelfSparring algorithm of [ 26] and the battling bandit algorithms of [27], which are applicable to choice models defined in terms of an underlying pairwise comparison model P . However, these algorithms all return multisets S t , and any simple reduction of such multisets to strict sets as considered in our setting (as well as the setting of [23]) can end up throwing away important information learned by the algorithms, resulting in a comparison that could be unfair to those algorithms. We did explore such reductions and our algorithm easily outperformed them, but we chose not to include the results here due to this issue of fairness. (Moreover, under the MNL model, [23] already established that MaxMinUCB outperforms those algorithms – presumably under similar reductions – so in the end, we decided such a comparison would provide little additional value here.) Another advantage of our setting is that we do not rely on historic data as our data collection is online. Hence, one does not need to worry about past biases being reflected in the choice datasets. However, one has to be cautious about the use of our algorithm in applications where arms represent individuals/entities such as job applicants, property renters etc. In these applications, the choices of people can be biased against certain individuals/groups, thereby hurting the chances of these individuals/groups to be selected by our algorithm. Here, depending on the application, one might need to consider imposing some form of fairness constraints on the choice sets output by our algorithm in order to prevent any discrimination against such individuals/groups.",Broader Impact,357,12,,,TRUE,TRUE,FALSE,Choice Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Ranking and Preference Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Arpit Agarwal', ' Nicholas Johnson', ' Shivani Agarwal']",{'University of Pennsylvania'},1,0,0,{'USA'}
What if Neural Networks had SVDs?,"Alexander Mathiasen, Frederik Hvilshøj, Jakob Rødsgaard Jørgensen, Anshul Nasery, Davide Mottin",What if Neural Networks had SVDs?,d61e4bbd6393c9111e6526ea173a7c8b,https://proceedings.neurips.cc/paper/2020/file/d61e4bbd6393c9111e6526ea173a7c8b-Paper.pdf,"Our algorithm speeds up the use of Householder decompositions in Neural Networks. This can positively impact researchers who use Householder decompositions, since they will be able to execute experiments faster. This is particularly beneficial for researchers with a constraint on their computational budget, in other words, a PhD student with one GPU stands to benefit more than a lab with state-of-the-art GPU computing infrastructure. The reduction in computing time also decrease power consumption and thus carbon emissions. However, as a potential negative impact, it is possible that the decrease in computation time will increase the usage of Neural Networks and thus increase overall carbon emission.",Broader Impact,105,5,,,TRUE,TRUE,FALSE,What if Neural Networks had SVDs?,Algorithms,Deep Learning,Deep learning,"['Alexander Mathiasen', ' Frederik Hvilshøj', ' Jakob Rødsgaard Jørgensen', ' Anshul Nasery', ' Davide Mottin']","{'Indian Institute of Technology', 'Aarhus University'}",1,0,0,"{'India', 'Denmark'}"
A Matrix Chernoff Bound for Markov Chains and Its Application to Co-occurrence Matrices,"Jiezhong Qiu, Chi Wang, Ben Liao, Richard Peng, Jie Tang",A Matrix Chernoff Bound for Markov Chains and Its Application to Co-occurrence Matrices,d63fbf8c3173730f82b150c5ef38b8ff,https://proceedings.neurips.cc/paper/2020/file/d63fbf8c3173730f82b150c5ef38b8ff-Paper.pdf,Our work contributes to the research literature of Chernoff-type bounds and co-occurrence statistics. Chernoff-type bound have become one of the most important probabilistic results in computer science. Our result generalize Chernoff bound to Markov dependence and random matrices. Co-occurrence statistics have emerged as important tools in machine learning. Our work addresses the sample complexity of estimating co-occurrence matrix. We believe such better theoretical understanding can further the understanding of potential and limitations of graph representation learning and reinforcement learning.,Broader Impact,79,6,,,FALSE,FALSE,FALSE,A Matrix Chernoff Bound for Markov Chains and Its Application to Co-occurrence Matrices,Theory -> Large Deviations and Asymptotic Analysis,Algorithms -> Spectral Methods; Applications -> Network Analysis,Theory (including computational and statistical analyses),,"{'Georgia Tech', 'Microsoft Research', 'Tsinghua University', 'Tencent'}",1,1,1,"{'USA', 'China'}"
CoMIR: Contrastive Multimodal Image Representation for Registration,"Nicolas Pielawski, Elisabeth Wetzer, Johan Öfverstedt, Jiahao Lu, Carolina Wählby, Joakim Lindblad, Natasa Sladoje",CoMIR: Contrastive Multimodal Image Representation for Registration,d6428eecbe0f7dff83fc607c5044b2b9,https://proceedings.neurips.cc/paper/2020/file/d6428eecbe0f7dff83fc607c5044b2b9-Paper.pdf,"Using CoMIRs for multimodal image registration has a direct application in multimodal image fusion. A wide range of areas benefit from fusing content of images of different sensors. One such area is material science. Early stage anomaly detection is used to characterize newly developed materials w.r.t. physical properties. As a concrete example, carbides along the grain boundary of a material can indicate impairments in material strength, but require different Scanning Electron Microscopy (SEM) sensors which acquire images asynchronously at different spatial resolutions [7]. This results in a multimodal registration problem which could be addressed by the proposed CoMIRs. The implications research in material science based on successful registration and fusion of images of this kind can have on the society are widespread. The Materials Genome Initiative (MGI) which has been launched by the US Federal Government in 2011 for example, aims to address clean energy, national security, and human welfare [41]. While this area of research can have a beneficial impact on society, by developing biocompatible materials for medical advances or materials needed in a variety of settings to reduce the carbon footprint, scientific findings in this area are directly linked to military developments also (see e.g. the US Air Force’s involvement in MGI). Another area of application which makes use of multimodal imaging data is the field of remote sensing. Again, while aerial observation can be used to monitor geological changes like melting glaciers due to climate change or early detection of wildfires, it is also tightly connected to military action (espionage, navigation systems such as Unmanned Aerial Vehicles (UAV), target localization, lethal autonomous war weapons). The area which can profit the most from multimodal image registration and following fusion in a positive way, is biomedicine. It is a broad and active field of research to combine information from modalities such as computed tomography (CT), magnetic resonance imaging (MRI) and Positron emission tomography (PET) or BF, SHG and two-photon- excited fluorescence (TPEF) microscopy. These imaging techniques often provide complementary and clinically relevant information needed for a diagnostic task. For example CT gives good spatial resolution and dense tissue contrast, while MRI yields better soft tissue contrast. BF and SHG are for example studied together in connection with collagen organization in tumor growth. By providing a joint representation between multiple modalities, issues regarding patient data anonymization need to be taken into account, e.g. if only images in one modality were subject to anonymization (e.g. photographs), while the other was not (e.g. CT scan), CoMIRs could potentially facilitate data de-anonymization from one modality to another. Registration by MI is computationally expensive, and as we show in our paper, MI is highly susceptible to an initial starting position close to the global extremum. In order to perform well, a larger number of restarts is needed to overcome being trapped in a local extremum, increasing the computational load even more. Generating CoMIRs for an entire dataset combined with registration by SIFT is much cheaper computationally, especially regarding the small training data needed for CoMIR generation. Hence, in settings where multimodal registration is already in place, CoMIRs can reduce the energy cost required and in consequence the environmental impact, however it may encourage the analyses of multimodal data on a much greater scale than ever before. The CoMIRs’ usage is also not limited to the task of multimodal registration, but could be useful for classification, segmentation or patch retrieval. This is subject of future research, but we foresee a potential in segmentation by training on the label masks as a second modality for example.",6 Broader Impact,590,23,,,TRUE,TRUE,FALSE,CoMIR: Contrastive Multimodal Image Representation for Registration,Algorithms -> Multimodal Learning,Algorithms -> Representation Learning; Algorithms -> Similarity and Distance Learning; Applications -> Computational Biology and Bioinformatics; Applications -> Computer Vision; Deep Learning -> Embedding Approaches; Deep Learning -> Supervised Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Nicolas Pielawski', ' Elisabeth Wetzer', ' Johan Öfverstedt', ' Jiahao Lu', ' Carolina Wählby', ' Joakim Lindblad', ' Natasa Sladoje']","{'Uppsala University', 'Department of Information Technology, Uppsala University', 'Centre for Image Analysis, Department of Information Technology, Uppsala University, Sweden'}",1,0,0,{'Sweden'}
Ensuring Fairness Beyond the Training Data,"Debmalya Mandal, Samuel Deng, Suman Jana, Jeannette Wing, Daniel J. Hsu",Ensuring Fairness Beyond the Training Data,d6539d3b57159babf6a72e106beb45bd,https://proceedings.neurips.cc/paper/2020/file/d6539d3b57159babf6a72e106beb45bd-Paper.pdf,"This paper addresses a topic of societal interest that has received considerable attention in the NeurIPS community over the past several years. Two anticipated positive outcomes of our work include: (i) increased awareness of the dataset robustness concerns when evaluating fairness criteria, and (ii) algorithmic techniques for coping with these robustness concerns. Thus, we believe researchers and practitioners who seek to develop classifiers that satisfy certain fairness criteria would be the primary beneficiaries of this work. A possible negative outcome of the work is the use of the techniques to declare some classifiers as “fair” without proper consideration of the semantics of the fairness criteria or the underlying dataset used to evaluate these criteria. Thus, individuals subject to the decisions made by such classifiers could be adversely affected. Finally, our experimental evaluations use “real world” datasets, so the conclusions that we draw in our paper may have implications for individuals associated with these data. Acknowledgments : We thank Shipra Agrawal and Roxana Geambasu for helpful preliminary dis- cussions. DM was supported through a Columbia Data Science Institute Post-Doctoral Fellowship. DH was partially supported by NSF awards CCF-1740833 and IIS-15-63785 as well as a Sloan Fellowship. SJ was partially supported by NSF award CNS-18-01426.",6 Broader Impact,203,10,,,FALSE,FALSE,FALSE,Ensuring Fairness Beyond the Training Data,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Online Learning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Debmalya Mandal', ' Samuel Deng', ' Suman Jana', ' Jeannette Wing', ' Daniel Hsu']",{'Columbia University'},1,0,0,{'USA'}
How do fair decisions fare in long-term qualification?,"Xueru Zhang, Ruibo Tu, Yang Liu, mingyan liu, Hedvig Kjellstrom, Kun Zhang, Cheng Zhang",How Do Fair Decisions Fare in Long-term Qualification?,d6d231705f96d5a35aeb3a76402e49a3,https://proceedings.neurips.cc/paper/2020/file/d6d231705f96d5a35aeb3a76402e49a3-Paper.pdf,"In this paper, we focus on the (un)fairness issue that arises in automated decision-making systems and aim to understand the long-term impact of algorithmic (fair) decisions on the well-being of different sub-groups in a population. Our partially observed sequential decision making framework is applicable to a wide range of domains (e.g., lending, recruitment, admission, criminal justice, etc.). By conducting an equilibrium analysis and evaluating the long-term impact of different fairness criteria, our results provide a theoretical foundation that can help answer questions such as whether/when imposing short-term fairness constraints are effective in promoting long-term equality. First of all, our results can help policymakers (e.g., companies, banks, governments, etc.) in their decision making process by highlighting the potential pitfalls of commonly used static fairness criteria and providing guidance on how to design effective interventions that can avoid such unintended consequences and result in positive long-term societal impacts. Secondly, our results may be useful to research in fields outside of the computer science community. The experiments on static real-world datasets have shown consistent findings with literature in social sciences [36, 17, 41]. Although these empirical results are obtained using simulated dynamics due to a lack of real datasets, they may provide insights and theoretical supports for research in other fields. Lastly, while this work is limited to binary decisions, the main take-away can be applied in other applications such as computer vision, natural language processing, etc., using more complicated classifiers such as DNN. We hope that our work will encourage researchers in these domains to similarly consider discrimination risks when developing techniques, and raise awareness that static fairness constraint may not suffice and long-term fairness cannot be designed in a vacuum without considering the human element. We thus emphasize the importance of performing real-time measurements and developing proper fair classifiers from dynamic datasets. Having mentioned the potential positive impact of our work, we also want to point out the limitations in our model and analysis. Firstly, in this work we use a set of transitions T yd s to capture individuals’ abilities to improve/maintain future qualifications, and our analysis and conclusions rely on this set of values. In practice, however, these quantities can be extremely hard to measure due to the complexity of human behaviors and environmental factors. In addition, as we have noted in the paper, in some cases the conclusion can be highly sensitive to minor changes in these transitions. Secondly, our theoretical results have focused on scenarios with a unique equilibrium, while in practice the situation can be much more complicated (multiple equilibria or no equilibria), as demonstrated by the oscillations we see in the COMPAS simulation study. Thus, it is worthwhile for future work to consider these more complex cases. Lastly, due to the lack of dynamic datasets, our experiments are performed over static real-world datasets with simulated dynamics. Thus, an accurate model of real-world dynamics is needed when deploying our method for practical decision making.",Broader Impact,488,19,,,FALSE,TRUE,FALSE,How do fair decisions fare in long-term qualification?,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Xueru Zhang', ' Ruibo Tu', ' Yang Liu', ' mingyan liu', ' Hedvig Kjellstrom', ' Kun Zhang', ' Cheng Zhang']","{'UC Santa Cruz', 'University of Michigan', 'CMU', 'university of Michigan, Ann Arbor', 'Microsoft Research, Cambridge, UK', 'KTH Royal Institute of Technology'}",1,1,1,"{'UK', 'USA', 'Sweden'}"
Pre-training via Paraphrasing,"Mike Lewis, Marjan Ghazvininejad, Gargi Ghosh, Armen Aghajanyan, Sida Wang, Luke Zettlemoyer",Pre-training via Paraphrasing,d6f1dd034aabde7657e6680444ceff62,https://proceedings.neurips.cc/paper/2020/file/d6f1dd034aabde7657e6680444ceff62-Paper.pdf,"This work has a broad scope, covering discriminative and generative tasks in many languages. As such, the broader impact is similar to that of the field of NLP; there exist many potential good and bad applications. The pre-training method is likely to capture and potentially amplify any biases found in the pre-training corpus. Our work learns to translate languages in an unsupervised way, which could  be used to bring NLP to more languages, but could also potentially introduce more translation errors that supervised methods.",Broader Impact,84,4,,,FALSE,FALSE,FALSE,Pre-training via Paraphrasing,Applications -> Natural Language Processing,,,"['Mike Lewis', ' Marjan Ghazvininejad', ' Gargi Ghosh', ' Armen Aghajanyan', ' Sida Wang', ' Luke Zettlemoyer']","{'Facebook', 'University of Washington and Allen Institute for Artificial Intelligence', 'Facebook AI Research'}",1,1,1,{'USA'}
GCN meets GPU: Decoupling “When to Sample” from “How to Sample”,"Morteza Ramezani, Weilin Cong, Mehrdad Mahdavi, Anand Sivasubramaniam, Mahmut Kandemir",GCN meets GPU: Decoupling “When to Sample” from “How to Sample”,d714d2c5a796d5814c565d78dd16188d,https://proceedings.neurips.cc/paper/2020/file/d714d2c5a796d5814c565d78dd16188d-Paper.pdf,"The proposed L AZY GCN algorithm has two applicable aspects: system and theory. In terms of system design it is aiming at improving the main bottleneck of GCN training, however its application is not limited to CPU-GPU system, but any other distributed training setting, where either workers or communication is at disadvantage. In addition, the analysis of theoretical aspects of lazy sampling, provides powerful tools for future studies of sampling-based GCNs.",Broader Impact,71,3,,,FALSE,FALSE,FALSE,GCN meets GPU: Decoupling “When to Sample” from “How to Sample”,Algorithms -> Representation Learning,Algorithms -> Large Scale Learning; Applications -> Hardware and Systems; Deep Learning -> Efficient Training Methods,Deep learning,"['Morteza Ramezani', ' Weilin Cong', ' Mehrdad Mahdavi', ' Anand Sivasubramaniam', ' Mahmut Kandemir']","{'Penn State', 'Pennsylvania State University'}",1,0,0,{'USA'}
Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks,"Zixuan Ke, Bing Liu, Xingchang  Huang",Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks,d7488039246a405baf6a7cbc3613a56f,https://proceedings.neurips.cc/paper/2020/file/d7488039246a405baf6a7cbc3613a56f-Paper.pdf,"An intelligent agent typically needs to learn many skills or tasks. Some of the tasks are similar to each other and some are distinct. It is desirable that the agent can learn these tasks without interference with each other and also improve its learning when there is shared/transferable knowledge learned in the past. As more and more chatbots, intelligent personal assistants and physical robots appear in our lives, we believe that this research will become more and more important. We could not see anyone will be put at disadvantage by this research. The consequence of failure of the system is that the system makes some incorrect classifications. Our task and method do not leverage biases in the data.",Broader Impact,118,7,,,FALSE,FALSE,FALSE,Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks,Algorithms -> Continual Learning,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Zixuan Ke', ' Bing Liu', ' Xingchang Huang']","{'University of Illinois, Chicago', 'ETH Zurich', 'University of Illionis at Chicago'}",1,0,0,"{'USA', 'Switzerland'}"
All your loss are belong to Bayes,"Christian Walder, Richard Nock",All your loss are belong to Bayes,d75320797f266ba9ed6dd6dc218cb1b5,https://proceedings.neurips.cc/paper/2020/file/d75320797f266ba9ed6dd6dc218cb1b5-Paper.pdf,"From an ethical standpoint, it is likely that any advancements in fundamental machine learning methodologies will eventually give rise to both positive and negative outcomes. The present work is sufficiently general and application independent, however, as to pose relatively little cause for immediate concern. Nonetheless, we note one example of an optimistic take on the potential impact of the present work. The example is from the field of quantitative criminology , wherein it is advocated that further study of asymmetric loss functions may provide lawmakers with “procedures far more sensitive to the real consequences of forecasting errors” in the context of law enforcement [Ber11]. Such a study implies that symmetric links — like the ones derived from most common losses: logistic, square, Matsushita, etc. — are not a good fit for sensitive fields. Since inference on proper losses can produce non-symmetric links, the present contribution may be useful for such application fields.",Broader Impact,152,7,,,FALSE,FALSE,FALSE,All your loss are belong to Bayes,Probabilistic Methods -> Gaussian Processes,Algorithms -> Kernel Methods; Algorithms -> Regression; Theory -> Statistical Learning Theory,,"['Christian Walder', ' Richard Nock']","{'Data61, the Australian National University and the University of Sydney', 'DATA61'}",1,1,1,{'Australia'}
HAWQ-V2: Hessian Aware trace-Weighted Quantization of Neural Networks,"Zhen Dong, Zhewei Yao, Daiyaan Arfeen, Amir Gholami, Michael W. Mahoney, Kurt Keutzer",HAWQ-V2: Hessian Aware trace-Weighted Quantization of Neural Networks,d77c703536718b95308130ff2e5cf9ee,https://proceedings.neurips.cc/paper/2020/file/d77c703536718b95308130ff2e5cf9ee-Paper.pdf,"Deep learning models are rapidly increasing in size and this has created a challenge for deploying these models in practice. Our work addresses this problem by developing a novel compression method with minimal impact on accuracy. Our work is applicable to a wide range of NN models, as depicted in our empirical evaluation. Furthermore, our method can help reduce both the computation and the memory bottleneck, so that state-of-the-art neural network models can be deployed even onto edge devices. This helps to realize wider applications of technology, especially in area such as deep learning based daily applications on smart phones, or basic and always-on applications on embedded chips.",Broader Impact,108,5,,,FALSE,FALSE,FALSE,HAWQ-V2: Hessian Aware trace-Weighted Quantization of Neural Networks,Deep Learning -> Efficient Inference Methods,,Resource aware machine learning,"['Zhen Dong', ' Zhewei Yao', ' Daiyaan Arfeen', ' Amir Gholami', ' Michael Mahoney', ' Kurt Keutzer']","{'EECS, UC Berkeley', 'UC Berkeley', 'University of California, Berkeley'}",1,0,0,{'USA'}
Sample-Efficient Reinforcement Learning of Undercomplete POMDPs,"Chi Jin, Sham Kakade, Akshay Krishnamurthy, Qinghua Liu",Sample-Efficient Reinforcement Learning of Undercomplete POMDPs,d783823cc6284b929c2cd8df2167d212,https://proceedings.neurips.cc/paper/2020/file/d783823cc6284b929c2cd8df2167d212-Paper.pdf,"As this is a theoretical contribution, we do not envision that our direct results will have a tangible societal impact. Our broader line of inquiry could impact a line of thinking in a way that provides additional means to provide confidence intervals relevant for planning and learning. There is an increasing needs for applications to understand planning under uncertainty in the broader context of safety and reliability, and POMDPs provide one potential framework.",Broader Impact,73,3,,,FALSE,FALSE,FALSE,Sample-Efficient Reinforcement Learning of Undercomplete POMDPs,Theory -> Statistical Learning Theory,Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Chi Jin', ' Sham Kakade', ' Akshay Krishnamurthy', ' Qinghua Liu']","{'Microsoft', 'Princeton University', 'University of Washington'}",1,1,1,{'USA'}
Non-Convex SGD Learns Halfspaces with Adversarial Label Noise,"Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos, Nikos Zarifis",Non-Convex SGD Learns Halfspaces with Adversarial Label Noise,d785bf9067f8af9e078b93cf26de2b54,https://proceedings.neurips.cc/paper/2020/file/d785bf9067f8af9e078b93cf26de2b54-Paper.pdf,"Our work fits within the broader agenda of designing efficient robust learners in the presence of noisy data. The practical significance of learning linear classifiers is well-established. In most use-cases, the labels of the examples are noisy, e.g., a non-spam email is incorrectly labeled as spam and vice versa. Machine learning algorithms are now used more than ever having applications in social networks, auctions, advertising, etc. Therefore, having erroneous results due to noise can have far reaching consequences. The goal of our work is to develop robust machine learning algorithms that have theoretical performance guarantees and, at the same time, are easy to implement and use in practice. Since the primary focus of our work is theoretical, we do not expect our results to have immediate societal impact. Nonetheless, we believe that our algorithm is practical and provides interesting insights that could be useful in practice. We show that one can use a simple black-box optimization routine (Stochastic Gradient Descent) on a simple objective function and learn an accurate linear classifier, even if a small constant fraction of the labels is chosen adversarially. Moreover, while many of the linear classification methods currently used in practice rely on optimizing convex surrogate objectives, our work shows that such methods may achieve significantly sub-optimal results, even under very benign distributions. Our method outperforms the error guarantee of any method relying on optimizing convex losses.",Broader Impact,231,11,,,FALSE,FALSE,FALSE,Non-Convex SGD Learns Halfspaces with Adversarial Label Noise,Theory -> Computational Learning Theory,,Theory (including computational and statistical analyses),"['Ilias Diakonikolas', ' Vasilis Kontonis', ' Christos Tzamos', ' Nikos Zarifis']","{'UW Madison', 'University of Wisconsin-Madison'}",1,0,0,{'USA'}
A Tight Lower Bound and Efficient Reduction for Swap Regret,Shinji Ito,A Tight Lower Bound and Efficient Reduction for Swap Regret,d79c8788088c2193f0244d8f1f36d2db,https://proceedings.neurips.cc/paper/2020/file/d79c8788088c2193f0244d8f1f36d2db-Paper.pdf,"The authors believe that this paper presents neither ethical nor societal issues, as this is a theoretical work.",Broader impact,18,1,TRUE,FALSE,FALSE,FALSE,FALSE,A Tight Lower Bound and Efficient Reduction for Swap Regret,Algorithms -> Online Learning,Theory -> Computational Learning Theory; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),['Shinji Ito'],{'NEC Corporation'},0,1,0,{'Japan'}
DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction,"Aviral Kumar, Abhishek Gupta, Sergey Levine",DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction,d7f426ccbc6db7e235c57958c21c5dfa,https://proceedings.neurips.cc/paper/2020/file/d7f426ccbc6db7e235c57958c21c5dfa-Paper.pdf,"Approximate dynamic programming methods are a key ingredient in modern deep reinforcement learning algorithms, which have had successes on a number of practical problems. However, reinforcement learning algorithms are still limited by problems such as instability and sensitivity to hyperparameters. In this work, we analyzed one such issue, which we called “corrective feedback”, that afflicts modern ADP algorithms: the interaction between online data distributions and function approximation may not be able to correct errors in the Q-function. By optimizing for the distribution to maximize corrective feedback, our proposed method, DisCor, significantly improves RL problems in several challenging reinforcement learning and multi-task reinforcement learning settings, across a wide range of domains. DisCor is simple, intuitive, and admits a principled derivation, and can be applied with a number of modern deep RL algorithms. The broad theme behind this work is to identify and address problems that arise with deep reinforcement learning algorithms. Reinforcement learning algorithms often enjoy provable guarantees with tabular representations, but it is unclear how to extend these to deep networks. Instead we could take an alternate approach: optimize for quantities of interest (such as in our case, corrective feedback) directly. We believe that this general principle can help scale end-to-end learning autonomous decision-making based approaches to real-life problems, such as robotics, software systems and autonomous driving. Machines that can reason and perform autonomous decision-making have a wide range of applications, in a wide range of domains, and like any other technological innovations that mankind has seen, effective autonomous decision-making has both positive and negative societal effects. While effective autonomous decision-making can have considerable positive economic effects, such as by automating manufacturing lines, and other positive effects, that enhance human life quality, it can have complex economic effects due to changing economic conditions (e.g., changing job requirements, loss of jobs in some sectors and growth in others, etc.). Such implications apply broadly to technologies that enable automation agnostic of data-driven learning or reinforcement learning, and are largely not unique to this specific work.",Broader Impact,333,12,,,FALSE,FALSE,FALSE,DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Aviral Kumar', ' Abhishek Gupta', ' Sergey Levine']","{'UC Berkeley', 'University of California, Berkeley'}",1,0,0,{'USA'}
OTLDA: A Geometry-aware Optimal Transport Approach for Topic Modeling,"Viet Huynh, He Zhao, Dinh Phung",OTLDA: A Geometry-Aware Optimal Transport Approach for Topic Modeling,d800149d2f947ad4d64f34668f8b20f6,https://proceedings.neurips.cc/paper/2020/file/d800149d2f947ad4d64f34668f8b20f6-Paper.pdf,"Topic modeling is one of the most popular tools for text understanding and text mining. Understan- ding large document collections, retrieving scientific findings related to some disease, or discovering the trends of current news of the election are some examples of domain application of topic models. Our work provides a new theoretical framework to improve the interpretation of learned topics. Hence, it will be beneficial to some current applications that use directly from learned topics of the topic models. Learning more interpretable topics from a huge corpus can also be important for deci- sion making support applications. As the work addresses a fundamental research problem we believe that it does not put anyone at disadvantages. Our method is data-driven which completely depends on the input corpora. The potential of unfairness may come from the process of data collection.",Broader Impact,138,8,,,FALSE,FALSE,FALSE,OTLDA: A Geometry-aware Optimal Transport Approach for Topic Modeling,Algorithms -> Clustering,Probabilistic Methods -> Topic Models,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Viet Huynh', ' He Zhao', ' Dinh Phung']",{'Monash University'},1,0,0,{'Australia'}
Measuring Robustness to Natural Distribution Shifts in Image Classification,"Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, Ludwig Schmidt",Measuring Robustness to Natural Distribution Shifts in Image Classification,d8330f857a17c53d217014ee776bfd50,https://proceedings.neurips.cc/paper/2020/file/d8330f857a17c53d217014ee776bfd50-Paper.pdf,"Robustness is one of the key problems that prevents deploying machine learning in the real world and harnessing the associated benefits. A canonical example is image classification for medical diagnosis. As was found when researchers attempted to deploy a neural network to detect diabetes from retina images, “an accuracy assessment from a lab goes only so far. It says nothing of how the AI will perform in the chaos of a real-world environment” [3]. Similarly, researcher also found that current methods for chest X-ray classification are brittle even in the absence of recognized confounders [110]. If models were robust, then this transfer to the real world would be straightforward. Unfortunately, achieving robustness on real data is still a substantial challenge for machine learning. Our work studies how robust current image classification methods are to distribution shifts arising in real data. We hope that our paper will have a positive effect on the study of distribution shifts and allow researchers to more accurately evaluate to what extent a proposed technique increases the robustness to particular forms of distribution shift. This will allow researchers to better understand how a deployed system will work in practice, without actually having to deploy it first and users potentially suffering negative consequences. However, there are several potential ways in which our study could cause unintended harm. It is possible that our paper might be used as an argument to stop performing research on some synthetic forms of robustness, e.g., adversarial examples or common corruptions. This is not our intention. These forms of corruption are interesting independent of any correlation to existing natural distribution shift (e.g., adversarial examples are a genuine security problem). We only capture a small number of natural distribution shifts among all the possible distribution shifts. We selected these shifts because they have been used extensively in the literature and are concrete examples of the types of distribution shift we would like models to be robust to. It is likely that there are shifts that we do not capture, and so even if the shifts we define were to be completely solved, other shifts would remain a concern. One significant form of distribution shift we do not evaluate is dataset bias in representing different demographic groups. For example, the Inclusive Images dataset [75] attempts to correct for the geographical bias introduced in the Open Images dataset [51] by including a more balanced representation of images from Africa, Asia, and South America. Neglecting such implicit biases in the data distribution can harm underrepresented demographic groups. Ultimately, evaluating on fixed datasets may not be enough, and validating the fairness and safety of deployable machine learning requires careful analysis in the application domain. Finally, more reliable machine learning can also enable negative uses cases, e.g., widespread surveil- lance or autonomous weapon systems. As with many technologies, these risks require careful regulation and awareness of unintended consequences arising from technological advances.",Broader Impact,483,23,,,FALSE,FALSE,FALSE,Measuring Robustness to Natural Distribution Shifts in Image Classification,Deep Learning -> Analysis and Understanding of Deep Networks,,Deep learning,"['Rohan Taori', ' Achal Dave', ' Vaishaal Shankar', ' Nicholas Carlini', ' Benjamin Recht', ' Ludwig Schmidt']","{'UC Berkeley', 'University of California, Berkeley', 'Carnegie Mellon University', 'Google'}",1,1,1,{'USA'}
Can I Trust My Fairness Metric? Assessing Fairness with Unlabeled Data and Bayesian Inference,"Disi Ji, Padhraic Smyth, Mark Steyvers",Can I Trust My Fairness Metric? Assessing Fairness with Unlabeled Data and Bayesian Inference,d83de59e10227072a9c034ce10029c39,https://proceedings.neurips.cc/paper/2020/file/d83de59e10227072a9c034ce10029c39-Paper.pdf,"Machine learning classifiers are currently widely used to make decisions about individuals, across a broad variety of societal contexts: education admissions, health insurance, medical diagnosis, court decisions, marketing, face recognition, and more—and this trend is likely to continue to grow. It is now well-recognized that these machine learning models are susceptible to built-in biases that can lead to systematic discrimination against protected groups. The machine learning research community has begun to recognize this important issue and in the past few years had devoted considerable research resources towards developing principles, frameworks, and algorithmic solutions to address these problems. In this general context, this paper addresses the understudied problem of how to assess how fair or unfair a model may be, and how much confidence we should have in this assessment given access to a limited amount of labeled data. One particular example of how the proposed approach can be used is in the increasingly common situation where the user of a blackbox classification model needs to assess its performance from a fairness perspective, in a manner that is separate and independent from the claims made by the entity that trained the model. For example, a hospital system or a university might wish to evaluate the fairness characteristics of a pre-trained classification model in the specific context of the population of patients or students in their institution. The methodology developed in this paper is well-suited to such an application. In terms of negative potential outcomes, although the proposed approach was shown to be robust across multiple datasets and models relative to existing techniques, as with any machine learning methodology there are nonetheless potential blind spots such as the impact of misspecification in the calibration model on the accuracy of estimates of metrics and on posterior credible intervals. In addition, there is also always the danger of miscommunication of the results of the type of estimation methodology proposed here, in particular given the various challenges in communicating concepts related to uncertainty to a non-expert audience (e.g., van der Bles et al. [2019]).",Broader Impacts,339,10,,,FALSE,TRUE,FALSE,Can I Trust My Fairness Metric? Assessing Fairness with Unlabeled Data and Bayesian Inference,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Probabilistic Methods,,"['Disi Ji', ' Padhraic Smyth', ' Mark Steyvers']","{'UC Irvine', 'UC, Irvine', 'University of California, Irvine'}",1,0,0,{'USA'}
RandAugment: Practical Automated Data Augmentation with a Reduced Search Space,"Ekin Dogus Cubuk, Barret Zoph, Jon Shlens, Quoc Le",RandAugment: Practical Automated Data Augmentation with a Reduced Search Space,d85b63ef0ccb114d0a3bb7b7d808028f,https://proceedings.neurips.cc/paper/2020/file/d85b63ef0ccb114d0a3bb7b7d808028f-Paper.pdf,"Data augmentation has recently played a central role in a variety of deep learning research directions, including self- and semi-supervised learning, out-of-domain generalization and calibration, and reinforcement learning. Being able to improve data augmentation pipelines efficiently has promise for more accurate, robust, and calibrated machine learning models to be used for positive societal applications (e.g. autonomous vehicles, healthcare, etc.). On the other hand, this improved technology can also be used by bad actors. Finally, removing the need for a separate augmentation search phase reduces the carbon footprint and computational cost of training better models.",Broader Impact,94,4,,,FALSE,FALSE,FALSE,RandAugment: Practical Automated Data Augmentation with a Reduced Search Space,Algorithms -> AutoML,,Vision,"['Ekin Dogus Cubuk', ' Barret Zoph', ' Jon Shlens', ' Quoc V Le']","{'Google Brain', 'Google', 'Google Research'}",0,1,0,{'USA'}
Asymptotic normality and confidence intervals for derivatives of 2-layers neural network in the random features model,"Yiwei Shen, Pierre C Bellec",Asymptotic normality and confidence intervals for derivatives of 2-layers neural network in the random features model,d87ca511e2a8593c8039ef732f5bffed,https://proceedings.neurips.cc/paper/2020/file/d87ca511e2a8593c8039ef732f5bffed-Paper.pdf,"Our work provides a first step towards frequentist uncertainty quantification, in the form of confidence intervals, for the NN estimate (1). Uncertainty quantification and confidence intervals are important for decision making in society, where decisions with long-lasting effects are made based on summary statistics computed on characteristics of individual human beings. As two concrete examples, consider the GPA awarded by Universities to their undergraduate students, or the credit score assigned to individuals in the US regarding their capacity to manage their debts. Graduate schools would refuse admissions to student applying with a GPA under a fixed threshold, and banks would refuse loans to individuals with a credit score under a threshold. In order to make fairer decisions, graduate schools and banks ought to consider the uncertainty of these summary statistics, for instance by comparing the admission threshold to some confidence interval [ GPA − STD , GPA + STD ] that takes into account the uncertainty of computing the GPA summary statistic. Similarly, banks should take into account confidence intervals when making loan decisions about an individual based on their credit score summary statistic. Although the neural network model (1) studied in the present paper is admittedly simple and far from the state-of-the-art networks used for predictions in practice, we hope that our results will provide useful ideas and inspire new results of frequentist uncertainty quantification for machine learning tools that are implemented in societal decision making and praised for their prediction properties, but, so far, lack provable uncertainty quantification guarantees.",Broader Impact,251,7,,,FALSE,FALSE,FALSE,Asymptotic normality and confidence intervals for derivatives of 2-layers neural network in the random features model,Theory -> High-Dimensional Inference,Deep Learning -> Analysis and Understanding of Deep Networks,Theory (including computational and statistical analyses),"['Yiwei Shen', ' Pierre Bellec']","{'Rutgers', 'Rutgers University'}",1,0,0,{'USA'}
DisARM: An Antithetic Gradient Estimator for Binary Latent Variables,"Zhe Dong, Andriy Mnih, George Tucker",DisARM: An Antithetic Gradient Estimator for Binary Latent Variables,d880e783834172e5ebd1868d84463d93,https://proceedings.neurips.cc/paper/2020/file/d880e783834172e5ebd1868d84463d93-Paper.pdf,"Gradient estimators for discrete latent variables have particular applicability to interpretable models and modeling natural systems with discrete variables. Discrete latent variables tend to be easier to interpret than continuous latent variables. While interpretable systems are typically viewed as a positive, they only give a partial view of a complex system. If they are not used with care and presented to the user properly, they may give the user a misplaced sense of trust. Providing simple and effective foundational tools enables non-experts to contribute, however, it also enables bad actors.",Broader Impacts,90,5,,,FALSE,FALSE,FALSE,DisARM: An Antithetic Gradient Estimator for Binary Latent Variables,Deep Learning -> Generative Models,Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,,"{'Google Brain', 'Google Research', 'DeepMind'}",0,1,0,"{'UK', 'USA'}"
Variational Inference for Graph Convolutional Networks in the Absence  of Graph Data and Adversarial Settings,"Pantelis Elinas, Edwin V. Bonilla, Louis Tiao",Variational Inference for Graph Convolutional Networks in the Absence of Graph Data and Adversarial Settings,d882050bb9eeba930974f596931be527,https://proceedings.neurips.cc/paper/2020/file/d882050bb9eeba930974f596931be527-Paper.pdf,"There exist numerous useful applications for graph- CNN s including e-commerce product recommendations [41], online social network recommendations [45], drug discovery [27, 32, 14], computational pharmacology [50], disease understanding [39], bioinformatics [12], finance [16], anti-money laundering [42], online hate speech classification [36], and understanding online fake news propagation [30]. Of the above applications, several can benefit from VGCN over existing graph- CNN s. Any application where there is incentive for bad actors to poison the data in order to (a) hide their activities, e.g., online hate speech, (b) control the activities of others, e.g., trick consumers into purchasing unreliable or expensive products, or (c) promote misinformation, e.g., fake news, stand to benefit from VGCN ’s ability to deal with adversarial attacks. Furthermore, VGCN is directly applicable to non-graph domains via the ad hoc construction of graphs hence the benefits of graph- CNN s can be brought into domains where data is not inherently graph-structured. As we have discussed earlier, such ad hoc graph creation results in noisy graphs requiring the use of principled structure modeling for training useful predictive models. Just like any machine learning algorithm can be used for good it can also be used for harm. Graph- CNN s and our method VGCN are not immune to such misuse. For example, understanding how VGCN deals with adversarial attacks can be used by an adversarial agent to create more robust attacks and subvert attempts at detection. Currently, we have no solution for such a general problem but we understand that this needs to be addressed in future work. Overall, we believe that our work is beneficial to society because of the many important applications that stand to benefit from VGCN ’s ability to handle noise in the graph structure.",Broader Impact,290,9,,,FALSE,FALSE,FALSE,Variational Inference for Graph Convolutional Networks in the Absence  of Graph Data and Adversarial Settings,Applications -> Network Analysis,,Graph neural networks,"['Pantelis Elinas', ' Edwin Bonilla', 'Chun Tiao']","{'Data61', 'University of Sydney'}",1,1,1,{'Australia'}
Supervised Contrastive Learning,"Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan",Supervised Contrastive Learning,d89a66c7c80a29b1bdbab0f2a1a94af8,https://proceedings.neurips.cc/paper/2020/file/d89a66c7c80a29b1bdbab0f2a1a94af8-Paper.pdf,"This work provides a technical advancement in the field of supervised classification, which already has tremendous impact throughout industry. Whether or not they realize it, most people experience the results of this type of classifier many times a day. As we have shown, supervised contrastive learning can improve both the accuracy and robustness of classifiers, which for most applications should strictly be an improvement. For example, an autonomous car that makes a classification error due to data distribution shift can result in catastrophic results. Thus decreasing this class of error undoubtedly promotes safety. Human driver error is a massive source of fatalities around the world, so improving the safety of autonomous cars furthers the efforts of replacing human drivers. The flip side of that progress is of course the potential for loss of employment in fields like trucking and taxi driving. Similar two-sided coins can be considered for assessing the impact of any application of classification. An additional potential impact of our work in particular is showing the value of training with large batch sizes. Generally, large batch size training comes at the cost of substantial energy consumption, which unfortunately today requires the burning of fossil fuels, which in turn warms our planet. We are proud to say that the model training that was done in the course of this research was entirely carbon-neutral, where all power consumed was either green to start with, or offset by purchases of green energy. There is unfortunately no way to guarantee that once this research is publicly available that all practitioners of it will choose, or even have the ability to choose, to limit the environmental impact of their model training.",Broader Impact,278,12,,,FALSE,FALSE,FALSE,Supervised Contrastive Learning,Deep Learning,Deep Learning -> Supervised Deep Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Prannay Khosla', ' Piotr Teterwak', ' Chen Wang', ' Aaron Sarna', ' Yonglong Tian', ' Phillip Isola', ' Aaron Maschinot', ' Ce Liu', ' Dilip Krishnan']","{'Google Research', 'Google', 'Google LLC', 'Massachusetts Institute of Technology', 'MIT'}",1,1,1,{'USA'}
Learning Optimal Representations with the Decodable Information Bottleneck,"Yann Dubois, Douwe Kiela, David J. Schwab, Ramakrishna Vedantam",Learning Optimal Representations with the Decodable Information Bottleneck,d8ea5f53c1b1eb087ac2e356253395d8,https://proceedings.neurips.cc/paper/2020/file/d8ea5f53c1b1eb087ac2e356253395d8-Paper.pdf,"Our work takes the perspective that an “optimal” representation is one such that any classifier that fits the training data should generalize well to test. In terms of potential practical benefits, it is possible that using our optimal representations, one can alleviate the effort of hyperparameter search and selection currently required to tune deep learning models. This could be a step towards democratizing machine learning to sections of the society without large computational resources – since hyperparameter search is often computationally expensive. We do not anticipate that our work will advantage or disadvantage any particular group.",Broader Impact,96,4,,,FALSE,FALSE,FALSE,Learning Optimal Representations with the Decodable Information Bottleneck,Algorithms -> Representation Learning,Deep Learning -> Supervised Deep Networks; Theory -> Information Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yann Dubois', ' Douwe Kiela', ' David Schwab', ' Ramakrishna Vedantam']",{'Facebook AI Research'},0,1,0,{'USA'}
Meta-trained agents implement Bayes-optimal agents,"Vladimir Mikulik, Grégoire Delétang, Tom McGrath, Tim Genewein, Miljan Martic, Shane Legg, Pedro Ortega",Meta-trained agents implement Bayes-optimal agents,d902c3ce47124c66ce615d5ad9ba304f,https://proceedings.neurips.cc/paper/2020/file/d902c3ce47124c66ce615d5ad9ba304f-Paper.pdf,"Our work helps advance and verify the current understanding of the nature of solutions that metalearning brings about (our empirical work focused on modern recurrent neural network architectures and training algorithms, but we expect the findings to qualitatively hold for a large range of AI systems that are trained through meta-learning). Understanding how advanced AI and ML systems work is of paramount importance for safe deployment and reliable operation of such systems. This has also been recognized by the wider machine-learning community with a rapidly growing body of literature in this emerging field of “Analysis and Understanding” of deep learning. While increased understanding is likely to ultimately also contribute towards building more capable AI systems, thus potentially amplifying their negative aspects, we strongly believe that the merits of understanding how these systems work clearly outweigh the potential risks in this case. We argue that understanding meta-learning on a fundamental level is important, since meta-learning subsumes many specific learning tasks and is thought to play an important role for AI systems that generalize well to novel situations. Accordingly we expect meta-learning to be highly relevant over the next decade(s) in AI research and in the development of powerful AI algorithms and applications. In this work we also show a proof-of-concept implementation for analysis methods that might potentially allow one to separate (heterogeneous) agents into certain equivalence classes, which would allow to safely generalize findings about an individual agent to the whole equivalence class. We believe that this might open up interesting future opportunities to boost the generality of analysis methods and automatic diagnostic tools for monitoring of AI systems.",6 Broader Impact,268,8,,,FALSE,FALSE,FALSE,Meta-trained agents implement Bayes-optimal agents,Deep Learning -> Analysis and Understanding of Deep Networks,"Algorithms -> Meta-Learning; Deep Learning -> Recurrent Networks; Deep Learning -> Visualization, Interpretability, and Explainability; Social Aspects of Machine Learning -> AI Safety",Theory (including computational and statistical analyses),"['Vladimir Mikulik', ' Grégoire Delétang', ' Tom McGrath', ' Tim Genewein', ' Miljan Martic', ' Shane Legg', ' Pedro Ortega']","{'DeepMind', 'Google DeepMind', 'Deepmind'}",0,1,0,{'UK'}
Learning Agent Representations for Ice Hockey,"Guiliang Liu, Oliver Schulte, Pascal Poupart, Mike Rudd, Mehrsan Javan",Learning Agent Representations for Ice Hockey,d90e5b6628b4291225cba0bdc643c295,https://proceedings.neurips.cc/paper/2020/file/d90e5b6628b4291225cba0bdc643c295-Paper.pdf,"We expect the main impact outside of the machine learning community to be in professional sports. As an entertainment industry, professional sports increases the quality of life for many people. With respect to the broad challenges of our society (polarization, inequality, bias), entertainment is in our view neutral. The main stakeholders impacted will be sports teams, managers, and athletes. For sports stakeholders, we expect mainly positive and some negative outcomes. Positive Outcomes. Our work significantly enhances the reliability of the machine learning algorithm on modeling complex sport dynamics. This allows teams, coaches, and fans to better understand a player’s style, influence, and contributions. The result will be better and even more enjoyable sports. For sports stakeholders, the main positive outcome will be that coaches can deploy players more effectively, which will help them display and improve their considerable skills. This will create winners and losers among the players, but on the whole, a A data-driven approach will increase fairness and objectivity in player performance ranking, while decreasing bias. Bias towards underrepresented groups is known to hurt the perception and career chances of underrepresented groups, such as indigenous ice hockey players; Fred Sasakamoose is a prominent example. Negative Outcomes. Putting players’ performance and contribution under intense study may lead to more performance pressure on the professional players. We believe that for most players this Taylorist pressure [46] is outweighed by the guidance for how to improve both their play and their market value. To apply our model, sports team should invest in technical analytic resources, which might not be affordable for small clubs. It potentially increases the inequality between top-ranked teams and lower-ranked teams. To help level the analytics playing field, we have placed our code in the public domain at github 1. 1 https://github.com/Guiliang/player-embedding-ice-hockey",7 Broader Impact,294,19,,,TRUE,TRUE,FALSE,Learning Agent Representations for Ice Hockey,Deep Learning -> Embedding Approaches,Algorithms -> Representation Learning; Applications -> Game Playing; Deep Learning -> Deep Autoencoders,"Other applications (e.g., robotics, biology, climate, finance)","['Guiliang Liu', ' Oliver Schulte', ' Pascal Poupart', ' Mike Rudd', ' Mehrsan Javan']","{'University of Waterloo', 'Simon Fraser University', 'SPORTLOGiQ'}",1,1,1,{'Canada'}
Weak Form Generalized Hamiltonian Learning,"Kevin Course, Trefor Evans, Prasanth Nair",Weak Form Generalized Hamiltonian Learning,d93c96e6a23fff65b91b900aaa541998,https://proceedings.neurips.cc/paper/2020/file/d93c96e6a23fff65b91b900aaa541998-Paper.pdf,"Since this work is in large part theoretical in nature there are few ethical considerations directly related to this work. In terms of broader impact, this work builds on a long line of work which seeks to build better models for dynamical systems. The long term intent of work in this field is to learn better models of real world systems which currently evade first-principles-based modeling; for example, this has potential applications in climate science, financial markets, and disease outbreak modeling. In addition, this work specifically has presented a novel method for placing strong, high-level, physics informed priors onto the form of the equations governing nonlinear dynamical system to directly learn an ODE and a generalized Hamiltonian from noisy measurements of the system state. We hope this work inspires further development on learning physics inspired parameterizations of dynamical systems.",7 Broader Impact,139,5,,,FALSE,FALSE,FALSE,Weak Form Generalized Hamiltonian Learning,Algorithms -> Dynamical Systems,,,"['Kevin L Course', ' Trefor Evans', ' Prasanth Nair']",{'University of Toronto'},1,0,0,{'Canada'}
Neural Non-Rigid Tracking,"Aljaz Bozic, Pablo Palafox, Michael  Zollhöfer, Angela Dai, Justus Thies, Matthias Niessner",Neural Non-Rigid Tracking,d93ed5b6db83be78efb0d05ae420158e,https://proceedings.neurips.cc/paper/2020/file/d93ed5b6db83be78efb0d05ae420158e-Paper.pdf,"Our paper presents learned non-rigid tracking. It is establishing the basis for the important research field of non-rigid tracking and reconstruction, which is needed for a variety of applications where man-machine and machine-environment interaction is required. These applications range from the field of augmented and virtual reality to autonomous driving and robot control. In the former, a precise understanding of dynamic and deformable objects is of major importance in order to provide an immersive experience to the user. Applications such as holographic calls would greatly benefit from research like ours. This, in turn, could provide society with the next generation of 3D communication tools. On the other hand, as a low-level building block, our work has no direct negative outcome, other than what could arise from the aforementioned applications.",Broader Impact,129,7,,,FALSE,FALSE,FALSE,Neural Non-Rigid Tracking,"Applications -> Body Pose, Face, and Gesture Analysis",Applications -> Computer Vision,Vision,"['Aljaz Bozic', ' Pablo Palafox', ' Michael Zollhöfer', ' Angela Dai', ' Justus Thies', ' Matthias Niessner']","{'Technical University Munich', 'Stanford University', 'Technical University of Munich'}",1,0,0,"{'USA', 'Germany'}"
Collegial Ensembles,"Etai Littwin, Ben Myara, Sima Sabah, Joshua Susskind, Shuangfei Zhai, Oren Golan",Collegial Ensembles,d958628e70134d9e1e17499a9d815a71,https://proceedings.neurips.cc/paper/2020/file/d958628e70134d9e1e17499a9d815a71-Paper.pdf,"We introduce Collegial Ensembles (CE), which is a principled framework for neural network architecture search. The paper makes theoretical contributions backed up by empirical results. In addition, there is a practical message: In order to find a good model with a fixed budget of parameters, one would optimize the primal form of the CE objective, which will minimize variance of the NTK (maximize smoothness) and thereby have a better chance of improving generalization performance. This essentially aims to make optimal use of fixed model capacity. Instead, if the goal is to find a model that minimizes the number of parameters of a base architecture while preserving performance, one would optimize the dual form. This is a form of principled model pruning backed by theory and empirical analysis. Crucially, the CE method allows a user to make smart choices to construct neural network models without needing to train a large search space of models. Instead, they can plug a base architecture into a simple formula corresponding to either the dual or primal objective, and get back a reasonable model that only needs to be trained once. Given that the typical architecture selection process involves an expensive grid search or evolutionary strategy, advances like CE have the potential to reduce data center costs and developer time. In terms of scientific contributions, CE introduces theory and analysis that furthers the growing body of work on understanding deep learning in wide networks, including insights on the neural tangent kernel, which is becoming an important tool in analysis of neural network training behavior. In addition, this work leads to insights in how capacity can be smartly used to produce improved generalization on held out data, which is still a poorly understood aspect of machine learning – which has traditionally focused on optimization. Finally, the empirical studies demonstrate that the theoretical framework can explain certain design choices that have become goto neural network architectures including ResNext, which can lead to further principled advancements. Considering that our work is fundamental science, we are not advocating a particular application, and are instead trying to ensure that the practitioner has more control over how to effectively design models.",Broader Impact,359,13,,,TRUE,TRUE,FALSE,Collegial Ensembles,Deep Learning -> Analysis and Understanding of Deep Networks,Deep Learning -> CNN Architectures,,"['Etai Littwin', ' Ben Myara', ' Sima Sabah', ' Joshua M Susskind', ' Shuangfei Zhai', ' Oren Golan']","{'Apple', 'apple'}",0,1,0,{'USA'}
ICNet: Intra-saliency Correlation Network for Co-Saliency Detection,"Wen-Da Jin, Jun Xu, Ming-Ming Cheng, Yi Zhang, Wei Guo",ICNet: Intra-saliency Correlation Network for Co-Saliency Detection,d961e9f236177d65d21100592edb0769,https://proceedings.neurips.cc/paper/2020/file/d961e9f236177d65d21100592edb0769-Paper.pdf,"This work would potentially benefit researchers in the computer vision community, especially those who are interested in (co-)saliency detection. The authors believe that this work does not have negative societal consequences.",Broader Impact,31,2,FALSE,FALSE,FALSE,FALSE,FALSE,ICNet: Intra-saliency Correlation Network for Co-Saliency Detection,Applications -> Computer Vision,Applications -> Image Segmentation,Vision,"['Da Jin', ' Jun Xu', 'Ming Cheng', ' Yi Zhang', ' Wei Guo']","{'Nankai University', 'Tianjin University'}",1,0,0,{'China'}
Improved Variational Bayesian Phylogenetic Inference with Normalizing Flows,Cheng Zhang,Improved Variational Bayesian Phylogenetic Inference with Normalizing Flows,d96409bf894217686ba124d7356686c9,https://proceedings.neurips.cc/paper/2020/file/d96409bf894217686ba124d7356686c9-Paper.pdf,"Bayesian phylogenetic inference has been applied to a wide range of applications, including genomic epidemiology, conservation genetics, comparative immunology, vaccine design and many more. Our research could be used as a faster alternative to the current MCMC based Bayesian phylogenetic inference methods used in these applications, to deliver reasonably accurate posterior estimates in a more timely manner. Moreover, our use of normalizing flows for more expressive branch length approximations demonstrates the power of deep Bayesian learning for models with complex, highly  structured, non-Euclidean parameter space and is likely to drive the development of new deep learning methods for phylogenetic models and other models with similar structures.",Broader Impact,106,3,,,FALSE,FALSE,FALSE,Improved Variational Bayesian Phylogenetic Inference with Normalizing Flows,Applications -> Computational Biology and Bioinformatics,Algorithms -> Representation Learning; Deep Learning -> Efficient Inference Methods; Probabilistic Methods -> Graphical Models; Probabilistic Methods -> Variational Inference,"Other applications (e.g., robotics, biology, climate, finance)",['Cheng Zhang'],{'Peking University'},1,0,0,{'China'}
Deep Metric Learning with Spherical Embedding,"Dingyi Zhang, Yingming Li, Zhongfei Zhang",Deep Metric Learning with Spherical Embedding,d9812f756d0df06c7381945d2e2c7d4b,https://proceedings.neurips.cc/paper/2020/file/d9812f756d0df06c7381945d2e2c7d4b-Paper.pdf,"In this paper, we mainly investigate the effect of embedding norm to the direction update in the existing angular loss functions and how to improve the angular distance optimization. Our experiments indicate that the proposed SEC would be beneficial for applications related to discriminative representation learning of images in an angular space, where experiments on face recognition are also conducted. However, we note that although face recognition is quite controversial as a technique, there is no reason to expect that the mild improvement brought by SEC to the face recognition performance should make substantial difference to its societal application, nor is it expected to exacerbate its e.g. racial unbalances. As for the existing society and ethical problems of face recognition, we also agree that further study is still needed to make a substantial improvement before it is widely used in real life.",Broader Impact,142,4,,,FALSE,FALSE,FALSE,Deep Metric Learning with Spherical Embedding,Deep Learning,Algorithms -> Metric Learning; Deep Learning -> Embedding Approaches,Deep learning,"['Dingyi Zhang', ' Yingming Li', ' Zhongfei Zhang']",{'Zhejiang University'},1,0,0,{'China'}
Preference-based Reinforcement Learning with Finite-Time Guarantees,"Yichong Xu, Ruosong Wang, Lin Yang, Aarti Singh, Artur Dubrawski",Preference-based Reinforcement Learning with Finite-Time Guarantees,d9d3837ee7981e8c064774da6cdd98bf,https://proceedings.neurips.cc/paper/2020/file/d9d3837ee7981e8c064774da6cdd98bf-Paper.pdf,"Reinforcement learning is increasingly being used in a myriad of decision-making applications ranging from robotics and drone control, to computer games, to tutoring systems, to clinical trials in medicine, to social decision making. Many of these applications have goals that are hard to capture mathematically using a single reward definition, and the common practice of reward hacking [8, 1] (trying to achieve best performance under the specified metric) often leads to undesired behaviors with respect to the original goal of the application. Preference based RL provides an appealing alternative where the user can specify their preferences over alternative trajectories without hard-coding a single reward metric and this way avoid unexpected behavior caused by misspecified reward metrics. This paper substantially expands theoretical understanding of preference based RL by providing the first finite time guarantees, and it could help broaden applicability of this learning modality across multiple areas of its potential beneficial use, in particular where it is currently considered too expensive to set up and deploy.",Broader Impact Discussion,165,4,,,FALSE,FALSE,FALSE,Preference-based Reinforcement Learning with Finite-Time Guarantees,Theory -> Statistical Learning Theory,Algorithms -> Ranking and Preference Learning; Reinforcement Learning and Planning -> Reinforcement Learning,Theory (including computational and statistical analyses),"['Yichong Xu', ' Ruosong Wang', ' Lin Yang', ' Aarti Singh', ' Artur Dubrawski']","{'UCLA', 'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients,"Juntang Zhuang, Tommy Tang, Yifan Ding, Sekhar C. Tatikonda, Nicha Dvornek, Xenophon Papademetris, James Duncan",AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients,d9d4f495e875a2e075a1a4a6e1b9770f,https://proceedings.neurips.cc/paper/2020/file/d9d4f495e875a2e075a1a4a6e1b9770f-Paper.pdf,"Optimization is at the core of modern machine learning, and numerous efforts have been put into it. To our knowledge, AdaBelief is the first optimizer to achieve fast speed, good generalization and training stability. Adabelief can be used for the training of all models that can numerically estimate parameter gradients, hence can boost the development and application of deep learning models.  This work mainly focuses on the theory part, and the social impact is mainly determined by each application rather than by optimizer.",Broader Impact,83,4,,,FALSE,FALSE,FALSE,AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients,Optimization -> Stochastic Optimization,Deep Learning -> Efficient Training Methods; Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Juntang Zhuang', ' Tommy Tang', ' Sekhar C Tatikonda', ' Nicha Dvornek', ' Yifan Ding', ' Xenophon Papademetris', ' James Duncan']","{'University of Central Florida', 'Yale University', 'University of Illinois Urbana-Champaign'}",1,0,0,{'USA'}
Interpretable Sequence Learning for Covid-19 Forecasting,"Sercan Arik, Chun-Liang Li, Jinsung Yoon, Rajarishi Sinha, Arkady Epshteyn, Long  Le, Vikas Menon, Shashank Singh, Leyou Zhang, Martin Nikoltchev, Yash Sonthalia, Hootan Nakhost, Elli Kanal, Tomas Pfister",Interpretable Sequence Learning for COVID-19 Forecasting,d9dbc51dc534921589adf460c85cd824,https://proceedings.neurips.cc/paper/2020/file/d9dbc51dc534921589adf460c85cd824-Paper.pdf,"COVID-19 is an epidemic that is affecting almost all countries in the world at the moment. As of the first week of June, more than 6.5 million people have been infected, resulting in more than 380k fatalities unfortunately. The economical and sociological impacts of COVID-19 are significant, and will be felt for many years to come. Forecasting of the severity of COVID-19 is crucial, for healthcare providers to deliver the healthcare support for those who will be in the most need, for governments to take the most optimal policy actions while minimizing the negative impact of the outbreak, and for business owners to make crucial decisions on when and how to restart their businesses. With the motivation of helping all these actors, we propose a machine learning-based forecasting model that significantly outperforms any alternative methods, including the ones used by the healthcare providers and public sector. Not only are our forecasts far more accurate, our model is explainable by design. It is aligned with how epidemiology experts approach the problem, and the machine learnable components shed light on what data features have the most impact on the outcomes. These would be crucial for data-driven understanding of COVID-19, that can help domain experts for effective medical and public health decision-making. Besides COVID-19 forecasting, our approach is in the direction of ingesting data-driven learning while using the inductive bias of differential equations, while representing the input-output relationships at a system-level. Not only infectious disease modeling, but numerous scientific fields that use such equations, such as Physics, Environmental Sciences, Chemistry etc. are expected to benefit from our contributions.",Broader Impact,265,11,,,FALSE,FALSE,FALSE,Interpretable Sequence Learning for Covid-19 Forecasting,Applications -> Health,Applications -> Time Series Analysis,,"['Sercan Arik', 'Liang Li', ' Martin Nikoltchev', ' Rajarishi Sinha', ' Arkady Epshteyn', ' Jinsung Yoon', ' Long Le', ' Vikas Menon', ' Shashank Singh', ' Yash Sonthalia', ' Hootan Nakhost', ' Leyou Zhang', ' Elli Kanal', ' Tomas Pfister']",{'Google'},0,1,0,{'USA'}
Off-policy Policy Evaluation For Sequential Decisions Under Unobserved Confounding,"Hongseok Namkoong, Ramtin Keramati, Steve Yadlowsky, Emma Brunskill",Off-policy Policy Evaluation For Sequential Decisions Under Unobserved Confounding,da21bae82c02d1e2b8168d57cd3fbab7,https://proceedings.neurips.cc/paper/2020/file/da21bae82c02d1e2b8168d57cd3fbab7-Paper.pdf,"Understanding the impact of unobserved confounding in off-policy policy evaluation is crucial to reliable deployment of sequential policies. Our work is the one of the first—hopefully many others to follow—to develops tools that protect against deploying unreliable policies. For example, in healthcare systems, our methods can prevent premature deployment of unreliable automated policies based on spurious correlations, and guarantee that observed gains are robust to potential bias caused by unobserved confounding. The goal of our method is to certify the reliability of off-policy policy evaluation. However, we require making assumptions about the data generating process to do so. In particular, we assume a bounded effect of confounding on the behavior policy’s actions. Therefore, our certificates are only valid if this assumption holds. Users might be overconfident—trusting the bounds produced by this method could lead to problems if there is more confounding than assumed. To mitigate the risk of such usage, researchers should be aware of our modeling assumptions, have thoughtful conversations with application area experts about the plausible levels of confounding and think rigorously about all off-policy policy evaluation estimates and bounds. In high risk applications, results of our method or any off-policy policy evaluation should be confirmed in limited online evaluation before being widely deployed. Finally, we hope that our work can bridge the gap between many different communities— epidemiology, economics, operations research, RL and causal inference—working on similar topics. Building reliable sequential policies for high stake scenarios like health care and education is an ambitious goal that will require an interdisciplinary effort.",Broader Impact,254,12,,,FALSE,TRUE,FALSE,Off-policy Policy Evaluation For Sequential Decisions Under Unobserved Confounding,Probabilistic Methods -> Causal Inference,Social Aspects of Machine Learning -> AI Safety,Reinforcement learning and planning,"['Hongseok Namkoong', ' Ramtin Keramati', ' Steve Yadlowsky', ' Emma Brunskill']",{'Stanford University'},1,0,0,{'USA'}
Modern Hopfield Networks and Attention for Immune Repertoire Classification,"Michael Widrich, Bernhard Schäfl, Milena Pavlović, Hubert Ramsauer, Lukas Gruber, Markus Holzleitner, Johannes Brandstetter, Geir Kjetil Sandve, Victor Greiff, Sepp Hochreiter, Günter Klambauer",Modern Hopfield Networks and Attention for Immune Repertoire Classification,da4902cb0bc38210839714ebdcf0efc3,https://proceedings.neurips.cc/paper/2020/file/da4902cb0bc38210839714ebdcf0efc3-Paper.pdf,"Impact on machine learning and related scientific fields. We envision that with (a) the increasing availability of large immunosequencing datasets (Kovaltsuk et al., 2018; Corrie et al., 2018; Christley et al., 2018; Zhang et al., 2020; Rosenfeld et al., 2018; Shugay et al., 2018), (b) further fine-tuning of ground-truth benchmarking immune receptor datasets (Weber et al., 2020; Olson et al., 2019; Marcou et al., 2018), (c) accounting for repertoire-impacting factors such as age, sex, ethnicity, and environment (potential confounding factors), and (d) increased GPU memory and increased computing power, it will be possible to identify discriminating immune receptor motifs for many diseases, potentially even for the current SARS-CoV-2 (COVID-19) pandemic (Raybould et al., 2020; Minervina et al., 2020; Galson et al., 2020). Such results would greatly benefit ongoing research on antibody and TCR-driven immunotherapies and immunodiagnostics as well as rational vaccine design (Brown et al., 2019). In the course of this development, the experimental verification and interpretation of machine-learning- identified motifs could receive additional focus, as for most of the sequences within a repertoire the corresponding antigen is unknown. Nevertheless, recent technological breakthroughs in high- throughput antigen-labeled immunosequencing are beginning to generate large-scale antigen-labeled single-immune-receptor-sequence data, thus resolving this longstanding problem (Setliff et al., 2019). From a machine learning perspective, the successful application of DeepRC on immune repertoires with their large numbers of instances per bag might encourage the application of modern Hopfield networks and attention mechanisms on new, previously unsolved or unconsidered, datasets and problems. Impact on society. If the approach proves itself successful, it could lead to faster testing of individuals for their immune status w.r.t. a range of diseases based on blood samples. This might motivate changes in the pipeline of diagnostics and tracking of diseases, e.g. automated testing of the immune status in regular intervals. It would furthermore make the collection and screening of blood samples for larger databases more attractive. In consequence, the improved testing of immune statuses might identify individuals that do not have a working immune response towards certain diseases to government or insurance companies, which could then push for targeted immunisation of the individual. Similarly to compulsory vaccination, such testing for the immune status could be made compulsory by governments, possibly violating privacy or personal self-determination in exchange for increased over-all health of a population. Ultimately, if the approach proves itself successful, the insights gained from the screening of individuals that have successfully developed resistances against specific diseases could lead to faster targeted immunisation, once a certain number of individuals with resistances can be found. This might strongly decrease the harm done by e.g. pandemics and lead to a change in the societal perception of such diseases. Consequences of failures of the method. As common with methods in machine learning, potential danger lies in the possibility that users rely too much on our new approach and use it without reflecting on the outcomes. However, the full pipeline in which our method would be used includes wet lab tests after its application to verify and investigate the results, gain insights, and possibly derive treatments. Failures of the proposed method would lead to unsuccessful wet lab validation and negative wet lab tests. Since the proposed algorithm does not directly suggest treatment or therapy, human beings are not directly at risk of being treated with a harmful therapy. Substantial wet lab and in-vitro testing and would indicate wrong decisions by the system. Leveraging of biases in the data and potential discrimination. As for almost all machine learning methods, confounding factors, such as age or sex, could be used for classification. This, might lead to biases in predictions or uneven predictive performance across subgroups. As a result, failures in the wet lab would occur (see paragraph above). Moreover, insights into the relevance of the confounding factors could be gained, leading to possible therapies or counter-measures concerning said factors. Furthermore, the amount of data available with respect to relevant confounding factors could lead to better or worse performance of our method. E.g. a dataset consisting mostly of data from individuals within a specific age group might yield better performance for that age group, possibly resulting in better or exclusive treatment methods for that specific group. Here, again, the application of DeepRC would be followed by in-vitro testing and development of a treatment, where all target groups for the treatment have to be considered accordingly.",Broader Impact,727,30,,,TRUE,TRUE,FALSE,Modern Hopfield Networks and Attention for Immune Repertoire Classification,Applications -> Computational Biology and Bioinformatics,Deep Learning -> Attention Models,Deep learning,"['Michael Widrich', ' Bernhard Schäfl', ' Milena Pavlović', ' Hubert Ramsauer', ' Lukas Gruber', ' Markus Holzleitner', ' Johannes Brandstetter', ' Geir Kjetil Sandve', ' Victor Greiff', ' Sepp Hochreiter', ' Günter Klambauer']","{'Department of Immunology, University of Oslo', 'Department of Informatics, University of Oslo', 'LIT AI Lab, Institute for Machine Learning, Johannes Kepler University Linz, Austria', 'LIT AI Lab / University Linz / IARAI', 'JKU Linz', 'Johannes Kepler University', 'LIT AI Lab / University Linz'}",1,1,1,"{'Austria', 'Norway'}"
One Ring to Rule Them All: Certifiably Robust Geometric Perception with Outliers,"Heng Yang, Luca Carlone",One Ring to Rule Them All: Certifiably Robust Geometric Perception with Outliers,da6ea77475918a3d83c7e49223d453cc,https://proceedings.neurips.cc/paper/2020/file/da6ea77475918a3d83c7e49223d453cc-Paper.pdf,"Geometric perception plays an essential role in robotics applications ranging from autonomous driving, robotic manipulation, autonomous flight, to robotic search and rescue. Occasional perception failures are almost inevitable while operating in the wild ( e.g., due to sensor malfunction, or incorrect data association resulting from neural networks or hand-crafted feature matching techniques). These failures, if not detected and handled properly, have detrimental effects, especially in safety-critical and high-integrity applications ( e.g., they may put passengers at risk in autonomous driving or damage a satellite in space applications). Existing perception algorithms ( e.g., fast heuristics) can fail without notice. On the contrary, the certifiable algorithms presented in this work perform geometric perception with optimality guarantees and act as safeguards to detect perception failures. The development of certifiable algorithms has the potential to enhance the robustness of perception systems, inform system certification and monitoring, and increase the trustworthiness of autonomous systems. On the negative side, the use of certifiable algorithms as an enabler for robots and autonomous systems inherits the shortcomings connected to the misuse of these technologies. The use of autonomous systems in military applications as well as the impact of robotics and automation on the (human) workforce must be carefully pondered to ensure a positive societal impact.",Broader Impact,207,8,,,FALSE,FALSE,FALSE,One Ring to Rule Them All: Certifiably Robust Geometric Perception with Outliers,Optimization -> Non-Convex Optimization,Applications -> Computer Vision; Applications -> Object Detection; Applications -> Robotics; Optimization -> Convex Optimization,Vision,"['Heng Yang', ' Luca Carlone']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Task-Robust Model-Agnostic Meta-Learning,"Liam Collins, Aryan Mokhtari, Sanjay Shakkottai",Task-Robust Model-Agnostic Meta-Learning,da8ce53cf0240070ce6c69c48cd588ee,https://proceedings.neurips.cc/paper/2020/file/da8ce53cf0240070ce6c69c48cd588ee-Paper.pdf,"Our work presents a formulation for learning how to learn optimally on the worst-case task from some environment. Although this formulation has no immediate societal consequences, it provides a novel framework for developing realizable meta-learning systems that are robust across all tasks. Such systems are necessary for many applications; one can think of few-shot fingerprint recognition in security systems, one-shot imitation learning for assembly line machines, and few-shot fraud detection as just a few examples. Moreover, systems that treat performance on all tasks equally despite disparities in the amount of data available for each task are critical for fairness in settings where tasks are correlated with people from a particular instance of a protected class such as race or gender. One weakness of our formulation is that it is not robust against adversarial tasks, but in settings where some tasks may be adversarial, our formulation may be modified to optimize the worst-case loss among the percentage of tasks known to be non-adversarial, the analysis of which we leave for future work.",Broader Impact,171,5,,,FALSE,FALSE,FALSE,Task-Robust Model-Agnostic Meta-Learning,Algorithms -> Meta-Learning,Optimization -> Stochastic Optimization,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Liam Collins', ' Aryan Mokhtari', ' Sanjay Shakkottai']","{'UT Austin', 'University of Texas at Austin'}",1,0,0,{'USA'}
R-learning in actor-critic model offers a biologically relevant mechanism for sequential decision-making,"Sergey Shuvaev, Sarah Starosta, Duda Kvitsiani, Adam Kepecs, Alexei Koulakov",R-learning in actor-critic model offers a biologically relevant mechanism for sequential decision-making,da97f65bd113e490a5fab20c4a69f586,https://proceedings.neurips.cc/paper/2020/file/da97f65bd113e490a5fab20c4a69f586-Paper.pdf,"In this work, we used a new foraging task involving decorrelated reward sequences which enabled causal inference of stay-or-leave decision rules in behaving agents (as opposed to the average-case rules studied previously). We propose a biologically relevant decision rule and the corresponding learning mechanism accounting for individual decisions of real-world agents. The authors are not aware of any potential negative societal or other consequences of the new results introduced in this work. All animal procedures in this work were approved by the Cold Spring Harbor Laboratory Institutional Animal Care and Use Committee in accordance with the National Institutes of Health regulations.",Broader Impact,101,4,,,FALSE,FALSE,FALSE,R-learning in actor-critic model offers a biologically relevant mechanism for sequential decision-making,Neuroscience and Cognitive Science -> Neuroscience,"Algorithms -> Continual Learning; Applications -> Computational Biology and Bioinformatics; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Visualization, Interpretability, and Explainability; Neuroscience and Cognitive Science -> Cognitive Science; Neuroscience and Cognitive Science -> Human or Animal Learning; Neuroscience and Cognitive Science -> Plasticity and Adaptation; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> Computational Learning Theory; Theory -> Data-driven Algorithm Design; Theory -> Models of Learning and Generalization",Neuroscience and cognitive science,"['Sergey Shuvaev', ' Sarah Starosta', ' Duda Kvitsiani', ' Adam Kepecs', ' Alexei Koulakov']","{'Cold Spring Harbor Laboratory', 'Aarhus University'}",1,0,0,{'Denmark'}
Revisiting Frank-Wolfe for Polytopes: Strict Complementarity and Sparsity,Dan Garber,Revisiting Frank-Wolfe for Polytopes: Strict Complementarity and Sparsity,da9e6a4a4aeca98588e4dd77ceb37695,https://proceedings.neurips.cc/paper/2020/file/da9e6a4a4aeca98588e4dd77ceb37695-Paper.pdf,Not applicable for this work.,Broader Impact,5,1,TRUE,FALSE,FALSE,FALSE,FALSE,Revisiting Frank-Wolfe for Polytopes: Strict Complementarity and Sparsity,Optimization -> Convex Optimization,,Optimization Methods (continuous or discrete),['Dan Garber'],{'Technion - Israel Institute of Technology'},1,1,1,{'Israel'}
Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev,"Xiao Wang, Qi Lei, Ioannis Panageas",Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev,dab10c50dc668cd8560df444ff3a4227,https://proceedings.neurips.cc/paper/2020/file/dab10c50dc668cd8560df444ff3a4227-Paper.pdf,"Our results is motivated by variant applications of sampling algorithms in machine learning. Generat- ing random sample especially in higher dimension with good convergence and error bound can be used in fast integration and volume computation. With the development of continuous game theory and GANs in recent years, our results have potential impact to solve the Nash equilibrium of the games with continuous strategy space.",7 Broader Impact,65,3,,,FALSE,FALSE,FALSE,Fast Convergence of Langevin Dynamics on Manifold: Geodesics meet Log-Sobolev,Algorithms -> Dynamical Systems,Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Xiao Wang', ' Qi Lei', ' Ioannis Panageas']","{'SUTD', 'Singapore university of technology and design', 'Princeton University'}",1,0,0,"{'Singapore', 'USA'}"
Tensor Completion Made Practical,"Allen Liu, Ankur Moitra",Tensor Completion Made Practical,dab1263d1e6a88c9ba5e7e294def5e8b,https://proceedings.neurips.cc/paper/2020/file/dab1263d1e6a88c9ba5e7e294def5e8b-Paper.pdf,"Our work gives new algorithms for tensor completion. These could certainly have positive societal benefit in terms of furnishing better methods to use in applications, such as those we discussed in the introduction. While a main application is to recommendation systems, where biases in the data can be amplified through algorithms, we believe that an important intermediate goal towards mitigating unfairness is to have a suite of algorithms where we can rigorously analyze them and understand their behavior. Our work takes a positive step in this direction.",Broader Impact,87,4,,,FALSE,FALSE,FALSE,Tensor Completion Made Practical,Algorithms -> Missing Data,Theory -> Computational Learning Theory,Theory (including computational and statistical analyses),"['Allen Liu', ' Ankur Moitra']",{'MIT'},1,0,0,{'USA'}
Optimization and Generalization Analysis of Transduction through Gradient Boosting and Application to Multi-scale Graph Neural Networks,"Kenta Oono, Taiji Suzuki",Optimization and Generalization Analysis of Transduction through Gradient Boosting and Application to Multi-scale Graph Neural Networks,dab49080d80c724aad5ebf158d63df41,https://proceedings.neurips.cc/paper/2020/file/dab49080d80c724aad5ebf158d63df41-Paper.pdf,"Benefits Deepening the theoretical understanding of machine learning models motivates people to explore their advanced usage. For example, the universality of MLPs boosted their usage as a building block of more advanced models as a function approximator (e.g., deep reinforcement  learning). In this study, we investigated the probable optimization and generalization guarantees of GNNs, especially multi-scale GNNs. We expect that this research to broaden the applicability of GNNs in both theoretical and practical situations. Potential Risks and Associated Mitigations The theoretical understanding of GNNs could result in their misuse, either intentionally or unintentionally. For example, if a GNN is used in social networks, the contamination of biased information on the networks such as fake news could affect the prediction of GNNs, thereby resulting in the promotion of social disruption or unfair treatment to minority groups. The methods devised in the study of fairness could mitigate such misuse of GNNs.",Broader Impact,149,7,,,FALSE,FALSE,FALSE,Optimization and Generalization Analysis of Transduction through Gradient Boosting and Application to Multi-scale Graph Neural Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Boosting and Ensemble Methods; Deep Learning -> Optimization for Deep Networks; Optimization -> Convex Optimization; Theory -> Statistical Learning Theory,Deep learning,"['Kenta Oono', ' Taiji Suzuki']",{'The University of Tokyo/JST-PRESTO/RIKEN'},1,1,1,{'Japan'}
Content Provider Dynamics and Coordination in Recommendation Ecosystems,"Omer Ben-Porat, Itay Rosenberg, Moshe Tennenholtz",Content Provider Dynamics and Coordination in Recommendation Ecosystems,dabd8d2ce74e782c65a973ef76fd540b,https://proceedings.neurips.cc/paper/2020/file/dabd8d2ce74e782c65a973ef76fd540b-Paper.pdf,"It is well-understood in the Machine Learning community that economic aspects must be incorporated into machine learning algorithms. In that view, estimating content satisfaction in RSs is not enough. As we argue in this paper, content providers depend on the system for some part of their income; thus, their better treatment makes them the main beneficiaries of the stance this paper offers. We envision that RSs that will coordinate their content providers (and hence the content available for recommendation) will suffer from less fluctuations, be deemed fairer by all their stakeholders, and will enjoy long-term consumer engagement.",Broader Impact,97,4,,,FALSE,FALSE,FALSE,Content Provider Dynamics and Coordination in Recommendation Ecosystems,Theory -> Game Theory and Computational Economics,,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Porat', ' Itay Rosenberg', ' Moshe Tennenholtz']","{'Technion--Israel Institute of Technology', 'Technion'}",1,1,1,{'Israel'}
Almost Surely Stable Deep Dynamics,"Nathan Lawrence, Philip Loewen, Michael Forbes, Johan Backstrom, Bhushan Gopaluni",Almost Surely Stable Deep Dynamics,daecf755df5b1d637033bb29b319c39a,https://proceedings.neurips.cc/paper/2020/file/daecf755df5b1d637033bb29b319c39a-Paper.pdf,"Stability goes hand in hand with safety. Therefore, stability considerations are crucial for the broad acceptance of DNNs in real-world industrial applications such as control, self-driving vehicles, or anaesthesia feedback, to name a few. To this end, industries or companies with sufficient compu- tational and storage resources would benefit significantly through the use of such autonomous and interpretable technologies. However, this work mostly provides some theory and a proof of concept for stable DNNs in stochastic settings and as such does not pose a clear path nor an ethical quandary regarding such widespread control applications.",Broader Impact,95,4,,,FALSE,FALSE,FALSE,Almost Surely Stable Deep Dynamics,Algorithms -> Dynamical Systems,,"Resubmitting form: either ""deep learning"" or (if applicable) ""dynamical systems""","['Nathan Lawrence', ' Philip Loewen', ' Michael Forbes', ' Johan Backstrom', ' Bhushan Gopaluni']","{'University of British Columbia', 'Honeywell'}",1,1,1,"{'Canada', 'USA'}"
Experimental design for MRI by greedy policy search,"Tim Bakker, Herke van Hoof, Max Welling",Experimental design for MRI by greedy policy search,daed210307f1dbc6f1dd9551408d999f,https://proceedings.neurips.cc/paper/2020/file/daed210307f1dbc6f1dd9551408d999f-Paper.pdf,"Accelerating MRI reconstructions beyond the current standard has the potential to improve patient satisfaction and throughput. In this paper we have attempted to analyse the subproblem of designing optimal sampling strategies with deep learning methods in a way that provides future research with more principled motivations for choosing a particular approach to this problem. However, more work is needed before the insights of this paper become directly clinically relevant. In particular, it is unclear that simple image quality metrics (such as the SSIM used in this work) provide an adequate measure of clinical usability [7]. While the results of the fastMRI reconstruction challenge [22] suggest that the SSIM does provide estimates of image quality consistent with the preferences of radiologists, it is also noted that current reconstruction methods have trouble identifying subtle pathologies, as these are smoothed out by the average signal from the dataset. The authors of [22] suggest that more work is needed relating radiologists’ preferences to image quality metrics at the level of diagnostic interpretation. Until then, methods optimised on such metrics should be used in clinical settings only with extreme care, as they risk falsely declaring a patient free of potential health- and life-threatening pathologies.",Broader Impact,199,7,,,FALSE,FALSE,FALSE,Experimental design for MRI by greedy policy search,Applications -> Health,Algorithms -> Active Learning; Applications -> Computer Vision; Applications -> Signal Processing; Deep Learning -> CNN Architectures; Optimization -> Submodular Optimization; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Reinforcement Learning,Healthcare,"['Tim Bakker', ' Herke van Hoof', ' Max Welling']","{'University of Amsterdam', 'University of Amsterdam / Qualcomm AI Research'}",1,1,1,"{'USA', 'Netherlands'}"
Expert-Supervised Reinforcement Learning for Offline Policy Learning and Evaluation,"Aaron Sonabend, Junwei Lu, Leo Anthony Celi, Tianxi Cai, Peter Szolovits",Expert-Supervised Reinforcement Learning for Offline Policy Learning and Evaluation,daf642455364613e2120c636b5a1f9c7,https://proceedings.neurips.cc/paper/2020/file/daf642455364613e2120c636b5a1f9c7-Paper.pdf,"We believe ESRL is a tool that can help bring RL closer to real-world applications. In particular this will be useful in the clinical setting to find optimal dynamic treatment regimes for complex diseases, or at least assist in treatment decision making. This is because ESRL’s framework lends itself to be questioned by users (physicians) and sheds light into potential biases introduced by the data sampling mechanism used to generate the observed data set. Additionally, using hypothesis testing and accommodating different levels of risk aversion makes the method sensible to offline settings and different real-world applications. It is important when using ESRL and any RL method, to question the validity of the policy’s decisions, the quality of the data, and the method that was used to derive these.",Broader Impact,128,5,,,FALSE,FALSE,FALSE,Expert-Supervised Reinforcement Learning for Offline Policy Learning and Evaluation,Reinforcement Learning and Planning -> Model-Based RL,Applications -> Computational Biology and Bioinformatics; Applications -> Health,Reinforcement learning and planning,"['Aaron Sonabend', ' Junwei Lu', ' Leo Anthony Celi', ' Tianxi Cai', ' Peter Szolovits']","{'Harvard School of Public Health', 'Harvard University', 'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
ColdGANs: Taming Language GANs with Cautious Sampling Strategies,"Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano",ColdGANs: Taming Language GANs with Cautious Sampling Strategies,db261d4f615f0e982983be499e57ccda,https://proceedings.neurips.cc/paper/2020/file/db261d4f615f0e982983be499e57ccda-Paper.pdf,"Fluent and reliable Natural Language Generation can have significant societal impacts. On the one hand, we envision several applications beneficial for business, research or education: from automatic summarization of news, papers or books, to efficient information access; from automatic and person- alized student evaluation tests trough question generation, to responsive conversational interfaces. On the other hand, malicious actors can use the same technology to build tools detrimental to society, e.g. for creation and propagation of misleading (fake) news as discussed in [30], impersonation, and deceit. Nonetheless, keeping this research open and under public scrutiny is arguably one of the best ways to defend against such actors [53].",Broader Impact,107,4,,,FALSE,FALSE,FALSE,ColdGANs: Taming Language GANs with Cautious Sampling Strategies,Applications -> Natural Language Processing,,Natural language processing,"['Thomas Scialom', 'Alexis Dray', ' Sylvain Lamprier', ' Benjamin Piwowarski', ' Jacopo Staiano']","{'LIP6, UPMC / CNRS, Paris, France', 'LIP6-UPMC', 'reciTAL'}",1,1,1,{'France'}
Hedging in games: Faster convergence of external and swap regrets,"Xi Chen, Binghui Peng",Hedging in games: Faster convergence of external and swap regrets,db346ccb62d491029b590bbbf0f5c412,https://proceedings.neurips.cc/paper/2020/file/db346ccb62d491029b590bbbf0f5c412-Paper.pdf,"The paper has impact on research in the game theory community, and could also benefit future research on multi-agent learning.",Broader Impact,20,1,FALSE,FALSE,FALSE,TRUE,FALSE,Hedging in games: Faster convergence of external and swap regrets,Theory -> Game Theory and Computational Economics,Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Xi Chen', ' Binghui Peng']",{'Columbia University'},1,0,0,{'USA'}
The Origins and Prevalence of Texture Bias in Convolutional Neural Networks,"Katherine Hermann, Ting Chen, Simon Kornblith",The Origins and Prevalence of Texture Bias in Convolutional Neural Networks,db5f9f42a7157abe65bb145000b5871a,https://proceedings.neurips.cc/paper/2020/file/db5f9f42a7157abe65bb145000b5871a-Paper.pdf,"People who build and interact with tools for computer vision, especially those without extensive training in machine learning, often have a mental model of computer vision models as similar to human vision. Our findings contribute to a body of work showing that this view is actually far from correct, especially for ImageNet, one of the datasets most commonly used to train and evaluate models. Divergences between human and machine vision of the kind we study could cause users to make significant errors in anticipating and reasoning about the behavior of computer vision systems. Our findings contribute to a body of work delineating divergences between human and machine vision, and suggesting avenues for bringing the two systems closer together. Allowing people from a wide range of backgrounds to make safe, predictable, and equitable models requires vision systems to perform at least roughly in accordance with their expectations. Making computer vision models that share the same inductive biases as humans is an important step towards this goal. At the same time, we recognize the possible negative consequences of blindly constraining models’ judgments to agree with people’s: human visual judgments display forms of bias that should be kept out of computer models. More broadly, we believe that work like ours can have a beneficial impact on the internal sociology of the machine learning community. By identifying connections to developmental psychology and neuroscience, we hope to enhance interdisciplinary connections across fields, and to encourage people with a broader range of training and backgrounds to participate in machine learning research.",Broader Impact,255,9,,,FALSE,FALSE,FALSE,The Origins and Prevalence of Texture Bias in Convolutional Neural Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Applications -> Computer Vision; Deep Learning -> CNN Architectures; Neuroscience and Cognitive Science -> Visual Perception,Vision,"['Katherine Hermann', ' Ting Chen', ' Simon Kornblith']","{'Google', 'Stanford University', 'Google Brain'}",1,1,1,{'USA'}
Time-Reversal Symmetric ODE Network,"In Huh, Eunho Yang, Sung Ju Hwang, Jinwoo Shin",Time-Reversal Symmetric ODE Network,db8419f41d890df802dca330e6284952,https://proceedings.neurips.cc/paper/2020/file/db8419f41d890df802dca330e6284952-Paper.pdf,"In this paper, we introduce a neural network model that regularized by a physics-originated inductive bias, the symmetry. Our proposed model can be used to identify and predict unknown dynamics of physical systems. In what follows, we summarize the expected broader impacts of our research from two perspectives. Use for current real world applications. Predicting dynamics plays a important role in various practical applications, e.g., robotic manipulation [16], autonomous driving [25], and other trajectory planning tasks. For these tasks, the predictive models should be highly reliable to prevent human and material losses due to accidents. Our propose model have a potential to satisfy this high standard on reliability, considering its robustness and efficiency (see Figure 4 as an example). First step for fundamental inductive bias. According to the CPT theorem in quantum field theory, the CPT symmetry, which means the invariance under the combined transformation of charge conjugate (C), parity transformation (P), and time reversal (T), exactly holds for all phenomena of physics [21]. Thus, the CPT symmetry is a fundamental rule of nature: that means, it is a fundamental inductive bias of deep learning models for natural science. However, this symmetry-based bias has been unnoticed previously. We study one of the fundamental symmetry, the time-reversal symmetry in classical mechanics, as a proof-of-concept in this paper. We expect our finding can encourage researchers to focus on the fundamental bias of nature and extend the research from classical to quantum, and from time-reversal symmetry to CPT symmetry. Our work would also contribute to bring together experts in physics and deep learning in order to stimulate interaction and to begin exploring how deep learning can shed light on physics.",Broader Impact,277,14,,,FALSE,FALSE,FALSE,Time-Reversal Symmetric ODE Network,Algorithms -> Dynamical Systems,Deep Learning -> Predictive Models,"Other applications (e.g., robotics, biology, climate, finance)","['In Huh', ' Eunho Yang', ' Sung Ju Hwang', ' Jinwoo Shin']","{'Samsung Electronics, Samsung Advanced Institute of Technology', 'KAIST, AITRICS', 'KAIST'}",1,1,1,{'South Korea'}
Provable Overlapping Community Detection in Weighted Graphs,"Jimit Majmudar, Stephen Vavasis",Provable Overlapping Community Detection in Weighted Graphs,db957c626a8cd7a27231adfbf51e20eb,https://proceedings.neurips.cc/paper/2020/file/db957c626a8cd7a27231adfbf51e20eb-Paper.pdf,"The problem of community detection (or graph clustering) is a standard abstraction that has been studied by various research communities for a few decades now. This work presents a provable overlapping community detection method which may possibly be used, for instance, by biologists to discover new potentially overlapping protein complexes. Moreover, the proposed work is fairly general and does not present any foreseeable negative societal consequences.",6 Broader Impact,66,3,FALSE,FALSE,FALSE,TRUE,FALSE,Provable Overlapping Community Detection in Weighted Graphs,Algorithms -> Clustering,Algorithms -> Unsupervised Learning; Applications -> Computational Biology and Bioinformatics; Applications -> Network Analysis; Optimization -> Convex Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jimit Majmudar', ' Stephen Vavasis']","{'University of Waterloo', 'University of Waterloo '}",1,0,0,{'Canada'}
Fast Unbalanced Optimal Transport on a Tree,"Ryoma Sato, Makoto Yamada, Hisashi Kashima",Fast Unbalanced Optimal Transport on a Tree,dba31bb5c75992690f20c2d3b370ec7c,https://proceedings.neurips.cc/paper/2020/file/dba31bb5c75992690f20c2d3b370ec7c-Paper.pdf,"This work involves no ethical aspects. Because our algorithm reduces massive amount of computation, this work contributes to society by reducing power consumption and carbon footprint.",Broader Impact,26,2,FALSE,FALSE,FALSE,FALSE,FALSE,Fast Unbalanced Optimal Transport on a Tree,Algorithms -> Similarity and Distance Learning,Deep Learning -> Efficient Inference Methods,Theory (including computational and statistical analyses),,"{'Kyoto University/RIKEN AIP', 'Kyoto University', 'Kyoto University/RIKEN Center for AIP'}",1,0,0,{'Japan'}
Acceleration with a Ball Optimization Oracle,"Yair Carmon, Arun Jambulapati, Qijia Jiang, Yujia Jin, Yin Tat Lee, Aaron Sidford, Kevin Tian",Acceleration with a Ball Optimization Oracle,dba4c1a117472f6aca95211285d0587e,https://proceedings.neurips.cc/paper/2020/file/dba4c1a117472f6aca95211285d0587e-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Acceleration with a Ball Optimization Oracle,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Yair Carmon', ' Arun Jambulapati', ' Qijia Jiang', ' Yujia Jin', ' Yin Tat Lee', ' Aaron Sidford', ' Kevin Tian']","{'UW', 'Stanford University', 'Stanford'}",1,0,0,{'USA'}
Avoiding Side Effects By Considering Future Tasks,"Victoria Krakovna, Laurent Orseau, Richard Ngo, Miljan Martic, Shane Legg",Avoiding Side Effects By Considering Future Tasks,dc1913d422398c25c5f0b81cab94cc87,https://proceedings.neurips.cc/paper/2020/file/dc1913d422398c25c5f0b81cab94cc87-Paper.pdf,"In present-day reinforcement learning, what the agent should not do is usually specified manually, e.g. through constraints or negative rewards. This ad-hoc approach is unlikely to scale to more advanced AI systems in more complex environments. Ad-hoc specifications are usually incomplete, and more capable AI systems will be better at finding and exploiting gaps and loopholes in the specification. We already see many examples of specification gaming with present-day AI systems, and this problem is likely to get worse for more capable AI systems [11]. We think that building and deploying more advanced AI systems calls for general approaches and design principles for specifying agent objectives. Our paper makes progress on developing such a general principle, which aims to capture the heuristic of “do no harm” in terms of the available options in the environment, and gives the agent an incentive to consider the future consequences of its actions beyond the current task. Without a reliable and principled way to avoid unnecessary changes to the world, the deployment of AI systems will be limited to narrow domains where the designer can enumerate everything the agent should not do. Thus, general approaches to objective specification would enable society to reap the benefits of applying capable AI systems to more difficult problems, which has potential for high long-term impact. In terms of negative impacts, adding an auxiliary reward for future tasks increases the computational requirements and thus the energy cost of training reinforcement learning algorithms, compared to hand-designed rewards and constraints for avoiding side effects. The remaining gaps in the theoretical foundations of our method could lead to unexpected issues if they are not researched properly and instead left to empirical evaluation.",Broader Impact,280,10,,,FALSE,FALSE,FALSE,Avoiding Side Effects By Considering Future Tasks,Social Aspects of Machine Learning -> AI Safety,Reinforcement Learning and Planning -> Reinforcement Learning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Victoria Krakovna', ' Laurent Orseau', ' Richard Ngo', ' Miljan Martic', ' Shane Legg']",{'DeepMind'},0,1,0,{'UK'}
Handling Missing Data with Graph Representation Learning,"Jiaxuan You, Xiaobai Ma, Yi Ding, Mykel J. Kochenderfer, Jure Leskovec",Handling Missing Data with Graph Representation Learning,dc36f18a9a0a776671d4879cae69b551,https://proceedings.neurips.cc/paper/2020/file/dc36f18a9a0a776671d4879cae69b551-Paper.pdf,"The problem of missing data arises in almost all practical statistical analyses. The quality of the imputed data influences the reliability of the dataset itself as well as the success of the downstream tasks. Our research provides a new point of view for analysing and handling missing data problems with graph representations . There are many benefits to using this framework. First, different from many existing imputation methods which rely on good heuristics to ensure the performance [43], G RAPE formulates the problem in a natural way without the need of handcrafted features and heuristics. This makes our method ready to use for datasets coming from different domains. Second, similar to convolutional neural networks [24, 41], G RAPE is suitable to serve as a pre-processing module to be connected with downstream task-specific modules. G RAPE could either be pre-trained and fixed or concurrently learned with downstream modules. Third, G RAPE is general and flexible. There is little limitation on the architecture of the graph neural network as well as the imputation ( O edge ) and prediction ( O node ) module. Therefore, researchers can easily plug in domain-specific neural architectures, e.g., BERT [12], to the design of G RAPE . Overall, we see exciting opportunities for G RAPE to help researchers handle missing data and thus boost their research.",Broader Impact,220,12,,,FALSE,FALSE,FALSE,Handling Missing Data with Graph Representation Learning,Algorithms -> Relational Learning,Algorithms -> Missing Data; Algorithms -> Representation Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Jiaxuan You', ' Xiaobai Ma', ' Yi Ding', ' Mykel J Kochenderfer', ' Jure Leskovec']","{'Stanford University', 'Stanford University and Pinterest'}",1,0,0,{'USA'}
Improving Auto-Augment via Augmentation-Wise Weight Sharing,"Keyu Tian, Chen Lin, Ming Sun, Luping Zhou, Junjie Yan, Wanli Ouyang",Improving Auto-Augment via Augmentation-Wise Weight Sharing,dc49dfebb0b00fd44aeff5c60cc1f825,https://proceedings.neurips.cc/paper/2020/file/dc49dfebb0b00fd44aeff5c60cc1f825-Paper.pdf,"In this paper, we propose a new framework to conduct an efficient and reliable Automated Augmentation (AutoAug) search and achieve superior performance compared with existing methods. AutoAug enhances the performances of deep models as a typical Automated Machine Learning (AutoML) technique. For fundamental research and ML applications, our research contributes towards many computer vision areas that benefit from image data augmentations. It may help reduce the demand for data scientists by enabling domain experts to automatically design tailored augmentation strategies without extensive knowledge of statistics and machine learning. For broader societal implications, as an AutoML technique, our approach can be utilized to build models and establish reasonable lower bounds of them for performance quickly and cheaply. It may be useful and powerful to ML practitioners in various entities, such as the media industry, the transportation industry, and the automatic production industries. However, each of these uses may result in job losses. Some other issues, like personal privacy leak problems, may also be raised when this technique is used by those malicious. In summary, this technique may be socially beneficial or harmful, which depends on the users. We would encourage the researchers, general practitioners, or anyone else to use it for social benefits, rather than infringe the interests of individuals and the nation, and threaten social stability.",Broader Impact,216,10,,,FALSE,FALSE,FALSE,Improving Auto-Augment via Augmentation-Wise Weight Sharing,Algorithms -> AutoML,Algorithms -> Classification; Reinforcement Learning and Planning -> Reinforcement Learning,AutoML,"['Keyu Tian', ' CHEN LIN', ' Ming Sun', ' Luping Zhou', ' Junjie Yan', ' Wanli Ouyang']","{'Sensetime', 'SenseTime Group Limited', 'Sensetime Group Limited', 'University of Sydney', 'SenseTime', 'The University of Sydney'}",1,1,1,"{'Hong Kong', 'Australia', 'China'}"
MMA Regularization: Decorrelating Weights of Neural Networks by Maximizing the Minimal Angles,"Zhennan Wang, Canqun Xiang, Wenbin Zou, Chen Xu",MMA Regularization: Decorrelating Weights of Neural Networks by Maximizing the Minimal Angles,dcd2f3f312b6705fb06f4f9f1b55b55c,https://proceedings.neurips.cc/paper/2020/file/dcd2f3f312b6705fb06f4f9f1b55b55c-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,MMA Regularization: Decorrelating Weights of Neural Networks by Maximizing the Minimal Angles,Applications -> Computer Vision,"Applications -> Body Pose, Face, and Gesture Analysis; Applications -> Object Recognition",Deep learning,"['Zhennan Wang', ' Canqun Xiang', ' Wenbin Zou', ' Chen Xu']",{'Shenzhen University'},1,0,0,{'China'}
HRN: A Holistic Approach to One Class Learning,"Wenpeng Hu, Mengyu Wang, Qi Qin, Jinwen Ma, Bing Liu",HRN: A Holistic Approach to One Class Learning,dd1970fb03877a235d530476eb727dab,https://proceedings.neurips.cc/paper/2020/file/dd1970fb03877a235d530476eb727dab-Paper.pdf,"One-class learning has a wide range of applications, especially in anomaly or novelty detection, e.g., detecting intrusions, fraud, medical anomalies, and anomalies in social networks, Internet of things, text documents, images, and videos. Perhaps, more importantly, we believe that our holistic one-class learning can help positive and unlabeled (PU) learning, open-world learning (or out-of-distribution detection), and continual learning as all these learning paradigms need to face unseen/novel situations. We have shown a continual learning application in the paper. We don’t see that anyone could be put at disadvantage from this research. The consequence of failure of the system is that the system recognizes some anomalies wrongly. We don’t think that the task or the method leverages biases in the data. In fact, our proposed holistic regularization tries to avoid using any biases in the data.",Broader Impact,135,7,,,FALSE,FALSE,FALSE,HRN: A Holistic Approach to One Class Learning,Algorithms -> Semi-Supervised Learning,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,{'Peking University'},1,0,0,{'China'}
The Generalized Lasso with Nonlinear Observations and Generative Priors,"Zhaoqiang Liu, Jonathan Scarlett",The Generalized Lasso with Nonlinear Observations and Generative Priors,dd45045f8c68db9f54e70c67048d32e8,https://proceedings.neurips.cc/paper/2020/file/dd45045f8c68db9f54e70c67048d32e8-Paper.pdf,"Who may benefit from this research. This is a theory paper primarily targeted at the research community. The signal recovery techniques studied could potentially be useful for practitioners in areas such as image processing, audio processing, and medical imaging. Who may be put at disadvantage from this research. We are not aware of any significant/imminent risks of placing anyone at a disadvantage. Consequences of failure of the system. We believe that most failures should be immediately evident and detectable due to visibly poor reconstruction performance, and any such outputs could be discarded as needed. However, some more subtle issues could arise, such as the reconstruction missing important details in the signal due to the generative model not capturing them. As a result, care is advised in the choice of generative model, particularly in applications for which the reconstruction of fine details is crucial. Potential biases. The signal recovery algorithm that we consider takes as input an arbitrary pre- trained generative model. If such a pre-trained model has inherent biases, they could be transferred to the signal recovery algorithm.",Broader Impact,178,12,,,FALSE,FALSE,FALSE,The Generalized Lasso with Nonlinear Observations and Generative Priors,Algorithms -> Sparsity and Compressed Sensing,Theory -> High-Dimensional Inference,Theory (including computational and statistical analyses),"['Zhaoqiang Liu', ' Jonathan Scarlett']",{'National University of Singapore'},1,0,0,{'Singapore'}
Fair regression via plug-in estimator and recalibration with statistical guarantees,"Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto, Massimiliano Pontil",Fair Regression via Plug-In Estimator and Recalibration,ddd808772c035aed516d42ad3559be5f,https://proceedings.neurips.cc/paper/2020/file/ddd808772c035aed516d42ad3559be5f-Paper.pdf,"Although theoretical, our work may have at least two indirect positive future societal effects. First, the proposed algorithm is easy to implement and use, since it works in a post-processing regime. This makes it potentially attractive to practitioners who use computationally demanding methods. Second, our procedure comes with strong theoretical guarantees, making our contribution more reliable in practice. Despite this potentially positive impact, one should be aware that the notion of demographic parity is only a way to formalize the idea of fairness in a rigorous mathematical manner and, as other similar formalizations, it might not reflect the reality. Hence, while this fact does not compromise our theoretical contribution, one has to pay extra care to the choice of the fairness notion when machine learning algorithms are to be deployed to society.",Broader impact,132,6,,,FALSE,FALSE,FALSE,Fair regression via plug-in estimator and recalibration with statistical guarantees,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Regression; Theory -> Statistical Learning Theory,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Evgenii Chzhen', ' Christophe Denis', ' Mohamed Hebiri', ' Luca Oneto', ' Massimiliano Pontil']","{'IIT', 'Université Gustave Eiffel', 'University of Genoa', 'Universite Paris Est', 'Université Paris-Saclay'}",1,0,0,"{'France', 'India', 'Italy'}"
Modeling Shared responses in Neuroimaging Studies through MultiView ICA,"Hugo Richard, Luigi Gresele, Aapo Hyvarinen, Bertrand Thirion, Alexandre Gramfort, Pierre Ablin",Modeling Shared Responses in Neuroimaging Studies through MultiView ICA,de03beffeed9da5f3639a621bcab5dd4,https://proceedings.neurips.cc/paper/2020/file/de03beffeed9da5f3639a621bcab5dd4-Paper.pdf,"We develop a novel unsupervised learning method for Independent Component Analysis of a group of subjects sharing commmon sources. Our method is not limited to a particular type of data, and could hence be employed in observational sciences where ICA is relevant: neurosciences, genomics, astrophysics, finance or computer vision for instance. ICA is widely used in these fields as a tool among data processing pipelines, and therefore inherits from all the ethical questions of the fields above. In particular, data collection bias will result in biased outputs. Our algorithm is based on individual linear transforms and therefore decisions based on its application are easier to interpret than more complex models such as deep learning methods: in most applications, the set of parameters has a natural interpretation. For instance in EEG, MEG and fMRI processing, the coefficients of the linear operator can be interpreted as topographic brain maps.",Broader Impact,147,6,,,FALSE,FALSE,FALSE,Modeling Shared responses in Neuroimaging Studies through MultiView ICA,Neuroscience and Cognitive Science -> Brain Imaging,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)",Neuroscience and cognitive science,"['Hugo Richard', ' Luigi Gresele', ' Aapo Hyvarinen', ' Bertrand Thirion', ' Alexandre Gramfort', ' Pierre Ablin']","{'MPI for Intelligent Systems, Tübingen', 'University of Helsinki', 'INRIA'}",1,0,0,"{'France', 'Finland', 'Germany'}"
Efficient Planning in Large MDPs with Weak Linear Function Approximation,"Roshan Shariff, Csaba Szepesvari",Efficient Planning in Large MDPs with Weak Linear Function Approximation,de07edeeba9f475c9395959494cd8f64,https://proceedings.neurips.cc/paper/2020/file/de07edeeba9f475c9395959494cd8f64-Paper.pdf,"Our research has the nature of basic science — we are working on foundational improvements to reinforcement learning algorithms. We are not targeting any specific applications, and it is hard to foresee any societal consequences beyond those brought about by advancing the state of our knowledge of machine learning.",Broader Impact,49,2,TRUE,FALSE,FALSE,FALSE,FALSE,Efficient Planning in Large MDPs with Weak Linear Function Approximation,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning; Theory,Reinforcement learning and planning,"['Roshan Shariff', ' Csaba Szepesvari']","{'University of Alberta', 'DeepMind / University of Alberta'}",1,1,1,"{'Canada', 'UK'}"
Efficient Learning of Generative Models via Finite-Difference Score Matching,"Tianyu Pang, Taufik Xu, Chongxuan LI, Yang Song, Stefano Ermon, Jun Zhu",Efficient Learning of Generative Models via Finite-Difference Score Matching,de6b1cf3fb0a3aa1244d30f7b8c29c41,https://proceedings.neurips.cc/paper/2020/file/de6b1cf3fb0a3aa1244d30f7b8c29c41-Paper.pdf,"This work proposes an efficient way to learn generative models and does not have a direct impact on society. However, by reducing the computation required for training unnormalized models, it may facilitate large-scale applications of, e.g., EBMs to real-world problems, which could have both positive (e.g., anomaly detection and denoising) and negative (e.g., deepfakes) consequences.",Broader Impact,55,2,FALSE,TRUE,FALSE,FALSE,FALSE,Efficient Learning of Generative Models via Finite-Difference Score Matching,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Deep Learning -> Efficient Training Methods,Probabilistic methods and inference,"['Tianyu Pang', ' Taufik Xu', ' Chongxuan LI', ' Yang Song', ' Stefano Ermon', ' Jun Zhu']","{'Stanford', 'Stanford University', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Semialgebraic Optimization for Lipschitz Constants of ReLU Networks,"Tong Chen, Jean B. Lasserre, Victor Magron, Edouard Pauwels",Semialgebraic Optimization for Lipschitz Constants of ReLU Networks,dea9ddb25cbf2352cf4dec30222a02a5,https://proceedings.neurips.cc/paper/2020/file/dea9ddb25cbf2352cf4dec30222a02a5-Paper.pdf,Developing optimization methods resulting in numerical certificates is a necessary step toward the verification of systems involving AI trained components. Such systems are expected to be more and more common in the transport industry and constitute a major challenge in terms of certification. We believe that polynomial optimization is one promising tool to address this challenge.,Broader Impact,56,3,FALSE,FALSE,FALSE,FALSE,FALSE,Semialgebraic Optimization for Lipschitz Constants of ReLU Networks,Deep Learning -> Optimization for Deep Networks,"Optimization -> Non-Convex Optimization; Social Aspects of Machine Learning -> AI Safety; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Optimization Methods (continuous or discrete),"['Tong Chen', ' Jean B Lasserre', ' Victor Magron', ' Edouard Pauwels']","{'IRIT', 'LAAS-CNRS'}",1,0,0,{'France'}
Linear-Sample Learning of Low-Rank Distributions,"Ayush Jain, Alon Orlitsky",Linear-Sample Learning of Low-Rank Distributions,df0b8fb21c53254b7afa62e020447c81,https://proceedings.neurips.cc/paper/2020/file/df0b8fb21c53254b7afa62e020447c81-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Linear-Sample Learning of Low-Rank Distributions,Theory -> Information Theory,Algorithms -> Density Estimation,Theory (including computational and statistical analyses),"['Ayush Jain', ' Alon Orlitsky']","{'UC San Diego', 'University of California, San Diego'}",1,0,0,{'USA'}
Transferable Calibration with Lower Bias and Variance in Domain Adaptation,"Ximei Wang, Mingsheng Long, Jianmin Wang, Michael Jordan",Transferable Calibration with Lower Bias and Variance in Domain Adaptation,df12ecd077efc8c23881028604dbb8cc,https://proceedings.neurips.cc/paper/2020/file/df12ecd077efc8c23881028604dbb8cc-Paper.pdf,"The open problem of Calibration in DA that we delve into is a very promising research direction and important for decision making in safety-critical applications, such as automated diagnosis system for lung cancer. Since our method can be easily applied to recalibrate the existing DA methods and generate more reliable predictions, it will benefit the transfer learning community. If the method fails in some extreme circumstances, it will confuse researchers or engineers who apply our method but it will not bring about any negative ethical or societal consequences. Meanwhile, our method did not leverage biases in the data such as racial discrimination and gender discrimination since we conduct experiments on standard domain adaptation datasets that are more about animals or pieces of equipment in the office. In summary, we hold a positive view of the broader impact on this paper.",Broader Impact,140,5,,,FALSE,FALSE,FALSE,Transferable Calibration with Lower Bias and Variance in Domain Adaptation,Algorithms -> Multitask and Transfer Learning,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Ximei Wang', ' Mingsheng Long', ' Jianmin Wang', ' Michael Jordan']","{'UC Berkeley', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
Generalization bound of globally optimal non-convex neural network training: Transportation map estimation by infinite dimensional Langevin dynamics,Taiji Suzuki,Generalization bound of globally optimal non-convex neural network training: Transportation map estimation by infinite dimensional Langevin dynamics,df1a336b7e0b0cb186de6e66800c43a9,https://proceedings.neurips.cc/paper/2020/file/df1a336b7e0b0cb186de6e66800c43a9-Paper.pdf,"Benefit Since deep learning is used in several applications across broad range of areas, our theoretical analysis about optimization of deep learning would influence wide range of areas in terms of understanding of the algorithmic behavior. One of the biggest criticisms on deep learning is its poor explainability and interpretability. Our work on optimization analysis of deep learning can much improve explainability and would facilitate its usage. This is quite important step toward trustworthy machine learning. Potential risk On the other hand, this is purely theoretical work and thus would not directly bring on severe ethical issues. However, misunderstanding of theoretical work would cause misuse of its statement to conduct an intensional opinion making. To avoid such a potential risk, we made our best effort to minimize technical ambiguity in our paper presentation.",Broader impact,133,7,,,FALSE,FALSE,FALSE,Generalization bound of globally optimal non-convex neural network training: Transportation map estimation by infinite dimensional Langevin dynamics,Theory -> Statistical Learning Theory,Deep Learning -> Optimization for Deep Networks; Optimization -> Non-Convex Optimization; Theory -> Models of Learning and Generalization,,['Taiji Suzuki'],{'The University of Tokyo/JST-PRESTO/RIKEN'},1,1,1,{'Japan'}
Online Bayesian Goal Inference for Boundedly Rational Planning Agents,"Tan Zhi-Xuan, Jordyn Mann, Tom Silver, Josh Tenenbaum, Vikash Mansinghka",Online Bayesian Goal Inference for Boundedly-Rational Planning Agents,df3aebc649f9e3b674eeb790a4da224e,https://proceedings.neurips.cc/paper/2020/file/df3aebc649f9e3b674eeb790a4da224e-Paper.pdf,"We embarked upon this research in the belief that, as increasingly powerful autonomous systems become embedded in our society, it may eventually become necessary for them to accurately understand our goals and values, so as to robustly act in our collective interest. Crucially, this will require such systems to understand the ways in which humans routinely fail to achieve our goals, and not take that as evidence that those goals were never desired. Due to our manifold cognitive limitations, gaps emerge between our goals and our intentions, our intentions and our actions, our beliefs and our conclusions, and our ideals and our practices. To the extent that we would like machines to aid us in actualizing the goals and ideals we most value, rather than those we appear to be acting towards, it will be critical for them to understand how, when, and why those gaps emerge. This aspect of the value alignment problem has thus far been under-explored [51]. By performing this research at the intersection of cognitive science and AI, we hope to lay some of the conceptual and technical groundwork that may be necessary to understand our boundedly-rational behavior. Of course, the ability to infer the goals of others, and to do so online and despite failures, has many more immediate uses, each of them with its own set of benefits and risks. Perhaps the most straightforwardly beneficial are assistive use cases, such as smart user interfaces [52], intelligent personal assistants, and collaborative robots, which may offer to aid a user if that user appears to be pursuing a sub-optimal plan. However, even those use cases come with the risk of reducing human autonomy, and care should be taken so that such applications ensure the autonomy and willing consent of those being aided [53]. More concerning however is the potential for such technology to be abused for manipulative, offensive, or surveillance purposes. While the research presented in this paper is nowhere near the level of integration that would be necessary for active surveillance or manipulation, it is highly likely that mature versions of similar technology will be co-opted for such purposes by governments, militaries, and the security industry [54, 55]. Although detecting and inferring “suspicious intent” may not seem harmful in its own right, these uses need to be considered within the broader context of society, especially the ways in which marginalized peoples are over-policed and incarcerated [56]. Given these risks, we urge future research on this topic to consider seriously the ways in which technology of this sort will most likely be used, by which institutions, and whether those uses will tend to lead to just and beneficial outcomes for society as a whole. The ability to infer and understand the motives of others is a skill that can be wielded to both great benefit and great harm. We ought to use it wisely.",7 Broader Impact,478,15,,,FALSE,FALSE,FALSE,Online Bayesian Goal Inference for Boundedly Rational Planning Agents,Probabilistic Methods -> Probabilistic Programming,Neuroscience and Cognitive Science -> Cognitive Science; Reinforcement Learning and Planning -> Planning,Probabilistic methods and inference,"['Xuan', ' Jordyn Mann', ' Tom Silver', ' Josh Tenenbaum', ' Vikash Mansinghka']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
BayReL: Bayesian Relational Learning for Multi-omics Data Integration,"Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna Narayanan, Xiaoning Qian",BayReL: Bayesian Relational Learning for Multi-omics Data Integration,df5511886da327a5e2877c3cd733d9d7,https://proceedings.neurips.cc/paper/2020/file/df5511886da327a5e2877c3cd733d9d7-Paper.pdf,"Our BayReL provides a general graph learning framework that can flexibly integrate prior knowledge when facing a limited number of training samples, which is often the case in scientific and biomedical applications. BayReL is unique in its model and potential applications. This novel generative model is able to deal with growing complexity and heterogeneity of modern large-scale data with complex dependency structures, which is especially critical when analyzing multi-omics data to derive biological insights, the main focus of our research. Furthermore, learning with biomedical data can have significant impact in helping decision making in healthcare. However, decision making in biomedicine has to be robust and aware of potential data and prediction uncertainty as it can lead to significant consequences (life vs. death). Therefore, it is critical to develop accurate and reproducible results from new machine learning efforts. BayReL is a generative model with Bayesian modeling and robust variational inference and hence is equipped with natural uncertainty estimates, which will help derive reproducible and accurate prediction for robust decision making, with the ultimate goal of improving human health outcomes, as showcased in the three experiments.",Broader Impact,184,7,,,FALSE,FALSE,FALSE,BayReL: Bayesian Relational Learning for Multi-omics Data Integration,Applications -> Computational Biology and Bioinformatics,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Ehsan Hajiramezanali', ' Arman Hasanzadeh', ' Nick Duffield', ' Krishna Narayanan', ' Xiaoning Qian']",{'Texas A&M University'},1,0,0,{'USA'}
Weakly Supervised Deep Functional Maps for Shape Matching,"Abhishek Sharma, Maks Ovsjanikov",Weakly Supervised Deep Functional Map for Shape Matching,dfb84a11f431c62436cfb760e30a34fe,https://proceedings.neurips.cc/paper/2020/file/dfb84a11f431c62436cfb760e30a34fe-Paper.pdf,"Efficient algorithms for solving the shape correspondence problem have immediate impact in many areas of science and engineering from statistical shape analysis, creation of virtual avatars, medical imaging (for instance for detecting anomalies, and performing follow-up analysis). Our approach can immediately be adapted and tested in such diverse scenarios. This is particularly true as our method is efficient and fully automatic. We believe that the observations made in our work can also lead to new insights in other areas including graph matching and machine translation, where data is often represented as point clouds in some embedding space.",8 Broader Impact,97,4,,,FALSE,FALSE,FALSE,Weakly Supervised Deep Functional Maps for Shape Matching,Applications -> Computer Vision,"Algorithms -> Representation Learning; Algorithms -> Spectral Methods; Algorithms -> Unsupervised Learning; Applications -> Body Pose, Face, and Gesture Analysis",Vision,"['Abhishek Sharma', ' Maks Ovsjanikov']","{'Ecole Polytechnique', 'Ecole polytechnique'}",1,0,0,"{'France', 'Switzerland'}"
Domain Adaptation with Conditional Distribution Matching and Generalized Label Shift,"Remi Tachet des Combes, Han Zhao, Yu-Xiang Wang, Geoffrey J. Gordon",Domain Adaptation with Conditional Distribution Matching and Generalized Label Shift,dfbfa7ddcfffeb581f50edcf9a0204bb,https://proceedings.neurips.cc/paper/2020/file/dfbfa7ddcfffeb581f50edcf9a0204bb-Paper.pdf,"Our work focuses on domain adaptation and attempts to properly handle mismatches in the label distributions between the source and target domains. Domain Adaptation as a whole aims at transferring knowledge gained from a certain domain (or data distribution) to another one. It can potentially be used in a variety of decision making systems, such as spam filters, machine translation, etc.. One can also potentially think of much more sensitive applications such as recidivism prediction, or loan approvals. While it is unclear to us to what extent DA is currently applied, or how it will be applied in the future, the bias formalized in Th. 2.1 and verified in Table ?? demonstrates that imbalances between classes will result in poor transfer performance of standard ADA methods on a subset of them, which is without a doubt a source of potential inequalities. Our method is actually aimed at counter-balancing the effect of such imbalances. As shown in our empirical results (for instance Table ?? ) it is rather successful at it, especially on significant shifts. This makes us rather confident in the algorithm’s ability to mitigate potential effects of biases in the datasets. On the downside, failure in the weight estimation of some classes might result in poor performance on those. However, we have not observed, in any of our experiments, our method performing significantly worse than its base version. Finally, our method is a variation over existing deep learning algorithms. As such, it carries with it the uncertainties associated to deep learning models, in particular a lack of interpretability and of formal convergence guarantees.",Broader Impact,264,14,,,FALSE,FALSE,FALSE,Domain Adaptation with Conditional Distribution Matching and Generalized Label Shift,Algorithms -> Multitask and Transfer Learning,Algorithms -> Representation Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Remi Tachet des Combes', ' Han Zhao', 'Xiang Wang', ' Geoffrey Gordon']","{'Microsoft Research Montreal', 'Carnegie Mellon University', 'UC Santa Barbara'}",1,1,1,{'USA'}
Rethinking the Value of Labels for Improving Class-Imbalanced Learning,"Yuzhe Yang, Zhi Xu",Rethinking the Value of Labels for Improving Class-Imbalanced Learning,e025b6279c1b88d3ec0eca6fcb6e6280,https://proceedings.neurips.cc/paper/2020/file/e025b6279c1b88d3ec0eca6fcb6e6280-Paper.pdf,"Real-world data often exhibits skewed distributions with a long tail, rather than the ideal uniform distributions over each class. We tackle this important problem through two novel perspectives: (1) using unlabeled data without depending on additional human labeling; (2) explore intrinsic properties from data itself with self-supervision. These simple yet effective strategies introduce new frameworks for improving generic imbalanced learning tasks, which we believe will broadly benefit practitioners dealing with heavily imbalanced data in realistic applications. On the other hand, however, we only extensively test our strategies on academic datasets. In many real-world applications such as autonomous driving, medical diagnosis, and healthcare, beyond being naturally imbalanced, the data may impose additional constraints on learning process and final models, e.g., being fair or private. We focus on standard accuracy as our measure and largely ignore other ethical issues in imbalanced data, especially in minor classes. As such, the risk of producing unfair or biased outputs reminds us to carry rigorous validations in critical, high-stakes applications.",Broader Impact,164,7,,,FALSE,FALSE,FALSE,Rethinking the Value of Labels for Improving Class-Imbalanced Learning,Applications -> Computer Vision,Applications; Deep Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yuzhe Yang', ' Zhi Xu']",{'MIT'},1,0,0,{'USA'}
Provably Robust Metric Learning,"Lu Wang, Xuanqing Liu, Jinfeng Yi, Yuan Jiang, Cho-Jui Hsieh",Provably Robust Metric Learning,e038453073d221a4f32d0bab94ca7cee,https://proceedings.neurips.cc/paper/2020/file/e038453073d221a4f32d0bab94ca7cee-Paper.pdf,"In this work, we study the problem of adversarial robustness of metric learning. Adversarial robust- ness, especially robustness verification, is very important when deploying machine learning models into real-world systems. A potential risk is the research on adversarial attack, while understanding adversarial attack is a necessary step towards developing provably robust models. In general, this work does not involve specific applications and ethical issues.",Broader impact,64,4,,,FALSE,FALSE,FALSE,Provably Robust Metric Learning,Algorithms -> Adversarial Learning,Social Aspects of Machine Learning -> AI Safety,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Lu Wang', ' Xuanqing Liu', ' Jinfeng Yi', ' Yuan Jiang', 'Jui Hsieh']","{'UCLA', 'University of California, Los Angeles', 'National Key lab for Novel Software Technology', 'Nanjing University', 'JD Research'}",1,1,1,"{'USA', 'China'}"
Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings,"Yu Chen, Lingfei Wu, Mohammed Zaki",Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings,e05c7ba4e087beea9410929698dc41a6,https://proceedings.neurips.cc/paper/2020/file/e05c7ba4e087beea9410929698dc41a6-Paper.pdf,"The fundamental goal of our research is to develop a method for jointly learning graph structures and embeddings that are optimized for (semi-)supervised downstream tasks. Our technique can be widely applied to a large range of applications, including social network analysis, natural language processing (e.g., question answering and text generation), drug discovery and community detection. Conceptually, any application with the purpose of jointly learning the graph structures and embeddings in order to perform well in downstream tasks. Those potential applications range from computer vision, natural language processing, and network analysis. For instance, our research might be used to help better capture the semantic relationships between word tokens (beyond a sequence of tokens) in natural language processing. There are many benefits of using our method as a tool, such as applying graph neural networks to non-graph structured data without manual graph construction, and learning node/graph embeddings that are more robust to noisy input graphs. Those benefits that might be utilized by a large number of potential applications may have a board range of societal impacts: • the graphs use from of our noisy/incomplete research could improve graphs (e.g., and social speed networks) up the process or even of non-graph learning meaningful structured data (e.g., text and images). • the noisy/incomplete use of our research graph-structured could improve data in terms the robustness of learning of good graph node/graph neural networks embeddings to for downstream task. We would encourage the research to explore similar approaches in more specific real-world appli- cations. We would also suggest the research to understand the adversarial robustness of the use of graph neural networks in safety/security-critical applications.",Broader Impact,270,10,,,FALSE,FALSE,FALSE,Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings,Deep Learning,Algorithms -> Model Selection and Structure Learning; Algorithms -> Relational Learning,Deep learning,,"{'IBM Research AI', 'Facebook', 'RPI'}",1,1,1,{'USA'}
COPT: Coordinated Optimal Transport on Graphs,"Yihe Dong, Will Sawin",COPT: Coordinated Optimal Transport on Graphs,e0640c93b05097a9380870aa06aa0df4,https://proceedings.neurips.cc/paper/2020/file/e0640c93b05097a9380870aa06aa0df4-Paper.pdf,"Graph-structured data are ubiquitous, thus fast and accurate graph retrieval and comparison is an important application. COPT improves upon state of the art methods on real world datasets such as Proteins and Enzymes, this can be useful for both scientific research and medical applications, such as comparing a novel synthesized protein with existing ones or trying to identify a molecule. As the COPT metric can be used to compare graphs with different numbers of vertices and is invariant under permutations of the vertices, it can be applied to a broad spectrum of graphs. In addition, the fact that equidimensional COPT sketches achieve competitive retrieval accuracy at a fraction of the time compared to state of the art methods makes it suitable for retrieval in large-scale datasets. However,  caution is warranted to avoid over-interpreting COPT or other graph distances - if the distance is low, that only implies structural similitary, not necessarily semantic similarity.",Broader Impact,153,5,,,FALSE,FALSE,FALSE,COPT: Coordinated Optimal Transport on Graphs,Algorithms -> Representation Learning,Algorithms -> Metric Learning; Algorithms -> Similarity and Distance Learning; Algorithms -> Unsupervised Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Yihe Dong', ' Will Sawin']","{'Microsoft', 'Columbia University'}",1,1,1,{'USA'}
No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems,"Nimit Sohoni, Jared Dunnmon, Geoffrey Angus, Albert Gu, Christopher Ré",No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems,e0688d13958a19e087e123148555e4b4,https://proceedings.neurips.cc/paper/2020/file/e0688d13958a19e087e123148555e4b4-Paper.pdf,"The potential real-world impact of G EORGE , the approach we present in this work, is that it would allow machine learning practitioners to both measure and mitigate hidden stratification without requiring any additional prior information. Concretely, this means that users would be able to leverage clusters identified in Step 1 of G EORGE to measure performance gaps between unlabeled subclasses, and that they would subsequently be able to reduce that subclass performance gap via Step 2 of G EORGE . We hope that G EORGE could serve as a drop-in replacement for standard ERM- based techniques in situations where ensuring good performance across many potentially unknown subclasses is important, as it is simple to implement and can be generically applied: all that is required to apply G EORGE to an existing model is (a) clustering within the representation space of a trained model and (b) retraining using a GDRO objective with the cluster assignments used as groups. As an example of how G EORGE could be important for meaningful practical applications, we consider our results presented on the ISIC dataset in a real-world context. Naively, the overall AUROC on the ISIC dataset obtained using an ERM-trained model is 0.956, which suggests a high-performing model; however, our clustering (Step 1 of G EORGE ) reveals that a large fraction of the benign images contain a “spurious” brightly colored patch, which makes them very easy to classify. The model performs substantially worse for cases without such a patch, and worse still on cases for which a clinician would also have required a histopathology examination to make a diagnosis. Thus, if deployed in practice with a target sensitivity value in mind, the appropriate way to set an operating point for this model is in fact cluster-dependent ; if a single operating point were set using the aggregate ROC curve, the true sensitivity on the histopathology subclass would be substantially lower than intended. This means that even just measuring hidden stratification via Step 1 of G EORGE can provide crucial information that would help avoid spurious false negatives at test time—the worst type of error a medical screening application can make. As shown in the paper, Step 2 of G EORGE can improve performance on underperforming subclasses. Our approach thus provides additional value via a simple retraining procedure that can reduce the amount of hidden stratification exhibited by the model. While our approach will certainly not provide substantial gains in every possible case—for instance, if performance gaps between subclasses are already minimal—we also do not expect it to cause substantial performance degradation. Indeed, even if the clusters returned by G EORGE are random groupings of points that do not align well with the true subclasses, we still expect a model trained to be robust across such groups to perform similarly to a standard ERM model (as in this case the average per-cluster losses are likely to be close to the overall loss on the superclass). This conclusion is empirically supported by the random-GDRO results of Appendix B, which are generally comparable to ERM. In summary, we hope that G EORGE will have broader impacts by (a) enabling better measurement of hidden stratification via Step 1, even without knowledge of the subclasses, and (b) potentially improving performance on underserved subclasses with Step 2, with only modest additional effort required compared to normal training procedures (i.e., clustering + retraining with GDRO). In addition to medical imaging tasks such as ISIC, subclasses could represent a large number of important categories including race, gender, and others on which one would generally want to ensure good performance on all subclasses, rather than optimizing for average performance while underserving certain categories. If successful, G EORGE can help to detect and mitigate such important performance differences before models are deployed in practice. To support these potential impacts, we have released a complete implementation of our code, 3 with an easily usable PyTorch API. We look forward to engaging with the broader community to improve our work and deploy it on real-world applications.",Broader Impact,672,18,,,FALSE,FALSE,FALSE,No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems,Algorithms -> Classification,Algorithms -> Representation Learning; Deep Learning -> Supervised Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Nimit S Sohoni', ' Jared Dunnmon', ' Geoffrey Angus', ' Albert Gu', ' Christopher Ré']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
"Model Rubik’s Cube: Twisting Resolution, Depth and Width for TinyNets","Kai Han, Yunhe Wang, Qiulin Zhang, Wei Zhang, Chunjing XU, Tong Zhang","Model Rubik’s Cube: Twisting Resolution, Depth and Width for TinyNets",e069ea4c9c233d36ff9c7f329bc08ff1,https://proceedings.neurips.cc/paper/2020/file/e069ea4c9c233d36ff9c7f329bc08ff1-Paper.pdf,The widely usage of deep neural networks which require large amount of computation resource is putting pressure on the energy source and the natural environment. The proposed model shrinking method for obtaining tiny neural networks is beneficial to energy conservation and environment protection.,Broader Impact,43,2,FALSE,FALSE,FALSE,FALSE,FALSE,"Model Rubik’s Cube: Twisting Resolution, Depth and Width for TinyNets",Deep Learning,Applications -> Object Recognition; Deep Learning -> CNN Architectures; Deep Learning -> Efficient Inference Methods,Deep learning,"['Kai Han', ' Yunhe Wang', ' Qiulin Zhang', ' Wei Zhang', ' Chunjing XU', ' Tong Zhang']","{'Tencent AI Lab', 'Huawei Technologies', 'Beijing University of Posts and Telecommunications'}",1,1,1,{'China'}
Self-Adaptive Training: beyond Empirical Risk Minimization,"Lang Huang, Chao Zhang, Hongyang Zhang",Self-Adaptive Training: beyond Empirical Risk Minimization,e0ab531ec312161511493b002f9be2ee,https://proceedings.neurips.cc/paper/2020/file/e0ab531ec312161511493b002f9be2ee-Paper.pdf,"Our work advances robust learning from data under potential corruptions, which is a common feature for real-world, uncurated large-scale datasets due to the error-prone nature of data acquisition. In contrast to a large existing literature focuses on noisy label setting, our motivation is to provide a generic algorithm that not only is robust to various kinds of noises with varying noise levels, but also incurs no extra computational cost. In practice, these factors are crucial since the exact noise scheme is unknown and the computation budget is indeed very limited. Built upon the analysis on the intrinsic failure patterns of ERM under data corruptions, we introduce an elegant way to incorporate model predictions into training process to improve the generalization of deep networks under noisy data. By correcting outliers and calibrating the training process, our approach is ready for real-world application of deep learning. It can serve as a basic building block of large-scale AI system that generalizes well to a wide range of visual tasks. While we have empirically evaluated our approach on data under both random and adversarial noises, most of our studies focus on artificial data corruptions (except the analysis on ImageNet which contains annotation error by itself), which may not represent natural noises in practice. However, the presented methodology that properly incorporates model predictions into training process sheds light on understanding and improving the generalization of deep networks under data corruptions in the future study.",Broader Impact,239,8,,,FALSE,FALSE,FALSE,Self-Adaptive Training: beyond Empirical Risk Minimization,Deep Learning -> Efficient Training Methods,,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Lang Huang', ' Chao Zhang', ' Hongyang Zhang']","{'TTIC', 'Peking University'}",1,0,0,"{'USA', 'China'}"
Effective Dimension Adaptive Sketching Methods for Faster Regularized Least-Squares Optimization,"Jonathan Lacotte, Mert Pilanci",Effective Dimension Adaptive Sketching Methods for Faster Regularized Least-Squares Optimization,e105b88b3e1ac23ec811a708cd7edebf,https://proceedings.neurips.cc/paper/2020/file/e105b88b3e1ac23ec811a708cd7edebf-Paper.pdf,We believe that the proposed method in this work can have positive societal impacts. Our algorithm can be applied in massive scale distributed learning and optimization problems encountered in real-life problems. The computational effort can be significantly lowered as a result of adaptive dimension reduction. Consequently energy costs for optimization can be significantly reduced.,Broader Impact,54,4,FALSE,FALSE,FALSE,FALSE,FALSE,Effective Dimension Adaptive Sketching Methods for Faster Regularized Least-Squares Optimization,Optimization -> Convex Optimization,Algorithms -> Large Scale Learning; Algorithms -> Regression; Theory -> Regularization,Optimization Methods (continuous or discrete),"['Jonathan Lacotte', ' Mert Pilanci']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Near-Optimal Comparison Based Clustering,"Michaël Perrot, Pascal Esser, Debarghya Ghoshdastidar",Near-Optimal Comparison Based Clustering,e11943a6031a0e6114ae69c257617980,https://proceedings.neurips.cc/paper/2020/file/e11943a6031a0e6114ae69c257617980-Paper.pdf,"This work primarily has applications in the fields of psychophysics and crowdsourcing, and more generally, in learning from human responses. Such data and learning problems could be affected by implicit biases in human responses. However, this latter issue is beyond the scope of this work and, thus, was not formally analysed.",Broader Impact,51,3,FALSE,FALSE,FALSE,FALSE,FALSE,Near-Optimal Comparison Based Clustering,Algorithms -> Clustering,Algorithms -> Ranking and Preference Learning; Theory -> Frequentist Statistics,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Michaël Perrot', ' Pascal Esser', ' Debarghya Ghoshdastidar']","{'Technical University of Munich', 'Technical University Munich', 'Max Planck Institute for Intelligent Systems'}",1,0,0,{'Germany'}
Multi-Task Temporal Shift Attention Networks for On-Device Contactless Vitals Measurement,"Xin Liu, Josh Fromm, Shwetak Patel, Daniel McDuff",Multi-Task Temporal Shift Attention Networks for On-Device Contactless Vitals Measurement,e1228be46de6a0234ac22ded31417bc7,https://proceedings.neurips.cc/paper/2020/file/e1228be46de6a0234ac22ded31417bc7-Paper.pdf,"Non-contact camera-based vital sign monitoring has great potential as a tool for telehealth. Our proposed system can promote global health equity and make healthcare more accessible for those in rural areas or those who find it difficult to travel to clinics and hospitals in-person (perhaps because of age, mobility issues or care responsibilities). These needs are likely to be particularly acute in low-resource settings. Non-contact sensing has other potential benefits for measuring the vitals of infants who ideally would not have contact sensors attached to their delicate skin. Furthermore, due to the exceptionally fast inference speed, the computational budget required for our proposed system is minimal. Therefore, people who cannot afford high-end computing devices still will be able to access the technology. While low-cost, ubiquitous sensing democratizes physiological measurement, it presents other challenges. If measurement can be performed from only a video, what happens if we detect a health condition in an individual when analyzing a video for other purposes. When and how should that information be disclosed? If the system fails in a context where a person is in a remote location, it may lead them to panic. It is also important to consider how such technology could be used by “bad actors” or applied with negligence and without sufficient forethought for the implications. Non-contact sensing could be used to measure personal physiological information without the knowledge of the subject. Law enforcement might be tempted to apply this in an attempt to detect individuals who appear “nervous” via signals such as an elevated heart rate or irregular breathing, or an employer may surreptitiously screen prospective employees for health conditions without their knowledge during an interview. These applications would set a very dangerous precedent and would be illegal in many cases. Just as is the case with traditional contact sensors, it must be made transparent when these methods are being used and subjects should be required to consent before physiological data is measured or recorded. There should be no penalty for individuals who decline to be measured. Ubiquitous sensing offers the ability to measure signals in more contexts, but that does not mean that this should necessarily be acceptable. Just because cameras may be able to measure these signals in a new context, or with less effort, it does not mean they should be subject to any less regulation than existing sensors, in fact quite the contrary. In the United States, the Health Insurance Portability and Accountability Act (HIPAA) and the HIPAA Privacy Rule sets a standard for protecting sensitive patient data and there should be no exception with regard to camera-based sensing. In the case of videos there should be particular care in how videos are transferred, given that significant health data can be contained with the channel. That was one of the motivations for designing our methods to run on-device, as it can minimize the risks involved in data transfer.",6 Broader Impact,482,21,,,FALSE,FALSE,FALSE,Multi-Task Temporal Shift Attention Networks for On-Device Contactless Vitals Measurement,Applications -> Health,"Applications -> Body Pose, Face, and Gesture Analysis; Deep Learning -> Efficient Inference Methods",Healthcare,"['Xin Liu', ' Josh Fromm', ' Shwetak Patel', ' Daniel McDuff']","{'University of Washington ', 'Microsoft Research', 'University of Washington', 'OctoML'}",1,1,1,{'USA'}
A new convergent variant of Q-learning with linear function approximation,"Diogo Carvalho, Francisco S. Melo, Pedro Santos",A new convergent variant of Q -learning with linear function approximation,e1696007be4eefb81b1a1d39ce48681b,https://proceedings.neurips.cc/paper/2020/file/e1696007be4eefb81b1a1d39ce48681b-Paper.pdf,"Even though our work is mostly theoretical, we include a reflection on the general impacts of the field. Artificial intelligence (AI) and machine learning (ML) adoption in society is rapidly increasing. Within the classical application domains—such as robotics, natural language processing, computer vision, predictive models, and others, AI algorithms are now a part of our daily lives. In some of those applications, AI and ML-driven algorithms can surpass human-level performance. Additionally, these algorithms are being used to address critical problems in our world. For example, deep learning algorithms are being used to predict poverty from satellite images [10], and to predict and manage traffic patterns to avoid pollution and congestion in cities [11]. While the impacts of intelligent algorithms are immense, many solid empirical successes are not supported by an equally solid theoretical understanding. This gap between theory and practice is notorious in the field of reinforcement learning (RL), particularly with respect to the recent successes of deep RL. The present work contributes a new algorithm—a modification of Q -learning inspired by successful architectures such as DQN—along with the theoretical analysis of its properties. Such contribution has the potential to impact the broader area of RL, including deep RL, by providing a sharper understanding of the theoretical properties of RL algorithms and potentially pushing research towards a new class of stable RL algorithms which make use of more complex approximation architectures than the ones considered in this work— e.g. , neural networks. Given the fundamental nature of the work, we expect its impact on our daily lives to be as far-reaching as that of AI and ML.",Broader impact,267,11,,,FALSE,FALSE,FALSE,A new convergent variant of Q-learning with linear function approximation,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning; Reinforcement Learning and Planning -> Decision and Control,Reinforcement learning and planning,"['Diogo Carvalho', ' Melo', ' Santos']","{'IST/INESC-ID', 'Instituto Superior Técnico', 'GAIPS, INESC-ID'}",1,0,0,"{'France', 'Portugal'}"
TaylorGAN: Neighbor-Augmented Policy Update Towards Sample-Efficient Natural Language Generation,"Chun-Hsing Lin, Siang-Ruei Wu, Hung-yi Lee, Yun-Nung Chen",TaylorGAN: Neighbor-Augmented Policy Update for Sample-Efficient Natural Language Generation,e1fc9c082df6cfff8cbcfff2b5a722ef,https://proceedings.neurips.cc/paper/2020/file/e1fc9c082df6cfff8cbcfff2b5a722ef-Paper.pdf,"Improving text generation may have a wide range of beneficial impact across many domains. This includes human-machine collaboration of code, literature or even music, chatbots, question-answering systems, etc. However, this technology may be misused whether deliberately or not. Because our model learns the underlying distribution of datasets like any other language model, it inherently risks producing biased or offensive content reflective of the training data. Studies have shown that language models could produce biased content with respect to gender, race, religion, while modeling texts from the web [29]. Better text generation could lower costs of disinformation campaigns and even weaken our detection ability of synthetic texts. Studies found that extremist groups can use language models for misuse specifically by finetuning the model on corresponding ideological positions [29].",Broader Impact,127,7,,,FALSE,FALSE,FALSE,TaylorGAN: Neighbor-Augmented Policy Update Towards Sample-Efficient Natural Language Generation,Applications -> Natural Language Processing,Deep Learning -> Generative Models; Reinforcement Learning and Planning -> Reinforcement Learning,Natural language processing,"['Hsing Lin', 'Ruei Wu', 'yi Lee', 'Nung Chen']",{'National Taiwan University'},1,0,0,{'Taiwan'}
Neural Networks with Small Weights and Depth-Separation Barriers,"Gal Vardi, Ohad Shamir",Neural Networks with Small Weights and Depth-Separation Barriers,e1fe6165cad3f7f3f57d409f78e4415f,https://proceedings.neurips.cc/paper/2020/file/e1fe6165cad3f7f3f57d409f78e4415f-Paper.pdf,Not applicable as far as we can see (this is a purely theoretical paper).,Broader impact,14,1,TRUE,FALSE,FALSE,FALSE,FALSE,Neural Networks with Small Weights and Depth-Separation Barriers,Theory,Deep Learning -> Analysis and Understanding of Deep Networks,Theory (including computational and statistical analyses),"['Gal Vardi', ' Ohad Shamir']",{'Weizmann Institute of Science'},1,0,0,{'Israel'}
Untangling tradeoffs between recurrence and self-attention in artificial neural networks,"Giancarlo Kerg, Bhargav Kanuparthi, Anirudh Goyal ALIAS PARTH GOYAL, Kyle Goyette, Yoshua Bengio, Guillaume Lajoie",Untangling tradeoffs between recurrence and self-attention in neural networks,e2065cb56f5533494522c46a72f1dfb0,https://proceedings.neurips.cc/paper/2020/file/e2065cb56f5533494522c46a72f1dfb0-Paper.pdf,"We provide a framework for researchers to shape gradient propagation and memory footprint in self-attentive RNNs, which is helpful in tasks requiring ongoing online predictions that cannot be based on future inputs (i.e. in an online sequential setting) and where long-term credit assignment is crucial, such as various RL tasks [16, 20]. The added resource gains can save GPU hours and thus have a positive environmental impact. Along this line, we firmly believe that researchers should take environmental impact of model training seriously, and we are hopeful that our work contributes to this direction. Meanwhile, the theoretical tools provided in the proofs lay the ground for more theoretical work on attentive systems to emerge in the future. More effective RNN models can amplify already existing biases in RNN-based NLP systems through an increased exposure to bias. Finally, we cannot exclude that the cognitive inductive bias we use to build our relevancy screening mechanism may induce prediction quality disparity (e.g. in language modelling) because of the memory tokens it throws away.",Broader Impact,170,6,,,FALSE,FALSE,FALSE,Untangling tradeoffs between recurrence and self-attention in artificial neural networks,Deep Learning -> Recurrent Networks,Neuroscience and Cognitive Science -> Memory,Deep learning,"['Giancarlo Kerg', ' Bhargav Kanuparthi', ' Anirudh Goyal ALIAS PARTH GOYAL', ' Kyle Goyette', ' Yoshua Bengio', ' Guillaume Lajoie']","{'University of Montreal', 'Université de Montréal', 'MILA', 'Montreal Institute for Learning Algorithms', 'Mila, Université de Montréal'}",1,0,0,{'Canada'}
Dual-Free Stochastic Decentralized Optimization with Variance Reduction,"Hadrien Hendrikx, Francis Bach, Laurent Massoulié",Dual-Free Stochastic Decentralized Optimization with Variance Reduction,e22312179bf43e61576081a2f250f845,https://proceedings.neurips.cc/paper/2020/file/e22312179bf43e61576081a2f250f845-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader impact statement,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Dual-Free Stochastic Decentralized Optimization with Variance Reduction,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Hadrien Hendrikx', ' Francis Bach', ' Laurent Massoulié']","{'INRIA - PSL', 'INRIA - Ecole Normale Superieure', 'Inria'}",1,0,0,{'France'}
Online Learning in Contextual Bandits using Gated Linear Networks,"Eren Sezener, Marcus Hutter, David Budden, Jianan Wang, Joel Veness",Online Learning in Contextual Bandits using Gated Linear Networks,e287f0b2e730059c55d97fa92649f4f2,https://proceedings.neurips.cc/paper/2020/file/e287f0b2e730059c55d97fa92649f4f2-Paper.pdf,"Contextual bandit algorithms can be utilized to deliver personalized content such as news or advertis- ing. Privacy and algorithmic bias should therefore be considered during the implementation process. GLNs are more easily interpretable than conventional neural networks [15], which might be helpful for understanding and addressing any potential bias. Our proposed algorithm is online and therefore does not require storing data. This is potentially beneficial in terms of privacy. Using smaller context dimensions might help further by avoiding contexts with small number of data points as much as possible.",Broader Impact,89,6,,,FALSE,FALSE,FALSE,Online Learning in Contextual Bandits using Gated Linear Networks,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning; Reinforcement Learning and Planning -> Exploration,,"['Eren Sezener', ' Marcus Hutter', ' David Budden', ' Jianan Wang', ' Joel Veness']","{'DeepMind', 'Deepmind'}",0,1,0,{'UK'}
Throughput-Optimal Topology Design for Cross-Silo Federated Learning,"Othmane MARFOQ, CHUAN XU, Giovanni Neglia, Richard Vidal",Throughput-Optimal Topology Design for Cross-Silo Federated Learning,e29b722e35040b88678e25a1ec032a21,https://proceedings.neurips.cc/paper/2020/file/e29b722e35040b88678e25a1ec032a21-Paper.pdf,"We have proposed topology design algorithms that can significantly speed-up federated learning in a cross-silo setting. Improving the efficiency of federated learning can foster its adoption, allowing different entities to share datasets that otherwise would not be available for training. Federated learning is intended to protect data privacy, as the data is not collected at a single point. At the same time a federated learning system, as any Internet-scale distributed system, may be more vulnerable to different attacks aiming to jeopardize training or to infer some characteristics of the local dataset by looking at the different messages [26, 92]. Encryption [10, 80, 8] and differential privacy [1] techniques may help preventing such attacks. Federated learning is less efficient than training in a highly-optimized computing cluster. It may in particular increase energy training costs, due to a more discontinuous usage of local computing resources and the additional cost of transmitting messages over long distance links. To the best of our knowledge, energetic considerations for federated learning have not been adequately explored, but for a few papers considering FL for mobile devices [42, 97].",6 Broader Impact,182,8,,,FALSE,FALSE,FALSE,Throughput-Optimal Topology Design for Cross-Silo Federated Learning,Deep Learning -> Efficient Training Methods,Algorithms -> Large Scale Learning,Federated Learning,,"{'Inria Sophia Antipolis', 'Accenture', 'Inria'}",1,1,1,{'France'}
Quantized Variational Inference,Amir Dib,Quantized Variational Inference,e2a23af417a2344fe3a23e652924091f,https://proceedings.neurips.cc/paper/2020/file/e2a23af417a2344fe3a23e652924091f-Paper.pdf,"Our work provides a method to speed up the convergence of any procedure involving the computation of an expectation on a large distribution class. Such case corresponds to a broad range of applications from probabilistic inference to pricing of financial products [29]. More generally, we hope to introduce the concept of optimal quantizer to the machine learning community and to convince of the value of deterministic sampling in stochastic optimization procedures. Reducing the computational cost associated with probabilistic inference allows considering a broader range of models and hyperparameters. Improving goodness of fit is the primary goal of any statistician and virtually impacts all aspects of social life where such domain is applied. For instance, we chose to consider the sensitive subject of the New York City Frisk and Search policy in the 1990s. In-depth analysis of the results shows that minority groups are excessively targeted by such measure even after controlling for precinct demographic and ethnic-specific crime participation [11]. This study gave a strong statistical argument to be presented to the authorities for them to justify and amend their policies. Even though environmental benefits could be argued, we do not believe that such benefits can be obtained through increased efficiency of a system due to the rebound effect. In the paper, we stressed the benefit of using our approach to improve automated machine learning pipelines, which consider large classes of models to find the best fit. This process can remove the practitioner from the modeling process, overlook any ML model’s inherent biases, and ignore possible critical errors in the prediction. We strongly encourage practitioners to follow standard practices such as posterior predictive analysis and carefully examine the chosen model’s underlying hypothesis.",5 Broader Impact,281,12,,,FALSE,FALSE,FALSE,Quantized Variational Inference,Probabilistic Methods -> Variational Inference,Algorithms -> Model Selection and Structure Learning; Algorithms -> Similarity and Distance Learning; Optimization -> Convex Optimization; Optimization -> Stochastic Optimization; Probabilistic Methods -> Bayesian Theory; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Probabilistic Programming; Theory -> Large Deviations and Asymptotic Analysis,Optimization Methods (continuous or discrete),['Amir DIB'],"{'Paris-Saclay University, ENS Paris-Saclay'}",1,0,0,{'France'}
Asymptotically Optimal Exact Minibatch Metropolis-Hastings,"Ruqi Zhang, A. Feder Cooper, Christopher M. De Sa",Asymptotically Optimal Exact Minibatch Metropolis-Hastings,e2a7555f7cabd6e31aef45cb8cda4999,https://proceedings.neurips.cc/paper/2020/file/e2a7555f7cabd6e31aef45cb8cda4999-Paper.pdf,"Our work shines a light on how to scale MCMC methods responsibly. We make the case that inexact minibatch MH methods can lead to egregious errors in inference, which suggests that—particularly for high-impact applications [14, 22]—we should avoid their use. We provide an alternative: a minibatch MH method that guarantees correctness, while also maintaining an optimal balance between ef fi ciency and scalability, enabling its safe use on large-scale applications.",Broader Impact,70,3,,,FALSE,FALSE,FALSE,Asymptotically Optimal Exact Minibatch Metropolis-Hastings,Probabilistic Methods -> MCMC,,Probabilistic methods and inference,"['Ruqi Zhang', ' Feder Cooper', ' Christopher De Sa']","{'Cornell', 'Cornell University'}",1,0,0,{'USA'}
Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search,"Linnan Wang, Rodrigo Fonseca, Yuandong Tian",Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search,e2ce14e81dba66dbff9cbc35ecfdb704,https://proceedings.neurips.cc/paper/2020/file/e2ce14e81dba66dbff9cbc35ecfdb704-Paper.pdf,"Black-box optimization has a variety of applications in practice, ranging from the hyper-parameter tuning in the distributed system and database, Integrated Circuit(IC) design, Reinforcement Learning (RL), and many more. Most real-world problems are heterogeneous and high-dimensional while existing black-box solvers struggle to yield a reasonable performance in these problems. In this paper, we made our first step to show a gradient-free algorithm partially solves high-dimensional complex MuJoCo tasks, indicating its potential to other high-dimensional tasks in various domains. Switching to LA-MCTS may improve the productivity at a minimal cost when searching for better performance in a wide variety of applications where the gradient of the function is not known. At the same time, we don’t foresee any negative social consequences.",6 Broader impact,120,5,,,FALSE,FALSE,FALSE,Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search,Algorithms -> Meta-Learning,Optimization -> Non-Convex Optimization,,,"{'Facebook AI Research', 'Brown University'}",1,1,1,{'USA'}
Feature Shift Detection: Localizing Which Features Have Shifted via Conditional Distribution Tests,"Sean Kulinski, Saurabh Bagchi, David I. Inouye",Feature Shift Detection: Localizing Which Features Have Shifted via Conditional Distribution Tests,e2d52448d36918c575fa79d88647ba66,https://proceedings.neurips.cc/paper/2020/file/e2d52448d36918c575fa79d88647ba66-Paper.pdf,"Positive implications of our technology. Our solution allows the deployment of sensor networks, including large-scale ones, with trust placed on the values obtained from the network. This can happen despite the presence of sophisticated adversaries, such as, an adversary that can observe and faithfully reproduce the values of some sensors. Such trust now opens up the possibility of deploying sensor networks in critical operations, such as, monitoring dangerous terrain (e.g., for IEDs), monitoring large industrial plants (e.g., for noxious gases), and monitoring industrial control systems through digital PLC controllers (e.g., for vibrations of motors). The huge volume of sensor network research has had challenges in translating to practical impact and one of the well-identified concerns has been that the networks are easy to compromise, thus eroding trust in their operation. Our work can start to address this concern. Due to the fact that the compromised sensors can be localized, our work sheds some light on the reason behind its detection, allowing mitigation actions. This gets at the more explainable nature of ML models. Due to the scalable nature of our solution (e.g., the score based test statistic computation is lightweight), it is applicable to large-scale sensor networks. Negative implications of our technology. An adoption of our solution without careful understanding of the adversary capabilities may lead to a false sense of confidence. For example, a sophisticated adversary may be able to compromise multiple correlated sensors and change their values in a correlated manner so as to defeat our defense. Generally, reasoning about such correlated attacks needs a higher degree of sophistication and is called upon prior to the use of our technology.",Broader Impact,272,13,,,FALSE,FALSE,FALSE,Feature Shift Detection: Localizing Which Features Have Shifted via Conditional Distribution Tests,Probabilistic Methods,Applications -> Time Series Analysis,Probabilistic methods and inference,"['Sean Kulinski', ' Saurabh Bagchi', ' David Inouye']",{'Purdue University'},1,0,0,{'USA'}
Unifying Activation- and Timing-based Learning Rules for Spiking Neural Networks,"Jinseok Kim, Kyungsu Kim, Jae-Joon Kim",Unifying Activation- and Timing-based Learning Rules for Spiking Neural Networks,e2e5096d574976e8f115a8f1e0ffb52b,https://proceedings.neurips.cc/paper/2020/file/e2e5096d574976e8f115a8f1e0ffb52b-Paper.pdf,"The purpose of our work is to improve the general supervised learning performance of SNNs. Even though we can use SNNs for any cognitive task, the complexity of problems that SNNs are currently targeting is very limited. This is because of the fundamental problems of the existing learning methods that are addressed in this work. Nevertheless, SNNs have significant implications as a biologically plausible artificial neural network, which helps bridge the gap between our understanding  of biological neurons and the remarkable success of deep learning. In particular, the successful use of SNNs can provide clues to the high energy efficiency of the biological brains. We believe our work lays the groundwork for such a research direction.",Broader Impact,116,6,,,FALSE,FALSE,FALSE,Unifying Activation- and Timing-based Learning Rules for Spiking Neural Networks,Deep Learning -> Biologically Plausible Deep Networks,,Deep learning,"['Jinseok Kim', 'Pohang University of Science and Technology', ' Kyungsu Kim', 'Joon Kim']",{'POSTECH'},1,0,0,{'France'}
Space-Time Correspondence as a Contrastive Random Walk,"Allan Jabri, Andrew Owens, Alexei Efros",Space-Time Correspondence as a Contrastive Random Walk,e2ef524fbf3d9fe611d5a8e90fefdc9c,https://proceedings.neurips.cc/paper/2020/file/e2ef524fbf3d9fe611d5a8e90fefdc9c-Paper.pdf,"Research presented in the paper has a potential to positively contribute to a number of practical applications where establishing temporal correspondence in video is critical, among them pedestrian safely in automotive settings, patient monitoring in hospitals and elderly care homes, video-based animal monitoring and 3D reconstruction, etc. However, there is also a potential for the technology to be used for nefarious purposes, mainly in the area of unauthorized surveillance, especially by  autocratic regimes. As partial mitigation, we commit to not entering into any contracts involving this technology with any government or quasi-governmental agencies of countries with an EIU Democracy Index [24] score of 4 . 0 or below (“authoritarian regimes""), or authorizing them to use our software. Acknowledgments. We thank Amir Zamir, Ashish Kumar, Yu Sun, Tim Brooks, Bill Peebles, Dave Epstein, Armand Joulin, and Jitendra Malik for helpful feedback and support. We are also grateful to the wonderful members of VGG for hosting us during a dreamy semester at Oxford. This work would not have been possible without the hospitality of Port Meadow and the swimming pool on Iffley Road. Research was supported, in part, by NSF grant IIS-1633310, the DARPA MCS program, and NSF IIS-1522904. We are grateful for compute resources donated by NVIDIA. AJ is supported by the PD Soros Fellowship.",6 Broader Impact,214,11,,,FALSE,FALSE,FALSE,Space-Time Correspondence as a Contrastive Random Walk,Applications -> Computer Vision,Applications -> Tracking and Motion in Video; Applications -> Video Analysis,,"['Allan Jabri', ' Andrew Owens', ' Alexei Efros']",{'UC Berkeley'},1,0,0,{'USA'}
The Flajolet-Martin Sketch Itself Preserves Differential Privacy: Private Counting with Minimal Space,"Adam Smith, Shuang Song, Abhradeep Thakurta",The Flajolet-Martin Sketch Itself Preserves Differential Privacy: Private Counting with Minimal Space,e3019767b1b23f82883c9850356b71d6,https://proceedings.neurips.cc/paper/2020/file/e3019767b1b23f82883c9850356b71d6-Paper.pdf,"Counting distinct elements with space constraints is one of the fundamental problems encountered in web-scale systems [1, 2]. As more organizations attempt to adopt differential privacy in their data processing pipeline (e.g., Apple, Google, Facebook, and US Census), having a practical differentially private cardinality estimator is becoming all the more important. Furthermore, [13] showed that many non-private estimators can leak “significant” sensitive information about individuals. Hence, we believe our differentially private solution will help control the information leakage about individuals through cardinality estimation sketches. We hope that reducing leakage enables better security and more responsible data management overall; the simplicity of our algorithm means that its adoption need not be limited to highly sophisticated organizations.",Broader Impact,115,5,,,FALSE,FALSE,FALSE,The Flajolet-Martin Sketch Itself Preserves Differential Privacy: Private Counting with Minimal Space,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Theory -> Data-driven Algorithm Design,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Adam Smith', ' Shuang Song', ' Abhradeep Thakurta']","{'Google', 'Boston University'}",1,1,1,{'USA'}
Exponential ergodicity of mirror-Langevin diffusions,"Sinho Chewi, Thibaut Le Gouic, Chen Lu, Tyler Maunu, Philippe Rigollet, Austin Stromme",Exponential ergodicity of mirror-Langevin diffusions,e3251075554389fe91d17a794861d47b,https://proceedings.neurips.cc/paper/2020/file/e3251075554389fe91d17a794861d47b-Paper.pdf,"The sampling algorithms designed in this paper have the potential to improve a wide variety of Bayesian methods and therefore have an indirect impact on various domains such as health and medicine where such methods are pervasive. Sampling algorithms are also used for the generation of automated spam messages, which have potentially negative effects on society. Since this paper is primarily focused on theory, these questions are not addressed here.",Broader impact,70,3,,,FALSE,FALSE,FALSE,Exponential ergodicity of mirror-Langevin diffusions,Probabilistic Methods -> MCMC,,Theory (including computational and statistical analyses),"['Sinho Chewi', ' Thibaut Le Gouic', ' Chen Lu', ' Tyler Maunu', ' Philippe Rigollet', ' Austin J Stromme']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
An Efficient Framework for Clustered Federated Learning,"Avishek Ghosh, Jichan Chung, Dong Yin, Kannan Ramchandran",An Efficient Framework for Clustered Federated Learning,e32cc80bf07915058ce90722ee17bb71,https://proceedings.neurips.cc/paper/2020/file/e32cc80bf07915058ce90722ee17bb71-Paper.pdf,"In this paper, we study the problem of clustered Federated Learning. Our formulation is one of the problem setups for personalized Federated Learning. We expect that, overall our framework will better protect the users’ privacy in a Federated Learning system while still provide personalized predictions. The reason is that our algorithm does not require the users to send any of their own personal data to the central server, and the users can still learn a personalized model using their on-device computing power. One potential risk is that our algorithm still requires the users to send the estimates of their cluster identities to the central server. Thus there might still be privacy concerns in this step. We suggest that before applying our algorithm, or generally any FL algorithms, in a real-world system, we should first request the users’ consent.",Broader Impact,138,7,,,FALSE,FALSE,FALSE,An Efficient Framework for Clustered Federated Learning,Optimization,Algorithms -> Clustering; Optimization -> Convex Optimization; Theory -> Frequentist Statistics,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Avishek Ghosh', ' Jichan Chung', ' Dong Yin', ' Kannan Ramchandran']","{'UC Berkeley', 'University of California, Berkeley', 'DeepMind'}",1,1,1,"{'UK', 'USA'}"
Autoencoders that don't overfit towards the Identity,Harald Steck,Autoencoders that don’t overfit towards the Identity,e33d974aae13e4d877477d51d8bafdc4,https://proceedings.neurips.cc/paper/2020/file/e33d974aae13e4d877477d51d8bafdc4-Paper.pdf,"This paper provides a theoretical analysis of the overfitting problem of (linear) autoencoders to the identity-function when learned from data, and how it can be mitigated. These novel scientific insights hopefully help improve autoencoders in various practical application areas, with positive societal effects. Given that autoencoders may also be applied to collaborative filtering / recommender systems, as done in this paper for empirical illustration of the derived theoretical results, the various ethical or societal concerns that apply to collaborative filtering systems in general, like the danger of filter bubbles or various aspects of fairness, also apply here. They may be mitigated by the fact that the collaborative filtering approach (e.g., autoencoder) is typically only one component in a larger system, where several of the other components are tasked to guard against negative ethical and societal effects.",Broader Impact,136,4,,,FALSE,FALSE,FALSE,Autoencoders that don't overfit towards the Identity,Algorithms -> Unsupervised Learning,Algorithms -> Collaborative Filtering; Algorithms -> Similarity and Distance Learning; Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,['Harald Steck'],{'Netflix'},0,1,0,{'USA'}
Polynomial-Time Computation of Optimal Correlated Equilibria in Two-Player Extensive-Form Games with Public Chance Moves and Beyond,"Gabriele Farina, Tuomas Sandholm",Polynomial-Time Computation of Optimal Correlated Equilibria in Two-Player Extensive-Form Games with Public Chance Moves and Beyond,e366d105cfd734677897aaccf51e97a3,https://proceedings.neurips.cc/paper/2020/file/e366d105cfd734677897aaccf51e97a3-Paper.pdf,"Correlated solution concepts have many advantages. First, they enable incentive-compatible coor- dination of agents. Such coordination is achieved via incentives, rather than forcing: mediators in correlated solution concepts are only able to recommend behavior, but not force it. So, it is up to the mediator to come up with a correlated distribution of recommendations such that no agent has incentive to deviate from the recommendations. Second, in some general-sum interactions these solution concepts are known to enable significantly higher social welfare than Nash equilibrium, while at the same time sidestepping some of the other shortcomings of Nash equilibrium (for example,  some equilibrium selection issues that make Nash equilibrium less appealing as a prescriptive tool for rational behavior). In this paper, we are particularly interested in optimal correlated equilibria. In other words, our technology can empower the system designer (mediator) to select, among the infinite number of correlated equilibria of the game, one that maximizes a given objective. For example, this technology could be used to find correlated equilibria that maximize the sum of utilities of the players, potentially leading to higher societal good. However, like most technology, our technology has potential for abuse. If used maliciously, the ability to select particular correlated equilibria could be used to minimize social welfare, maximize only one of the agent’s utility, or minimize all others’ utilities—thereby furthering existing inequality or creating new inequality.",Broader Impact,229,10,,,FALSE,FALSE,FALSE,Polynomial-Time Computation of Optimal Correlated Equilibria in Two-Player Extensive-Form Games with Public Chance Moves and Beyond,Theory -> Game Theory and Computational Economics,,Game theory,"['Gabriele Farina', ' Tuomas Sandholm']","{'Carnegie Mellon University', 'CMU, Strategic Machine, Strategy Robot, Optimized Markets'}",1,1,1,{'USA'}
Parameterized Explainer for Graph Neural Network,"Dongsheng Luo, Wei Cheng, Dongkuan Xu, Wenchao Yu, Bo Zong, Haifeng Chen, Xiang Zhang",Parameterized Explainer for Graph Neural Network,e37b08dd3015330dcbb5d6663667b8b8,https://proceedings.neurips.cc/paper/2020/file/e37b08dd3015330dcbb5d6663667b8b8-Paper.pdf,"Graph neural networks are powerful tools that have been applied in various real-world applications, including community detection, recommendation systems, computer vision, and natural language processing [3, 13, 30, 51]. Our work can not only provide interpretable explanations with local fidelity for predictions made by GNN models, but also improve the global understanding of the model. There are several broader impacts of using our method to explain predictions made by GNNs. First, our method can increase the transparency of applying GNNs for decision-critical applications, such as drug discovery and diagnosis. As a result, our method can help alleviate safety, and fairness risks. For example, as we show in our experiments, we could correctly identify motifs that have determinant effects on the mutagenicity of molecules. On the other hand, our method also puts GNN models at a high risk of being attacked. Our method extracts subgraphs that are important to GNNs’ behaviors. Disturbing these parts leads to significant changes in GNNs’ predictions. Besides, increasing the interpretability of GNNs may cause automation bias, such as an undue trust on GNN models.",Broader impact,178,10,,,FALSE,FALSE,FALSE,Parameterized Explainer for Graph Neural Network,"Deep Learning -> Visualization, Interpretability, and Explainability",Deep Learning -> Analysis and Understanding of Deep Networks,Deep learning,"['Dongsheng Luo', ' Wei Cheng', ' Dongkuan Xu', ' Wenchao Yu', ' Bo Zong', ' Haifeng Chen', ' Xiang Zhang']","{'UCLA', 'NEC Labs', 'The Pennsylvania State University', 'NEC Labs America'}",1,1,1,"{'Japan', 'USA'}"
Recursive Inference for Variational Autoencoders,"Minyoung Kim, Vladimir Pavlovic",Recursive Inference for Variational Autoencoders,e3844e186e6eb8736e9f53c0c5889527,https://proceedings.neurips.cc/paper/2020/file/e3844e186e6eb8736e9f53c0c5889527-Paper.pdf,"1. Who may benefit from this research? For any individuals, practitioners, organizations, and groups who aim to identify the underlying generative process of the high-dimensional structured data via the variational auto-encoding model framework, this research can be a very useful tool that provides highly accurate solutions generalizable to unseen data. 2. Who may be put at disadvantage from this research? Not particularly applicable. 3. What are the consequences of failure of the system? Any failure of the system that implements our algorithm would not do any serious harm since the failure can be easily detectable at the validation stage, in which case alternative strategies or internal decisions might be looked for. 4. Whether the task/method leverages biases in the data? Our method does not leverage biases in the data.",Broader Impact,129,10,FALSE,FALSE,TRUE,TRUE,FALSE,Recursive Inference for Variational Autoencoders,Algorithms -> Boosting and Ensemble Methods,Deep Learning -> Deep Autoencoders; Deep Learning -> Efficient Inference Methods; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Minyoung Kim', ' Vladimir Pavlovic']","{'Samsung AI Center', 'Rutgers University'}",1,1,1,"{'South Korea', 'USA'}"
Flexible mean field variational inference using mixtures of non-overlapping exponential families,Jeffrey Spence,Flexible mean field variational inference using mixtures of non-overlapping exponential families,e3a54649aeec04cf1c13907bc6c5c8aa,https://proceedings.neurips.cc/paper/2020/file/e3a54649aeec04cf1c13907bc6c5c8aa-Paper.pdf,"The primary contribution of this paper is theoretical and so the broader societal impact depends on how the theorems are used. The polygenic score application has the possibility to improve the overall quality of healthcare, but because the majority of GWAS are performed on individuals of European ancestries, PGSs are more accurate for individuals from those ancestry groups, potentially exacerbating health disparities between individuals of different ancestries as PGSs see clinical use [39]. The methods presented here are equally applicable to GWAS data collected from any ancestry group, however, and so efforts to diversify genetic data will ameliorate performance differences across ancestry groups. PGSs used for some traits such as sexual orientation [18], educational attainment [22], or stigmatized psychiatric disorders [14] raise thorny ethical considerations, especially when the application of such PGSs could enable genetic discrimination or fuel dangerous public misconceptions about the genetic basis of such traits [44]. On the other hand, PGSs applied to diseases have the potential to improve health outcomes and so if used responsibly could provide tremendous benefit to society.",Broader Impact,175,5,,,FALSE,FALSE,FALSE,Flexible mean field variational inference using mixtures of non-overlapping exponential families,Probabilistic Methods -> Variational Inference,Applications -> Computational Biology and Bioinformatics,Probabilistic methods and inference,,{'Stanford University'},1,0,0,{'USA'}
HYDRA: Pruning Adversarially Robust Neural Networks,"Vikash Sehwag, Shiqi Wang, Prateek Mittal, Suman Jana",HYDRA: Pruning Adversarially Robust Neural Networks,e3a72c791a69f87b05ea7742e04430ed,https://proceedings.neurips.cc/paper/2020/file/e3a72c791a69f87b05ea7742e04430ed-Paper.pdf,"Our work provides an important capability for deploying machine learning in safety critical and resource constrained environments. Our compressed networks provide a pathway for higher efficiency in terms of inference latency, energy consumption, and storage. On the other hand, these networks provide robustness against adversarial examples, including verified robustness properties, mitigating test-time attacks on critical ML services and applications. Recent work has leveraged adversarial examples against neural networks for positive societal applications, such as pushing back against large-scale facial recognition and surveillance. The development of robust networks may hinder such societal applications. Nevertheless, it is important to understand the limits and capabilities of compressed networks in safety critical environments, as failure to develop robust systems can also have catastrophic consequences. Our approach does not leverage any biases in data.",Broader Impact,129,7,,,FALSE,FALSE,FALSE,HYDRA: Pruning Adversarially Robust Neural Networks,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Adversarial Learning; Algorithms -> Classification; Applications -> Computer Vision; Deep Learning -> Analysis and Understanding of Deep Networks,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Vikash Sehwag', ' Shiqi Wang', ' Prateek Mittal', ' Suman Jana']","{'Columbia', 'Princeton University', 'Columbia University'}",1,0,0,{'USA'}
NVAE: A Deep Hierarchical Variational Autoencoder,"Arash Vahdat, Jan Kautz",NVAE: A Deep Hierarchical Variational Autoencoder,e3b21256183cf7c2c7a66be163579d37,https://proceedings.neurips.cc/paper/2020/file/e3b21256183cf7c2c7a66be163579d37-Paper.pdf,"This paper’s contributions are mostly centered around the fundamental challenges in designing expressive neural architectures for image VAEs, and the ideas, here, are examined on commonly used public datasets. This work has applications in content generation, computer graphics, data augmentation, semi-supervised learning, and representation learning. VAEs are known to represent the data distribution more faithfully than commonly used generative adversarial networks (GANs), as VAEs do not suffer from the mode collapse problem. Thus, in the long run, enabling VAEs to generate high-quality images will help us reduce bias in the generated content, produce diverse output, and represent minorities better. One should also take into consideration that VAEs are trained to mimic the training data distribution, and, any bias introduced in data collection will make VAEs generate samples with a similar bias. Additional bias could be introduced during model design, training, or when VAEs are sampled using small temperatures. Bias correction in generative learning is an active area of research, and we recommend the interested readers to check this area [80] before building applications using this work.",Impact Statement,176,7,,,FALSE,FALSE,FALSE,NVAE: A Deep Hierarchical Variational Autoencoder,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Deep Learning -> CNN Architectures; Probabilistic Methods -> Hierarchical Models; Probabilistic Methods -> Latent Variable Models; Probabilistic Methods -> Variational Inference,Probabilistic methods and inference,"['Arash Vahdat', ' Jan Kautz']",{'NVIDIA'},0,1,0,{'USA'}
Can Temporal-Diﬀerence and Q-Learning Learn Representation? A Mean-Field Theory,"Yufeng Zhang, Qi Cai, Zhuoran Yang, Yongxin Chen, Zhaoran Wang",Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Analysis,e3bc4e7f243ebc05d66a0568a3331966,https://proceedings.neurips.cc/paper/2020/file/e3bc4e7f243ebc05d66a0568a3331966-Paper.pdf,"The popularity of RL creates a responsibility for researchers to design algorithms with guaranteed safety and robustness, which rely on their stability and convergence. In this paper, we provide a theoretical understanding of the global optimality and convergence of the TD and Q-learning with neural network parameterization. We believe that our work is an important step forward in the algorithm design of RL in emerging high-stakes applications, such as autonomous driving, personalized medicine, power systems, and robotics.",Broader Impact,77,3,,,FALSE,FALSE,FALSE,Can Temporal-Diﬀerence and Q-Learning Learn Representation? A Mean-Field Theory,Reinforcement Learning and Planning -> Reinforcement Learning,Optimization -> Non-Convex Optimization,Reinforcement learning and planning,"['Yufeng Zhang', ' Qi Cai', ' Zhuoran Yang', ' Yongxin Chen', ' Zhaoran Wang']","{'Princeton', 'Georgia Institute of Technology', 'Northwestern University'}",1,0,0,{'USA'}
What Do Neural Networks Learn When Trained With Random Labels?,"Hartmut Maennel, Ibrahim M. Alabdulmohsin, Ilya O. Tolstikhin, Robert Baldock, Olivier Bousquet, Sylvain Gelly, Daniel Keysers",What Do Neural Networks Learn When Trained With Random Labels?,e4191d610537305de1d294adb121b513,https://proceedings.neurips.cc/paper/2020/file/e4191d610537305de1d294adb121b513-Paper.pdf,"This work is partially theoretical and contains experiments to study the theoretical results and related hypotheses. The paper aims at improving our understanding of how DNNs learn from data and therefore does not have a direct impact on applications or society. Hence, speculating on its potential broader impact is difficult at this stage. Nevertheless, we hope that a better understanding of deep neural networks will lead to improvements in the future along the direction of building interpretable and explainable AI, which are critical ingredients for the creation of socially-responsible AI systems.",Broader Impact,91,4,,,FALSE,FALSE,FALSE,What Do Neural Networks Learn When Trained With Random Labels?,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Unsupervised Learning; Deep Learning -> Supervised Deep Networks,Deep learning,"['Hartmut Maennel', ' Ibrahim Alabdulmohsin', ' Ilya Tolstikhin', ' Robert Baldock', ' Olivier Bousquet', 'Google Brain', ' Sylvain Gelly', 'Google Brain', ' Daniel Keysers']","{'Google Research', 'Google', 'Google, Brain Team, Zurich', 'Zurich', 'Google Research, Brain Team'}",0,1,0,{'USA'}
Counterfactual Prediction for Bundle Treatment,"Hao Zou, Peng Cui, Bo Li, Zheyan Shen, Jianxin Ma, Hongxia Yang, Yue He",Counterfactual Prediction for Bundle Treatment,e430ad64df3de73e6be33bcb7f6d0dac,https://proceedings.neurips.cc/paper/2020/file/e430ad64df3de73e6be33bcb7f6d0dac-Paper.pdf,"This work investigates in the problem of counterfactual outcome prediction. This can utilize the power of machine learning technology to assist better decision making in many domains. For example, the marketer can be helped to find the best marketing actions to improve user conversion. At the same time, this work may suffer from some risk. It relies on some standard assumption in causal inference field, such as unconfoundedness, stable unit treatment value. These assumptions may be violated in some scenarios. For example, some confounders, such as economic status, may not be measured due to ethical or technical reasons. The samples may also have interactions with each other in some scenarios. All these violation can bring risk to the prediction results and lead to poor decision making.",6 Broader Impact,126,9,,,FALSE,FALSE,FALSE,Counterfactual Prediction for Bundle Treatment,Probabilistic Methods -> Causal Inference,,Causality,"['Hao Zou', ' Peng Cui', ' Bo Li', ' Zheyan Shen', ' Jianxin Ma', ' Hongxia Yang', ' Yue He']","{'Alibaba Group', 'Tsinghua University'}",1,1,1,{'China'}
Beta Embeddings for Multi-Hop Logical Reasoning in Knowledge Graphs,"Hongyu Ren, Jure Leskovec",Beta Embeddings for Multi-Hop Logical Reasoning in Knowledge Graphs,e43739bba7cdb577e9e3e4e42447f5a5,https://proceedings.neurips.cc/paper/2020/file/e43739bba7cdb577e9e3e4e42447f5a5-Paper.pdf,"B ETA E gives rise to the first method that handles all logical operators in large heterogeneous KGs. It will greatly increase the scalability and capability of multi-hop reasoning over real-world KGs and heterogenous networks. One potential risk is that the model may make undesirable predictions in a completely random KG, or a KG manipulated by adversarial and malicious attacks [36, 37]. Recent progress on adversarial attacks [36, 37] have shown that manipulation of the KG structure may effectively deteriorate the performance of embedding-based methods. And this may mislead the users and cause negative impact. We will continue to work on this direction to design more robust KG embeddings. Alternatively, this issue can also be alleviated through human regularization of real-world KGs.",Broader Impact,122,7,,,FALSE,FALSE,FALSE,Beta Embeddings for Multi-Hop Logical Reasoning in Knowledge Graphs,Algorithms -> Relational Learning,Algorithms -> Representation Learning; Deep Learning -> Embedding Approaches,Deep learning,"['Hongyu Ren', ' Jure Leskovec']","{'Stanford University', 'Stanford University and Pinterest'}",1,0,0,{'USA'}
Learning Disentangled Representations and Group Structure of Dynamical Environments,"Robin Quessard, Thomas Barrett, William Clements",Learning Disentangled Representations and Group Structure of Dynamical Environments,e449b9317dad920c0dd5ad0a2a2d5e49,https://proceedings.neurips.cc/paper/2020/file/e449b9317dad920c0dd5ad0a2a2d5e49-Paper.pdf,"We propose a new methodology for learning disentangled representations which is demonstrated on model datasets as a proof of principle, therefore our contribution is not at a stage where it is expected to have immediate societal impact. More broadly, however, improved representations can be expected to underpin powerful ML systems that model real-world environments and data. Inter- pretability is one of the goals of disentangled representations and does merit particular consideration as it is essentially an attempt to extract the underlying description of the world that the system has learnt. It is therefore important that this interpretation is both fair (free from inherent bias) and presented with sufficient context (for example, the learnt representation could simply be one of many equal valid descriptions of the observed data). In this context, a mathematically rigorous definition of disentanglement, such as that presented by Higgins et al. (2018) and used in this work, would seem to be a good first step, though it cannot be considered to fully address these considerations on its own.",Broader Impact,171,6,,,FALSE,FALSE,FALSE,Learning Disentangled Representations and Group Structure of Dynamical Environments,Algorithms -> Representation Learning,Algorithms -> Dynamical Systems,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Robin Quessard', ' Thomas Barrett', ' William Clements']",{'University of Oxford'},1,0,0,{'UK'}
Learning Linear Programs from Optimal Decisions,"Yingcong Tan, Daria Terekhov, Andrew Delong",Learning Linear Programs from Optimal Decisions,e44e875c12109e4fa3716c05008048b2,https://proceedings.neurips.cc/paper/2020/file/e44e875c12109e4fa3716c05008048b2-Paper.pdf,"We believe this work may be of interest to scientists working in machine learning, operations research, mechanism design and/or game theory. The methodology applies whenever desired outcomes of an LP can be given by example, rather than by the LP’s coefficients. Linear programs are widely used for planning, for modeling natural phenomena, and for decision-making agents. A positive impact of this work is faster and more flexible training of LPs. For example, this may be useful for training better recommender systems when users are known to optimize their choices. Another positive impact is data efficiency: LPs are a strong class of inductive priors, so we can learn more interpretable models from less data. Data efficiency is important because collecting data on optimal decisions (and under different conditions) can be very expensive, and because interpretability is important in decision-making settings where unwanted biases may be introduced from the data. While our goal is for the work to have positive impact, and it has potential applications in co-operative games, negative outcomes are also possible if the framework is applied with malicious or adversarial goals, for example to build a model of an opponent’s decision-making process in an adversarial game.",Broader Impact,197,8,,,FALSE,FALSE,FALSE,Learning Linear Programs from Optimal Decisions,Optimization,Optimization -> Convex Optimization; Optimization -> Non-Convex Optimization,Optimization Methods (continuous or discrete),"['Yingcong Tan', ' Daria Terekhov', ' Andrew Delong']",{'Concordia University'},1,0,0,{'Canada'}
Wisdom of the Ensemble: Improving Consistency of Deep Learning Models,"Lijing Wang, Dipanjan Ghosh, Maria Gonzalez Diaz, Ahmed Farahat, Mahbubul Alam, Chetan Gupta, Jiangzhuo Chen, Madhav Marathe",Wisdom of the Ensemble: Improving Consistency of Deep Learning Models,e464656edca5e58850f8cec98cbb979b,https://proceedings.neurips.cc/paper/2020/file/e464656edca5e58850f8cec98cbb979b-Paper.pdf,"Users’ trust in AI systems is of paramount importance and is the genesis of the problem discussed in this study. We developed metrics to measure consistency as well as correct-consistency of the outcome of AI systems. The problem discussed in this paper is foundational in nature, however, we firmly believe that the study may have a major impact on applications of prognostics and recommendation  engines where users’ behavior or actions can be affected immediately. Examples of such applications include but are not limited to vehicle/industrial asset repair recommendations, medical diagnosis recommendations, failure predictions, vehicle safety alerts, epidemic onset/peak time forecasting, traffic predictions, etc. Our recommendation is to use the proposed metrics in addition to existing aggregate metrics like accuracy to evaluate the AI system before deployment. The Data scientist and DevOps team may consider highlighting these metrics to decision makers before deployment. While this work highlights the importance of consistency and correct-consistency, care should be taken to study and quantify generalization capability of the AI models. An AI model with 100% accuracy generally indicates possible overfitting, and hence, appropriate trade-off between consistency metrics and generalization metrics may be required. Moreover, careful weighting of these metrics should be considered in applications by decision makers. Thus, we also further recommend to emphasize on continual learning research by the AI community and incorporate our proposed metrics appropriately. Furthermore, we emphasize that the proposed work is applicable to other non-neural network algorithms such as XGBoost which does not have a closed form solution. This may be an immediate future direction to extend this study. In conclusion, we strongly recommend further development in this newly introduced impactful research direction before any real deployment to critical applications.",Broader Impact,281,13,,,FALSE,FALSE,FALSE,Wisdom of the Ensemble: Improving Consistency of Deep Learning Models,Deep Learning -> Analysis and Understanding of Deep Networks,Algorithms -> Classification; Deep Learning -> Predictive Models; Deep Learning -> Supervised Deep Networks,Deep learning,"['Lijing Wang', ' Dipanjan Ghosh', ' Maria Gonzalez Diaz', ' Ahmed Farahat', ' Mahbubul Alam', ' Chetan Gupta', ' Jiangzhuo Chen', ' Madhav Marathe']",{'University of Virginia'},1,0,0,{'USA'}
Universal Function Approximation on Graphs,Rickard Gabrielsson,Universal Function Approximation on Graphs,e4acb4c86de9d2d9a41364f93951028d,https://proceedings.neurips.cc/paper/2020/file/e4acb4c86de9d2d9a41364f93951028d-Paper.pdf,"This work helps advance the fields of machine learning and AI, which as a whole is likely to have both positive and negative societal consequences [17, 5]; many of which might be unintended [6]. The coupling of application and theory in this work aims at improving human understanding of AI which is related to efforts within for example explainable AI [2]. Such efforts may reduce unintended consequences of AI.",6 Broader Impact,69,3,,,FALSE,FALSE,FALSE,Universal Function Approximation on Graphs,Algorithms,Algorithms -> Representation Learning; Applications -> Network Analysis; Theory -> Computational Learning Theory,Theory (including computational and statistical analyses),['Rickard Gabrielsson'],{'Stanford University'},1,0,0,{'USA'}
Accelerating Reinforcement Learning through GPU Atari Emulation,"Steven Dalton, iuri frosio",Accelerating Reinforcement Learning through GPU Atari Emulation,e4d78a6b4d93e1d79241f7b282fa3413,https://proceedings.neurips.cc/paper/2020/file/e4d78a6b4d93e1d79241f7b282fa3413-Paper.pdf,"As interest in deep reinforcement learning has grown so has the computational requirements for researchers in this field. However, the reliance of DRL on the CPU, especially for environment simu- lation/emulation, severely limits the utilization of the computational resources typically accessible to DL researchers, specifically GPUs. Though Atari is a specialized DRL environment, it is arguably one of the most studied in recent times and provides access to several training environments with various levels of difficulty. The development and testing of DRL using Atari games remains a relevant and significant step toward more efficient algorithms. There are two impact points for CuLE: 1) Provide access to an accelerated training environment to researchers with limited computational capabilities. 2) Facilitate research in novel directions that explore thousands of agents without requiring access to a distributed system with hundreds of CPU cores. Although leaving RL environments ""as-is"" on CPUs and parallelizing across multiple nodes is indeed the shortest path to make progres, it is also inherently inefficient, in terms of the resource utilization on the local machine, and expensive, since it requires access to a large number of distributed machines. The more efficient use of the computational resources could also lead to a smaller carbon footprint.",6 Impact Statement,203,8,,,FALSE,FALSE,FALSE,Accelerating Reinforcement Learning through GPU Atari Emulation,Reinforcement Learning and Planning -> Reinforcement Learning,"Applications -> Hardware and Systems; Data, Challenges, Implementations, and Software -> Benchmarks; Data, Challenges, Implementations, and Software -> Software Toolkits","Datasets, challenges, software","['Steven Dalton', ' iuri frosio']","{'nvidia', 'Nvidia'}",0,1,0,{'USA'}
EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning,"Jiachen Li, Fan Yang, Masayoshi Tomizuka, Chiho Choi",EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning,e4d8163c7a068b65a64c89bd745ec360,https://proceedings.neurips.cc/paper/2020/file/e4d8163c7a068b65a64c89bd745ec360-Paper.pdf,"In this work, the authors introduce EvolveGraph, a generic trajectory prediction framework with dynamic relational reasoning, which can handle evolving interacting systems involving multiple heterogeneous, interactive agents. The proposed framework could be applied to a wide range of applications, from purely physical systems to complex social dynamics systems. In this paper, we demonstrate some illustrative applications to physics objects, traffic participants, and sports players. The framework could also be applied to analyze and predict the evolution of larger interacting systems, such as social networks and traffic flows. Although there are existing works using graph neural  networks to handle trajectory prediction tasks, here we emphasize the impact of using our framework to recognize and predict the evolution of the underlying relations. With accurate and reasonable relational structures, we can forecast or generate plausible system behaviors, which help much with optimal decision making. However, if the predicted relational structures are wrong or misleading, the prediction performance may be degraded since the forecast highly depends on relational structures. There is no guarantee that such frameworks are able to work well on all kinds of applications. Therefore, users are expected to assess the applicability and risk for a specific purpose.",Broader Impact,196,9,,,FALSE,FALSE,FALSE,EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning,Applications -> Robotics,Applications -> Computer Vision,"Other applications (e.g., robotics, biology, climate, finance)","['Jiachen Li', ' Fan Yang', ' Masayoshi Tomizuka', ' Chiho Choi']","{'University of California, Berkeley', 'Honda Research Institute US'}",1,1,1,{'USA'}
Comparator-Adaptive Convex Bandits,"Dirk van der Hoeven, Ashok Cutkosky, Haipeng Luo",Comparator-Adaptive Convex Bandits,e4f37b9ed429c1fe5ce61860d9902521,https://proceedings.neurips.cc/paper/2020/file/e4f37b9ed429c1fe5ce61860d9902521-Paper.pdf,"Our contribution is primarily theoretical, and we do not foresee any negative ethical or society impact.",Broader Impact,16,1,TRUE,FALSE,FALSE,FALSE,FALSE,Comparator-Adaptive Convex Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning,Theory (including computational and statistical analyses),"['Dirk van der Hoeven', ' Ashok Cutkosky', ' Haipeng Luo']","{'University of Southern California', 'Leiden University', 'Google Research'}",1,1,1,"{'USA', 'Netherlands'}"
Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs,"Jianzhun Du, Joseph Futoma, Finale Doshi-Velez",Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs,e562cd9c0768d5464b64cf61da7fc6bb,https://proceedings.neurips.cc/paper/2020/file/e562cd9c0768d5464b64cf61da7fc6bb-Paper.pdf,"We introduce a new approach for continuous-time reinforcement learning that could eventually be useful for a variety of applications with irregular time-series, e.g. in healthcare. However, models are only as good as the assumptions made in the architecture, the data they are trained on, and how they are integrated into a broader context. Practitioners should treat any output from RL models objectively and carefully, as in real life there are many novel situations that may not be covered by the RL algorithm.",Broader Impact,82,3,,,FALSE,FALSE,FALSE,Model-based Reinforcement Learning for Semi-Markov Decision Processes with Neural ODEs,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Model-Based RL,Reinforcement learning and planning,"['Jianzhun Du', ' Joseph Futoma', 'Velez']","{'Harvard University', 'Harvard'}",1,0,0,{'USA'}
The Adaptive Complexity of Maximizing a Gross Substitutes Valuation,"Ron Kupfer, Sharon Qian, Eric Balkanski, Yaron Singer",The Adaptive Complexity of Maximizing a Gross Substitutes Valuation,e56954b4f6347e897f954495eab16a88,https://proceedings.neurips.cc/paper/2020/file/e56954b4f6347e897f954495eab16a88-Paper.pdf,"This work focuses on the adaptivity of maximizing gross substitutes functions. While previous work has been done on maximizing submodular functions, a superclass of gross substitutes, little is known about the adaptivity complexity to achieve optimal results for this particular class of functions. Our results show an exponentially faster algorithm with near-optimal approximation guarantees for optimization of gross substitute valuations, which have numerous applications in microeconomics and market design [2, 33, 3, 23, 25] and appear in multiple fields such as discrete mathematics [28] and number theory [14]. The algorithm presented in this work is particularly relevant to applications on large datasets where sequential algorithms such as G REEDY become impractical and computationally infeasible. By using a low-adaptivity algorithm such as GSAS, we are able to take advantage of parallelization and dramatically speed up computation on large datasets. In Section 5, we show an application of this algorithm on large constructed Twitter networks to efficiently match keywords in advertisements to bidders or advertisers. In our experimental results, we show both the effective performance and computational efficiency of using GSAS on different networks. This shows that the limited adaptivity of GSAS can be effectively leveraged to analyze trends on other large-scale social networks and applications.",Broader Impact,204,8,,,FALSE,FALSE,FALSE,The Adaptive Complexity of Maximizing a Gross Substitutes Valuation,Theory -> Game Theory and Computational Economics,,Theory (including computational and statistical analyses),"['Ron Kupfer', ' Sharon Qian', ' Eric Balkanski', ' Yaron Singer']","{'Harvard University', 'Harvard', 'The Hebrew University of Jerusalem'}",1,0,0,"{'USA', 'Israel'}"
A Robust Functional EM Algorithm for Incomplete Panel Count Data,"Alexander Moreno, Zhenke Wu, Jamie Roslyn Yap, Cho Lam, David Wetter, Inbal Nahum-Shani, Walter Dempsey, James M. Rehg",A Robust Functional EM Algorithm for Incomplete Panel Count Data,e56eea9a45b153de634b23780365f976,https://proceedings.neurips.cc/paper/2020/file/e56eea9a45b153de634b23780365f976-Paper.pdf,"Understanding the dynamics for individuals who attempt to change and maintain behaviors to improve health has important societal value, for example, a comprehensive understanding of how smokers attempt to quit smoking may guide behavioral scientists to design better intervention strategies that tailor to the highest risk windows of relapse. Our theory and method provide an approach to understanding a particular aspect of the smoking behavior (mean function). The resulting algoithm is robust to Poisson process violations, readily adaptable and simple to implement, highlighting the potential for its wider adoption. The negative use case could be lack of sensitivity analysis around the assumptions such as missing data mechanism which may lead to misleading conclusions. Our current recommendation is to consult scientists about the plausibility of the assumption about missing data.",Broader Impact,129,5,,,FALSE,FALSE,FALSE,A Robust Functional EM Algorithm for Incomplete Panel Count Data,Theory -> Spaces of Functions and Kernels,Algorithms -> Missing Data; Applications -> Health; Optimization -> Non-Convex Optimization,,"['Alexander Moreno', ' Zhenke Wu', ' Jamie Roslyn Yap', ' Cho Lam', ' David Wetter', 'Shani', ' Walter Dempsey', ' James M Rehg']","{'University of Michigan', 'Georgia Institute of Technology', 'Georgia Tech', 'University of Utah'}",1,0,0,{'USA'}
Graph Stochastic Neural Networks for Semi-supervised Learning,"Haibo Wang, Chuan Zhou, Xin Chen, Jia Wu, Shirui Pan, Jilong Wang",Graph Stochastic Neural Networks for Semi-supervised Learning,e586a4f55fb43a540c2e9dab45e00f53,https://proceedings.neurips.cc/paper/2020/file/e586a4f55fb43a540c2e9dab45e00f53-Paper.pdf,"Our work could bring the following positive impacts. (1) The proposed framework, which models the uncertainty of the classification function, provides a new idea for semi-supervised learning on graph data. (2) In practice, labeled nodes are generally scarce and expensive to obtain. GSNN could effectively alleviate the overfitting problem and improve the performance. (3) Noise could render deterministic GNN-based models vulnerable, while GSNN could alleviate the negative impacts of noise to a large extent. Many real-world applications, especially the risk-sensitive applications ( e.g., financial transaction), would benefit from it. Similar with many other GNNs, one potential issue of our model is that it provides limited interpreta- tion of its predictions. We advocate peer researchers to make a profound study on this to improve the interpretability of modern GNN architectures and make GNNs applicable in more risk-sensitive applications.",Broader Impact,137,8,,,FALSE,FALSE,FALSE,Graph Stochastic Neural Networks for Semi-supervised Learning,Algorithms -> Semi-Supervised Learning,Algorithms -> Representation Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Haibo Wang', ' Chuan Zhou', ' Xin Chen', ' Jia Wu', ' Shirui Pan', ' Jilong Wang']","{'Macquarie University', 'Institute for Network Sciences and Cyberspace, Tsinghua University', 'Monash University', 'Chinese Academy of Sciences', 'Tsinghua University'}",1,0,0,"{'Australia', 'China'}"
Compositional Zero-Shot Learning via Fine-Grained Dense Feature Composition,"Dat Huynh, Ehsan Elhamifar",Compositional Zero-Shot Learning via Fine-Grained Dense Feature Composition,e58cc5ca94270acaceed13bc82dfedf7,https://proceedings.neurips.cc/paper/2020/file/e58cc5ca94270acaceed13bc82dfedf7-Paper.pdf,"This work addresses the problem of learning without labeled samples, which has fundamental societal, environmental, privacy and technological impacts. Depending less on large-scale annotated data facilitates the process of democratizing machine learning for resource-constrained communities and entities that lack high computational powers or data collection capacity [73]. We also reduce the need for collecting and learning from personal data [74]. Learning without labeled data enables recognition of endangered animal species and plants, and subsequently taking protective measures. As with any technologies, it is important to study the potential misuses of our method. Since semantic descriptions are often given by humans, methods such as ours could reinforce biases encoded in the semantic information. To prevent biases in predictions, it is important to establish guidelines for regulating and examining the semantic descriptions used for training.",Broader Impacts,133,7,,,FALSE,FALSE,FALSE,Compositional Zero-Shot Learning via Fine-Grained Dense Feature Composition,Algorithms -> Few-Shot Learning,Applications -> Computer Vision; Deep Learning -> Attention Models,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,{'Northeastern University'},1,0,0,{'USA'}
A Benchmark for Systematic Generalization in Grounded Language Understanding,"Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, Brenden M. Lake",A Benchmark for Systematic Generalization in Grounded Language Understanding,e5a90182cc81e12ab5e72d66e0b46fe3,https://proceedings.neurips.cc/paper/2020/file/e5a90182cc81e12ab5e72d66e0b46fe3-Paper.pdf,"Systematic generalization characterizes human language and thought, but it remains a challenge for modern AI systems. The gSCAN benchmark is designed to stimulate further research on this topic. Advances in machine systematic generalization could facilitate improvements in learning efficiency, robustness, and human-computer interaction. We do not anticipate that the broader impacts would selectively benefit some groups at the expense of others.",Broader Impact,61,4,,,FALSE,FALSE,FALSE,A Benchmark for Systematic Generalization in Grounded Language Understanding,Applications -> Natural Language Processing,"Algorithms -> Few-Shot Learning; Data, Challenges, Implementations, and Software -> Benchmarks; Deep Learning -> Attention Models; Deep Learning -> Recurrent Networks; Deep Learning -> Supervised Deep Networks; Neuroscience and Cognitive Science -> Cognitive Science; Neuroscience and Cognitive Science -> Language for Cognitive Science; Neuroscience and Cognitive Science -> Reasoning",Neuroscience and cognitive science,"['Laura Ruis', ' Jacob Andreas', ' Marco Baroni', ' Diane Bouchacourt', ' Brenden Lake']","{'Facebook Artificial Intelligence Research', 'University of Amsterdam', 'Facebook AI', 'MIT', 'New York University'}",1,1,1,"{'USA', 'Netherlands'}"
Weston-Watkins Hinge Loss and Ordered Partitions,"Yutong Wang, Clayton Scott",Weston-Watkins Hinge Loss and Ordered Partitions,e5e6851e7f7ffd3530e7389e183aa468,https://proceedings.neurips.cc/paper/2020/file/e5e6851e7f7ffd3530e7389e183aa468-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Weston-Watkins Hinge Loss and Ordered Partitions,Theory -> Statistical Learning Theory,Algorithms -> Classification; Algorithms -> Kernel Methods,Theory (including computational and statistical analyses),"['Yutong Wang', ' Clayton Scott']",{'University of Michigan'},1,0,0,{'USA'}
Reinforcement Learning with Augmented Data,"Misha Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel, Aravind Srinivas",Reinforcement Learning with Augmented Data,e615c82aba461681ade82da2da38004a,https://proceedings.neurips.cc/paper/2020/file/e615c82aba461681ade82da2da38004a-Paper.pdf,"While there has been a trend in growing complexity and compute requirements to achieve state-of- the-art results in Computer Vision [20], NLP [47], and RL [48], there are two negative long-term consequences of these trends: (i) the energy demands of these large models are harmful to the environment due to increased carbon emissions if not powered by renewable energy sources (ii) they make AI research inaccessible to researchers without access to tremendous compute and engineering resources. RAD shows that, by incorporating powerful inductive biases, state-of-the-art results can be achieved with simpler methods that require less compute and model complexity than complex competing methods. RAD is therefore accessible to a broad range of researchers (even those without access to GPUs) and leaves a much smaller carbon footprint than competing methods. While it’s fair to say that even with the result from this paper, we are far removed from making Deep RL practical for solving real-world-complexity robotics problems, we believe this work provides progress towards that goal. Robots being able to learn through RL in the real world opens up opportunities for better elderly care, autonomous cleaning and disinfecting, more reliable / resilient supply chain and manufacturing operations (especially when humans might not be available due to a pandemic). On the flipside, an RL agent will optimize whatever reward one specifies. If the person in charge of the system specifies a reward that’s bad for the world (or perhaps mistakenly even for themselves), the more powerful the RL, the worse the outcome. For this reason, in addition to developing better algorithms that achieve new state-of-the-art performance, it is also important to pursue complementary research on safety [49, 50].",7 Broader Impact,276,8,,,FALSE,FALSE,FALSE,Reinforcement Learning with Augmented Data,Reinforcement Learning and Planning,Deep Learning -> Efficient Training Methods; Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Reinforcement Learning,,"['Misha Laskin', ' Kimin Lee', ' Adam Stooke', ' Lerrel Pinto', ' Pieter Abbeel', ' Aravind Srinivas']","{'UC Berkeley', 'NYU/Berkeley'}",1,0,0,{'USA'}
Towards Minimax Optimal Reinforcement Learning in Factored Markov Decision Processes,"Yi Tian, Jian Qian, Suvrit Sra",Towards Minimax Optimal Reinforcement Learning in Factored Markov Decision Processes,e61eaa38aed621dd776d0e67cfeee366,https://proceedings.neurips.cc/paper/2020/file/e61eaa38aed621dd776d0e67cfeee366-Paper.pdf,"This work focuses on a theoretical problem about efficient learning in factored MDPs. The work itself is ethically neutral. Future societal consequences heavily depend on the specific domain of application. For example, applications to home robots can potentially alleviate the housework in a middle-class family and contribute to the harmony therein.",Broader impact,51,4,FALSE,TRUE,FALSE,FALSE,FALSE,Towards Minimax Optimal Reinforcement Learning in Factored Markov Decision Processes,Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Model-Based RL,Reinforcement learning and planning,"['Yi Tian', ' Jian Qian', ' Suvrit Sra']",{'MIT'},1,0,0,{'USA'}
Graduated Assignment for Joint Multi-Graph Matching and Clustering with Application to Unsupervised Graph Matching Network Learning,"Runzhong Wang, Junchi Yan, Xiaokang Yang",Graduated Assignment for Joint Multi-Graph Matching and Clustering with Application to Unsupervised Graph Matching Network Learning,e6384711491713d29bc63fc5eeb5ba4f,https://proceedings.neurips.cc/paper/2020/file/e6384711491713d29bc63fc5eeb5ba4f-Paper.pdf,"a) Who may benefit from this research. In this paper, a graduated assignment approach is proposed for two challenging real-world problems – multi-graph matching (MGM) and multi-graph matching and clustering (MGMC), together with an unsupervised learning scheme for both problems. The wide range of applications in pattern recognition and data mining may benefit from this research, as unsupervised learning with comparative performance with supervised learning is usually welcomed for real-world applications. b) Who may be put at disadvantage from this research. Multi-graph matching and multi-graph matching and clustering techniques may be applied to some intensive areas, e.g. analyzing surveillance sequences, which improves security but potentially puts citizens’ privacy at risk. Therefore, the potentially affected people should be well informed before any deployment of our technique in such intensive areas. c) What are the consequences of failure of the system. A failure of our system may result in totally meaningless matching and clustering results, further affecting the algorithm for downstream tasks. It is worth noting that unsupervised learning approach may overfit on small-scaled training data, and people should carefully validate the efficacy of the system before deploying to real-world scenes. d) Whether the task/method leverages biases in the data. Although unsupervised learning may overfit on biased training data, we think our unsupervised learning approach helps to mitigate such issue because its data collection is cheaper compared to supervised learning, making it easier to build an unbiased training set. Furthermore, within the scope of our experiments, our unsupervised learning seems to not leverage the bias in data, as our model performs comparatively on both seen an unseen data during training, as shown in the top of Fig. 2.",Broader Impact,276,13,,,FALSE,FALSE,FALSE,Graduated Assignment for Joint Multi-Graph Matching and Clustering with Application to Unsupervised Graph Matching Network Learning,Deep Learning,Algorithms -> Clustering; Algorithms -> Similarity and Distance Learning; Algorithms -> Unsupervised Learning; Applications -> Computer Vision; Applications -> Network Analysis; Optimization -> Discrete Optimization,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Runzhong Wang', ' Junchi Yan', ' Xiaokang Yang']",{'Shanghai Jiao Tong University'},1,0,0,{'China'}
Estimating Training Data Influence by Tracing Gradient Descent,"Garima Pruthi, Frederick Liu, Satyen Kale, Mukund Sundararajan",Estimating Training Data Influence by Tracing Gradient Descent,e6385d39ec9394f2f3a354d9d2b88eec,https://proceedings.neurips.cc/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf,"This paper proposes a practical technique to understand the influence of training data points on predictions. For most real world applications, the impact of improving the quality of training data is simply to improve the quality of the model. In this sense, we expect the broader impact to be positive. For models that impact humans, for instance a loan application model, the technique could be used to examine the connection between biased training data and biased predictions. Again, we expect the societal impact to be generally positive. However there is an odd chance that an inaccuracy in our method results in calling a model fair when it is not, or unfair, when it is actually fair. This potential negative impact is amplified in the hands of an adversary looking to prove a point, one way or the other. It is also possible that the technique could be used to identify modifications to the training data that hurt predictions broadly or for some narrow category.",8 Broader Impact,164,8,,,FALSE,FALSE,FALSE,Estimating Training Data Influence by Tracing Gradient Descent,"Deep Learning -> Visualization, Interpretability, and Explainability","Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Deep learning,,"{'Google', 'Google LLC'}",0,1,0,{'USA'}
Joint Policy Search for Multi-agent Collaboration with Imperfect Information,"Yuandong Tian, Qucheng Gong, Yu Jiang",Joint Policy Search for Multi-agent Collaboration with Imperfect Information,e64f346817ce0c93d7166546ac8ce683,https://proceedings.neurips.cc/paper/2020/file/e64f346817ce0c93d7166546ac8ce683-Paper.pdf,"This work has the following potential positive impact in the society: • JPS proposes a general formulation and can be applied to multi-agent pure collaborative games (or team collaboration compnents in multi-agent games) beyond the simple games and Contract Bridge we demonstrate in the paper; • JPS can potentially encourage more efficient collaboration between agents and between agents and humans. It might suggest novel coordination patterns, helping jump out of existing (but sub-optimal) social convention. We do not foresee negative societal consequences from JPS.",9 Broader Impact,84,3,,,FALSE,FALSE,FALSE,Joint Policy Search for Multi-agent Collaboration with Imperfect Information,Applications -> Game Playing,Reinforcement Learning and Planning -> Multi-Agent RL,,,{'Facebook AI Research'},0,1,0,{'USA'}
Adversarial Bandits with Corruptions: Regret Lower Bound and No-regret Algorithm,"lin yang, Mohammad Hajiesmaili, Mohammad Sadegh Talebi, John C. S. Lui, Wing Shing Wong",Adversarial Bandits with Corruptions: Regret Lower Bound and No-regret Algorithm,e655c7716a4b3ea67f48c6322fc42ed6,https://proceedings.neurips.cc/paper/2020/file/e655c7716a4b3ea67f48c6322fc42ed6-Paper.pdf,"Our work fits within the broad direction of research concerning safety issues in AI/ML at large. With the recent radical advances in machine learning, ML-assisted decision making is fast becoming an intrinsic part of the design of systems and services that billions of people around the world use every day. And not surprisingly, investigating the vulnerability of existing learning models and robustness against manipulation attacks are becoming critically important in the light of trustworthy learning paradigm . Hence, there has been a surge of interest in making learning models that are robust against adversarial attacks for both applied ML such as supervised learning and deep learning, and theoretical ML such as reinforcement learning and multi-armed bandits. This is critically important for society, since the ML algorithms are being adopted more and more in safety-critical domains across sciences, businesses, and governments that impact people’s daily lives. Last, we see no ethical concerns related to this paper.",7 Broader Impacts,155,6,,,FALSE,FALSE,FALSE,Adversarial Bandits with Corruptions,Algorithms -> Bandit Algorithms,Algorithms -> Online Learning,Reinforcement learning and planning,"['lin yang', ' Mohammad Hajiesmaili', ' Mohammad Sadegh Talebi', ' Lui', ' Wing Shing Wong']","{'The Chinese University of Hong Kong', 'University of Copenhagen', 'UMass', 'UMass Amherst'}",1,0,0,"{'Denmark', 'USA', 'China'}"
Beta R-CNN: Looking into Pedestrian Detection from Another Perspective,"Zixuan Xu, Banghuai Li, Ye Yuan, Anhong Dang",Beta R-CNN: Looking into Pedestrian Detection from Another Perspective,e6b4b2a746ed40e1af829d1fa82daa10,https://proceedings.neurips.cc/paper/2020/file/e6b4b2a746ed40e1af829d1fa82daa10-Paper.pdf,"Our contributions focus on the novel representation and pipeline for pedestrian detection, which can be extended to other computer vision tasks. Also, it may provide new ideas for follow-up research. It therefore has the potential to advance both the beneficial and harmful applications of object detectors, such as autonomous vehicles, intelligent video surveillance, robotics and so on. As for ethical aspects and future societal consequences, this technology can bring harmful or beneficial effects to the society, which depends on the citizens who have evil or pure motivation and who can make good use of this technological progress.",Broader Impact,97,4,,,FALSE,FALSE,FALSE,Beta R-CNN: Looking into Pedestrian Detection from Another Perspective,Applications -> Computer Vision,Algorithms -> Representation Learning,Vision,,"{'Megvii', 'Peking University'}",1,1,1,{'China'}
Batch Normalization Biases Residual Blocks Towards the Identity Function in Deep Networks,"Soham De, Sam Smith",Batch Normalization Biases Residual Blocks Towards the Identity Function in Deep Networks,e6b738eca0e6792ba8a9cbcba6c1881d,https://proceedings.neurips.cc/paper/2020/file/e6b738eca0e6792ba8a9cbcba6c1881d-Paper.pdf,"This work seeks to develop fundamental understanding by identifying the benefits batch normalization brings when training residual networks. We do not foresee any specific negative consequences of this work, although we hope that fundamental understanding may help drive future progress in the field.",Broader impact,43,2,FALSE,TRUE,FALSE,TRUE,FALSE,Batch Normalization Biases Residual Blocks Towards the Identity Function in Deep Networks,Deep Learning -> Analysis and Understanding of Deep Networks,,Deep learning,"['Soham De', ' Sam Smith']","{'Google Brain', 'DeepMind'}",0,1,0,"{'UK', 'USA'}"
Learning Retrospective Knowledge with Reverse Reinforcement Learning,"Shangtong Zhang, Vivek Veeriah, Shimon Whiteson",Learning Retrospective Knowledge with Reverse Reinforcement Learning,e6cbc650cd5798a05dfd0f51d14cde5c,https://proceedings.neurips.cc/paper/2020/file/e6cbc650cd5798a05dfd0f51d14cde5c-Paper.pdf,"Reverse-RL makes it possible to implement anomaly detection with little extra memory. This is particularly important for embedded systems with limited memory, e.g., satellites, spacecrafts, microdrones, and IoT devices. The saved memory can be used to improve other functionalities of those systems. Systems where memory is not a bottleneck, e.g., self-driving cars, benefit from Reverse-RL-based anomaly detection as well, as saving memory saves energy, making them more environment-friendly. Reverse-RL provides a probabilistic perspective for anomaly detection. So misjudgment is possible. Users may have to make a decision considering other available information as well to reach a  certain confidence level. Like any other neural network application, combining neural network with Reverse-RL-based anomaly detection is also vulnerable to adversarial attacks. This means the users, e.g., companies or governments, should take extra care for such attacks when making a decision on whether there is an anomaly or not. Otherwise, they may suffer from property losses. Although Reverse-RL itself does not have any bias or unfairness, if the simulator used to train reverse GVFs is biased or unfair, the learned GVFs are likely to inherit those bias or unfairness. Although Reverse-RL itself does not raise any privacy issue, to make a better simulator for training, users may be tempted to exploit personal data. Like any artificial intelligence system, Reverse-RL-based anomaly detection has the potential to greatly improve human productivity. However, it may also reduce the need for human workers, resulting in job losses.",Broader Impact,239,14,,,FALSE,FALSE,FALSE,Learning Retrospective Knowledge with Reverse Reinforcement Learning,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Shangtong Zhang', ' Vivek Veeriah', ' Shimon Whiteson']","{'University of Michigan', 'University of Oxford'}",1,0,0,"{'UK', 'USA'}"
Dialog without Dialog Data: Learning Visual Dialog Agents from VQA Data,"Michael Cogswell, Jiasen Lu, Rishabh Jain, Stefan Lee, Devi Parikh, Dhruv Batra",Dialog without Dialog Data: Learning Visual Dialog Agents from VQA Data,e7023ba77a45f7e84c5ee8a28dd63585,https://proceedings.neurips.cc/paper/2020/file/e7023ba77a45f7e84c5ee8a28dd63585-Paper.pdf,"We think the main ethical aspects of this work and their consequences for society have to do with fairness. There is an open research problem around existing deep learning models often reflecting and amplifying undesirable biases that exist in society. While visual question answering and visual dialog models do not currently work well enough to be relied on in the real world (largely because of the aforementioned proneness to bias), they could be deployed in applications where these biases could have negative impacts on fairness in the future. For example, visually impaired users might use these models to understand visual aspects of their world [39]. If these models are not familiar with people in certain contexts (e.g., men shopping) or are only used to interacting with certain users (e.g., native English speakers) then they might fail for some sub-groups (e.g., non-native English speakers who go shopping with men) but not others. Our research model may be prone to biases, though it was trained on the VQAv2 dataset [6], which aimed to be more balanced than its predecessor. However, by increasing the intelligibility of generated language our work may help increase the overall interpretability of models. This may help by making bias easier to measure and providing additional avenues for correcting it.",8 Broader Impact,211,8,,,FALSE,FALSE,FALSE,Dialog without Dialog Data: Learning Visual Dialog Agents from VQA Data,Applications -> Visual Question Answering,Applications -> Dialog- or Communication-Based Learning,Natural language processing,"['Michael Cogswell', ' Jiasen Lu', ' Rishabh Jain', ' Stefan Lee', ' Devi Parikh', ' Facebook AI Research', ' Dhruv Batra', ' Facebook AI Research']","{'Georgia Tech', 'Oregon State University', 'FAIR', 'Allen Institute of Artificial Intelligence '}",1,1,1,{'USA'}
GCOMB: Learning Budget-constrained Combinatorial Algorithms over Billion-sized Graphs,"Sahil Manchanda, AKASH MITTAL, Anuj Dhawan, Sourav Medya, Sayan Ranu, Ambuj Singh",GCOMB: Learning Budget-constrained Combinatorial Algorithms over Billion-sized Graphs,e7532dbeff7ef901f2e70daacb3f452d,https://proceedings.neurips.cc/paper/2020/file/e7532dbeff7ef901f2e70daacb3f452d-Paper.pdf,"The need to solve NP-hard combinatorial problems on graphs routinely arise in several real-world problems. Examples include facility location problems on road networks [20], strategies to combat rumor propagation in online social networks [3], computational sustainability [8] and health-care [33]. Each of these problems plays an important role in our society. Consequently, designing effective and efficient solutions are important, and our current work is a step in that direction. The major impact of this paper is that good heuristics for NP-hard problems can be learned for large-scale data. While we are not the first to observe that heuristics for combinatorial algorithms can be learned, we are the first to make them scale to billion-size graphs, thereby bringing an algorithmic idea to practical use-cases.",Broader Impact,123,6,,,FALSE,FALSE,FALSE,GCOMB: Learning Budget-constrained Combinatorial Algorithms over Billion-sized Graphs,Applications -> Network Analysis,Algorithms -> Large Scale Learning; Applications,Machine Learning for Graphs,"['Sahil Manchanda', ' AKASH MITTAL', ' Anuj Dhawan', ' Sourav Medya', ' Sayan Ranu', ' Ambuj K Singh']","{'UNIVERSITY OF CALIFORNIA, SANTA BARBARA', 'Indian Institute of Technology Delhi', 'IIT Delhi', 'Kellogg School of Management, Northwestern University'}",1,0,0,"{'India', 'USA'}"
A General Large Neighborhood Search Framework for Solving Integer Linear Programs,"Jialin Song, ravi lanka, Yisong Yue, Bistra Dilkina",A General Large Neighborhood Search Framework for Solving Integer Linear Programs,e769e03a9d329b2e864b4bf4ff54ff39,https://proceedings.neurips.cc/paper/2020/file/e769e03a9d329b2e864b4bf4ff54ff39-Paper.pdf,"This paper addresses the general problem of integer linear program optimization which has wide applications in the society. Our contribution allows for faster optimization for these problems. By improving solution qualities within a limited optimization time, one can benefit from, for instance, more efficient resource allocations. In our experiments, we focus on comparing with Gurobi which is a leading commercial integer program solver used by lots of companies. Any concrete improvement is likely to result in positive impact on the day-to-day operations of those companies and the soceity as well. We see opportunities of research that incorporating existing highly optimized solvers into the machine learning loop beyond integer programs. We encourage research into understanding how to incorporate previous algorithmic developments with novel machine learning components and the benefit of such synergy.",7 Broad Impact,131,7,,,FALSE,FALSE,FALSE,A General Large Neighborhood Search Framework for Solving Integer Linear Programs,Optimization -> Discrete Optimization,Algorithms -> Structured Prediction; Reinforcement Learning and Planning -> Reinforcement Learning,Optimization Methods (continuous or discrete),"['Jialin Song', ' ravi lanka', ' Yisong Yue', ' Bistra Dilkina']","{'University of Southern California', 'Caltech', 'rakuten'}",1,1,1,"{'Japan', 'USA'}"
A Theoretical Framework for Target Propagation,"Alexander Meulemans, Francesco Carzaniga, Johan Suykens, João Sacramento, Benjamin F. Grewe",A Theoretical Framework for Target Propagation,e7a425c6ece20cbc9056f98699b53c6f,https://proceedings.neurips.cc/paper/2020/file/e7a425c6ece20cbc9056f98699b53c6f-Paper.pdf,"Since the nature of our work is mostly theoretical with no immediate practical applications, we do not anticipate any direct societal impact. However, on the long-term, our work can have an impact on related research communities such as neuroscience or deep learning, which can have both positive and negative societal impact, depending on how these fields develop. For example, we show that the TP framework, when using a new reconstruction loss, is a viable credit assignment method for feedforward networks that fundamentally differs from the standard training method known as BP. Furthermore, TP only uses information which is local to each neuron and mitigates the weight transport and signed error transmission problem, the two major criticisms of BP. This renders TP appealing for neuroscientists that investigate how credit assignment is organized in the brain (Lillicrap et al., 2020; Richards et al., 2019) and how neural circuits (dys)function in health and disease. From a machine learning perspective, the TP framework has inspired new training methods for recurrent neural networks (RNNs) (Manchev and Spratling, 2020; Ororbia et al., 2020; DePasquale et al., 2018; Abbott et al., 2016), which is beneficial because the conventional backpropagation-through-time method (Werbos, 1988; Robinson and Fallside, 1987; Mozer, 1995) for training RNNs still suffers from significant drawbacks, such as vanishing and exploding gradients (Hochreiter, 1991; Hochreiter and Schmidhuber, 1997). Here, our work provides a new angle for the field to investigate the theoretical underpinnings of credit assignment in RNNs based on TP.",Broader impact,244,7,,,FALSE,FALSE,FALSE,A Theoretical Framework for Target Propagation,Deep Learning -> Biologically Plausible Deep Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Neuroscience and cognitive science,"['Alexander Meulemans', ' Francesco Carzaniga', ' Johan Suykens', ' João Sacramento', ' Grewe']","{'ETH Zurich', 'Institute of Neuroinformatics, University of Zurich and ETH Zurich', 'KU Leuven'}",1,0,0,"{'Belgium', 'Switzerland'}"
OrganITE: Optimal transplant donor organ offering using an individual treatment effect,"Jeroen Berrevoets, James Jordon, Ioana Bica, alexander gimson, Mihaela van der Schaar",OrganITE: Optimal transplant donor organ offering using an individual treatment effect,e7c573c14a09b84f6b7782ce3965f335,https://proceedings.neurips.cc/paper/2020/file/e7c573c14a09b84f6b7782ce3965f335-Paper.pdf,"It is very clear that machine learning has the potential to transform healthcare. Its success both in other domains and already within healthcare is very promising. OrganITE has the potential to extend lives . However, as with almost any other machine learning method, there are risks associated with its deployment in a real healthcare setting. We would stress that to mitigate these risks, we envisage OrganITE as a decision support tool , with the clinicians and their patients making the final decision on any suggested organ-recipient pairing.  A match made in high dimensions. A persistent problem in all transplantation programs is the shortage of suitable donor organs of appropriate quality, resulting in a significant waiting list mortality. That issue is compounded by the importance of matching high-dimensional donor characteristics to high-dimensional recipient characteristics to achieve the best outcome for that donor and recipient pair. Outcome after transplantation is dependent on a wide range of factors including the cause of the disease, clinical status, and laboratory parameters of the recipient (describing how sick they are) as well as characteristics related to the donor quality including age, body mass index, donor diabetes, and other factors. The interaction of all these parameters is complex and makes the problem ripe for a machine learning driven solution [52]. Machine learning can fail. It is very important to note that machine learning models can fail, and OrganITE is no exception. In Section 3 we outline two assumptions that need to hold to make correct estimations of the potential outcomes used in OrganITE: overlap, and unconfoundedness. Failing to satisfy these assumptions can lead to OrganITE failing to learn the necessary individualised treatment effect, and thus assigning an organ sub-optimally with respect to its objective, resulting in the ""proper"" recipient potentially failing to receive an organ they should have. This has the very serious potential for mortality that would/could have otherwise been avoided. Having domain knowledge of the data is therefore crucially important [3, 53, 28] to ensure it satisfies the assumptions. The past is not the present. Learning from historical data (the data used in the experiments of this paper spanned 26 years), presents further possible concerns. Surgical techniques, immunosuppressive protocols, allocation and management policies have all materially changed over the years. Biases will present differently over time. Historical data will not only reflect biases produced by medical policy but also social policy, which has implications regarding the fairness of the learned model with respect to previously disadvantaged subgroups of the population - if access to healthcare in the past was difficult for certain subgroups, they may not be well represented in the data, and OrganITE may fail to learn their potential outcomes well. A population of equals. Agreeing on the best objective in organ-transplantation is incredibly difficult [54]. The total life-years objective used here puts equal value in each year of each person’s life. On the surface this may seem ""fair"", but the moral question of whether, for example, 2 people surviving for 10 additional years is better than 1 surviving for 21 additional years is deep and one that society needs to answer for itself. Does the answer change if you learn that one of the people involved is 85 while the other is 15? OrganITE, and moreover this paper, does not attempt to answer this question, nor is it tied to total life-years. OrganITE can be adapted to other objectives straightforwardly by replacing the value function associated with total life-years with another that places different weighting on different recipients’ lives. There are several different organ allocation schemes that have been considered in health systems [55, 56, 57], where the issue of the definition of equitable allocation continues to be debated. Factors such as equity concerning aetiology of organ disease [58], demographic, and deprivation status need to be considered [59], as well as geography and distance from a transplant centre [60, 61]. Whilst methodologies such as OrganITE, including its emphasis on future donor organ density, may show theoretic benefits, ensuring equity of access in those parameters will be important and will need to be considered before actual implementation. The National Liver Offering Scheme, based on net life-years gained, transplant benefit, currently used in the UK, was introduced in March 2018 after a transplant benefit score was shown to maximise population life years in a simulation comparing transplant benefit with prior unit based allocation, a sickest first policy or a utility policy [3]. Transplant benefit policies, as compared to a simple needs-based policy also have some ethical benefits [62] as they attempt to balance both justice (prioritizing high need) and utility. Although concerns have been raised about the imprecision in calculating net benefit using Cox models, which was acknowledged by Schaubel et al. [54], our results demonstrates OrganITE’s superiority compared to other policies in our simulations.",Broader impact,800,35,,,TRUE,TRUE,FALSE,OrganITE: Optimal transplant donor organ offering using an individual treatment effect,Applications -> Health,Probabilistic Methods -> Causal Inference,Healthcare,"['Jeroen Berrevoets', ' James Jordon', ' Ioana Bica', ' alexander gimson', ' Mihaela van der Schaar']","{'University of Oxford', 'University of Cambridge', 'Cambridge University Hospitals'}",1,0,0,{'UK'}
The Complete Lasso Tradeoff Diagram,"Hua Wang, Yachong Yang, Zhiqi Bu, Weijie Su",The Complete Lasso Tradeoff Diagram,e7db14e12fb49c1d78a573e6e5f542c2,https://proceedings.neurips.cc/paper/2020/file/e7db14e12fb49c1d78a573e6e5f542c2-Paper.pdf,"In this work, we provide a theoretical study to better understand the performance of Lasso as a model (feature) selector. We evaluate the performance of Lasso by TPP–FDP (i.e., type I error and power) tradeoff along the entire Lasso path. Such a plot is called the Lasso Diagram. Our result is the first complete analysis of the Lasso Diagram. We extend the previous unachievability results in [21] and the DT phase transition in [10] by discovering three different kinds of the Lasso Diagram,. Overall, our theoretical study provides a better understanding of the advantages and limitations of the Lasso as a model selector. Our theoretical work has the potential to impact many other neighboring areas in the statistics and the ML community. The Lasso is one of the most famous ways to do the feature selection. Its solution is usually sparse, and thus can be used to select a subset of variables out of many possible explanatory variables. This way it has extensive applications in computational biology, genetics, medicine, statistical finance, among others. Though as a primitive statistical method, there are many modern variants outperform the Lasso itself, a thorough understanding of the Lasso is nevertheless a good starting point for a better understanding of other related and more powerful methods. Sometimes, the hardness of using Lasso as a model selector is also a good proxy for the hardness of the problem itself. To the least extent, it is also of great theoretical value to understand it thoroughly. There are a number of good works, for example [9, 23, 24, 5], that devote to understanding the advantages and limitations of the Lasso. Our new and complete analysis of the Lasso Diagram has the potential to provide new insight into the model selection problem itself along with other more complex model selection methods. We hope our theoretical analysis can inspire more studies into other unsolved related questions. For example, similar questions also arise for other penalized regression-based model selection methods, like SLOPE or SCAD. A fine-grained analysis of the achievable region of those methods can be of great theoretical value and enhance our understanding of the pros and cons of those methods. For the practitioners, it is also very interesting and important to see how we can leverage our understanding of the Lasso diagram to better analyze practical problems and guide more informed fine-tuning in practice. A complete theoretical explanation of why certain methods have better empirical performance in certain scenarios is the scaffold to build better methods.",Broader Impact,417,20,,,FALSE,FALSE,FALSE,The Complete Lasso Tradeoff Diagram,Theory -> High-Dimensional Inference,Algorithms -> Regression,Theory (including computational and statistical analyses),"['Hua Wang', ' Yachong Yang', ' Zhiqi Bu', ' Weijie Su']","{'Wharton School, University of Pennsylvania', 'University of Pennsylvania', 'The Wharton School, University of Pennsylvania'}",1,0,0,{'USA'}
On the universality of deep learning,"Emmanuel Abbe, Colin Sandon",On the universality of deep learning,e7e8f8e5982b3298c8addedf6811d500,https://proceedings.neurips.cc/paper/2020/file/e7e8f8e5982b3298c8addedf6811d500-Paper.pdf,We do not anticipate any ethical aspects and future societal consequences due to the theoretical focus of this work.,Broader Impact,19,1,TRUE,FALSE,FALSE,FALSE,FALSE,On the universality of deep learning,Deep Learning -> Optimization for Deep Networks,Theory -> Statistical Learning Theory,Deep learning,"['Emmanuel Abbe', ' Colin Sandon']","{'MIT', 'Princeton University'}",1,0,0,{'USA'}
Regression with reject option and application to kNN,"Ahmed Zaoui, Christophe Denis, Mohamed Hebiri",Regression with reject option and application to k NN,e8219d4c93f6c55c6b10fe6bfe997c6c,https://proceedings.neurips.cc/paper/2020/file/e8219d4c93f6c55c6b10fe6bfe997c6c-Paper.pdf,"Approaches based on reject option may be helpful at least from two perspectives. First, when human action is limited by time or any other constraint, reject option is an efficient tool to prioritize the human action. On the other hand, in a world where automatic decisions need to be balanced and considered with caution, abstaining from prediction is one way to prevent from damageable decision- making. In particular, human is more likely able to detect anomalies such as bias in data. In a manner of speaking, the use of the reject option compromises between human and machines! Our numerical and theoretical analyses support this idea, in particular because our estimation of the rejection rate is accurate. While the rejection rate has to be fixed according to the considered problem, it appears that the main drawback of our approach is that border instances may be automatically treated while they would have deserved a human consideration. From a general perspective, this is a weakness of all methods based on reject option. This inconvenience is even stronger when the conditional variance function is poorly estimated.",Broader impact,182,9,,,FALSE,FALSE,FALSE,Regression with reject option and application to kNN,Algorithms -> Regression,Theory -> Statistical Learning Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Christophe Denis', ' Mohamed Hebiri', ' Ahmed Zaoui']","{'Universite Paris Est', 'Université Gustave Eiffel'}",1,0,0,{'France'}
The Primal-Dual method for Learning Augmented Algorithms,"Etienne Bamas, Andreas Maggiori, Ola Svensson",The Primal-Dual method for Learning Augmented Algorithms,e834cb114d33f729dbc9c7fb0c6bb607,https://proceedings.neurips.cc/paper/2020/file/e834cb114d33f729dbc9c7fb0c6bb607-Paper.pdf,"The field of learning augmented algorithms lies in the intersection of machine learning and online algorithms, trying to combine the best of the two worlds. Learning augmented algorithms are particularly suited for critical applications where maintaining worst-case guarantees is mandatory but at the same time predictions about the future are possible. Thus, our work represents a stepping stone towards (easily) integrating ML predictions in such applications, increasing this way the possible benefits of ML to society. PDLA offers a recipe on how to incorporate predictions to tackle classical covering online problems, that is to first solve the online problem using the Primal-Dual technique and then use the prediction to change the rate at which primal and dual variables increase or decrease. We believe that since the idea behind this technique is simple and does not require too much domain- specific knowledge, it might be applicable to different problems and can also be implemented in practice.",Broader Impact,155,5,,,FALSE,FALSE,FALSE,The Primal-Dual method for Learning Augmented Algorithms,Optimization -> Discrete Optimization,,Optimization Methods (continuous or discrete),"['Etienne Bamas', ' Andreas Maggiori', ' Ola Svensson']",{'EPFL'},1,0,0,{'Switzerland'}
FLAMBE: Structural Complexity and Representation Learning of Low Rank MDPs,"Alekh Agarwal, Sham Kakade, Akshay Krishnamurthy, Wen Sun",FLAMBE: Structural Complexity and Representation Learning of Low Rank MDPs,e894d787e2fd6c133af47140aa156f00,https://proceedings.neurips.cc/paper/2020/file/e894d787e2fd6c133af47140aa156f00-Paper.pdf,"This paper is theoretical in nature, and so we expect the ethical and societal consequences of our specific results to be minimal. More broadly, we do expect that reinforcement learning will have significant impact on society. There is much potential for benefits to humanity in the often-referenced application domains of precision medicine, personalized education, and elsewhere. There is also much potential for harms, both malicious and unintentional. To this end, we hope that research into the foundations of reinforcement learning can help enable these applications and mitigate harms through the development of algorithms that are efficient, robust, and safe.",Broader impact,99,5,,,FALSE,FALSE,FALSE,FLAMBE: Structural Complexity and Representation Learning of Low Rank MDPs,Theory -> Statistical Learning Theory,Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Alekh Agarwal', ' Sham Kakade', ' Akshay Krishnamurthy', ' Wen Sun']","{'Microsoft', 'University of Washington', 'Microsoft Research', 'Microsoft Research NYC'}",1,1,1,{'USA'}
A Class of Algorithms for General Instrumental Variable Models,"Niki Kilbertus, Matt J. Kusner, Ricardo Silva",A Class of Algorithms for General Instrumental Variable Models,e8b1cbd05f6e6a358a81dee52493dd06,https://proceedings.neurips.cc/paper/2020/file/e8b1cbd05f6e6a358a81dee52493dd06-Paper.pdf,"Cause effect estimation is crucial in many areas where data-driven decisions may be desirable such as healthcare, governance or economics. These settings commonly share the characteristic that experimentation with randomized actions is unethical, infeasible or simply impossible. One of the promises of causal inference is to provide useful insights into the consequences of hypothetical actions based on observational data. However, causal inference is inherently based on assumptions, which are often untestable. Even a slight violation of the assumptions may lead to drastically different conclusions, potentially changing the desired course of action. Especially in high-stakes scenarios, it is thus indispensable to thoroughly challenge these assumptions. This work offers a technique to formalize such a challenge of standard assumptions in continuous IV models. It can thus help inform highly-influential decisions. One important characteristic of our method is that while it can provide informative bounds under certain assumptions on the functional form of effects, the bounds will widen as less prior information supporting such assumptions is available. We can view this as a way of deferring judgment until stricter assumptions have been assessed and verified. Since our algorithms are causal inference methods, they requires assumptions too. Therefore, our method also requires a careful assessment of these assumptions by domain-experts and practitioners. In addition, as we are optimizing a non-convex problem with local methods, we have no theoretical guarantee of correctness of our bounds. Hence, if wrong assumptions for our model are accepted prematurely, or our optimization strategy fails to find global optima, our method may wrongly inform decisions. If these are high-stakes decisions, then wrong decisions can have significant negative consequences (e.g., a decision not to treat a patient that should be treated). If the data that this model is trained on is biased against certain groups (e.g., different sexes, races, genders) this model will replicate those biases. We believe a fruitful approach towards making our model more sensitive to uncertainties due to structurally-biased, unrepresentative data, is to learn how to derive, then inflate (to account for bias) uncertainty estimates for our bounds.",Broader Impact,340,17,,,FALSE,FALSE,FALSE,A Class of Algorithms for General Instrumental Variable Models,Probabilistic Methods -> Causal Inference,,Causality,"['Niki Kilbertus', ' Matt Kusner', ' Ricardo Silva']","{'University College London', 'Helmholtz AI'}",1,1,1,"{'UK', 'Germany'}"
Black-Box Ripper: Copying black-box models using generative evolutionary algorithms,"Antonio Barbalau, Adrian Cosma, Radu Tudor Ionescu, Marius Popescu",Black-Box Ripper: Copying black-box models using generative evolutionary algorithms,e8d66338fab3727e34a9179ed8804f64,https://proceedings.neurips.cc/paper/2020/file/e8d66338fab3727e34a9179ed8804f64-Paper.pdf,"Our work has shown that, in the current state of machine learning, it is possible to obtain state- of-the-art results in model functionality replication without knowledge of the internal structure or parameters of the targeted model. With our work, we wish to raise awareness in the domain of AI security, to expose and better understand the exposure and vulnerabilities of public machine learning APIs. Currently, we were able to replicate functionality in a black-box scenario without having knowledge of the training data, reporting a gap of 3 . 2% between the original model and the replica in one scenario, achieving similar or better results than glass-box approaches. As such, we show that the boundary between glass-box and black-box models is thin and public black-box APIs are as exposed as glass-box models. Our inquiry is that no, or very few models are safe in the current context. We assume that replicas can be analyzed in order to find vulnerabilities in the original model and profit from them. We believe our work represents a solid building block for research in AI security, towards detecting, understanding and preventing any sort of AI vulnerabilities. By exposing techniques such as Black-Box Ripper, we aim to get a head start in designing preventive solutions. Our aim is to stimulate future research in detecting functionality stealing attacks. In the current scenario, for example, the optimization process can be proactively detected based on the API call patterns and stopped. The process can also be impeded by limiting access to prediction confidence scores. Finally, and maybe one of the most important aspects, such model stealing processes can be impeded by designing neural networks that do not focus on textures, but rather on semantics. Our work helps to further push development in this area, which will make deep learning models safer and more robust. Having knowledge of the current work, public APIs can implement such techniques and keep their models in a much safer and desired state, which is the improvement we want to bring to the community. We hope further research on this subject will follow, as we, ourselves, will continue to do so.",6 Broader Impact,355,16,,,FALSE,FALSE,FALSE,Black-Box Ripper: Copying black-box models using generative evolutionary algorithms,Optimization -> Evolutionary Computation,Algorithms; Applications -> Object Recognition; Deep Learning -> Generative Models,Deep learning,"['Antonio Barbalau', ' Adrian Cosma', ' Radu Tudor Ionescu', ' Marius Popescu']","{'University of Bucharest', 'Politehnica University of Bucharest'}",1,0,0,{'Romania'}
Bayesian Optimization of Risk Measures,"Sait Cakmak, Raul Astudillo Marban, Peter Frazier, Enlu Zhou",Bayesian Optimization of Risk Measures,e8f2779682fd11fa2067beffc27a9192,https://proceedings.neurips.cc/paper/2020/file/e8f2779682fd11fa2067beffc27a9192-Paper.pdf,"Our work is of interest whenever one needs to make a decision guided by an expensive simulator, and subject to environmental uncertainties. Such scenarios arise in simulation assisted medical decision making [4], in financial risk management [7, 59, 60], in public policy, and disaster management [61]. The impact of our algorithms could be summarized as facilitating risk averse decision making. In many scenarios, risk averse approaches result in decisions that are more robust to environmental uncertainties compared to decisions resulting from common risk neutral alternatives. For example, in a financial crisis, an earlier risk-averse decision of holding more cash and other low-risk securities might prevent large losses or even the default of a financial institution. As another example, a risk averse decision of stockpiling of excess medical supplies in non-crisis times would alleviate the shortages faces during crisis times, such as the COVID-19 pandemic we are facing today. On the negative side of things, the risk averse decisions we facilitate may not always benefit all stakeholders. For a commercial bank, a risk averse approach may suggest a higher credit score threshold for making loans, which might end up preventing certain groups from access to much needed credit. In our case, the failure of the system would mean a poor optimization of the objective, and recom- mendation of a bad solution. Implementation of a bad decision can have harmful consequences in many settings; however, we imagine that any solution recommended by our algorithms would then be evaluated using the simulator, thus preventing the implementation of said decision. Our methods do not rely on training data, and only require noisy evaluations of the function value. Thus, it can be said that our method does not leverage any bias in any training data. However, the solutions recommended by our algorithms are only good up to the supplied function evaluations, thus are directly affected by any biases built into the simulator used for these evaluations.",Broader Impact,321,13,,,FALSE,FALSE,FALSE,Bayesian Optimization of Risk Measures,Probabilistic Methods -> Bayesian Nonparametrics,Optimization -> Non-Convex Optimization; Probabilistic Methods -> Gaussian Processes,Probabilistic methods and inference,"['Sait Cakmak', ' Raul Astudillo Marban', ' Peter Frazier', ' Enlu Zhou']","{'Cornell / Uber', 'Georgia Institute of Technology', 'Cornell University'}",1,1,1,{'USA'}
TorsionNet: A Reinforcement Learning Approach to Sequential Conformer Search,"Tarun Gogineni, Ziping Xu, Exequiel  Punzalan, Runxuan Jiang, Joshua Kammeraad, Ambuj Tewari, Paul Zimmerman",TorsionNet: A Reinforcement Learning Approach to Sequential Conformer Search,e904831f48e729f9ad8355a894334700,https://proceedings.neurips.cc/paper/2020/file/e904831f48e729f9ad8355a894334700-Paper.pdf,The reported viability of TorsionNet signifies that it can be applied to conformer generation of relevant large flexible molecules in other areas such as chemistry and materials science. The investigation on the non-fossil carbon source lignin helps inform targeted depolymerization strategies to yield valuable products for applications such as renewable energy.,6 Broader Impacts,51,2,FALSE,FALSE,FALSE,FALSE,FALSE,TorsionNet: A Reinforcement Learning Approach to Sequential Conformer Search,Applications,"Algorithms -> Multitask and Transfer Learning; Data, Challenges, Implementations, and Software -> Benchmarks; Data, Challenges, Implementations, and Software -> Virtual Environments; Deep Learning; Reinforcement Learning and Planning -> Exploration; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> Models of Learning and Generalization","Other applications (e.g., robotics, biology, climate, finance)","['Tarun Gogineni', ' Ziping Xu', ' Exequiel Punzalan', ' Runxuan Jiang', ' Joshua Kammeraad', ' Ambuj Tewari', ' Paul Zimmerman']",{'University of Michigan'},1,0,0,{'USA'}
GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis,"Katja Schwarz, Yiyi Liao, Michael Niemeyer, Andreas Geiger",GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis,e92e1b476bb5262d793fd40931e0ed53,https://proceedings.neurips.cc/paper/2020/file/e92e1b476bb5262d793fd40931e0ed53-Paper.pdf,"3D-aware image synthesis is a relatively novel research area [19, 30, 39, 40, 44] and does not yet scale to generating complex real-world scenes, preventing immediate applications for society. However, our work takes an important step towards this goal as it enables high-fidelty reconstruction at resolutions beyond 64 2 pixels while requiring no 3D supervision as input. In the long run, we hope that our resesarch will facilitate the use of 3D-aware generative models in applications such as virtual reality, data augmentation or robotics. For example, intelligent systems such as autonomous vehicles require large amounts of data for training and validation which will be impossible to collect using static offline datasets. We believe that building generative, photo-realistic and large-scale 3D models of our world will ultimately allow for cost-efficient data collection and simulation. While many use-cases are possible, we believe that these types of models can be particularly beneficial to close the existing domain gap between real-world and synthetic data. However, working with generative models also requires care. While generating photorealistic 3D-scenarios is very intriguing it also bears the risk of manipulation and the creation of misleading content. In particular, models that can create 3D-consistent fake images might increase credibility of fake contents and might potentially fool systems that rely on multi-view consistency, e.g., modern face recognition systems. Therefore, we believe that it is of equal importance for the community to develop methods which are able to clearly distinguish between synthetic and real-world content. We see encouraging progress in this area, e.g., [2, 3, 13, 32, 38, 58].",Broader Impact,258,11,,,FALSE,FALSE,FALSE,GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis,Applications -> Computer Vision,Deep Learning -> Adversarial Networks; Deep Learning -> Generative Models,Vision,"['Katja Schwarz', ' Yiyi Liao', ' Michael Niemeyer', ' Andreas Geiger']","{'Max Planck for Intelligent Systems', 'MPI Tuebingen', 'MPI-IS and University of Tuebingen'}",1,0,0,{'Germany'}
PIE-NET: Parametric Inference of Point Cloud Edges,"Xiaogang Wang, Yuelang Xu, Kai Xu, Andrea Tagliasacchi, Bin Zhou, Ali Mahdavi-Amiri, Hao Zhang",PIE-NET: Parametric Inference of Point Cloud Edges,e94550c93cd70fe748e6982b3439ad3b,https://proceedings.neurips.cc/paper/2020/file/e94550c93cd70fe748e6982b3439ad3b-Paper.pdf,"We introduce a methodology that can benefit a range of current and new applications, from 3D data acquisition to object recognition. On the broader societal level, this work remains largely academic in nature, and does not pose foreseeable risks regarding defense, security, and other sensitive fields.",Broader impact,46,2,TRUE,TRUE,FALSE,FALSE,FALSE,PIE-NET: Parametric Inference of Point Cloud Edges,Applications,Applications -> Computer Vision; Applications -> Object Detection,Vision,"['Xiaogang Wang', ' Yuelang Xu', ' Kai Xu', ' Andrea Tagliasacchi', ' Bin Zhou', 'Amiri', ' Hao Zhang']","{'Beihang University', 'State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering,Beihang University', 'Google Research, Brain', 'National University of Defense Technology', 'Simon Fraser University', 'Tsinghua University'}",1,1,1,"{'Canada', 'USA', 'China'}"
A Simple Language Model for Task-Oriented Dialogue,"Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, Richard Socher",A Simple Language Model for Task-Oriented Dialogue,e946209592563be0f01c844ab2170f0c,https://proceedings.neurips.cc/paper/2020/file/e946209592563be0f01c844ab2170f0c-Paper.pdf,"This work may have implications for the simplification of conversational agents. In the narrow sense, this work addresses task-oriented dialogue, but similar results might also hold for open-domain conversational systems. If so, the improvement of these systems and easier deployment would amplify both the positive and negative aspects of conversational AI. Positively, conversational agents might play a role in automating predictable communications, thereby increasing efficiency in areas of society that currently lose time navigating the multitude of APIs, webpages, and telephonic systems that are used to achieve goals. Negatively, putting conversational agents at the forefront might dehumanize communication that can be automated and might lead to frustration where human agents could provide more efficient solutions – for example, when predicted solutions do not apply. These consequences are not specific to this work, but should be considered by the field of conversational AI more broadly.",7 Broader Impact,144,6,,,FALSE,FALSE,FALSE,A Simple Language Model for Task-Oriented Dialogue,Applications -> Dialog- or Communication-Based Learning,Applications -> Natural Language Processing,Natural language processing,"['Ehsan Hosseiniasl', ' Bryan McCann', 'Sheng Wu', ' Semih Yavuz', ' Richard Socher']","{'Salesforce Research', 'Salesforce'}",0,1,0,{'USA'}
A Continuous-Time Mirror Descent Approach to Sparse Phase Retrieval,"Fan Wu, Patrick Rebeschini",A Continuous-Time Mirror Descent Approach to Sparse Phase Retrieval,e9470886ecab9743fb7ea59420c245d2,https://proceedings.neurips.cc/paper/2020/file/e9470886ecab9743fb7ea59420c245d2-Paper.pdf,This work does not present any foreseeable ethical or societal consequences.,Broader impact,11,1,TRUE,FALSE,FALSE,FALSE,FALSE,A Continuous-Time Mirror Descent Approach to Sparse Phase Retrieval,Optimization -> Non-Convex Optimization,Algorithms -> Sparsity and Compressed Sensing; Theory -> Information Theory; Theory -> Statistical Learning Theory,Optimization Methods (continuous or discrete),"['Fan Wu', ' Patrick Rebeschini']",{'University of Oxford'},1,0,0,{'UK'}
Confidence sequences for sampling without replacement,"Ian Waudby-Smith, Aaditya Ramdas",Confidence sequences for sampling without replacement,e96c7de8f6390b1e6c71556e4e0a4959,https://proceedings.neurips.cc/paper/2020/file/e96c7de8f6390b1e6c71556e4e0a4959-Paper.pdf,"The main type of broader impact caused by our work is the reduction of time, money and energy due to the ability to continuously monitor data and hence make critical decisions early. In Appendix A, we provide four prototypical examples of situations where our methods may prove useful. In Exam- ple A, every single phone call requires time to collect the opinions, thus using up money as well, and if we can accurately quantify uncertainty then we can stop collecting data sooner. In Example B, randomization tests such as those involving permutations are a common way to quantify statistical significance, but they are computationally intensive and thus take up a lot of time. Knowing when to stop, based on the test being clearly statistically significant (or clearly far from it), can save on energy costs. In Example D, when an educational intervention is unrolled one school at a time, there are two possibilities again: if it is clearly beneficial, we would like to recognize it quickly so that every student can avail of the benefits, while if it is for some reason harmful (e.g. causing stress without measurable benefit), then it would be equally important to end the program quickly. Once more, accurately quantifying uncertainty as the process unfolds underpins the ability to make these decisions early to disseminate benefits rapidly or mitigate harms quickly. As a side remark, though we have not demonstrated it in this paper, our techniques are also applicable to auditing elections (checking whether the results are as announced by a manual random recount). ‘Risk-limiting audits’ [ 22] constitute a full-fledged application area that we intend to pursue in future work; there are many variants depending on how voters express their preferences (choose one, or rank all, or score all) and the aggregation mechanism used to decide on one or multiple winners. Audits are not currently required by law in many state/county (or federal) elections due to high perceived effort among other reasons, so being able to stop these audits early, yet accurately and confidently, is critical to their broad adoption. In this sense, a longer-term broader impact to trust in elections is anticipated.",Broader impact,358,11,,,FALSE,FALSE,FALSE,Confidence sequences for sampling without replacement,Theory -> Frequentist Statistics,Algorithms -> Uncertainty Estimation,Theory (including computational and statistical analyses),"['Smith', ' Aaditya Ramdas']","{'CMU', 'Carnegie Mellon University'}",1,0,0,{'USA'}
A mean-field analysis of two-player zero-sum games,"Carles Domingo-Enrich, Samy Jelassi, Arthur Mensch, Grant Rotskoff, Joan Bruna",A mean-field analysis of two-player zero-sum games,e97c864e8ac67f7aed5ce53ec28638f5,https://proceedings.neurips.cc/paper/2020/file/e97c864e8ac67f7aed5ce53ec28638f5-Paper.pdf,"We study algorithms designed to find equilibria in games, provide theoretical guarantees of convergence and test their performance empirically. Among other applications, our results give insight into training algorithms for generative adversarial networks (GANs), which are useful for many relevant tasks such as image generation, image-to-image or text-to-image translation and video prediction. As always, we note that machine learning improvements like ours come in the form of “building machines to do X better”. For a sufficiently malicious or ill-informed choice of X, such as surveillance or recidivism prediction, almost any progress in machine learning might indirectly lead to a negative outcome, and our work is not excluded from that.",Broader impact,109,4,,,FALSE,FALSE,FALSE,A mean-field analysis of two-player zero-sum games,Optimization -> Non-Convex Optimization,Deep Learning -> Generative Models; Theory -> Game Theory and Computational Economics,Optimization Methods (continuous or discrete),"['Enrich', ' Samy Jelassi', ' Arthur Mensch', ' Grant Rotskoff', ' Joan Bruna']","{'New York University', 'ENS', 'Princeton University', 'NYU'}",1,0,0,"{'France', 'USA'}"
Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge,"Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, Jonathan Berant",Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge,e992111e4ab9985366e806733383bd8c,https://proceedings.neurips.cc/paper/2020/file/e992111e4ab9985366e806733383bd8c-Paper.pdf,"Our work, if successful, paves a possible path towards models that learn in a one-shot manner by interacting with users. Users of Question Answering and other systems utilizing reasoning over natural language may benefit by constantly improving models that do not require re-training in an interactive manner. However, users teaching false rules and facts may lead to the spread of ungrounded and possibly “fake” information. Thus, the provided rules and facts must be constantly monitored and curated. Finally, users relying on the reasoning of such systems for mission critical tasks, such as medical advice, might be at risk from possible errors. At current level of accuracy of state-of-the-art models, this type of usage is not advised.",Broader Impact,116,6,,,FALSE,FALSE,FALSE,Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge,Applications -> Natural Language Processing,Deep Learning -> Analysis and Understanding of Deep Networks,Natural language processing,,"{'Allen Institute for AI, Tel Aviv University', 'Allen Institute for AI, Bar Ilan University', 'Tel Aviv University', 'Allen Institute for AI'}",1,0,0,"{'USA', 'Israel'}"
Pipeline PSRO: A Scalable Approach for Finding Approximate Nash Equilibria in Large Games,"Stephen Mcaleer, J.B. Lanier, Roy Fox, Pierre Baldi",Pipeline PSRO: A Scalable Approach for Finding Approximate Nash Equilibria in Large Games,e9bcd1b063077573285ae1a41025f5dc,https://proceedings.neurips.cc/paper/2020/file/e9bcd1b063077573285ae1a41025f5dc-Paper.pdf,"Stratego and Barrage Stratego are very large imperfect information board games played by many around the world. Although variants of self-play reinforcement learning have achieved grandmaster level performance on video games, it is unclear if these algorithms could work on Barrage Stratego or Stratego because they are not principled and fail on smaller games. We believe that P2SRO will be able to achieve increasingly good performance on Barrage Stratego and Stratego as more time and compute are added to the algorithm. We are currently training P2SRO on Barrage Stratego and we hope that the research community will also take interest in beating top humans at these games as a challenge and inspiration for artificial intelligence research. This research focuses on how to scale up algorithms for computing approximate Nash equilibria in large games. These methods are very compute-intensive when applied to large games. Naturally, this favors large tech companies or governments with enough resources to apply this method for large, complex domains, including in real-life scenarios such as stock trading and e-commerce. It is hard to predict who might be put at an advantage or disadvantage as a result of this research, and it could be argued that powerful entities would gain by reducing their exploitability. However, the same players already do and will continue to benefit from information and computation gaps by exploiting suboptimal behavior of disadvantaged parties. It is our belief that, in the long run, preventing exploitability and striving as much as practical towards a provably efficient equilibrium can serve to level the field, protect the disadvantaged, and promote equity and fairness.",Broader Impact,265,10,,,FALSE,FALSE,FALSE,Pipeline PSRO: A Scalable Approach for Finding Approximate Nash Equilibria in Large Games,Reinforcement Learning and Planning -> Multi-Agent RL,Reinforcement Learning and Planning; Reinforcement Learning and Planning -> Reinforcement Learning; Theory -> Game Theory and Computational Economics,Reinforcement learning and planning,"['Stephen Mcaleer', ' Lanier', ' Roy Fox', ' Pierre Baldi']","{'UC Irvine', 'University of California Irvine'}",1,0,0,{'USA'}
Improving Sparse Vector Technique with Renyi Differential Privacy,"Yuqing Zhu, Yu-Xiang Wang",Improving Sparse Vector Technique with Renyi Differential Privacy,e9bf14a419d77534105016f5ec122d62,https://proceedings.neurips.cc/paper/2020/file/e9bf14a419d77534105016f5ec122d62-Paper.pdf,"As mentioned in the paper, differential privacy is undergoing an exciting transition from theory to practice and there is an increasing number of deployment of differential private algorithms and systems in both the private and public sectors. The focus of the work is to bring a mature and classical technique in differential privacy — Sparse Vector Technique — to practice by improving the privacy-utility trade-off, and also to conduct numerical studies so as to provide recommendations on which method to use in each regime. This task is strongly tied to the goal of AI/ML for social good and responsible computing. Notice that in practice, the computation of privacy loss or the calibration of noise to privacy budgets is extremely important as these seemingly theoretical calculations will affect the number of data points to collect, and affect the statistical power in sensitive applications such as clinical studies. Moreover, our application to adaptive data analysis is strongly tied to the reproducibility crisis in science and the problems of overfitting common benchmarks that we are currently experiencing in the machine learning community.",Broader impacts,179,5,,,FALSE,FALSE,FALSE,Improving Sparse Vector Technique with Renyi Differential Privacy,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Adaptive Data Analysis,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yuqing Zhu', 'Xiang Wang']","{'University of California Santa Barbara', 'UC Santa Barbara'}",1,0,0,{'USA'}
Latent Template Induction with Gumbel-CRFs,"Yao Fu, Chuanqi Tan, Bin Bi, Mosha Chen, Yansong Feng, Alexander Rush",Latent Template Induction with Gumbel-CRFs,ea119a40c1592979f51819b0bd38d39d,https://proceedings.neurips.cc/paper/2020/file/ea119a40c1592979f51819b0bd38d39d-Paper.pdf,"Generally, this work is about controllable text generation. When applying this work to chatbots, one may get a better generation quality. This could potentially improve the accessibility [8, 53] for people who need a voice assistant to use an electronic device, e.g. people with visual, intellectual, and other disabilities [51, 2]. However, if not properly tuned, this model may generate improper sentences like fake information, putting the user at a disadvantage. Like many other text generation models, if trained with improper data (fake news [21], words of hatred [12]), a model could generate these sentences as well. In fact, one of the motivations for controllable generation is to avoid these situations [63, 12]. But still, researchers and engineers need to be more careful when facing these challenges.",Broader Impact,127,7,,,FALSE,FALSE,FALSE,Latent Template Induction with Gumbel-CRFs,Applications -> Natural Language Processing,Algorithms -> Structured Prediction; Optimization -> Discrete Optimization; Probabilistic Methods -> Latent Variable Models,Natural language processing,"['Yao Fu', ' Chuanqi Tan', ' Bin Bi', ' Mosha Chen', ' Yansong Feng', ' Alexander Rush']","{'Alibaba Group', 'Alibaba DAMO Academy', 'Peking University', 'Columbia University', 'Cornell University'}",1,1,1,"{'USA', 'China'}"
Instance Based Approximations to Profile Maximum Likelihood,"Nima Anari, Moses Charikar, Kirankumar Shiragur, Aaron Sidford",Instance Based Approximations to Profile Maximum Likelihood,ea33b4fd0fc1ea0a40344be8a8641123,https://proceedings.neurips.cc/paper/2020/file/ea33b4fd0fc1ea0a40344be8a8641123-Paper.pdf,"Symmetric property estimation has a broad range of applications, ranging from ecology [Cha84, CL92, BF93, CCG + 12], to physics [VBB + 12], to neuroscience [RWdRvSB99], and beyond [HJWW17, HJM17, AOST14, RVZ17, ZVV + 16, WY16b, RRSS07, WY15, OSW16, VV11b, WY16a, JVHW15, JHW16, VV11a]. By providing new, broadly applicable, computationally efficient tools for obtaining higher accuracy estimates to symmetric properties this work could enable a variety of applications in machine learning and the sciences more broadly. Though the primary contributions of this work are theoretical, the preliminary experimental results show that this work could ultimately lead to obtaining higher quality answers to statistical questions at lower computational cost, with less manual tuning to the particular statistical question of interest. This could ultimately help save time, energy, and the many costs associated with data collection. There are always risks in widespread application of statistical tools, we are unaware of any particular biases or harm from the methods proposed. Further research may be required before the results of this paper can have a broad societal impact.",Broader Impact,174,6,,,FALSE,FALSE,FALSE,Instance Based Approximations to Profile Maximum Likelihood,Theory -> Computational Learning Theory,Theory -> Information Theory; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Nima Anari', ' Moses Charikar', ' Kirankumar Shiragur', ' Aaron Sidford']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Factorizable Graph Convolutional Networks,"Yiding Yang, Zunlei Feng, Mingli Song, Xinchao Wang",Factorizable Graph Convolutional Networks,ea3502c3594588f0e9d5142f99c66627,https://proceedings.neurips.cc/paper/2020/file/ea3502c3594588f0e9d5142f99c66627-Paper.pdf,"In this work we introduce a GCN framework, termed as FactorGCN, that explicitly accounts for disentanglement FactorGCN is applicable to various scenarios, both technical and social. For conven- tional graph-related tasks, like node classification of the social network and graph classification of the molecular graph, our proposed method can serve as a general GCN framework. For disentangling tasks, our method generates factor graphs that reveal the latent relations among entities, and facili- tate the further decision making process like recommendation. Furthermore, given sufficient data, FactorGCN can be used as a tool to analyze social issues like discovering the reasons for the quick spread of the epidemic disease in some areas. Like all learning-based methods, FactorGCN is not free of errors. If the produced disentangled factor graphs are incorrect, for example, the subsequent inference and prediction results will be downgraded, possibly yielding undesirable bias.",Broader Impact,143,6,,,FALSE,FALSE,FALSE,Factorizable Graph Convolutional Networks,Deep Learning,Algorithms -> Multimodal Learning; Algorithms -> Multitask and Transfer Learning; Applications -> Network Analysis; Deep Learning -> Attention Models; Deep Learning -> Efficient Training Methods,Deep learning,"['Yiding Yang', ' Zunlei Feng', ' Mingli Song', ' Xinchao Wang']","{'Stevens Institute of Technology', 'Zhejiang University'}",1,0,0,"{'USA', 'China'}"
Guided Adversarial Attack for Evaluating and Enhancing Adversarial Defenses,"Gaurang Sriramanan, Sravanti Addepalli, Arya Baburaj, Venkatesh Babu R",Guided Adversarial Attack for Evaluating and Enhancing Adversarial Defenses,ea3ed20b6b101a09085ef09c97da1597,https://proceedings.neurips.cc/paper/2020/file/ea3ed20b6b101a09085ef09c97da1597-Paper.pdf,"As Deep Networks see increasing utility in everyday life, it is essential to be cognizant of their worst-case performance and failure modes. Adversarial attacks in particular could have disastrous consequences for safety critical applications such as autonomous navigation, surveillance systems and medical diagnosis. In this paper, we propose a novel adversarial attack method, GAMA, that reliably bounds the worst-case performance of Deep Networks for a relatively small computational budget. We also introduce a complementary adversarial training mechanism, GAT, that produces adversarially robust models while utilising only single-step adversaries that are relatively cheap to generate. Thus, our work has immense potential to have a positive impact on society, by enabling the deployment of adversarially robust Deep Networks that can be trained with minimal computational overhead. During the development phase of systems that use Deep Networks, the GAMA attack can be used to provide reliable worst-case evaluations, helping ensure that systems behave as expected when deployed in real-world settings. On the negative side, a bad-actor could potentially use the proposed attack to compromise Deep Learning systems. However, since the proposed method is a white-box attack, it is applicable only when the entire network architecture and parameters are known to the adversary, which is a relatively rare scenario as model weights are often kept highly confidential in practice.",7 Broader Impact,215,8,,,FALSE,TRUE,FALSE,Guided Adversarial Attack for Evaluating and Enhancing Adversarial Defenses,Deep Learning,Algorithms -> Adversarial Learning,Adversarial Robustness of Deep Networks,"['Gaurang Sriramanan', ' Sravanti Addepalli', ' Arya Baburaj', ' Venkatesh Babu R']","{'Indian institute of science', 'Indian Institute of Science', 'Indian Institute of Science, Bangalore'}",1,0,0,{'India'}
A Study on Encodings for Neural Architecture Search,"Colin White, Willie Neiswanger, Sam Nolen, Yash Savani",A Study on Encodings for Neural Architecture Search,ea4eb49329550caaa1d2044105223721,https://proceedings.neurips.cc/paper/2020/file/ea4eb49329550caaa1d2044105223721-Paper.pdf,"Our work gives a study on encodings for neural architecture search, with the goal of helping future researchers improve their NAS algorithms. Therefore, this work may not have a direct impact on society, since it is two levels of abstraction from real applications, but it can indirectly impact society. As an example, our work may inspire the creation of a new state-of-the-art NAS algorithm, which is then used to improve the performance of various deep learning algorithms, which can have both beneficial and detrimental uses (e.g. optimizers that reduce CO 2 emissions, or deep fake generators). Due to the recent push for the AI community to be more conscious and prescient about the societal impact of its work [3], we are hoping that future AI models, including ones influenced by our work, will have a positive impact on society.",6 Broader Impact,139,4,,,FALSE,FALSE,FALSE,A Study on Encodings for Neural Architecture Search,Algorithms -> AutoML,,AutoML,"['Colin White', ' Willie Neiswanger', ' Sam Nolen', ' Yash Savani']",{'Carnegie Mellon University'},1,0,0,{'USA'}
Noise2Same: Optimizing A Self-Supervised Bound for Image Denoising,"Yaochen Xie, Zhengyang Wang, Shuiwang Ji",Noise2Same: Optimizing A Self-Supervised Bound for Image Denoising,ea6b2efbdd4255a9f1b3bbc6399b58f4,https://proceedings.neurips.cc/paper/2020/file/ea6b2efbdd4255a9f1b3bbc6399b58f4-Paper.pdf,"In this paper, we introduce Noise2Same, a self-supervised framework for deep image denoising. As Noise2Same does not need paired clean data, paired noisy data, nor the noise model, its application scenarios could be much broader than both traditional supervised and existing self-supervised denoising frameworks. The most direct application of Noise2Same is to perform denoising on digital images captured under poor conditions. Individuals and corporations related to photography may benefit from our work. Besides, Noise2Same could be applied as a pre-processing step for computer vision tasks such as object detection and segmentation [ 18], making the downstream algorithms more robust to noisy images. Also, specific research communities could benefit from the development of Noise2Same as well. For example, the capture of high-quality microscopy data of live cells, tissue, or nanomaterials is expensive in terms of budget and time [27]. Proper denoising algorithms allow researchers to obtain high-quality data from low-quality data and hence remove the need to capture high-quality data directly. In addition to image denoising applications, the self-supervised denoising framework could be extended to other domains such as audio noise reduction and single-cell [1]. On the negative aspect, as many imaging-based research tasks and computer vision applications may be built upon the denoising algorithms, the failure of Noise2Same could potentially lead to biases or failures in these tasks and applications.",Broader Impact,220,10,,,FALSE,FALSE,FALSE,Noise2Same: Optimizing A Self-Supervised Bound for Image Denoising,Applications -> Denoising,Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yaochen Xie', ' Zhengyang Wang', ' Shuiwang Ji']",{'Texas A&M University'},1,0,0,{'USA'}
Early-Learning Regularization Prevents Memorization of Noisy Labels,"Sheng Liu, Jonathan Niles-Weed, Narges Razavian, Carlos Fernandez-Granda",Early-Learning Regularization Prevents Memorization of Noisy Labels,ea89621bee7c88b2c5be6681c8ef4906,https://proceedings.neurips.cc/paper/2020/file/ea89621bee7c88b2c5be6681c8ef4906-Paper.pdf,"This work has the potential to advance the development of machine-learning methods that can be deployed in contexts where it is costly to gather accurate annotations. This is an important issue in applications such as medicine, where machine learning has great potential societal impact.",8 Broader Impact,44,2,FALSE,FALSE,FALSE,FALSE,FALSE,Early-Learning Regularization Prevents Memorization of Noisy Labels,Algorithms -> Classification,Algorithms -> Semi-Supervised Learning; Applications -> Computer Vision; Deep Learning -> Supervised Deep Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Sheng Liu', 'Weed', ' Narges Razavian', 'Granda']","{'New York University School of Medicine', 'NYU'}",1,0,0,{'USA'}
LAPAR: Linearly-Assembled Pixel-Adaptive Regression Network for Single Image Super-resolution and Beyond,"Wenbo Li, Kun Zhou, Lu Qi, Nianjuan Jiang, Jiangbo Lu, Jiaya Jia",LAPAR: Linearly-Assembled Pixel-Adaptive Regression Network for Single Image Super-Resolution and Beyond,eaae339c4d89fc102edd9dbdb6a28915,https://proceedings.neurips.cc/paper/2020/file/eaae339c4d89fc102edd9dbdb6a28915-Paper.pdf,"This paper aims to promote academic development. In the past decades, image super-resolution, denoising and deblocking techniques have marked new milestones and also been widely used in industry. As far as we know, they have no negative impact on the ethical and societal aspects.",Broader Impact,44,3,TRUE,TRUE,FALSE,FALSE,FALSE,LAPAR: Linearly-Assembled Pixel-Adaptive Regression Network for Single Image Super-resolution and Beyond,Applications -> Computer Vision,Algorithms -> Regression; Applications -> Denoising; Deep Learning -> Efficient Inference Methods; Deep Learning -> Supervised Deep Networks,Vision,"['Wenbo Li', ' Kun Zhou', ' Lu Qi', ' Nianjuan Jiang', ' Jiangbo Lu', ' Jiaya Jia']","{'The Chinese University of Hong Kong', 'CUHK', 'Chinese University of Hong Kong'}",1,0,0,{'China'}
Learning Parities with Neural Networks,"Amit Daniely, Eran Malach",Learning Parities with Neural Networks,eaae5e04a259d09af85c108fe4d7dd0c,https://proceedings.neurips.cc/paper/2020/file/eaae5e04a259d09af85c108fe4d7dd0c-Paper.pdf,"As the primary focus of this paper is on theoretical results and theoretical analysis, a Broader Impact discussion is not applicable.",Broader Impact,21,1,TRUE,FALSE,FALSE,FALSE,FALSE,Learning Parities with Neural Networks,Theory -> Computational Learning Theory,Theory -> Hardness of Learning and Approximations; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Eran Malach', ' Amit Daniely']","{'Hebrew University and Google Research', 'Hebrew University Jerusalem Israel'}",1,0,0,{'Israel'}
Consistent Plug-in Classifiers for Complex Objectives and Constraints,"Shiv Kumar Tavker, Harish Guruprasad Ramaswamy, Harikrishna Narasimhan",Consistent Plug-in Classifiers for Complex Objectives and Constraints,eab1bceaa6c5823d7ed86cfc7a8bd824,https://proceedings.neurips.cc/paper/2020/file/eab1bceaa6c5823d7ed86cfc7a8bd824-Paper.pdf,"There’s an increasing impetus in the machine learning community to design algorithms that are fair and free from bias and inequity. Most existing approaches for enforcing group-based fairness goals have been limited to simple objectives and constraints. In this paper, we allow a user to specify for more nuanced definitions of utilities and fairness goals than allowed by standard methods in the literature, and provide an algorithm to directly and efficiently optimize for these goals. We show theoretically that our algorithm is able to achieve a desired trade-off between overall utility and the specified fairness criteria. As with prior work on group-based fairness (and more generally with constrained supervised learning), a drawback of our approach is that while we guarantee that the fairness criterion is likely to be satisfied on new examples, there is a small probability that it isn’t, and these rare failures can have an adverse impact in practice. Moreover, our algorithm requires the use of stochastic classifiers, which may bring in additional ethical considerations. See Cotter et al. [8] for a discussion on the practical ramifications of deploying a stochastic classifier, and for ways to convert a stochastic classifier into a similar performing deterministic classifier. All experiments in this paper were carried out with publicly available datasets.",Broader Impact,210,9,,,FALSE,FALSE,FALSE,Consistent Plug-in Classifiers for Complex Objectives and Constraints,Theory -> Statistical Learning Theory,"Algorithms -> Classification; Optimization -> Convex Optimization; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Shiv Kumar Tavker', ' Harish Guruprasad Ramaswamy', ' Harikrishna Narasimhan']","{'IIT Madras', 'Google Research'}",1,1,1,"{'India', 'USA'}"
Movement Pruning: Adaptive Sparsity by Fine-Tuning,"Victor Sanh, Thomas Wolf, Alexander Rush",Movement Pruning: Adaptive Sparsity by Fine-Tuning,eae15aabaa768ae4a5993a8a4f4fa6e4,https://proceedings.neurips.cc/paper/2020/file/eae15aabaa768ae4a5993a8a4f4fa6e4-Paper.pdf,"This work is part of a broader line of research on reducing the memory size of state-of-the-art models in Natural Language Processing (and more generally in Artificial Intelligence). This line of research has potential positive impact in society from a privacy and security perspective: being able to store and run state-of-the-art NLP capabilities on devices (such as smartphones) would erase the need to send API calls (with potentially private data) to a remote server. It is particularly important since there is a rising concern about the potential negative uses of centralized personal data. Moreover, this is complementary to hardware manufacturers’ efforts to build chips that will considerably speedup inference for sparse networks while reducing the energy consumption of such networks. From an accessibility standpoint, this line of research has the potential to give access to extremely large models [Raffel et al., 2019, Brown et al., 2020] to the broader community, and not only big labs with large clusters. Extremely compressed models with comparable performance enable smaller teams or individual researchers to experiment with large models on a single GPU. For instance, it would enable the broader community to engage in analyzing a model’s biases such as gender bias [Lu et al., 2018, Vig et al., 2020], or a model’s lack of robustness to adversarial attacks [Wallace et al., 2019]. More in-depth studies are necessary in these areas to fully understand the risks associated to a model and create robust ways to mitigate them before massively deploying these capabilities.",9 Broader Impact,248,8,,,FALSE,FALSE,FALSE,Movement Pruning: Adaptive Sparsity by Fine-Tuning,Applications -> Natural Language Processing,Algorithms -> Sparsity and Compressed Sensing; Deep Learning -> Attention Models; Deep Learning -> Efficient Inference Methods,Resource aware machine learning,"['Victor Sanh', ' Thomas Wolf', ' Alexander Rush']","{'Cornell University', 'Hugging Face'}",1,0,0,{'USA'}
Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot,"Jingtong Su, Yihang Chen, Tianle Cai, Tianhao Wu, Ruiqi Gao, Liwei Wang, Jason D. Lee",Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot,eae27d77ca20db309e056e3d2dcd7d69,https://proceedings.neurips.cc/paper/2020/file/eae27d77ca20db309e056e3d2dcd7d69-Paper.pdf,"We investigate into neural network pruning methods, which is an important way to reduce computational resource required in modern deep learning. It can potentially help enable faster inference, conserve less energy, and make AI widely deployable and assessable in mobile and embedded systems. Our experiments can also provide more insight for neural networks in deep learning algorithms, which could potentially lead to the development of better deep learning algorithms.",Broader Impact,69,3,,,FALSE,FALSE,FALSE,Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,Deep learning,"['Jingtong Su', ' Yihang Chen', ' Tianle Cai', ' Tianhao Wu', ' Ruiqi Gao', ' Liwei Wang', ' Jason Lee']","{'Princeton University', 'Peking University'}",1,0,0,"{'USA', 'China'}"
Online Matrix Completion with Side Information,"Mark Herbster, Stephen Pasteris, Lisa Tse",Online Matrix Completion with Side Information,eb06b9db06012a7a4179b8f3cb5384d3,https://proceedings.neurips.cc/paper/2020/file/eb06b9db06012a7a4179b8f3cb5384d3-Paper.pdf,"In general this work does not present any foreseeable specific societal consequence in the authors’ joint opinion. This is foundational research in regret-bounded online learning. As such it is not targeted towards any particular application area. Although this research may have societal impact for good or for ill in the future, we cannot foresee the shape and the extent.",Broader Impact,59,4,TRUE,FALSE,TRUE,TRUE,FALSE,Online Matrix Completion with Side Information,Algorithms -> Online Learning,,Theory (including computational and statistical analyses),"['Mark Herbster', ' Stephen Pasteris', ' Fai Yu Lisa Tse']",{'University College London'},1,0,0,{'UK'}
Position-based Scaled Gradient for Model Quantization and Pruning,"Jangho Kim, KiYoon Yoo, Nojun Kwak",Position-based Scaled Gradient for Model Quantization and Pruning,eb1e78328c46506b46a4ac4a1e378b91,https://proceedings.neurips.cc/paper/2020/file/eb1e78328c46506b46a4ac4a1e378b91-Paper.pdf,"PSG is a fundamental method of scaling each gradient component differently depending on the position of a weight vector. This technique can replace conventional gradient in any applications that require different treatment of specific locations in the parameter space. As shown in the paper, the easiest conceivable applications would be quantization and pruning where a definite preference for specific weight forms exists. These model compression techinques are at the heart of the fast and lightweight deployment of any deep learning algorithms and thus, PSG can make a huge impact in the related industry. As another potentially related research topic, PSG has a chance to be utilized in the optimization area such as the integer programming and the combinatorial optimization acting as a tool in optimizing a continuous surrogate of an objective function in a discrete space.",Broader Impact,136,5,,,FALSE,FALSE,FALSE,Position-based Scaled Gradient for Model Quantization and Pruning,Deep Learning -> Efficient Training Methods,Deep Learning -> Efficient Inference Methods; Deep Learning -> Embedding Approaches; Deep Learning -> Optimization for Deep Networks; Optimization -> Stochastic Optimization; Theory -> Regularization,Deep learning,,{'Seoul National University'},1,0,0,{'South Korea'}
Online Learning with Primary and Secondary Losses,"Avrim Blum, Han Shao",Online Learning with Primary and Secondary Losses,eb2e9dffe58d635b7d72e99c8e61b5f2,https://proceedings.neurips.cc/paper/2020/file/eb2e9dffe58d635b7d72e99c8e61b5f2-Paper.pdf,"This research studies a society-constrained online decision making problem, where we take the decision receiver’s objective into consideration. Therefore, in a decision making process (e.g. deciding whether to hire a job applicant, whether to approve a loan, or whether to admit a student to an honors class), the decision receiver (e.g., job applicants, loan applicants, students) could benefit from our study at the cost of increasing the loss of the decision maker (e.g., recruiters, banks, universities) a little. The consequences of failure of the system and biases in the data are not applicable.",Broader Impact,93,3,FALSE,FALSE,FALSE,FALSE,FALSE,Online Learning with Primary and Secondary Losses,Algorithms -> Online Learning,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Theory (including computational and statistical analyses),"['Avrim Blum', ' Han Shao']",{'Toyota Technological Institute at Chicago'},1,0,0,{'USA'}
Graph Information Bottleneck,"Tailin Wu, Hongyu Ren, Pan Li, Jure Leskovec",Graph Information Bottleneck,ebc2aa04e75e3caabda543a1317160c0,https://proceedings.neurips.cc/paper/2020/file/ebc2aa04e75e3caabda543a1317160c0-Paper.pdf,"Who may benefit from this research: Graphs have been used to represent a vast amount of real- world data from social science [ 44], biology [45], geographical mapping [46], finances [47] and recommender systems [48], because of their flexibility in modeling both the relation among the data (structures) and the content of the data (features). Graph neural networks (GNN), naturally entangle both aspects of the data in the most expressive way, have attracted unprecedented attention from both academia and industry across a wide range of disciplines. However, GNNs share a common issue with other techniques based on neural networks. They are very sensitive to noise of data and are fragile to model attacks. This drawback yields the potential safety problems to deploy GNNs in the practical systems or use them to process data in those disciplines that heavily emphasize unbiased analysis. The Graph Information Bottleneck (GIB) principle proposed in this work paves a principled way to alleviate the above problem by increasing the robustness of GNN models. Our work further releases the worries about the usage of GNN techniques in practical systems, such as recommender systems, social media, or to analyze data for other disciplines, including physics, biology, social science. Ultimately, our work increases the interaction between AI, machine learning techniques and other aspects of our society, and could achieve far-reaching impact. Who may be put at disadvantage from this research: Not applicable. What are the consequences of failure of the system: Not applicable. Does the task/method leverage biases in the data: The proposed GIB principle and the GIB-GAT model as an instantiation of GIB leverage the node features and structural information which in general are not believed to include undesirable biases. The datasets to evaluate our approaches are among the most widely-used benchmarks, which in general are not believed to include undesirable biases as well.",Broader Impact,306,12,FALSE,FALSE,FALSE,FALSE,FALSE,Graph Information Bottleneck,Algorithms -> Relational Learning,Algorithms -> Representation Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Tailin Wu', ' Hongyu Ren', ' Pan Li', ' Jure Leskovec']","{'Stanford', 'Stanford University', 'Stanford University - Purdue University', 'Stanford University and Pinterest'}",1,0,0,{'USA'}
The Complexity of Adversarially Robust Proper Learning of Halfspaces with Agnostic Noise,"Ilias Diakonikolas, Daniel M. Kane, Pasin Manurangsi",The Complexity of Adversarially Robust Proper Learning of Halfspaces with Agnostic Noise,ebd64e2bf193fc8c658af2b91952ce8d,https://proceedings.neurips.cc/paper/2020/file/ebd64e2bf193fc8c658af2b91952ce8d-Paper.pdf,"Our work aims to advance the algorithmic foundations of adversarially robust machine learning. This subfield focuses on protecting machine learning models (especially their predictions) against small perturbations of the input data. This broad goal is a pressing challenge in many real-world scenarios, where successful adversarial example attacks can have far-reaching implications given the adoption of machine learning in a wide variety of applications, from self-driving cars to banking. Since the primary focus of our work is theoretical and addresses a simple concept class, we do not expect our results to have immediate societal impact. Nonetheless, we believe that our findings provide interesting insights on the algorithmic possibilities and fundamental computational limitations of adversarially robust learning. We hope that, in the future, these insights could be useful in the design of practically relevant adversarially robust classifiers in the presence of noisy data.",Broader Impact,141,6,,,FALSE,FALSE,FALSE,The Complexity of Adversarially Robust Proper Learning of Halfspaces with Agnostic Noise,Theory -> Computational Learning Theory,Theory -> Hardness of Learning and Approximations,,"['Ilias Diakonikolas', ' Kane', ' Pasin Manurangsi']","{'Google', 'UW Madison', 'UCSD'}",1,1,1,{'USA'}
Adaptive Online Estimation of Piecewise Polynomial Trends,"Dheeraj Baby, Yu-Xiang Wang",Adaptive Online Estimation of Piecewise Polynomial Trends,ebd6d2f5d60ff9afaeda1a81fc53e2d0,https://proceedings.neurips.cc/paper/2020/file/ebd6d2f5d60ff9afaeda1a81fc53e2d0-Paper.pdf,"1. Who may benefit from the research? This work can be applied to the task of estimating trends in time series forecasting. For example, financial firms can use it to do stock market predictions, distribution sector can use it do inventory planning, meterological observatories can use it for weather forecast and health and planning sector can forecast the spread of contagious diseases etc. 2. Who may be put at disadvantage? Not applicable 3. What are the consequences of failure of the system? There is no system to speak off, but failure of the strategy can lead to financial losses for the firms deploying the strategy to do forecasting. Under the assumptions stated in the paper though, the technical results are formally proven and come with the stated mathematical guarantee. 4. Method leverages the biases in data? Not applicable.",Broader Impact,138,11,FALSE,FALSE,FALSE,FALSE,FALSE,Adaptive Online Estimation of Piecewise Polynomial Trends,Optimization -> Stochastic Optimization,Algorithms -> Online Learning; Algorithms -> Regression,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Dheeraj Baby', 'Xiang Wang']",{'UC Santa Barbara'},1,0,0,{'USA'}
RNNPool: Efficient Non-linear Pooling for RAM Constrained Inference,"Oindrila Saha, Aditya Kusupati, Harsha Vardhan Simhadri, Manik Varma, Prateek Jain",RNNPool : Efficient Non-linear Pooling for RAM Constrained Inference,ebd9629fc3ae5e9f6611e2ee05a31cef,https://proceedings.neurips.cc/paper/2020/file/ebd9629fc3ae5e9f6611e2ee05a31cef-Paper.pdf,"Pros: ML models are compute-intensive and are typically served on power-intensive cloud hardware with a large resource footprint that adds to the global energy footprint. Our models can help reduce this footprint by (a) allowing low power edge sensors with small memory to analyze images and admit only interesting images for cloud inference, and (b) reducing the inference complexity of the cloud models themselves. Further, edge-first inference enabled by our work can reduce reliance on networks and also help provide privacy guarantees to end-user. Furthermore, vision models on tiny edge devices enables accessible technologies, e.g., Seeing AI [33] for people with visual impairment. Cons: While our intentions are to enable socially valuable use cases, this technology can enable cheap, low-latency and low-power tracking systems that could enable intrusive surveillance by malicious actors. Similarly, abuse of technology in certain wearables is also possible. Again, we emphasize that it depends on the user to see the adaptation to either of these scenarios.",Broader Impact,160,7,,,FALSE,FALSE,FALSE,RNNPool: Efficient Non-linear Pooling for RAM Constrained Inference,Deep Learning -> Efficient Inference Methods,Applications -> Computer Vision; Deep Learning -> Recurrent Networks,Resource aware machine learning,"['Oindrila Saha', ' Venkata Aditya Kusupati', ' Harsha Vardhan Simhadri', ' Manik Varma', ' Prateek Jain']","{'University of Washington', 'Microsoft Research', 'Microsoft Research India'}",1,1,1,"{'India', 'USA'}"
Agnostic Learning with Multiple Objectives,"Corinna Cortes, Mehryar Mohri, Javier Gonzalvo, Dmitry Storcheus",Agnostic Learning with Multiple Objectives,ebea2325dc670423afe9a1f4d9d1aef5,https://proceedings.neurips.cc/paper/2020/file/ebea2325dc670423afe9a1f4d9d1aef5-Paper.pdf,"This paper presents a novel approach for learning with multiple losses. The algorithm is robust in the sense that it optimizes for the most adversarial mixture of the included losses. It furthermore demonstrates good performance on losses not included in the optimization. This is an important problem from a fairness perspective, where multiple losses are often at play and different interest groups may disagree on what loss to optimize for. An illustrative example is the analysis of the COMPAS tool for predicting recidivism by Angwin et al. [2019] demonstrating how different interest groups would have wanted to optimize for different losses. Not all losses can be optimized for simultaneously, as proven by Kleinberg et al. [2017], but to the extent that this is possible, our algorithm provides a step in the direction of guarding against the most unfavorable condition.",Broader Impact,139,8,,,FALSE,FALSE,FALSE,Agnostic Learning with Multiple Objectives,Algorithms -> AutoML,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Corinna Cortes', ' Mehryar Mohri', ' Javier Gonzalvo', ' Dmitry Storcheus']","{'Google', 'Google Research'}",0,1,0,{'USA'}
3D Multi-bodies: Fitting Sets of Plausible 3D Human Models to Ambiguous Image Data,"Benjamin Biggs, David Novotny, Sebastien Ehrhardt, Hanbyul Joo, Ben Graham, Andrea Vedaldi",3D Multi-bodies: Fitting Sets of Plausible 3D Human Models to Ambiguous Image Data,ebf99bb5df6533b6dd9180a59034698d,https://proceedings.neurips.cc/paper/2020/file/ebf99bb5df6533b6dd9180a59034698d-Paper.pdf,"Our method improves the ability of machines to understand human body poses in images and videos. Understanding people automatically may arguably be misused by bad actors. However, importantly, our method is not a form of biometric as it does not allow the identification of people. Rather, only their overall body shape and pose is reconstructed, but these details are insufficient for unique identification. In particular, individual facial features are not reconstructed at all. Furthermore, our method is an improvement of existing capabilities, but does not introduce a rad- ical new capability in machine learning. Thus our contribution is unlikely to facilitate misuse of technology which is already available to anyone. Finally, any potential negative use of a technology should be balanced against positive uses. Un- derstanding body poses has many legitimate applications in VR and AR, medical, assistance to the elderly, assistance to the visual impaired, autonomous driving, human-machine interactions, image and video categorization, platform integrity, etc.",Broader impact,157,9,,,FALSE,FALSE,FALSE,3D Multi-bodies: Fitting Sets of Plausible 3D Human Models to Ambiguous Image Data,Applications -> Computer Vision,,Vision,"['Benjamin Biggs', ' David Novotny', ' Sebastien Ehrhardt', ' Hanbyul Joo', ' Ben Graham', ' Andrea Vedaldi']","{'Facebook Research', 'University of Oxford / Facebook AI Research', 'Facebook AI Research', 'University of Cambridge', 'FAIR', 'University of Oxford'}",1,1,1,"{'UK', 'USA'}"
Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation,"Yangxin Wu, Gengwei Zhang, Hang Xu, Xiaodan Liang, Liang Lin",Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation,ec1f764517b7ffb52057af6df18142b7,https://proceedings.neurips.cc/paper/2020/file/ec1f764517b7ffb52057af6df18142b7-Paper.pdf,"This work makes the first attempt to search for all key components of panoptic pipeline and manages to accomplish this via the proposed Cooperative Multi-Component Architecture Search and efficient Path-Priority Search Policy. Most related work in the literature of NAS for fine-grained vision tasks concentrates on searching a specific part of the network and the balance of the overall network is largely ignored. Nevertheless, this type of technology is essential to improve the upper bound of popular detectors and segmentation networks. This may inspire new work towards the efficient search of the overall architecture for fine-grained vision tasks, e.g., object detection, semantic segmentation, panoptic segmentation and so on. We are not aware of any imminent risks of placing anyone at a disadvantage. In the future, more constraints and optimization algorithms can be applied to strike the optimal trade-off between accuracy and latency to deliver customized architecture for different platforms and devices.",Broader Impacts,151,6,,,FALSE,FALSE,FALSE,Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation,Applications -> Image Segmentation,Applications -> Computer Vision,Vision,"['Yangxin Wu', ' Gengwei Zhang', ' Hang Xu', ' Xiaodan Liang', ' Liang Lin']","{'Sun Yat-Sen University', 'Sun Yat-sen University'}",1,0,0,{'China'}
Differentiable Top-k with Optimal Transport,"Yujia Xie, Hanjun Dai, Minshuo Chen, Bo Dai, Tuo Zhao, Hongyuan Zha, Wei Wei, Tomas Pfister",Differentiable Top- k with Optimal Transport,ec24a54d62ce57ba93a531b460fa8d18,https://proceedings.neurips.cc/paper/2020/file/ec24a54d62ce57ba93a531b460fa8d18-Paper.pdf,"This paper makes a significant contribution to extending the frontier of the end-to-end training of compositional models. To the best of our knowledge, our method is the first work targeting at efficient end-to-end training with top- k operation. We remark that our proposed SOFT top- k operator can be integrated into many existing machine learning methods, and has a great potential to become a standard routine in various applications such as computer vision, natural language processing, healthcare, and computational social science.",8 Broader Impact,81,3,,,FALSE,TRUE,FALSE,Differentiable Top-k with Optimal Transport,Deep Learning -> Supervised Deep Networks,Algorithms -> Metric Learning; Applications -> Natural Language Processing,Deep learning,"['Yujia Xie', ' Hanjun Dai', ' Minshuo Chen', ' Bo Dai', ' Tuo Zhao', ' Hongyuan Zha', ' Wei Wei', ' Tomas Pfister']","{'Google Brain', 'Google', 'Georgia Tech', 'Georgia Institute of Technology', 'Gatech'}",1,1,1,{'USA'}
Information-theoretic Task Selection for Meta-Reinforcement Learning,"Ricardo Luna Gutierrez, Matteo Leonetti",Information-theoretic Task Selection for Meta-Reinforcement Learning,ec3183a7f107d1b8dbb90cb3c01ea7d5,https://proceedings.neurips.cc/paper/2020/file/ec3183a7f107d1b8dbb90cb3c01ea7d5-Paper.pdf,"This work is tied to current meta-RL algorithms, and thus its social impact is directly related to meta-RL itself. In meta-RL, the final goal is to train general agents that can perform in many different tasks with low adaptation time required. Recent work has shown that this goal is still a long way away [33], but progress in the field could have an important presence in real-world tasks in the near future. Increasingly general agents could lead to an acceleration in the deployment and training of smart systems, saving time and energy, and assisting human decision makers and workers in an evergrowing gamut of tasks. General considerations on desirable safety of AI systems apply to meta-RL as well.",7 Broader Impact,118,5,,,FALSE,FALSE,FALSE,Information-theoretic Task Selection for Meta-Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Algorithms -> Meta-Learning,Reinforcement learning and planning,"['Ricardo Luna Gutierrez', ' Matteo Leonetti']",{'University of Leeds'},1,0,0,{'UK'}
A Limitation of the PAC-Bayes Framework,"Roi Livni, Shay Moran",A Limitation of the PAC-Bayes Framework,ec79d4bed810ed64267d169b0d37373e,https://proceedings.neurips.cc/paper/2020/file/ec79d4bed810ed64267d169b0d37373e-Paper.pdf,There are no foreseen ethical or societal consequences for the research presented herein.,Broader Impact,13,1,TRUE,FALSE,FALSE,FALSE,FALSE,A Limitation of the PAC-Bayes Framework,Theory -> Statistical Learning Theory,Algorithms -> Classification; Theory -> Information Theory; Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Roi Livni', ' Shay Moran']","{'Google AI Princeton', 'Tel Aviv University'}",1,1,1,"{'USA', 'Israel'}"
On Completeness-aware Concept-Based Explanations in Deep Neural Networks,"Chih-Kuan Yeh, Been Kim, Sercan Arik, Chun-Liang Li, Tomas Pfister, Pradeep Ravikumar",On Completeness-aware Concept-Based Explanations in Deep Neural Networks,ecb287ff763c169694f682af52c1f309,https://proceedings.neurips.cc/paper/2020/file/ecb287ff763c169694f682af52c1f309-Paper.pdf,"Bringing explainability can be crucial for AI deployments, for decision makers to build trust, for users to understand decisions, and for model developers to improve the quality. There are many use cases, from Finance, Healthcare, Employment/Recruiting, Retail, Environmental Sciences etc., that the explainability indeed constitutes the bottleneck to use deep neural networks (DNNs) despite their high performance. Thus, bringing explainability to DNNs can open many horizons for new AI deployments. There are different forms of explainability, and our contributions are specifically for the very important ‘concept-based’ explanations, towards a coherent and complete transparency to DNNs. Our paper contributes to the quantification of the “completeness” of concept explanations, which can be useful to evaluate how sufficient existing and future concept-based explanations are, on the task of explaining a neural network. Validating the how sufficient the explanations are in explaining the model is a necessary sanity check, but often overlooked for concept explanations. As the field of explainable AI progresses rapidly, critiques and doubts on whether explanations are actually useful and accountable for models have also increased. Our objective metric bridges the gap between existing explanations and model accountability. Most post-hoc concept-based explanations are applied only on image data. Our method is data type agnostic. We demonstrate our canonical idea on both image and language data, which we believe can be applied to other data types as well. We believe our work lays a groundwork on general concept-based explanations, and hopefully will encourage future works on exploring concept explanations on all kinds of data types. Our concept discovery method explain a model using a small number of concepts, which can be explained by providing nearest neighbors in the training data to help users understand the concepts better. Such explanations provide a broader understanding of the model compared to the widely-used methods, such as saliency maps, and can be helpful for model developers and data scientists in understanding how the model works, improving the model based on insights, and ultimately learning from AI systems to build better AI systems.",7 Broader Impact,336,14,,,FALSE,FALSE,FALSE,On Completeness-aware Concept-Based Explanations in Deep Neural Networks,"Deep Learning -> Visualization, Interpretability, and Explainability","Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Kuan Yeh', ' Been Kim', ' Sercan Arik', 'Liang Li', ' Tomas Pfister', ' Pradeep Ravikumar']","{'Google', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Stochastic Recursive Gradient Descent Ascent for Stochastic Nonconvex-Strongly-Concave Minimax Problems,"Luo Luo, Haishan Ye, Zhichao Huang, Tong Zhang",Stochastic Recursive Gradient Descent Ascent for Stochastic Nonconvex-Strongly-Concave Minimax Problems,ecb47fbb07a752413640f82a945530f8,https://proceedings.neurips.cc/paper/2020/file/ecb47fbb07a752413640f82a945530f8-Paper.pdf,This paper studied the theory of stochastic minimax optimization. The proposed method SREDA is the first stochastic algorithm which attains the optimal dependency on ε . This observation help us to understand the minimax optimization without convex-concave assumption. It is interesting to apply SREDA to more machine learning applications in future.,Broader Impact,51,4,FALSE,FALSE,FALSE,FALSE,FALSE,Stochastic Recursive Gradient Descent Ascent for Stochastic Nonconvex-Strongly-Concave Minimax Problems,Theory,Optimization -> Stochastic Optimization; Theory -> Computational Learning Theory; Theory -> Statistical Learning Theory,Optimization Methods (continuous or discrete),"['Luo Luo', ' Haishan Ye', ' Zhichao Huang', ' Tong Zhang']","{'The Chinese University of Hong Kong, Shenzen', 'HKUST', 'Tencent AI Lab', 'The Hong Kong University of Science and Technology'}",1,1,1,"{'Chile', 'China'}"
Why Normalizing Flows Fail to Detect Out-of-Distribution Data,"Polina Kirichenko, Pavel Izmailov, Andrew G. Wilson",Why Normalizing Flows Fail to Detect Out-of-Distribution Data,ecb9fe2fbb99c31f567e9823e884dbec,https://proceedings.neurips.cc/paper/2020/file/ecb9fe2fbb99c31f567e9823e884dbec-Paper.pdf,"Out-of-distribution detection is crucial for robust, reliable and fair machine learning systems. Mitchell et al. [27] and Gebru et al. [13] argue that applying machine learning models outside of the context where they were trained and tested can lead to dangerous and discriminatory outcomes in high-stake domains. We hope that our work will generally contribute to the understanding of out-of-distribution detection and facilitate methodological progress in this area.",10 Broader impact,68,5,,,FALSE,FALSE,FALSE,Why Normalizing Flows Fail to Detect Out-of-Distribution Data,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Algorithms -> Uncertainty Estimation,Deep learning,"['Polina Kirichenko', ' Pavel Izmailov', ' Andrew Gordon Wilson']",{'New York University'},1,0,0,{'USA'}
Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay,"Joao Marques-Silva, Thomas Gerspacher, Martin Cooper, Alexey Ignatiev, Nina Narodytska",Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay,eccd2a86bae4728b38627162ba297828,https://proceedings.neurips.cc/paper/2020/file/eccd2a86bae4728b38627162ba297828-Paper.pdf,"Recent advances in the power of machine learning have not always been accompanied with the explainability of decisions made by complex models. The capacity to produce human-understandable explanations is sometimes not only an advantage but a legal obligation. Linear classifiers, including the Naive Bayes Classifier (NBC), are ubiquitous in Machine Learning, being extensively studied and finding a wide range of practical uses. Recent work [34, 6] proposed worst-case exponential time and space algorithms for computing PI-explanations of NBCs, where PI-explanations denote minimal sets of feature-value pairs that are sufficient for the prediction. Our paper investigates PI-explanations for linear classifiers, and proposes efficient (i.e. polyno- mial time) algorithms for computing one PI-explanation, but also efficient (i.e. polynomial delay) algorithms for enumerating PI-explanations. In practice, and for the specific case of NBCs, the new algorithms achieve orders of magnitude speed-ups over earlier work. More importantly, our algorithms enable computing PI-explanations for classifiers that were until now beyond the reach of existing approaches.",Broader Impact,160,7,,,FALSE,FALSE,FALSE,Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay,Applications,"Algorithms -> Classification; Applications -> Automated Reasoning and Formal Methods; Deep Learning -> Visualization, Interpretability, and Explainability",Explainability,"['Silva', ' Thomas Gerspacher', ' Martin Cooper', ' Alexey Ignatiev', ' Nina Narodytska']","{'ANITI', 'University of Toulouse 3', 'VMmare Research', 'Monash University', 'ANITI, Federal University of Toulouse Midi-Pyrénées'}",1,1,1,"{'France', 'UK', 'Australia'}"
Unsupervised Translation of Programming Languages,"Baptiste Roziere, Marie-Anne Lachaux, Lowik Chanussot, Guillaume Lample",Unsupervised Translation of Programming Languages,ed23fbf18c2cd35f8c7f8de44f85c08d,https://proceedings.neurips.cc/paper/2020/file/ed23fbf18c2cd35f8c7f8de44f85c08d-Paper.pdf,"Automatic transcompilation has the potential to make programmers working in companies or on open source projects more efficient, by allowing them to integrate various codes from other teams within the company or other open source projects more easily. It can also lower the cost of updating an old codebase written in an obsolete language to a more recent language. Many large banks, insurance companies and utilities companies still run code written in COBOL. Advances in transcompilation could incite them to update to more recent languages and facilitate future innovation. Transcom- pilation being a tool facilitating innovation, its applications could have both positive and negative societal impacts. However, we believe that the impact of more innovation within companies and in open source projects would be positive overall. In the long-term, updates of old codebases could put the experts in obsolete languages at a disadvantage as the need for their expertise will decrease. We believe it would be offset by an increased need for programmers caused by more innovative projects, benefiting all programmers.",Broader Impact,171,8,,,FALSE,FALSE,FALSE,Unsupervised Translation of Programming Languages,Applications -> Natural Language Processing,Algorithms -> Unsupervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Baptiste Roziere', 'Anne Lachaux', ' Lowik Chanussot', ' Guillaume Lample']",{'Facebook AI Research'},0,1,0,{'USA'}
Adversarial Style Mining for One-Shot Unsupervised Domain Adaptation,"Yawei Luo, Ping Liu, Tao Guan, Junqing Yu, Yi Yang",Adversarial Style Mining for One-Shot Unsupervised Domain Adaptation,ed265bc903a5a097f61d3ec064d96d2e,https://proceedings.neurips.cc/paper/2020/file/ed265bc903a5a097f61d3ec064d96d2e-Paper.pdf,"Using as few manual annotations as possible to get a model that can handle data in different environments and states has been a long standing topic in computer vision and artificial intelligence community. UDA has been dedicating to this topic while our proposed ASM has taken a step further by relaxing the assumption of sufficient target data. In many scenarios, not only data labeling but also data collection itself might be challenging, if not impossible, for the target task. For example, it could be hard to acquire rare disease information with privacy or to shoot videos under extreme weather conditions. From this point of view, the proposed ASM has the potential to not only reduce the amount of labor required to collect data, but also to protect private data from being leaked. Overall, the impact of our proposed ASM to the research community is positive and beneficial.",Broader Impact,147,6,,,FALSE,FALSE,FALSE,Adversarial Style Mining for One-Shot Unsupervised Domain Adaptation,Algorithms -> Multitask and Transfer Learning,Applications -> Computer Vision; Applications -> Image Segmentation; Deep Learning -> Adversarial Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yawei Luo', ' Ping Liu', ' Tao Guan', ' Junqing Yu', ' Yi Yang']","{'Huazhong University of Science and Technology', 'Zhejiang University', 'UTS'}",1,0,0,"{'Australia', 'China'}"
Optimally Deceiving a Learning Leader in Stackelberg Games,"Georgios Birmpas, Jiarui Gan, Alexandros Hollender, Francisco Marmolejo, Ninad Rajgopal, Alexandros Voudouris",Optimally Deceiving a Learning Leader in Stackelberg Games,ed383ec94720d62a939bfb6bdd98f50c,https://proceedings.neurips.cc/paper/2020/file/ed383ec94720d62a939bfb6bdd98f50c-Paper.pdf,"The nature of our work is mainly theoretical, and aims to abstractly model many interesting and practical applications. Our paper can be considered as part of an emerging literature which aims to advance our understanding on the behavior of learning algorithms in the presence of strategic noise, an assumption that is arguably very realistic and appears in practice. We are able to show that the follower can always benefit by deceiving the algorithm used by the leader to learn an equilibrium in Stackelberg games. This result has a greater impact by showing that in real-world settings which can be modeled as Stackelberg games, such as firm competition and allocating defensive resources, the design of learning algorithms needs to take into account possible ways of manipulation by the users.",Broader Impact Statement,128,4,,,FALSE,FALSE,FALSE,Optimally Deceiving a Learning Leader in Stackelberg Games,Theory -> Game Theory and Computational Economics,Algorithms -> Active Learning,Theory (including computational and statistical analyses),"['Georgios Birmpas', ' Jiarui Gan', ' Alexandros Hollender', ' Francisco Marmolejo', ' Ninad Rajgopal', ' Alexandros Voudouris']","{'University of Essex', 'University of Oxford'}",1,0,0,{'UK'}
Online Optimization with Memory and Competitive Control,"Guanya Shi, Yiheng Lin, Soon-Jo Chung, Yisong Yue, Adam Wierman",Online Optimization with Memory and Competitive Control,ed46558a56a4a26b96a68738a0d28273,https://proceedings.neurips.cc/paper/2020/file/ed46558a56a4a26b96a68738a0d28273-Paper.pdf,"Online convex optimization with switching cost (SOCO) has been widely used in commercial and industrial applications such as data centers, power systems, and vehicle charging. By proposing a generalization of SOCO together with new algorithms with competitive ratio guarantees in this setting, this paper opens a new set of applications for online optimization. Additionally, the results provide new fundamental insights about the connection between online optimization and control. However, like many other theoretical contributions, this paper’s results are limited to its assumptions, e.g., strongly convex cost functions. We see no ethical concerns related to the results in this paper.",Broader Impact,99,5,,,FALSE,FALSE,FALSE,Online Optimization with Memory and Competitive Control,Algorithms -> Online Learning,Reinforcement Learning and Planning -> Decision and Control; Theory -> Control Theory,"Online Learning, Online Optimization, Control and Dynamics","['Guanya Shi', ' Yiheng Lin', 'Jo Chung', ' Yisong Yue', ' Adam Wierman']","{'California Institute of Technology', 'Caltech'}",1,0,0,{'USA'}
IDEAL: Inexact DEcentralized Accelerated Augmented Lagrangian Method,"Yossi Arjevani, Joan Bruna, Bugra Can, Mert Gurbuzbalaban, Stefanie Jegelka, Hongzhou Lin",IDEAL: Inexact DEcentralized Accelerated Augmented Lagrangian Method,ed77eab0b8ff85d0a6a8365df1846978,https://proceedings.neurips.cc/paper/2020/file/ed77eab0b8ff85d0a6a8365df1846978-Paper.pdf,"Centralization of data is not always possible because of security and legacy concerns [14]. Our work proposes a new optimization algorithm in the decentralized setting, which can learn a model without revealing the privacy sensitive data. Potential applications include data coming from healthcare, environment, safety, etc, such as personal medical information [19, 20], keyboard input history [22, 32] and beyond.",Broader impact,60,3,FALSE,FALSE,FALSE,FALSE,FALSE,IDEAL: Inexact DEcentralized Accelerated Augmented Lagrangian Method,Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Yossi Arjevani', ' Joan Bruna', ' Bugra Can', ' Mert Gurbuzbalaban', ' Stefanie Jegelka', ' Hongzhou Lin']","{'MIT', 'Rutgers University', 'NYU', 'Rutgers'}",1,0,0,{'USA'}
Evolving Graphical Planner: Contextual Global Planning for Vision-and-Language Navigation,"Zhiwei Deng, Karthik Narasimhan, Olga Russakovsky",Evolving Graphical Planner: Contextual Global Planning for Vision-and-Language Navigation,eddb904a6db773755d2857aacadb1cb0,https://proceedings.neurips.cc/paper/2020/file/eddb904a6db773755d2857aacadb1cb0-Paper.pdf,"This work has several downstream applications in areas like autonomous navigation and robotic control, especially through the use of natural language instruction. Potential downstream uses of such agents range from healthcare delivery to elderly home assistance to disaster relief efforts. We believe that imbuing these agents with a global awareness of the environment and long-term planning will enable them to handle more challenging tasks and recover gracefully from mistakes. While the graph-based approach we propose is scalable and easy to manipulate in real time, future research can address computation challenges and increase the planning time-scale to enable better decision making.",Broader Impact,100,4,,,FALSE,FALSE,FALSE,Evolving Graphical Planner: Contextual Global Planning for Vision-and-Language Navigation,Reinforcement Learning and Planning -> Navigation,Algorithms -> Multimodal Learning; Algorithms -> Structured Prediction; Applications -> Computer Vision; Reinforcement Learning and Planning -> Planning,"imitation learning, Embodied AI in vision","['Zhiwei Deng', ' Karthik Narasimhan', ' Olga Russakovsky']",{'Princeton University'},1,0,0,{'USA'}
Learning from Failure: De-biasing Classifier from Biased Classifier,"Junhyun Nam, Hyuntak Cha, Sung-Soo Ahn, Jaeho Lee, Jinwoo Shin",Learning from Failure: Training Debiased Classifier from Biased Classifier,eddc3427c5d77843c2253f1e799fe933,https://proceedings.neurips.cc/paper/2020/file/eddc3427c5d77843c2253f1e799fe933-Paper.pdf,"Mitigating the potential risk caused by biased datasets is a timely subject, especially with the widespread use of AI systems in our daily lives. Since the world is biased by nature, biased models are often deployed without perceiving their discriminative behavior, thereby leading to invoking the potential risk. For instance, a facial recognition software in digital cameras turned out to “over-predict” Asians as blinking when it was trained on Caucasian faces [20]. Disregarding such potential risks would further result in critical social issues [13], such as racism, gender discrimination, filter bubbles [22], and social polarization. We propose the debiasing scheme to mitigate the aforementioned potential risks. A common approach to reducing the risks is to develop schemes that specifically tackle a bias of interest, e.g., gender, race, etc. However, underexplored biases might exist in the dataset, but bias-specific schemes would not be able to address these other biases. We thus recommend leveraging the general behaviors of neural networks trained on biased datasets, which can be applied for debiasing in diverse applications. Now we discuss potential benefits and limitations of the proposed scheme. The underexplored types of bias can be discovered by using a set of samples that are hard for the model to learn. Using this approach can increase awareness of underexplored biases. This awareness can be specifically important for groups that would be potentially affected. We acknowledge that assessing the reduction of potential risks by the proposed scheme can be a challenge without specifically identifying the biases. Still, we anticipate that our approach opens a potential to analyze and interpret underexplored types of bias.",Broader Impact,265,14,,,FALSE,FALSE,FALSE,Learning from Failure: De-biasing Classifier from Biased Classifier,Deep Learning -> Supervised Deep Networks,"Algorithms -> Classification; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Junhyun Nam', ' Hyuntak Cha', 'Soo Ahn', ' Jaeho Lee', ' Jinwoo Shin']","{'University of Illinois at Urbana-Champaign', 'KAIST'}",1,0,0,"{'South Korea', 'USA'}"
Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder,"Zhisheng Xiao, Qing Yan, Yali Amit",Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder,eddea82ad2755b24c4e168c5fc2ebd40,https://proceedings.neurips.cc/paper/2020/file/eddea82ad2755b24c4e168c5fc2ebd40-Paper.pdf,"Out-of-distribution detection is a research direction with significant social impact. Nowadays, deep learning is deployed on many systems that are making critical decisions, such as medical diagnosis, factory manufacturing, autonomous driving. Being able to detect anomalous cases is crucial for these systems. Therefore, our work, together with many other research efforts on out-of-distribution detection, is very important for the future development of artificial intelligence. However, we should be cautious on solely relying on algorithmic anomaly detection, as there is always the risk of certain anomalous cases that can fool the algorithms. It is very risky to completely trust these imperfect algorithms.",Broader Impact,101,6,,,FALSE,FALSE,FALSE,Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder,Deep Learning -> Deep Autoencoders,Algorithms -> Representation Learning; Algorithms -> Uncertainty Estimation; Algorithms -> Unsupervised Learning,Deep learning,"['Zhisheng Xiao', ' Qing Yan', ' Yali Amit']","{'University of Chicago', 'The University of Chicago'}",1,0,0,{'USA'}
Deep Diffusion-Invariant Wasserstein Distributional Classification,"Sung Woo Park+, Dong Wook Shu, Junseok Kwon",Deep Diffusion-Invariant Wasserstein Distributional Classification,ede7e2b6d13a41ddf9f4bdef84fdc737,https://proceedings.neurips.cc/paper/2020/file/ede7e2b6d13a41ddf9f4bdef84fdc737-Paper.pdf,"The proposed framework can considerably enhance conventional classification methods, of which performance is very sensitive to various types of perturbations ( e . g ., rotations, impulse noise, and down-scaling). The proposed Wasserstein distributional classifier represents both input data and target labels as probability measures and its diffusion invariant property prevents the classifier from being affected by severe perturbations. Hence, various research fields under real-world environments can benefit from exploiting our framework to obtain accurate classification results.",Broader Impact,77,4,,,FALSE,FALSE,FALSE,Deep Diffusion-Invariant Wasserstein Distributional Classification,Algorithms -> Classification,Algorithms -> Representation Learning,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['', ' Dong Wook Shu', ' Junseok Kwon']",{'Chung-Ang University'},1,0,0,{'South Korea'}
Finding All ϵϵ-Good Arms in Stochastic Bandits,"Blake Mason, Lalit Jain, Ardhendu Tripathy, Robert Nowak",Finding All ✏ -Good Arms in Stochastic Bandits,edf0320adc8658b25ca26be5351b6c4a,https://proceedings.neurips.cc/paper/2020/file/edf0320adc8658b25ca26be5351b6c4a-Paper.pdf,"The application of machine learning (ML) in domains such as advertising, biology, or medicine brings the possibility of utilizing large computational power and large datasets to solve new problems. It is tempting to use powerful, if not fully understood, ML tools to maximize scientific discovery. However, at times the gap between a tool’s theoretical guarantees and its practical performance can lead to sub-optimal behavior. This is especially true in adaptive data collection where misspecifying the model or desired output (e.g., “return the top k performing compounds” vs. “return all compounds with a potency about a given threshold”) may bias data collection and hinder post-hoc consideration of different objectives. In this paper we highlight several such instances in real-life data collection using multi-armed bandits where such a phenomenon occurs. We believe that the objective studied in this work, that of returning all arms whose mean is quantifiably near-best, more naturally aligns with practical objectives as diverse as finding funny captions to performing medical tests. We point out that methods from adaptive data collection and multi-armed bandits can also be used on content- recommendation platforms such as social media or news aggregator sites. In these scenarios, time and again, we have seen that recommendation systems can be greedy, attempting purely to maximize clickthrough with a long term effect of a less informed public. Adjacent to one of the main themes of this paper, we recommend that practitioners not just focus on the objective of recommendation for immediate profit maximization but rather keep track of a more holistic set of metrics. We are excited to see our work used in practical applications and believe it can have a major impact on driving the process of scientific discovery.",6 Broader Impacts and Funding Transparency Statement,284,10,,,TRUE,TRUE,FALSE,Finding All $\epsilon$-Good Arms in Stochastic Bandits,Algorithms -> Bandit Algorithms,Algorithms -> Active Learning,Theory (including computational and statistical analyses),,"{'University of Washington', 'University of Wisconsion-Madison', 'University of Wisconsin - Madison'}",1,0,0,{'USA'}
Meta-Learning through Hebbian Plasticity in Random Networks,"Elias Najarro, Sebastian Risi",Meta-Learning through Hebbian Plasticity in Random Networks,ee23e7ad9b473ad072d57aaa9b2a5222,https://proceedings.neurips.cc/paper/2020/file/ee23e7ad9b473ad072d57aaa9b2a5222-Paper.pdf,"The ethical and future societal consequences of this work are hard to predict but likely similar to other work dealing with more adaptive agents and robots. In particular, by giving robots the ability to still function when injured could make it easier for them being deployed in areas that have both a positive and negative impact on society. In the very long term, robots that can adapt could help in industrial automation or help to care for the elderly. On the other hand, more adaptive robots could also be more easily used for military applications. The approach presented in this paper is far from being deployed in these areas, but it its important to discuss its potential long-term consequences early on.",Broader Impact,121,5,,,FALSE,FALSE,FALSE,Meta-Learning through Hebbian Plasticity in Random Networks,Neuroscience and Cognitive Science,Algorithms -> Continual Learning; Algorithms -> Online Learning; Deep Learning -> Biologically Plausible Deep Networks; Neuroscience and Cognitive Science -> Plasticity and Adaptation; Neuroscience and Cognitive Science -> Synaptic Modulation; Optimization -> Evolutionary Computation,Neuroscience and cognitive science,"['Elias Najarro', ' Sebastian Risi']",{'IT University of Copenhagen'},1,0,0,{'Denmark'}
A Computational Separation between Private Learning and Online Learning,Mark Bun,A Computational Separation between Private Learning and Online Learning ∗,ee715daa76f1b51d80343f45547be570,https://proceedings.neurips.cc/paper/2020/file/ee715daa76f1b51d80343f45547be570-Paper.pdf,"As this work is theoretical in nature, its tangible ethical and societal impacts are especially difficult to predict. Optimistically, the conceptual message that efficient private learning is possible without efficient online learning opens the door to the design of private learners for classes for which there are no efficient online counterparts. This could lead to surprising tractable learning algorithms for problems motivated by the practice of DP, and downstream, enable the analysis of data that could otherwise not be shared. Computational efficiency in differential privacy is a major bottleneck for its real-world adoption, and must often be traded off against statistical error and bias. The availability of new, more efficient tools should ideally only increase the adoption and efficacy of privcy-preserving technology. However, there is also a general danger of making inappropriate choices of these tradeoffs when new technologies become available. For instance, a much more efficient algorithm with weaker privacy or accuracy guarantees might be chosen over a less efficient one for, e.g., a real-time analytics application. The availability of new tools should always be complemented by thorough analyses of their accuracy and privacy guarantees so that such decisions can be made in an informed and careful manner.",Broader Impact,199,8,,,FALSE,FALSE,FALSE,A Computational Separation between Private Learning and Online Learning,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Algorithms -> Classification; Algorithms -> Online Learning; Theory -> Computational Learning Theory; Theory -> Hardness of Learning and Approximations,"Social aspects of machine learning (e.g., fairness, safety, privacy)",['Mark Bun'],{'Boston University'},1,0,0,{'USA'}
Top-KAST: Top-K Always Sparse Training,"Siddhant Jayakumar, Razvan Pascanu, Jack Rae, Simon Osindero, Erich Elsen",Top-KAST: Top-K Always Sparse Training,ee76626ee11ada502d5dbf1fb5aae4d2,https://proceedings.neurips.cc/paper/2020/file/ee76626ee11ada502d5dbf1fb5aae4d2-Paper.pdf,"Our work proposes a new method to train sparse neural networks that allows them to remain sparse throughout training – thereby enabling a practitioner to increase the model size that can be trained on a given piece of hardware. (This would also impact deployment too, in the case of on-device or real- time learning.) As we note in our introduction this scale-enabling should benefit the democratisation of deep learning since state-of-the-art models are ever increasing in size. Furthermore, there are beneficial impacts to be expected by reducing the computational footprint and energy consumption for training neural networks, as well as the higher-order impacts achieved if our work promotes the adoption of sparse networks more broadly – thereby also reducing the deployment/inference costs. While we do not expect any direct negative consequences from this work, the proposed method is general and widely applicable. We believe that the benefits offered by advances in machine learning net outweigh (by a significant margin) the potential risks and negative consequences. However, the technology as a whole is not purely good or benign. As one suggestion for future research building on our contribution, we would encourage colleagues who extend or apply our work to help us assess whether the inductive biases promoted by our sparsification methods have lead to any differential sensitivity to class imbalances or other aspects of the underlying data, relative to dense counterpart approaches for a given application. Since such issues could exacerbate problems related to algorithmic bias.",Broader Impact,245,9,,,FALSE,FALSE,FALSE,Top-KAST: Top-K Always Sparse Training,Deep Learning,Algorithms -> Sparsity and Compressed Sensing; Deep Learning -> Efficient Training Methods,,"['Siddhant Jayakumar', ' Razvan Pascanu', ' Jack Rae', ' Simon Osindero', ' Erich Elsen']","{'DeepMind, UCL', 'DeepMind', 'Google DeepMind'}",1,1,1,{'UK'}
Meta-Learning with Adaptive Hyperparameters,"Sungyong Baik, Myungsub Choi, Janghoon Choi, Heewon Kim, Kyoung Mu Lee",Meta-Learning with Adaptive Hyperparameters,ee89223a2b625b5152132ed77abbcc79,https://proceedings.neurips.cc/paper/2020/file/ee89223a2b625b5152132ed77abbcc79-Paper.pdf,"Meta-learning and few-shot classification can help nonprofit organizations and small businesses automate their tasks at low cost, as only few labeled data may be needed. Due to the efficiency of automated tasks, nonprofit organizations can help more people from the minority groups, while small businesses can enhance their competitiveness in the world market. Thus, we believe that meta-learning, in a long run, will promote diversity and improve the quality of everyday life. On the other hand, the automation may lead to social problems concerning job losses, and thus such technological improvements should be considered with extreme care. Better education of existing workers to encourage changing their roles ( e.g. managing the failure cases of intelligent systems, polishing the data for incremental learning) can help prevent unfortunate job losses.",Broader Impact,128,5,,,FALSE,FALSE,FALSE,Meta-Learning with Adaptive Hyperparameters,Algorithms -> Few-Shot Learning,Algorithms -> Meta-Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,{'Seoul National University'},1,0,0,{'South Korea'}
Tight last-iterate convergence rates for no-regret learning in multi-player games,"Noah Golowich, Sarath Pattathil, Constantinos Daskalakis",Tight last-iterate convergence rates for no-regret learning in multi-player games,eea5d933e9dce59c7dd0f6532f9ea81b,https://proceedings.neurips.cc/paper/2020/file/eea5d933e9dce59c7dd0f6532f9ea81b-Paper.pdf,"As this is a theoretical paper, we expect that the direct ethical and societal impacts of this work will be limited. As the setting of multi-agent learning in games describes many systems with potential for practical impact, such as GANs, we believe that the insights developed in this paper may eventually aid the improvement of such technologies. If not deployed and regulated carefully, technologies such as GANs could lead to harmful outcomes, such as through the proliferation of false media (“deepfakes”). We hope that, through a combination of legal and technological measures, such negative impacts of GANs can be limited and the positive applications, such as drug discovery and image analysis in the medical field, may be realized.",Broader impact,118,4,,,FALSE,FALSE,FALSE,Tight last-iterate convergence rates for no-regret learning in multi-player games,Optimization -> Convex Optimization,Algorithms -> Online Learning; Theory -> Game Theory and Computational Economics,Optimization Methods (continuous or discrete),"['Noah Golowich', ' Sarath Pattathil', ' Constantinos Daskalakis']","{'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Curvature Regularization to Prevent Distortion in Graph Embedding,"Hongbin Pei, Bingzhe Wei, Kevin Chang, Chunxu Zhang, Bo Yang",Curvature Regularization to Prevent Distortion in Graph Embedding,eeb29740e8e9bcf14dc26c2fff8cca81,https://proceedings.neurips.cc/paper/2020/file/eeb29740e8e9bcf14dc26c2fff8cca81-Paper.pdf,"This work raised the distortion problem in graph embedding for the first time. As the problem is important but neglected in the existing works, it will attract many researchers to design new approaches to address it. In this work, three kinds of curvature regularization and an optimizing algorithm have been proposed to prevent the pattern distortion during graph embedding. Obviously, the results of the work will have an immediate impact on improving the performance of various proximity-preserving graph embedding methods. This work will also benefit graph analysis applications in the real world, such as social network analysis, recommendation system, and knowledge graph mining. The proposed models and algorithm advance the development of graph representation models which may bring negative societal consequences including privacy leak and fairness issues. For example, sensitive personal information, e.g., political orientation, occupation, and disease, may encode implicitly in user connections in social network. Those privacy can be learned effectively by graph representation models, and then may be leaked illegally by someone with bad intentions. Meanwhile, the links in social network also encode the information about population subgroups, such as gender and ethnic group. If such information is extracted by graph representation models and fed into downstream machine learning models, the trained model may lead to unfair predictions. For example, if one company scarcely employees women, models trained on this data would prefer man.",8 Broader Impact,227,11,,,FALSE,FALSE,FALSE,Curvature Regularization to Prevent Distortion in Graph Embedding,Applications -> Network Analysis,Deep Learning -> Embedding Approaches,Graph representation learning,"['Hongbin Pei', ' Bingzhe Wei', ' Kevin Chang', ' Chunxu Zhang', ' Bo Yang']","{'Jilin University', 'University of Illinois at Urbana-Champaign'}",1,0,0,"{'USA', 'China'}"
Perturbing Across the Feature Hierarchy to Improve Standard and Strict Blackbox Attack Transferability,"Nathan Inkawhich, Kevin Liang, Binghui Wang, Matthew Inkawhich, Lawrence Carin, Yiran Chen",Perturbing Across the Feature Hierarchy to Improve Standard and Strict Blackbox Attack Transferability,eefc7bfe8fd6e2c8c01aa6ca7b1aab1a,https://proceedings.neurips.cc/paper/2020/file/eefc7bfe8fd6e2c8c01aa6ca7b1aab1a-Paper.pdf,"Unlike many areas of research, the very name of “adversarial machine learning,” with key terms such as “attacker” and “defender,” may predispose readers to believing that such research automatically bears a negative societal impact. Conversely, much of the research in this area, including this work, is in pursuit of more positive goals: vulnerability awareness, robustness, and understanding, as related to DNNs. Much as “white hat hacking” leads to more secure computer systems, by studying adversarial attacks, we are working to find potential exploits and vulnerabilities that may be used by a malicious party in the future. This is especially important as deep learning technologies are adopted into real-world applications. The goal would then be to make such deployed DNNs robust against known vulnerabilities so the predictions can be interpreted with confidence. We also study adversarial examples and attacking techniques to enhance our practical understanding of how DNNs make decisions, as we are examining the behavior of models near and around the decision boundaries, which are formed after a long and difficult-to-interpret training process. In the context of society at large, a positive impact that this work may have is the development of more robust models in consumer products and applications. For example, in the space of self-driving cars, if the developers of the object detection and classification systems are aware of our method (along with many others) as a known vulnerability, the resulting system may not be fooled in the presence of a physical adversary who is trying to intentionally cause a malfunction of the system when the car is on the road. Another example is the creation of robust digital products and applications that rely on remotely-hosted models with secure/protected/unknown datasets (e.g., Google Cloud Vision). Previously, transfer attacks were primarily discussed in the context of the source and target model being trained on the same dataset. Therefore, a company/institution confident in their training dataset being under wraps may be lulled into a false sense of security with regards to vulnerability to transfer attacks on their system. The designers may then assume that throttling user query rate to hamper query-based adversaries is sufficient for adversarial threat mitigation. However, our work shows that a feature-based adversary can transfer even in cross-distribution settings, where the attacker needs not have access to the exact training data or label space of the proprietary model. Since transfer attacks have a very small query “profile,” and do not require repetitive querying, such threat mitigation systems may easily be circumvented by the attack we have proposed. Informed with the renewed capabilities of a transfer adversary, designers of such remote and proprietary models may now consider other ways to improve the robustness of their models, resulting in an overall positive impact on the quality and safety of their machine learning systems. There are also some potential negative consequences of the work on society, especially if the exposed adversarial vulnerabilities are not addressed in the design of future systems. Given trade-offs that system designers may have to make, such as accuracy/generalization vs. robustness, training time vs. robustness, development time vs. deadlines, it may be tempting to develop non-robust models for high accuracy, low training time, and low development time. However, if this is done, and the model is deployed without proper consideration of adversarial vulnerabilities including (but not limited to) our method, it may result in the crash of a self-driving car, a weapon passing through an X-ray baggage scanner, poisoned data samples being classified (and potentially re-trained on) by a remote system, etc. Overall, although there is potential for both positive and negative consequences, we believe the best use for our work is to be used in the development stages of a system to ultimately create more robust and safe models with interfaces to society.",Broader Impact,627,19,,,FALSE,FALSE,FALSE,Perturbing Across the Feature Hierarchy to Improve Standard and Strict Blackbox Attack Transferability,Deep Learning,"Algorithms -> Adversarial Learning; Algorithms -> Classification; Applications -> Computer Vision; Deep Learning -> Adversarial Networks; Deep Learning -> Analysis and Understanding of Deep Networks; Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,"['Nathan Inkawhich', ' Kevin Liang', ' Binghui Wang', ' Matthew J Inkawhich', ' Lawrence Carin', ' Yiran Chen']",{'Duke University'},1,0,0,{'USA'}
Statistical and Topological Properties of Sliced Probability Divergences,"Kimia Nadjahi, Alain Durmus, Lénaïc Chizat, Soheil Kolouri, Shahin Shahrampour, Umut Simsekli",Statistical and Topological Properties of Sliced Probability Divergences,eefc9e10ebdc4a2333b42b2dbb8f27b6,https://proceedings.neurips.cc/paper/2020/file/eefc9e10ebdc4a2333b42b2dbb8f27b6-Paper.pdf,"This paper is focused on the theoretical properties of sliced probability divergences, which have become increasingly popular in recent years due to their applications on implicit generative modeling. Our analysis uncovers the topological and statistical consequences of the slicing operation, and aims at providing answers to the question “When and why do sliced divergences perform well in practice?” . We believe that our theory would provide useful guidelines for practitioners working in this field, in terms of designing new sliced divergences as well as obtaining a better understanding on the existing sliced divergences. Our contributions are mainly theoretical, and we believe these will not pose any negative or positive ethical or societal consequence in the broad sense.",Broader Impact,117,4,,,FALSE,FALSE,FALSE,Statistical and Topological Properties of Sliced Probability Divergences,Theory -> Frequentist Statistics,,Theory (including computational and statistical analyses),"['Kimia Nadjahi', ' Alain Durmus', ' Lénaïc Chizat', ' Soheil Kolouri', ' Shahin Shahrampour', ' Umut Simsekli']","{'ENS Paris Saclay', 'HRL Laboratories LLC', 'Institut Polytechnique de Paris/ University of Oxford', 'Télécom ParisTech', 'CNRS'}",1,1,1,"{'France', 'UK'}"
Probabilistic Active Meta-Learning,"Jean Kaddour, Steindor Saemundsson, Marc Deisenroth",Probabilistic Active Meta-Learning,ef0d17b3bdb4ee2aa741ba28c7255c53,https://proceedings.neurips.cc/paper/2020/file/ef0d17b3bdb4ee2aa741ba28c7255c53-Paper.pdf,"The fundamental goal of this work is making learning algorithms more data-efficient. Fewer tasks to be observed might result in fewer experiments in real-world scenarios, directly reducing the resources needed to conduct these. Another consequence is shorter computation time during model training since less data is required. Less computation time reduces the overall energy consumption. Furthermore, the latent representation of tasks can be used to automatically infer similarities and commonalities between tasks, which may contribute to interpretability.",Broader Impact,77,5,,,FALSE,FALSE,FALSE,Probabilistic Active Meta-Learning,Algorithms -> Active Learning,Algorithms -> Meta-Learning; Probabilistic Methods,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Jean Kaddour', ' Steindor Saemundsson', ' Marc Deisenroth']","{'University College London', 'Imperial College London'}",1,0,0,{'UK'}
"Knowledge Distillation in Wide Neural Networks: Risk Bound, Data Efficiency and Imperfect Teacher","Guangda Ji, Zhanxing Zhu","Knowledge Distillation in Wide Neural Networks: Risk Bound, Data Efficiency and Imperfect Teacher",ef0d3930a7b6c95bd2b32ed45989c61f,https://proceedings.neurips.cc/paper/2020/file/ef0d3930a7b6c95bd2b32ed45989c61f-Paper.pdf,"Knowledge distillation is a heavily used technique for model compression. It is of high industrial importance since small models are easy deployed and cost saving. Unfortunately, it remains as a black box. The lack of a theoretical explanation limits a wider application of this technique. Our work provide a theoretical analysis and rethinking of this technique. Even though this work has no direct societal impact, with the guidance of our analysis, new distillation techniques of higher efficiency and performance may be proposed. However, development of model compression techniques can have negative impact: it reduces the time and cost of training functional deep learning applications, which make the abuse of deep learning techniques easier. We suggest that deep learning community and governments to put forward stronger restrictions on the opensource of data and models, and more careful supervision on the abuse of computing power.",Broader Impact,143,8,,,FALSE,FALSE,FALSE,"Knowledge Distillation in Wide Neural Networks: Risk Bound, Data Efficiency and Imperfect Teacher",Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks,Theory (including computational and statistical analyses),"['Guangda Ji', ' Zhanxing Zhu']",{'Peking University'},1,0,0,{'China'}
Adversarial Attacks on Deep Graph Matching,"Zijie Zhang, Zeru Zhang, Yang Zhou, Yelong Shen, Ruoming Jin, Dejing Dou",Adversarial Attacks on Deep Graph Matching,ef126722e64e98d1c33933783e52eafc,https://proceedings.neurips.cc/paper/2020/file/ef126722e64e98d1c33933783e52eafc-Paper.pdf,"Graph data are ubiquitous in the real world, ranging from biological, communication, and transporta- tion graphs, to knowledge, social, and collaborative networks. Many real-world graphs are essentially crowdsourced projects, such as social and knowledge networks, where information and knowledge are produced by internet users who came to the sites. Thus, the quality of crowdsourced graph data is not stable, depending on human knowledge and expertise. In addition, it is well known that the openness of crowdsourced websites makes them vulnerable to malicious behaviors of interested parties to gain some level of control of the websites and steal users’ sensitive information, or deliberately influence public opinion by injecting misleading information and knowledge into crowdsourced graphs. Graph matching is one of the most important research topics in the graph domain, which aims to match the same entities (i.e., nodes) across two or more graphs [91, 98, 43, 46, 48, 72, 54, 105, 13, 75]. It has been widely applied to many real-world applications ranging from protein network matching in bioinformatics [33, 63], user account linking in different social networks [62, 51, 100, 37, 101, 21, 38], and knowledge translation in multilingual knowledge bases [87, 124], to geometric keypoint matching in computer vision [22]. Owing to the openness of crowdsourced graphs, more work is needed to analyze the vulnerability of graph matching under adversarial attacks and to future develop robust solutions that are readily applicable in production systems. A potential downside of this research is about the application of user account linking in different social networks due to the user privacy issues. Recent advances in differential privacy and privacy preserving graph analytics have shown the superior performance of protecting sensitive information about individuals in the datasets. Therefore, these techniques offer a great opportunity to integrate them into the vulnerability analysis of graph matching, for alleviating the user privacy threats.",Broader Impact,306,10,,,FALSE,FALSE,FALSE,Adversarial Attacks on Deep Graph Matching,Applications -> Network Analysis,,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Zijie Zhang', ' Zeru Zhang', ' Yang Zhou', ' Yelong Shen', ' Ruoming Jin', ' Dejing Dou']","{'Microsoft Dynamics 365 AI', 'Kent State University', 'Auburn University'}",1,1,1,{'USA'}
The Generalization-Stability Tradeoff In Neural Network Pruning,"Brian Bartoldson, Ari Morcos, Adrian Barbu, Gordon Erlebacher",The Generalization-Stability Tradeoff In Neural Network Pruning,ef2ee09ea9551de88bc11fd7eeea93b0,https://proceedings.neurips.cc/paper/2020/file/ef2ee09ea9551de88bc11fd7eeea93b0-Paper.pdf,"This work focuses on resolving an apparent contradiction in the scientific understanding of the relationship between pruning and generalization performance. As such, we believe its primary impact will be on other researchers and it is unlikely to have substantial broader impacts. That said, understanding the mechanisms underlying our models is important for the safe deployment of such models in application domains. Our work takes a step in that direction, and we hope may help pave the way for further understanding.",Broader Impact,80,4,,,FALSE,FALSE,FALSE,The Generalization-Stability Tradeoff In Neural Network Pruning,Deep Learning -> Analysis and Understanding of Deep Networks,"Deep Learning -> Visualization, Interpretability, and Explainability",Deep learning,"['Brian Bartoldson', ' Ari Morcos', ' Adrian Barbu', ' Gordon Erlebacher']","{'Florida State University', 'Facebook AI Research', 'Florida State University, USA'}",1,1,1,{'USA'}
Gradient-EM Bayesian Meta-Learning,"Yayi Zou, Xiaoqi Lu",Gradient-EM Bayesian Meta-learning,ef48e3ef07e359006f7869b04fa07f5e,https://proceedings.neurips.cc/paper/2020/file/ef48e3ef07e359006f7869b04fa07f5e-Paper.pdf,"Meta-learning algorithms can be applied in AI products that requires fast adaptation with few data points. Examples are: 1) facial recognition system for enterprise where only few photo shots from each employer are taken as training samples; 2) manufacturing robot that masters new tasks quickly from few times of human demonstration; 3) AI assistant that customizes to a new user after few interactions. Our research, in particular, makes an impact by introducing a novel approach that improves computational efficiency, robustness (and other advantages) of meta-learning. This generally benefits future AI researches in meta-learning, rather than direct impact on specific product. In particular, our method improves the computational efficiency, uncertainty prediction and has potential use in building distributed and privacy protected meta-learning system. Potential advantage for deep NN because it can be parallelized among network layers. Specifically, under a distributed setting where meta-update and inner-update take place in separate devices, unlike previous methods, our method avoids transmission of gradients which may cause leakage of user data due to a recent research [29]. It may help protect user privacy and enhance decentralization of AI, preventing the monopoly of AI.",Broader Impact,187,8,,,FALSE,FALSE,FALSE,Gradient-EM Bayesian Meta-Learning,Algorithms -> Meta-Learning,Algorithms -> Few-Shot Learning; Algorithms -> Multitask and Transfer Learning; Probabilistic Methods -> Bayesian Theory; Probabilistic Methods -> Variational Inference; Reinforcement Learning and Planning -> Reinforcement Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yayi Zou', ' Xiaoqi Lu']","{'Didi Research America', 'Columbia University'}",1,1,1,{'USA'}
Logarithmic Regret Bound in Partially Observable Linear Dynamical Systems,"Ali Sahin Lale, Kamyar Azizzadenesheli, Babak Hassibi, Anima Anandkumar",Logarithmic Regret Bound in Partially Observable Linear Dynamical Systems,ef8b5fcc338e003145ac9c134754db71,https://proceedings.neurips.cc/paper/2020/file/ef8b5fcc338e003145ac9c134754db71-Paper.pdf,"In this work, we study the two open problems regarding the system identification and the adaptive control in partially observable linear dynamical systems. In the system identification front, we provide the first estimation method that provides finite-time guarantees in estimating the model parameters from the data collected by using a controller that acts based on history of inputs and outputs (closed- loop control). We believe this result is crucial in both theory and practice fronts. It opens doors for developing efficient interactive learning algorithms, that adaptively utilize past experiences to improve performance. We provide our estimation method, using a different representation of the system. We believe the idea of using different representations would inspire new advancements in future methods in system identification. Moreover, this result provides a solution with theoretical guarantees to a practical problem. In real-world system identification problems, the system is not usually stable and a stabilizing controller is required for data collection to avoid catastrophic results in data collection, e.g. a robot learning to accomplish a task using a stabilizing controller. Prior methods cannot provide finite-sample guarantees in learning dynamics of this setting. However, our novel method provides guarantees in this setting and we think this will be useful in designing policies in many similar RL tasks. In adaptive control front, we deploy our novel estimation method in an RL algorithm and show that how it can significantly improve the performance. We believe the structure of our algorithm can inspire new developments of RL algorithms in high dimensional and realistic environment when the whole system is not fully observable by the decision making agent.",9 Broader Impact,267,12,,,FALSE,FALSE,FALSE,Logarithmic Regret Bound in Partially Observable Linear Dynamical Systems,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Decision and Control; Theory -> Control Theory,Reinforcement learning and planning,"['Ali Sahin Lale', ' Kamyar Azizzadenesheli', ' Babak Hassibi', ' Anima Anandkumar']","{'California Institute of Technology', 'Caltech', 'NVIDIA / Caltech'}",1,1,1,{'USA'}
Linearly Converging Error Compensated SGD,"Eduard Gorbunov, Dmitry Kovalev, Dmitry Makarenko, Peter Richtarik",Linearly Converging Error Compensated SGD,ef9280fbc5317f17d480e4d4f61b3751,https://proceedings.neurips.cc/paper/2020/file/ef9280fbc5317f17d480e4d4f61b3751-Paper.pdf,"Our contribution is primarily theoretical. Therefore, a broader impact discussion is not applicable.",Broader Impact,13,2,TRUE,FALSE,FALSE,FALSE,FALSE,Linearly Converging Error Compensated SGD,Optimization -> Stochastic Optimization,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Eduard Gorbunov', ' Dmitry Koralev', ' Dmitry Makarenko', ' Peter Richtarik']","{'Moscow Institute of Physics and Technology', 'MIPT', 'KAUST'}",1,0,0,"{'Russia', 'Saudi Arabia'}"
Canonical 3D Deformer Maps: Unifying parametric and non-parametric methods for dense weakly-supervised category reconstruction,"David Novotny, Roman Shapovalov, Andrea Vedaldi",Canonical 3D Deformer Maps: Unifying parametric and non-parametric methods for dense weakly-supervised category reconstruction,efe34c4e2190e97d1adc625902822b13,https://proceedings.neurips.cc/paper/2020/file/efe34c4e2190e97d1adc625902822b13-Paper.pdf,"Our work achieves better image-based 3D reconstruction than the existing technology, which is already available to the wider public. While we outperform existing methods on benchmarks, however, the capabilities of our algorithm are not sufficiently different to be likely to open new possibilities for misuse. Our method interprets images and reconstructs objects in 3D. This is conceivably useful in many applications, from autonomy to virtual and augmented reality. Likewise, it is possible that this technology, as any other, could be misused. However, we do not believe that our method is more prone to misuse than most contributions to machine learning. As for any research output, there is an area of uncertainty on how our contributions could be incorporated in future research work and the consequent impact of that. We believe that our advances are methodologically significant, and thus we hope to have a positive impact in the community, leading to further developments down the line. However, it is very difficult to predict the nature of all such possible developments.",Potential broader impact,169,9,,,FALSE,FALSE,FALSE,Canonical 3D Deformer Maps: Unifying parametric and non-parametric methods for dense weakly-supervised category reconstruction,Applications -> Computer Vision,Algorithms -> Representation Learning,Vision,"['David Novotny', ' Roman Shapovalov', ' Andrea Vedaldi']","{'University of Oxford / Facebook AI Research', 'Facebook AI Research'}",1,1,1,"{'UK', 'USA'}"
A Self-Tuning Actor-Critic Algorithm,"Tom Zahavy, Zhongwen Xu, Vivek Veeriah, Matteo Hessel, Junhyuk Oh, Hado P. van Hasselt, David Silver, Satinder Singh",A Self-Tuning Actor-Critic Algorithm,f02208a057804ee16ac72ff4d3cec53b,https://proceedings.neurips.cc/paper/2020/file/f02208a057804ee16ac72ff4d3cec53b-Paper.pdf,"The last decade has seen significant improvements in Deep Reinforcement Learning algorithms. To make these algorithms more general, it became a common practice in the DRL community to measure the performance of a single DRL algorithm by evaluating it in a diverse set of environments, where at the same time, it must use a single set of hyperparameters. That way, it is less likely to overfit the agent’s hyperparameters to specific domains, and more general properties can be discovered. These principles are reflected in popular DRL benchmarks like the ALE and the DM control suite. In this paper, we focus on exactly that goal and design a self-tuning RL agent that performs well across a diverse set of environments. Our agent starts with a global loss function that is shared across the environments in each benchmark. But then, it has the flexibility to self-tune this loss function, separately in each domain. Moreover, it can adapt its loss function within a single lifetime to account for inherent non-stationarities in RL algorithms - exploration vs. exploitation, changing data distribution, and degree of off-policy. While using meta-learning to tune hyperparameters is not new, we believe that we have made significant progress that will convince many people in the DRL community to use metagradients. We demonstrated that our agent performs significantly better than the baseline algorithm in four benchmarks. The relative improvement is much more significant than in previous metagradient papers and is demonstrated across a wider range of environments. While each of these benchmarks is diverse on its own, together, they give even more significant evidence to our approach’s generality. Furthermore, we show that it’s possible to self-tune tenfold more metaparameters from different types. We also showed that we gain improvement from self-tuning various subsets of the meta parameters, and that performance kept improving as we self-tuned more metaparameters. Finally, we have demonstrated how embracing self-tuning can help to introduce new concepts (leaky V-trace and parameterized auxiliary tasks) to RL algorithms without needing tuning.",6 Broader Impact,331,15,,,FALSE,FALSE,FALSE,A Self-Tuning Actor-Critic Algorithm,Reinforcement Learning and Planning,Algorithms -> Meta-Learning,Reinforcement learning and planning,"['Tom Zahavy', ' Zhongwen Xu', ' Vivek Veeriah', ' Matteo Hessel', ' Junhyuk Oh', ' Hado van Hasselt', ' David Silver', ' Satinder Singh']","{'Technion', 'Google DeepMind', 'DeepMind', 'University of Michigan'}",1,1,1,"{'UK', 'USA', 'Israel'}"
The Cone of Silence: Speech Separation by Localization,"Teerapat Jenrungrot, Vivek Jayaram, Steve Seitz, Ira Kemelmacher-Shlizerman",The Cone of Silence: Speech Separation by Localization,f056bfa71038e04a2400266027c169f9,https://proceedings.neurips.cc/paper/2020/file/f056bfa71038e04a2400266027c169f9-Paper.pdf,"We believe that our method has the potential to help people hear better in a variety of everyday scenarios. This work could be integrated with headphones, hearing aids, smart home devices, or laptops, to facilitate source separation and localization. Our localization output also provides a more privacy-friendly alternative to camera based detection for applications like robotics or optical tracking. We note that improved ability to separate speakers in noisy environments comes with potential privacy concerns. For example, this method could be used to better hear a conversation at a nearby table in a restaurant. Tracking speakers with microphone input also presents a similar range of privacy concerns as camera based tracking and recognition in everyday environments.",Broader Impact Statement,116,6,,,FALSE,TRUE,FALSE,The Cone of Silence: Speech Separation by Localization,Applications -> Audio and Speech Processing,,Audio / Music / Speech,"['Teerapat Jenrungrot', ' Vivek Jayaram', ' Steve Seitz', 'Shlizerman']",{'University of Washington'},1,0,0,{'USA'}
High-Dimensional Bayesian Optimization via Nested Riemannian Manifolds,"Noémie Jaquier, Leonel Rozo",High-Dimensional Bayesian Optimization via Nested Riemannian Manifolds,f05da679342107f92111ad9d65959cd3,https://proceedings.neurips.cc/paper/2020/file/f05da679342107f92111ad9d65959cd3-Paper.pdf,"The HD-GaBO formulation presented in this paper makes a step towards more explainable and interpretable BO approaches. Indeed, in addition to the benefits in terms of performance, the inclusion of domain knowledge via Riemannian manifolds into the BO framework permits to treat the space parameters in a principled way. This can notably be contrasted with approaches based on random features, that generally remain hard to interpret for humans. As often, the gains in terms of explainability and interpretability come at the expense of the low computational cost that characterizes random-based approaches. However, the carbon footprint of the proposed approach remains low compared to many deep approaches used nowadays in machine learning applications.",Broader Impact,112,5,,,FALSE,FALSE,FALSE,High-Dimensional Bayesian Optimization via Nested Riemannian Manifolds,Algorithms -> Bandit Algorithms,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Probabilistic Methods -> Gaussian Processes,Optimization Methods (continuous or discrete),"['Noémie Jaquier', ' Leonel Rozo']","{'Karlsruhe Institute of Technology', 'Bosch Center for Artificial Intelligence'}",1,1,1,{'Germany'}
Train-by-Reconnect: Decoupling Locations of Weights from Their Values,"Yushi Qiu, Reiji Suda",Train-by-Reconnect: Decoupling Locations of Weights from Their Values,f0682320ccbbb1f1fb1e795de5e5639a,https://proceedings.neurips.cc/paper/2020/file/f0682320ccbbb1f1fb1e795de5e5639a-Paper.pdf,"The hardware implementation [8, 3, 44] can exploit the inherently distributed computation and memory components of DNNs. On the other hand, implementations of physical neural networks usually face difficulties when building a large number of neurons and weighted connections while guaranteeing its reconfigurability [39]. In this work, we presented a novel method that achieved promising results on a variety of convolutional neural architectures by reconnecting random weights. Consequently, for a DNN existing in the physical world to be made of a set of neurons, where each neuron owns a set of neuron connections that is made of different materials functioning as random weights, we can modify such a neural network to perform well for different image classification tasks by simply reconnecting its neurons. Our work might inspire alternative physical weight connection implementations. For example, we could replace sophisticated electrical adjustable weight devices with fixed weight devices and let a permutation circuit control the flow of the input to the weights. When the network needs to function differently, we could directly update the configuration of the permutation circuit without having to rebuild the network. This approach would potentially enable reconfigurable physical neural networks to be produced and deployed at a lower cost. However, such a system may be specifically vulnerable to common security risks associated with DNNs, such as adversarial attacks [12], as it might be difficult to regulate their usage and update them in a timely manner with improved adversarial robustness, as compared with their software-based counterpart. On the bright side, in addition to the obvious benefits, e.g., fast inference, that a physical neural network could offer, they could potentially be made into a new type of puzzle game or Lego ® -like educational toy. This could benefit children, hobbyists, and experts who would like to tweak an physical artificial neural network to study how it works. In Section 5.5, and Figure 10, we have obtained a simple network F 1 made of around 3000 neuron connections with a single shared weight value, which is able to achieve over 85% accuracy using the MNIST dataset. They can be reconnected for classifying other data, e.g., Fashion-MNIST [50]. Since jigsaw puzzles on today’s market come in sizes of 1000~40,000 pieces, assuming a sufficiently advanced technology in the future for producing permutation-based artificial neural networks, 3000 might not be an impressively large number.",Broader Impact,390,14,,,FALSE,FALSE,FALSE,Train-by-Reconnect: Decoupling Locations of Weights from Their Values,Deep Learning,"Algorithms -> Stochastic Methods; Applications -> Computer Vision; Deep Learning -> Visualization, Interpretability, and Explainability; Optimization -> Stochastic Optimization",Deep learning,"['Yushi Qiu', ' Reiji Suda']","{'University of Tokyo', 'The University of Tokyo'}",1,0,0,{'Japan'}
Learning discrete distributions: user vs item-level privacy,"Yuhan Liu, Ananda Theertha Suresh, Felix Xinnan X. Yu, Sanjiv Kumar, Michael Riley",Learning discrete distributions: user vs item-level privacy,f06edc8ab534b2c7ecbd4c2051d9cb1e,https://proceedings.neurips.cc/paper/2020/file/f06edc8ab534b2c7ecbd4c2051d9cb1e-Paper.pdf,"In this work, we propose algorithms that have better privacy-utility trade-offs under global differential privacy compared to those of standard algorithms. Privacy-aware techniques are crucial for widespread use of machine learning leveraging user data. While our work is theoretical in nature, we hope that having higher utility private algorithms would encourage more practitioners to adopt user-level differential privacy in their applications.",7 Broader impact,61,3,,,FALSE,FALSE,FALSE,Learning discrete distributions: user vs item-level privacy,Theory -> Frequentist Statistics,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security; Theory -> Information Theory","Social aspects of machine learning (e.g., fairness, safety, privacy)","['Yuhan Liu', ' Ananda Theertha Suresh', ' Felix Xinnan Yu', ' Sanjiv Kumar', ' Michael D Riley']","{'Google', 'Google Research', 'Cornell University'}",1,1,1,{'USA'}
Matrix Completion with Quantified Uncertainty through Low Rank Gaussian Copula,"Yuxuan Zhao, Madeleine Udell",Matrix Completion with Quantified Uncertainty through Low Rank Gaussian Copula,f076073b2082f8741a9cd07b789c77a0,https://proceedings.neurips.cc/paper/2020/file/f076073b2082f8741a9cd07b789c77a0-Paper.pdf,"In principle, this paper may benefit any research or practical projects that requires imputing missing values, especially on large scale datasets. The quantified uncertainty may serve as a step to exclude unreliable imputed entries or provide confidence levels after imputation. In areas in which unreliable imputation could have adverse effect on people’s lives, such as healthcare datasets, quantified uncertainty is important to aid related decision making. On the other hand, if model assumptions are not met and the resulting quantified uncertainty estimate is not accurate, it may incorrectly lead a practitioner to trust certain entries and distrust others entries when the opposite is true. This problem may be mitigated by running some experiments on a validation set to check whether the proposed method works well on the particular dataset.",Broader Impact,129,5,,,FALSE,FALSE,FALSE,Matrix Completion with Quantified Uncertainty through Low Rank Gaussian Copula,Algorithms -> Missing Data,Algorithms -> Collaborative Filtering; Algorithms -> Uncertainty Estimation; Applications -> Recommender Systems; Probabilistic Methods -> Latent Variable Models,Probabilistic methods and inference,"['Yuxuan Zhao', ' Madeleine Udell']",{'Cornell University'},1,0,0,{'USA'}
Sparse and Continuous Attention Mechanisms,"André Martins, António Farinhas, Marcos Treviso, Vlad Niculae, Pedro Aguiar, Mario Figueiredo",Sparse and Continuous Attention Mechanisms,f0b76267fbe12b936bd65e203dc675c1,https://proceedings.neurips.cc/paper/2020/file/f0b76267fbe12b936bd65e203dc675c1-Paper.pdf,"We discuss the broader impact of our work, including ethical aspects and future societal consequences. Given the early stage of our work and its predominantly theoretical nature, the discussion is mostly speculative. The continuous attention models developed in our work can be used in a very wide range of applications, including natural language processing, computer vision, and others. For many of these applications, current state-of-the-art models use discrete softmax attention, whose interpretation capabilities have been questioned in prior work [43, 44, 45]. Our models can potentially lead to more interpretable decisions, since they lead to less scattered attention maps (as shown in our Figures 2–3) and are able to select contiguous text segments or image regions. As such, they may provide better inductive bias for interpretation. In addition, our attention densities using Gaussian and truncated paraboloids include a variance term, being potentially useful as a measure of confidence—for example, a large ellipse in an image may indicate that the model had little confidence about where it should attend to answer a question, while a small ellipse may denote high confidence on a particular object. We also see opportunities for research connecting our work with other continuous models [34, 35, 38] leading to end-to-end continuous models which, by avoiding discretization, have the potential to be less susceptible to adversarial attacks via input perturbations. Outside the machine learning field, the links drawn in §2 between sparse alternatives to softmax and models used in non-extensive (Tsallis) statistical physics suggest a potential benefit in that field too. Note, however, that our work is a first step into all these directions, and as such further investigation will be needed to better understand the potential benefits. We strongly recommend carrying out user studies before deploying any such system, to better understand the benefits and risks. Some of the examples in App. H may help understand potential failure modes. We should also take into account that, for any computer vision model, there are important societal risks related to privacy-violating surveillance applications. Continuous attention holds the promise to scale to larger and multi-resolution images, which may, in the longer term, be deployed in such undesirable domains. Ethical concerns hold for natural language applications such as machine translation, where biases present in data can be arbitrarily augmented or hidden by machine learning systems. For example, our natural language processing experiments mostly use English datasets (as a target language in machine translation, and in document classification). Further work is needed to understand if our findings generalize to other languages. Likewise, in the vision experiments, the VQA-v2 dataset uses COCO images, which have documented biases [46]. In line with the fundamental scope and early stage of this line of research, we deliberately choose applications on standard benchmark datasets, in an attempt to put as much distance as possible from malevolent applications. Finally, although we chose the most widely used evaluation metrics for each task (accuracy for document classification and visual question answering, BLEU for machine translation), these metrics do not always capture performance quality—for example, BLEU in machine translation is far from being a perfect metric. The data, memory, and computation requirements for training systems with continuous attention do not seem considerably higher than the ones which use discrete attention. On the other hand, for NLP applications, our approach has the potential to better compress sequential data, by using fewer basis functions than the sequence length (as suggested by our document classification experiments). While there is nothing specific about our research that poses environmental concerns or that promises to alleviate such concerns, our models share the same problematic property as other neural network models in terms of their energy consumption to train models and tune hyperparameters [47].",Broader Impact,616,24,,,FALSE,FALSE,FALSE,Sparse and Continuous Attention Mechanisms,Deep Learning -> Attention Models,Theory -> Statistical Physics of Learning,Deep learning,"['André Martins', ' Marcos Treviso', ' António Farinhas', ' Vlad Niculae', ' Mario Figueiredo', ' Pedro Aguiar']","{'Instituto de Telecomunicações, LUMIS Instituto Superior Técnico, Unbabel', 'University of Lisbon', 'Instituto de Telecomunicações', 'Instituto Superior Técnico', 'Instituto de Telecomunicacoes'}",1,1,1,"{'France', 'Portugal'}"
Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection,"Xiang Li, Wenhai Wang, Lijun Wu, Shuo Chen, Xiaolin Hu, Jun Li, Jinhui Tang, Jian Yang",Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection,f0bda020d2470f2e74990a07a607ebd9,https://proceedings.neurips.cc/paper/2020/file/f0bda020d2470f2e74990a07a607ebd9-Paper.pdf,"Superior performances for object detection tasks indeed have some societal consequences. Specifically for our work, we push the boundary of accuracy-speed for dense detectors to a new level by generating a fast and also accurate object detector. The improved detector can have benefits for a range of fields that involves object recognition tasks, e.g., vision-based self-driving or visual navigation, to avoid accidents and ensure human safety. Further, the ideas of (1) improving representations via a joint formulation for classification and localization quality and (2) directly learning the arbitrary distribution of box locations potentially demonstrate many insights and can inspire more thinking on the representation learning of the computer vision community. Finally, the technique in this paper has no obvious negative ethical and harmful social impact.",Broader Impact,125,5,,,TRUE,TRUE,FALSE,Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection,Applications -> Computer Vision,Applications -> Object Detection,Vision,"['Xiang Li', ' Wenhai Wang', ' Lijun Wu', ' Shuo Chen', ' Xiaolin Hu', ' Jun Li', ' Jinhui Tang', ' Jian Yang']","{'NJUST', 'Sun Yat-sen University', 'Nanjing University', 'Tsinghua University', 'Nanjing University of Science and Technology'}",1,0,0,{'China'}
Learning by Minimizing the Sum of Ranked Range,"Shu Hu, Yiming Ying, xin wang, Siwei Lyu",Learning by Minimizing the Sum of Ranked Range,f0d7053396e765bf52de12133cf1afe8,https://proceedings.neurips.cc/paper/2020/file/f0d7053396e765bf52de12133cf1afe8-Paper.pdf,"Loss functions are fundamental components in any machine learning system. Our work, by designing new types of loss functions based on the use of SoRR , is expected to be applicable to a wide range of ML problems. The benefit of using our method is the better handling of potential outliers in the training dataset, which could be the result of gross error or intentional “poisoning” of the dataset. However, there is also a risk of resulting a biased learning model when certain training samples are excluded. To mitigate such risks, we encourage further study to understand the impacts of using SoRR based losses in particular real-world scenarios, focusing on the more contextually meaning choice of the values m and k for better tradeoff of robustness and bias.  Acknowledgments . We are grateful to all anonymous reviewers for their constructive comments. This work is supported by NSF research grants (IIS-1816227 and IIS-2008532) as well as an Army Research Office grant (agreement number: W911 NF-18-1-0297).",6 Broader Impact,164,8,,,FALSE,FALSE,FALSE,Learning by Minimizing the Sum of Ranked Range,Algorithms -> Classification,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Shu Hu', ' Yiming Ying', ' xin wang', ' Siwei Lyu']","{'State University of New York at Albany', 'CuraCloud', 'University at Albany', 'University at Buffalo, State University of New York'}",1,1,1,{'USA'}
Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations,"Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, mingyan liu, Duane Boning, Cho-Jui Hsieh",Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations,f0eb6568ea114ba6e293f903c34d7488,https://proceedings.neurips.cc/paper/2020/file/f0eb6568ea114ba6e293f903c34d7488-Paper.pdf,"Reinforcement learning is a central part of modern artificial intelligence and is still under heavy development in recent years. Unlike supervised learning which has been widely deployed in many commercial and industrial applications, reinforcement learning has not been widely accepted and deployed in real-world settings. Thus, the study of reinforcement learning robustness under the adversarial attacks settings receives less attentions than the supervised learning counterparts. However, with the recent success of reinforcement learning on many complex games such as Go [65], StartCraft [73] and Dota 2 [6], we will not be surprised if we will see reinforcement learning (especially, deep reinforcement learning) being used in everyday decision making tasks in near future. The potential social impacts of applying reinforcement learning agents thus must be investigated before its wide deployment. One important aspect is the trustworthiness of an agent, where robustness plays a crucial rule. The robustness considered in our paper is important for many realistic settings such as sensor noise, measurement errors, and man-in-the-middle (MITM) attacks for a DRL system. if the robustness of reinforcement learning can be established, it has the great potential to be applied into many mission-critical tasks such as autonomous driving [60, 56, 85] to achieve superhuman performance. On the other hand, one obstacle for applying reinforcement learning to real situations (beyond games like Go and StarCraft) is the “reality gap”: a well trained reinforcement learning agent in a simulation environment can easily fail in real-world experiments. One reason for this failure is the potential sensing errors in real-world settings; this was discussed as early as in Brooks [8] in 1992 and still remains an open challenge now. Although our experiments were done in simulated environments, we believe that a smoothness regularizer like the one proposed in our paper can also benefit agents tested in real-world settings, such as robot hand manipulation [2].",Broader Impact,307,11,,,FALSE,FALSE,FALSE,Robust Deep Reinforcement Learning against Adversarial Perturbations on State Observations,Social Aspects of Machine Learning -> AI Safety,Algorithms -> Adversarial Learning,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Huan Zhang', ' Hongge Chen', ' Chaowei Xiao', ' Bo Li', ' mingyan liu', ' Duane Boning', 'Jui Hsieh']","{'UIUC', 'UCLA', 'University of Michigan, Ann Arbor', 'university of Michigan, Ann Arbor', 'Massachusetts Institute of Technology', 'MIT'}",1,0,0,{'USA'}
Understanding Anomaly Detection with Deep Invertible Networks through Hierarchies of Distributions and Features,"Robin Schirrmeister, Yuxuan Zhou, Tonio Ball, Dan Zhang",Understanding Anomaly Detection with Deep Invertible Networks through Hierarchies of Distributions and Features,f106b7f99d2cb30c3db1c3cc0fde9ccb,https://proceedings.neurips.cc/paper/2020/file/f106b7f99d2cb30c3db1c3cc0fde9ccb-Paper.pdf,"A better understanding of deep generative networks with regards to anomaly detection can help the machine learning research community in multiple ways. It allows to estimate which tasks deep generative networks may be suitable or unsuitable for when trained via maximum likelihood. With regards to that, our work helps more precisely understand the outcomes of maximum likelihood training. This more precise understanding can also help guide the design of training regimes that combine maximum likelihood training with other objectives depending on the task, if the task is unlikely to be solved by maximum likelihood training alone. Anomaly detection in general itself has positive uses. For example, detecting anomalies in medical data can detect existing and developing medical problems earlier. Safety of machine learning systems in healthcare, autonomous driving, etc., can be improved by detecting if they are processing data that is unlike their training distribution. Negative uses and consequences of anomaly detection can be that it allows tighter control of people by those with access to large computer and data, as they can more easily find unusual patterns deviating from the norm. For example, it may also allow health insurance companies to detect unusual behavioral patterns and associate them with higher insurance costs. Similarly repressive governments may detect unusual behavioral patterns to target tighter surveillance. These developments may be steered in a better direction by a better public understanding and regulation for what purpose anomaly-detection machine-learning systems are developed and used.",Broader Impact,241,11,,,FALSE,FALSE,FALSE,Understanding Anomaly Detection with Deep Invertible Networks through Hierarchies of Distributions and Features,Deep Learning -> Generative Models,Algorithms -> Density Estimation; Deep Learning -> Analysis and Understanding of Deep Networks,Deep Anomaly Detection,"['Robin T Schirrmeister', ' Yuxuan Zhou', ' Tonio Ball', ' Dan Zhang']","{'Albert-Ludwigs-University', 'Bosch Center for Artificial Intelligence', 'University Medical Center Freiburg', 'Stuttgart University'}",1,1,1,{'Germany'}
Fair Hierarchical Clustering,"Sara Ahmadian, Alessandro Epasto, Marina Knittel, Ravi Kumar, Mohammad Mahdian, Benjamin Moseley, Philip Pham, Sergei Vassilvitskii, Yuyan Wang",Fair Hierarchical Clustering,f10f2da9a238b746d2bac55759915f0d,https://proceedings.neurips.cc/paper/2020/file/f10f2da9a238b746d2bac55759915f0d-Paper.pdf,"Our work builds upon a long line of work of fairness in machine learning. See the excellent books by Kearns and Roth [27], and Barocas et al. [7] for a rich introduction to the field. Our aim in this work is algorithmic in nature, finding near-optimal hierarchical clustering algorithms that attain certain fairness guarantees. Since these methods are common unsupervised learning primitives, it is important to develop tools for practitioners to use. At the same time we remark that just because an algorithm is proven to be “fair” under some definition, does not mean it can be applied blindly. As is now well known, [29], different fairness notions can be incompatible with each other. Moreover, fairness in machine learning is necessarily problem specific, and depends on the goals and the values of the person invoking the algorithm. While these facts are well established in the research community, they are far from common knowledge outside of it. Thus work on algorithmic notions of fairness runs the risk of someone treating the results as a silver bullet, and eschewing the deeper analysis that is necessary in any real world application.",Broader Impact,188,10,,,FALSE,FALSE,FALSE,Fair Hierarchical Clustering,"Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency",Algorithms -> Clustering,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Sara Ahmadian', ' Alessandro Epasto', ' Marina Knittel', ' Ravi Kumar', ' Mohammad Mahdian', ' Benjamin Moseley', ' Philip Pham', ' Sergei Vassilvitskii', ' Yuyan Wang']","{'Google', 'University of Maryland, College Park', 'Google Research', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Self-training Avoids Using Spurious Features Under Domain Shift,"Yining Chen, Colin Wei, Ananya Kumar, Tengyu Ma",Self-training Avoids Using Spurious Features Under Domain Shift,f1298750ed09618717f9c10ea8d1d3b0,https://proceedings.neurips.cc/paper/2020/file/f1298750ed09618717f9c10ea8d1d3b0-Paper.pdf,"Our work promotes robustness and fairness in machine learning. First, we study algorithms that make machine learning models robust when deployed in the real world. Second, our work addresses the scenario where the target domain is under-resourced and hence collecting labels is difficult. Third, our theoretical work guides efforts to mitigate dataset bias. We demonstrate that curating a diverse pool of unlabeled data from the true population can help combating existing bias in labeled datasets. We give conditions for when bias will be mitigated and when it will be reinforced or amplified by popular algorithms used in practice. We take a first step towards understanding and preventing the adverse effects of self-training.",Broader Impact,112,7,,,FALSE,FALSE,FALSE,Self-training Avoids Using Spurious Features Under Domain Shift,Theory -> Statistical Learning Theory,Theory,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yining Chen', ' Colin Wei', ' Ananya Kumar', ' Tengyu Ma']",{'Stanford University'},1,0,0,{'USA'}
Improving Online Rent-or-Buy Algorithms with Sequential Decision Making and ML Predictions,Soumya Banerjee,Improving Online Rent-or-Buy Algorithms with Sequential Decision Making and ML Predictions,f12a6a7477077af66212ef0813bcf332,https://proceedings.neurips.cc/paper/2020/file/f12a6a7477077af66212ef0813bcf332-Paper.pdf,The current paper presents theoretical results that revisits well known problems in computer science using established ideas from machine learning. Our work presents a transparent framework where online algorithms and predictions can be merged seamlessly to improve algorithmic performance. This can help with cost benefit analysis of deploying ML systems to boost performance in processes that require algorithmic decision making in the face of uncertain inputs. We do not see any conceivable way in which this work will put any section of society at a disadvantage or amplify biases in input data.,Broader Impact,92,4,,,FALSE,FALSE,FALSE,Improving Online Rent-or-Buy Algorithms with Sequential Decision Making and ML Predictions,Algorithms,Algorithms -> Boosting and Ensemble Methods; Algorithms -> Online Learning,Algorithms,['Soumya Banerjee'],"{'Minnesota State University, Mankato'}",1,0,0,{'USA'}
CircleGAN: Generative Adversarial Learning across Spherical Circles,"Woohyeon Shim, Minsu Cho",CircleGAN: Generative Adversarial Learning across Spherical Circles,f14bc21be7eaeed046fed206a492e652,https://proceedings.neurips.cc/paper/2020/file/f14bc21be7eaeed046fed206a492e652-Paper.pdf,"This work addresses the problem of generative modeling and adversarial learning, which is a crucial topic in machine learning and artificial intelligence; b) the proposed technique is generic and does not have any direct negative impact on society; c) the proposed model improves sample diversity, thus contributing to reducing biases in generated data samples.",Broader Impact,54,1,FALSE,FALSE,FALSE,FALSE,FALSE,CircleGAN: Generative Adversarial Learning across Spherical Circles,Deep Learning -> Generative Models,Deep Learning -> Adversarial Networks,Deep learning,"['Woohyeon Shim', ' Minsu Cho']","{'Postech', 'POSTECH'}",1,0,0,{'France'}
WOR and pp's: Sketches for ℓpℓp-Sampling Without Replacement,"Edith Cohen, Rasmus Pagh, David Woodruff",WOR and p ’s: Sketches for p -Sampling Without Replacement,f1507aba9fc82ffa7cc7373c58f8a613,https://proceedings.neurips.cc/paper/2020/file/f1507aba9fc82ffa7cc7373c58f8a613-Paper.pdf,Broader Impact Discussion is not applicable. We presented a method for WOR sampling that has broad applications in ML. But this is a technical paper with no particular societal implications.,8 Broader Impact,30,3,TRUE,FALSE,FALSE,FALSE,FALSE,WOR and $p$'s: Sketches for $\ell_p$-Sampling Without Replacement,Algorithms,Algorithms -> Data Compression; Algorithms -> Sparsity and Compressed Sensing,Theory (including computational and statistical analyses),,"{'Google', 'IT University of Copenhagen', 'Carnegie Mellon University'}",1,1,1,"{'USA', 'Denmark'}"
Hypersolvers: Toward Fast Continuous-Depth Models,"Michael Poli, Stefano Massaroli, Atsushi Yamashita, Hajime Asama, Jinkyoo Park",Hypersolvers: Toward Fast Continuous-Depth Models,f1686b4badcf28d33ed632036c7ab0b8,https://proceedings.neurips.cc/paper/2020/file/f1686b4badcf28d33ed632036c7ab0b8-Paper.pdf,"Major application areas for continuous deep learning architectures so far have been generative modeling (Grathwohl et al., 2018) and forecasting, particularly in the context of patient medical data (Jia & Benson, 2019). While these models have an intrinsic interpretability advantages over discrete counterparts, it is important that future iterations preserve these properties in the search for greater scalability. Early adoption of the hypersolver paradigm would speed up widespread utilization of Neural ODEs in these domains, ultimately leading to positive impact in healthcare applications. Accurate forecasting is at the foundation of system identification and control, two additional application areas set to be greatly impacted by continuous models. Unfortunately, theoretical guarantees of robustness in the worst–case scenario are challenging to construct for data–driven approaches. As these approaches are refined, they are also likely to negatively impact the employment market by accelerating job automation in critical areas.",Broader Impact,144,6,,,FALSE,FALSE,FALSE,Hypersolvers: Toward Fast Continuous-Depth Models,Algorithms -> Dynamical Systems,Deep Learning -> Efficient Inference Methods,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Michael Poli', ' Stefano Massaroli', ' Atsushi Yamashita', ' edit Hajime Asama', ' Jinkyoo Park']","{'The University of Tokyo', 'KAIST'}",1,0,0,"{'Japan', 'South Korea'}"
Log-Likelihood Ratio Minimizing Flows: Towards Robust and Quantifiable Neural Distribution Alignment,"Ben Usman, Avneesh Sud, Nick Dufour, Kate Saenko",Log-Likelihood Ratio Minimizing Flows: Towards Robust and Quantifiable Neural Distribution Alignment,f169b1a771215329737c91f70b5bf05c,https://proceedings.neurips.cc/paper/2020/file/f169b1a771215329737c91f70b5bf05c-Paper.pdf,"Many recent advances in deep learning rely heavily on large labeled datasets. Unfortunately, in many important problem domains, such as medical imaging, labeling costs and high variability of target environments, such as differences in image capturing medical equipment, prohibit widespread adoption of these novel deep image processing techniques. Our work proposes a deep domain adaptation method that brings together verifiable convergence, as in older non-parametric methods, and meaningful priors over the structure of aligned datasets from deep adversarial alignment models.  Of course, none of aforementioned advancements can guarantee perfect semantic alignment, therefore manual evaluation in critical applications, such as medical diagnosis, is still required. However, improved interpretability that comes from having a single minimization objective would definitely ease the adoption of such methods by making validation and model selection more straightforward, as well as reducing the chance of deploying a silently failing model due to human evaluator error. As with the majority of deep models, our model might be susceptible to adversarial attacks by malicious agents, as well as privacy-related attacks, but properly addressing these issues, their consequences, and defence techniques goes far beyond the scope of this paper.",7 Broader Impact,189,6,,,FALSE,TRUE,FALSE,Log-Likelihood Ratio Minimizing Flows: Towards Robust and Quantifiable Neural Distribution Alignment,Algorithms -> Unsupervised Learning,Algorithms -> Adversarial Learning; Algorithms -> Density Estimation; Deep Learning -> Adversarial Networks; Probabilistic Methods,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Ben Usman', ' Avneesh Sud', ' Nick Dufour', ' Kate Saenko']","{'Google', 'Boston University', 'Boston University, Google AI', 'Google Research'}",1,1,1,{'USA'}
Escaping the Gravitational Pull of Softmax,"Jincheng Mei, Chenjun Xiao, Bo Dai, Lihong Li, Csaba Szepesvari, Dale Schuurmans",Escaping the Gravitational Pull of Softmax,f1cf2a082126bf02de0b307778ce73a7,https://proceedings.neurips.cc/paper/2020/file/f1cf2a082126bf02de0b307778ce73a7-Paper.pdf,"This research pursues a fundamental and mostly theoretical goal of understanding how a basic component in machine learning, the softmax transformation, impacts the convergence properties of subsequent optimization methods. The implications of this research are very high level and broad, since we investigate a widely used component. It is difficult to identify specific impacts, since this research does not target any specific application area that would directly impact people or society. If forced to make society level claims, we could attempt to claim that modifying architectures in ways that that improve optimization efficiency would have an effect on the overall energy footprint consumed by machine learning technologies, given how much computation is currently being expended on training softmax classifiers and policies.",Broader Impact,121,4,,,FALSE,FALSE,FALSE,Escaping the Gravitational Pull of Softmax,Reinforcement Learning and Planning -> Reinforcement Learning,,Reinforcement learning and planning,"['Jincheng Mei', ' Chenjun Xiao', ' Bo Dai', ' Lihong Li', ' Csaba Szepesvari', ' Dale Schuurmans']","{'Google Brain', 'University of Alberta', 'Google Research', 'DeepMind / University of Alberta'}",1,1,1,"{'Canada', 'UK', 'USA'}"
Regret in Online Recommendation Systems,"Kaito Ariu, Narae Ryu, Se-Young Yun, Alexandre Proutiere",Regret in Online Recommendation Systems,f1daf122cde863010844459363cd31db,https://proceedings.neurips.cc/paper/2020/file/f1daf122cde863010844459363cd31db-Paper.pdf,"This work, although mostly theoretical, may provide guidelines and insights towards an improved design of recommendation systems. The benefits of such improved design could be to increase user experience with these systems, and to help companies to improve their sales strategies through differentiated recommendations. The massive use of recommendation systems and its potential side effects have recently triggered a lot of interest. We must remain aware of and investigate such effects. These include: opinion polarization, a potential negative impact on users’ behavior and their willingness to pay, privacy issues.",Broader Impact,89,5,,,FALSE,FALSE,FALSE,Regret in Online Recommendation Systems,Algorithms -> Bandit Algorithms,Algorithms -> Clustering; Algorithms -> Collaborative Filtering; Algorithms -> Online Learning; Applications -> Recommender Systems,"Bandit Algorithms, Theoretical Analysis of Recommender Systems","['Kaito Ariu', ' Narae Ryu', 'Young Yun', ' Alexandre Proutiere']","{'KTH', 'KAIST'}",1,0,0,"{'Sweden', 'South Korea'}"
On Convergence and Generalization of Dropout Training,"Poorya Mianjy, Raman Arora",On Convergence and Generalization of Dropout Training,f1de5100906f31712aaa5166689bfdf4,https://proceedings.neurips.cc/paper/2020/file/f1de5100906f31712aaa5166689bfdf4-Paper.pdf,"We investigate the convergence and generalization of a popular algorithmic regularization technique in deep learning. Although we can not think of any direct social impacts per se, we hope such theoretical studies serve the community in long-term, by improving our understanding of the foundations, which shall eventually lead to more powerful machine learning systems.",Broader Impact,54,2,TRUE,TRUE,FALSE,FALSE,FALSE,On Convergence and Generalization of Dropout Training,Theory -> Regularization,Deep Learning -> Analysis and Understanding of Deep Networks,Theory (including computational and statistical analyses),"['Poorya Mianjy', ' Raman Arora']",{'Johns Hopkins University'},1,0,0,{'USA'}
Second Order PAC-Bayesian Bounds for the Weighted Majority Vote,"Andres Masegosa, Stephan Lorenzen, Christian Igel, Yevgeny Seldin",Second-Order Optimality in Non-Convex Decentralized Optimization via Perturbed Gradient Tracking,f1ea154c843f7cf3677db7ce922a2d17,https://proceedings.neurips.cc/paper/2020/file/f1ea154c843f7cf3677db7ce922a2d17-Paper.pdf,"Over the last couple of years we have witnessed an unprecedented increase in the amount of data collected and processed in order to tackle real life problems. Advances in numerous data-driven system such as the Internet of Things, health-care, multi-agent robotics wherein data are scattered across the agents (e.g., sensors, clouds, robots), and the sheer volume and spatial/temporal disparity of data render centralized processing and storage infeasible or inefficient. Compared to the typical parameter-server type distributed system with a fusion center, decentralized optimization has its unique advantages in preserving data privacy, enhancing network robustness, and improving the computation efficiency. Furthermore, in many emerging applications such as collaborative filtering, federated learning, distributed beamforming and dictionary learning, the data is naturally collected in a decentralized setting, and it is not possible to transfer the distributed data to a central location. Therefore, decentralized computation has sparked considerable interest in both academia and industry. At the same time convex formulations for training machine learning tasks have been replaced by nonconvex representations such as neural networks and a line of significant non convex problems are on the spotlight. Our paper contributes to this line of work and broadens the set of problems that can be successfully solved without the presence of a central coordinating authority in the aforementioned framework. The implications on the privacy of the agents are apparent while rendering the presence of an authority unnecessary has political and economical extensions. Furthermore, numerous applications are going to benefit from our result impacting society in many different ways.",7 Broader Impact,253,9,,,FALSE,FALSE,FALSE,Second Order PAC-Bayesian Bounds for the Weighted Majority Vote,Theory -> Statistical Learning Theory,Algorithms -> Boosting and Ensemble Methods,Theory (including computational and statistical analyses),"['Andres Masegosa', ' Stephan Lorenzen', ' Christian Igel', ' Yevgeny Seldin']","{'University of Almeria', 'University of Copenhagen'}",1,0,0,"{'Spain', 'Denmark'}"
Implicit Regularization in Deep Learning May Not Be Explainable by Norms,"Noam Razin, Nadav Cohen",Implicit Regularization in Deep Learning May Not Be Explainable by Norms,f21e255f89e0f258accbe4e984eef486,https://proceedings.neurips.cc/paper/2020/file/f21e255f89e0f258accbe4e984eef486-Paper.pdf,"The application of deep learning in practice is based primarily on trial and error, conventional wisdom and intuition, often leading to suboptimal performance, as well as compromise in important aspects such as safety, privacy and fairness. Developing rigorous theoretical foundations behind deep learning may facilitate a more principled use of the technology, alleviating aforementioned shortcomings. The current paper takes a step along this vein, by addressing the central question of implicit regularization induced by gradient-based optimization. While theoretical advances — particularly those concerned with explaining widely observed empirical phenomena — oftentimes do not pose apparent societal threats, a potential risk they introduce is misinterpretation by scientific readership. We have therefore made utmost efforts to present our results as transparently as possible.",Broader Impact,121,5,,,FALSE,FALSE,FALSE,Implicit Regularization in Deep Learning May Not Be Explainable by Norms,Deep Learning -> Analysis and Understanding of Deep Networks,Theory -> Models of Learning and Generalization,Theory (including computational and statistical analyses),"['Noam Razin', ' Nadav Cohen']",{'Tel Aviv University'},1,0,0,{'Israel'}
POMO: Policy Optimization with Multiple Optima for Reinforcement Learning,"Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon, Youngjune Gwon, Seungjai Min",POMO: Policy Optimization with Multiple Optima for Reinforcement Learning,f231f2107df69eab0a3862d50018a9b2,https://proceedings.neurips.cc/paper/2020/file/f231f2107df69eab0a3862d50018a9b2-Paper.pdf,"This work can facilitate the use of reinforcement learning approach based on deep neural net as a replacement for traditional heuristic methods used in operations of many sectors of business. Better and easier-to-use optimization tools will increase the productivity, but may lead to automation of works that previously needed more manual operations (jobs).",Broader Impact,53,2,FALSE,FALSE,FALSE,FALSE,FALSE,POMO: Policy Optimization with Multiple Optima for Reinforcement Learning,Optimization -> Discrete Optimization,Optimization; Reinforcement Learning and Planning; Reinforcement Learning and Planning -> Exploration,Reinforcement learning and planning,"['Dae Kwon', ' Jinho Choo', ' Byoungjip Kim', ' Iljoo Yoon', ' Youngjune Gwon', ' Seungjai Min']",{'Samsung SDS'},0,1,0,{'South Korea'}
Uncertainty-aware Self-training for Few-shot Text Classification,"Subhabrata Mukherjee, Ahmed Awadallah",Uncertainty-aware Self-training for Few-shot Text Classification,f23d125da1e29e34c552f448610ff25f,https://proceedings.neurips.cc/paper/2020/file/f23d125da1e29e34c552f448610ff25f-Paper.pdf,"In this work, we introduce a framework for self-training of neural language models with only a few labeled examples. This work is likely to increase the progress of NLP applications and drive the development of general-purpose language systems especially for domains with limited resources. While it is not only expensive to acquire large amounts of labeled data for every task and language, in many cases, we cannot perform large-scale labeling due to access constraints from privacy and compliance concerns. The latter concerns are amplified when dealing with sensitive user data for various personalization and recommendation tasks. Our framework helps in this regard for the NLP systems to obtain state-of-the-art-performance while alleviating privacy concerns. To this end, our framework can be used for applications in finance, legal, healthcare, retail and other domains where adoption of deep neural network may have been hindered due to lack of large-scale manual annotations on sensitive user data. While our framework accelerates the progress of NLP, it also suffers from associated societal implications of automation ranging from job losses for workers who provide annotations as a service as well as for other industries relying on human labor. Additionally, it suffers from similar concerns as with the use of NLP models by malicious agents for propagating bias, misinformation and indulging in other nefarious activities. However, many of these concerns can also be alleviated with our framework to develop better detection models and mitigation strategies with only a few representative examples of such intents.",Broader Impact,246,9,,,FALSE,FALSE,FALSE,Uncertainty-aware Self-training for Few-shot Text Classification,Applications -> Natural Language Processing,Algorithms -> Semi-Supervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,"{'Microsoft', 'Microsoft Research'}",1,1,1,{'USA'}
Learning to Learn with Feedback and Local Plasticity,"Jack Lindsey, Ashok Litwin-Kumar",Learning to Learn with Feedback and Local Plasticity,f291e10ec3263bd7724556d62e70e25d,https://proceedings.neurips.cc/paper/2020/file/f291e10ec3263bd7724556d62e70e25d-Paper.pdf,"While the eventual impacts of our work are hard to predict because of its theoretical nature, we hope that it represents a step toward a better understanding of biological learning algorithms. Such an understanding may lead to more flexible artificial systems as well as advances in basic neuroscience. One concern is that these and related methods are computationally expensive, and their widespread adoption at scale could lead to significant energy consumption and/or raise barriers to entry in this field of research. It remains to be seen whether algorithmic advances can mitigate this issue.",Broader Impact,93,4,,,FALSE,FALSE,FALSE,Learning to Learn with Feedback and Local Plasticity,Deep Learning -> Biologically Plausible Deep Networks,Algorithms -> Continual Learning; Algorithms -> Meta-Learning; Algorithms -> Online Learning; Deep Learning; Neuroscience and Cognitive Science -> Neuroscience; Neuroscience and Cognitive Science -> Plasticity and Adaptation,Neuroscience and cognitive science,"['Jack Lindsey', 'Kumar']",{'Columbia University'},1,0,0,{'USA'}
Every View Counts: Cross-View Consistency in 3D Object Detection with Hybrid-Cylindrical-Spherical Voxelization,"Qi Chen, Lin Sun, Ernest Cheung, Alan L. Yuille",Every View Counts: Cross-View Consistency in 3D Object Detection with Hybrid-Cylindrical-Spherical Voxelization,f2fc990265c712c49d51a18a32b39f0c,https://proceedings.neurips.cc/paper/2020/file/f2fc990265c712c49d51a18a32b39f0c-Paper.pdf,"3D detection is the first stage in the computational pipeline for a self-driving car. Just as perception enables humans to make instant associations and act on them, the ability to identify what and where the visual targets are from immediate surroundings is a fundamental pillar for the safe operation of an autonomous vehicle. The pandemic of COVID-19 manifests greater needs for autonomous driving and delivery robots, when contact-less delivery is encouraged. Though there is controversy about the ethics for autonomous vehicles especially for their decision making, robust 3D detection with higher accuracy is always desired to improve safety. In addition, LiDAR point clouds do not capture person identity and thus 3D detection on LiDAR point clouds does not involves privacy issue.",Broader Impact,121,5,,,FALSE,FALSE,FALSE,Every View Counts: Cross-View Consistency in 3D Object Detection with Hybrid-Cylindrical-Spherical Voxelization,Applications -> Object Detection,Applications -> Computer Vision,Vision,"['Qi Chen', ' Lin Sun', ' Ernest Cheung', ' Alan Yuille']","{'Samsung', 'Johns Hopkins University', 'Samsung, Stanford, HKUST'}",1,1,1,"{'Chile', 'South Korea', 'USA', 'China'}"
Sharper Generalization Bounds for Pairwise Learning,"Yunwen Lei, Antoine Ledent, Marius Kloft",Sharper Generalization Bounds for Pairwise Learning,f3173935ed8ac4bf073c1bcd63171f8a,https://proceedings.neurips.cc/paper/2020/file/f3173935ed8ac4bf073c1bcd63171f8a-Paper.pdf,This work does not present any foreseeable societal consequence.,7 Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Sharper Generalization Bounds for Pairwise Learning,Theory -> Statistical Learning Theory,Algorithms -> Ranking and Preference Learning; Algorithms -> Similarity and Distance Learning; Theory -> Computational Learning Theory; Theory -> Models of Learning and Generalization ; Theory -> Regularization,Theory (including computational and statistical analyses),"['Yunwen Lei', ' Antoine Ledent', ' Marius Kloft']","{'Technical University of Kaiserslautern', 'TU Kaiserslautern'}",1,0,0,{'Germany'}
A Measure-Theoretic Approach to Kernel Conditional Mean Embeddings,"Junhyung Park, Krikamol Muandet",A Measure-Theoretic Approach to Kernel Conditional Mean Embeddings,f340f1b1f65b6df5b5e3f94d95b11daf,https://proceedings.neurips.cc/paper/2020/file/f340f1b1f65b6df5b5e3f94d95b11daf-Paper.pdf,"The nature of this work is theoretical, and hence we do not feel it is applicable to discuss its broader societal impact.",Broader Impact,22,1,TRUE,FALSE,FALSE,FALSE,FALSE,A Measure-Theoretic Approach to Kernel Conditional Mean Embeddings,Algorithms -> Kernel Methods,Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Junhyung Park', ' Krikamol Muandet']","{'MPI for Intelligent Systems, Tübingen', 'Max Planck Institute for Intelligent Systems'}",1,0,0,{'Germany'}
Quantifying the Empirical Wasserstein Distance to a Set of Measures: Beating the Curse of Dimensionality,"Nian Si, Jose Blanchet, Soumyadip Ghosh, Mark Squillante",Quantifying the Empirical Wasserstein Distance to a Set of Measures: Beating the Curse of Dimensionality,f3507289cfdc8c9ae93f4098111a13f9,https://proceedings.neurips.cc/paper/2020/file/f3507289cfdc8c9ae93f4098111a13f9-Paper.pdf,"This is a theoretical contribution that, nevertheless, has the potential of impacting a wide range of application domains in business, engineering and science. In particular, all of those in which the Wasserstein distance has been extensively used as a statistical inference tool (e.g. image analysis and computer vision, signal processing, operations research, and so on). Because our paper provides a step towards breaking the curse of dimensionality in statistical rates of convergence, we believe that we have the potential of enabling more applications to multiple hypothesis testing (e.g., certifying Wasserstein GANs). In turn, we plan to improve human resource development by including some of the main findings in this paper in Ph.D. courses.",Broader Impact,113,4,,,FALSE,FALSE,FALSE,Quantifying the Empirical Wasserstein Distance to a Set of Measures: Beating the Curse of Dimensionality,Theory -> Large Deviations and Asymptotic Analysis,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Theory -> Models of Learning and Generalization ; Theory -> Spaces of Functions and Kernels; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Nian Si', ' Soumyadip Ghosh', ' Jose Blanchet', ' Mark Squillante']","{'Stanford University', 'IBM Research'}",1,1,1,{'USA'}
Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning,"Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, Bilal Piot, koray kavukcuoglu, Remi Munos, Michal Valko",Bootstrap Your Own Latent A New Approach to Self-Supervised Learning,f3ada80d5c4ee70142b17b8192b2958e,https://proceedings.neurips.cc/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf,"The presented research should be categorized as research in the field of unsupervised learning. This work may inspire new algorithms, theoretical, and experimental investigation. The algorithm presented here can be used for many different vision applications and a particular use may have both positive or negative impacts, which is known as the dual use problem. Besides, as vision datasets could be biased, the representation learned by BYOL could be susceptible to replicate these biases.",Broader impact,74,4,,,FALSE,FALSE,FALSE,Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning,Algorithms -> Unsupervised Learning,Algorithms -> Semi-Supervised Learning; Applications -> Computer Vision; Deep Learning,Deep learning,"['Bastien Grill', ' Florian Strub', ' Florent Altché', ' Corentin Tallec', ' Pierre Richemond', ' Elena Buchatskaya', ' Carl Doersch', ' Bernardo Avila Pires', ' Zhaohan Guo', ' Mohammad Gheshlaghi Azar', ' Bilal Piot', ' koray kavukcuoglu', ' Remi Munos', ' Michal Valko']","{'Imperial College', 'DeepMind', 'Deepmind'}",1,1,1,{'UK'}
Towards Theoretically Understanding Why Sgd Generalizes Better Than Adam in Deep Learning,"Pan Zhou, Jiashi Feng, Chao Ma, Caiming Xiong, Steven Chu Hong Hoi, Weinan E",Towards Theoretically Understanding Why S GD Generalizes Better Than A DAM in Deep Learning,f3f27a324736617f20abbf2ffd806f6d,https://proceedings.neurips.cc/paper/2020/file/f3f27a324736617f20abbf2ffd806f6d-Paper.pdf,"This work theoretically analyzes a fundamental problem in deep learning field, namely the generalization gap between adaptive gradient algorithms and S GD , and reveals the essential reasons for the generalization degeneration of adaptive algorithms. The established theoretical understanding of these algorithms may inspire new algorithms with both fast convergence speed and good generalization performance, which alleviate the need for computational resource and achieve state-of-the-art results. Yet it still needs more efforts to provide more insights to design practical algorithms.",Broader Impacts,80,3,,,FALSE,FALSE,FALSE,Towards Theoretically Understanding Why Sgd Generalizes Better Than Adam in Deep Learning,Deep Learning -> Optimization for Deep Networks,Deep Learning -> Analysis and Understanding of Deep Networks; Optimization -> Non-Convex Optimization,Deep learning,"['Pan Zhou', ' Jiashi Feng', ' Chao Ma', ' Caiming Xiong', ' Steven Chu Hong Hoi', ' Weinan E']","{'Salesforce', 'Princeton University', 'National University of Singapore'}",1,1,1,"{'Singapore', 'USA'}"
RSKDD-Net: Random Sample-based Keypoint Detector and Descriptor,"Fan Lu, Guang Chen, Yinlong Liu, Zhongnan Qu, Alois Knoll",RSKDD-Net: Random Sample-based Keypoint Detector and Descriptor,f40723ed94042ea9ea36bfb5ad4157b2,https://proceedings.neurips.cc/paper/2020/file/f40723ed94042ea9ea36bfb5ad4157b2-Paper.pdf,"The proposed RSKDD-Net provides an efficient scheme to detect keypoints and generate descriptors for large scale point cloud registration. The method is most likely to be applied to localization and mapping system of autonomous vehicles to reduce the computation of point cloud registration, which may promote the development of autonomous driving. The development of autonomous driving can reduce the workload of human drivers and the incidence of traffic accidents, however, can have an impact on the determination of liability for traffic accidents and results in unemployment of human drivers. Besides, the proposed method has also applications on unmanned aerial vehicles. However, unmanned aerial vehicles can be utilized in military field, thereby threatening human safety. We should explore more beneficial applications of this method, such as promoting the development of autonomous driving to improve the quality of human life and improve its safety to reduce accidents.",Broader Impact,145,6,,,FALSE,FALSE,FALSE,RSKDD-Net: Random Sample-based Keypoint Detector and Descriptor,Applications -> Computer Vision,Applications -> Robotics; Deep Learning -> Attention Models,Vision,"['Fan Lu', ' Guang Chen', ' Yinlong Liu', ' Zhongnan Qu', ' Alois Knoll']","{'ETH Zurich', 'Robotics and Embedded Systems', 'Technische Universität München', 'Tongji University'}",1,0,0,"{'China', 'Switzerland', 'Germany'}"
Efficient Clustering for Stretched Mixtures: Landscape and Optimality,"Kaizheng Wang, Yuling Yan, Mateo Diaz",Efficient Clustering for Stretched Mixtures: Landscape and Optimality,f40ee694989b3e2161be989e7b9907fc,https://proceedings.neurips.cc/paper/2020/file/f40ee694989b3e2161be989e7b9907fc-Paper.pdf,"This work presents a framework CURE for solving clustering problems which are ubiquitous in data science problems, especially in early stages of knowledge discovery. Thanks to its flexibility, CURE has potential applications in numerous fields including science, engineering, economics, sociology and so on. It can be easily integrated with other tools in machine learning and can be adapted to meet ethical and societal standards. Our theoretical analysis under a canonical model establishes guarantees for CURE and provides useful guidances to practitioners. Numerical experiments on image data demonstrate the remarkable efficacy of CURE. For better deployment of the system in sensitive real-world problems, we still need to ensure the reliability, quantify the uncertainty and develop diagnosis procedures in case of failure. These are fundamental questions worth investigation in the future.",Broader Impact,129,7,,,FALSE,FALSE,FALSE,Efficient Clustering for Stretched Mixtures: Landscape and Optimality,"Algorithms -> Components Analysis (e.g., CCA, ICA, LDA, PCA)",Algorithms -> Clustering; Algorithms -> Unsupervised Learning; Optimization -> Non-Convex Optimization,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Kaizheng Wang', ' Yuling Yan', ' Mateo Diaz']","{'Princeton University', 'Columbia University', 'Cornell University'}",1,0,0,{'USA'}
A Group-Theoretic Framework for Data Augmentation,"Shuxiao Chen, Edgar Dobriban, Jane Lee",A Group-Theoretic Framework for Data Augmentation,f4573fc71c731d5c362f0d7860945b88,https://proceedings.neurips.cc/paper/2020/file/f4573fc71c731d5c362f0d7860945b88-Paper.pdf,"Our probabilistic framework is to our knowledge the first of its kind to rigorously prove and quantify how data augmentation helps the learning task. Further, the invariance-variance tradeoff may provide new insight for how we think about choosing and composing transformations used in data augmentation. Since data augmentation is routinely used in modern deep learning pipelines and it is emerging in other applications, like self-supervised learning (see, e.g., [14]), our theoretical framework developed in this paper could potentially be used to provide guidance on the choice of the augmentation groups in these application domains. However, care must be taken when using our theories to develop new augmentation strategies. We’ve demonstrated that the benefits of data augmentation crucially depends on the invariance structures present in the data distribution — if one chooses an augmentation group which does not correctly capture the invariance structures, or if the data at hand simply has no such structures, then blindly using data augmentation can potentially harm the model performance. In this sense, domain expertise is required to fully harness the power of our theories.",Broader Impact,179,6,,,FALSE,FALSE,FALSE,A Group-Theoretic Framework for Data Augmentation,Deep Learning,Deep Learning -> Efficient Training Methods; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Shuxiao Chen', ' Edgar Dobriban', ' Jane Lee']",{'University of Pennsylvania'},1,0,0,{'USA'}
The Statistical Cost of Robust Kernel Hyperparameter Turning,"Raphael Meyer, Christopher Musco",The Statistical Cost of Robust Kernel Hyperparameter Tuning,f4661398cb1a3abd3ffe58600bf11322,https://proceedings.neurips.cc/paper/2020/file/f4661398cb1a3abd3ffe58600bf11322-Paper.pdf,"This is a theoretical paper, so discussion of broader impacts has to speculate on future applications for this broad line of research. In particular, this paper considers active regression that is robust and sample-efficient. In other words, we advance our understanding of learning patterns when samples are expensive and noise is large. We speculate on the various impacts of machine learning in these high-sample-cost and high-noise settings. One of the most common guiding positive benefits is the benefit to medical imaging, where instru- ments have biased noisy measurements and are expensive to run. So, having ML techniques with low sample complexity and high robustness can give medical practitioners high confidence in their medical conclusions while keeping costs low. However, this broad framework can just as easily apply to large-scale illegal surveillance through “Internet of Things” (IoT) devices. Many IoT devices are known to have cheap microphones, weak security, and internet access. Well crafted internet crawling code could plausibly access a massive number of such IoT devices, and hence be able to access a massive number of private microphones. Without progress in our line of research, it may be prohibitively expensive to process or store all the speech heard from all of these microphones. Alternatively, the internet download patterns might be too noticeable for such an operation to secretly run at a large scale. However, progress toward statistically efficient algorithms in the high-sample-cost and high-noise regime might allow code that sends very few messages online while still transmitting all the interesting audio to a third party. This would allow such illegal surveillance on a massive scale. Both of these settings, the medical and the surveillance, look equivalent from our current level of mathematical/statistical abstraction. Notably, our current research is still too abstract to directly benefit either application. It will require more research to connect results like ours to either the medical or the surveillance applications. Note that the specific examples of medical imaging and IoT surveillance are just two examples of highly positive or highly negative ML applications. So, under the assumption that the research community will focus on positive applications like medical imaging while avoiding negative applications like large scale IoT surveillance , we believe that the benefits of our theoretical research outweigh the negative potential ramifications. Admittedly, this may be an optimistic assumption.",Broader Impact,384,19,,,FALSE,FALSE,FALSE,The Statistical Cost of Robust Kernel Hyperparameter Turning,Theory,Algorithms -> Kernel Methods; Theory -> Models of Learning and Generalization ; Theory -> Spaces of Functions and Kernels; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Raphael Meyer', ' Christopher Musco']",{'New York University'},1,0,0,{'USA'}
How does Weight Correlation Affect Generalisation Ability of Deep Neural Networks?,"Gaojie Jin, Xinping Yi, Liang Zhang, Lijun Zhang, Sven Schewe, Xiaowei Huang",How does Weight Correlation Affect the Generalisation Ability of Deep Neural Networks?,f48c04ffab49ff0e5d1176244fdfb65c,https://proceedings.neurips.cc/paper/2020/file/f48c04ffab49ff0e5d1176244fdfb65c-Paper.pdf,"Our findings sharpen the theoretical and practical aspects of generalisation, one of the most important topics in machine learning: considering whether a trained model can be used on unseen data. Our findings can increase our understanding of the generalisation ability of deep learning and engender a broad discussion and in-depth research on how to improve the performance of deep learning. This can unfold impact, first within the machine learning community and subsequently—through the impact of machine leaning—to other academic disciplines and the industrial sectors. Beyond the improvements that always come with better models, we also provide a better estimation of the generalisation error, which in turn leads to improved quality guarantees. This will enlarge the envelope of applications where deep neural networks can be used; not by much, maybe, but moving the goalposts of a vast field a little has a large effect. A different kind of impact is that (neuronal) correlation is a concept, which is well studied in neuroscience. Our results could therefore lead to follow-up research that re-visits the connection between deep neural networks and neuroscience concepts.",8 Broader Impact,180,7,,,TRUE,TRUE,FALSE,How does Weight Correlation Affect Generalisation Ability of Deep Neural Networks?,Theory -> Models of Learning and Generalization,Deep Learning -> Analysis and Understanding of Deep Networks; Theory -> Regularization,Theory (including computational and statistical analyses),"['Gaojie Jin', ' Xinping Yi', ' Liang Zhang', ' Lijun Zhang', ' Sven Schewe', ' Xiaowei Huang']","{'University of Liverpool', 'Institute of Software, Chinese Academy of Sciences', 'Liverpool University'}",1,0,0,"{'UK', 'China'}"
ContraGAN: Contrastive Learning for Conditional Image Generation,"Minguk Kang, Jaesik Park",ContraGAN: Contrastive Learning for Conditional Image Generation,f490c742cd8318b8ee6dca10af2a163f,https://proceedings.neurips.cc/paper/2020/file/f490c742cd8318b8ee6dca10af2a163f-Paper.pdf,"We proposed a new conditional image generation model that can synthesize more realistic and diverse images. Our work can contribute to image-to-image translations [50, 51], generating realistic human faces [52, 53, 54], or any task that utilizes adversarial training. Since conditional GANs can expand to various image processing applications and can learn the representations of high-dimensional datasets, scientists can enhance the quality of astronomical images [55, 56], design complex architectured materials [57], and efficiently search chemical space for developing materials [58]. We can do so many beneficial tasks with conditional GANs, but we should be concerned that conditional GANs can be used for deepfake techniques [59]. Modern generative models can synthesize realistic images, making it more difficult to distinguish between real and fake. This can trigger sexual harassment [60], fake news [61], and even security issues of face recognition systems [62]. To avoid improper use of conditional GANs, we need to be aware of generative models’ strengths and weaknesses. Besides, it would be good to study the general characteristics of generated samples [63] and how we can distinguish fake images from unknown generative models [64, 65, 66].",Broader Impact,187,8,,,FALSE,FALSE,FALSE,ContraGAN: Contrastive Learning for Conditional Image Generation,Deep Learning -> Generative Models,Deep Learning -> Adversarial Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,{'POSTECH'},1,0,0,{'France'}
On the distance between two neural networks and the stability of learning,"Jeremy Bernstein, Arash Vahdat, Yisong Yue, Ming-Yu Liu",On the distance between two neural networks and the stability of learning,f4b31bee138ff5f7b84ce1575a738f95,https://proceedings.neurips.cc/paper/2020/file/f4b31bee138ff5f7b84ce1575a738f95-Paper.pdf,"This paper aims to improve our foundational understanding of learning in neural networks. This could lead to many unforeseen consequences down the line. An immediate practical outcome of the work is a learning rule that seems to require less hyperparameter tuning than stochastic gradient descent. This may have the following consequences: • Network training may become less time and energy intensive. • It may become easier to train and deploy neural networks without human oversight. • It may become possible to train more complex network architectures to solve new problems. In short, this paper could make a powerful tool both easier to use and easier to abuse.",Broader impact,107,7,,,FALSE,FALSE,FALSE,On the distance between two neural networks and the stability of learning,Optimization -> Non-Convex Optimization,Deep Learning -> Analysis and Understanding of Deep Networks,Optimization Methods (continuous or discrete),"['Jeremy Bernstein', ' Arash Vahdat', ' Yisong Yue', 'Yu Liu']","{'Caltech', 'NVIDIA', 'Nvidia Research'}",1,1,1,{'USA'}
A Topological Filter for Learning with Label Noise,"Pengxiang Wu, Songzhu Zheng, Mayank Goswami, Dimitris Metaxas, Chao Chen",A Topological Filter for Learning with Label Noise,f4e3ce3e7b581ff32e40968298ba013d,https://proceedings.neurips.cc/paper/2020/file/f4e3ce3e7b581ff32e40968298ba013d-Paper.pdf,"Label noise is ubiquitous in real-world data. This noise may arise from the cheap but imperfect annotations, such as crowdsourcing and online queries. Moreover, even by human annotators, the data labeling process is still error-prone. Another typical source of noise is the data poisoning, where corruptions are intentionally injected into the labels. Training with noisy labels would severely deteriorate the performance of deep models, due to their strong memorization ability and overfitting on corrupted information [51, 2]. Therefore, limiting the adverse influence of noisy labels is of great practical significance and has gained increasing attention from the community. In this work we attack the label noise from the perspective of data topology. Different from previous works which mostly inspect the sample losses or predicted posteriors, we show that the spatial behavior of the data could be well exploited, a point that has been largely ignored before. Importantly, in theory we prove that our topology-motivated method is able to exhaustively select the clean data with high probability. In this way we keep the network away from the negative influence of corrupted labels and promote the training healthily and steadily. Our method is simple yet with theoretical insights, and would provide contributions supplementary to the existing works. We believe it deserves the attention from the machine learning community.",Broader Impact,216,12,,,FALSE,FALSE,FALSE,A Topological Filter for Learning with Label Noise,Algorithms -> Classification,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Pengxiang Wu', ' Songzhu Zheng', ' Mayank Goswami', ' Dimitris Metaxas', ' Chao Chen']","{'Stony Brook University', 'Computer Science, Rutgers', 'Rutgers University', 'Queens College of CUNY'}",1,0,0,"{'UK', 'USA'}"
Personalized Federated Learning with Moreau Envelopes,"Canh T. Dinh, Nguyen Tran, Tuan Dung Nguyen",Personalized Federated Learning with Moreau Envelopes,f4f1f13c8289ac1b1ee0ff176b56fc60,https://proceedings.neurips.cc/paper/2020/file/f4f1f13c8289ac1b1ee0ff176b56fc60-Paper.pdf,"There have been numerous applications of FL in practice. One notable commercial FL usage, which has proved successful in recent years, is in the next-character prediction task on mobile devices. However, we believe this technology promises many more breakthroughs in a number of fields in the near future with the help of personalized FL models. In health care, for example, common causes of a disease can be identified from many patients without the need to have access to their raw data. The development of capable personalized models helps build better predictors on patients’ conditions, allowing for faster, more efficient diagnosis and treatment. As much as FL promises, it also comes with a number of challenges. First, an important societal requirement when deploying such technique is that the server must explain which clients’ data will be participated and which will not. The explainability and interpretability of a system are necessary for the sake of public understanding and making informed consent. Second, to successfully preserve privacy, FL has to overcome malicious actors who possibly interfere in the training process during communication. The malicious behaviors include stealing personalized models from the server, performing adversarial attacks such as changing a personalized model on some examples while remaining a good performance on average, and attempting to alter a model. Finally, an effective and unbiased FL system must be aware that data and computational power among clients can be extremely uneven in practice and, therefore, must ensure that the contribution of each client to the global model is adjusted to its level of distribution. These challenges help necessitate future research in decentralized learning in general and personalized FL in particular.",Broader Impact,274,12,,,FALSE,FALSE,FALSE,Personalized Federated Learning with Moreau Envelopes,Optimization -> Convex Optimization,Algorithms -> Large Scale Learning; Applications -> Dialog- or Communication-Based Learning; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"[' Dinh', ' Tran', ' Tuan Dung Nguyen']","{'The University of Sydney', 'The University of Melbourne'}",1,0,0,{'Australia'}
Avoiding Side Effects in Complex Environments,"Alex Turner, Neale Ratzlaff, Prasad Tadepalli",Avoiding Side Effects in Complex Environments,f50a6c02a3fc5a3a5d4d9391f05f3efc,https://papers.nips.cc/paper/2020/file/f50a6c02a3fc5a3a5d4d9391f05f3efc-Paper.pdf,"A scalable side effect avoidance method would ease the challenge of reward specification and aid deployment of RL in situations where mistakes are costly, such as embodied robotics tasks for which sim2real techniques are available. Conversely, developers should carefully consider how RL algorithms might produce policies with catastrophic impact. Developers should not blindly rely on even a well-tested side effect penalty. In some applications, AUP may decrease performance on the primary objective. In this case, developers may be incentivized to “cut corners” on safety in order to secure competitive advantage.",Broader Impact,90,5,,,TRUE,TRUE,TRUE,Avoiding Side Effects in Complex Environments,Social Aspects of Machine Learning -> AI Safety,Reinforcement Learning and Planning -> Reinforcement Learning,AI safety (reinforcement learning),"['Alex Turner', ' Neale Ratzlaff', ' Prasad Tadepalli']",{'Oregon State University'},1,0,0,{'USA'}
No-regret Learning in Price Competitions under Consumer Reference Effects,"Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang",No-regret Learning in Price Competitions under Consumer Reference Effects,f51238cd02c93b89d8fbee5667d077fc,https://proceedings.neurips.cc/paper/2020/file/f51238cd02c93b89d8fbee5667d077fc-Paper.pdf,"This work sheds light on market stability concerning competition among multiple firms under consumers’ reference effects. As discussed at the very beginning of the introduction, market stability is an important feature for business organizations and entities who are interacting in complex and highly dynamic environments. In a stable market, firms can better understand market behavior to guide their long-term decision making. This work shows that firms can obtain the desired market stability condition by running simple off-the-shelf online algorithms such as OMD. These algorithms do not require a large amount of information about market characteristics and perform very well in a dynamic competitive environments. In many e-commerce and online retail platforms, automated learning and pricing algorithms are prevalent. Thus, we believe that our paper provides firms with a simple automated solution for complex dynamic pricing decisions, which may potentially lead to stable markets.",Broader Impact,143,7,,,FALSE,FALSE,FALSE,No-regret Learning in Price Competitions under Consumer Reference Effects,Theory -> Game Theory and Computational Economics,Algorithms -> Online Learning,,"['Negin Golrezaei', ' Patrick Jaillet', ' Jason Cheuk Nam N Liang']","{'MIT', 'Google Research'}",1,1,1,{'USA'}
Geometric Dataset Distances via Optimal Transport,"David Alvarez Melis, Nicolo Fusi",Geometric Dataset Distances via Optimal Transport,f52a7b2610fb4d3f74b4106fb80b233d,https://proceedings.neurips.cc/paper/2020/file/f52a7b2610fb4d3f74b4106fb80b233d-Paper.pdf,"A notion of distance is such a basic and fundamental concept that it is most often used as a primitive from which other tools and methods derive utility. In the specific case of the dataset distance we propose here, it would most likely be used as tool within a machine learning pipeline. Thus, by its very nature, the prospect of potential impact of this work is broad enough to essentially encompass most settings where machine learning is used. In this statement, we focus on aspects that are immediate, tractable, and precise enough to be discussed constructively in this format. Perhaps the most immediate impact of this work could be through its application in transfer learning. Improvements in this paradigm can have a myriad outcomes, ranging from societal to environmental, both within and beyond the machine learning community. Among potential beneficial outcomes, one that stands out is the environmental impact of making transfer learning more efficient by providing guidance as to what resources to use for pretraining (§6.2) or choosing optimal data augmentations (§6.3). This would be particularly relevant for NLP, where the carbon footprint of models has grown exponentially in recent years, driven largely by pretraining of very large models on massive datasets [49]. Another beneficial outcome of this specific use of the distance proposed in this work rests on the intuition that more efficient transfer learning would could erode or mitigate economic barriers that currently limit large-scale data pretraining and adaptation to resource-rich entities and institutions. However, work studying the impact of improved data and method efficiency has pointed out that this intuition is perhaps too optimistic, as there are various unexpected yet feasible negative collateral consequences of increased efficiency, e. g., in terms of privacy, data markets and misuse [51]. We next highlight a few potential failure modes of this work. The modeling approximations used here to make this notion of distance efficiently computable, in particular the use of Gaussian distribution for modeling same-class collections, might prove too unrealistic in some datasets, leading to unreliable distance estimation. This, of course, could have negative impact on downstream applications that would rely on this distance as a sub-component, especially so given how deeply embedded within an ML pipeline it would be. In order to mitigate such impact, we suggest the practitioner verify how realistic these modeling assumptions are for the application at hand. On the other hand, despite the limited number of hyperparameters the computation of this distance relies on, inadequate choices for these ( e. g., the entropy regularization parameter "" ) might nevertheless lead to unreliable or imprecise results. Again, care should be taken in test the validity of the parameters, ideally running sanity-checks on identical or near-identical datasets to corroborate that the results are sensible.",Broader Impact,458,16,,,TRUE,TRUE,FALSE,Geometric Dataset Distances via Optimal Transport,Optimization,Algorithms -> Multitask and Transfer Learning; Algorithms -> Similarity and Distance Learning; Deep Learning -> Efficient Training Methods,AutoML,"['David Alvarez Melis', ' Nicolo Fusi']","{'MIT', 'Microsoft Research'}",1,1,1,{'USA'}
Task-Agnostic Amortized Inference of Gaussian Process Hyperparameters,"Sulin Liu, Xingyuan Sun, Peter J. Ramadge, Ryan P. Adams",Task-Agnostic Amortized Inference of Gaussian Process Hyperparameters,f52db9f7c0ae7017ee41f63c2a7353bc,https://proceedings.neurips.cc/paper/2020/file/f52db9f7c0ae7017ee41f63c2a7353bc-Paper.pdf,"Iterative hyperparameter optimization procedures often place a heavy computation burden on people who apply Gaussian processes to real-world applications. The optimization procedure itself usually has hyperparameters to be tuned (learning rate, number of iterations, etc.), which further increases the computational cost. Our proposed method amortizes this cost by training a single meta-model that is then useful across a wide range of tasks. Once the meta-model is trained, it can be repeatedly applied to future kernel hyperparameter selection tasks, reducing resource usage and carbon footprint. The minimal computation required by our method also makes it more accessible to the general public instead of only to those with abundant computing resources. Like most deep learning models, our neural model has the potential risk of overfitting and low robustness. In an effort to avoid this, we use only synthetic data generated from a family of kernel function space that is expressive enough to cover a variety of Gaussian process use cases. Our goal is to avoid biasing the model towards any particular task. Additionally, we impose regularizations such as permutation invariance and weight sharing to encourage generalizable representations. Even with all these efforts, our model might still produce misspecified hyperparameters which can lead to poor prediction performance versus conventional MLL optimization procedures.",Broader Impact,209,11,,,FALSE,FALSE,FALSE,Task-Agnostic Amortized Inference of Gaussian Process Hyperparameters,Probabilistic Methods -> Gaussian Processes,Algorithms -> AutoML; Algorithms -> Meta-Learning,Probabilistic methods and inference,"['Sulin Liu', ' Xingyuan Sun', ' Peter J Ramadge', ' Ryan Adams']","{'Princeton', 'Princeton University'}",1,0,0,{'USA'}
A novel variational form of the Schatten-pp quasi-norm,"Paris Giampouras, Rene Vidal, Athanasios Rontogiannis, Benjamin Haeffele",A novel variational form of the Schatten- p quasi-norm,f53eb4122d5e2ce81a12093f8f9ce922,https://proceedings.neurips.cc/paper/2020/file/f53eb4122d5e2ce81a12093f8f9ce922-Paper.pdf,"Low-rank modeling and estimation is a fundamental tool in machine learning and has numerous applications such as matrix completion and recommendation systems. As a result, understanding models for low-rank modeling and estimation is critical to understanding any potential biases and failure risks of such models. The proposed work offers new insights when it comes to the optimality properties of these problems, which might be of further interest to scientists studying relevant nonconvex theory. Moreover, our results provide theoretical insights and guidance which might be of interest to practitioners in guaranteeing and understanding the performance of their models.",Broader Impact,97,4,,,FALSE,FALSE,FALSE,A novel variational form of the Schatten-$p$ quasi-norm,Applications -> Matrix and Tensor Factorization,Algorithms -> Collaborative Filtering; Algorithms -> Missing Data; Optimization -> Non-Convex Optimization,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)",,"{'National Observatory of Athens', 'Johns Hopkins University, USA', 'Johns Hopkins University', 'The Johns Hopkins University'}",1,0,0,{'USA'}
Energy-based Out-of-distribution Detection,"Weitang Liu, Xiaoyun Wang, John Owens, Yixuan Li",Energy-based Out-of-distribution Detection,f5496252609c43eb8a3d147ab9b9c006,https://proceedings.neurips.cc/paper/2020/file/f5496252609c43eb8a3d147ab9b9c006-Paper.pdf,"Our project aims to improve the dependability and trustworthiness of modern machine learning models. This stands to benefit a wide range of fields and societal activities. We believe out-of- distribution uncertainty estimation is an increasingly critical component of systems that range from consumer and business applications (e.g., digital content understanding) to transportation (e.g., driver assistance systems and autonomous vehicles), and to health care (e.g., rare disease identification). Through this work and by releasing our code, we hope to provide machine learning researchers a new methodological perspective and offer machine learning practitioners an easy-to-use tool that renders safety against anomalies in the open world. While we do not anticipate any negative consequences to our work, we hope to continue to improve and build on our framework in future work.",7 Broader Impact,128,5,,,FALSE,FALSE,FALSE,Energy-based Out-of-distribution Detection,Deep Learning,Algorithms -> Classification; Algorithms -> Uncertainty Estimation; Social Aspects of Machine Learning -> AI Safety,Out of distribution detection,"['Weitang Liu', ' Xiaoyun Wang', ' John Owens', ' Sharon Yixuan Li']","{'Stanford University', 'University of California, Davis'}",1,0,0,{'USA'}
On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them,"Chen Liu, Mathieu Salzmann, Tao Lin, Ryota Tomioka, Sabine Süsstrunk",On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them,f56d8183992b6c54c92c16a8519a6e2b,https://proceedings.neurips.cc/paper/2020/file/f56d8183992b6c54c92c16a8519a6e2b-Paper.pdf,"The existence of adversarial examples has raised serious concerns about the deployment of deep learning models in safety-sensitive domains, such as medical imaging [32] and autonomous navigation [1]. In these domains, as in many others, adversarial training remains the most popular, effective, and general method to train robust models. By studying the nature of optimization in adversarial training and proposing solutions to overcome the underlying challenges, our work has potential for high societal impact in these fields. Although the robust accuracy is much lower than the clean accuracy so far, the intrinsic properties of adversarial training we have discovered open up future research directions to improve its performance. From an ecological perspective, however, we acknowledge that the higher computational cost of adversarial training translates to higher carbon footprint than vanilla training. Nevertheless, we believe that the potential societal benefits of robustness to attacks outweigh this drawback.",8 Broader Impact,146,6,,,FALSE,FALSE,FALSE,On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them,Algorithms -> Adversarial Learning,Deep Learning -> Optimization for Deep Networks,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Chen Liu', ' Mathieu Salzmann', ' Tao LIN', ' Ryota Tomioka', ' Sabine Süsstrunk']","{'Microsoft Research Cambridge', 'EPFL'}",1,1,1,"{'USA', 'Switzerland'}"
User-Dependent Neural Sequence Models for Continuous-Time Event Data,"Alex Boyd, Robert Bamler, Stephan Mandt, Padhraic Smyth",User-Dependent Neural Sequence Models for Continuous-Time Event Data,f56de5ef149cf0aedcc8f4797031e229,https://proceedings.neurips.cc/paper/2020/file/f56de5ef149cf0aedcc8f4797031e229-Paper.pdf,"While many of the successful and highly-visible applications of machine learning are in classification and regression, there are a broad range of applications that don’t naturally fit into these categories and that can potentially benefit significantly from machine learning approaches. In particular, in this paper we focus on continuous-time event data, which is very common in real-world applications but has not yet seen significant attention from the ML research community. There are multiple important problems in society where such data is common and that could benefit from the development of better predictive and simulation, including: • Education: Understanding of individual learning habits of students, especially in online educa- tional programs, could improve and allow for more personalized curricula. • Medicine: Customized tracking and predictions of medical events could save lives and improve patients’ quality of living. • Behavioral Models: Person-specific simulations of their behavior can lead to better systematic understandings of people’s social activities and actions in day-to-day lives. • Cybersecurity: Through the user identification capabilities, our work could aid in cyber-security applications for the purposes of identifying fraud detection and identify theft. Another potential positive broad impact of the work, is that by utilizing amortized VI, our methods do not require further costly training or fine-tuning to accommodate new users, which can potentially produce energy savings and lessen environmental impact in a production setting. On the other hand, as with many machine learning technologies, there is also always the potential for negative impact from a societal perspective. For example, more accurate individualized models for user-generated data could be used in a negative fashion for applications such as surveillance (e.g., to monitor and negatively impact individuals in protected groups). In addition, better predictions and recommendations for products and services, through explicitly conditioning on prior behavior from a user, could potentially further worsen existing privacy concerns.",Broader Impacts,305,10,,,FALSE,TRUE,FALSE,User-Dependent Neural Sequence Models for Continuous-Time Event Data,Applications -> Time Series Analysis,Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models,Probabilistic methods and inference,"['Alex Boyd', ' Robert Bamler', ' Stephan Mandt', ' Padhraic Smyth']","{'University of California at Irvine', 'UC Irvine', 'University of California, Irivine', 'University of California, Irvine'}",1,0,0,{'USA'}
Active Structure Learning of Causal DAGs via Directed Clique Trees,"Chandler Squires, Sara Magliacane, Kristjan Greenewald, Dmitriy Katz, Murat Kocaoglu, Karthikeyan Shanmugam",Active Structure Learning of Causal DAGs via Directed Clique Trees,f57bd0a58e953e5c43cd4a4e5af46138,https://proceedings.neurips.cc/paper/2020/file/f57bd0a58e953e5c43cd4a4e5af46138-Paper.pdf,"Causality is an important concern in medicine, biology, econometrics and science in general (Pearl, 2009; Spirtes et al., 2000; Peters et al., 2017). A causal understanding of the world is required to correctly predict the effect of actions or external factors on a system, but also to develop fair algorithms. It is well-known that learning causal relations from observational data alone is not possible in general (except in special cases or under very strong assumptions); in these cases experimental (“interventional”) data is necessary to resolve ambiguities. In many real-world applications, interventions may be time-consuming or expensive, e.g. randomized controlled trials to develop a new drug or gene knockout experiments. These settings crucially rely on experiment design , or more precisely intervention design , i.e. finding a cost-optimal set of interventions that can fully identify a causal model. The ultimate goal of intervention design is accelerating scientific discovery by decreasing its costs, both in terms of actual costs of performing the experiments and in terms of automation of new discoveries. Our work focuses on intervention design for learning causal DAGs, which have been notably employed as models in system biology, e.g. for gene regulatory networks (Friedman et al., 2000) or for protein signalling networks (Sachs et al., 2005). Protein signalling networks represent the way cells communicate with each other, and having reliable models of cell signalling is crucial to develop new treatments for many diseases, including cancer. Understanding how genes influence each other has also important healthcare applications, but is also crucial in other fields, e.g. agriculture or the food industry. Since even the genome of a simple organism as the common yeast contains 6275 genes, interventions like gene knockouts have to be carefully planned. Moreover, experimental design algorithms may prove to be a useful tool for driving down the time and cost of investigating the impact of cell type, drug exposure, and other factors on gene expression. These benefits suggest that there is a potential for experimental design algorithms such as ours to be a commonplace component of the future biological workflow. In particular, our work establishes a number of new theoretical tools and results that 1) may drive development of new experimental design algorithms, 2) allow practitioners to estimate, prior to beginning experimentation, how costly their task may be, 3) offer an intervention policy that is able to run on much larger graphs than most of the related work, and provides more efficient intervention schedules than the rest. Importantly, our work and in general intervention design algorithms have some limitations. In particular, as we have mentioned in the main paper, all these algorithms have relatively strong assumptions (e.g. no latent confounders or selection bias, infinite observational data, noiseless interventions, or in some case limitations on the graph structure (Greenewald et al., 2019)). If these assumptions are not satisfied in the data, or the practitioner does not realize their importance, the outcome of these algorithms could be misinterpreted or over-interpreted, leading to wasteful experiments or overconfident causal conclusions. Wrong causal conclusions may lead to potentially severe unintended side effects or unintended perpetuation of bias in algorithms. Even in case of correct causal conclusions, the actualized impact of experimental design depends on the experiments in which it is used. Potential positive uses cases include decreasing the cost of drug development, in turn leading to better and cheaper medicine for consumers.",Broader impact statement,559,19,,,FALSE,FALSE,FALSE,Active Structure Learning of Causal DAGs via Directed Clique Trees,Probabilistic Methods -> Causal Inference,Algorithms -> Model Selection and Structure Learning; Probabilistic Methods -> Graphical Models,Causality,"['Chandler Squires', ' Sara Magliacane', ' Kristjan Greenewald', ' Dmitriy Katz', ' Murat Kocaoglu', ' Karthikeyan Shanmugam']","{'Massachusetts Institute of Technology', 'IBM Research, NY', 'IBM Research', 'MIT-IBM Watson AI Lab'}",1,1,1,{'USA'}
Convergence and Stability of Graph Convolutional Networks on Large Random Graphs,"Nicolas Keriven, Alberto Bietti, Samuel Vaiter",Convergence and Stability of Graph Convolutional Networks on Large Random Graphs,f5a14d4963acf488e3a24780a84ac96c,https://proceedings.neurips.cc/paper/2020/file/f5a14d4963acf488e3a24780a84ac96c-Paper.pdf,"Graph Neural Networks have been used to many applications, including computer vision, generative models in NLP or protein prediction to cite only a few. Thus, our work is included in a wide literature whose societal impact and ethical considerations are not one-sided. We provide here a theoretical understanding of the behaviour of large random graphs, with the most natural application is community detection in social science [3]. Our contributions, of a theoretical nature, are far from a direct impact in our opinion. We do not see continuous GCNs applied directly in the forseeable future otherwise as a proxy for the study of classic GCNs. Nevertheless, as a stability result, it is a step forward to handle adversarial attacks as highlighted in [19].",Broader Impact,122,6,,,FALSE,FALSE,FALSE,Convergence and Stability of Graph Convolutional Networks on Large Random Graphs,Deep Learning -> Analysis and Understanding of Deep Networks,Probabilistic Methods -> Latent Variable Models; Theory -> High-Dimensional Inference,Deep learning,"['Nicolas Keriven', ' Alberto Bietti', ' Samuel Vaiter']","{'CNRS', 'CNRS, GIPSA-lab', 'Inria'}",1,0,0,{'France'}
BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization,"Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham, Andrew G. Wilson, Eytan Bakshy",BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization,f5b1b89d98b7286673128a5fb112cb9a,https://proceedings.neurips.cc/paper/2020/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf,"Bayesian optimization is a generic methodology for optimizing black-box functions, and therefore, by its very nature, not tied to any particular application domain. As mentioned earlier in the paper, Bayesian optimization has been used for various arguably good causes, including drug discovery or reducing the energy footprint of ML applications by reducing the computational cost of tuning hyperparameters. In the Appendix, we give an specific example for how our work can be applied in a public health context, namely to efficiently distribute survey locations for estimating malaria prevalence. BOTORCH as a tool specifically has been used in various applications, including transfer learning for neural networks [62], high-dimensional Bayesian optimization [59], drug discovery [10], sim-to-real transfer [69], trajectory optimization [42], and nano-material design [73]. However, there is nothing inherent to this work and Bayesian optimization as a field more broadly that would preclude it from being abused in some way, as is the case with any general methodology.",Broader Impact,157,5,,,TRUE,TRUE,FALSE,BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization,Probabilistic Methods -> Gaussian Processes,"Algorithms -> AutoML; Algorithms -> Kernel Methods; Algorithms -> Uncertainty Estimation; Data, Challenges, Implementations, and Software -> Software Toolkits; Optimization -> Non-Convex Optimization; Optimization -> Stochastic Optimization",Optimization Methods (continuous or discrete),"['Maximilian Balandat', ' Brian Karrer', ' Daniel Jiang', ' Samuel Daulton', ' Ben Letham', ' Andrew Gordon Wilson', ' Eytan Bakshy']","{'Facebook', 'New York University'}",1,1,1,{'USA'}
Reconsidering Generative Objectives For Counterfactual Reasoning,"Danni Lu, Chenyang Tao, Junya Chen, Fan Li, Feng Guo, Lawrence Carin",Reconsidering Generative Objectives For Counterfactual Reasoning,f5cfbc876972bd0d031c8abc37344c28,https://proceedings.neurips.cc/paper/2020/file/f5cfbc876972bd0d031c8abc37344c28-Paper.pdf,"This study presents a novel generative causal inference framework, called BV-NICE, that brings together ideas from both statistical and machine learning based causal modeling. By joining the strength of variational inference, R-learning, and Fenchel mini-max learning, the resulting procedure fully acknowledges the representation uncertainty and enables accurate, reliable direct estimation of individualized causal effect in a flexible, scalable manner. Importantly, while there has been growing consensus that generative causal modeling such as CE-VAE is more suited for many applications yet with suboptimal performance, our research identifies the performance bottleneck and closes the gap between generative causal schemes and state-of-the-art alternatives. This work promises to have positive societal impacts into the future. And with the best intention in the world, the author(s) wish this research will be applied to progress the course of humanity for the good. Areas stand most likely to benefit from this research are personalized healthcare, public policy, and transportation safety regulations. Variant of the proposed variational framework also promises robustness against the algorithmic biases towards the minority populations, a major issue that draws criticism for machine learning applications. This implies our model can be well suited for ensuring social justice.",Broader Impact,194,8,,,FALSE,TRUE,FALSE,Reconsidering Generative Objectives For Counterfactual Reasoning,Probabilistic Methods -> Causal Inference,Deep Learning -> Generative Models,Causality,"['Danni Lu', ' Chenyang Tao', ' Junya Chen', ' Fan Li', ' Feng Guo', ' Lawrence Carin']","{'Duke U', 'Virginia Tech', 'Duke University'}",1,0,0,{'USA'}
Robust Federated Learning: The Case of Affine Distribution Shifts,"Amirhossein Reisizadeh, Farzan Farnia, Ramtin Pedarsani, Ali Jadbabaie",Robust Federated Learning: The Case of Affine Distribution Shifts,f5e536083a438cec5b64a4954abc17f1,https://proceedings.neurips.cc/paper/2020/file/f5e536083a438cec5b64a4954abc17f1-Paper.pdf,"As the amount of private data generated at users’ devices surges, we are observing ever-growing interests in the industry to develop applications that leverage such personal and private data to boost the performance of their product, such as smart healthcare, online banking, self-driving cars, semantic learning, etc. To address such critical concern on users’ privacy, governments in the U.S. and Europe have been passing regulations to ensure data protection and data traceability on such frameworks. Federated Learning is a novel learning paradigm that significantly improves data protection guarantees over the standard frameworks, in addition to various other upsides. In machine learning community in particular, developing federated learning and in general privacy preserving algorithms has gained compelling interest while user privacy is being acknowledged as an ethic in algorithm design. This powerful paradigm is yet prone to several drawbacks and demands extensive theoretical and empirical studies. Our work particularly targets data heterogeneity and local resource consumption as two major concerns in federated learning methods. Our methodology results in a fast and robust federated learning framework and improves the performance of standard techniques. Image recognition is a particular use-case of our framework where we capture the variations of images due to camera imperfections or weather conditions impacting the images. Our robust method can improve the accuracy of a variety of image recognition tasks such as guiding autonomous robots, self-driving cars and accident avoidance systems, while protecting users’ private data.",Broader Impact,237,9,,,FALSE,FALSE,FALSE,Robust Federated Learning: The Case of Affine Distribution Shifts,Optimization -> Non-Convex Optimization,Algorithms -> Adversarial Learning; Algorithms -> Large Scale Learning,Optimization Methods (continuous or discrete),"['Amirhossein Reisizadeh', ' Farzan Farnia', ' Ramtin Pedarsani', ' Ali Jadbabaie']","{'Stanford University', 'MIT', 'UC Santa Barbara'}",1,0,0,{'USA'}
Quantile Propagation for Wasserstein-Approximate Gaussian Processes,"Rui Zhang, Christian Walder, Edwin V. Bonilla, Marian-Andrei Rizoiu, Lexing Xie",Quantile Propagation for Wasserstein-Approximate Gaussian Processes,f5e62af885293cf4d511ceef31e61c80,https://proceedings.neurips.cc/paper/2020/file/f5e62af885293cf4d511ceef31e61c80-Paper.pdf,"It is likely that the majority of significant technological advancements will eventually lead to both positive and negative societal and ethical outcomes. It is important, however, to consider how and when these outcomes may arise, and whether the net balance is likely to be favourable. After careful consideration, however, we found that the present work is sufficiently general and application independent, as to warrant relatively little specific concern.",Broader Impact,68,3,,,FALSE,FALSE,FALSE,Quantile Propagation for Wasserstein-Approximate Gaussian Processes,Probabilistic Methods -> Gaussian Processes,Probabilistic Methods -> Belief Propagation,Probabilistic methods and inference,"['Rui Zhang', ' Christian Walder', ' Edwin Bonilla', 'Andrei Rizoiu', ' Lexing Xie']","{'The Australian National University', 'Data61', 'University of Technology Sydney', 'Australian National University and NICTA', 'DATA61'}",1,1,1,{'Australia'}
Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning,"Tianren Zhang, Shangqi Guo, Tian Tan, Xiaolin Hu, Feng Chen",Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning,f5f3b8d720f34ebebceb7765e447268b,https://proceedings.neurips.cc/paper/2020/file/f5f3b8d720f34ebebceb7765e447268b-Paper.pdf,"This work may promote the research in the field of HRL and RL, and has potential real-world applications such as robotics. The main uncertainty of the proposed method might be the fact that the RL training process itself is somewhat brittle, and may break in counterintuitive ways when the  reward function is misspecified. Also, since the training data of RL heavily depends on the training environments, designing unbiased simulators or real-world training environments is important for eliminating the biases in the data collected by the agents.",Broader Impact,86,3,,,FALSE,FALSE,FALSE,Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning,Reinforcement Learning and Planning -> Hierarchical RL,Reinforcement Learning and Planning -> Decision and Control; Reinforcement Learning and Planning -> Markov Decision Processes; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Tianren Zhang', ' Shangqi Guo', ' Tian Tan', ' Xiaolin Hu', ' Feng Chen']","{'Stanford University', 'Tsinghua University'}",1,0,0,"{'USA', 'China'}"
High-contrast “gaudy” images improve the training of deep neural network models of visual cortex,"Benjamin Cowley, Jonathan W. Pillow",High-contrast “gaudy” images improve the training of deep neural network models of visual cortex,f610a13de080fb8df6cf972fc01ad93f,https://proceedings.neurips.cc/paper/2020/file/f610a13de080fb8df6cf972fc01ad93f-Paper.pdf,"The goal of our work is to train DNNs as accurately as possible with as little training data as possible. This reduces the amount of research hours needed to collect data (e.g., an experimenter collecting neural data) and potentially reduces the suffering of the animal. We focus on a specific regression problem of interest in computational neuroscience versus object recognition, for which many active learning algorithms already exist and would likely require tens of thousands of hours of GPU compute time to perform our analyses. All of our work was performed on a small cluster of eight 12-Gb GPUs (GeForce RTX 2080 Ti). We estimate that ~8,000 GPU hours in total were used, emitting ~200 lbs of CO2 (assuming 40 GPU hours consumes 10 kWh). This is equivalent to driving ~230 miles in a car. We do not foresee any short-term negative consequences to society from our work. Code to produce the figures in this paper is available at https://github.com/pillowlab/gaudy-images .",Broader Impact,161,8,,,FALSE,FALSE,FALSE,High-contrast “gaudy” images improve the training of deep neural network models of visual cortex,Neuroscience and Cognitive Science -> Neuroscience,Neuroscience and Cognitive Science -> Neural Coding,Neuroscience and cognitive science,"['Benjamin Cowley', ' Jonathan W Pillow']",{'Princeton University'},1,0,0,{'USA'}
Duality-Induced Regularizer for Tensor Factorization Based Knowledge Graph Completion,"Zhanqiu Zhang, Jianyu Cai, Jie Wang",Duality-Induced Regularizer for Tensor Factorization Based Knowledge Graph Completion,f6185f0ef02dcaec414a3171cd01c697,https://proceedings.neurips.cc/paper/2020/file/f6185f0ef02dcaec414a3171cd01c697-Paper.pdf,"The proposed regularizer DURA can significantly improve the performance of tensor factorization based knowledge graph completion models. In other words, it can help us to predict missing links in knowledge graphs automatically. Therefore, using models with DURA, we do not need to complete knowledge graphs manually. A great amount of manpower can be saved, and work efficiency can be increased. After the completion process, knowledge graphs can provide volume and valuable human knowledge in a structured way. They can be applied to many scenarios that require human knowledge. For example, an E-commerce company can use knowledge graphs for customer service and personalized recommendation. Medical workers can use them to make a diagnosis. One ethical concern when using automatic knowledge graph completion methods is the potential for privacy disclosure. If we use public data on the Internet to construct a knowledge graph and then complete it using the proposed method, personal information that one does not want to make public may be unveiled. Therefore, we advise everyone to be cautious about usage scenarios of automatic knowledge graph completion methods.",Broader Impact,178,11,,,FALSE,FALSE,FALSE,Duality-Induced Regularizer for Tensor Factorization Based Knowledge Graph Completion,Algorithms -> Representation Learning,Algorithms -> Relational Learning; Deep Learning -> Embedding Approaches,,"['Zhanqiu Zhang', ' Jianyu Cai', ' Jie Wang']",{'University of Science and Technology of China'},1,0,0,{'China'}
Distributed Training with Heterogeneous Data: Bridging Median- and Mean-Based Algorithms,"Xiangyi Chen, Tiancong Chen, Haoran Sun, Steven Z. Wu, Mingyi Hong",Distributed Training with Heterogeneous Data: Bridging Median- and Mean-Based Algorithms,f629ed9325990b10543ab5946c1362fb,https://proceedings.neurips.cc/paper/2020/file/f629ed9325990b10543ab5946c1362fb-Paper.pdf,"As machine learning models are trained on increasingly large datasets, more and more training processes are done in a distributive fashion, where the training data are distributed across the nodes in a network. These nodes may correspond to data centers across different regions or mobile devices of individual users. In these settings, the data distributions across different nodes can be inherently heterogeneous. Under this setting of heterogeneous distributions across nodes, our work provides new understandings on the behavior of popular distributed training algorithms that are optimized for robustness and communication efficiency. These insights can be useful for practitioners to formally reason about the trade-offs across accuracy, robustness, and communication efficiency.",7 Broader Impacts,110,5,,,FALSE,FALSE,FALSE,Distributed Training with Heterogeneous Data: Bridging Median- and Mean-Based Algorithms,Optimization -> Stochastic Optimization,Deep Learning -> Optimization for Deep Networks; Optimization -> Non-Convex Optimization; Theory -> Statistical Learning Theory,Optimization Methods (continuous or discrete),"['Xiangyi Chen', ' Tiancong Chen', ' Haoran Sun', ' Steven Wu', ' Mingyi Hong']","{'University of Minnesota', 'Carnegie Mellon University'}",1,0,0,{'USA'}
H-Mem: Harnessing synaptic plasticity with Hebbian Memory Networks,"Thomas Limbacher, Robert Legenstein",H-Mem: Harnessing synaptic plasticity with Hebbian Memory Networks,f6876a9f998f6472cc26708e27444456,https://proceedings.neurips.cc/paper/2020/file/f6876a9f998f6472cc26708e27444456-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,H-Mem: Harnessing synaptic plasticity with Hebbian Memory Networks,Deep Learning -> Biologically Plausible Deep Networks,Neuroscience and Cognitive Science -> Memory,Deep learning,"['Thomas Limbacher', ' Robert Legenstein']",{'Graz University of Technology'},1,0,0,{'Austria'}
Neural Unsigned Distance Fields for Implicit Function Learning,"Julian Chibane, Mohamad Aymen mir, Gerard Pons-Moll",Neural Unsigned Distance Fields for Implicit Function Learning,f69e505b08403ad2298b9f262659929a,https://proceedings.neurips.cc/paper/2020/file/f69e505b08403ad2298b9f262659929a-Paper.pdf,"Real-world 3D data captured with sensors like cameras, scanners and lidar is often noisy and in the form of incomplete point clouds. NDFs are useful to reconstruct and complete such point clouds of complex objects and the 3D environment – this is relevant for AR or VR, autonomous vehicles, robotics, virtual humans, cultural heritage, quality assurance in fabrication.We show state-of-the-art results for this point cloud completion task. Application of NDFs for other 3D processing tasks, such as denoising and semantic segmentation can have further practical interest. NDFs are also of theoretical interest, in particular for representation learning of 3D shapes, and can open the door to new methods for manifold learning and multi-target regression. A potential danger of our method is that NDFs allow to learn from general world statistics to create complete 3D reconstructions from only sparsely or partially 3D captured environments, scenes and persons (e.g. gained from structure-from-motion techniques from images), which may violate personal or proprietary rights. The application of reconstruction algorithms, as ours, in safety relevant scenarios need to consider the risk of unreliable system predictions and should consider human intervention.",Broader Impact,185,6,,,FALSE,FALSE,FALSE,Neural Unsigned Distance Fields for Implicit Function Learning,Applications -> Computer Vision,Deep Learning,Vision,"['Julian Chibane', ' Mohamad Aymen mir', 'Moll']","{'MPI Informatics, Saarland', 'Max Planck Institute for Informatics, University of Wuerzburg', 'MPII, Germany'}",1,0,0,{'Germany'}
Curriculum By Smoothing,"Samarth Sinha, Animesh Garg, Hugo Larochelle",Curriculum by Smoothing,f6a673f09493afcd8b129a0bcf1cd5bc,https://proceedings.neurips.cc/paper/2020/file/f6a673f09493afcd8b129a0bcf1cd5bc-Paper.pdf,"In this paper we describe a technique to fundamentally improve training for CNNs. This paper has impact wherever CNNs are used, since they can also be trained using the same regime, which would results in improved task-performance. Applications of CNNs, such as object recognition, can be used for good or malicious purposes. Any user or practitioner has the ultimate impact and authority on how to deploy such a network in practice. The user can use our proposed strategy to improve their underlying machine learning algorithm, and deploy it in whichever way they choose.",Broader Impact,93,5,,,FALSE,FALSE,FALSE,Curriculum By Smoothing,Deep Learning -> Predictive Models,Algorithms -> Classification; Algorithms -> Unsupervised Learning; Applications -> Signal Processing; Deep Learning -> Supervised Deep Networks,,"['Samarth Sinha', ' Animesh Garg', ' Hugo Larochelle']","{'Google Brain', 'University of Toronto, Vector Institute'}",1,1,1,"{'Canada', 'USA'}"
Fast Transformers with Clustered Attention,"Apoorv Vyas, Angelos Katharopoulos, François Fleuret",Fast Transformers with Clustered Attention,f6a8dd1c954c8506aadc764cc32b895e,https://proceedings.neurips.cc/paper/2020/file/f6a8dd1c954c8506aadc764cc32b895e-Paper.pdf,"This work contributes towards the wider adoption of transformers by reducing their computational requirements; thus enabling their use on embedded or otherwise resource constrained devices. In addition, we have shown that for long sequences clustered attention can result to almost 50% reduction in GPU training time which translates to equal reduction in CO2 emmisions and energy consumption.",Broader Impact,57,2,FALSE,FALSE,FALSE,FALSE,FALSE,Fast Transformers with Clustered Attention,Deep Learning -> Attention Models,Deep Learning -> Efficient Inference Methods; Deep Learning -> Efficient Training Methods,Deep learning,"['Apoorv Vyas', ' Angelos Katharopoulos', ' François Fleuret']","{'University of Geneva', 'Idiap', 'Idiap Research Institute'}",1,0,0,{'Switzerland'}
"The Convex Relaxation Barrier, Revisited: Tightened Single-Neuron Relaxations for Neural Network Verification","Christian Tjandraatmadja, Ross Anderson, Joey Huchette, Will Ma, KRUNAL KISHOR PATEL, Juan Pablo Vielma","The Convex Relaxation Barrier, Revisited: Tightened Single-Neuron Relaxations for Neural Network Verification",f6c2a0c4b566bc99d596e58638e342b0,https://proceedings.neurips.cc/paper/2020/file/f6c2a0c4b566bc99d596e58638e342b0-Paper.pdf,"In a world where deep learning is impacting our lives in ever more tangible ways, verification is an essential task to ensure that these black box systems behave as we expect them to. Our fast, simple algorithms have the potential to make a positive impact by verifying a larger number of inputs to be robust within a short time-frame, often required in several applications. Of course, we should be cautious that although our algorithms provide a mathematical certificate of an instance being robust, failure to use the system correctly, such as modeling the verification problem in a way that does not reflect real-world concerns, can still lead to unreliable neural networks. We also highlight that our version of the verification problem, while accurately capturing a reasonable formal specification of robustness, clearly does not perfectly coincide with “robustness” as may be used in a colloquial sense. Therefore, we highlight the importance of understanding the strengths and limitations of the mathematical model of verification used, so that a false sense of complacency does not set in.",Broader Impact,174,5,,,FALSE,FALSE,FALSE,"The Convex Relaxation Barrier, Revisited: Tightened Single-Neuron Relaxations for Neural Network Verification",Algorithms -> Adversarial Learning,Optimization -> Discrete Optimization,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Christian Tjandraatmadja', ' Ross Anderson', ' Joey Huchette', ' Will Ma', ' KRUNAL KISHOR PATEL', ' Juan Pablo Vielma']","{'Google and MIT', 'Columbia University', 'Google Research', 'Google', 'Rice University'}",1,1,1,{'USA'}
Strongly Incremental Constituency Parsing with Graph Neural Networks,"Kaiyu Yang, Jia Deng",Strongly Incremental Constituency Parsing with Graph Neural Networks,f7177163c833dff4b38fc8d2872f1ec6,https://proceedings.neurips.cc/paper/2020/file/f7177163c833dff4b38fc8d2872f1ec6-Paper.pdf,"We evaluated our method on constituency parsing for English and Chinese. They are the two most spoken languages, with more than two billion speakers across the globe. However, there are more than 7,000 languages in the world. And it is important to deliver parsing and other NLP technology to benefit speakers of diverse languages. Fortunately, our method can be applied to many languages with little additional effort. We developed the system using PTB, and when adding CTB, we only had to make a few minor changes in language-specific preprocessing. However, a potential barrier is the lack of training data for low-resource languages. Our method relies on supervised learning with a large number of annotated parse trees, which are available only for some languages. A potential solution is to do joint multilingual training as in Kitaev et al. [20].",Broader Impact,138,10,,,FALSE,FALSE,FALSE,Strongly Incremental Constituency Parsing with Graph Neural Networks,Applications,Applications -> Natural Language Processing,Natural language processing,"['Kaiyu Yang', ' Jia Deng']",{'Princeton University'},1,0,0,{'USA'}
AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection,"Hao Zhu, Chaoyou Fu, Qianyi Wu, Wayne Wu, Chen Qian, Ran He",AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection,f718499c1c8cef6730f9fd03c8125cab,https://proceedings.neurips.cc/paper/2020/file/f718499c1c8cef6730f9fd03c8125cab-Paper.pdf,"Deepfake refers to synthesized media in which a portrait of a person in real media is replaced by that of someone else. Deepfakes have been widely applied in the digital entertainment industry, but they also present potential threats to the public. Identity swapping is an approach to produce Deepfakes and is also the research direction of this paper. Given the sensitivity of Deepfakes and their potential negative impacts, we further discuss the potential threats and the corresponding mitigation solutions with respect to our work. 6.1 Potential Threats to the Public Although the Deepfake was originally invented for social good, such as digital entertainment [69, 71, 62, 58, 44, 32], it may also be used for malicious proposes, thus exerting substantially negative impacts on individuals, institutions, and society. Political threats. In the political arena, Deepfakes may be used to impact elections around the world or to foment political controversy. Malevolent Deepfakes may be part of fake news, which has the potential to undermine the political system, especially during an election year. Disinformation attacks. The vivid Deepfake may be adopted as false evidence to mislead and incite the public. For example, social media postings with Deepfakes may maliciously create controversy over a sensitive topic. Identity theft. Deepfakes facilitate the crime of obtaining the identity information of another person to conduct a transaction, such as financial fraud. For example, the Deepfake enables a criminal to pretend to be a manager and ask employees to send money. At the same time, powerful identity swapping applications can pose security problems when facial recognition or face forgery detection algorithms fail to detect manipulated faces. Celebrity pornography. Making fake pornography has been a common threat, where faces of victims are swapped with those of porn stars. With today’s technology, the identity swapping can be done after obtaining a set of social photos of the victims. In light of this, Deepfakes can lead to bullying or harassment, which may bring major psychological burdens and legal consequences to people. Given these potential negative effects, we need a clear solution to limit the use of Deepfakes in order to reduce the threats to public safety and to protect people’s rights. 6.2 Ways to Prevent the Harms and Our Contributions There are several effective solutions to alleviate the aforementioned concerns. Keep up with the latest Deepfake technologies. Understanding the characteristics of various Deepfake synthesis algorithms is crucial for the development of Deepfake detection algorithms. In order to facilitate tracking the latest technologies, common standards can be developed for summarizing and recording technology advances. Recent work adequately collates and summarizes latest Deepfakes developments. Such work will greatly help researchers to better understand current developments and develop new strategies to detect Deepfakes. Collect Deepfakes data. Recent studies have shown that Deepfakes synthesized by different algorithms can be used as training data to improve the performance of detection algorithms. It is highly suggested that researchers actively expand the latest Deepfakes imagery into training data. These data need to be properly managed. For instance, non-profit organizations could be established to manage and maintain these data. Develop detection algorithms. Using detection algorithms to automatically identify Deepfakes is a primary way to reduce their negative impact. Government agencies and related organizations should actively support the development of detection algorithms. Legislation. Given the enormous potential harm of Deepfakes, there is an urgency to start the legislation process to regulate Deepfakes. The law should standardize the allowed usage of Deepfakes and the consequences of illicitly using Deepfakes to commit crimes. Our contributions to the community. Apart from proposing an efficient algorithm to advance the development of generative models, we are also striving to mitigate the harm caused by Deepfakes: (1) We are building a new Deepfake dataset (synthesized by our algorithm) to advance the state of the art in Deepfake detection algorithms. (2) We are committed to support the development of Deepfake detection algorithms in any way, including but not limited to summarizing the latest Deepfake algorithms and developing novel detection algorithms. Please refer to our project page for the latest progress.",6 Broader Impact,673,41,,,TRUE,TRUE,FALSE,AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection,"Applications -> Body Pose, Face, and Gesture Analysis",Applications -> Computer Vision,Vision,,"{'Sensetime', 'NLPR, CASIA', 'SenseTime', 'Anhui University', 'Tsinghua University', 'Institute of Automation, Chinese Academy of Sciences'}",1,1,1,"{'Hong Kong', 'China'}"
Uncertainty-Aware Learning for Zero-Shot Semantic Segmentation,"Ping Hu, Stan Sclaroff, Kate Saenko",Uncertainty-Aware Learning for Zero-Shot Semantic Segmentation,f73b76ce8949fe29bf2a537cfa420e8f,https://proceedings.neurips.cc/paper/2020/file/f73b76ce8949fe29bf2a537cfa420e8f-Paper.pdf,"Our work aims to learn reliable models for zero-shot semantic segmentation. From the technical perspective, our algorithm addresses the lack of training data in the open-set setting, thus benefiting a lot of real-world applications like image editing, open-world scene understanding. From the social responsibility perspective, our work aims for building machine learning algorithms with less training data, thus helping save both financial and energy costs during the data annotation process. The failures of our system may incur incorrect segmentation, which needs manual corrections from users before performing downstream tasks. The negative impact of our work could be that making companies, governments, or individuals more easily deploy these systems for unethical purposes.",Broader Impact.,111,5,,,FALSE,FALSE,FALSE,Uncertainty-Aware Learning for Zero-Shot Semantic Segmentation,Applications -> Image Segmentation,Algorithms -> Few-Shot Learning,Vision,"['Ping Hu', ' Stan Sclaroff', ' Kate Saenko']",{'Boston University'},1,0,0,{'USA'}
Delta-STN: Efficient Bilevel Optimization for Neural Networks using Structured Response Jacobians,"Juhan Bae, Roger B. Grosse",Delta-STN: Efficient Bilevel Optimization for Neural Networks using Structured Response Jacobians,f754186469a933256d7d64095e963594,https://proceedings.neurips.cc/paper/2020/file/f754186469a933256d7d64095e963594-Paper.pdf,"Most application of deep learning involves regularization hyperparameters, and hyperparameter tuning is one stage of a much longer pipeline. Hence, any discussion of societal impacts would necessarily be speculative. One predictable impact of this work is to lessen the need for massive computing resources to tune hyperparameters.",Broader Impact,47,3,FALSE,FALSE,FALSE,FALSE,FALSE,Delta-STN: Efficient Bilevel Optimization for Neural Networks using Structured Response Jacobians,Deep Learning -> Optimization for Deep Networks,Algorithms -> AutoML,Deep learning,"['Juhan Bae', ' Roger Grosse']",{'University of Toronto'},1,0,0,{'Canada'}
First-Order Methods for Large-Scale Market Equilibrium Computation,"Yuan Gao, Christian Kroer",First-Order Methods for Large-Scale Market Equilibrium Computation,f75526659f31040afeb61cb7133e4e6d,https://proceedings.neurips.cc/paper/2020/file/f75526659f31040afeb61cb7133e4e6d-Paper.pdf,"As mentioned in the introduction, large-scale market equilibrium computation problems arise in important applications such as Internet advertising markets, course assignment at universities, fair recommender systems and compute resource allocation. As such, this work has the following potential positive societal impact: Based on this work, resource allocation schemes, especially those with desirable fairness properties, that were previously deemed hard to solve at scale (and are thus simplified or disregarded), can be implemented in reasonable time through computing a market equilibrium by a first-order method. Progress of a FOM can be easily monitored via the duality gap while feasibility is guaranteed. Our work also enables greater scalability of certain Internet advertising market equilibrium models. This could be used for greater market efficiency or better monetization of such markets. Whether this is viewed as a positive or negative thing is beyond the scope of our paper.",8 Broader Impact,144,6,,,FALSE,FALSE,FALSE,First-Order Methods for Large-Scale Market Equilibrium Computation,Theory -> Game Theory and Computational Economics,Optimization -> Convex Optimization,Optimization Methods (continuous or discrete),"['Yuan Gao', ' Christian Kroer']",{'Columbia University'},1,0,0,{'USA'}
Minimax Optimal Nonparametric Estimation of Heterogeneous Treatment Effects,"Zijun Gao, Yanjun Han",Minimax Optimal Nonparametric Estimation of Heterogeneous Treatment Effects,f75b757d3459c3e93e98ddab7b903938,https://proceedings.neurips.cc/paper/2020/file/f75b757d3459c3e93e98ddab7b903938-Paper.pdf,"This work mainly provides theoretical tools and bounds for the HTE estimation in causal inference, as well as potentially useful practical insights such as the two-stage nearest-neighbors and throwing away observations with poor covariate matching quality. This special form of nonparametric estimation problems could be a useful addition to the literature in nonparametric statistics, and theorists and practitioners working on causal inference may potentially benefit from this work.",Broader Impact,68,2,,,FALSE,FALSE,FALSE,Minimax Optimal Nonparametric Estimation of Heterogeneous Treatment Effects,Probabilistic Methods -> Causal Inference,Algorithms -> Density Estimation; Theory -> Frequentist Statistics,Causality,"['Zijun Gao', ' Yanjun Han']",{'Stanford University'},1,0,0,{'USA'}
Residual Force Control for Agile Human Behavior Imitation and Extended Motion Synthesis,"Ye Yuan, Kris Kitani",Residual Force Control for Agile Human Behavior Imitation and Extended Motion Synthesis,f76a89f0cb91bc419542ce9fa43902dc,https://proceedings.neurips.cc/paper/2020/file/f76a89f0cb91bc419542ce9fa43902dc-Paper.pdf,"The proposed techniques, RFC and dual policy control, enable us to create virtual humans that can imitate a variety of agile human motions and autonomously exhibit long-term human behaviors. This is useful in many applications. In the context of digital entertainment, animators could use our approach to automatically animate numerous background characters to perform various motions. In game production, designers could make high-fidelity physics-based characters that interact with the environment robustly. In virtual reality (VR), using techniques like ours to improve motion fidelity of digital content could be important for applications such as rehabilitation, sports training, dance instruction and physical therapy. The learned motion policies could also be used for the preservation of cultural heritage such as traditional dances, ceremonies and martial arts. Our research on physics-based human motion synthesis combined with advances of human digitaliza- tion in computer graphics could be used to generate highly realistic human action videos which are visually and physically indistinguishable from real videos. Similar to the creation of ‘deepfakes’ using image synthesis technology, the technology developed in this work could enable more advanced forms of fake video generation, which could lead to the propagation of false information. To mitigate this issue, it is important that future research should continue to investigate the detection of synthesized videos of human motions.",Broader Impact,215,9,,,FALSE,FALSE,FALSE,Residual Force Control for Agile Human Behavior Imitation and Extended Motion Synthesis,Reinforcement Learning and Planning -> Decision and Control,"Applications -> Body Pose, Face, and Gesture Analysis; Applications -> Computer Vision; Applications -> Motor Control",,"['Ye Yuan', ' Kris Kitani']",{'Carnegie Mellon University'},1,0,0,{'USA'}
A General Method for Robust Learning from Batches,"Ayush Jain, Alon Orlitsky",A General Method for Robust Learning from Batches,f7a82ce7e16d9687e7cd9a9feb85d187,https://proceedings.neurips.cc/paper/2020/file/f7a82ce7e16d9687e7cd9a9feb85d187-Paper.pdf,"With the vast increase in data availability, data sources are often corrupt or untrustworthy. This untrusted data severely limits the efficacy of several leaning algorithms, even when a vast amount of the data is available. Yet in many applications the data is collected in batches. We consider two essential problems in machine learning, Classification and distribution estimation. We show that in these applications, the effect of data corruption diminishes with the batch size, and demonstrate how batch structure can be used to reduce the effect of the corrupted or adversarial data, thereby paving a path to more reliable machine learning algorithms.",Broader impact,101,5,,,FALSE,FALSE,FALSE,A General Method for Robust Learning from Batches,Theory -> Statistical Learning Theory,Theory -> Information Theory,Theory (including computational and statistical analyses),"['Ayush Jain', ' Alon Orlitsky']","{'UC San Diego', 'University of California, San Diego'}",1,0,0,{'USA'}
Not All Unlabeled Data are Equal: Learning to Weight Data in Semi-supervised Learning,"Zhongzheng Ren, Raymond Yeh, Alexander Schwing",Not All Unlabeled Data are Equal: Learning to Weight Data in Semi-supervised Learning,f7ac67a9aa8d255282de7d11391e1b69,https://proceedings.neurips.cc/paper/2020/file/f7ac67a9aa8d255282de7d11391e1b69-Paper.pdf,"We propose a method to improve existing semi-supervised learning (SSL) techniques, i.e ., achieving better model performance using a limited amount of labeled data. In general, SSL has a large impact on machine learning applications where labeled data are not widely available, e.g ., biomedical data, or applications where labeling is expensive, e.g ., dense labeling of videos. While our research focuses on classification benchmarks for SSL, in general, improving SSL techniques will further broaden the scope which machine learning can be applied to. Due to this we foresee a potential positive social impact from our work. In general, we observe that data are being labeled based on the demand of the users. Consider speech recognition datasets: for common languages large scale corpora exists, e.g ., the LibriSpeech ASR corpus [30] contains over 1000 hours of English speech. However, very few datasets exist for rare dialects. In other words, minority groups may benefit less from progress in machine learning as the datasets are not collected/labeled. We hope that improvements in SSL will make machine learning more accessible and applicable to everyone as it reduces the need for a collection of large scale labeled data.",Broader Impact,194,9,,,FALSE,FALSE,FALSE,Not All Unlabeled Data are Equal: Learning to Weight Data in Semi-supervised Learning,Algorithms -> Semi-Supervised Learning,Algorithms -> Classification; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Zhongzheng Ren', ' Raymond Yeh', ' Alexander Schwing']","{'University of Illinois at Urbana-Champaign', 'UIUC'}",1,0,0,{'USA'}
Hard Negative Mixing for Contrastive Learning,"Yannis Kalantidis, Mert Bulent Sariyildiz, Noe Pion, Philippe Weinzaepfel, Diane Larlus",Hard Negative Mixing for Contrastive Learning,f7cade80b7cc92b991cf4d2806d6bd78,https://proceedings.neurips.cc/paper/2020/file/f7cade80b7cc92b991cf4d2806d6bd78-Paper.pdf,"Self-supervised tasks and dataset bias. Prominent voices in the field advocate that self-supervised learning will play a central role during the next years in the field of AI. Not only representations learned using self-supervised objectives directly reflect the biases of the underlying dataset, but also it is the responsibility of the scientist to explicitly try to minimize such biases. Given that, the larger the datasets, the harder it is to properly investigate biases in the corpus, we believe that notions of fairness need to be explicitly tackled during the self-supervised optimization, e.g. by regulating fairness on protected attributes. This is especially important for systems whose decisions affect humans and/or their behaviours.  Self-supervised learning, compute and impact on the environment. On the one hand, self- supervised learning involves training large models on very large datasets, on long periods of time. As we also argue in the main paper, the computational cost of every self-supervised learning paper is very high: pre-training for 200 epochs on the relatively small ImageNet-1K dataset requires around 24 GPU days (6 days on 4 GPUs). In this paper we show that, by mining harder negatives, one can get higher performance after training for fewer epochs; we believe that it is indeed important to look deeper into self-supervised learning approaches that utilize the training dataset better and learn generalizable representations faster. Looking at the bigger picture, however, we believe that research in self-supervised learning is highly justified in the long run, despite its high computational cost, for two main reasons. First, the goal of self-supervised learning is to produce models whose representations generalize better and are therefore potentially useful for many subsequent tasks. Hence, having strong models pre-trained by self-supervision would reduce the environmental impact of deploying to multiple new downstream tasks. Second, representations learned from huge corpora have been shown to improve results when directly fine-tuned, or even used as simple feature extractors, on smaller datasets. Most socially minded applications and tasks fall in this situation where they have to deal with limited annotated sets, because of a lack of funding, hence they would directly benefit from making such pretraining models available. Given the considerable budget required for large, high quality datasets, we foresee that strong generalizable representations will greatly benefit socially mindful tasks more than e.g. a multi-billion dollar industry application, where the funding to get large clean datasets already exists.",Broader Impact,398,15,,,FALSE,TRUE,FALSE,Hard Negative Mixing for Contrastive Learning,Algorithms -> Unsupervised Learning,Algorithms -> Metric Learning; Algorithms -> Representation Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Yannis Kalantidis', ' Mert B Sariyildiz', ' Noe Pion', ' Philippe Weinzaepfel', ' Diane Larlus']","{'Facebook', 'NAVER LABS Europe', 'Bilkent University', 'NAVER Labs Europe', 'Naver Labs Europe'}",1,1,1,"{'Turkey', 'South Korea', 'USA'}"
MOReL: Model-Based Offline Reinforcement Learning,"Rahul Kidambi, Aravind Rajeswaran, Praneeth Netrapalli, Thorsten Joachims",MOReL: Model-Based Offline Reinforcement Learning,f7efa4f864ae9b88d43527f4b14f750f,https://proceedings.neurips.cc/paper/2020/file/f7efa4f864ae9b88d43527f4b14f750f-Paper.pdf,"This paper studies offline RL, which allows for data driven policy learning using pre-collected datasets. The ability to train policies offline can expand the range of applications where RL can be applied as well as the sample efficiency of any downstream online learning. Since the dataset has already been collected, offline RL enables us to abstract away the exploration or data collection challenge. Safe exploration is crucial for applications like robotics and healthcare, where poorly designed exploratory actions can have harmful physical consequences. Avoiding online exploration by an autonomous agent, and working with a safely collected dataset, can have the broader impact of alleviating safety challenges in RL. That said, the impact of RL agents to the society at large is highly dependent on the  design of the reward function. If the reward function is designed by malicious actors, any RL agent, be it offline or not, can present negative consequences. Therefore, the design of reward functions requires checks, vetting, and scrutiny to ensure RL algorithms are aligned with societal norms.",Broader Impact,171,8,,,FALSE,FALSE,FALSE,MOReL: Model-Based Offline Reinforcement Learning,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Model-Based RL,Reinforcement learning and planning,"['Rahul Kidambi', ' Aravind Rajeswaran', ' Praneeth Netrapalli', ' Thorsten Joachims']","{'Cornell', 'Microsoft Research', 'University of Washington', 'Cornell University'}",1,1,1,{'USA'}
Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings,"Christopher Morris, Gaurav Rattan, Petra Mutzel",Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings,f81dee42585b3814de199b2e88757f5c,https://proceedings.neurips.cc/paper/2020/file/f81dee42585b3814de199b2e88757f5c-Paper.pdf,"We view our work mainly as a methodological contribution. It studies the limits of current (supervised) graph embeddings methods, commonly used in chemoinformatics [103], bioinformatics [10], or network science [27]. Currently, methods used in practice, such as GNNs or extended-connectivity fingerprints [93] have severe limitations and might miss crucial patterns in today’s complex, inter- connected data. We investigate how to scale up graph embeddings that can deal with higher-order interactions of vertices (or atom of molecules, users in social networks, variables in optimization, . . .) to larger graphs or networks. Hence, our method paves the way for more resource-efficient and expressive graph embeddings. We envision that our (methodological) contributions enable the design of more expressive and scalable graph embeddings in fields such as quantum chemistry, drug-drug interaction prediction, in-silicio, data-driven drug design/generation, and network analysis for social good. However, progress in graph embeddings might also trigger further advancements in hostile social network analysis, e.g., extracting more fine-grained user interactions for social tracking. Example impact We are actively cooperating with chemists on drug design to evaluate further our approach to new databases for small molecules. Here, the development of new databases is quite tedious, and graph embeddings can provide hints to the wet lab researcher where to start their search. However, still, humans need to do much of the intuition-driven, manual wet lab work. Hence, we do not believe that our methods will result in job losses in the life sciences in the foreseeable future.",Broader impact,245,14,FALSE,FALSE,FALSE,TRUE,FALSE,Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings,Algorithms -> Representation Learning,Algorithms -> Classification; Algorithms -> Kernel Methods; Deep Learning -> Embedding Approaches; Deep Learning -> Supervised Deep Networks,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Christopher Morris', ' Gaurav Rattan', ' Petra Mutzel']","{'TU Dortmund University', 'University of Bonn', 'RWTH Aachen University'}",1,0,0,{'Germany'}
Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion,"Qianqian Ma, Alex Olshevsky",Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion,f86890095c957e9b949d11d15f0d0cd5,https://proceedings.neurips.cc/paper/2020/file/f86890095c957e9b949d11d15f0d0cd5-Paper.pdf,"In this work, we provide a new robust matrix completion methods which can make recommendation systems more accurate in the presence of spam. This can benefit users of platforms like Amazon Mechanical Turk and Yelp. In terms of negative impact, our work could allow the same platforms to learn more about the preferences of their users. It is possible that this data could be leaked, resulting in privacy loss.",Broader Impact,69,4,FALSE,FALSE,FALSE,TRUE,FALSE,Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion,Applications -> Recommender Systems,Algorithms -> Collaborative Filtering,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Qianqian Ma', ' Alex Olshevsky']",{'Boston University'},1,0,0,{'USA'}
Learning Semantic-aware Normalization for Generative Adversarial Networks,"Heliang Zheng, Jianlong Fu, Yanhong Zeng, Jiebo Luo, Zheng-Jun Zha",Learning Semantic-aware Normalization for Generative Adversarial Networks,f885a14eaf260d7d9f93c750e1174228,https://proceedings.neurips.cc/paper/2020/file/f885a14eaf260d7d9f93c750e1174228-Paper.pdf,"The proposed image generation approach pursues generating high-fidelity and various image samples. Extensive experiments have shown competitive performance on several benchmark datasets. This work has the potential positive impact of enabling automatic content creation and editing for high- quality multimedia data like images and videos, and generating image variants from existing training datasets at no additional cost to human annotators. By using the synthesized data, the proposed approach may also benefit the training of more computer vision tasks like image classification and object detection for better modeling large data variations in the real world. At the same time, any image generation application runs the risk of producing biased or offensive content as the priors existed in human-curated training datasets. Besides, the rapid progress in image generation and manipulation has now come to a point where it raises significant concerns in our society. Leveraging powerful image generation technologies (including the proposed approach in this paper) to manipulate or generate visual content with a high potential to deceive might cause harm, especially by spreading fake information. More work is needed to build towards a more automated pipeline for image generation, review, and publishing.",Broader Impact,191,8,,,FALSE,FALSE,FALSE,Learning Semantic-aware Normalization for Generative Adversarial Networks,Applications -> Computer Vision,Deep Learning -> Generative Models,Vision,"['Heliang Zheng', ' Jianlong Fu', ' Yanhong Zeng', 'Jun Zha', ' Jiebo Luo']","{'University of Science and Technology of China', 'Sun Yat-sen University', 'Microsoft Research'}",1,1,1,"{'USA', 'China'}"
Differentiable Causal Discovery from Interventional Data,"Philippe Brouillard, Sébastien Lachapelle, Alexandre Lacoste, Simon Lacoste-Julien, Alexandre Drouin",Differentiable Causal Discovery from Interventional Data,f8b7aa3a0d349d9562b424160ad18612,https://proceedings.neurips.cc/paper/2020/file/f8b7aa3a0d349d9562b424160ad18612-Paper.pdf,"Causal structure learning algorithms are general tools that address two high-level tasks: understanding and acting. That is, they can help a user understand a complex system and, once such an understanding is achieved, they can help in recommending actions. We envision positive impacts of our work in fields such as scientific investigation (e.g., interpreting and anticipating the outcome of experiments), policy making for decision-makers (e.g., identifying actions that could stimulate economic growth), and improving policies in autonomous agents (e.g., learning causal relationships in the world via interaction). As a concrete example, consider the case of gene knockouts/knockdowns experiments in the field of genomics, which aim to understand how specific genes and diseases interact [55]. Learning causal models using interventions performed in this setting could help gain precious insight into gene pathways, which may catalyze the development of better pharmaceutic targets and broaden our understanding of complex diseases such as cancer. Of course, applications are likely to extend beyond these examples which seem natural from our current position. Like any methodological contribution, our work is not immune to undesirable applications that could have negative impacts. For instance, it would be possible, yet unethical for a policy-maker to use our algorithm to understand how specific human-rights violations can reduce crime and recommend their enforcement. The burden of using our work within ethical and benevolent boundaries would rely on the user. Furthermore, even when used in a positive application, our method could have unintended consequences if used without understanding its assumptions. In order to use our method correctly, it is crucial to understand the assumptions that it makes about the data. When such assumptions are not met, the results may still be valid, but should be used as a support to decision rather than be considered as the absolute truth. These assumptions are: • Causal sufficiency: there are no hidden confounding variables • The samples for a given interventional distribution are independent and identically distributed • The causal relationships form an acyclic graph (no feedback loops) • Our theoretical results are valid in the infinite-data regime We encourage users to be mindful of this and to carefully analyze their results before making decisions that could have a significant downstream impact.",Broader impact,367,13,,,TRUE,TRUE,FALSE,Differentiable Causal Discovery from Interventional Data,Probabilistic Methods -> Causal Inference,Algorithms -> Density Estimation; Algorithms -> Model Selection and Structure Learning; Deep Learning,Causality,"['Philippe Brouillard', ' Sébastien Lachapelle', ' Alexandre Lacoste', 'Julien', ' Alexandre Drouin']","{'Element AI', 'Mila, Université de Montréal', 'Mila'}",1,1,1,{'Canada'}
One-sample Guided Object Representation Disassembling,"Zunlei Feng, Yongming He, Xinchao Wang, Xin Gao, Jie Lei, Cheng Jin, Mingli Song",One-sample Guided Object Representation Disassembling,f8e59f4b2fe7c5705bf878bbd494ccdf,https://proceedings.neurips.cc/paper/2020/file/f8e59f4b2fe7c5705bf878bbd494ccdf-Paper.pdf,"This research belongs to the image representation learning area. Positive: the proposed method can be applied to many machine learning tasks, including image editing, image classification, few/zero- shot learning, and visual concepts learning. It supplies a universal tool for other downstream tasks. Negative: the research can be adopted to generate some fake image, which also can be used for malicious purposes.",Broader Impact,61,4,,,FALSE,FALSE,FALSE,One-sample Guided Object Representation Disassembling,Deep Learning,Algorithms -> Representation Learning; Applications -> Computer Vision; Applications -> Network Analysis,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Zunlei Feng', ' Yongming He', ' Xinchao Wang', ' Xin Gao', ' Jie Lei', ' Cheng Jin', ' Mingli Song']","{'Stevens Institute of Technology', 'Zhejiang University', 'Fudan University', 'Alibaba Group'}",1,1,1,"{'USA', 'China'}"
Extrapolation Towards Imaginary 0-Nearest Neighbour and Its Improved Convergence Rate,"Akifumi Okuno, Hidetoshi Shimodaira",Extrapolation Towards Imaginary 0 -Nearest Neighbour and Its Improved Convergence Rate,f9028faec74be6ec9b852b0a542e2f39,https://proceedings.neurips.cc/paper/2020/file/f9028faec74be6ec9b852b0a542e2f39-Paper.pdf,"For improving the convergence rate of the conventional k -NN, we propose to consider a simple extrapolation idea; it provides an intuitive understanding of not only the optimal k -NN but also more general nonparametric statistics. By virtue of the simplicity, MS- k -NN is also easy to implement; the similar idea may be applied to some other statistical and machine learning methods.",Broader Impact,63,2,,,FALSE,FALSE,FALSE,Extrapolation Towards Imaginary 0-Nearest Neighbour and Its Improved Convergence Rate,Theory -> Statistical Learning Theory,Algorithms -> Classification,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Akifumi Okuno', ' Hidetoshi Shimodaira']","{'Kyoto University / RIKEN AIP', 'RIKEN AIP'}",1,0,0,{'Japan'}
Robust Persistence Diagrams using Reproducing Kernels,"Siddharth Vishwanath, Kenji Fukumizu, Satoshi Kuriki, Bharath K. Sriperumbudur",Robust Persistence Diagrams using Reproducing Kernels,f99499791ad90c9c0ba9852622d0d15f,https://proceedings.neurips.cc/paper/2020/file/f99499791ad90c9c0ba9852622d0d15f-Paper.pdf,"Over the last decade, Topological Data Analysis has become an important tool for extracting geometric and topological information from data, and its applications have been far reaching. For example, it has been used successfully in the study the fragile X-syndrome, to discover traumatic brain injuries, and has also become an important tool in the study of protein structure. In astrophysics, it has aided the study of cosmic microwave background, and the discovery of cosmic voids and filamental structures in cosmological data. With a continual increase in its adoption in data analysis, it has become important to understand the limitations of using persistent homology in machine learning applications. As real-world data is often flustered with measurement errors and other forms of noise, in this work, we examine the sensitivity of persistence diagrams to such noise, and provide methods to mitigate the effect of this noise, so as to make reliable topological inference.",Broader Impact,151,5,,,FALSE,FALSE,FALSE,Robust Persistence Diagrams using Reproducing Kernels,Algorithms -> Kernel Methods,Algorithms -> Density Estimation; Theory -> Frequentist Statistics; Theory -> Regularization; Theory -> Spaces of Functions and Kernels; Theory -> Statistical Learning Theory,Theory (including computational and statistical analyses),"['Siddharth Vishwanath', ' Kenji Fukumizu', ' Satoshi Kuriki', ' Bharath Sriperumbudur']","{'Institute of Statistical Mathematics', 'Penn State University', 'The Pennsylvania State University', 'Institute of Statistical Mathematics / Preferred Networks / RIKEN AIP'}",1,1,1,"{'Japan', 'USA'}"
Contextual Games: Multi-Agent Learning with Side Information,"Pier Giuseppe Sessa, Ilija Bogunovic, Andreas Krause, Maryam Kamgarpour",Contextual Games: Multi-Agent Learning with Side Information,f9afa97535cf7c8789a1c50a2cd83787,https://proceedings.neurips.cc/paper/2020/file/f9afa97535cf7c8789a1c50a2cd83787-Paper.pdf,"As systems using machine learning get deployed more and more widely, these systems increasingly interact with each other. Examples range from road traffic over auctions and financial markets, to robotic systems. Understanding these interactions and their effects for individual participants and the reliability of the overall system becomes ever more important. We believe our work contributes positively to this challenge by studying principled algorithms that are efficient, while converging to suitable, and often efficient, equilibria.",Broader Impact,75,4,,,FALSE,FALSE,FALSE,Contextual Games: Multi-Agent Learning with Side Information,Theory -> Game Theory and Computational Economics,Algorithms -> Bandit Algorithms; Algorithms -> Online Learning; Probabilistic Methods -> Gaussian Processes,Reinforcement learning and planning,"['Pier Giuseppe Sessa', ' Ilija Bogunovic', ' Andreas Krause', ' Maryam Kamgarpour']","{'ETH Zurich', 'ETH Zürich'}",1,0,0,{'Switzerland'}
Goal-directed Generation of Discrete Structures with Conditional Generative Models,"Amina Mollaysa, Brooks Paige, Alexandros Kalousis",Goal-directed Generation of Discrete Structures with Conditional Generative Models,f9b9f0fef2274a6b7009b5d52f44a3b6,https://proceedings.neurips.cc/paper/2020/file/f9b9f0fef2274a6b7009b5d52f44a3b6-Paper.pdf,"When a training dataset of suitable examples is available, the methodology introduced by this paper provides an easy approach to learning conditional models. These models otherwise would be fit using an expensive reinforcement learning algorithm, or by less-performant maximum likelihood estimation. Our hope is that learning algorithms that are simpler to tune can help drive adoption of machine learning methods by the broader scientific community, and may help reduce computational and energy requirements for training these models. Furthermore, we are not aware of existing work that trains a single model capable of conditional generation of molecules given such a diverse set of properties; we believe this application and its results will be of independent interest to the computational chemistry community.",Broader Impact,120,4,,,FALSE,FALSE,FALSE,Goal-directed Generation of Discrete Structures with Conditional Generative Models,Deep Learning -> Generative Models,Algorithms -> Structured Prediction; Deep Learning -> Efficient Training Methods,Deep learning,"['Maolaaisha Aminanmu', ' Brooks Paige', ' Alexandros Kalousis']","{'University of Applied Sciences, Western Switzerland', 'University of Geneva,University of Applied Sciences Western Switzerland', 'University College London'}",1,0,0,"{'UK', 'Switzerland'}"
Beyond Lazy Training for Over-parameterized Tensor Decomposition,"Xiang Wang, Chenwei Wu, Jason D. Lee, Tengyu Ma, Rong Ge",Beyond Lazy Training for Over-parameterized Tensor Decomposition,f9d3a954de63277730a1c66d8b38dee3,https://proceedings.neurips.cc/paper/2020/file/f9d3a954de63277730a1c66d8b38dee3-Paper.pdf,This work does not present any foreseeable societal consequence.,Broader Impact,9,1,TRUE,FALSE,FALSE,FALSE,FALSE,Beyond Lazy Training for Over-parameterized Tensor Decomposition,Optimization -> Non-Convex Optimization,Applications -> Matrix and Tensor Factorization,Theory (including computational and statistical analyses),"['Xiang Wang', ' Chenwei Wu', ' Jason Lee', ' Tengyu Ma', ' Rong Ge']","{'Stanford University', 'Princeton University', 'Duke University'}",1,0,0,{'USA'}
Denoised Smoothing: A Provable Defense for Pretrained Classifiers,"Hadi Salman, Mingjie Sun, Greg Yang, Ashish Kapoor, J. Zico Kolter",Denoised Smoothing: A Provable Defense for Pretrained Classifiers,f9fd2624beefbc7808e4e405d73f57ab,https://proceedings.neurips.cc/paper/2020/file/f9fd2624beefbc7808e4e405d73f57ab-Paper.pdf,"The vulnerability of deep learning to adversarial attacks poses serious problems in many safety critical computer vision applications, including self-driving cars. Our method is a step towards building robust models that can be deployed reliably in the real world. Using our method, any off-the-shelf classifier, for the first time, can immediately be wrapped by our framework and converted into a provably robust one as we demonstrate on four real world online APIs. Furthermore, one major use case of our method is when users of public APIs want to get provably robust predictions from these APIs, but can not really change or retrain these APIs as they are black-box for them. Our method helps these users simply convert these APIs into provably robust ones by wrapping them with our framework. We believe this is an important step towards having machine learning confidently and safely used and deployed.",Statement of Broader Impact,146,6,,,FALSE,FALSE,FALSE,Denoised Smoothing: A Provable Defense for Pretrained Classifiers,Algorithms -> Adversarial Learning,Social Aspects of Machine Learning -> AI Safety,,"['Hadi Salman', ' Mingjie Sun', ' Greg Yang', ' Ashish Kapoor', ' Zico Kolter']","{'Microsoft Research', 'Carnegie Mellon University', 'Microsoft', 'Carnegie Mellon University / Bosch Center for AI', 'Microsoft Research AI'}",1,1,1,"{'USA', 'Germany'}"
Minibatch Stochastic Approximate Proximal Point Methods,"Hilal Asi, Karan Chadha, Gary Cheng, John C. Duchi",Minibatch Stochastic Approximate Proximal Point Methods,fa2246fa0fdf0d3e270c86767b77ba1b,https://proceedings.neurips.cc/paper/2020/file/fa2246fa0fdf0d3e270c86767b77ba1b-Paper.pdf,"Data centers draw increasing amounts of the total energy we consume, and increasing applications of machine learning mean that model-fitting and parameter exploration require a larger and larger proportion of their energy expenditures [1, 14, 30]. Indeed, as Asi and Duchi [1] note, the energy to train and tune some models is roughly on the scale of driving thousands of cars from San Francisco to Los Angeles, while training a modern transformer network (with architecture search) generates roughly six times the total CO 2 of an average car’s lifetime [30]. It is thus centrally important to build more efficient and robust methods, which allow us to avoid wasteful hyperparameter search but simply work. A major challenge in building better algorithms is that fundamental physical limits have forced CPU speed and energy to essentially plateau; only by parallelization can we harness both increasing speed and reduce the energy to fit models [14]. In this context, our methods take a step toward reducing the energy and overhead to perform machine learning. Taking a step farther back, we believe optimization and model-fitting research in machine learning should refocus its attention: rather than developing algorithms that, with appropriate hyperparameter tuning, achieve state-of-the-art accuracy for a given dataset, we should evaluate algorithms by whether they robustly work. This would allow a more careful consideration of an algorithms’ costs and benefits: is it worth 2 × faster training, for appropriate hyperparameters, if one has to spend 25 × as much time to find the appropriate algorithmic hyperparameters? Even more, as Strubell et al. [30] point out, the extraordinary costs of hyperparameter tuning for fitting large-scale models price many researchers out of making progress on certain frontiers; to the extent that we can mitigate these challenges, we will allow more equity in who can help machine learning progress.",Broader Impact,301,9,,,FALSE,FALSE,FALSE,Minibatch Stochastic Approximate Proximal Point Methods,Optimization -> Convex Optimization,Optimization -> Stochastic Optimization,Optimization Methods (continuous or discrete),"['Hilal Asi', ' Karan Chadha', ' Gary Cheng', ' John Duchi']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
Attribute Prototype Network for Zero-Shot Learning,"Wenjia Xu, Yongqin Xian, Jiuniu Wang, Bernt Schiele, Zeynep Akata",Attribute Prototype Network for Zero-Shot Learning,fa2431bf9d65058fe34e9713e32d60e6,https://proceedings.neurips.cc/paper/2020/file/fa2431bf9d65058fe34e9713e32d60e6-Paper.pdf,"Computers have become much smarter over the past decades, but they cannot distinguish between two objects without a properly annotated training dataset. Since humans can learn general representations that generalize well across many classes, they require very little or even no training data to recognize novel classes. Zero-shot learning aims to mimic this ability to recognize objects using only some class level descriptions (e.g., identify a bird according to the color and pattern of bird body parts), and takes a first step to build a machine that has a similar decision process as humans. Therefore, ZSL techniques would benefit those who do not have access to large-scale annotated datasets, e.g. a wildlife biologist who wants to build an automatic classification system for rare animals. Our work introduces an attribute prototype network, which is good at predicting attributes with local features. Specifically, we deal with the attribute correlation problem, where the network cannot tell attributes apart because they co-occur very often, eg, the yellow forehead and yellow crown of birds. By decorrelating attribute prototypes, we use the local information for predicting attributes, rather than using the correlated contexts, which is an important direction that we hope there will be a greater focus by the community. Additionally, we strengthen the interpretability of the inference process, by highlighting the attributes our model has learnt in the image. Interpretability is important for helping users to understand the learning process and check model errors. Broadly speaking, there are two shortcuts of zero-shot learning. Firstly, the prediction accuracy is still lower than models trained with both seen and unseen classes. Thus ZSL is not applicable to those settings that require high accuracy and confidence, e.g., self-driving cars. Secondly, the model’s generalization ability depends to a great extent on the quality of side information that describes the similarity between seen and unseen classes. Thus biased side information might harm the generalization ability of ZSL models.",Broader Impact,318,14,FALSE,FALSE,FALSE,FALSE,FALSE,Attribute Prototype Network for Zero-Shot Learning,Algorithms -> Few-Shot Learning,"Algorithms -> Representation Learning; Deep Learning -> Visualization, Interpretability, and Explainability","Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Wenjia Xu', ' Yongqin Xian', ' Jiuniu Wang', ' Bernt Schiele', ' Zeynep Akata']","{'Max Planck Institute for Informatics', 'City University of Hong Kong', 'University of Tübingen', 'Max Planck Institute Informatics', 'University of Chinese Academy of Sciences'}",1,0,0,"{'China', 'Germany'}"
CrossTransformers: spatially-aware few-shot transfer,"Carl Doersch, Ankush Gupta, Andrew Zisserman",CrossTransformers: spatially-aware few-shot transfer,fa28c6cdf8dd6f41a657c3d7caa5c709,https://proceedings.neurips.cc/paper/2020/file/fa28c6cdf8dd6f41a657c3d7caa5c709-Paper.pdf,"The algorithm presented in this paper most directly applies to few-shot recognition, which has numerous uses in industry, including vision systems for robotics that must adapt to new objects, and photo-organizing software which must infer the presence of new classes of objects on-the-fly. Unfamiliar objects are ubiquitous in many real-world vision applications due to the so-called ‘long tail’ [93] of objects that occur in real scenes, and therefore we expect our algorithm to improve the robustness of visual recognition systems. While our current work only addresses classification, many other tasks in computer vision, such as object detection and segmentation, use neural network representations that can likewise be made more robust using the kind of architectures presented here. Our algorithm attempts to build representations which factorize the object recognition problem into sub-problems (feature correspondence and feature comparison) that will each transfer correctly to new datasets. We hope that further research in this direction may help address dataset biases, including biases regarding race, gender, or other attributes [96], by helping to disentangle the truly meaningful traits from the spurious correlations. Finally, while this algorithm presents an advance to state-of-the-art in understanding rare objects, the general performance of such systems is still far below human performance. For safety-critical applications (e.g., surgery or self-driving cars), relying on the ability of vision systems to correctly interpret unusual situations is risky with current systems, even with the advances presented here.",Broader Impact,234,7,,,FALSE,FALSE,FALSE,CrossTransformers: spatially-aware few-shot transfer,Algorithms -> Multitask and Transfer Learning,Algorithms -> Representation Learning; Applications -> Computer Vision; Applications -> Object Recognition; Applications -> Visual Scene Analysis and Interpretation; Deep Learning -> Analysis and Understanding of Deep Networks,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Carl Doersch', ' Ankush Gupta', ' Andrew Zisserman']",{'DeepMind'},0,1,0,{'UK'}
Learning Latent Space Energy-Based Prior Model,"Bo Pang, Tian Han, Erik Nijkamp, Song-Chun Zhu, Ying Nian Wu",Learning Latent Space Energy-Based Prior Model,fa3060edb66e6ff4507886f9912e1ab9,https://proceedings.neurips.cc/paper/2020/file/fa3060edb66e6ff4507886f9912e1ab9-Paper.pdf,"Our work can be of interest to researchers working on generator model, energy-based models, MCMC sampling and unsupervised learning. It may also be of interest to people who are interested in image synthesis and text generation.",Broader Impact,36,2,FALSE,FALSE,FALSE,FALSE,FALSE,Learning Latent Space Energy-Based Prior Model,Deep Learning -> Generative Models,Probabilistic Methods -> Latent Variable Models,Probabilistic methods and inference,"['Bo Pang', ' Tian Han', ' Erik Nijkamp', 'Chun Zhu', ' Ying Nian Wu']","{'UCLA', 'University of California Los Angeles', 'University of California, Los Angeles', 'Stevens Institute of Technology'}",1,1,1,{'USA'}
SEVIR : A Storm Event Imagery Dataset for Deep Learning Applications in Radar and Satellite Meteorology,"Mark Veillette, Siddharth Samsi, Chris Mattioli",SEVIR : A Storm Event Imagery Dataset for Deep Learning Applications in Radar and Satellite Meteorology,fa78a16157fed00d7a80515818432169,https://proceedings.neurips.cc/paper/2020/file/fa78a16157fed00d7a80515818432169-Paper.pdf,"This work offers a free and open dataset with the purpose of advancing machine learning applications in the area of meteorology. In addition to the dataset, we offer two benchmark problems with working implementations and evaluation metrics. These will allow other researchers to easily build off of this work to create new and enhanced capabilities. Authors do not foresee negative ethical consequences as a result of this work. A potential positive societal impact may arise from the development of models that can generate radar imagery from modalities that are not available world-wide. This could give new meteorological monitoring capabilities to underdeveloped or low resource societies.",Broader Impact,105,6,,,FALSE,FALSE,FALSE,SEVIR : A Storm Event Imagery Dataset for Deep Learning Applications in Radar and Satellite Meteorology,"Data, Challenges, Implementations, and Software","Algorithms -> Adversarial Learning; Algorithms -> Regression; Data, Challenges, Implementations, and Software -> Benchmarks; Data, Challenges, Implementations, and Software -> Data Sets or Data Repositories; Data, Challenges, Implementations, and Software -> Software Toolkits","Datasets, challenges, software","['Siddharth Samsi', ' Mark Veillette', ' Chris Mattioli']",{'MIT Lincoln Laboratory'},1,0,0,{'USA'}
Lightweight Generative Adversarial Networks for Text-Guided Image Manipulation,"Bowen Li, Xiaojuan Qi, Philip Torr, Thomas Lukasiewicz",Lightweight Generative Adversarial Networks for Text-Guided Image Manipulation,fae0b27c451c728867a567e8c1bb4e53,https://proceedings.neurips.cc/paper/2020/file/fae0b27c451c728867a567e8c1bb4e53-Paper.pdf,"We have proposed a novel lightweight generative adversarial network for efficient image manipulation using natural language descriptions. To achieve this, we have introduced a powerful word-level discriminator, which can provide the generator with fine-grained training feedback in terms of each word in the given description, contributing to the construction of a lightweight architecture without sacrificing much image quality. Furthermore, the proposed novel word-level discriminator can be easily implemented in other tasks involving different modality features, e.g., text-to-image generation and visual question answering, which is able to provide the generator with fine-grained supervisory feedback explicitly related to each word, to facilitate training a lightweight generator that has a small number of parameters, but can still achieve a satisfactory performance. Additionally, our powerful word-level discriminator allows to further simplify the architecture of the discriminator, enabling to build a complete lightweight network and thus providing the possibility to train a powerful and efficient neural network on memory-limited devices, such as mobile phones.",6 Broader Impact,159,4,,,FALSE,FALSE,FALSE,Lightweight Generative Adversarial Networks for Text-Guided Image Manipulation,Deep Learning -> Generative Models,Applications -> Computer Vision,Deep learning,"['Bowen Li', ' Xiaojuan Qi', ' Philip Torr', ' Thomas Lukasiewicz']","{'The University of Hong Kong', 'University of Oxford'}",1,0,0,"{'UK', 'China'}"
High-Dimensional Contextual Policy Search with Unknown Context Rewards using Bayesian Optimization,"Qing Feng , Ben Letham, Hongzi Mao, Eytan Bakshy",High-Dimensional Contextual Policy Search with Unknown Context Rewards using Bayesian Optimization,faff959d885ec0ecf70741a846c34d1d,https://proceedings.neurips.cc/paper/2020/file/faff959d885ec0ecf70741a846c34d1d-Paper.pdf,"The methods introduced in this paper expand the scope of problems to which contextual Bayesian optimization can be applied, and are especially important for settings where policies are evaluated with A/B tests. We expect this work to be directly beneficial in this setting, for instance for improving services at Internet companies as in the ABR example that we described in the paper. We are including our complete code for all of the models introduced in this paper, so the work will be immediately useful. As shown in the paper, contextualization improves not only the top-line performance of policies, but also improves the fairness of policies by improving outcomes specifically for small populations that do not achieve good performance under an existing non-contextual policy. This work will directly benefit these currently under-served populations.",Broader Impact,132,5,,,FALSE,FALSE,FALSE,High-Dimensional Contextual Policy Search with Unknown Context Rewards using Bayesian Optimization,Optimization,Optimization -> Non-Convex Optimization; Probabilistic Methods -> Gaussian Processes,Optimization Methods (continuous or discrete),"['Qing Feng', ' Ben Letham', ' Hongzi Mao', ' Eytan Bakshy']","{'MIT', 'Facebook'}",1,1,1,{'USA'}
Model Fusion via Optimal Transport,"Sidak Pal Singh, Martin Jaggi",Model Fusion via Optimal Transport,fb2697869f56484404c8ceee2985b01d,https://proceedings.neurips.cc/paper/2020/file/fb2697869f56484404c8ceee2985b01d-Paper.pdf,"Model fusion is a fundamental building block in machine learning, as a way of direct knowledge transfer between trained neural networks. Beyond theoretical interest it can serve a wide range of concrete applications. For instance, collaborative learning schemes such as federated learning are of increasing importance for enabling privacy-preserving training of ML models, as well as a better alignment of each individual’s data ownership with the resulting utility from jointly trained machine learning models, especially in applications where data is user-provided and privacy sensitive [29]. Here fusion of several models is a key building block to allow several agents to participate in joint training and knowledge exchange. We propose that a reliable fusion technique can serve as a step towards more broadly enabling privacy-preserving and efficient collaborative learning.",Broader Impact,128,5,,,FALSE,FALSE,FALSE,Model Fusion via Optimal Transport,Deep Learning,Algorithms -> Boosting and Ensemble Methods; Algorithms -> Multitask and Transfer Learning,Deep learning,"['Sidak Pal Singh', ' Martin Jaggi']",{'EPFL'},1,0,0,{'Switzerland'}
On the Stability and Convergence of Robust Adversarial Reinforcement Learning: A Case Study on Linear Quadratic Systems,"Kaiqing Zhang, Bin Hu, Tamer Basar",On the Stability and Convergence of Robust Adversarial Reinforcement Learning: A Case Study on Linear Quadratic Systems,fb2e203234df6dee15934e448ee88971,https://proceedings.neurips.cc/paper/2020/file/fb2e203234df6dee15934e448ee88971-Paper.pdf,"We believe that researchers of reinforcement learning (RL), especially those who are interested in the theoretical foundations of robust RL, would benefit from this work, through the new insights and angles we have provided regarding robust adversarial RL (RARL) in linear quadratic (LQ) setups, from a rigorous robust control perspective. In particular, considering the impact of RARL [2] in RL with prominent empirical performance, and the ubiquity and fundamentality of LQ setups in continuous control, our results help pave the way for applying the RARL idea in control tasks. More importantly, building upon the concepts from robust control, we have laid emphasis on the robust stability of RARL algorithms when applied to control systems, which has been overlooked in the RL literature, and is significant in continuous control, as a destabilized system can lead to catastrophic consequences. Such emphasis may encourage the development of more robust, and more importantly, safe on-the-fly , RARL algorithms, and push forward the development of RL for safety-critical systems as a whole. It also opens up the possibility to integrate more tools from the classic (robust) control theory, to improve the stability and robustness of popular RL algorithms practically used. We do not believe that our research will cause any ethical issue, or put anyone at any disadvantage.",Broader Impact,213,6,,,FALSE,FALSE,FALSE,On the Stability and Convergence of Robust Adversarial Reinforcement Learning: A Case Study on Linear Quadratic Systems,Theory -> Control Theory,Algorithms -> Dynamical Systems; Social Aspects of Machine Learning -> AI Safety,Reinforcement learning and planning,"['Kaiqing Zhang', 'Champaign', ' Bin Hu', ' Tamer Basar']","{'University of Illinois at Urbana-Champaign', 'UIUC'}",1,0,0,{'USA'}
Learning Individually Inferred Communication for Multi-Agent Cooperation,"Ziluo Ding, Tiejun Huang, Zongqing Lu",Learning Individually Inferred Communication for Multi-Agent Cooperation,fb2fcd534b0ff3bbed73cc51df620323,https://proceedings.neurips.cc/paper/2020/file/fb2fcd534b0ff3bbed73cc51df620323-Paper.pdf,"The experimental results are encouraging in the sense that we demonstrate I2C is a promising method for dealing with targeted communication in multi-agent communication based on causal influence. It is not yet at the application stage, and does not have broader impact. However, this work learns one-to-one communication instead of one/all-to-all communication, making I2C more practical in real-world applications.",Broader Impact,59,3,TRUE,TRUE,FALSE,FALSE,FALSE,Learning Individually Inferred Communication for Multi-Agent Cooperation,Reinforcement Learning and Planning -> Multi-Agent RL,,,"['Ziluo Ding', ' Tiejun Huang', ' Zongqing Lu']",{'Peking University'},1,0,0,{'China'}
Set2Graph: Learning Graphs From Sets,"Hadar Serviansky, Nimrod Segol, Jonathan Shlomi, Kyle Cranmer, Eilam Gross, Haggai Maron, Yaron Lipman",Set2Graph: Learning Graphs From Sets,fb4ab556bc42d6f0ee0f9e24ec4d1af0,https://proceedings.neurips.cc/paper/2020/file/fb4ab556bc42d6f0ee0f9e24ec4d1af0-Paper.pdf,"Our contribution describes a class of neural network models for functions from sets to graphs and includes theoretical results that the model family is universal. The potential uses of these models is very broad and includes the physical sciences, computer graphics, and social networks. The paper includes experiments that show the positive impact of these models in the context of particle physics, and similar tasks appear repeatedly in the physical sciences. The models could also be used for social networks and areas with more complex ethical and societal consequences. Because the models treat the input as a set and are permutation equivariant, they have the potential to mitigate potential bias in data due to sorting and other pre-processing that could impact methods that treat the input as a sequence. Otherwise, the considerations of bias in the data and impact of failure are no different for our model than the generic considerations of the use of supervised learning and neural networks. Finally we note that the models we describe are already being used in real-world particle physics research.",Broader Impact,177,7,,,FALSE,FALSE,FALSE,Set2Graph: Learning Graphs From Sets,Deep Learning,Deep Learning -> Analysis and Understanding of Deep Networks; Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Hadar Serviansky', ' Nimrod Segol', ' Jonathan Shlomi', ' Kyle Cranmer', ' Eilam Gross', ' Haggai Maron', ' Yaron Lipman']","{'NVIDIA Research', 'Weizmann Institute of Science', 'New York University'}",1,1,1,"{'USA', 'Israel'}"
Graph Random Neural Networks for Semi-Supervised Learning on Graphs,"Wenzheng Feng, Jie Zhang, Yuxiao Dong, Yu Han, Huanbo Luan, Qian Xu, Qiang Yang, Evgeny Kharlamov, Jie Tang",Graph Random Neural Networks for Semi-Supervised Learning on Graphs,fb4c835feb0a65cc39739320d7a51c02,https://proceedings.neurips.cc/paper/2020/file/fb4c835feb0a65cc39739320d7a51c02-Paper.pdf,"Over the past years, GNNs have been extensively studied and widely used for semi-supervised graph learning, with the majority of efforts devoted to designing advanced and complex GNN architectures. Instead of heading towards that direction, our work focuses on an alternative perspective by examining whether and how simple and traditional machine learning (ML) techniques can help overcome the common issues that most GNNs faced, including over-smoothing, non-robustness, and weak generalization. Instead of the nonlinear feature transformations and advanced neural techniques (e.g., attention), the presented G RAND model is built upon dropout (and its simple variant), linear feature propagation, and consistency regularization—the common ML techniques. Its consistent and significant outperformance over 14 state-of-the-art GNN baselines demonstrates the effectiveness of our alternative direction. In addition, our results also echo the recent discovery in SGC [39] to better understand the source of GCNs’ expressive power. More importantly, these simple ML techniques in G RAND empower it to be more robust, better avoid over-smoothing, and offer stronger generalization than GNNs. In light of these advantages, we argue that the ideas in G RAND offer a different perspective in understanding and advancing GNN based semi-supervised learning. For future research in GNNs, in addition to designing complex architectures, we could also invest in simple and traditional graph techniques under the regularization framework which has been widely used in (traditional) semi- supervised learning.",Broader Impact,226,8,,,FALSE,FALSE,FALSE,Graph Random Neural Networks for Semi-Supervised Learning on Graphs,Algorithms -> Representation Learning,Algorithms -> Relational Learning; Algorithms -> Semi-Supervised Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Wenzheng Feng', ' Jie Zhang', ' Yuxiao Dong', ' Yu Han', ' Huanbo Luan', ' Qian Xu', ' Qiang Yang', ' Evgeny Kharlamov', ' Jie Tang']","{'WeBank and HKUST', 'WeBank', 'Microsoft', 'Bosch Center for Artificial Intelligence', 'Tsinghua University'}",1,1,1,"{'USA', 'China', 'Germany'}"
Gradient Boosted Normalizing Flows,"Robert Giaquinto, Arindam Banerjee",Gradient Boosted Normalizing Flows,fb5d9e209ebda9ab6556a31639190622,https://proceedings.neurips.cc/paper/2020/file/fb5d9e209ebda9ab6556a31639190622-Paper.pdf,"As a generative model, gradient boosted normalizing flows (GBNF) are suited for a variety of tasks, including the synthesis of new data-points. A primary motivation for choosing GBNF, in particular, is producing a flexible model that can synthesize new data-points quickly. GBNF’s individual components can be less complex and thus faster, yet as a whole the model is powerful. Since the components operate in parallel, prediction and sampling can be done quickly—a valuable characteristic for deployment on mobile devices. One limitation of GBNF is the requirement for additional computing resources to train the added components, which can be costly for deep flow- based models. As such, GBNF advantages research laboratories and businesses with access to scalable computing. Those with limited computing resources may find benchmarking or deploying GBNF too costly.",8 Broader Impact,130,7,,,FALSE,FALSE,FALSE,Gradient Boosted Normalizing Flows,Deep Learning -> Generative Models,Algorithms -> Boosting and Ensemble Methods; Algorithms -> Density Estimation; Probabilistic Methods -> Variational Inference,,"['Robert Giaquinto', ' Arindam Banerjee']","{'University of Minnesota', 'University of Minnesota, Twin Cities'}",1,0,0,{'USA'}
Open Graph Benchmark: Datasets for Machine Learning on Graphs,"Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, Jure Leskovec",Open Graph Benchmark: Datasets for Machine Learning on Graphs,fb60d411a5c5b72b2e7d3527cfc84fd0,https://proceedings.neurips.cc/paper/2020/file/fb60d411a5c5b72b2e7d3527cfc84fd0-Paper.pdf,"We expect the Open Graph Benchmark (OGB) to have a significant impact on fundamental graph ML research as well as many of its application domains. We also discuss a potential negative impact. Impact on Graph ML Research Historically, high-quality and large-scale datasets have played significant roles in advancing research fields (e.g., IMAGENET [23], MS-COCO [58], GLUE benchmark [86], SQUAD [69]). The amount of impact these datasets have brought is enormous, leading to the significant methodological advancements in the respective fields [24, 39]. We expect OGB to be a standard benchmark in graph ML, contributing to the significant advancements of the field. To this end, our datasets are carefully designed to address the two major drawbacks of current graph benchmark datasets, namely (1) small dataset sizes, and (2) unrealistic random splits. Overall, OGB provides a set of diverse, realistic, and large-scale graph datasets to facilitate the development of graph ML models that are scalable and generalizable under realistic data splits, both of which are crucial in practice. In addition, OGB aims to address the fundamental problem of reproducibility in graph ML research. We promote the reproducibility by standardizing the research pipeline, as illustrated in Figure 2, and provide official leaderboards, for which public code is mandatory to make a submission. Altogether, OGB incentivises researchers to release their code, and allows researchers to easily compare different models under equal settings. Impact on Diverse Application Domains In OGB, we have curated graph datasets that are relevant to a variety of practical and realistic application domains, including science (e.g., biology, chemistry), knowledge graphs, academic graphs, and source code ASTs. For example, we provided a biomedical knowledge graph (ogbl-biokg), where algorithmic advances on this dataset can be immediately translated into solutions for problems in precision medicine. In another example, we provide a dataset of 450K molecular graphs (ogbg-molpcba) that have direct implications for drug discovery. In academic domains, we prepared a variety of prediction tasks (e.g., recommending missing citations as well as future collaborations, predicting paper categories and venues, etc.), solving which can lead to improved scholarly efficiency and to better organization of academic knowledge. In technological domains, OGB includes a dataset of source code snippets (ogbg-code). The development of graph ML models on this dataset can lead to exciting applications for advanced code analysis and retrieval. To further increase the impact of OGB, all of our datasets are mapped to real entities in the world. For example, each node in the drug-drug interaction network (ogbl-ddi) is mapped to a unique Drug ID in DrugBank [90], each molecule in the molecule datasets (ogbg-mol*) is mapped to a SMILES string that uniquely identifies the molecule, and each node in the paper citation networks (ogbn-arxiv and ogbn-papers100M) is mapped into a real research paper indexed by the Microsoft Academic Graph [87]. Such mappings to real entities allow researchers to draw scientific insight and to augment the graphs with external information. Potential Negative Impact If OGB becomes the standard de-facto benchmark for graph ML, one potential negative impact is that OGB might contribute to narrowing down the scope of future papers to the tasks and dataset types that have been included in OGB. In order to avoid such a negative impact, we will regularly update our datasets and tasks, based on the input from the community.",Broader Impact,548,22,,,TRUE,TRUE,FALSE,Open Graph Benchmark: Datasets for Machine Learning on Graphs,"Data, Challenges, Implementations, and Software -> Benchmarks",Algorithms -> Relational Learning,"Datasets, challenges, software","['Weihua Hu', ' Matthias Fey', ' Marinka Zitnik', ' Yuxiao Dong', ' Hongyu Ren', ' Bowen Liu', ' Michele Catasta', ' Jure Leskovec']","{'Stanford University', 'Stanford University and Pinterest', 'Microsoft', 'Harvard University', 'TU Dortmund University'}",1,1,1,"{'USA', 'Germany'}"
Towards Understanding Hierarchical Learning: Benefits of Neural Representations,"Minshuo Chen, Yu Bai, Jason D. Lee, Tuo Zhao, Huan Wang, Caiming Xiong, Richard Socher",Towards Understanding Hierarchical Learning: Benefits of Neural Representations,fb647ca6672b0930e9d00dc384d8b16f,https://proceedings.neurips.cc/paper/2020/file/fb647ca6672b0930e9d00dc384d8b16f-Paper.pdf,"This paper extensively contributes to the theoretical frontier of deep learning. We do not foresee direct ethical or societal consequences. Instead, our theoretical finding reduces the gap between the theory and practice, and is in sharp contrast to existing theories, which cannot show any advantage of deep networks over the shallow ones. In viewing of a notably increasing trend towards establishing a quantitative framework using deep neural networks in diverse areas, e.g., computational social science, this paper will provide an important theoretical guideline for practitioners.",Broader impact,85,4,,,FALSE,FALSE,FALSE,Towards Understanding Hierarchical Learning: Benefits of Neural Representations,Deep Learning -> Analysis and Understanding of Deep Networks,,Theory (including computational and statistical analyses),"['Minshuo Chen', ' Yu Bai', ' Jason Lee', ' Tuo Zhao', ' Huan Wang', ' Caiming Xiong', ' Richard Socher']","{'Salesforce', 'Salesforce Research', 'Princeton University', 'Georgia Tech', 'Gatech'}",1,1,1,{'USA'}
Texture Interpolation for Probing Visual Perception,"Jonathan Vacher, Aida Davila, Adam Kohn, Ruben  Coen-Cagli",Texture Interpolation for Probing Visual Perception,fba9d88164f3e2d9109ee770223212a0,https://proceedings.neurips.cc/paper/2020/file/fba9d88164f3e2d9109ee770223212a0-Paper.pdf,"Any protocol that quantifies perception could potentially be turned into a diagnostic tool. Apart from that, our work does not present any foreseeable societal consequence.",Broader Impact,25,2,TRUE,TRUE,FALSE,FALSE,FALSE,Texture Interpolation for Probing Visual Perception,Neuroscience and Cognitive Science -> Visual Perception,Applications -> Computer Vision; Neuroscience and Cognitive Science -> Cognitive Science,Vision,"['Jonathan Vacher', ' Aida Davila', ' Adam Kohn', 'Cagli']",{'Albert Einstein College of Medicine'},1,0,0,{'USA'}
Hierarchical Neural Architecture Search for Deep Stereo Matching,"Xuelian Cheng, Yiran Zhong, Mehrtash Harandi, Yuchao Dai, Xiaojun Chang, Hongdong Li, Tom Drummond, Zongyuan Ge",Hierarchical Neural Architecture Search for Deep Stereo Matching,fc146be0b230d7e0a92e66a6114b840d,https://proceedings.neurips.cc/paper/2020/file/fc146be0b230d7e0a92e66a6114b840d-Paper.pdf,"The task of stereo matching has been studied for over half a century and numerous methods have been proposed. From traditional methods to deep learning based methods, people keep setting a new state-of-the-art through these years. Nowadays, deep learning based methods become more popular than traditional methods since deep methods are more accurate and faster. However, finding a better architecture for stereo matching networks remains a hot topic recently. Rather than designing a handcrafted architecture with trial and error, we propose to allow the network to learn a good architecture by itself in an end-to-end manner. Our method reduces more than 2 / 3 of searching time than previous method [25] and has much better performance, thus saves lots of energy consumption and good for our planet by reducing massive carbon footprints. In addition, our proposed search framework is relatively general and not limited to the specific task of stereo matching. It can be well extended to other dense matching tasks such as optical flow estimation and multi-view stereo.",Broader Impact,169,8,,,FALSE,FALSE,FALSE,Hierarchical Neural Architecture Search for Deep Stereo Matching,Applications -> Computer Vision,Algorithms -> AutoML,Vision,"['Xuelian Cheng', ' Yiran Zhong', ' Mehrtash T Harandi', ' Yuchao Dai', ' Xiaojun Chang', ' Hongdong Li', ' Tom Drummond', ' Zongyuan Ge']","{'Northwestern Polytechnical University', 'Monash University', 'Australian National University'}",1,0,0,"{'Australia', 'China'}"
MuSCLE: Multi Sweep Compression of LiDAR using Deep Entropy Models,"Sourav Biswas, Jerry Liu, Kelvin Wong, Shenlong Wang, Raquel Urtasun",MuSCLE: Multi Sweep Compression of LiDAR using Deep Entropy Models,fc152e73692bc3c934d248f639d9e963,https://proceedings.neurips.cc/paper/2020/file/fc152e73692bc3c934d248f639d9e963-Paper.pdf,"On an immediate level, our contributions are directly applicable as a data compression algorithm in a novel problem setting: the greater we can maximize the performance of such an algorithm, the more we can reduce the storage cost and space required by point clouds. We hope that this in turn unlocks a milestone towards fulfilling our ultimate vision: scaling up the research and deployment of intelligent robots, such as self-driving vehicles, that will revolutionize the safety, efficiency, and convenience of our transportation infrastructure. By capturing the 3D geometry of the scene, LiDAR sensors have proven to be crucial in effective and safe prediction/planning of these robots. Currently, LiDAR sensors are not only expensive due to the upfront cost, but also due to the recurring costs of the massive quantities of data they generate. Good point cloud and LiDAR compression algorithms will thus help to democratize the usage of LiDAR by making it more feasible for people to own and operate. Perhaps just as importantly, our responsibility as researchers in a novel problem area led us to carefully consider the downstream impacts of such a compression algorithm—if the primary usage of LiDAR currently is on perception tasks, such as detection and segmentation, then we need to demonstrate how compression bitrate affects perception performance, helping the community determine the acceptable bitrate at which compression can be used for safe vision and robotics applications. We hope that our work inspires the community to further advance sensor compression in addition to the traditional image and video settings.",Broader Impact,253,7,,,FALSE,FALSE,FALSE,MuSCLE: Multi Sweep Compression of LiDAR using Deep Entropy Models,Algorithms -> Data Compression,Algorithms -> Uncertainty Estimation; Applications -> Computer Vision; Applications -> Robotics,Deep learning,"['Sourav Biswas', ' Jerry Liu', ' Kelvin Wong', ' Shenlong Wang', ' Raquel Urtasun']","{'University of Waterloo', 'Uber ATG', 'University of Toronto'}",1,1,1,"{'Canada', 'USA'}"
Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy,"Edward Moroshko, Blake E. Woodworth, Suriya Gunasekar, Jason D. Lee, Nati Srebro, Daniel Soudry",Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy,fc2022c89b61c76bbef978f1370660bf,https://proceedings.neurips.cc/paper/2020/file/fc2022c89b61c76bbef978f1370660bf-Paper.pdf,"The goal of this work is to shed light on the implicit bias hidden in the training process of deep networks. These results may enable a better understanding of how hyperparameters select the types of solutions that deep networks converge to, which in turn affect their final generalization performance and hidden biases. This could lead to better performance guarantees or to improved training algorithms which quickly converge to beneficial types of biases. Eventually, we believe progress on these fronts can transform deep learning from the current nascent “alchemy” age (where all the “knobs and levers” of the model and the training algorithm are tuned mostly heuristically during research and development), to a more mature field (like “chemistry”), which can be seamlessly integrated in many real world applications that require high performance, safety, and fair decisions. Our guiding principal is that when studying a new or not-yet-understood phenomena, we should first study it in the simplest model that shows it, so as not to get distracted by possible confounders, and to enable a detailed analytic understanding, e.g., when understanding or teaching many statistical issues, we would typically start with linear regression, understand the phenomena there, and then move on to more complex models. In the specific case here, one of the few models where we have an analytic handle on the implicit bias in the “rich” regime are linear diagonal networks, and it would be very optimistic to hope to get a detailed analytic description of the more complex phenomena we study in models where we can’t even understand the endpoint.",Broader Impact,260,6,,,FALSE,FALSE,FALSE,Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy,Deep Learning -> Analysis and Understanding of Deep Networks,Deep Learning -> Optimization for Deep Networks,Deep learning,"['Edward Moroshko', ' Suriya Gunasekar', ' Blake Woodworth', ' Jason Lee', ' Nati Srebro', ' Daniel Soudry']","{'TTIC', 'Princeton University', 'Technion', 'TTI-Chicago', 'Microsoft Research Redmond'}",1,1,1,"{'USA', 'Israel'}"
Focus of Attention Improves Information Transfer in Visual Features,"Matteo Tiezzi, Stefano Melacci, Alessandro Betti, Marco Maggini, Marco Gori",Focus of Attention Improves Information Transfer in Visual Features,fc2dc7d20994a777cfd5e6de734fe254,https://proceedings.neurips.cc/paper/2020/file/fc2dc7d20994a777cfd5e6de734fe254-Paper.pdf,"Our work is a foundational study. We believe that there are neither ethical aspects nor future societal consequences that should be discussed at the current state of our work. Unsupervised criteria paired with a spatio-temporal filtering can potentially lead to the development of more robust features to describe visual information. In particular, the outcomes of this work could help in designing improved neural models, capable of extracting relevant information from a continuous video stream, from the same areas that attract the human gaze.",Broader Impact,83,4,,,FALSE,FALSE,FALSE,Focus of Attention Improves Information Transfer in Visual Features,Neuroscience and Cognitive Science -> Visual Perception,Algorithms -> Online Learning; Algorithms -> Unsupervised Learning; Theory -> Information Theory,Vision,"['Matteo Tiezzi', ' Stefano Melacci', ' Alessandro Betti', ' Marco Maggini', ' Marco Gori']",{'University of Siena'},1,0,0,{'Italy'}
Auditing Differentially Private Machine Learning: How Private is Private SGD?,"Matthew Jagielski, Jonathan Ullman, Alina Oprea",Auditing Differentially Private Machine Learning: How Private is Private SGD?,fc4ddc15f9f4b4b06ef7844d6bb53abf,https://proceedings.neurips.cc/paper/2020/file/fc4ddc15f9f4b4b06ef7844d6bb53abf-Paper.pdf,"Differentially private algorithms have the potential to unlock the societal benefits of analyzing datasets of sensitive information while giving strong protections of individual privacy . While all differentially private algorithms offer a strong qualitative privacy guarantee, the specific quantitative implications  of specific deployments are not as well understood, and, in order to give high utility, these systems only offer weak worst-case guarantees. The concern is that such systems might only be offering a veneer of individual privacy, and we believe this status quo poses significant risk. We believe our work is a step towards giving organizations the information and tools they need to make informed decisions about the implications of specific deployments of differential privacy. Moreover, our work can support those working on new methods and tools to ultimately push the Pareto frontier of privacy-utility tradeoffs forward. We note that the sort of individual privacy guarantees do not address all possible concerns about how data is used, not even all concerns that are informally described as “privacy concerns.” Our work cannot ultimately answer when and how differential privacy should or should not be used in specific applications, it merely provides the people entrusted with making those decisions with correct information. This situation is similar to cryptography, where tools like encryption address specific problems, and must be used carefully and only when appropriate, but better encryption technology, or exposing the flaws of specific encryption technologies enables better policy decisions. Lastly, we point out that our work only exposes potential privacy risks in experiments based on public benchmark datasets. We have not used our methods to reveal any sensitive information about real individuals that was previously believed to be private. As with cryptanalysis, it is important to follow ethical disclosure guidelines of any attacks against deployed systems to balance the value of public knowledge of the breach versus harm to existing users.",6 Broader Impact,310,10,,,FALSE,FALSE,FALSE,Auditing Differentially Private Machine Learning: How Private is Private SGD?,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Matthew Jagielski', ' Jonathan Ullman', ' Alina Oprea']",{'Northeastern University'},1,0,0,{'USA'}
A Dynamical Central Limit Theorem for Shallow Neural Networks,"Zhengdao Chen, Grant Rotskoff, Joan Bruna, Eric Vanden-Eijnden",A Dynamical Central Limit Theorem for Shallow Neural Networks,fc5b3186f1cf0daece964f78259b7ba0,https://proceedings.neurips.cc/paper/2020/file/fc5b3186f1cf0daece964f78259b7ba0-Paper.pdf,"Our work addresses theoretical guarantees of idealised deep learning (DL) systems, which are critical to one day extend DL applications to the broad spectrum of scientific computing. If successful, DL could transform scientific computing in domains where efficient high-dimensional function estimation is critical, such as molecular dynamics, climate science, or computational drug design. We acknowledge that machine learning improvements like ours come in the form of “building machines to do X better”. For a sufficiently malicious or ill-informed choice of X, almost any progress in machine learning might indirectly lead to a negative outcome, and our work is not excluded from that.",Broader Impact,102,4,,,FALSE,FALSE,FALSE,A Dynamical Central Limit Theorem for Shallow Neural Networks,Theory -> Large Deviations and Asymptotic Analysis,Deep Learning -> Analysis and Understanding of Deep Networks; Theory -> Regularization; Theory -> Spaces of Functions and Kernels; Theory -> Statistical Physics of Learning,Theory (including computational and statistical analyses),"['Zhengdao Chen', ' Grant Rotskoff', ' Joan Bruna', 'Eijnden']","{'New York University', 'NYU'}",1,0,0,{'USA'}
Measuring Systematic Generalization in Neural Proof Generation with Transformers,"Nicolas Gontier, Koustuv Sinha, Siva Reddy, Chris Pal",Measuring Systematic Generalization in Neural Proof Generation with Transformers,fc84ad56f9f547eb89c72b9bac209312,https://proceedings.neurips.cc/paper/2020/file/fc84ad56f9f547eb89c72b9bac209312-Paper.pdf,"Transformer based models have been very effective for various language understanding and generation tasks. Due to their recent successes, there is significant interest in the applications of these models to real world scenarios such as: Dialogue, Question Answering and text-classification. However, failure of such systems could produce nonsensical, wrong or racially-biased results (Henderson et al., 2018). Therefore, a logical analysis of their limitations and issues in generalization to unseen data, such as in this work, could have a positive impact on building safer, more robust and interpretable systems in these domains. In this work, we rely on systematic tests to trigger Transformer-based models to generate an interpretable proof in natural language, and then evaluate the robustness properties of that proof. Using a first-order logic based dataset, we explicitly test the logical consistency of such proof. This research can shed some light into developing more robust and systematic models in the future. In addition, it can help us understand the reasoning strategies employed by Transformer-based models for both inference and generation. However, the fact that proof-free inference works so well, may also imply that models which generate proofs, do so in a decoupled way from the computations yielding the final answer. This negative result could give users a false sense of explainability.",Broader Impact,211,10,,,FALSE,FALSE,FALSE,Measuring Systematic Generalization in Neural Proof Generation with Transformers,Applications -> Natural Language Processing,"Algorithms -> Structured Prediction; Deep Learning -> Visualization, Interpretability, and Explainability; Neuroscience and Cognitive Science -> Reasoning",Natural language processing,"['Nicolas Gontier', ' Koustuv Sinha', ' Siva Reddy', ' Chris Pal']","{'McGill University / Mila / FAIR', 'Montreal Institute for Learning Algorithms, École Polytechnique, Université de Montréal', 'McGill University', 'Mila, Polytechnique Montréal'}",1,1,1,"{'Canada', 'France', 'USA'}"
Big Self-Supervised Models are Strong Semi-Supervised Learners,"Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, Geoffrey E. Hinton",Big Self-Supervised Models are Strong Semi-Supervised Learners,fcbc95ccdd551da181207c0c1400c655,https://proceedings.neurips.cc/paper/2020/file/fcbc95ccdd551da181207c0c1400c655-Paper.pdf,"The findings described in this paper can potentially be harnessed to improve accuracy in any ap- plication of computer vision where it is more expensive or difficult to label additional data than to train larger models. Some such applications are clearly beneficial to society. For example, in medical applications where acquiring high-quality labels requires careful annotation by clinicians, better semi-supervised learning approaches can potentially help save lives. Applications of computer vision to agriculture can increase crop yields, which may help to improve the availability of food. However, we also recognize that our approach could become a component of harmful surveillance systems. Moreover, there is an entire industry built around human labeling services, and technology that reduces the need for these services could lead to a short-term loss of income for some of those currently employed or contracted to provide labels.",6 Broader Impact,140,6,,,FALSE,FALSE,FALSE,Big Self-Supervised Models are Strong Semi-Supervised Learners,Algorithms -> Representation Learning,Algorithms -> Semi-Supervised Learning; Applications -> Computer Vision,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Ting Chen', ' Simon Kornblith', ' Kevin Swersky', ' Mohammad Norouzi', ' Geoffrey E Hinton']","{'Google Brain', 'Google', 'Google & University of Toronto'}",1,1,1,"{'Canada', 'USA'}"
Learning from Label Proportions: A Mutual Contamination Framework,"Clayton Scott, Jianxin Zhang",Learning from Label Proportions: A Mutual Contamination Framework,fcde14913c766cf307c75059e0e89af5,https://proceedings.neurips.cc/paper/2020/file/fcde14913c766cf307c75059e0e89af5-Paper.pdf,"LLP has been discussed as a model for summarizing a fully labeled dataset for public dissemination. The idea is that individual labels are not disclosed, so some degree of privacy is retained. As we show, consistent classification is still possible in this setting. If the two class-conditional distributions are nonoverlapping, labels of training instances can be recovered with no uncertainty by an optimal classifier. If the class-conditional distributions have some overlap, training instances in the nonoverlapping region can still be labeled with no uncertainty, while training instances in the overlapping regions can have their labels guessed with some uncertainty, depending on the degree of overlap.",Broader Impact,105,5,,,FALSE,FALSE,FALSE,Learning from Label Proportions: A Mutual Contamination Framework,Theory -> Statistical Learning Theory,Algorithms -> Classification; Algorithms -> Missing Data,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Clayton Scott', ' Jianxin Zhang']",{'University of Michigan'},1,0,0,{'USA'}
Fast Matrix Square Roots with Applications to Gaussian Processes and Bayesian Optimization,"Geoff Pleiss, Martin Jankowiak, David Eriksson, Anil Damle, Jacob Gardner",Fast Matrix Square Roots with Applications to Gaussian Processes and Bayesian Optimization,fcf55a303b71b84d326fb1d06e332a26,https://proceedings.neurips.cc/paper/2020/file/fcf55a303b71b84d326fb1d06e332a26-Paper.pdf,"This paper introduces an algorithm to improve the efficiency and scalability of a common-place computation. The results section highlights three common use cases of this algorithm: variational Gaussian processes, Bayesian optimization, and Gibbs sampling. While there are other potential use-cases of this method, we will focus on the broader impacts with respect to these three applications.  Variational Gaussian processes and Gibbs sampling are common methods. Other researchers have focused on domains like medicine [28, 68], geo-statistics [19, 73], and time-series modelling [64, 81] to motivate the need for increased scalability and efficiency. We believe that our proposed algorithm will make Gaussian process models and Gibbs sampling techniques increasingly applicable in these settings. Researchers/practitioners in these fields might have previously been unable to use Gaussian processes/Gibbs sampling due to scalability issues. While we believe increasing the scalability and usability of these probabilistic techniques is a worthwhile goal, we note that they require additional care when using. If a system is to rely on probabilistic methods for calibrated uncertainty estimates, it will no longer be sufficient to iterate on accuracy as a target method. We also note that performing meaningful probabilistic inferences requires some level of domain expertise regarding modeling priors and potential biases of sampling/variational approximations. Bayesian optimization is a tool commonly used for hyperparameter optimization [72], A/B testing [5], and other black-box optimization problems. One of the most popular and best performing acquisition functions is Thompson sampling, which requires sampling the unknown function at a candidate set. The primary benefit of the proposed method is better optimization, which could lead to better machine learning models (via better hyperparameter searches) and faster experimental testing (via A/B testing). We would argue that improving the efficiency of such algorithms poses minimal risk beyond more general concerns about potential misapplications of the underlying technology to the optimization of nefarious objectives, intentionally or otherwise. However, we will make note here of some general risks associated with black-box optimization: a potential over-reliance on fully automated methods and computationally expensive searches for what might be marginal improvements. We have release an open-sourced implementation of this algorithm to facilitate the adoption of this method. 8 Since our method relies on quadrature approximations and iterative refinement, one mode of failure is when such iterations fail to converge to a good estimate (for example, due to bad conditioning). However, there are several easy-to-perform convergence checks (e.g. the msMINRES residual), and such convergence checks are part of our implementation to catch such failure cases.",Broader Impact,413,18,,,FALSE,FALSE,FALSE,Fast Matrix Square Roots with Applications to Gaussian Processes and Bayesian Optimization,Probabilistic Methods -> Gaussian Processes,,Probabilistic methods and inference,"['Geoff Pleiss', ' Martin Jankowiak', ' David Eriksson', ' Anil Damle', ' Jacob Gardner']","{'Facebook', 'University of Pennsylvania', 'Columbia University', 'Uber AI Labs', 'Cornell University'}",1,1,1,{'USA'}
Self-Adaptively Learning to Demoiré from Focused and Defocused Image Pairs,"Lin Liu, Shanxin Yuan, Jianzhuang Liu, Liping Bao, Gregory Slabaugh, Qi Tian",Self-Adaptively Learning to Demoiré from Focused and Defocused Image Pairs,fd348179ec677c5560d4cd9c3ffb6cd9,https://proceedings.neurips.cc/paper/2020/file/fd348179ec677c5560d4cd9c3ffb6cd9-Paper.pdf,"Our method improves the quality of photographs taken from a digital camera, by removing moiré patterns to restore an underlying clean, moiré-free image. By design, the algorithm produces restored images that are more faithful to the true scene. This makes the photograph’s information more apparent and representative. It is envisioned better quality images will have a positive societal benefit, making visually recorded information more detailed, informative, and useful. With any approach that improves image quality also comes the risk of negative uses, such as privacy issues. For images of natural scenes, further downstream applications such as surveillance and tracking may become more effective particularly in high-frequency regions of an image where moiré patterns are more likely. Another consideration is that by removing moiré patterns from pictures taken of digital displays, it may become more difficult to determine, from the image alone, if it is taken of natural scene or of a display such as a computer screen. Potentially this could make it easier for one to take a photograph of a digital screen and claim that the photo is an authentic capture of real scene. However, there may be other indicators if the photo is taken of the screen, particularly if the layout of the LCD elements are visible. Potential future research could explore the difficulty of classifying screen and natural images, with and without demoiréd results produced by the proposed method. We note, although our method substantially improves the state-of-the-art, it is not perfect and its failures may result in moiré patterns to remain in an image, or be replaced with blurry outputs. As the method is self-adaptive, learning at test-time from two images, we believe the implications of learning from biased data to be minimal.",Broader Impact,287,12,,,FALSE,FALSE,FALSE,Self-Adaptively Learning to Demoiré from Focused and Defocused Image Pairs,Applications -> Computer Vision,Applications -> Computational Photography,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Lin Liu', ' Shanxin Yuan', 'Huawei Technologies Research and Development', ' Jianzhuang Liu', ' Liping Bao', ' Gregory Slabaugh', ' Qi Tian']","{'University of Science and Technology of China', 'UK'}",1,0,0,"{'UK', 'China'}"
Confounding-Robust Policy Evaluation in Infinite-Horizon Reinforcement Learning,"Nathan Kallus, Angela Zhou",Confounding-Robust Policy Evaluation in Infinite-Horizon Reinforcement Learning,fd4f21f2556dad0ea8b7a5c04eabebda,https://proceedings.neurips.cc/paper/2020/file/fd4f21f2556dad0ea8b7a5c04eabebda-Paper.pdf,"As a contribution to offline RL, our work is of particular importance for RL in the context of social and medical sciences, where experimentation is limited and observational data must be used. The validity of the no-unobserved-confounders assumption is of particular importance to applied research in these fields since the presence of unobserved confounding can bias standard evaluations that assume the issue away and, unchecked, this may potentially hide harms done by the policy being evaluated or learned. Our work is the first step in developing offline RL algorithms that directly address this real, practical issue, and its primary purpose is to directly deal with such biases in the data. That said, it is well understood that there is generally a gap between theory and practice in RL as it is applied to very complex and large-scale systems. It is therefore important to keep in mind practical heuristics, stopgaps, and approximations from applied RL when translating this work into practice. The systematic investigation of the use of these in the context of confounded offline RL and more extensive experimental studies in larger environments may require additional future work. Moreover, there are several general potential dangers to be cognizant of when applying any offline RL tool in practice. First, if the observational data is not representative of the population, that is, there is a covariate shift in the state distribution, then the evaluation will reflect these biases and correspondingly be unrepresentative, under-emphasizing value to some parts of the population and over-emphasizing value to others. More generally, even without covariate shift, here we focused on evaluation of average welfare, which may average the harms to some and the benefits to others; it may therefore be important in some applications to also conduct auxiliary evaluations on certain protected subgroups to ensure equal impact, which can be done by segmenting the data. Third, it is possible that any offline RL approach may be applied inappropriately when the assumptions are not met – here we dealt directly with how to deal with violations of unconfoundedness assumptions but there may still be other assumptions such as our Assumption 1 – and this will mislead any evaluation or learning. For example, concerns about violations of absolute continuity of importance weights (overlap) are especially relevant in the offline RL setting. Therefore, we strongly recommend considering such offline RL and, in particular the sensitivity analyses we developed herein, as a way to inform further investigation, additional data collection, and/or investment in a randomized trial, rather than as an outright replacement for any of these. That said, offline evaluation, especially robust evaluation as we propose herein, is crucial for assessing policies before even trialling them, where they may effect actual negative impacts on study populations.",Broader Impact,455,13,,,FALSE,FALSE,FALSE,Confounding-Robust Policy Evaluation in Infinite-Horizon Reinforcement Learning,Probabilistic Methods -> Causal Inference,Reinforcement Learning and Planning; Theory -> Statistical Learning Theory,,"['Nathan Kallus', ' Angela Zhou']",{'Cornell University'},1,0,0,{'USA'}
Model Class Reliance for Random Forests,"Gavin Smith, Roberto Mansilla, James Goulding",Model Class Reliance for Random Forests,fd512441a1a791770a6fa573d688bff5,https://proceedings.neurips.cc/paper/2020/file/fd512441a1a791770a6fa573d688bff5-Paper.pdf,"The proposed work has the potential for significant societal impact. Understanding alternative predictive relationships that machine learnt models could equally be employing in their decision making while still achieving the same predictive performance is important for many applications. One particular case is when machine learnt models are then used in a way that significantly affects people’s lives, such as the recidivism example detailed in this work. As such the approach has a part to play in ensuring algorithm fairness and reducing bias, including in model and data auditing. Other important use cases include scientific exploration of potentially causal factors in large datasets which then can form hypotheses for future causal studies. Without such methods proposed here that can be executed tractably and easily by those outside the field of computer science, the use of machine learning models may lead to misunderstanding if a practitioner assumes the relationship identified by a model is the only one or concludes that their hypothesised relationship does not exist or is not well performing when it is. A similar argument can be made with regard for the need for such techniques in business applications. Again as is discussed in the paper, the approach has applications for marketing and communication. The work could of course be used negatively. Rather than identifying and selecting the model from the set of best models in a principled way that benefits humanity, people could use it to select a model that furthers their aims at the detriment of others while still being able to claim they selected a performance optimal model. When releasing the model in a proprietary package this may go unnoticed.",Broader Impact,273,11,,,FALSE,FALSE,FALSE,Model Class Reliance for Random Forests,Algorithms -> Boosting and Ensemble Methods,"Algorithms -> Model Selection and Structure Learning; Social Aspects of Machine Learning -> Fairness, Accountability, and Transparency","Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Gavin Smith', ' Roberto Mansilla', ' James Goulding']",{'University of Nottingham'},1,0,0,{'UK'}
Follow the Perturbed Leader: Optimism and Fast Parallel Algorithms for Smooth Minimax Games,"Arun Suggala, Praneeth Netrapalli",Follow the Perturbed Leader: Optimism and Fast Parallel Algorithms for Smooth Minimax Games,fd5ac6ce504b74460b93610f39e481f7,https://proceedings.neurips.cc/paper/2020/file/fd5ac6ce504b74460b93610f39e481f7-Paper.pdf,"Many problems in machine learning and statistics have a game theoretic component to them. Two popular modern applications that illustrate this are adversarial training and density estimation using IPMs. These applications often involve solving large-scale minimax games. In many cases these games are nonconvex-nonconcave, which makes it even more harder to find a NE. Existing approaches for solving these games have mostly relied on algorithms from online convex learning. However, such algorithms are not guaranteed to converge to a NE of nonconvex-nonconcave games. As a result, there is a need for faster algorithms for provably solving large-scale nonconvex-nonconcave games. Our work takes a first step towards this goal by proposing fast parallelizable algorithms which provably converge to a NE in both convex and nonconvex settings.",Broader Impact,125,8,FALSE,FALSE,FALSE,FALSE,FALSE,Follow the Perturbed Leader: Optimism and Fast Parallel Algorithms for Smooth Minimax Games,Algorithms -> Online Learning,Optimization,Optimization Methods (continuous or discrete),"['Arun Suggala', ' Praneeth Netrapalli']","{'Microsoft Research', 'Carnegie Mellon University'}",1,1,1,{'USA'}
Agnostic QQ-learning with Function Approximation in Deterministic Systems: Near-Optimal Bounds on Approximation Error and Sample Complexity,"Simon S. Du, Jason D. Lee, Gaurav Mahajan, Ruosong Wang",Agnostic Q -learning with Function Approximation in Deterministic Systems: Near-Optimal Bounds on Approximation Error and Sample Complexity,fd5c905bcd8c3348ad1b35d7231ee2b1,https://proceedings.neurips.cc/paper/2020/file/fd5c905bcd8c3348ad1b35d7231ee2b1-Paper.pdf,"The focus of this paper is purely theoretical, and thus a broader impact discussion is not applicable.",Broader Impact,17,1,TRUE,FALSE,FALSE,FALSE,FALSE,Agnostic $Q$-learning with Function Approximation in Deterministic Systems: Near-Optimal Bounds on Approximation Error and Sample Complexity,Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement Learning and Planning -> Exploration; Theory,Theory (including computational and statistical analyses),"['Simon Du', ' Jason Lee', ' Gaurav Mahajan', ' Ruosong Wang']","{'University of California, San Diego', 'Princeton University', 'Institute for Advanced Study', 'Carnegie Mellon University'}",1,0,0,{'USA'}
Learning to Adapt to Evolving Domains,"Hong Liu, Mingsheng Long, Jianmin Wang, Yu Wang",Learning to Adapt to Evolving Domains,fd69dbe29f156a7ef876a40a94f65599,https://proceedings.neurips.cc/paper/2020/file/fd69dbe29f156a7ef876a40a94f65599-Paper.pdf,"The propose method may open up the applications of domain adaptation in more real-world scenarios. Without access to target labels, it may help protect privacy. As a method of mitigating the negative effect of dataset shift, EAML can also be applied to undo dataset bias in fair machine learning.",Broader Impact,49,3,FALSE,FALSE,FALSE,FALSE,FALSE,Learning to Adapt to Evolving Domains,Algorithms -> Continual Learning,Algorithms -> Meta-Learning,"Learning with limited supervision (e.g., unsupervised learning, active learning, few-shot, meta-learning, transfer learning, etc.)","['Hong Liu', ' Mingsheng Long', ' Jianmin Wang', ' Yu Wang']",{'Tsinghua University'},1,0,0,{'China'}
Synthesizing Tasks for Block-based Programming,"Umair Ahmed, Maria Christakis, Aleksandr Efremov, Nigel Fernandez, Ahana Ghosh, Abhik Roychoudhury, Adish Singla",Synthesizing Tasks for Block-based Programming ∗,fd9dd764a6f1d73f4340d570804eacc4,https://proceedings.neurips.cc/paper/2020/file/fd9dd764a6f1d73f4340d570804eacc4-Paper.pdf,"This paper develops new techniques for improving pedagogy in block-based visual programming environments. Such programming environments are increasingly used nowadays to introduce computing concepts to novice programmers, and our work is motivated by the clear societal need of enhancing K- 12 computing education. In existing systems, the programming tasks are hand-curated by tutors, and the available set of tasks is typically very limited. This severely limits the utility of existing systems for long-term learning as students do not have access to practice tasks for mastering the programming concepts. We take a step towards tackling this challenge by developing a methodology to generate new practice tasks for a student that match a desired level of difficulty and exercise specific programming concepts. Our task synthesis algorithm is able to generate 1000’s of new similar tasks for reference tasks taken from the Hour of Code: Classic Maze challenge by Code.org and the Intro to Programming with Karel course by CodeHS.com . Our extensive experiments and user study further validate the quality of the generated tasks. Our task synthesis algorithm could be useful in many different ways in practical systems. For instance, tutors can assign new practice tasks as homework or quizzes to students to check their knowledge, students can automatically obtain new similar tasks after they failed to solve a given task and received assistance, and intelligent tutoring systems could automatically generate a personalized curriculum of problems for a student for long-term learning.",Broader Impact,240,9,,,FALSE,FALSE,FALSE,Synthesizing Tasks for Block-based Programming,Applications -> Program Understanding and Generation,Applications -> Automated Reasoning and Formal Methods; Applications -> Visual Question Answering,"Other applications (e.g., robotics, biology, climate, finance)","['Umair Ahmed', ' Maria Christakis', ' Aleksandr Efremov', ' Nigel Fernandez', ' Ahana Ghosh', ' Abhik Roychoudhury', ' Adish Singla']","{'MPI-SWS', 'National University of Singapore'}",1,0,0,"{'Singapore', 'Germany'}"
Scalable Belief Propagation via Relaxed Scheduling,"Vitalii Aksenov, Dan Alistarh, Janne H. Korhonen",Relaxed Scheduling for Scalable Belief Propagation,fdb2c3bab9d0701c4a050a4d8d782c7f,https://proceedings.neurips.cc/paper/2020/file/fdb2c3bab9d0701c4a050a4d8d782c7f-Paper.pdf,"As this work is focused on speeding up existing inference techniques and does not focus on a specific application, the main benefit is enabling belief propagation applications to process data sets more efficiently, or enable use of larger data sets. We do not expect direct negative societal consequences to follow from our work, though we note that as with all heuristic machine learning techniques, there is an inherent risk of misinterpreting the results or ignoring biases in the data if proper care is not taken in application of the methods. However, such risks exist regardless of our work.",Broader Impact,98,3,,,FALSE,FALSE,FALSE,Scalable Belief Propagation via Relaxed Scheduling,Probabilistic Methods -> Distributed Inference,Probabilistic Methods -> Belief Propagation,Probabilistic methods and inference,"['Vitalii Aksenov', ' Dan Alistarh', ' Janne Korhonen']",{'IST Austria'},1,0,0,{'Austria'}
Firefly Neural Architecture Descent: a General Approach for Growing Neural Networks,"Lemeng Wu, Bo Liu, Peter Stone, Qiang Liu",Firefly Neural Architecture Descent: a General Approach for Growing Neural Networks,fdbe012e2e11314b96402b32c0df26b7,https://proceedings.neurips.cc/paper/2020/file/fdbe012e2e11314b96402b32c0df26b7-Paper.pdf,"This work develops a new framework that can grow neural networks simply and efficiently, which can be generally used in various applications that using neural networks and positively enhance their capacity and performance. In particular, we anticipate it can be applied on devices which have hard memory/computation constraint, i.e. mobile devices or robots. Our work does not have any negative societal impacts.",Broader Impact,62,3,,,FALSE,FALSE,FALSE,Firefly Neural Architecture Descent: a General Approach for Growing Neural Networks,Deep Learning -> Optimization for Deep Networks,Algorithms -> Continual Learning,AutoML,"['Lemeng Wu', ' Bo Liu', ' Qiang Liu', ' Peter Stone']","{'University of Texas at Austin', 'The University of Texas at Austin', 'UT Austin'}",1,0,0,{'USA'}
Risk-Sensitive Reinforcement Learning: Near-Optimal Risk-Sample Tradeoff in Regret,"Yingjie Fei, Zhuoran Yang, Yudong Chen, Zhaoran Wang, Qiaomin Xie",Risk-Sensitive Reinforcement Learning: Near-Optimal Risk-Sample Tradeoff in Regret,fdc42b6b0ee16a2f866281508ef56730,https://proceedings.neurips.cc/paper/2020/file/fdc42b6b0ee16a2f866281508ef56730-Paper.pdf,"This work contributes to the risk-awareness of machine learning and improves the way RL algorithms handle risks arising from uncertain environments. We have proposed two efficient and model-free algorithms for risk-sensitive RL with the exponential utility. We show that both algorithms follow the principle of Risk-Sensitive Optimism in the Face of Uncertainty (RS-OFU), and they achieve nearly optimal regret bounds with respect to the risk parameter, horizon length and total number of timesteps.",Broader Impact,73,3,,,FALSE,FALSE,FALSE,Risk-Sensitive Reinforcement Learning: Near-Optimal Risk-Sample Tradeoff in Regret,Reinforcement Learning and Planning,Reinforcement Learning and Planning -> Planning; Reinforcement Learning and Planning -> Reinforcement Learning,Reinforcement learning and planning,"['Yingjie Fei', ' Zhuoran Yang', ' Yudong Chen', ' Zhaoran Wang', ' Qiaomin Xie']","{'Princeton', 'Northwestern University', 'Cornell University'}",1,0,0,{'USA'}
Learning to Decode: Reinforcement Learning for Decoding of Sparse Graph-Based Channel Codes,"Salman Habib, Allison Beemer, Joerg Kliewer",Learning to Decode: Reinforcement Learning for Decoding of Sparse Graph-Based Channel Codes,fdd5b16fc8134339089ef25b3cf0e588,https://proceedings.neurips.cc/paper/2020/file/fdd5b16fc8134339089ef25b3cf0e588-Paper.pdf,"The proposed approach outlines a comprehensive RL framework for low-complexity, low-latency, decoding of short-to-moderate length LDPC codes. This approach has broader technological and so- cietal impacts through several complementary mechanisms, elaborated on as follows. One broader impact is on the advancement of information technology – and its benefits to society – through newly established theory and practice in the area of RL-based error correction for linear graph-based codes. As global per-capita information usage continues to grow significantly over the next decade, considerable improvements in error correcting codes will be required in order to satisfy the high- throughput, low-latency requirements of emerging communication systems, while ensuring scalable service requirements for a host of heterogeneous devices. Our application of RL provides a significant gain in performance while reducing decoding complexity for linear graph-based codes. As a consequence, the results of this work have the potential to materially impact our daily lives. In addi- tion, the results presented in this work have the potential to have a significant transformative impact on other critical applications employing low-latency, reliable networked communication. Among many others, these include applications in the fields of healthcare, environmental monitoring, and finance.",Broader Impact,191,8,,,FALSE,FALSE,FALSE,Learning to Decode: Reinforcement Learning for Decoding of Sparse Graph-Based Channel Codes,Theory -> Information Theory,Algorithms -> Bandit Algorithms; Algorithms -> Sparse Coding and Dimensionality Expansion; Reinforcement Learning and Planning -> Markov Decision Processes,Reinforcement learning and planning,"['Salman Habib', ' Allison Beemer', ' Joerg Kliewer']","{'New Jersey Institute of Technology', 'New Jersey Institute of Tech'}",1,0,0,{'USA'}
Faster DBSCAN via subsampled similarity queries,"Heinrich Jiang, Jennifer Jang, Jakub Lacki",Faster DBSCAN via subsampled similarity queries,fdf1bc5669e8ff5ba45d02fded729feb,https://proceedings.neurips.cc/paper/2020/file/fdf1bc5669e8ff5ba45d02fded729feb-Paper.pdf,"As stated in the introduction, DBSCAN has a wide range of applications within machine learning and data mining. Our contribution is a more efficient variant of DBSCAN. The potential impact of SNG-DBSCAN lies in considerable savings in computational resources and further applications of density clustering which weren’t possible before due to scalability constraints.",Broader Impact,53,3,FALSE,FALSE,FALSE,FALSE,FALSE,Faster DBSCAN via subsampled similarity queries,Algorithms -> Clustering,,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Heinrich Jiang', ' Jennifer Jang', ' Jakub Lacki']","{'Google', 'Google Research', 'Uber'}",0,1,0,{'USA'}
De-Anonymizing Text by Fingerprinting Language Generation,"Zhen Sun, Roei Schuster, Vitaly Shmatikov",De-Anonymizing Text by Fingerprinting Language Generation,fdf2aade29d18910051a6c76ae661860,https://proceedings.neurips.cc/paper/2020/file/fdf2aade29d18910051a6c76ae661860-Paper.pdf,"This work will help improve security of ML code by (a) identifying a new category of potential vulnerabilities faced by ML systems that operate on sensitive data, and (b) explaining how to design implementations so as to mitigate this risk. This research will primarily benefit implementors of ML models and, in general, increase trust in ML systems.",Broader Impact,57,2,FALSE,FALSE,FALSE,FALSE,FALSE,De-Anonymizing Text by Fingerprinting Language Generation,"Social Aspects of Machine Learning -> Privacy, Anonymity, and Security",Applications -> Natural Language Processing,"Social aspects of machine learning (e.g., fairness, safety, privacy)","['Zhen Sun', ' Roei Schuster', ' Vitaly Shmatikov']","{'Cornell Tech', 'Cornell University'}",1,0,0,{'USA'}
Multiparameter Persistence Image for Topological Machine Learning,"Mathieu Carrière, Andrew Blumberg",Multiparameter Persistence Images for Topological Machine Learning,fdff71fcab656abfbefaabecab1a7f6d,https://proceedings.neurips.cc/paper/2020/file/fdff71fcab656abfbefaabecab1a7f6d-Paper.pdf,"Multiparameter persistence descriptors are sorely needed to enhance the reach and usability of topological data analysis, since many applications require understanding and encoding multiple filtrations at once. We believe that proposing an efficient descriptor that encodes strictly more information than just the union of all 1D-persistence diagrams associated to slices, and enabling the community to use it with an easy-to-use Python package, can have a significant impact and is an important contribution to data science and topological data analysis. In particular, we hope that our work helps to make topological methods within machine learning more accessible to practitioners.",Broader Impact,98,3,,,FALSE,FALSE,FALSE,Multiparameter Persistence Image for Topological Machine Learning,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning,Algorithms -> Kernel Methods,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['re', ' Andrew Blumberg']","{'Inria Sophia Antipolis', 'University of Texas'}",1,0,0,"{'France', 'USA'}"
PLANS: Neuro-Symbolic Program Learning from Videos,Raphaël Dang-Nhu,PLANS: Neuro-Symbolic Program Learning from Videos,fe131d7f5a6b38b23cc967316c13dae2,https://proceedings.neurips.cc/paper/2020/file/fe131d7f5a6b38b23cc967316c13dae2-Paper.pdf,"The ability to understand agents’ decision making logic from visual input can be applied to real-world observations such as videos of people driving. In this context, a simple example of logic that can be represented by a program is: ""if the traffic light is green, move, else stop"". Since PLANS requires no program supervision, it extends the applicability of prior work to new settings where no ground-truth programs are available. We believe that PLANS can eventually be applied in all contexts involving interaction between agents (human, animal or robotic) and their environment. In the case of human agents, it is essential to foresee the impact on privacy of the observed subjects. In order to avoid privacy violations, it must be carefully assessed in each application of PLANS which components of a person’s decision making logic can be interpreted without being intrusive. While the concern of data privacy is not specific to PLANS, it opens up new ethical and legal questions about the exact meaning and status of describing an agent’s behavior. It is also crucial to protect individuals from misinterpretation of their behavior. Prior systems for program synthesis from visual observations essentially have two failures modes: The first one corresponds to the case where the behavior in one individual video is not understood correctly, which will lead the synthesized program to capture behaviors that have not been actually observed. The second one occurs when the different videos are individually correctly interpreted, but the branching between the different behaviors (represented by the program control-flow) is not correctly inferred. PLANS addresses the first problem by leveraging the prediction confidence of its neural component, and the second by using a rule-based system that offers correctness guarantees. These aspects make PLANS more robust than prior work, which implies more reliability for end-users.",Broader Impact,298,12,,,FALSE,FALSE,FALSE,PLANS: Neuro-Symbolic Program Learning from Videos,Algorithms -> Program Induction,Applications -> Activity and Event Recognition; Applications -> Video Analysis,Reasoning,['Nhu'],{'ETH Zürich'},1,0,0,{'Switzerland'}
Matrix Inference and Estimation in Multi-Layer Models,"Parthe Pandit, Mojtaba Sahraee Ardakan, Sundeep Rangan, Philip Schniter, Alyson K. Fletcher",Matrix Inference and Estimation in Multi-Layer Models,fe2b421b8b5f0e7c355ace66a9fe0206,https://proceedings.neurips.cc/paper/2020/file/fe2b421b8b5f0e7c355ace66a9fe0206-Paper.pdf,"In statistical physics, systems with a large number of degrees of freedom often admit a simplified macroscopic description. Modern neural networks have thousands of hidden units and billions of free parameters; is there an analogous macroscopic description of the dynamics of multi-layer neural networks? This paper identifies some of these macroscopic descriptions that can be used to analyze a large class of optimization problems (See Section 2 for examples) arising in Signal Processing, Data Science, and Machine Learning. The techniques developped in this paper allow analyzing and understanding the fundamental limits of learning in 1 and 2 layer neural networks which are basic building blocks in modern machine learning pipelines.",Broader Impact,110,4,,,FALSE,FALSE,FALSE,Matrix Inference and Estimation in Multi-Layer Models,Theory -> High-Dimensional Inference,Deep Learning -> Deep Autoencoders; Deep Learning -> Generative Models; Theory -> Large Deviations and Asymptotic Analysis; Theory -> Statistical Physics of Learning,Theory (including computational and statistical analyses),"['Parthe Pandit', ' Mojtaba Sahraee Ardakan', ' Sundeep Rangan', ' Philip Schniter', ' Alyson Fletcher']","{'UCLA', 'The Ohio State University', 'University of California, Los Angeles', 'NYU'}",1,1,1,{'USA'}
MeshSDF: Differentiable Iso-Surface Extraction,"Edoardo Remelli, Artem Lukoianov, Stephan Richter, Benoit Guillard, Timur Bagautdinov, Pierre Baque, Pascal Fua",MeshSDF: Differentiable Iso-Surface Extraction,fe40fb944ee700392ed51bfe84dd4e3d,https://proceedings.neurips.cc/paper/2020/file/fe40fb944ee700392ed51bfe84dd4e3d-Paper.pdf,"Computational Fluid Dynamics is key to addressing the critical engineering problem of designing shapes that maximize aerodynamic, hydrodynamic, and heat transfer performance, and much else beside. The techniques we propose therefore have the potential to have a major impact in the field of Computer Assisted Design by unleashing the full power of deep learning in an area where it is not yet fully established.",7 Broader Impact,64,2,,,FALSE,FALSE,FALSE,MeshSDF: Differentiable Iso-Surface Extraction,Algorithms -> Representation Learning,Applications -> Computer Vision; Deep Learning -> Generative Models,Deep learning,"['Edoardo Remelli', ' Artem Lukoyanov', ' Stephan Richter', ' Benoit Guillard', ' Timur Bagautdinov', ' Pierre Baque', ' Pascal Fua']","{'Facebook', 'Neural Concept SA', 'Intel Labs', 'EPFL, Switzerland', 'EPFL'}",1,1,1,"{'USA', 'Switzerland'}"
Variational Interaction Information Maximization for Cross-domain Disentanglement,"HyeongJoo Hwang, Geon-Hyeong Kim, Seunghoon Hong, Kee-Eung Kim",Variational Interaction Information Maximization for Cross-domain Disentanglement,fe663a72b27bdc613873fbbb512f6f67,https://proceedings.neurips.cc/paper/2020/file/fe663a72b27bdc613873fbbb512f6f67-Paper.pdf,"Our method provides an information theoretic perspective on representation learning, and is likely to accelerate research in areas that involve datasets with two data domains with some common factors of variation. One of such areas is image to image translation we tackled in this paper. Beyond the image translation task, our method could be potentially applied to NLP tasks, such as language translation or text summarization where the source and the target data domains share semantics while they also have domain specific factors of variation in syntax. Leveraging IIAE, one could transform a sample from one domain to the other and measure the semantic similarity between languages from two different domains. However, one may exploit disentangled representations for wrongful purposes. For example, our approach could be adopted for Deepfake to generate more diverse fake images. Lastly, we do not see any serious consequences of system failure.",Broader Impact,146,7,,,FALSE,FALSE,FALSE,Variational Interaction Information Maximization for Cross-domain Disentanglement,Algorithms -> Representation Learning,Deep Learning -> Generative Models; Probabilistic Methods -> Latent Variable Models,Deep learning,"['HyeongJoo Hwang', 'Hyeong Kim', ' Seunghoon Hong', 'Eung Kim']","{'Korea Advanced Institute of Science and Technology', 'KAIST'}",1,0,0,{'South Korea'}
Provably Efficient Exploration for Reinforcement Learning Using Unsupervised Learning,"Fei Feng, Ruosong Wang, Wotao Yin, Simon S. Du, Lin Yang",Provably Efficient Exploration for Reinforcement Learning Using Unsupervised Learning,fe73f687e5bc5280214e0486b273a5f9,https://proceedings.neurips.cc/paper/2020/file/fe73f687e5bc5280214e0486b273a5f9-Paper.pdf,"Our research broadens our understanding on the use of unsupervised learning for RL, which in turn can help researchers design new principled algorithms and incorporate safety considerations for more complicated problems. We do not believe that the results in this work will cause any ethical issue, or put anyone at a disadvantage in the society.",Broader Impact,55,2,FALSE,TRUE,FALSE,TRUE,FALSE,Provably Efficient Exploration for Reinforcement Learning Using Unsupervised Learning,Reinforcement Learning and Planning -> Exploration,Theory,Reinforcement learning and planning,"['Fei Feng', ' Ruosong Wang', ' Wotao Yin', ' Simon Du', ' Lin Yang']","{'Alibaba US, DAMO Academy', 'Institute for Advanced Study', 'UCLA', 'University of California, Los Angeles', 'Carnegie Mellon University'}",1,1,1,"{'USA', 'China'}"
Faithful Embeddings for Knowledge Base Queries,"Haitian Sun, Andrew Arnold, Tania Bedrax Weiss, Fernando Pereira, William W. Cohen",Faithful Embeddings for Knowledge Base Queries,fe74074593f21197b7b7be3c08678616,https://proceedings.neurips.cc/paper/2020/file/fe74074593f21197b7b7be3c08678616-Paper.pdf,"Overview. This work addresses a general scientific question, query embedding (QE) for knowledge bases, and evaluates a new method, especially on a KB question-answering (KBQA) task. A key notion in the work the faithfulness of QE methods, that is, their agreement with deductive inference when the relevant premises are explicitly available. The main technical contribution of the paper is to show that massive improvements in faithfulness are possible, and that faithful QE systems can lead to substantial improvements in KBQA. In the following, we discuss how these advances may affect risks and benefits of knowledge representation and question answering technology. Query embedding. QE, and more generally KBE, is a way of generalizing the contents of a KB by building a probabilistic model of the statements in, or entailed by, a KB. This probabilistic model finds statements that could plausibly true, but are not explicitly stored: in essence it is a noisy classifier for possible facts. Two risks need to be considered in any deployment of such technology: first, the underlying KB may contain (mis)information that would improperly affect decisions; second, learned generalizations may be wrong or biased in a variety of ways that would lead to improperly justified decisions. In particular, training data might reflect societal biases that will be therebly incorporated into model predictions. Uses of these technologies should provide audit trails and recourse so that their predictions can be explained to and critiqued by affected parties. KB question-answering. General improvements to KBQA do not have a specific ethical burden, but like any other such technologies, their uses need to be subject to specific scrutiny. The general technology does require particular attention to accuracy-related risks. In particular, we propose a substantial “softening” of the typical KBQA architecture (which generally parses a question to produce a single hard KB query, rather than a soft mixture of embedded queries). In doing this we have replaced traditional KB, a mature and well-understood technology, with QE, a new and less well-understood technology. Although our approach makes learning end-to-end from denotations more convenient, and helps us reach a new state-of-the-art on some benchmarks, it is possible that replacing a hard queries to a KB with soft queries could lead to confusion as to whether answers arise from highly reliable KB facts, reliable reasoning over these facts, or are noise introduced by the soft QE system. As in KBE/QE, this has consequences for downstream tasks is uncertain predictions are misinterpreted by users. Faithful QE. By introducting the notion of faithfullness in studies of approximate knowledge representation in QE, we provided a conceptual yardstick for examining the accuracy and predictability of such systems. In particular, the centroid-sketch formalism we advocate often allows one to approximately distinguish entailed answers vs generalization-based answers by checking sketch membership. In addition to quantitatively improving faithfulness, EmQL ’s set representation thus may qualitatively improve the interpretability of answers. We leave further validation of this conjecture to future work.",Broader Impact,487,23,,,FALSE,TRUE,FALSE,Faithful Embeddings for Knowledge Base Queries,Deep Learning,Applications -> Natural Language Processing,Deep learning,"['Haitian Sun', ' Andrew Arnold', ' Tania Bedrax Weiss', ' Fernando Pereira', ' William Cohen']","{'Google', 'Google AI', 'Amazon', 'Google Research'}",0,1,0,{'USA'}
Wasserstein Distances for Stereo Disparity Estimation,"Divyansh Garg, Yan Wang, Bharath Hariharan, Mark Campbell, Kilian Q. Weinberger, Wei-Lun Chao",Wasserstein Distances for Stereo Disparity Estimation,fe7ecc4de28b2c83c016b5c6c2acd826,https://proceedings.neurips.cc/paper/2020/file/fe7ecc4de28b2c83c016b5c6c2acd826-Paper.pdf,"The end results of this paper are improved depth and disparity estimation, particularly on foreground objects. This is of use to self-driving cars, 3D reconstruction, and other robotics applications. In particular, it has the potential to improve the safety of these systems, as indicated by the increased 3D object detection performance. Our approach can also easily be incorporated into other depth or disparity estimation algorithms for further improvement. While our depth predictions are significantly better, any failure has important safety considerations, such as collisions and accidents. Before deployment, appropriate safety thresholds must be cleared. Our approach does not specifically leverage dataset biases, although being a machine learning approach, it is impacted as much as other machine learning techniques.",Broader Impact,118,7,,,FALSE,TRUE,FALSE,Wasserstein Distances for Stereo Disparity Estimation,Applications -> Computer Vision,Applications -> Object Detection; Theory -> Statistical Learning Theory,Vision,"['Divyansh Garg', ' Yan Wang', ' Bharath Hariharan', ' Mark Campbell', ' Kilian Weinberger', 'Lun Chao', 'Ohio State University']","{'Cornell', 'OSU', 'Cornell University', 'Cornell University / ASAPP Research'}",1,1,1,{'USA'}
Multi-agent Trajectory Prediction with Fuzzy Query Attention,"Nitin Kamra, Hao Zhu, Dweep Kumarbhai Trivedi, Ming Zhang, Yan Liu",Multi-agent Trajectory Prediction with Fuzzy Query Attention,fe87435d12ef7642af67d9bc82a8b3cd,https://proceedings.neurips.cc/paper/2020/file/fe87435d12ef7642af67d9bc82a8b3cd-Paper.pdf,"We have presented a general architecture for multi-agent trajectory prediction which includes the crucial inductive biases of motion. Our FQA attention mechanism models interactions in multi-agent trajectory prediction and outperforms existing state-of-the-art models in many diverse settings. Our architecture relies only on trajectory data and hence can be employed in conjunction to or alternatively as part of visual processing pipelines for trajectory prediction. It can be successfully incorporated in deep learning pipelines for predicting traffic trajectories around self-driving autonomous vehicles, predicting motion of pedestrians on roads etc. Note that while FQA is primarily designed to target interactions, it can be combined with stronger models for modeling intents, e.g., hierarchical policy networks [30] to improve performance on intent-driven prediction setups e.g. in sports analytics for predicting valid or alternative strategies for basketball players.",Broader Impact,132,5,,,FALSE,TRUE,FALSE,Multi-agent Trajectory Prediction with Fuzzy Query Attention,Deep Learning -> Attention Models,Algorithms -> Relational Learning; Deep Learning -> Recurrent Networks,"Other applications (e.g., robotics, biology, climate, finance)","['Nitin Kamra', ' Hao Zhu', ' Dweep Kumarbhai Trivedi', ' Ming Zhang', ' Yan Liu']","{'University of Southern California', 'Peking University'}",1,0,0,"{'USA', 'China'}"
Multilabel Classification by Hierarchical Partitioning and Data-dependent Grouping,"Shashanka Ubaru, Sanjeeb Dash, Arya Mazumdar, Oktay Gunluk",Multilabel Classification by Hierarchical Partitioning and Data-dependent Grouping,fea16e782bc1b1240e4b3c797012e289,https://proceedings.neurips.cc/paper/2020/file/fea16e782bc1b1240e4b3c797012e289-Paper.pdf,"Our work presents a novel approach to solve the extreme multilabel (XML) classification problem. The main contributions of our paper are (a) the use of matrix reordering techniques to hierarchically partition the label space, and (b) the development of a data-dependent group testing scheme, that improves label grouping significantly for MLGT, and can leverage the recently proposed log-time decoding algorithm. These innovations lead to a significantly faster training algorithm compared to most existing methods that yields comparable results. The XML problem is encountered in a number of applications from related searches to ad recommendations to natural language understanding in the technology industry, and from gene and molecule classifications to learning neural activities in scientific data analysis. A fast algorithm like ours will enable prediction in high-throughput and real-time settings, and address some of the limitations in traditional inline search suggestions or approaches for related searches. The preliminary results presented in the supplement demonstrate how the group testing approach achieves learning with less data for MLC. There is increasing interest among research (and defense) agencies in developing learning algorithms that achieve ‘Learning with Less Labels’ (LwLL), see darpa.mil/program/learning-with-less-labels . Thus, the business and research impacts are likely to be significant (and clear).",Broader Impact,201,8,,,FALSE,TRUE,FALSE,Multilabel Classification by Hierarchical Partitioning and Data-dependent Grouping,Algorithms -> Classification,Algorithms -> Data Compression; Algorithms -> Sparsity and Compressed Sensing; Theory -> Information Theory,"Core machine learning methods (e.g., supervised learning, ranking, clustering, metric learning, etc.)","['Shashanka Ubaru', ' Sanjeeb Dash', ' Arya Mazumdar', ' Oktay Gunluk']","{'IBM Research', 'University of Massachusetts Amherst', 'Cornell University'}",1,1,1,{'USA'}
An Analysis of SVD for Deep Rotation Estimation,"Jake Levinson, Carlos Esteves, Kefan Chen, Noah Snavely, Angjoo Kanazawa, Afshin Rostamizadeh, Ameesh Makadia",An Analysis of SVD for Deep Rotation Estimation,fec3392b0dc073244d38eba1feb8e6b7,https://proceedings.neurips.cc/paper/2020/file/fec3392b0dc073244d38eba1feb8e6b7-Paper.pdf,"This work considers the a fundamental question of how to best represent 3D rotation matrices in neural networks. This is a core component of many 3D vision and robotics deep learning pipelines, so any broader impact will be determined by applications or research that integrate our proposal into their systems.",6 Broader impact,50,2,FALSE,FALSE,FALSE,TRUE,FALSE,An Analysis of SVD for Deep Rotation Estimation,Applications -> Computer Vision,Algorithms -> Regression; Applications -> Robotics; Neuroscience and Cognitive Science -> Perception,Vision,"['Ameesh Makadia', ' Jake Levinson', ' Kefan Chen', ' Noah Snavely', ' Angjoo Kanazawa', ' Afshin Rostamizadeh', ' Carlos Esteves']","{'University of Washington', 'University of Pennsylvania', 'Google Research', 'Google', 'UC Berkeley', 'Cornell University and Google AI'}",1,1,1,{'USA'}
Can the Brain Do Backpropagation? --- Exact Implementation of Backpropagation in Predictive Coding Networks,"Yuhang Song, Thomas Lukasiewicz, Zhenghua Xu, Rafal Bogacz",Can the Brain Do Backpropagation? — Exact Implementation of Backpropagation in Predictive Coding Networks,fec87a37cdeec1c6ecf8181c0aa2d3bf,https://proceedings.neurips.cc/paper/2020/file/fec87a37cdeec1c6ecf8181c0aa2d3bf-Paper.pdf,"This work shows that backpropagation in artificial neural networks can be implemented in a biologically plausible way, providing previously missing evidence to the debate on whether backpropagation could describe learning in the brain. In machine learning, backpropagation drives the contemporary flourish of machine intelligence. However, it has been doubted for long that though backpropagation is indeed powerful, its computational procedure is not possible to be implemented in the brain. Our work provides strong evidence that backpropagation can be implemented in the brain, which will solidify the community’s confidence on pushing forward backpropagation-based machine intelligence. Specifically, the machine learning community may further explore if such equivalence holds for other or more complex BP-based networks. In neuroscience, models based on backpropagation have helped to understand how information is processed in the visual system [15, 16]. However, it was not possible to fully rely on these insights, as backpropagation was so far seen unrealistic for the brain to implement. Our work provides strong confidence to remove such concerns, and thus could lead to a series of future works on understanding the brain with backpropagation. Specifically, the neuroscience community may now use the patterns produced by BP to verify if such computational model can explain learning in brain. Also, our work may inspire researchers to look for the existence of the function φ , which completes the biological foundation of Fa-Z-IL. As for ethical aspects and future societal consequences, we consider our work to be an important step towards understanding biological intelligence, which indicates at least no harm on the ethical aspects. Instead, being able to understand biological intelligence potentially leads to advances in medical research, which will substantially benefit the well-beings of humans.",Broader Impact,280,12,,,FALSE,TRUE,FALSE,Can the Brain Do Backpropagation? --- Exact Implementation of Backpropagation in Predictive Coding Networks,Deep Learning -> Biologically Plausible Deep Networks,Deep Learning -> Analysis and Understanding of Deep Networks,Neuroscience and cognitive science,,"{'University of Oxford', 'Hebei University of Technology'}",1,0,0,"{'UK', 'China'}"
Manifold GPLVMs for discovering non-Euclidean latent structure in neural data,"Kristopher Jensen, Ta-Chu Kao, Marco Tripodi, Guillaume Hennequin",Manifold GPLVMs for discovering non-Euclidean latent structure in neural data,fedc604da8b0f9af74b6cfc0fab2163c,https://proceedings.neurips.cc/paper/2020/file/fedc604da8b0f9af74b6cfc0fab2163c-Paper.pdf,"There are two broad fields which we expect might be influenced by our work. From a technical point of view, mGPLVM extends a probabilistic machine learning toolbox which has downstream applications in fields ranging from speech recognition and image classification to personalized medicine (Ghahramani, 2015). However, this work is primarily geared towards neuroscience, and that is where we expect it to have the largest impact. One tangible application of methods for probabilistic inference in neural populations is in the fields of brain-machine interfaces (BMI) and neuroprosthetics – methods which allow the brain to control external devices directly and without intermediate motor output. The control of such actuated systems might be more effectively performed by representing high-level plans – such as 3D motor actions, navigational plans or rotation of objects – directly on the relevant non-Euclidean manifolds. We therefore expect that new inference methods in such spaces might accelerate the development of BMIs, fostering a range of medical applications, from amputees using neuroprosthetic devices as substitutes for missing limbs to surgeons operating remote high-precision surgical devices using neural activity directly. These applications come with various ethical and societal concerns; in particular, the ability to automatically extract internal brain representations comes with concerns of privacy. Fortunately, many of these challenges are already being considered by the community and actively explored in the field of bioethics (Clausen, 2009), and we hope that such ethical considerations will continue to shape the way we do research in the future.",Broader Impact,244,8,,,FALSE,TRUE,FALSE,Manifold GPLVMs for discovering non-Euclidean latent structure in neural data,Neuroscience and Cognitive Science -> Neuroscience,Algorithms -> Nonlinear Dimensionality Reduction and Manifold Learning; Neuroscience and Cognitive Science -> Neural Coding; Probabilistic Methods -> Gaussian Processes; Probabilistic Methods -> Latent Variable Models,Neuroscience and cognitive science,"['Kristopher Jensen', 'Chu Kao', ' Marco Tripodi', ' Guillaume Hennequin']","{'University of Cambridge', 'MRC', 'Cambridge'}",1,0,0,{'UK'}
Distributed Distillation for On-Device Learning,"Ilai Bistritz, Ariana Mann, Nicholas Bambos",Distributed Distillation for On-Device Learning,fef6f971605336724b5e6c0c12dc2534,https://proceedings.neurips.cc/paper/2020/file/fef6f971605336724b5e6c0c12dc2534-Paper.pdf,"This work deals with combining the training efforts of edge devices to obtain better machine learning models on each device. It scales up machine learning, making ML applications available on many more devices and accessible to many more people with all the positive and the negative effects that may ensue. At the same time, it maintains the setting where users keep their data on their device which allows for increased privacy and prevents the monopolistic aggregation of user data by large companies. A well functioning smart home IoT device that never records your conversations to the company’s servers should be an important milestone. By addressing the decentralized regime, Distributed Distillation further removes the dependency on a central authority, which contributes to making machine learning more open and democratic in nature. With no central server required to process any data or parameters, this work lowers the barrier to entry to deploy such an algorithm. On the negative side, the issue of bias in machine learning potentially increases in a decentralized system where it is harder to evaluate the decision outcomes and all countermeasures must also be implemented in a decentralized fashion.",Broader Impact,190,7,,,FALSE,TRUE,FALSE,Distributed Distillation for On-Device Learning,Deep Learning -> Optimization for Deep Networks,Algorithms -> Communication- or Memory-Bounded Learning,Resource aware machine learning,"['Ilai Bistritz', ' Ariana Mann', ' Nicholas Bambos']","{'Stanford', 'Stanford University'}",1,0,0,{'USA'}
COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning,"Simon Ging, Mohammadreza Zolfaghari, Hamed Pirsiavash, Thomas Brox",COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning,ff0abbcc0227c9124a804b084d161a2d,https://proceedings.neurips.cc/paper/2020/file/ff0abbcc0227c9124a804b084d161a2d-Paper.pdf,"This work contributes fundamental research and does not present any foreseeable societal consequence. In the long run, this line of research can contribute to services on video search and video organisation.",Broader Impact,31,2,TRUE,TRUE,FALSE,TRUE,FALSE,COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning,Applications -> Video Analysis,Algorithms -> Multimodal Learning; Algorithms -> Representation Learning; Deep Learning -> Attention Models,,"['Mohammadreza Zolfaghari', ' Simon Ging', ' Hamed Pirsiavash', ' Thomas Brox']","{'Uni Freiburg', 'University of Maryland, Baltimore County', 'University of Freiburg'}",1,0,0,"{'USA', 'Germany'}"
Passport-aware Normalization for Deep Model Protection,"Jie Zhang, Dongdong Chen, Jing Liao, Weiming Zhang, Gang Hua, Nenghai Yu",Passport-aware Normalization for Deep Model Protection,ff1418e8cc993fe8abcfe3ce2003e5c5,https://proceedings.neurips.cc/paper/2020/file/ff1418e8cc993fe8abcfe3ce2003e5c5-Paper.pdf,"Though deep learning evolves very fast in these years, IP protection for deep models is seriously under-researched. In this work, we mainly aim to propose a general technique for deep model IP protection. It will help both academia and industry to protect their interests from illegal distribution or usage. We hope it can inspire more works along this important direction.",Broader Impact,60,4,FALSE,FALSE,FALSE,TRUE,FALSE,Passport-aware Normalization for Deep Model Protection,Applications -> Computer Vision,Deep Learning,Deep learning,"['Jie Zhang', ' Dongdong Chen', ' Jing Liao', ' Weiming Zhang', ' Gang Hua', ' Nenghai Yu']","{'University of Science and Technology of China', 'Wormpex AI Research', 'City University of Hong Kong', 'Microsoft Cloud AI'}",1,1,1,"{'USA', 'China'}"
Sampling-Decomposable Generative Adversarial Recommender,"Binbin Jin, Defu Lian, Zheng Liu, Qi Liu, Jianhui Ma, Xing Xie, Enhong Chen",Sampling-Decomposable Generative Adversarial Recommender,ff42b03a06a1bed4e936f0e04958e168,https://proceedings.neurips.cc/paper/2020/file/ff42b03a06a1bed4e936f0e04958e168-Paper.pdf,"In this paper, we develop a new recommendation algorithm, which aims to efficiently solve the sparsity challenge in recommender system. The offline evaluation results on multiple datasets show that the new algorithm achieves better recommendation performance in terms of NDCG. The task does not leverage any biases in the data. As a consequence, the customers who often use recommendation services may more easily figure out their interested products, the researchers who design new recommendation algorithms may be inspired by the insight delivered in this paper, and the engineers who develop recommendation algorithms may implement the new algorithm and incorporate the new loss function and the new negative sampler in their recommendation services. Nobody would be put at disadvantage from this research. The practical recommendation service usually adopt the ensemble of many recommendation models, so any single algorithm does not lead to any serious consequences of user experiences.",Broader Impact,147,6,,,FALSE,TRUE,FALSE,Sampling-Decomposable Generative Adversarial Recommender,Algorithms -> Collaborative Filtering,Applications -> Recommender Systems; Deep Learning -> Adversarial Networks,"Collaborative Filtering, Recommender Systems, Adversarial Networks","['Binbin Jin', ' Defu Lian', ' Zheng Liu', ' Qi Liu', ' Jianhui Ma', ' Xing Xie', ' Enhong Chen']","{'University of Science and Technology of China', 'Microsoft', 'Microsoft Research Asia'}",1,1,1,"{'USA', 'China'}"
Limits to Depth Efficiencies of Self-Attention,"Yoav Levine, Noam Wies, Or Sharir, Hofit Bata, Amnon Shashua",Limits to Depth Efficiencies of Self-Attention,ff4dfdf5904e920ce52b48c1cef97829,https://proceedings.neurips.cc/paper/2020/file/ff4dfdf5904e920ce52b48c1cef97829-Paper.pdf,"Our work aims at providing fundamental guidelines which can assist all fields that employ Transformer-based architectures to use more efficient models. This way, these fields can achieve their goals while consuming less resources.",Broader Impact,33,4,FALSE,FALSE,TRUE,TRUE,FALSE,Limits to Depth Efficiencies of Self-Attention,Deep Learning -> Analysis and Understanding of Deep Networks,Deep Learning -> Attention Models,Deep learning,"['Yoav Levine', ' Noam Wies', ' Or Sharir', ' Hofit Bata', ' Amnon Shashua']","{'HUJI', 'Hebrew University of Jerusalem'}",1,1,1,{'Israel'}